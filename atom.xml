<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xgp &amp; Blog</title>
  
  <subtitle>Today is still beautiful</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wsdlxgp.top/"/>
  <updated>2020-06-07T14:35:40.116Z</updated>
  <id>https://wsdlxgp.top/</id>
  
  <author>
    <name>Wu Shao Dong</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>k8s架构，基本概念</title>
    <link href="https://wsdlxgp.top/posts/e863.html"/>
    <id>https://wsdlxgp.top/posts/e863.html</id>
    <published>2020-06-07T12:10:40.527Z</published>
    <updated>2020-06-07T14:35:40.116Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th>主机名</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td></td></tr><tr><td>node01</td><td>192.168.1.22</td><td></td></tr><tr><td>node02</td><td>192.168.1.23</td><td></td></tr></tbody></table><h1>kubernetes架构</h1><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/qqq.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/qqq.png" alt="image-20200104100759831"></a></p><p><strong>在这张系统架构图中，我们把服务分为运行在工作节点上的服务和组成集群级别控制板的服务。<br>Kubernetes节点有运行应用容器必备的服务，而这些都是受Master的控制。<br>每次个节点上当然都要运行Docker。Docker来负责所有具体的映像下载和容器运行。<br>Kubernetes主要由以下几个核心组件组成：</strong></p><h3 id="kubectl：k8s是命令行端，用来发送客户的操作指令。"><strong>kubectl</strong>：k8s是命令行端，用来发送客户的操作指令。</h3><h2 id="master节点">master节点</h2><p><strong>1. API server[资源操作入口]</strong>：是k8s集群的前端接口，各种各样客户端工具以及k8s的其他组件可以通过它管理k8s集群的各种资源。它提供了HTTP/HTTPS RESTful API,即K8S API。</p><blockquote><ul><li><strong>提供了资源对象的唯一操作入口，其他所有组件都必须通过它提供的API来操作资源数据，只有API Server与存储通信，其他模块通过API Server访问集群状态。</strong></li></ul><p><strong>第一，是为了保证集群状态访问的安全。</strong></p><p><strong>第二，是为了隔离集群状态访问的方式和后端存储实现的方式：API Server是状态访问的方式，不会因为后端存储技术etcd的改变而改变。</strong></p><ul><li><strong>作为kubernetes系统的入口，封装了核心对象的增删改查操作，以<a href="https://www.centos.bz/tag/restful/" target="_blank" rel="noopener">RESTFul</a>接口方式提供给外部客户和内部组件调用。对相关的资源数据“全量查询”+“变化监听”，实时完成相关的业务功能。</strong></li></ul></blockquote><p><strong>2. Scheduler[集群分发调度器]</strong>：负责决定将Pod放在哪个Node上运行。在调度时，会充分考虑集群的拓扑结构，当前各个节点的负载情况，以及应对高可用、性能、数据亲和性和需求。</p><blockquote><p><strong>1.Scheduler收集和分析当前Kubernetes集群中所有Minion节点的资源(内存、CPU)负载情况，然后依此分发新建的Pod到Kubernetes集群中可用的节点。</strong></p><p><strong>2.实时监测Kubernetes集群中未分发和已分发的所有运行的Pod。</strong></p><p><strong>3.Scheduler也监测Minion节点信息，由于会频繁查找Minion节点，Scheduler会缓存一份最新的信息在本地。</strong></p><p><strong>4.最后，Scheduler在分发Pod到指定的Minion节点后，会把Pod相关的信息Binding写回API Server。</strong></p></blockquote><p><strong>4. Controller Manager[内部管理控制中心]</strong>：负责管理集群的各种资源，保证资源处于预期的状态。它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等。</p><blockquote><p><strong>实现集群故障检测和恢复的自动化工作，负责执行各种控制器，主要有：</strong></p><p><strong>1.endpoint-controller：定期关联<a href="https://www.centos.bz/tag/service/" target="_blank" rel="noopener">service</a>和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的。</strong></p><p><strong>2.replication-controller：定期关联replicationController和pod，保证replicationController定义的复制数量与实际运行pod的数量总是一致的。</strong></p></blockquote><p><strong>5. Etcd</strong>：负责保存k8s集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速的通知k8s相关组件。<a href="https://wsdlxgp.top/posts/cd85.html">（第三方组件）它有可替换方案。Consul、zookeeper</a></p><p><strong>6. Pod:</strong> k8s集群的最小组成单位。一个Pod内，可以运行一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。</p><p><strong>7. Flanner</strong>：是k8s集群网络，可以保证Pod的跨主机通信。也有替换方案。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod --all-namespaces<br>//查看pod信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104100759831.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104100759831.png" alt="image-20200104100759831"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod --all-namespaces -o wide<br>//显示pod的节点信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104101023909.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104101023909.png" alt="image-20200104101023909"></a></p><h2 id="Node节点">Node节点</h2><p><strong>Kubelet[节点上的Pod管家]</strong>：它是Node的agent(代理)，当Scheduler确定某 个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet,kubelet会根据这些信息创建和运行容器，并向Master报告运行状态。</p><blockquote><ul><li><strong>负责Node节点上pod的创建、修改、监控、删除等全生命周期的管理</strong></li><li><strong>定时上报本Node的状态信息给API Server。</strong></li><li><strong>kubelet是Master API Server和Minion之间的桥梁，接收Master API Server分配给它的commands和work，与持久性键值存储etcd、file、server和http进行交互，读取配置信息。</strong></li><li><strong>具体的工作如下：</strong></li></ul><p><strong>设置容器的环境变量、给容器绑定<a href="https://www.centos.bz/tag/volume/" target="_blank" rel="noopener">Volume</a>、给容器绑定Port、根据指定的Pod运行一个单一容器、给指定的Pod创建network 容器。</strong></p><p><strong>同步Pod的状态、同步Pod的状态、从<a href="https://www.centos.bz/tag/cadvisor/" target="_blank" rel="noopener">cAdvisor</a>获取<a href="https://www.centos.bz/tag/container/" target="_blank" rel="noopener">Container</a> info、 pod info、 root info、 <a href="https://www.centos.bz/tag/machine/" target="_blank" rel="noopener">machine</a> info。</strong></p><p><strong>在容器中运行命令、杀死容器、删除Pod的所有容器。</strong></p></blockquote><p>**kube-proxy[负载均衡、路由转发]:**负责将访问service的TCP/UDP数据流转发到后端的容器。如果有多个副本，kube-proxy会实现负载均衡。</p><blockquote><ul><li><strong>Proxy是为了解决外部网络能够访问跨机器集群中容器提供的应用服务而设计的，运行在每个Node上。Proxy提供TCP/UDP sockets的proxy，每创建一种Service，Proxy主要从etcd获取Services和Endpoints的配置信息（也可以从file获取），然后根据配置信息在Minion上启动一个Proxy的进程并监听相应的服务端口，当外部请求发生时，Proxy会根据Load Balancer将请求分发到后端正确的容器处理。</strong></li><li><strong>Proxy不但解决了同一主宿机相同服务端口冲突的问题，还提供了Service转发服务端口对外提供服务的能力，Proxy后端使用了随机、轮循负载均衡算法。</strong></li></ul></blockquote><h2 id="除了核心组件，还有一些推荐的Add-ons：">除了核心组件，还有一些推荐的Add-ons：</h2><p><strong>kube-dns负责为整个集群提供DNS服务<br>Ingress Controller为服务提供外网入口<br>Heapster提供资源监控<br>Dashboard提供GUI<br>Federation提供跨可用区的集群<br>Fluentd-elasticsearch提供集群日志采集、存储与查询</strong></p><h2 id="一-分层架构">一. 分层架构</h2><p>Kubernetes设计理念和功能其实就是一个类似Linux的分层架构，如下图所示。<br><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607201704.png" alt="image-20200607201710035"></p><blockquote><p><strong>核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境</strong><br><strong>应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等）</strong><br><strong>管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等）</strong><br><strong>接口层：kubectl命令行工具、客户端SDK以及集群联邦</strong><br><strong>生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴</strong><br><strong>Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等</strong><br><strong>Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等</strong></p></blockquote><h2 id="二-在K8s中运行一个容器应用">二. 在K8s中运行一个容器应用</h2><h4 id="下面通过运行一个容器应用的过程，来一起理解一下K8s组件是如何协作的。">下面通过运行一个容器应用的过程，来一起理解一下K8s组件是如何协作的。</h4><p><strong>开发者开发一个应用后，打包Docker镜像，上传到Docker registry；然后编写一个yaml部署描述文件，以描述应用的结构和资源需求。开发者通过kubectl（或其它应用），将部署描述文件提交到API server，API server将部署需求更新到etcd。etcd在K8s管理结点中的作用相当于数据库，其它组件提交到API server的数据都存储于etcd。API server非常轻量，并不会直接去创建或管理Pod等资源，在多数场景下甚至不会去主动调用其它的K8s组件发出指令。其它组件通过建立和API server的长连接，监视关心的对象，监视到变化后，执行所负责的操作。</strong></p><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607201902.png" alt="img"></p><p><strong>继续我们的启动应用之旅，如图所示，Controller Manager中的控制器监视到新的部署描述后，根据部署描述，创建ReplicaSet、Pod等资源。Scheduler监视到新的Pod资源后，结合集群的资源情况，选定一或多个工作结点运行Pod。工作结点上的Kubelet监视到有Pod被计划在自己的结点后，向Docker等Container runtime发出启动容器的指令，Docker engineer将按照指令从Docker registy拉取镜像，然后启动并运行容器。</strong></p><h2 id="三-K8s集群的高可用部署">三. K8s集群的高可用部署</h2><p><strong>通过之前的介绍，我们看到K8s可以在多个工作结点上启动并管理容器，下面来学习一下，如何实现管理结点的高可用部署。</strong></p><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607201914.png" alt="img"></p><p><strong>上图的K8s高可用部署中有3个管理结点。etcd自身是一个分布式数据存储系统，按照其多实例部署方案，结点只需在启动时知道其它结点的IP和端口号即可组成高可用环境。和通常的应用服务器一样，API Server是无状态的，可以运行任意多个实例，且彼此之间无需互相知道。为了能使kubectl等客户端和Kubelet等组件连接到健康的API Server、减轻单台API Server的压力，需使用基础架构提供的负载均衡器作为多个API Server实例的入口。如上图的部署方法，每个主结点上都运行了一个etcd实例，这样API Server只需连接本地的etcd实例即可，无需再使用负载均衡器作为etcd的入口。</strong></p><p><strong>Controller Manager和Scheduler需要修改K8s集群，同时修改时可能引发并发问题。假设两个ReplicaSet Controller同时监视到需创建一个Pod，然后同时进行创建操作，就会创建出两个Pod。K8s为了避免这个问题，一组此类组件的实例将选举出一个leader，仅有leader处于活动状态，其它实例处于待命状态。Controller Manager和Scheduler也可以独立于API server部署，通过负载均衡器连接到多个API server实例。</strong></p><h2 id="范例">范例</h2><blockquote><h3 id="分析各个组件的作用以及架构工作流程">分析各个组件的作用以及架构工作流程:</h3><p><strong>1) kubectl发送部署 请求到API server</strong><br><strong>2) APIserver通知Controller Manager创建一个Deployment资源。</strong><br><strong>3) Scheduler执行调度任务,将两个副本Pod分发到node01和node02. 上。</strong><br><strong>4) node01和node02, 上的kubelet在各自节点上创建并运行Pod。</strong></p><h3 id="补充">补充</h3><p><strong>1.应用的配置和当前的状态信息保存在etcd中，执行kubectl get pod时API server会从etcd中读取这些数据。</strong></p><p><strong>2.flannel会为每个Pod分配一个IP。 但此时没有创建Service资源，目前kube-proxy还没有参与进来。</strong></p></blockquote><h3 id="运行一个例子（创建一个deployment资源对象-pod控制器-）">运行一个例子（创建一个deployment资源对象&lt;pod控制器&gt;）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl run test-web --image=httpd --replicas=2<br>//创建一个deployment资源对象。<br></code></pre></td></tr></table></figure><p><em><strong>运行完成之后，如果有镜像可直接开启，没有的话需要等待一会儿，node节点要在docker hup上下载</strong></em></p><h4 id="查看一下">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get  deployments.或 kubectl get  deploy<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104110812772.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104110812772.png" alt="image-20200104110812772"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104110954406.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104110954406.png" alt="image-20200104110954406"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod  -o wide<br>//显示pod的节点信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104111128779.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104111128779.png" alt="image-20200104111128779"></a></p><p><em><strong>如果，node节点没有运行test-web服务，需要在节点上重启一下</strong></em></p><h3 id="如果删除一个pod">如果删除一个pod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl delete pod test-web-5b56bdff65-2njqf<br></code></pre></td></tr></table></figure><h4 id="查看一下-2">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104112418012.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200104112418012.png" alt="image-20200104112418012"></a></p><p><em><strong>现在发现容器还存在，因为控制器会自动发现，一旦与之前执行的命令有误差，他会自动补全。</strong></em></p><p><a href="https://blog.csdn.net/gongxsh00/article/details/79932136" target="_blank" rel="noopener">https://blog.csdn.net/gongxsh00/article/details/79932136</a></p><p><a href="https://www.jianshu.com/p/18edac81c718" target="_blank" rel="noopener">https://www.jianshu.com/p/18edac81c718</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;服务&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;master&lt;/td&gt;
&lt;td&gt;192.168.1.21&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="docker" scheme="https://wsdlxgp.top/tags/docker/"/>
    
      <category term="kubeadml" scheme="https://wsdlxgp.top/tags/kubeadml/"/>
    
  </entry>
  
  <entry>
    <title>k8s复习</title>
    <link href="https://wsdlxgp.top/posts/h8er.html"/>
    <id>https://wsdlxgp.top/posts/h8er.html</id>
    <published>2020-06-07T12:10:33.599Z</published>
    <updated>2020-06-07T14:37:58.055Z</updated>
    
    <content type="html"><![CDATA[<h2 id="创建镜像的方法">创建镜像的方法</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# vim Dockerfile<br>FROM nginx<br>ADD index.htm /usr/share/nginx/html/<br>//创建Dockerfile<br><br>[root@master test]# echo "&lt;h1&gt;version 01 wsd&lt;/h1&gt;" &gt; index.html<br>[root@master test]# docker build -t 192.168.1.1:5000/nginx .<br>[root@master test]# echo "&lt;h1&gt;version 02 wsd&lt;/h1&gt;" &gt; index.html <br>[root@master test]# docker build -t 192.168.1.1:5000/nginx:v1.14 <br>[root@master test]# echo "&lt;h1&gt;version 03 wsd&lt;/h1&gt;" &gt; index.html .<br>[root@master test]# docker build -t 192.168.1.1:5000/nginx:v1.15 .<br>//创建不同index.html文件，生成测试镜像<br><br>[root@master test]# docker push 192.168.1.1:5000/nginx<br>[root@master test]# docker push 192.168.1.1:5000/nginx:v1.14<br>[root@master test]# docker push 192.168.1.1:5000/nginx:v1.15<br>//上传镜像<br></code></pre></td></tr></table></figure><h1>2) deployment名字为:nginx,保证运行3个Pod.service名字为：nginx-svc。映射到主机端口：31234.（10分）</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# docker pull nginx<br>//下载nginx镜像<br>[root@master yaml]# vim deployment.yaml <br>//编写deployment和service的yaml文件<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nginx<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx<br>    spec:<br>      containers:<br>      - name: nginx<br>        image: nginx<br>---<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: nginx-svc<br>spec:<br>  type: NodePort<br>  selector:<br>    app: nginx<br>  ports:<br>    - port: 80<br>      targetPort: 80<br>      nodePort: 31234<br></code></pre></td></tr></table></figure><h2 id="执行一下">执行一下</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f deployment.yaml<br></code></pre></td></tr></table></figure><h2 id="查看一下">查看一下</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://q9npprkue.bkt.clouddn.com/image-20200315100201329.png" target="_blank" rel="noopener"><img src="http://q9npprkue.bkt.clouddn.com/image-20200315100201329.png" alt="image-20200315100201329"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315100228967.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315100228967.png" alt="image-20200315100228967"></a></p><h2 id="访问一下http-192-168-1-21-31234">访问一下http://192.168.1.21:31234/</h2><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315100419217.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315100419217.png" alt="image-20200315100419217"></a></p><h1>3) 共有3个版本，版本1对应image镜像为：nginx，版本2对应的image为：nginx:1.14.版本3对应的版本为:nginx:1.15.分别运行各版本，每个版本要有在浏览器的访问验证。（10分）</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# docker pull nginx<br>[root@master yaml]# docker pull nginx:1.14<br>[root@master yaml]# docker pull nginx:1.15<br>//下载所需镜像<br></code></pre></td></tr></table></figure><h2 id="编写deployment的yaml文件">编写deployment的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim banben1.yaml<br>//编写deployment和service的yaml文件<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nginx<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx-svc        <br>    spec:<br>      containers:<br>      - name: nginx         <br>        image: nginx         #更改一下镜像（1.14和1.15的）<br>[root@master yaml]# vim banben2.yaml<br>//编写deployment和service的yaml文件<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nginx2<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx-svc        <br>    spec:<br>      containers:<br>      - name: nginx         <br>        image: nginx:1.14        #更改一下镜像（1.14和1.15的）<br>[root@master yaml]# vim banben3.yaml<br>//编写deployment和service的yaml文件<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nginx3<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx-svc        <br>    spec:<br>      containers:<br>      - name: nginx         <br>        image: nginx:1.15         #更改一下镜像（1.14和1.15的）<br></code></pre></td></tr></table></figure><h2 id="编写service的yaml文件">编写service的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim ngnix-svc.yaml <br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: nginx-svc<br>spec:<br>  type: NodePort<br>  selector:<br>    app: nginx-svc<br>  ports:<br>    - port: 80<br>      targetPort: 80<br>      nodePort: 31235<br></code></pre></td></tr></table></figure><h3 id="执行一下（记录版本信息）">执行一下（记录版本信息）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f banben1.yaml --record <br>[root@master yaml]# kubectl apply -f banben2.yaml --record <br>[root@master yaml]# kubectl apply -f banben3.yaml --record <br>[root@master yaml]# kubectl apply -f ngnix-svc.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-2">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315145551904.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315145551904.png" alt="image-20200315145551904"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315142530998.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315142530998.png" alt="image-20200315142530998"></a></p><h3 id="访问一下-http-192-168-1-21-31235">访问一下 <a href="http://192.168.1.21:31235/" target="_blank" rel="noopener">http://192.168.1.21:31235/</a></h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315143242088.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315143242088.png" alt="image-20200315143242088"></a></p><h1>4)运行到版本3之后，进行回滚操作回滚到版本4.（5分）</h1><h2 id="查看记录的版本信息">查看记录的版本信息</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]#  kubectl rollout history deployment nginx<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315142738558.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315142738558.png" alt="image-20200315142738558"></a></p><h3 id="回滚到指定版本">回滚到指定版本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout undo deployment nginx --to-revision=4<br>//这里指定的是版本信息的编号<br></code></pre></td></tr></table></figure><h3 id="访问一下">访问一下</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315143715792.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315143715792.png" alt="image-20200315143715792"></a></p><h1>5) 此时更改默认的3个Pod的访问界面,.版本1的访问界面内容为：考生名称+version:No1.版本2的访问界面:考生名称+version:No2,以此类推。（5分）</h1><h3 id="修改POD页面内容（三台不一样）">修改POD页面内容（三台不一样）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl exec -it xgp-web-8d5f9656f-8z7d9 /bin/bash<br>//根据pod名称进入pod之中<br></code></pre></td></tr></table></figure><h3 id="进入容器后修改页面内容">进入容器后修改页面内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">1<br>[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-8vcvt /bin/bash<br>root@nginx-d6c5c85cb-8vcvt:/# echo "&lt;h1&gt;version 01 wushaodong&lt;/h1&gt;"   &gt; /usr/share/nginx/html/index.html <br>root@nginx-d6c5c85cb-8vcvt:/# exit<br><br>2<br>[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-bxvvt /bin/bash<br>root@nginx-d6c5c85cb-bxvvt:/# echo "&lt;h1&gt;version 02 wushaodong&lt;/h1&gt;"   &gt; /usr/share/nginx/html/index.html<br>root@nginx-d6c5c85cb-bxvvt:/# exit<br><br>3<br>[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-lhlz9 /bin/bash<br>root@nginx-d6c5c85cb-lhlz9:/# echo "&lt;h1&gt;version 03 wushaodong&lt;/h1&gt;"   &gt; /usr/share/nginx/html/index.html<br>root@nginx-d6c5c85cb-lhlz9:/# exit<br></code></pre></td></tr></table></figure><h1>6) 验证界面是否会会有轮训效果，并加以分析论述。（5分）</h1><p><em><strong>不要在浏览器里测试轮询，有缓存</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:31235<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315150130146.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315150130146.png" alt="image-20200315150130146"></a></p><p><strong>答：会有轮询的效果，kubernetes 内部的负载均衡是通过 iptables 的 probability 特性来做到的，kube-proxy通过iptables 将访问 Service 的流量转发到后端 Pod，而且使用类似轮询的负载均衡策略。</strong></p><h1>7) 创建一个NFS PV，NFS共享目录为：考生名称。PV名称为：new-pv。创建一个PVC，名称为new-pvc。单独创建一个pod，使用new-pv，运行之后，验证nfs是否使用成功。（10分）</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# yum -y install nfs-utils rpcbind<br><br>[root@master yaml]# mkdir /wushaodong<br>//创建指定名称的共享目录<br>[root@master yaml]# echo "/wushaodong *(rw,sync,no_root_squash)" &gt; /etc/exports<br>//编写共享目录的权限<br><br>[root@master ~]#  systemctl start nfs-server<br>[root@master ~]#  systemctl start rpcbind<br>//启动服务<br><br>[root@master yaml]# showmount -e<br>//测试一下<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315152012176.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315152012176.png" alt="image-20200315152012176"></a></p><h2 id="1、创建一个NFS-PV的yaml文件">1、创建一个NFS PV的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim new-pv.yaml<br><br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: new-xgp<br>spec:<br>  capacity:<br>    storage: 1Gi<br>  accessModes:<br>    - ReadWriteOnce<br>  persistentVolumeReclaimPolicy: Recycle<br>  storageClassName: nfs<br>  nfs:<br>    path: /wushaodong/new-pv<br>    server: 192.168.1.21<br><br>[root@master yaml]# mkdir /wushaodong/new-pv<br>//创建指定目录<br></code></pre></td></tr></table></figure><h3 id="执行一下-2">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply  -f  new-pv.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-3">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315152639218.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315152639218.png" alt="image-20200315152639218"></a></p><h2 id="2、创建一个PVC的yaml文件">2、创建一个PVC的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim new-pvc.yaml<br>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: new-pvc<br>spec:<br>  accessModes:            #要和pv的一直否则关联不成功<br>  - ReadWriteOnce<br>  resources:<br>    requests:<br>      storage: 1Gi<br>  storageClassName: nfs   #要和pv的一直否则关联不成功<br></code></pre></td></tr></table></figure><h3 id="执行一下-3">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply  -f  new-pvc.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-4">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pvc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315153049267.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315153049267.png" alt="image-20200315153049267"></a></p><h2 id="3、单独创建一个pod，使用new-pv">3、单独创建一个pod，使用new-pv</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim pod.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: xgp-pod<br>spec:<br>  containers:<br>  - name: xgp-pod<br>    image: busybox<br>    args:<br>    - /bin/sh<br>    - -c<br>    - sleep 300000<br>    volumeMounts:<br>    - mountPath: /wushaodong  #容器的被挂载目录<br>      name: volumedata<br>  volumes:<br>    - name: volumedata<br>      persistentVolumeClaim:<br>        claimName: new-pvc<br></code></pre></td></tr></table></figure><h3 id="执行一下-4">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-5">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315153837882.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315153837882.png" alt="image-20200315153837882"></a></p><h2 id="4、测试一下">4、测试一下</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it xgp-pod /bin/sh<br>//进入pod<br><span class="hljs-meta">#</span><span class="bash">  <span class="hljs-built_in">echo</span> <span class="hljs-string">"xgpIwsd"</span> &gt; /wushaodong/xgp.txt</span><br>//添加内容到挂载目录<br><span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">exit</span></span><br></code></pre></td></tr></table></figure><h3 id="查看一下，挂载目录是否有添加内容">查看一下，挂载目录是否有添加内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# cat /wushaodong/new-pv/xgp.txt<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315154239587.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315154239587.png" alt="image-20200315154239587"></a></p><h1>8）请简述k8s集群中，master节点有哪些组件，node节点有哪些组件，作用分别有什么作用，各组件又是怎么交互的。（5分）</h1><h2 id="master节点">master节点</h2><p><strong>1. API server[资源操作入口]</strong>：是k8s集群的前端接口，各种各样客户端工具以及k8s的其他组件可以通过它管理k8s集群的各种资源。它提供了HTTP/HTTPS RESTful API,即K8S API。</p><blockquote><ul><li>提供了资源对象的唯一操作入口，其他所有组件都必须通过它提供的API来操作资源数据，只有API Server与存储通信，其他模块通过API Server访问集群状态。</li></ul><p>第一，是为了保证集群状态访问的安全。</p><p>第二，是为了隔离集群状态访问的方式和后端存储实现的方式：API Server是状态访问的方式，不会因为后端存储技术etcd的改变而改变。</p><ul><li>作为kubernetes系统的入口，封装了核心对象的增删改查操作，以<a href="https://www.centos.bz/tag/restful/" target="_blank" rel="noopener">RESTFul</a>接口方式提供给外部客户和内部组件调用。对相关的资源数据“全量查询”+“变化监听”，实时完成相关的业务功能。</li></ul></blockquote><p><strong>2. Scheduler[集群分发调度器]</strong>：负责决定将Pod放在哪个Node上运行。在调度时，会充分考虑集群的拓扑结构，当前各个节点的负载情况，以及应对高可用、性能、数据亲和性和需求。</p><blockquote><p>1.Scheduler收集和分析当前Kubernetes集群中所有Minion节点的资源(内存、CPU)负载情况，然后依此分发新建的Pod到Kubernetes集群中可用的节点。</p><p>2.实时监测Kubernetes集群中未分发和已分发的所有运行的Pod。</p><p>3.Scheduler也监测Minion节点信息，由于会频繁查找Minion节点，Scheduler会缓存一份最新的信息在本地。</p><p>4.最后，Scheduler在分发Pod到指定的Minion节点后，会把Pod相关的信息Binding写回API Server。</p></blockquote><p><strong>4. Controller Manager[内部管理控制中心]</strong>：负责管理集群的各种资源，保证资源处于预期的状态。它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等。</p><blockquote><p>实现集群故障检测和恢复的自动化工作，负责执行各种控制器，主要有：</p><p>1.endpoint-controller：定期关联<a href="https://www.centos.bz/tag/service/" target="_blank" rel="noopener">service</a>和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的。</p><p>2.replication-controller：定期关联replicationController和pod，保证replicationController定义的复制数量与实际运行pod的数量总是一致的。</p></blockquote><p>**5. Etcd：**负责保存k8s集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速的通知k8s相关组件。<a href="https://wsdlxgp.top/posts/gssl.html">（第三方组件）它有可替换方案。Consul、zookeeper</a></p><p><strong>6. Pod:</strong> k8s集群的最小组成单位。一个Pod内，可以运行一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。</p><p>**7. Flanner：**是k8s集群网络，可以保证Pod的跨主机通信。也有替换方案。</p><h2 id="Node节点">Node节点</h2><p><strong>Kubelet[节点上的Pod管家]</strong>：它是Node的agent(代理)，当Scheduler确定某 个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet,kubelet会根据这些信息创建和运行容器，并向Master报告运行状态。</p><blockquote><ul><li>负责Node节点上pod的创建、修改、监控、删除等全生命周期的管理</li><li>定时上报本Node的状态信息给API Server。</li><li>kubelet是Master API Server和Minion之间的桥梁，接收Master API Server分配给它的commands和work，与持久性键值存储etcd、file、server和http进行交互，读取配置信息。</li><li>具体的工作如下：</li></ul><p>设置容器的环境变量、给容器绑定<a href="https://www.centos.bz/tag/volume/" target="_blank" rel="noopener">Volume</a>、给容器绑定Port、根据指定的Pod运行一个单一容器、给指定的Pod创建network 容器。</p><p>同步Pod的状态、同步Pod的状态、从<a href="https://www.centos.bz/tag/cadvisor/" target="_blank" rel="noopener">cAdvisor</a>获取<a href="https://www.centos.bz/tag/container/" target="_blank" rel="noopener">Container</a> info、 pod info、 root info、 <a href="https://www.centos.bz/tag/machine/" target="_blank" rel="noopener">machine</a> info。</p><p>在容器中运行命令、杀死容器、删除Pod的所有容器。</p></blockquote><p>**kube-proxy[负载均衡、路由转发]:**负责将访问service的TCP/UDP数据流转发到后端的容器。如果有多个<br>副本，kube-proxy会实现负载均衡。</p><blockquote><ul><li>Proxy是为了解决外部网络能够访问跨机器集群中容器提供的应用服务而设计的，运行在每个Node上。Proxy提供TCP/UDP sockets的proxy，每创建一种Service，Proxy主要从etcd获取Services和Endpoints的配置信息（也可以从file获取），然后根据配置信息在Minion上启动一个Proxy的进程并监听相应的服务端口，当外部请求发生时，Proxy会根据Load Balancer将请求分发到后端正确的容器处理。</li><li>Proxy不但解决了同一主宿机相同服务端口冲突的问题，还提供了Service转发服务端口对外提供服务的能力，Proxy后端使用了随机、轮循负载均衡算法。</li></ul></blockquote><h2 id="各个组件的作用以及架构工作流程">各个组件的作用以及架构工作流程:</h2><p><strong>1) kubectl发送部署 请求到API server</strong><br><strong>2) APIserver通知Controller Manager创建一个Deployment资源。</strong><br><strong>3) Scheduler执行调度任务,将两个副本Pod分发到node01和node02. 上。</strong><br><strong>4) node01和node02, 上的kubelet在各自节点上创建并运行Pod。</strong></p><h3 id="补充">补充</h3><p><strong>1.应用的配置和当前的状态信息保存在etcd中，执行kubectl get pod时API server会从etcd中读取这些数据。</strong></p><p><strong>2.flannel会为每个Pod分配一个IP。 但此时没有创建Service资源，目前kube-proxy还没有参与进来。</strong></p><h1>9）部署一个dashboard。（5分）</h1><h2 id="1、下载所需yaml文件和镜像">1、下载所需yaml文件和镜像</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc5/aio/deploy/recommended.yaml<br>[root@master https]# docker pull kubernetesui/dashboard:v2.0.0-rc5<br></code></pre></td></tr></table></figure><h2 id="2、修改-recommended-yaml">2、修改 recommended.yaml</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]#vim recommended.yaml <br>---<br>kind: Service<br>apiVersion: v1<br>metadata:<br>  labels:<br>    k8s-app: kubernetes-dashboard<br>  name: kubernetes-dashboard<br>  namespace: kubernetes-dashboard<br>spec:<br>  type: NodePort            #添加40<br>  ports:<br>    - port: 443<br>      targetPort: 8443<br>  selector:<br>    k8s-app: kubernetes-dashboard<br></code></pre></td></tr></table></figure><h3 id="执行一下-5">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl apply -f recommended.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-6">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get svc -n kubernetes-dashboard<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315154708443.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315154708443.png" alt="image-20200315154708443"></a></p><h2 id="3、浏览器访问https-192-168-1-21-30949">3、浏览器访问https://192.168.1.21:30949/</h2><p><strong>PS:如果是使用的旧版本的dashboard, 使用Google浏览器登录，可能是不成功的，需要换成其他的浏览器，比如:火狐。</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315154859800.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315154859800.png" alt="image-20200315154859800"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315154929279.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315154929279.png" alt="image-20200315154929279"></a></p><h2 id="4、基于token的方法登录dashboard">4、基于token的方法登录dashboard</h2><h3 id="1-创建一个dashboard的管理用户">&lt;1&gt;创建一个dashboard的管理用户</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl create serviceaccount dashboard-admin -n kube-system<br></code></pre></td></tr></table></figure><h3 id="2-绑定用户为集群管理用户">&lt;2&gt;绑定用户为集群管理用户</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin<br></code></pre></td></tr></table></figure><h3 id="3-获取Token">&lt;3&gt;获取Token</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin<br>//先得到Token的名称<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315155029875.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315155029875.png" alt="image-20200315155029875"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl describe secrets -n kube-system  dashboard-admin-token-j874n<br>//查看上述得到的secret资源的详细信息，会得到token<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315155147297.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315155147297.png" alt="image-20200315155147297"></a></p><h3 id="4-在浏览器上使用token登录。">&lt;4&gt;在浏览器上使用token登录。</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315155307433.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315155307433.png" alt="image-20200315155307433"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315155326746.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315155326746.png" alt="image-20200315155326746"></a></p><p><strong>成功界面</strong></p><h1>10）使用helm的方式，部署mysql服务，要求使用storageclass作为持久化存储，服务运行之后，进入数据库，创建一个test库，库中一张test表，内容为： 9527.</h1><h1>然后模拟数据库Pod失败，待Pod重启后，查看对应数据是否还存在？（10分）</h1><h2 id="1、安装部署helm工具">1、安装部署helm工具</h2><h3 id="（1）下载helm的包">（1）下载helm的包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]#docker pull gcr.io/kubernetes-helm/tiller:v2.14.3<br>[root@master ~]# wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz<br></code></pre></td></tr></table></figure><h3 id="（2）把helm包的命令，复制到本地">（2）把helm包的命令，复制到本地</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# mv linux-amd64/helm /usr/local/bin/<br>//移动命令目录到/usr/local/bin/<br>[root@master helm]# chmod +x /usr/local/bin/helm <br>//给予执行权限<br>[root@master helm]# helm help<br>//验证是否安装成功<br></code></pre></td></tr></table></figure><h3 id="（3）设置命令自动补全">（3）设置命令自动补全</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]#  echo 'source &lt;(helm completion bash)' &gt;&gt; /etc/profile<br>[root@master helm]# . /etc/profile<br>//刷新一下<br></code></pre></td></tr></table></figure><h2 id="2、安装Tiller-server（服务端，需要创建授权用户）">2、安装Tiller server（服务端，需要创建授权用户）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim tiller-rbac.yaml   #创建授权用户<br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: tiller<br>  namespace: kube-system<br>---<br>apiVersion: rbac.authorization.k8s.io/v1beta1<br>kind: ClusterRoleBinding<br>metadata:<br>  name: tiller<br>roleRef:<br>  apiGroup: rbac.authorization.k8s.io<br>  kind: ClusterRole<br>  name: cluster-admin<br>subjects:<br>  - kind: ServiceAccount<br>    name: tiller<br>    namespace: kube-system<br></code></pre></td></tr></table></figure><h4 id="执行一下-6">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f tiller-rbac.yaml<br></code></pre></td></tr></table></figure><h3 id="（1）Tiller-server的环境初始化">（1）Tiller server的环境初始化</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# helm init  --service-account=tiller<br>//helm的服务端就是Tiller（因为是访问外国的网站，可能需要多次执行）<br></code></pre></td></tr></table></figure><h4 id="查看一下-7">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# kubectl get deployment. -n kube-system<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315163043816.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315163043816.png" alt="image-20200315163043816"></a></p><p><strong>现在发现没有开启，那是因为默认下载的Google的镜像，下载不下来</strong></p><h3 id="（2）设置镜像源改为阿里云的">（2）设置镜像源改为阿里云的</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts<br></code></pre></td></tr></table></figure><h4 id="查看一下-8">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# helm version<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315163313031.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315163313031.png" alt="image-20200315163313031"></a></p><h2 id="3、基于NFS服务，创建共享。">3、基于NFS服务，创建共享。</h2><p><strong>因为上面已经做过了，所以现在只需创建目录和设置权限即可</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master heml]# mkdir /xgpwsd<br>//创建目录<br>[root@master heml]# echo '/xgpwsd *(rw,sync,no_root_squash)' &gt;&gt; /etc/exports<br>//设置共享目录权限<br>[root@master heml]# systemctl restart nfs-server<br>[root@master heml]# systemctl restart rpcbind<br>//重启nfs服务<br>[root@master heml]# showmount -e<br>//测试一下<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315164157425.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315164157425.png" alt="image-20200315164157425"></a></p><h2 id="4、创建pv">4、创建pv</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# vim nfs-pv1.yml <br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: mysqlpv<br>spec:<br>  capacity:<br>    storage: 8Gi<br>  accessModes:<br>    - ReadWriteOnce<br>  persistentVolumeReclaimPolicy: Recycle<br>  nfs:<br>    path: /xgpwsd/xgp<br>    server: 192.168.1.21<br>[root@master xgp]# mkdir /xgpwsd/xgp<br>//创建所需目录<br></code></pre></td></tr></table></figure><h4 id="执行一下-7">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl apply -f nfs-pv1.yml<br></code></pre></td></tr></table></figure><h4 id="查看一下-9">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315182950429.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315182950429.png" alt="image-20200315182950429"></a></p><h2 id="5、创建StorageClass资源对象。">5、创建StorageClass资源对象。</h2><h3 id="（1）创建rbac权限。">（1）创建rbac权限。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim rbac.yaml <br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: nfs-provisioner<br>  namespace: default<br>---<br>apiVersion: rbac.authorization.k8s.io/v1<br>kind: ClusterRole<br>metadata:<br>  name: nfs-provisioner-runner<br>  namespace: default<br>rules:<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumes"]<br>      verbs: ["get", "list", "watch", "create", "delete"]<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumeclaims"]<br>      verbs: ["get", "list", "watch", "update"]<br>   -  apiGroups: ["storage.k8s.io"]<br>      resources: ["storageclasses"]<br>      verbs: ["get", "list", "watch"]<br>   -  apiGroups: [""]<br>      resources: ["events"]<br>      verbs: ["watch", "create", "update", "patch"]<br>   -  apiGroups: [""]<br>      resources: ["services", "endpoints"]<br>      verbs: ["get","create","list", "watch","update"]<br>   -  apiGroups: ["extensions"]<br>      resources: ["podsecuritypolicies"]<br>      resourceNames: ["nfs-provisioner"]<br>      verbs: ["use"]<br>---<br>kind: ClusterRoleBinding<br>apiVersion: rbac.authorization.k8s.io/v1<br>metadata:<br>  name: run-nfs-provisioner<br>subjects:<br>  - kind: ServiceAccount<br>    name: nfs-provisioner<br>    namespace: default        #必写字段<br>roleRef:<br>  kind: ClusterRole<br>  name: nfs-provisioner-runner<br>  apiGroup: rbac.authorization.k8s.io<br></code></pre></td></tr></table></figure><h4 id="执行一下-8">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f rbac.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）创建Deployment资源对象，用Pod代替-真正的NFS服务。">（2）创建Deployment资源对象，用Pod代替 真正的NFS服务。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nfs-deployment.yaml <br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nfs-client-provisioner<br>spec:<br>  replicas: 1<br>  strategy:<br>    type: Recreate<br>  template:<br>    metadata:<br>      labels:<br>        app: nfs-client-provisioner<br>    spec:<br>      serviceAccount: nfs-provisioner<br>      containers:<br>        - name: nfs-client-provisioner<br>          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner<br>          volumeMounts:<br>            - name: nfs-client-root<br>              mountPath:  /persistentvolumes<br>          env:<br>            - name: PROVISIONER_NAME<br>              value: xgp<br>            - name: NFS_SERVER<br>              value: 192.168.1.21<br>            - name: NFS_PATH<br>              value: /xgpwsd/wsd<br>      volumes:<br>        - name: nfs-client-root<br>          nfs:<br>            server: 192.168.1.21<br>            path: /xgpwsd/wsd<br>            <br>[root@master heml]# mkdir /xgpwsd/wsd<br>//创建指定目录<br></code></pre></td></tr></table></figure><h4 id="执行一下-9">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-deployment.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-10">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315164706266.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315164706266.png" alt="image-20200315164706266"></a></p><h3 id="（3）创建storageclass的yaml文件">（3）创建storageclass的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim xgp-storageclass.yaml <br>apiVersion: storage.k8s.io/v1<br>kind: StorageClass<br>metadata:<br>  name: xgp-nfs<br>provisioner: xgp  #通过provisioner字段关联到上述Deploy<br>reclaimPolicy: Retain<br></code></pre></td></tr></table></figure><h4 id="执行一下-10">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f xgp-storageclass.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-11">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get sc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315164758857.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315164758857.png" alt="image-20200315164758857"></a></p><h2 id="6、创建一个mysql服务">6、创建一个mysql服务</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# docker pull mysql:5.7.14<br>//下载所需镜像<br>[root@master yaml]# helm fetch stable/mysql<br>//直接下载stable/mysql的chart包<br>[root@master yaml]# tar -zxf mysql-0.3.5.tgz <br>//解压mysql包<br>[root@master yaml]# cd mysql/<br>[root@master mysql]# vim values.yaml <br>//修改values.yaml文件，添加storageClass存储卷<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315173613775.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315173613775.png" alt="image-20200315173613775"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# helm install stable/mysql -n xgp-mysql --set mysqlRootPassword=123.com -f values.yaml <br>//基于values.yaml和stable/mysql开启一个密码为123.com的mysqlpod<br></code></pre></td></tr></table></figure><h3 id="查看一下-12">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315173526818.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315173526818.png" alt="image-20200315173526818"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315173702896.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315173702896.png" alt="image-20200315173702896"></a></p><h2 id="7、进入mysql数据库，创建一个test库，库中一张test表，内容为：-9527。">7、进入mysql数据库，创建一个test库，库中一张test表，内容为： 9527。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl exec -it bdqn-mysql-mysql-7b89c7b99-8ff2r -- mysql -u root -p123.com<br></code></pre></td></tr></table></figure><h3 id="创建数据库">创建数据库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> create database <span class="hljs-built_in">test</span>;</span><br></code></pre></td></tr></table></figure><h3 id="切换数据库">切换数据库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> use <span class="hljs-built_in">test</span>;</span><br></code></pre></td></tr></table></figure><h3 id="创建表">创建表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> create table <span class="hljs-built_in">test</span>( id int(4))；</span><br></code></pre></td></tr></table></figure><h3 id="在表中插入数据">在表中插入数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> insert <span class="hljs-built_in">test</span> values(9527);</span><br></code></pre></td></tr></table></figure><h3 id="查看表">查看表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> select * from <span class="hljs-built_in">test</span>;</span><br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315181155502.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315181155502.png" alt="image-20200315181155502"></a></p><h2 id="8、模拟数据库Pod失败，待Pod重启后，查看对应数据是否还存在？">8、模拟数据库Pod失败，待Pod重启后，查看对应数据是否还存在？</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl delete pod xgp-mysql-mysql-67c6fb5f9-4h4kz<br>//删除这个pod让他重新生成<br>[root@master mysql]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315181626553.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315181626553.png" alt="image-20200315181626553"></a></p><h3 id="进入新的pod查看">进入新的pod查看</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl exec -it xgp-mysql-mysql-67c6fb5f9-k4c29 -- mysql -u root -p123.com<br><span class="hljs-meta">mysql&gt;</span><span class="bash"> use <span class="hljs-built_in">test</span>;</span><br>Reading table information for completion of table and column names<br>You can turn off this feature to get a quicker startup with -A<br><br>Database changed<br><span class="hljs-meta">mysql&gt;</span><span class="bash"> select * from <span class="hljs-built_in">test</span>;</span><br>+------+<br>| id   |<br>+------+<br>| 9527 |<br>+------+<br>1 row in set (0.00 sec)<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315181720939.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200315181720939.png" alt="image-20200315181720939"></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;创建镜像的方法&quot;&gt;创建镜像的方法&lt;/h2&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="nfs" scheme="https://wsdlxgp.top/tags/nfs/"/>
    
      <category term="StorageClass" scheme="https://wsdlxgp.top/tags/StorageClass/"/>
    
      <category term="pv" scheme="https://wsdlxgp.top/tags/pv/"/>
    
      <category term="pvc" scheme="https://wsdlxgp.top/tags/pvc/"/>
    
      <category term="dashboard" scheme="https://wsdlxgp.top/tags/dashboard/"/>
    
      <category term="helm" scheme="https://wsdlxgp.top/tags/helm/"/>
    
      <category term="deployment" scheme="https://wsdlxgp.top/tags/deployment/"/>
    
  </entry>
  
  <entry>
    <title>k8s的持续集成（jenkins+gitlab+k8s）</title>
    <link href="https://wsdlxgp.top/posts/b04b.html"/>
    <id>https://wsdlxgp.top/posts/b04b.html</id>
    <published>2020-06-07T12:10:31.526Z</published>
    <updated>2020-06-07T14:35:40.160Z</updated>
    
    <content type="html"><![CDATA[<h2 id="应用场景：">应用场景：</h2><p><strong><code>问题</code>项目分为app和后台两种，为了保证再同一个环境下面测试，所以不可能链接开发本地服务进行测试，所以需要搭建一个测试环境，供app进行开发测试。这个时候就有一个问题，如果开发新增加功能或者app调试的时候发现问题，这个时候就需要提交新的代码或者修复bug，然后重新发布到测试环境中去。但是后台人员又不能进入Linux服务器中，只能通过Linux运维人员来重新部署，这样的效率就会极低。</strong></p><p><strong><code>方案：</code>基于这种模式下面的，我们引入了Jenkins工具，通过Jenkins来拉取svn/git代码到服务器中，再Jenkins中编写Linux运行脚本，通过脚本我们就可以对代码进行编译运行，然后重新发布到服务器中运行。后端人员也不需要通知Linux运维人员来执行这个操作，直接再Jenkins的控制台就可以执行了。</strong></p><h2 id="实验环境">实验环境</h2><table><thead><tr><th>IP</th><th>主机名称</th><th>服务</th></tr></thead><tbody><tr><td><strong>192.168.1.21</strong></td><td><strong>master</strong></td><td><strong>k8s</strong></td></tr><tr><td><strong>192.168.1.22</strong></td><td><strong>node01</strong></td><td><strong>k8s</strong></td></tr><tr><td><strong>192.168.1.10</strong></td><td><strong>git</strong></td><td><strong>gitlab</strong></td></tr><tr><td><strong>192.168.1.13</strong></td><td><strong>jenkins</strong></td><td><strong>jenkins</strong></td></tr></tbody></table><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309134708695.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309134708695.png" alt="image-20200309134708695"></a></p><p><strong>总体流程：</strong></p><ul><li><strong>在开发机开发代码后提交到gitlab</strong></li><li><strong>之后通过webhook插件触发jenkins进行构建，jenkins将代码打成docker镜像，push到docker-registry</strong></li><li><strong>之后将在k8s-master上执行rc、service的创建，进而创建Pod，从私服拉取镜像，根据该镜像启动容器</strong></li></ul><p><strong>应用构建和发布流程说明。</strong></p><ol><li><strong>用户向Gitlab提交代码，代码中必须包含<code>Dockerfile</code></strong></li><li><strong>将代码提交到远程仓库</strong></li><li><strong>用户在发布应用时需要填写git仓库地址和分支、服务类型、服务名称、资源数量、实例个数，确定后触发Jenkins自动构建</strong></li><li><strong>Jenkins的CI流水线自动编译代码并打包成docker镜像推送到Harbor镜像仓库</strong></li><li><strong>Jenkins的CI流水线中包括了自定义脚本，根据我们已准备好的kubernetes的YAML模板，将其中的变量替换成用户输入的选项</strong></li><li><strong>生成应用的kubernetes YAML配置文件</strong></li><li><strong>更新Ingress的配置，根据新部署的应用的名称，在ingress的配置文件中增加一条路由信息</strong></li><li><strong>更新PowerDNS，向其中插入一条DNS记录，IP地址是边缘节点的IP地址。关于边缘节点，请查看<a href="https://jimmysong.io/kubernetes-handbook/practice/edge-node-configuration.html" target="_blank" rel="noopener">边缘节点配置</a></strong></li><li><strong>Jenkins调用kubernetes的API，部署应用</strong></li></ol><h1>一、前期工作</h1><h2 id="1、先验证k8s集群（1-21和1-22）">1、先验证k8s集群（1.21和1.22）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get nodes<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306083959440.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306083959440.png" alt="image-20200306083959440"></a></p><h2 id="2、master部署私有仓库">2、master部署私有仓库</h2><h3 id="Docker01部署"><strong>Docker01部署</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs shell">72 docker pull registry<br>//下载registry镜像<br><br>73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest<br>//基于registry镜像，启动一台容器<br><br>78 vim /usr/lib/systemd/system/docker.service #13行修改<br>ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.21:5000 <br><br>80 systemctl daemon-reload<br>81 systemctl restart docker.service<br>//重启docker<br><br>76 docker tag httpd:latest 192.168.1.11:5000/web:v1 <br>76 docker tag httpd:latest 192.168.1.11:5000/web:v2<br>//把容器重命名一个标签<br><br>77 docker ps<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309101144205.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309101144205.png" alt="image-20200309101144205"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">78 vim /usr/lib/systemd/system/docker.service #13行修改<br>ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 <br><br><br>80 systemctl daemon-reload<br>81 systemctl restart docker.service<br>//重启docker<br><br>100 docker push 192.168.1.11:5000/web:v1<br>100 docker push 192.168.1.11:5000/web:v2<br>//上传容器到私有仓库<br></code></pre></td></tr></table></figure><h3 id="Docker02和docker03加入私有仓库"><strong>Docker02和docker03加入私有仓库</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">78 vim /usr/lib/systemd/system/docker.service #13行修改<br>ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000  <br><br>80 systemctl daemon-reload<br>81 systemctl restart docker.service<br>//重启docker<br><br>99 docker pull 192.168.1.21:5000/web:v1<br>//测试下载<br></code></pre></td></tr></table></figure><h2 id="3、然后重要的地方到了，建立-yaml配置文件让kubernetes自己控制容器集群。"><strong>3、然后重要的地方到了，建立 yaml配置文件让kubernetes自己控制容器集群。</strong></h2><p><em><strong>用来模拟我们部署的服务</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master app]# vim deploy.yaml<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: web<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        name: web<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v1<br>        imagePullPolicy: Always     #改为本地仓库下载<br>        ports:<br>        - containerPort: 80<br></code></pre></td></tr></table></figure><h4 id="执行一下">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master app]# kubectl apply -f deploy.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master app]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306085507559.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306085507559.png" alt="image-20200306085507559"></a></p><h3 id="可是容器的ip只能在容器本机上访问，集群内的其他主机和集群外的主机都没办法访问，这个时候就需要将容器的端口映射到服务器上的端口了，所以需要做一个service的模板。service-模板可以将容器的端口映射到服务器的端口上，并且可以固定映射在服务器上的端口。"><strong>可是容器的ip只能在容器本机上访问，集群内的其他主机和集群外的主机都没办法访问，这个时候就需要将容器的端口映射到服务器上的端口了，所以需要做一个service的模板。service 模板可以将容器的端口映射到服务器的端口上，并且可以固定映射在服务器上的端口。</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master app]# vim deploy-svc.yaml<br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  labels:<br>    name: web<br>  name: web<br>spec:<br>  type: NodePort<br>  ports:<br>  - port: 80<br>    targetPort: 80<br>    nodePort: 31234<br>  selector:<br>    name: web<br></code></pre></td></tr></table></figure><p><strong>执行一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master app]# kubectl apply -f deploy-svc.yaml<br></code></pre></td></tr></table></figure><p><strong>查看一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master app]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306085725863.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306085725863.png" alt="image-20200306085725863"></a></p><p><strong>访问一下http://192.168.1.21:31234/</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306085846077.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306085846077.png" alt="image-20200306085846077"></a></p><h3 id="《ok-kubernetes-完毕，-开始配置-jenkins-gitlab联动》"><strong>《ok kubernetes</strong> <strong>完毕， 开始配置 jenkins+gitlab联动》</strong></h3><h3 id="4、git和jenkins加入私有仓库">4、git和jenkins加入私有仓库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">78 vim /usr/lib/systemd/system/docker.service #13行修改<br>ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000  <br><br>80 systemctl daemon-reload<br>81 systemctl restart docker.service<br>//重启docker<br><br>99 docker pull 192.168.1.11/busybox:v1<br>//测试下载<br></code></pre></td></tr></table></figure><h3 id="5、jenkins服务器向k8smaster做免密登录">5、jenkins服务器向k8smaster做免密登录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">100 ssh-copy-id 192.168.1.21<br></code></pre></td></tr></table></figure><h1>二、安装jenkins（1.13）</h1><h3 id="安装java环境">安装java环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@jenkins ~]# tar -zxf jdk-8u231-linux-x64.tar.gz<br><br>[root@jenkins ~]# mv jdk1.8.0_131 /usr/java<br><span class="hljs-meta">#</span><span class="bash">注意 这里有位置敏感，不要多一个“/”</span><br>[root@jenkins ~]# vim /etc/profile #在最下面写<br><br>export JAVA_HOME=/usr/java<br>export JRE_HOME=/usr/java/jre<br>export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH<br>export CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar<br><br>[root@jenkins ~]#  source /etc/profile<br>//环境变量生效<br>[root@jenkins ~]#  java -version<br>//验证环境变量<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306091443071.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306091443071.png" alt="image-20200306091443071"></a></p><h3 id="安装tomcat">安装tomcat</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@jenkins ~]# tar -zxf apache-tomcat-7.0.54.tar.gz <br>[root@jenkins ~]# mv apache-tomcat-7.0.54 /usr/tomcat7<br>[root@jenkins ~]# cd /usr/tomcat7/webapps/<br>[root@jenkins webapps]# rm -rf *<br>[root@jenkins webapps]# cp /root/jenkins.war . #这几步是jenkins的包放进了tomcat里<br>[root@jenkins webapps]# vim /usr/tomcat7/conf/server.xml <br>//修改tomcat的字符集<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306092022390.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306092022390.png" alt="image-20200306092022390"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@jenkins webapps]# cd /usr/tomcat7/bin/<br><br>[root@jenkins bin]# vim catalina.sh <br><span class="hljs-meta">#</span><span class="bash">!/bin/sh</span><br>export CATALINA_OPTS="-DJENKINS_HOME=/data/jenkins"<br>export JENKINS_JAVA_OPTIONS="-Djava.awt.headless=true -Dhudson.ClassicPluginStrategy.noBytecodeTransformer=true"<br>//这两行添加的是jenkins的家目录位置，这个很重要<br><br>[root@jenkins bin]# ./catalina.sh start <br>//启动tomcat<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306092523262.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306092523262.png" alt="image-20200306092523262"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@jenkins bin]# netstat -anput | grep 8080<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306110511541.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306110511541.png" alt="image-20200306110511541"></a></p><h3 id="浏览器安装jenkins">浏览器安装jenkins</h3><p><a href="http://192.168.1.11:8080/jenkins" target="_blank" rel="noopener">http://192.168.1.11:8080/jenkins</a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306110627790.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306110627790.png" alt="image-20200306110627790"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@jenkins bin]# cat /data/jenkins/secrets/initialAdminPassword<br>c577cbf75d934878a94b0f9e00ada328   //复制密码<br></code></pre></td></tr></table></figure><h3 id="（1）推荐安装">（1）推荐安装</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200308124155279.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200308124155279.png" alt="image-20200308124155279"></a></p><p><strong>#左边是自动安装， 右边是自定义安装，我们选左边的，如果不是这个画面则说明网络很卡或者没有网(推荐使用右边的，然后选择不安装插件，之后可以自定义安装）</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306151852889.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306151852889.png" alt="image-20200306151852889"></a></p><h3 id="（2）这个是自定义安装（自己上传的包）">（2）这个是自定义安装（自己上传的包）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@autoweb bin]# ./catalina.sh stop<br>[root@autoweb ~]# cd /data/jenkins/plugins/<br>[root@autoweb jenkins]# mv plugins plugins/.bk<br>然后上传plugins.tar.gz包：<br>[root@autoweb jenkins]# tar -zxf plugins.tar.gz <br>[root@autoweb ~]# cd /usr/tomcat7/bin/<br>[root@autoweb bin]# ./catalina.sh stop<br>[root@autoweb bin]# ./catalina.sh start<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306110627790.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306110627790.png" alt="image-20200306110627790"></a></p><p><strong>输入密码后断网</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200308124449039.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200308124449039.png" alt="image-20200308124449039"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200308123936170.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200308123936170.png" alt="image-20200308123936170"></a></p><h3 id="（3）两个剩下的方法一样">（3）两个剩下的方法一样</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306151900827.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306151900827.png" alt="image-20200306151900827"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306151905668.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306151905668.png" alt="image-20200306151905668"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306151911675.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306151911675.png" alt="image-20200306151911675"></a></p><h4 id="下载中文插件"><strong>下载中文插件</strong></h4><p><strong>系统管理-----&gt;插件管理-----&gt;avalilable(可选)然后搜索localization-zh-cn</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306152834083.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306152834083.png" alt="image-20200306152834083"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306152957419.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306152957419.png" alt="image-20200306152957419"></a></p><p><strong>然后还需要3个插件</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306153713286.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306153713286.png" alt="image-20200306153713286"></a></p><h1>三、安装gitlab（1.10）</h1><p><strong>GitLab CI 是 GitLab 默认集成的 CI 功能，GitLab CI 通过在项目内 .gitlab-ci.yaml 配置文件读取 CI 任务并进行相应处理；GitLab CI 通过其称为 GitLab Runner 的 Agent 端进行 build 操作；Runner 本身可以使用多种方式安装，比如使用 Docker 镜像启动等；Runner 在进行 build 操作时也可以选择多种 build 环境提供者；比如直接在 Runner 所在宿主机 build、通过新创建虚拟机(vmware、virtualbox)进行 build等；同时 Runner 支持 Docker 作为 build 提供者，即每次 build 新启动容器进行 build；GitLab CI 其大致架构如下</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309140112958.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309140112958.png" alt="image-20200309140112958"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> yum -y install curl policycoreutils openssh-server openssh-clients postfix git</span><br><span class="hljs-meta">#</span><span class="bash"> systemctl <span class="hljs-built_in">enable</span> sshd</span><br><span class="hljs-meta">#</span><span class="bash"> systemctl start sshd</span><br><span class="hljs-meta">#</span><span class="bash"> systemctl <span class="hljs-built_in">enable</span> postfix</span><br><span class="hljs-meta">#</span><span class="bash"> systemctl start postfix</span><br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306112315163.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306112315163.png" alt="image-20200306112315163"></a></p><h3 id="安装gitlab-ce"><strong>安装gitlab-ce</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@git ~]# curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash<br></code></pre></td></tr></table></figure><p><strong>注：由于网络问题，国内用户，使用清华大学的镜像源进行安装：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@git ~]# vim /etc/yum.repos.d/gitlab-ce.repo<br>[gitlab-ce]<br>name=gitlab-ce<br>baseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7<br>repo_gpgcheck=0<br>gpgcheck=0<br>enabled=1<br>gpgkey=https://packages.gitlab.com/gpg.key<br><br>[root@git ~]# yum makecache<br>//保存到本地<br><br>[root@git ~]# yum -y install gitlab-ce <br><span class="hljs-meta">#</span><span class="bash">这两条命令是把gitlab源先加入了yum，然后yum下载gitlab</span><br><br>[root@git ~]# vim /etc/gitlab/gitlab.rb <br>//修改端口是为了防止端口冲突，因为80默认是http服务的 <br><br>external_url 'http://192.168.1.21:90'  #端口， unicorn默认是8080 也是tomcat的端口 <br>unicorn['listen'] = '127.0.0.1'<br>unicorn['port'] = 3000 <br><br><br>[root@git ~]# gitlab-ctl reconfigure <br>//启动gitlab，这个过程可能会有点慢<br><br><br>[root@git ~]# ls /etc/yum.repos.d/<br>//查看一下<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306141100803.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306141100803.png" alt="image-20200306141100803"></a></p><h3 id="访问192-168-1-10-90">访问192.168.1.10:90</h3><p><strong>在网页配置用户密码后则安装完毕。用户默认root，这里让设置一个密码再登录，<a href="http://xn--12345-of3np30ehqhlqe.com/" target="_blank" rel="noopener">这里设置12345.com</a>（相对较短的密码不让设置）</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306141728312.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306141728312.png" alt="image-20200306141728312"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306142041682.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306142041682.png" alt="image-20200306142041682"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306142219600.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306142219600.png" alt="image-20200306142219600"></a></p><h1>四、jenkins和gitlab相互关联</h1><p><strong>jenkins：工具集成平台</strong></p><p><strong>gitlab: 软件托管平台</strong></p><p><strong>部署这两个服务的联动，需要经过ssh验证。</strong></p><h2 id="1、首先我们需要在gitlab上绑定jenkins服务器的ssh公钥，这里我们使用的是root用户的公私钥，切记生产环境是不允许随便用root的">1、<strong>首先我们需要在gitlab上绑定jenkins服务器的ssh公钥，这里我们使用的是root用户的公私钥，切记生产环境是不允许随便用root的</strong></h2><h3 id="（1）jenkins"><strong>（1）jenkins</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@jenkins ~]# ssh-keygen -t rsa <br>//然后不输入只回车会生成一对公私钥<br></code></pre></td></tr></table></figure><h4 id="默认在-root-ssh-目录里"><strong>默认在/root/.ssh/目录里</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@jenkins ~]# cat /root/.ssh/id_rsa.pub <br>//查看公钥并复制<br>ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDMA4+je3NsxZrF2v8TPLXJp1ejwy1YokXipEFyGVNo5IbtkiBDwBLOAl5i7yromY8YGgoNNriE2g89IM/44BGC5UDCokQ69Ze9Ta9Kynv3/1PDFXIABJJG0f6LsUqt0nKFaFoGz3ZuYAnl6AzLpXEic8DBDrsFk+UGrxvMfSEqHlYO2b7jRXE1HGRnqI/IcVB190cLT1kmBKi7hSqUNBc1cY6t3a6gGiBpp9tc8PW4r/RcLblhAL1LKx8x37NOZkqox8IMh3eM/wtWwAVFlI8XU+sz9akzJOVmd1ArT5Q4w8WA/uVHCDUGVI/fli/ZRv+mNZyF3EH26runctb5LkCT root@jenkins<br></code></pre></td></tr></table></figure><h3 id="（2）gitlab">（2）gitlab</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306195836403.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306195836403.png" alt="image-20200306195836403"></a></p><h4 id="在这里放刚才拷贝的公钥保存就行了。"><strong>在这里放刚才拷贝的公钥保存就行了。</strong></h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306200026493.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306200026493.png" alt="image-20200306200026493"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306200103458.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306200103458.png" alt="image-20200306200103458"></a></p><h4 id="我们先在gitlab上创建一个代码仓库-点击-new-project"><strong>我们先在gitlab上创建一个代码仓库 点击 new project</strong></h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306200156932.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306200156932.png" alt="image-20200306200156932"></a></p><p><strong>输入一个仓库的名字，权限选择公共的（public）然后直接点击创建</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306200431858.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306200431858.png" alt="image-20200306200431858"></a></p><h4 id="点击新建一个new-file"><strong>点击新建一个new.file</strong></h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306201437862.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306201437862.png" alt="image-20200306201437862"></a></p><h4 id="写入代码，起一个名字然后保存"><strong>写入代码，起一个名字然后保存</strong></h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306201558158.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306201558158.png" alt="image-20200306201558158"></a></p><h4 id="创建好了，然后在本地测试一下是否可用"><strong>创建好了，然后在本地测试一下是否可用</strong></h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306201744679.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306201744679.png" alt="image-20200306201744679"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@git ~]# mkdir xgp<br>[root@git ~]# cd xgp/<br>[root@git xgp]# git clone git@192.168.1.10:root/xgp-demo.git<br>//克隆xgp-demo仓库到本地<br><br>[root@git xgp]# ls xgp-demo/<br>index.html<br>[root@git xgp]# cat xgp-demo/index.html <br>print: "hello word!!!"<br>//查看一下<br></code></pre></td></tr></table></figure><h3 id="（3）自动构建">（3）自动构建</h3><p><strong>安装插件</strong></p><p><strong>先进入到之前查看插件的地方</strong></p><p><strong>系统设置----插件管理----高级_—上传插件gitlab-oauth、gitlab-plugin、 windows-slaves、ruby-runt ime、gitlab-hook</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306212734302.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306212734302.png" alt="image-20200306212734302"></a></p><h3 id="（4）如果可以用，则打开jenkins-点击新建">（4）如果可以用，则打开jenkins 点击新建</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306202647670.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306202647670.png" alt="image-20200306202647670"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306202724313.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306202724313.png" alt="image-20200306202724313"></a></p><h4 id="地址粘贴进去以后没有报错则没错"><strong>地址粘贴进去以后没有报错则没错</strong></h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306203441474.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306203441474.png" alt="image-20200306203441474"></a></p><p><strong>但是很伤心它报错了，那是因为jenkins和git没有关联上</strong></p><h3 id="解决">解决</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306203407502.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306203407502.png" alt="image-20200306203407502"></a></p><h4 id="git主机生成ssh密钥">git主机生成ssh密钥</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@jenkins ~]# ssh-keygen -t rsa <br>//然后不输入只回车会生成一对公私钥<br>[root@jenkins ~]# cat /root/.ssh/id_rsa   <br>//查看密钥并复制<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306203947496.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306203947496.png" alt="image-20200306203947496"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306204232588.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306204232588.png" alt="image-20200306204232588"></a></p><p><strong>下面的这个插件很重要，就是他实现自动化更新的webhook插件，安装过了就会有这条，然后点击这条下面出来的这些东西保持默认就行。同时注意复制</strong></p><p><strong>这个里面写的是jenkins构建时候会执行的shell脚本，这个是最重要的，就是他实现了下端kubernetes自动更新容器的操作。</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306204512237.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306204512237.png" alt="image-20200306204512237"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306204948462.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306204948462.png" alt="image-20200306204948462"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>backupcode="/data/backcode/$JOB_NAME/$BUILD_NUMBER"  <br>mkdir -p $backupcode     #jenkins创建上述目录<br>chmod 644 "$JENKINS_HOME"/workspace/"$JOB_NAME"/*<br>rsync -acP   "$JENKINS_HOME"/workspace/"$JOB_NAME"/*  $backupcode #$JENKINS_HOME和$JOB_NAME同步最新消息<br><span class="hljs-meta">#</span><span class="bash">ssh root@192.168.1.21 sed -i <span class="hljs-string">'s/v1/v2/g'</span> /root/app/deploy.yaml <span class="hljs-comment">#更改镜像版本</span></span><br>echo From  192.168.1.21:5000/web:v1 &gt; "$JENKINS_HOME"/workspace/Dockerfile<br>echo COPY ./"$JOB_NAME"/* /usr/local/apache2/htdocs/ &gt;&gt; "$JENKINS_HOME"/workspace/Dockerfile<br>docker rmi 192.168.1.21:5000/web:v1<br>docker build -t 192.168.1.21:5000/web:v1 /"$JENKINS_HOME"/workspace/.<br>docker push 192.168.1.21:5000/web:v1<br>ssh root@192.168.1.21 kubectl delete deployment web<br>ssh root@192.168.1.21 kubectl apply -f /root/app/deploy.yaml<br></code></pre></td></tr></table></figure><blockquote><p><strong>$JOB_NAME：项目名称</strong></p><p><strong>$BUILD_NUMBER：第几次构建</strong></p><p><strong>$JENKINS_HOME：jenkins的家目录</strong></p></blockquote><p><strong>完事以后先别保存，首先复制一下上面的jenkins地址，然后去gitlab上绑定webhook</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306213050759.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306213050759.png" alt="image-20200306213050759"></a></p><p><strong>保存，登陆gitlab，点击下图这个设置</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306213514819.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306213514819.png" alt="image-20200306213514819"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306213829519.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306213829519.png" alt="image-20200306213829519"></a></p><p><strong>测试显示下图 的蓝条说明jenkins 已经连通了gitlab</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306214117715.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306214117715.png" alt="image-20200306214117715"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215322180.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215322180.png" alt="image-20200306215322180"></a></p><h4 id="回到Jenkins开启匿名访问权限"><strong>回到Jenkins开启匿名访问权限</strong></h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215429619.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215429619.png" alt="image-20200306215429619"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215504413.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215504413.png" alt="image-20200306215504413"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215539717.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215539717.png" alt=""></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215611348.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306215611348.png" alt="image-20200306215611348"></a></p><p><strong>测试显示下图 的蓝条说明jenkins 已经连通了gitlab</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306214126410.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200306214126410.png" alt="image-20200306214126410"></a></p><p><strong>好了，jenkins和gitlab 都已经互相的ssh通过了，然后我们最后需要做的一个ssh是关于jenkins</strong></p><p><strong>///注意，这里是从git和jenkins向master节点做免密登录。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@git ~]# ssh-copy-id root@192.168.1.21<br>[root@jenkins ~]# ssh-copy-id root@192.168.1.21<br></code></pre></td></tr></table></figure><p><strong>好了，环境全部部署完毕！！！。开始测试</strong></p><h1>五、测试</h1><p><strong>测试的方法很简单，就是在gitlab上新建代码，删除代码，修改代码，都会触发webhook进行自动部署。最终会作用在所有的nginx容器中，也就是我们的web服务器。</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309100434912.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309100434912.png" alt="image-20200309100434912"></a></p><p><strong>这里我修改了之前建立的 index.html文件 保存以后，就打开浏览器 一直访问kubernetes-node 里面的容器了</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309100445830.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309100445830.png" alt="image-20200309100445830"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309100530210.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309100530210.png" alt="image-20200309100530210"></a></p><h2 id="访问一下http-192-168-1-21-31234">访问一下http://192.168.1.21:31234/</h2><p><em><strong>如果没有变，应该注意查看是否在jenkins上构建完成，等以小会就可以了。</strong></em></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309100557309.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200309100557309.png" alt="image-20200309100557309"></a></p><p><strong>构建成功</strong></p><h1>六、GitLab CI 总结</h1><p><strong>CS 架构</strong><br>GitLab 作为 Server 端，控制 Runner 端执行一系列的 CI 任务；代码 clone 等无需关心，GitLab 会自动处理好一切；Runner 每次都会启动新的容器执行 CI 任务</p><p><strong>容器即环境</strong><br>在 Runner 使用 Docker build 的前提下；所有依赖切换、环境切换应当由切换不同镜像实现，即 build 那就使用 build 的镜像，deploy 就用带有 deploy 功能的镜像；通过不同镜像容器实现完整的环境隔离</p><p><strong>CI即脚本</strong><br>不同的 CI 任务实际上就是在使用不同镜像的容器中执行 <a href="https://www.centos.bz/tag/shell/" target="_blank" rel="noopener">SHELL</a> 命令，自动化 CI 就是执行预先写好的一些小脚本</p><p><strong>敏感信息走环境变量</strong><br>一切重要的敏感信息，如账户密码等，不要写到 CI 配置中，直接放到 GitLab 的环境变量中；GitLab 会保证将其推送到远端 Runner 的 SHELL 变量中</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;应用场景：&quot;&gt;应用场景：&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;问题&lt;/code&gt;项目分为app和后台两种，为了保证再同一个环境下面测试，所以不可能链接开发本地服务进行测试，所以需要搭建一个测试环境，供app进行开发测试。这个时候就有一个问题，如果开发新增加
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="jenkins" scheme="https://wsdlxgp.top/tags/jenkins/"/>
    
      <category term="gitlab" scheme="https://wsdlxgp.top/tags/gitlab/"/>
    
  </entry>
  
  <entry>
    <title>k8s的charts的四种安装方式及helm私有仓库</title>
    <link href="https://wsdlxgp.top/posts/e7d.html"/>
    <id>https://wsdlxgp.top/posts/e7d.html</id>
    <published>2020-06-07T12:10:24.123Z</published>
    <updated>2020-06-07T14:35:40.154Z</updated>
    
    <content type="html"><![CDATA[<h1>自定义helm模板</h1><p><a href="https://hub.helm.sh/" target="_blank" rel="noopener">https://hub.helm.sh/</a></p><h2 id="1、开发自己的chare包">1、开发自己的chare包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm create mychare<br>//创建一个名为mychare的chare包<br>[root@master ~]# tree -C mychare/<br>//以树状图查看一下chare包<br>mychare/<br>├── charts<br>├── Chart.yaml<br>├── templates<br>│   ├── deployment.yaml<br>│   ├── _helpers.tpl<br>│   ├── ingress.yaml<br>│   ├── NOTES.txt<br>│   ├── service.yaml<br>│   └── tests<br>│       └── test-connection.yaml<br>└── values.yaml<br></code></pre></td></tr></table></figure><h2 id="2、调试chart">2、调试chart</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mychare]# cd<br>[root@master ~]# helm install --dry-run --debug mychare<br>//检查这个mychare是否有问题<br></code></pre></td></tr></table></figure><h2 id="3、安装chart">3、安装chart</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node02 ~]# docker pull nginx:stable<br></code></pre></td></tr></table></figure><h3 id="（1）通过仓库安装">（1）通过仓库安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mychare]# helm search redis<br>//搜索chare包<br>[root@master mychare]# helm repo list<br>//查看是否有能访问仓库<br>[root@master mychare]# helm install stable/redis<br>//安装<br></code></pre></td></tr></table></figure><h3 id="（2）通过tar包安装">（2）通过tar包安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm fetch stable/redis<br>//直接下载chare包<br>[root@master ~]# tar -zxf redis-1.1.15.tgz<br>//解压下载的chare包<br>[root@master ~]# tree -C redis<br>redis<br>├── Chart.yaml<br>├── README.md<br>├── templates<br>│   ├── deployment.yaml<br>│   ├── _helpers.tpl<br>│   ├── networkpolicy.yaml<br>│   ├── NOTES.txt<br>│   ├── pvc.yaml<br>│   ├── secrets.yaml<br>│   └── svc.yaml<br>└── values.yaml<br></code></pre></td></tr></table></figure><h3 id="（3）通过chare本地目录安装">（3）通过chare本地目录安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm fetch stable/redis<br>//直接下载chare包<br>[root@master ~]# tar -zxf redis-1.1.15.tgz<br>//解压下载的chare包<br>[root@master ~]# helm install redis<br></code></pre></td></tr></table></figure><h3 id="（4）通过URL安装">（4）通过URL安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm install https://example.com/charts/foo-1.2.3.tgz<br></code></pre></td></tr></table></figure><h3 id="（5）使用本地目录安装：">（5）使用本地目录安装：</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# cd mychare/<br>[root@master mychare]# vim values.yaml<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304094840738.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304094840738.png" alt="image-20200304094840738"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mychare]# cd templates/<br>[root@master templates]# vim service.yaml<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304095647172.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304095647172.png" alt="image-20200304095647172"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master templates]# cd ..<br>[root@master mychare]# helm install -n test ../mychare/<br>[root@master ~]# helm upgrade test mychare/ -f  mychare/values.yaml<br></code></pre></td></tr></table></figure><h2 id="4、例子">4、例子</h2><p><strong>使用mychart部署一个实例: xgp。使用镜像为私有镜像v1 版本。</strong></p><p><strong>完成之后，镜像版本。</strong></p><p><strong>全部成功之后，将实例做一个升级，将镜像改为v2版本。</strong></p><h3 id="更改镜像为私有镜像">更改镜像为私有镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim mychare/values.yaml<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304104416415.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304104416415.png" alt="image-20200304104416415"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]#  helm install -n xgp mychare/ -f mychare/values.yaml<br>[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304104645260.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304104645260.png" alt="image-20200304104645260"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim mychare/values.yaml<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304105120894.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304105120894.png" alt="image-20200304105120894"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm upgrade  xgp mychare/  -f mychare/values.yaml <br>[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304105211506.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304105211506.png" alt="image-20200304105211506"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl edit deployments. xgp-mychare<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304105334541.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304105334541.png" alt="image-20200304105334541"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304105359184.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304105359184.png" alt="image-20200304105359184"></a></p><h1>创建自己的Repo仓库</h1><h2 id="1、node01启动一个httpd的容器">1、node01启动一个httpd的容器</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node01 ~]# mkdir /var/xgp<br>//创建一个目录<br>[root@node01 ~]# docker pull httpd<br>//下载httpd镜像<br>[root@node02 ~]# docker run -d -p 8080:80 -v /var/xgp:/usr/local/apache2/htdocs httpd<br>//启动一个httpd的容器<br></code></pre></td></tr></table></figure><h2 id="2、master节点上，将mychart目录打包。">2、master节点上，将mychart目录打包。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm package mychare/<br>Successfully packaged chart and saved it to: /root/mychare-0.1.0.tgz<br></code></pre></td></tr></table></figure><h2 id="3、生成仓库的index文件。">3、生成仓库的index文件。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# mkdir myrepo<br>//创建一个目录存放打包的chare<br>[root@master ~]# mv mychare-0.1.0.tgz myrepo/<br>//移动打包好的文件<br>[root@master ~]# helm repo index myrepo/ --url http://192.168.1.22:8080/charts<br>//生成仓库的index文件<br>[root@master ~]# ls myrepo/<br>index.yaml  mychare-0.1.0.tgz<br></code></pre></td></tr></table></figure><h2 id="4、将生成的tar包和index-yaml上传到node01的-var-www-charts目录下">4、将生成的tar包和index.yaml上传到node01的/var/www/charts目录下.</h2><h3 id="node01创建目录">node01创建目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node01 ~]# mkdir /var/xgp/charts<br></code></pre></td></tr></table></figure><h3 id="master移动动到">master移动动到</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# scp myrepo/* node01:/var/xgp/charts/<br></code></pre></td></tr></table></figure><h3 id="node01查看一下">node01查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node01 ~]# ls /var/xgp/charts/<br>index.yaml  mychare-0.1.0.tgz<br></code></pre></td></tr></table></figure><h2 id="5、添加新的repo仓库。">5、添加新的repo仓库。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm repo add newrepo http://192.168.1.22:8080/charts<br>[root@master ~]# helm repo list<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304112410286.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304112410286.png" alt="image-20200304112410286"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm search mychare<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304112443931.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304112443931.png" alt="image-20200304112443931"></a></p><h2 id="6、我们就可以直接使用新的repo仓库部署实例了。">6、我们就可以直接使用新的repo仓库部署实例了。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm install newrepo/mychare -n wsd<br>[root@master ~]# helm list<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304112515084.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304112515084.png" alt="image-20200304112515084"></a></p><h2 id="7-如果以后仓库中新添加了chart包-需要用helm-repo-update命玲更新本地的index文件。">7.如果以后仓库中新添加了chart包,需要用helm repo update命玲更新本地的index文件。</h2><h3 id="练习：">练习：</h3><h4 id="新创建一个bdqn-的chart包。然后将chart包上传到上述repo源中。">新创建一个bdqn.的chart包。然后将chart包上传到上述repo源中。</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm create bdqn<br>[root@master ~]# helm package bdqn/<br>[root@master ~]# mv bdqn-0.1.0.tgz myrepo/<br>[root@master ~]#  helm repo index myrepo/ --url http://192.168.1.22:8080/charts<br>[root@master myrepo]# scp bdqn-0.1.0.tgz index.yaml  node01:/var/xgp/charts<br>[root@master myrepo]# helm repo update<br>[root@master myrepo]# helm search bdqn<br>[root@master myrepo]# helm install http://192.168.1.22:8080/charts/bdqn-0.1.0.tgz<br></code></pre></td></tr></table></figure><h2 id="1）创建helm的私有仓库，以自己的名字命名。">1）创建helm的私有仓库，以自己的名字命名。</h2><h3 id="1、node01启动一个httpd的容器-2">1、node01启动一个httpd的容器</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node01 ~]# mkdir /var/xgp<br>//创建一个目录<br>[root@node01 ~]# docker pull httpd<br>//下载httpd镜像<br>[root@node02 ~]# docker run -d -p 8080:80 -v /var/xgp:/usr/local/apache2/htdocs httpd<br>//启动一个httpd的容器<br></code></pre></td></tr></table></figure><h3 id="3、生成仓库的index文件。-2">3、生成仓库的index文件。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# mkdir xgprepo<br>//创建一个目录存放打包的chare<br>[root@master ~]# helm repo index xgprepo/ --url http://192.168.1.22:8080/charts<br>//生成仓库的index文件<br></code></pre></td></tr></table></figure><h3 id="4、将生成的index-yaml上传到node01的-var-www-charts目录下">4、将生成的index.yaml上传到node01的/var/www/charts目录下.</h3><h4 id="node01创建目录-2">node01创建目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node01 ~]# mkdir /var/xgp/charts<br></code></pre></td></tr></table></figure><h4 id="master移动动到-2">master移动动到</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# scp xgprepo/* node01:/var/xgp/charts/<br></code></pre></td></tr></table></figure><h4 id="node01查看一下-2">node01查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node01 ~]# ls /var/xgp/charts/<br>index.yaml<br></code></pre></td></tr></table></figure><h3 id="5、添加新的repo仓库">5、添加新的repo仓库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm repo add xgp http://192.168.1.22:8080/charts<br>[root@master ~]# helm repo list<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304132528938.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304132528938.png" alt="image-20200304132528938"></a></p><h2 id="2）-自定义一个chart包，要求这个包运行一个httpd的服务，使用私有镜像v1版本。3个副本Pod，service类型更改为NodePort，端口指定为-30000">2） 自定义一个chart包，要求这个包运行一个httpd的服务，使用私有镜像v1版本。3个副本Pod，service类型更改为NodePort，端口指定为:30000</h2><h4 id="自定义一个chart包">自定义一个chart包</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm create wsd<br>//创建一个名为wsd的chares包<br></code></pre></td></tr></table></figure><h4 id="按照要求修改配置文件">按照要求修改配置文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# cd wsd/<br>//进入这个chart包<br>[root@master wsd]# vim values.yaml<br>//修改wsd的配置文件<br>replicaCount: 3                         #三个副本<br><br>image:<br>  repository: 192.168.1.21:5000/web      #更改镜像为私有镜像<br>  tag: v1                                #镜像标签v1<br>  pullPolicy: IfNotPresent              <br><br>imagePullSecrets: []<br>nameOverride: ""<br>fullnameOverride: ""<br><br>service:<br>  type: NodePort              #修改模式为映射端口<br>  port: 80<br>  nodePort: 30000             #添加端口<br><br>[root@master wsd]# vim templates/service.yaml <br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: &#123;&#123; include "wsd.fullname" . &#125;&#125;<br>  labels:<br>&#123;&#123; include "wsd.labels" . | indent 4 &#125;&#125;<br>spec:<br>  type: &#123;&#123; .Values.service.type &#125;&#125;<br>  ports:<br>    - port: &#123;&#123; .Values.service.port &#125;&#125;<br>      targetPort: http<br>      protocol: TCP<br>      name: http<br>      nodePort: &#123;&#123; .Values.service.nodePort &#125;&#125;    #“添加”能让服务识别到nodePort的端口<br>  selector:<br>    app.kubernetes.io/name: &#123;&#123; include "wsd.name" . &#125;&#125;<br>    app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125;<br></code></pre></td></tr></table></figure><h4 id="测试一下">测试一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm install -n wsd  wsd/ -f wsd/values.yaml<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304134959273.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304134959273.png" alt="image-20200304134959273"></a></p><h4 id="查看一下镜像版本">查看一下镜像版本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304135106081.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304135106081.png" alt="image-20200304135106081"></a></p><h4 id="访问一下">访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30000<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304150609552.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304150609552.png" alt="image-20200304150609552"></a></p><h2 id="3-将实例进行更新，要求镜像生产v2版本。">3) 将实例进行更新，要求镜像生产v2版本。</h2><p><strong>私有镜像和官方镜像升级有所不同，官方的只需通过 （helm upgrade --set imageTag=“标签” 服务名称 charts包名 ）进行更改标签即可，而私有镜像需通过更改values.yaml中的标签才行比较麻烦一点。</strong></p><h3 id="1、修改values-yaml">1、修改values.yaml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim wsd/values.yaml <br><br><span class="hljs-meta">#</span><span class="bash"> Default values <span class="hljs-keyword">for</span> wsd.</span><br><span class="hljs-meta">#</span><span class="bash"> This is a YAML-formatted file.</span><br><span class="hljs-meta">#</span><span class="bash"> Declare variables to be passed into your templates.</span><br><br>replicaCount: 3<br><br>image:<br>  repository: 192.168.1.21:5000/web<br>  tag: v2                            #修改标签为v2<br>  pullPolicy: IfNotPresent<br>[root@master ~]# helm upgrade wsd wsd/ -f wsd/values.yaml<br>//基于配置文件刷新一下wsd服务<br></code></pre></td></tr></table></figure><h4 id="查看一下">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304140054269.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304140054269.png" alt="image-20200304140054269"></a></p><h4 id="访问一下-2">访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30000<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304150742815.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304150742815.png" alt="image-20200304150742815"></a></p><h3 id="2、使用edit进行版本更新">2、使用edit进行版本更新</h3><p><em><strong>确定wsd这个服务开启</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl edit deployments. wsd<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304140425336.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304140425336.png" alt="img"></a></p><h4 id="查看一下-2">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304140520342.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304140520342.png" alt="image-20200304140520342"></a></p><h4 id="访问一下-3">访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30000<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304150839440.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304150839440.png" alt="image-20200304150839440"></a></p><h2 id="4）重新定义一个chart包，名称为-new-test-将这个包上传到上述私有仓库中。">4）重新定义一个chart包，名称为: new-test,将这个包上传到上述私有仓库中。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm repo list<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304142059023.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304142059023.png" alt="image-20200304142059023"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm create xgp-wsd<br>//创建一个名为xgp-wsd的charts包<br><br>[root@master ~]# helm package xgp-wsd/<br>//将xgp-wsd打包在当前目录<br><br>[root@master ~]# mv xgp-wsd-0.1.0.tgz xgprepo/<br>//把打包文件放到仓库目录<br><br>[root@master ~]# helm repo index xgprepo/ --url http://192.168.1.22:8080/charts<br>//把仓库目录新加入的charts包信息记录在index.yaml中，使得其他加入的主机可以识别到，仓库的charts包<br><br>[root@master ~]# scp xgprepo/* node01:/var/xgp/charts<br>//将仓库目录的文件移动到httpd服务上，使各个主机可以访问，下载仓库的charts包<br><br>[root@master ~]# helm repo update <br>//更新一下chart存储库<br></code></pre></td></tr></table></figure><h3 id="查看一下-3">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm search xgp-wsd<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304142009776.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200304142009776.png" alt="image-20200304142009776"></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;自定义helm模板&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://hub.helm.sh/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://hub.helm.sh/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;1、开发自己的chare包&quot;&gt;1、开发
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="helm" scheme="https://wsdlxgp.top/tags/helm/"/>
    
      <category term="chares" scheme="https://wsdlxgp.top/tags/chares/"/>
    
      <category term="url" scheme="https://wsdlxgp.top/tags/url/"/>
    
  </entry>
  
  <entry>
    <title>k8s中helm安装部署，升级和回滚（chart，helm，tiller，StorageClass）</title>
    <link href="https://wsdlxgp.top/posts/5bc1.html"/>
    <id>https://wsdlxgp.top/posts/5bc1.html</id>
    <published>2020-06-07T12:10:22.073Z</published>
    <updated>2020-06-07T14:35:40.152Z</updated>
    
    <content type="html"><![CDATA[<h1>一、Helm介绍</h1><p><strong><code>helm</code>是基于<code>kubernetes</code> 的包管理器。它之于 <code>kubernetes</code> 就如 <code>yum</code> 之于 <code>centos</code>，<code>pip</code> 之于 <code>python，npm</code> 之于 <code>javascript</code></strong></p><p><strong>那 <code>helm</code> 的引入对于管理集群有哪些帮助呢？</strong></p><ul><li><strong>更方便地部署基础设施，如 <code>gitlab</code>，<code>postgres</code>，<code>prometheus</code>，<code>grafana</code> 等</strong></li><li><strong>更方便地部署自己的应用，为公司内部的项目配置 Chart，使用 <code>helm</code> 结合 CI，在 k8s 中部署应用一行命令般简单</strong></li></ul><h2 id="1、Helm用途">1、Helm用途</h2><p><strong>Helm把Kubernetes资源(比如deployments、services或 ingress等) 打包到一个chart中，而chart被保存到chart仓库。通过chart仓库可用来存储和分享chart。Helm使发布可配置，支持发布应用配置的版本管理，简化了Kubernetes部署应用的版本控制、打包、发布、删除、更新等操作。</strong></p><p><strong>做为Kubernetes的一个包管理工具，用来管理charts——预先配置好的安装包资源，有点类似于Ubuntu的APT和CentOS中的yum。</strong></p><h4 id="Helm具有如下功能：">Helm具有如下功能：</h4><ul><li><strong>创建新的chart</strong></li><li><strong>chart打包成tgz格式</strong></li><li><strong>上传chart到chart仓库或从仓库中下载chart</strong></li><li><strong>在Kubernetes集群中安装或卸载chart</strong></li><li><strong>管理用Helm安装的chart的发布周期</strong></li></ul><h4 id="使用Helm可以完成以下事情：">使用Helm可以完成以下事情：</h4><ul><li><strong>管理Kubernetes manifest files</strong></li><li><strong>管理Helm安装包charts</strong></li><li><strong>基于chart的Kubernetes应用分发</strong></li></ul><h2 id="2、Helm组件及相关术语">2、Helm组件及相关术语</h2><p><strong>开始接触Helm时遇到的一个常见问题就是Helm中的一些概念和术语非常让人迷惑，我开始学习Helm就遇到这个问题。</strong></p><p><strong>因此我们先了解一下Helm的这些相关概念和术语。</strong></p><h3 id="包管理工具"><strong>包管理工具:</strong></h3><ul><li><p><strong>Helm: Kubernetes的应用打包工具，也是命令行工具的名称。</strong></p></li><li><p><strong>Helm CLI：是 Helm 客户端，可以在本地执行</strong></p></li><li><p><strong>Tiller: Helm的服务端，部署在Kubernetes集群中，用于处理Helm的相关命令。</strong></p><blockquote><p><strong>helm的作用：像centos7中的yum命令一样，管理软件包，只不过helm这儿管理的是在k8s上安装的各种容器。</strong></p><p><strong>tiller的作用：像centos7的软件仓库一样，简单说类似于/etc/yum.repos.d目录下的xxx.repo。</strong></p></blockquote></li><li><p><strong>Repoistory: Helm的软件仓库，repository本质上是一个web服务器，该服务器保存了chart软件包以供下载，并有提供一个该repository的chart包的清单文件以供查询。在使用时，Helm可以对接多个不同的Repository。</strong></p></li><li><p><strong>Charts：是一个Helm的程序包，它包含了运行一个kubernetes应用程序所需要的镜像、依赖关系和资源定义等。</strong></p></li><li><p><strong>Release：应用程序运行Charts之后，得到的一个实例。</strong></p><blockquote><p><strong>需要特别注意的是， Helm中提到的Release和我们通常概念中的版本有所不同，这里的Release可以理解为Helm使用Chart包部署的一个应用实例。</strong></p><p><strong>其实Helm中的Release叫做Deployment更合适。估计因为Deployment这个概念已经被Kubernetes使用了，因此Helm才采用了Release这个术语。</strong></p></blockquote></li></ul><h3 id="命令介绍">命令介绍</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm search<br>//查看可用的Charts包<br>[root@master ~]# helm inspect  stable/redis<br>//查看stable/redis包的详细信息<br>[root@master mysql]# helm fetch stable/mysql<br>//直接下载stable/mysql的chart包<br>[root@master ~]# helm install stable/redis -n redis --dry-run <br>//基于stable/redis包运行一个名为redis的服务（把--dry-run去掉之后相当于安装了一个服务）<br>[root@master ~]# helm list<br>//查看安装的服务<br>[root@master ~]# helm delete redis<br>//删除这个服务<br>[root@master mysql]# helm upgrade --set imageTag=5.7.15 xgp-mysql stable/mysql -f values.yaml <br>//mysql服务的升级<br>[root@master mysql]#  helm history xgp-mysql<br>//查看历史版本<br>[root@master mysql]# helm rollback xgp-mysql 1  <br>//回滚到版本一<br></code></pre></td></tr></table></figure><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cmd"><span class="hljs-function">http://<span class="hljs-title">hub.kubeapps.com</span>/</span><br><span class="hljs-function"></span><br><span class="hljs-function"><span class="hljs-title">completion</span>  # 为指定的<span class="hljs-title">shell</span>生成自动完成脚本（<span class="hljs-title">bash</span>或<span class="hljs-title">zsh</span>）</span><br><span class="hljs-function"><span class="hljs-title">create</span>      # 创建一个具有给定名称的新 <span class="hljs-title">chart</span></span><br><span class="hljs-function"><span class="hljs-title">delete</span>      # 从 <span class="hljs-title">Kubernetes</span> 删除指定名称的 <span class="hljs-title">release</span></span><br><span class="hljs-function"><span class="hljs-title">dependency</span>  # 管理 <span class="hljs-title">chart</span> 的依赖关系</span><br><span class="hljs-function"><span class="hljs-title">fetch</span>       # 从存储库下载 <span class="hljs-title">chart</span> 并（可选）将其解压缩到本地目录中</span><br><span class="hljs-function"><span class="hljs-title">get</span>         # 下载一个命名 <span class="hljs-title">release</span></span><br><span class="hljs-function"><span class="hljs-title">help</span>        # 列出所有帮助信息</span><br><span class="hljs-function"><span class="hljs-title">history</span>     # 获取 <span class="hljs-title">release</span> 历史</span><br><span class="hljs-function"><span class="hljs-title">home</span>        # 显示 <span class="hljs-title">HELM_HOME</span> 的位置</span><br><span class="hljs-function"><span class="hljs-title">init</span>        # 在客户端和服务器上初始化<span class="hljs-title">Helm</span></span><br><span class="hljs-function"><span class="hljs-title">inspect</span>     # 检查 <span class="hljs-title">chart</span> 详细信息</span><br><span class="hljs-function"><span class="hljs-title">install</span>     # 安装 <span class="hljs-title">chart</span> 存档</span><br><span class="hljs-function"><span class="hljs-title">lint</span>        # 对 <span class="hljs-title">chart</span> 进行语法检查</span><br><span class="hljs-function"><span class="hljs-title">list</span>        # <span class="hljs-title">releases</span> 列表</span><br><span class="hljs-function"><span class="hljs-title">package</span>     # 将 <span class="hljs-title">chart</span> 目录打包成 <span class="hljs-title">chart</span> 档案</span><br><span class="hljs-function"><span class="hljs-title">plugin</span>      # 添加列表或删除 <span class="hljs-title">helm</span> 插件</span><br><span class="hljs-function"><span class="hljs-title">repo</span>        # 添加列表删除更新和索引 <span class="hljs-title">chart</span> 存储库</span><br><span class="hljs-function"><span class="hljs-title">reset</span>       # 从集群中卸载 <span class="hljs-title">Tiller</span></span><br><span class="hljs-function"><span class="hljs-title">rollback</span>    # 将版本回滚到以前的版本</span><br><span class="hljs-function"><span class="hljs-title">search</span>      # 在 <span class="hljs-title">chart</span> 存储库中搜索关键字</span><br><span class="hljs-function"><span class="hljs-title">serve</span>       # 启动本地<span class="hljs-title">http</span>网络服务器</span><br><span class="hljs-function"><span class="hljs-title">status</span>      # 显示指定 <span class="hljs-title">release</span> 的状态</span><br><span class="hljs-function"><span class="hljs-title">template</span>    # 本地渲染模板</span><br><span class="hljs-function"><span class="hljs-title">test</span>        # 测试一个 <span class="hljs-title">release</span></span><br><span class="hljs-function"><span class="hljs-title">upgrade</span>     # 升级一个 <span class="hljs-title">release</span></span><br><span class="hljs-function"><span class="hljs-title">verify</span>      # 验证给定路径上的 <span class="hljs-title">chart</span> 是否已签名且有效</span><br><span class="hljs-function"><span class="hljs-title">version</span>     # 打印客户端/服务器版本信息</span><br><span class="hljs-function"><span class="hljs-title">dep</span>         # 分析 <span class="hljs-title">Chart</span> 并下载依赖</span><br></code></pre></td></tr></table></figure><h2 id="3、组件架构">3、组件架构</h2><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200302214010170.png" alt></p><p><strong><code>Helm Client</code> 是用户命令行工具，其主要负责如下：</strong></p><ul><li><strong>本地 chart 开发</strong></li><li><strong>仓库管理</strong></li><li><strong>与 Tiller sever 交互</strong></li><li><strong>发送预安装的 chart</strong></li><li><strong>查询 release 信息</strong></li><li><strong>要求升级或卸载已存在的 release</strong></li></ul><p><strong><code>Tiller Server</code>是一个部署在<code>Kubernetes</code>集群内部的 server，其与 Helm client、Kubernetes API server 进行交互。Tiller server 主要负责如下：</strong></p><ul><li><strong>监听来自 Helm client 的请求</strong></li><li><strong>通过 chart 及其配置构建一次发布</strong></li><li><strong>安装 chart 到<code>Kubernetes</code>集群，并跟踪随后的发布</strong></li><li><strong>通过与<code>Kubernetes</code>交互升级或卸载 chart</strong></li><li><strong>简单的说，client 管理 charts，而 server 管理发布 release</strong></li></ul><h3 id="helm客户端">helm客户端</h3><p><strong>helm客户端是一个命令行工具，负责管理charts、reprepository和release。它通过gPRC API（使用kubectl port-forward将tiller的端口映射到本地，然后再通过映射后的端口跟tiller通信）向tiller发送请求，并由tiller来管理对应的Kubernetes资源。</strong></p><h3 id="tiller服务端">tiller服务端</h3><p><strong>tiller接收来自helm客户端的请求，并把相关资源的操作发送到Kubernetes，负责管理（安装、查询、升级或删除等）和跟踪Kubernetes资源。为了方便管理，tiller把release的相关信息保存在kubernetes的ConfigMap中。</strong><br><strong>tiller对外暴露gRPC API，供helm客户端调用。</strong></p><h2 id="4、工作原理">4、工作原理</h2><h4 id="Chart-Install-过程："><strong>Chart Install 过程：</strong></h4><ul><li><strong>Helm从指定的目录或者tgz文件中解析出Chart结构信息</strong></li><li><strong>Helm将指定的Chart结构和Values信息通过gRPC传递给Tiller</strong></li><li><strong>Tiller根据Chart和Values生成一个Release</strong></li><li><strong>Tiller将Release发送给Kubernetes运行。</strong></li></ul><h4 id="Chart-Update过程："><strong>Chart Update过程：</strong></h4><ul><li><strong>Helm从指定的目录或者tgz文件中解析出Chart结构信息</strong></li><li><strong>Helm将要更新的Release的名称和Chart结构，Values信息传递给Tiller</strong></li><li><strong>Tiller生成Release并更新指定名称的Release的History</strong></li><li><strong>Tiller将Release发送给Kubernetes运行</strong></li></ul><h4 id="Chart-Rollback">Chart Rollback</h4><ul><li><strong>helm将会滚的release名称传递给tiller</strong></li><li><strong>tiller根据release名称查找history</strong></li><li><strong>tiller从history中获取到上一个release</strong></li><li><strong>tiller将上一个release发送给kubernetes用于替换当前release</strong></li></ul><h4 id="Chart处理依赖">Chart处理依赖</h4><p><strong>Tiller 在处理 Chart 时，直接将 Chart 以及其依赖的所有 Charts 合并为一个 Release，同时传递给 Kubernetes。因此 Tiller 并不负责管理依赖之间的启动顺序。Chart 中的应用需要能够自行处理依赖关系。</strong></p><h1>二、安装部署helm工具（客户端）</h1><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302084446678.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302084446678.png" alt="image-20200302084446678"></a></p><h4 id="前提要求"><strong>前提要求</strong></h4><ul><li><strong>Kubernetes1.5以上版本</strong></li><li><strong>集群可访问到的镜像仓库</strong></li><li><strong>执行helm命令的主机可以访问到kubernetes集群</strong></li></ul><h3 id="（1）下载helm的包">（1）下载helm的包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]#docker pull gcr.io/kubernetes-helm/tiller:v2.14.3<br>[root@master ~]# wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz<br></code></pre></td></tr></table></figure><h3 id="（2）把helm包的命令，复制到本地">（2）把helm包的命令，复制到本地</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# mv linux-amd64/helm /usr/local/bin/<br>//移动命令目录到/usr/local/bin/<br>[root@master helm]# chmod +x /usr/local/bin/helm <br>//给予执行权限<br>[root@master helm]# helm help<br>//验证是否安装成功<br></code></pre></td></tr></table></figure><h3 id="（3）设置命令自动补全">（3）设置命令自动补全</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]#  echo 'source &lt;(helm completion bash)' &gt;&gt; /etc/profile<br>[root@master helm]# . /etc/profile<br>//刷新一下<br></code></pre></td></tr></table></figure><h2 id="2、安装Tiller-server（服务端，需要创建授权用户）">2、安装Tiller server（服务端，需要创建授权用户）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim tiller-rbac.yaml   #创建授权用户<br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: tiller<br>  namespace: kube-system<br>---<br>apiVersion: rbac.authorization.k8s.io/v1beta1<br>kind: ClusterRoleBinding<br>metadata:<br>  name: tiller<br>roleRef:<br>  apiGroup: rbac.authorization.k8s.io<br>  kind: ClusterRole<br>  name: cluster-admin<br>subjects:<br>  - kind: ServiceAccount<br>    name: tiller<br>    namespace: kube-system<br></code></pre></td></tr></table></figure><h4 id="执行一下">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f tiller-rbac.yaml<br></code></pre></td></tr></table></figure><h3 id="（1）Tiller-server的环境初始化">（1）Tiller server的环境初始化</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# helm init  --service-account=tiller<br>//helm的服务端就是Tiller（因为是访问外国的网站，可能需要多次执行）<br></code></pre></td></tr></table></figure><h4 id="查看一下">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# kubectl get deployment. -n kube-system<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228120107088.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228120107088.png" alt="image-20200228120107088"></a></p><p><strong>现在发现没有开启，那是因为默认下载的Google的镜像，下载不下来</strong></p><h3 id="（2）设置镜像源改为阿里云的">（2）设置镜像源改为阿里云的</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts<br></code></pre></td></tr></table></figure><h4 id="查看一下-2">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master helm]# helm version<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228120548734.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228120548734.png" alt="image-20200228120548734"></a></p><h2 id="3、部署一个实例helm-install-charts-n-Release名称。">3、部署一个实例helm install + charts -n Release名称。</h2><blockquote><p><strong>1、关于这个Release的描述。</strong></p><p><strong>2、关于这个Release资源的描述。</strong></p><p><strong>3、怎么使用这个Release。</strong></p></blockquote><h3 id="（1）Helm部署安装一个Mysql服务。">（1）Helm部署安装一个Mysql服务。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm search mysql<br>//查看关于mysqk的Charts包<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302091903599.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302091903599.png" alt="image-20200302091903599"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm install stable/mysql -n mysql <br>//基于stable/mysql包安装一个名为MySQL的服务<br></code></pre></td></tr></table></figure><h3 id="查看一下-3">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# helm list<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302092055970.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302092055970.png" alt="image-20200302092055970"></a></p><h3 id="（2）Charts包解压过后的目录">（2）Charts包解压过后的目录:</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# cd .helm/cache/archive<br>//查看helm缓存<br>[root@master archive]# ls<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302093625736.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302093625736.png" alt="image-20200302093625736"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# helm fetch stable/mysql<br>//直接下载stable/mysql的chart包<br>[root@master archive]# tar -zxf mysql-0.3.5.tgz <br>//解压一下MySQL包<br>[root@master archive]# tree -C mysql <br>//树状图查看解压出来的mysql目录，-C:显示颜色<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302093816396.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302093816396.png" alt="image-20200302093816396"></a></p><blockquote><p><strong>Chart.yaml：这个chart包的概要信息。（name和version 这两是必填项，其他可选。）</strong></p><p><strong>README md：是这个chart包的一个使用帮助文档。</strong></p><p><strong>templates：chart包内各种资源对象的模板。</strong></p><blockquote><p><strong>deployment.yaml：deployment 控制器的 Go 模板文件</strong></p><p><strong>_helpers.tpl：以 _ 开头的文件不会部署到 k8s 上，可用于定制通用信息</strong></p><p><strong>NOTES.txt：Chart 部署到集群后的一些信息</strong></p><p><strong>service.yaml：service 的 Go 模板文件</strong></p></blockquote><p><strong>values.yaml：是这个chart包的默认的值，可以被templet内的yaml文件使用。</strong></p></blockquote><h3 id="（3）Helm部署安装-个Mysql服务。">（3）Helm部署安装-个Mysql服务。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# docker pull mysql:5.7.14<br>[root@master ~]# docker pull mysql:5.7.15<br>[root@master ~]# docker pull busybox:1.25.0<br>下载所需的mysql镜像<br>[root@master ~]# helm delete mysql --purge <br>//删除之前的MySQL服务并清除缓存<br></code></pre></td></tr></table></figure><h3 id="（4）设置共享目录">（4）设置共享目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# yum -y install rpcbind nfs-utils<br>//安装nfs<br>[root@master ~]# mkdir /data<br>//创建共享目录<br>[root@master ~]# vim /etc/exports<br>/data *(rw,sync,no_root_squash)<br>//设置共享目录权限<br>[root@master ~]# systemctl restart rpcbind<br>[root@master ~]# systemctl restart nfs-server<br>//重启nfs服务<br><br>测试一下<br>[root@master ~]# showmount -e<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302105307662.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302105307662.png" alt="image-20200302105307662"></a></p><h3 id="（5）创建pv">（5）创建pv</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# vim nfs-pv1.yml <br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: mysqlpv<br>spec:<br>  capacity:<br>    storage: 8Gi<br>  accessModes:<br>    - ReadWriteOnce<br>  persistentVolumeReclaimPolicy: Recycle<br>  nfs:<br>    path: /data/mysqlpv<br>    server: 192.168.1.21<br>[root@master xgp]# mkdir /data/mysqlpv<br>//创建所需目录<br></code></pre></td></tr></table></figure><h4 id="执行一下-2">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl apply -f nfs-pv1.yml<br></code></pre></td></tr></table></figure><h4 id="查看一下-4">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302110137247.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302110137247.png" alt="image-20200302110137247"></a></p><h3 id="（6）创建一个mysql服务">（6）创建一个mysql服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# helm install stable/mysql -n bdqn-mysql --set mysqlRootPassword=123.com<br></code></pre></td></tr></table></figure><h4 id="查看一下-5">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302111518710.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302111518710.png" alt="image-20200302111518710"></a></p><h3 id="（7）进入pod并查看一下">（7）进入pod并查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl exec -it bdqn-mysql-mysql-7b89c7b99-8ff2r -- mysql -u root -p123.com<br><span class="hljs-meta">mysql&gt;</span><span class="bash"> show databases;</span><br>+--------------------+<br>| Database           |<br>+--------------------+<br>| information_schema |<br>| mysql              |<br>| performance_schema |<br>| sys                |<br>+--------------------+<br>4 rows in set (0.01 sec)<br></code></pre></td></tr></table></figure><h2 id="4、mysql服务的升级与回滚">4、mysql服务的升级与回滚</h2><h3 id="（1）mysql服务的升级">（1）mysql服务的升级</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# helm upgrade --set imageTag=5.7.15 bdqn-mysql stable/mysql -f values.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-6">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115511986.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115511986.png" alt="image-20200302115511986"></a></p><h3 id="（2）mysql服务的回滚">（2）mysql服务的回滚</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]#  helm history bdqn-mysql<br>//查看历史版本<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115645118.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115645118.png" alt="image-20200302115645118"></a></p><h4 id="回滚到版本一">回滚到版本一</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# helm rollback bdqn-mysql 1<br></code></pre></td></tr></table></figure><h4 id="查看一下-7">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115823991.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115823991.png" alt="image-20200302115823991"></a></p><h1>三、小实验</h1><p><strong>在部署mysql的时候，如何开启storageclass，以及如何将service资源对象的类型更改为NodePort, 如何使用?</strong></p><p><strong>将上述部署的实例进行升级回滚操作。升级的时候镜像改为： mysql:5.7.15版本。回滚到最初的版本。</strong></p><h2 id="1、基于NFS服务，创建NFS服务。">1、基于NFS服务，创建NFS服务。</h2><p><strong>下载nfs所需安装包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node02 ~]# yum -y install nfs-utils  rpcbind<br></code></pre></td></tr></table></figure><p><strong>创建共享目录</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# mkdir -p /xgp/wsd<br></code></pre></td></tr></table></figure><p><strong>创建共享目录的权限</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim /etc/exports<br>/xgp *(rw,sync,no_root_squash)<br></code></pre></td></tr></table></figure><p><strong>开启nfs和rpcbind（三台都要）</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# systemctl start nfs-server.service <br>[root@master ~]# systemctl start rpcbind<br></code></pre></td></tr></table></figure><p><strong>测试一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# showmount -e<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302143413268.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302143413268.png" alt="image-20200302143413268"></a></p><h2 id="2、创建StorageClass资源对象。">2、创建StorageClass资源对象。</h2><h3 id="（1）创建rbac权限。">（1）创建rbac权限。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim rbac.yaml <br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: nfs-provisioner<br>  namespace: default<br>---<br>apiVersion: rbac.authorization.k8s.io/v1<br>kind: ClusterRole<br>metadata:<br>  name: nfs-provisioner-runner<br>  namespace: default<br>rules:<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumes"]<br>      verbs: ["get", "list", "watch", "create", "delete"]<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumeclaims"]<br>      verbs: ["get", "list", "watch", "update"]<br>   -  apiGroups: ["storage.k8s.io"]<br>      resources: ["storageclasses"]<br>      verbs: ["get", "list", "watch"]<br>   -  apiGroups: [""]<br>      resources: ["events"]<br>      verbs: ["watch", "create", "update", "patch"]<br>   -  apiGroups: [""]<br>      resources: ["services", "endpoints"]<br>      verbs: ["get","create","list", "watch","update"]<br>   -  apiGroups: ["extensions"]<br>      resources: ["podsecuritypolicies"]<br>      resourceNames: ["nfs-provisioner"]<br>      verbs: ["use"]<br>---<br>kind: ClusterRoleBinding<br>apiVersion: rbac.authorization.k8s.io/v1<br>metadata:<br>  name: run-nfs-provisioner<br>subjects:<br>  - kind: ServiceAccount<br>    name: nfs-provisioner<br>    namespace: default        #必写字段<br>roleRef:<br>  kind: ClusterRole<br>  name: nfs-provisioner-runner<br>  apiGroup: rbac.authorization.k8s.io<br></code></pre></td></tr></table></figure><h4 id="执行一下-3">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f rbac.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）创建Deployment资源对象，用Pod代替-真正的NFS服务。">（2）创建Deployment资源对象，用Pod代替 真正的NFS服务。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nfs-deployment.yaml <br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nfs-client-provisioner<br>spec:<br>  replicas: 1<br>  strategy:<br>    type: Recreate<br>  template:<br>    metadata:<br>      labels:<br>        app: nfs-client-provisioner<br>    spec:<br>      serviceAccount: nfs-provisioner<br>      containers:<br>        - name: nfs-client-provisioner<br>          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner<br>          volumeMounts:<br>            - name: nfs-client-root<br>              mountPath:  /persistentvolumes<br>          env:<br>            - name: PROVISIONER_NAME<br>              value: xgp<br>            - name: NFS_SERVER<br>              value: 192.168.1.21<br>            - name: NFS_PATH<br>              value: /xgp/wsd<br>      volumes:<br>        - name: nfs-client-root<br>          nfs:<br>            server: 192.168.1.21<br>            path: /xgp/wsd<br></code></pre></td></tr></table></figure><h4 id="执行一下-4">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-deployment.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-8">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212104037272.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212104037272.png" alt="image-20200212104037272"></a></p><h3 id="（3）创建storageclass的yaml文件">（3）创建storageclass的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim xgp-storageclass.yaml <br>apiVersion: storage.k8s.io/v1<br>kind: StorageClass<br>metadata:<br>  name: xgp-nfs<br>provisioner: xgp  #通过provisioner字段关联到上述Deploy<br>reclaimPolicy: Retain<br></code></pre></td></tr></table></figure><h4 id="执行一下-5">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f test-storageclass.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-9">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get sc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302163422262.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302163422262.png" alt="image-20200302163422262"></a></p><h2 id="3、创建一个mysql服务">3、创建一个mysql服务</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# docker pull mysql:5.7.14<br>[root@master ~]# docker pull mysql:5.7.15<br>[root@master ~]# docker pull busybox:1.25.0<br>//下载所需镜像<br>[root@master yaml]# helm fetch stable/mysql<br>//直接下载stable/mysql的chart包<br>[root@master yaml]# tar -zxf mysql-0.3.5.tgz <br>//解压mysql包<br>[root@master yaml]# cd mysql/<br>[root@master mysql]# vim values.yaml <br>//修改values.yaml文件，添加storageClass存储卷和更改svc的模式为NodePort<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302164514380.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302164514380.png" alt="image-20200302164514380"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302164620871.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302164620871.png" alt="image-20200302164620871"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# helm install stable/mysql -n xgp-mysql --set mysqlRootPassword=123.com -f values.yaml <br>//基于values.yaml和stable/mysql开启一个密码为123.com的mysqlpod<br></code></pre></td></tr></table></figure><h3 id="查看一下-10">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302174753877.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302174753877.png" alt="image-20200302174753877"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302170330864.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302170330864.png" alt="image-20200302170330864"></a></p><h2 id="4、进入pod并查看一下">4、进入pod并查看一下</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]#  kubectl exec -it xgp-mysql-mysql-67c6fb5f9-dn7s2 -- mysql -u root -p123.com<br><span class="hljs-meta">mysql&gt;</span><span class="bash"> show databases;</span><br>+--------------------+<br>| Database           |<br>+--------------------+<br>| information_schema |<br>| mysql              |<br>| performance_schema |<br>| sys                |<br>+--------------------+<br>4 rows in set (0.01 sec)<br></code></pre></td></tr></table></figure><h2 id="5、mysql服务的升级与回滚">5、mysql服务的升级与回滚</h2><h3 id="（1）mysql服务的升级-2">（1）mysql服务的升级</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# helm upgrade --set imageTag=5.7.15 xgp-mysql stable/mysql -f values.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-11">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115511986.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115511986.png" alt="image-20200302115511986"></a></p><h3 id="（2）服务的回滚">（2）服务的回滚</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]#  helm history xgp-mysql<br>//查看历史版本<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302175135110.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302175135110.png" alt="image-20200302175135110"></a></p><h4 id="回滚到版本一-2">回滚到版本一</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# helm rollback xgp-mysql 1<br></code></pre></td></tr></table></figure><h4 id="查看一下-12">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115823991.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200302115823991.png" alt="image-20200302115823991"></a></p><h2 id="6、进入pod并查看一下">6、进入pod并查看一下</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master mysql]#  kubectl exec -it xgp-mysql-mysql-67c6fb5f9-dn7s2 -- mysql -u root -p123.com<br><span class="hljs-meta">mysql&gt;</span><span class="bash"> show databases;</span><br>+--------------------+<br>| Database           |<br>+--------------------+<br>| information_schema |<br>| mysql              |<br>| performance_schema |<br>| sys                |<br>+--------------------+<br>4 rows in set (0.01 sec)<br></code></pre></td></tr></table></figure><h1>四、总结</h1><p><strong>Helm作为kubernetes应用的包管理以及部署工具，提供了应用打包，发布，版本管理以及部署，升级，回退等功能。Helm以Chart软件包的形式简化Kubernetes的应用管理，提高了对用户的友好性。</strong></p><h2 id="使用心得">使用心得</h2><p><strong>helm 客户端的功能非常简单，直接参考官网文档即可。</strong></p><p><strong>列一下相关使用心得：</strong></p><ul><li><strong>Helm 的所有功能都是围绕着 chart、release 和 repository 的；</strong></li><li><strong>仅初始化客户端相关配置且仅建立本地仓库，可执行 <code>helm init --client-only --skip-refresh</code>；</strong></li><li><strong>查找 chart 的方式是通过 HELM_HOME（默认是 ~/.helm 目录）下的 repositories 目录进行的，几个重要文件或目录为 cache、repositories/cache；</strong></li><li><strong>修改 chart index.yaml 的 url，可执行 <code>helm serve --url http://demo.com</code> 来重新 reindex；</strong></li><li><strong>依赖关系管理，requirements定义，子 chart 值定义；</strong></li><li><strong>install 、 update 的方式管理不方便，这样需要维护 chart 的版本关系，集成 install 和 update ，组成类似 k8s 中的 apply 命令；</strong></li><li><strong>package 命令 -u 可以更新依赖，建议推到 repositiories 前先 package ，否则后期可能出现依赖检测不全的错误；</strong></li><li><strong>release 相关的信息存储在 k8s 的 configmap 中，命名形式为 release_name.v1 的格式。 rollback 相关功能就是通过存储在 configmap 中的信息进行回滚的；</strong></li><li><strong>Helm 客户端与 k8s 中的 TillerServer 是通过 k8s 提供的 port-forward 来实现的，而 port-forward 需要在指定节点上部署 socat；</strong></li><li><strong>TillerServer 可以不部署在 k8s 中， 此时 Helm 客户端需要通过 HELM_HOST 环境变量来指定 TillerServer 的地址和端口；</strong></li><li><strong>建议 TillerServer 部署在 k8s 中，既然 Helm 为 CNCF 的一员，那么就尽量把云原生做到极致吧；</strong></li><li><strong>写 chart 时多参考官方最佳实践，<a href="https://docs.helm.sh/chart_best_practices/" target="_blank" rel="noopener">The Chart Best Practices Guide</a>；</strong></li></ul><h2 id="不足">不足</h2><p><strong>Helm 虽然提供了 install、update 命令来安装或更新对应的 release，但这给使用者带来了需要维护 release 状态的压力。举个例子，在还没安装 release 之前，release 是不存在的，update 操作是会失败的。反之已经存在的 release，install 操作也会失败。其实大部分情况下我是不需要知道 release 的状态的，不管它存在还是不存在，我执行的命令就是我希望的意图，我希望 release 能成为我执行命令后的状态。这一点上 k8s 的 apply 命令就非常好，不需要用户来维护资源的状态。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;一、Helm介绍&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;helm&lt;/code&gt;是基于&lt;code&gt;kubernetes&lt;/code&gt; 的包管理器。它之于 &lt;code&gt;kubernetes&lt;/code&gt; 就如 &lt;code&gt;yum&lt;/code&gt; 之于 &lt;code&gt;cent
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="chart" scheme="https://wsdlxgp.top/tags/chart/"/>
    
      <category term="helm" scheme="https://wsdlxgp.top/tags/helm/"/>
    
      <category term="tiller" scheme="https://wsdlxgp.top/tags/tiller/"/>
    
  </entry>
  
  <entry>
    <title>k8s的HPA自动扩容与缩容</title>
    <link href="https://wsdlxgp.top/posts/5f70.html"/>
    <id>https://wsdlxgp.top/posts/5f70.html</id>
    <published>2020-06-07T12:10:19.599Z</published>
    <updated>2020-06-07T14:35:40.146Z</updated>
    
    <content type="html"><![CDATA[<h1>HPA介绍</h1><p><strong>Kubernetes HPA（水平Pod自动缩放）Pod水平自动伸缩，通过此功能，只需简单的配置，即可便可以利用监控指标（cpu使用率、磁盘、内存等）自动的扩容或缩容服务中Pod数量，当业务需求增加时，系统将为您无缝地自动增加适量容器，提高系统稳定性。此处将详细讲解HPA的核心设计原理和基于Hepaster的使用方法</strong>。</p><h3 id="前提条件">前提条件</h3><p><strong>系统应该能否获取到当前Pod的资源使用情况 (意思是可以执行kubectl top pod命令,并且能够得到反馈信息)。</strong></p><p><strong>若要实现自动扩缩容的功能，还需要部署heapster服务，用来收集及统计资源的利用率，支持kubectl top命令，heapster服务集成在prometheus（普罗米修斯） MertricServer服务中，所以说，为了方便，我这里基于prometheus服务的环境上进行部署HPA（动态扩缩容）的服务。</strong></p><h3 id="实验环境">实验环境</h3><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>k8s</td></tr><tr><td>node01</td><td>192.168.1.22</td><td>k8s</td></tr><tr><td>node02</td><td>192.168.1.23</td><td>k8s</td></tr></tbody></table><p><strong>基于<a href>https://blog.51cto.com/14320361/2473879</a> 的实验继续进行</strong></p><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607215857.png" alt="k8s的HPA自动扩容与缩容"></p><ul><li><strong>heapster：这个组件之前是集成在k8s集群的,不过在1.12版本之后被移除了。如果还想使用此功能，应该部署metricServer, 这个k8s集群资源使用情况的聚合器。</strong></li><li><strong>Cousom：同样处于beta阶段(autoscaling/v2beta1)，但是涉及到自定义的REST API的开发，复杂度会大一些，并且当需要从自定义的监控中获取数据时，只能设置绝对值，无法设置使用率。</strong></li></ul><h4 id="自动扩展主要分为两种：">自动扩展主要分为两种：</h4><ul><li><strong>水平扩展(scale out)，针对于实例数目的增减。</strong></li><li><strong>垂直扩展(scal up)，即单个实例可以使用的资源的增减, 比如增加cpu和增大内存。</strong><br><strong>HPA属于前者。它可以根据CPU使用率或应用自定义metrics自动扩展Pod数量(支持 replication controller、deployment 和 replica set)。</strong></li></ul><h3 id="工作流程">工作流程</h3><ul><li><strong>创建HPA资源，设定目标CPU使用率限额，以及最大/最小实例数，一定要设置Pod的资源限制参数: request，否则HPA不会工作。</strong></li><li><strong>控制管理器每隔30s(在kube-controller-manager.service中可以通过–-horizontal-pod-autoscaler-sync-period修改)查询metrics的资源使用情况。</strong></li><li><strong>然后与创建时设定的值和指标做对比(平均值之和/限额)，求出目标调整的实例个数。</strong></li><li><strong>目标调整的实例数不能超过第一条中设定的最大/最小实例数。如果没有超过，则扩容；超过，则扩容至最大的实例个数。</strong></li><li><strong>重复第2-4步。</strong></li></ul><p><strong>这里，我们使用一个测试镜像， 这个镜像基于php-apache制作的docker镜像，包含了一些可以运行cpu密集计算任务的代码。</strong></p><h2 id="1、创建一个deployment控制器">1、创建一个deployment控制器</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]#docker pull mirrorgooglecontainers/hpa-example:latest<br>//下载hpa-example镜像<br><br>[root@master ~]# kubectl run php-apache --image=mirrorgooglecontainers/hpa-example --requests=cpu=200m --expose  --port=80<br>//基于hpa-example镜像，运行一个deployment控制器，请求CPU的资源为200m，暴露一个80端口<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments.<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228102643352.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228102643352.png" alt="image-20200228102643352"></a></p><h2 id="2、创建HPA控制器">2、创建HPA控制器</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10<br>//当deployment资源对象的CPU使用率达到50%时，就进行扩容，最多可以扩容到10个<br></code></pre></td></tr></table></figure><h3 id="查看一下-2">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get hpa<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228101908398.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228101908398.png" alt="image-20200228101908398"></a></p><h2 id="3、测试（master开启三个端口）">3、测试（master开启三个端口）</h2><p><strong>新开启多个终端，对pod进行死循环请求php-apache的pod</strong></p><h3 id="端口一">端口一</h3><h4 id="（1）创建一个应用，用来不停的访问我们刚刚创建的php-apache的svc资源。">（1）创建一个应用，用来不停的访问我们刚刚创建的php-apache的svc资源。</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl run -i --tty load-generator --image=busybox /bin/sh<br></code></pre></td></tr></table></figure><h4 id="（2）进入Pod内，执行以下这条命令-用来模拟访问php-apache的svc资源。">（2）进入Pod内，执行以下这条命令.用来模拟访问php-apache的svc资源。</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# while true; do wget -q -O- http://php-apache.default.svc.cluster.local ; done<br>//不停地向php-apache的svc资源，发送ok<br></code></pre></td></tr></table></figure><h3 id="端口二">端口二</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get hpa -w<br>//实时查看pod的cpu状态<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200228133816724.png" alt="image-20200228133816724"></p><p><strong>可以看到php-apache的cpu使用情况已经超过了50%</strong></p><h3 id="端口三">端口三</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master images]# kubectl get pod -w<br>//实时查看pod的状态<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200228134105507.png" alt="image-20200228134105507"></p><p><strong>可以看到当php-apache的cpu使用情况超过50%后，就会不断生成新的php-apache来进行负载均衡（目前设置的上线时10个），当然，如果cpu使用情况下降到50%，master就会陆续地删除php-apache，这样的使用可以减少不必要的资源浪费、资源分配不均等情况。</strong></p><h1>二、资源限制</h1><h2 id="1、基于Pod">1、基于Pod</h2><p><strong>Kubernetes对资源的限制实际上是通过cgroup来控制的，cgroup 是容器的一组用来控制内核如何运行进程的相关属性集合。针对内存、CPU 和各种设备都有对应的cgroup</strong></p><p><strong>默认情况下，Pod运行没有CPU和内存的限额。这意味着系统中的任何 Pod将能够像执行该Pod所在的节点一样，消耗足够多的CPU和内存。一般会针对某些应用的pod资源进行资源限制，这个资源限制是通过</strong></p><p><strong>resources的requests和limits来实现</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim cgroup-pod.yaml<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200228153809932.png" alt="image-20200228153809932"></p><p><strong>requests: 要分配的资源，limits为最高请求的资源值。可以简单的理解为初始值和最大值。</strong></p><h2 id="2、基于名称空间"><strong>2、基于名称空间</strong></h2><h3 id="1）-计算资源配额">1） 计算资源配额</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim compute-resources.yaml<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200228153818288.png" alt="image-20200228153818288"></p><h3 id="2）配置对象数量配额限制">2）配置对象数量配额限制</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim object-counts.yaml<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200228153828002.png" alt="image-20200228153828002"></p><h3 id="3）-配置CPU和内存的LimitRange">3） 配置CPU和内存的LimitRange</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim limitRange.yaml<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200228153834705.png" alt="image-20200228153834705"></p><p><strong>default 即 limit的值。</strong></p><p><strong>defaultRequest 即 request的值。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;HPA介绍&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Kubernetes HPA（水平Pod自动缩放）Pod水平自动伸缩，通过此功能，只需简单的配置，即可便可以利用监控指标（cpu使用率、磁盘、内存等）自动的扩容或缩容服务中Pod数量，当业务需求增加时，系统将为您无缝地自动增加适
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="HPA" scheme="https://wsdlxgp.top/tags/HPA/"/>
    
      <category term="heapster" scheme="https://wsdlxgp.top/tags/heapster/"/>
    
      <category term="top" scheme="https://wsdlxgp.top/tags/top/"/>
    
  </entry>
  
  <entry>
    <title>k8s群集的三种的Web-UI界面部署（dashboard、weave-scope、Prometheus）</title>
    <link href="https://wsdlxgp.top/posts/4f99.html"/>
    <id>https://wsdlxgp.top/posts/4f99.html</id>
    <published>2020-06-07T12:10:17.163Z</published>
    <updated>2020-06-07T14:35:40.144Z</updated>
    
    <content type="html"><![CDATA[<h1>一、k8s的UI访问界面-dashboard</h1><p><strong>在dashboard中，虽然可以做到创建、删除、修改资源等操作，但通常情况下，我们会把它当做健康k8s集群的软件。</strong></p><p><strong>作为Kubernetes的Web用户界面，用户可以通过Dashboard在Kubernetes集群中部署容器化的应用，对应用进行问题处理和管理，并对集群本身进行管理。通过Dashboard，用户可以查看集群中应用的运行情况，同时也能够基于Dashboard创建或修改部署、任务、服务等Kubernetes的资源。通过部署向导，用户能够对部署进行扩缩容，进行滚动更新、重启Pod和部署新应用。当然，通过Dashboard也能够查看Kubernetes资源的状态。</strong></p><h2 id="1、Dashboard提供的功能">1、Dashboard提供的功能</h2><p><strong>在默认情况下，Dashboard显示默认(default)命名空间下的对象，也可以通过命名空间选择器选择其他的命名空间。在Dashboard用户界面中能够显示集群大部分的对象类型。</strong></p><h3 id="1）集群管理"><strong>1）集群管理</strong></h3><p><strong>集群管理视图用于对节点、命名空间、持久化存储卷、角色和存储类进行管理。 节点视图显示CPU和内存的使用情况，以及此节点的创建时间和运行状态。 命名空间视图会显示集群中存在哪些命名空间，以及这些命名空间的运行状态。角色视图以列表形式展示集群中存在哪些角色，这些角色的类型和所在的命名空间。 持久化存储卷以列表的方式进行展示，可以看到每一个持久化存储卷的存储总量、访问模式、使用状态等信息；管理员也能够删除和编辑持久化存储卷的YAML文件。</strong></p><h3 id="2）-工作负载"><strong>2）</strong> <strong>工作负载</strong></h3><p><strong>工作负载视图显示部署、副本集、有状态副本集等所有的工作负载类型。在此视图中，各种工作负载会按照各自的类型进行组织。 工作负载的详细信息视图能够显示应用的详细信息和状态信息，以及对象之间的关系。</strong></p><h3 id="3）-服务发现和负载均衡"><strong>3）</strong> <strong>服务发现和负载均衡</strong></h3><p><strong>服务发现视图能够将集群内容的服务暴露给集群外的应用，集群内外的应用可以通过暴露的服务调用应用，外部的应用使用外部的端点，内部的应用使用内部端点</strong>。</p><h3 id="4）-存储"><strong>4）</strong> <strong>存储</strong></h3><p><strong>存储视图显示被应用用来存储数据的持久化存储卷申明资源。</strong></p><h3 id="5）-配置"><strong>5）</strong> <strong>配置</strong></h3><p><strong>配置视图显示集群中应用运行时所使用配置信息，Kubernetes提供了配置字典（ConfigMaps）和秘密字典（Secrets），通过配置视图，能够编辑和管理配置对象，以及查看隐藏的敏感信息。</strong></p><h3 id="6）-日志视图"><strong>6）</strong> <strong>日志视图</strong></h3><p><strong>Pod列表和详细信息页面提供了查看日志视图的链接，通过日志视图不但能够查看Pod的日志信息，也能够查看Pod容器的日志信息。通过Dashboard能够根据向导创建和部署一个容器化的应用，当然也可以通过手工的方式输入指定应用信息，或者通过上传YAML和JSON文件来创建和不受应用。</strong></p><h2 id="2、下载所需yaml文件和镜像">2、下载所需yaml文件和镜像</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc5/aio/deploy/recommended.yaml<br>[root@master https]# docker pull kubernetesui/dashboard:v2.0.0-rc5<br></code></pre></td></tr></table></figure><h2 id="3、修改-recommended-yaml">3、修改 recommended.yaml</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]#vim recommended.yaml <br>---<br>kind: Service<br>apiVersion: v1<br>metadata:<br>  labels:<br>    k8s-app: kubernetes-dashboard<br>  name: kubernetes-dashboard<br>  namespace: kubernetes-dashboard<br>spec:<br>  type: NodePort            #添加40<br>  ports:<br>    - port: 443<br>      targetPort: 8443<br>  selector:<br>    k8s-app: kubernetes-dashboard<br></code></pre></td></tr></table></figure><h3 id="执行一下">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl apply -f recommended.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get svc -n kubernetes-dashboard<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226085710776.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226085710776.png" alt="image-20200226085710776"></a></p><h2 id="3、浏览器访问https-192-168-1-21-32306">3、浏览器访问https://192.168.1.21:32306</h2><p><strong>PS:如果是使用的旧版本的dashboard, 使用谷歌浏览器登录，可能是不成功的，需要换成其他的浏览器，比如:火狐。</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226110629545.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226110629545.png" alt="image-20200226110629545"></a></p><h2 id="4、基于token的方法登录dashboard">4、基于token的方法登录dashboard</h2><h3 id="1-创建一个dashboard的管理用户">&lt;1&gt;创建一个dashboard的管理用户</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl create serviceaccount dashboard-admin -n kube-system<br></code></pre></td></tr></table></figure><h3 id="2-绑定用户为集群管理用户">&lt;2&gt;绑定用户为集群管理用户</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin<br></code></pre></td></tr></table></figure><h3 id="3-获取Token">&lt;3&gt;获取Token</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin<br>//先得到Token的名称<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090141138.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090141138.png" alt="image-20200226090141138"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl describe secrets -n kube-system  dashboard-admin-token-62bh9<br>//查看上述得到的secret资源的详细信息，会得到token<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090425136.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090425136.png" alt="image-20200226090425136"></a></p><h3 id="4-在浏览器上使用token登录。">&lt;4&gt;在浏览器上使用token登录。</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090838680.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090838680.png" alt="image-20200226090838680"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226091007042.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226091007042.png" alt="image-20200226091007042"></a></p><p><strong>创建一个资源</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226094008072.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226094008072.png" alt="image-20200226094008072"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226094127460.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226094127460.png" alt="image-20200226094127460"></a></p><p><strong>查看是否创建成功</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226094149479.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226094149479.png" alt="image-20200226094149479"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226094209114.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226094209114.png" alt="image-20200226094209114"></a></p><h2 id="5、基于kubeconfig配置文件的方法登录dashboard">5、基于kubeconfig配置文件的方法登录dashboard</h2><h3 id="1-获取Token">&lt;1&gt;获取Token</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin<br>//先得到Token的名称<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090141138.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090141138.png" alt="image-20200226090141138"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl describe secrets -n kube-system  dashboard-admin-token-62bh9<br>//查看上述得到的secret资源的详细信息，会得到token<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090425136.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226090425136.png" alt="image-20200226090425136"></a></p><h3 id="2-生成kubeconfig配置文件。">&lt;2&gt;生成kubeconfig配置文件。</h3><p><strong>设置一个环境变量代表获取的token</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# DASH_TOKEN=$(kubectl get secrets -n kube-system dashboard-admin-token-62bh9  -o jsonpath=&#123;.data.token&#125; | base64 -d)<br></code></pre></td></tr></table></figure><p><strong>将k8s集群的配置信息写入kubeconfig配置文件中。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl config set-cluster kubernetes --server=192.168.1.21:6443 --kubeconfig=/root/.dashboard-admin.conf<br>[root@master https]# kubectl config set-credentials dashboard-admin --token=$DASH_TOKEN --kubeconfig=/root/.dashboard-admin.conf<br>[root@master https]# kubectl config set-context dashboard-admin@kubernetes --cluster=kubernetes --user=dashboard-admin --kubeconfig=/root/.dashboard-admin.conf<br>[root@master https]# kubectl config use-context dashboard-admin@kubernetes --kubeconfig=/root/.dashboard-admin.conf<br></code></pre></td></tr></table></figure><h3 id="3-将生成的-root-dashboard-admin-conf的配置文件，导出并做保存。">&lt;3&gt;将生成的/root/.dashboard-admin.conf的配置文件，导出并做保存。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# sz /root/.dashboard-admin.conf <br>//导出到自己习惯的位置即可<br></code></pre></td></tr></table></figure><h3 id="4-从浏览器选择kubeconfig的登录方式，然后导入配置文件即可。">&lt;4&gt;从浏览器选择kubeconfig的登录方式，然后导入配置文件即可。</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226100349876.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226100349876.png" alt="image-20200226100349876"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226100424656.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226100424656.png" alt="image-20200226100424656"></a></p><h1>二、部署weave-scope监控k8s集群</h1><p><strong>Weave Scope 是 Docker 和 Kubernetes 可视化监控工具。Scope 提供了至上而下的集群基础设施和应用的完整视图，用户可以轻松对分布式的容器化应用进行实时监控和问题诊断。</strong></p><h3 id="使用scope">使用scope</h3><ul><li><p><strong>Scope 会自动构建应用和集群的逻辑拓扑。比如点击顶部 PODS，会显示所有 Pod 以及 Pod 之间的依赖关系。</strong></p></li><li><p>点击 HOSTS，会显示各个节点之间的关系。</p><h3 id="实时资源监控">实时资源监控</h3></li><li><p><strong>可以在 Scope 中查看资源的 CPU 和内存使用情况。</strong></p></li><li><p>支持的资源有 Host、Pod 和 Container。**</p><h3 id="在线操作">在线操作</h3></li><li><p><strong>Scope 还提供了便捷的在线操作功能，比如选中某个 Host，点击 &gt;_ 按钮可以直接在浏览器中打开节点的命令行终端</strong></p></li><li><p><strong>点击 Deployment 的 + 可以执行 Scale Up 操作</strong></p></li><li><p><strong>可以查看 Pod 的日志</strong></p></li><li><p><strong>可以 attach、restart、stop 容器，以及直接在 Scope 中排查问题</strong></p><h3 id="强大的搜索功能">强大的搜索功能</h3></li><li><p><strong>Scope 支持关键字搜索和定位资源。</strong></p></li><li><p><strong>还可以进行条件搜索，比如查找和定位 MEMORY &gt; 100M 的 Pod。</strong></p></li></ul><h2 id="1、在github上查找scope的yaml文件">1、在github上查找scope的yaml文件</h2><h3 id="（1）github上搜索scope"><strong>（1）github上搜索scope</strong></h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226104345720.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226104345720.png" alt="image-20200226104345720"></a></p><h3 id="（2）进入k8s的部署scope的说明"><strong>（2）进入k8s的部署scope的说明</strong></h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226104445086.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226104445086.png" alt="image-20200226104445086"></a></p><h3 id="（3）选择k8s的部署"><strong>（3）选择k8s的部署</strong></h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226104603800.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226104603800.png" alt="image-20200226104603800"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226104711134.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226104711134.png" alt="image-20200226104711134"></a></p><h3 id="（4）复制上面的链接，并下载yaml文件">（4）复制上面的链接，并下载yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# wget https://cloud.weave.works/k8s/scope.yaml<br></code></pre></td></tr></table></figure><h2 id="2、修改下载的yaml文件并运行">2、修改下载的yaml文件并运行</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim scope.yaml  #编辑yaml文件<br><span class="hljs-meta">#</span><span class="bash">跳转至213行，修改其service的端口类型</span><br>    spec:<br>      type: NodePort         #修改类型为NodePort<br>      ports:<br>        - name: app<br>          port: 80<br>          protocol: TCP<br>          targetPort: 4040<br></code></pre></td></tr></table></figure><h3 id="（1）执行一下">（1）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl apply -f scope.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）查看容器的运行情况，确定处于正常运行">（2）查看容器的运行情况，确定处于正常运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get  pod -o wide -n weave<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226105456676.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226105456676.png" alt="image-20200226105456676"></a></p><ul><li><strong>DaemonSet weave-scope-agent，集群每个节点上都会运行的 scope agent 程序，负责收集数据。</strong></li><li><strong>Deployment weave-scope-app，scope 应用，从 agent 获取数据，通过 Web UI 展示并与用户交互。</strong></li><li><strong>Service weave-scope-app，默认是 ClusterIP 类型，我们已经在上面的命令中添加了参数k8s-service-type=NodePort修改为 NodePort。</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get svc -n weave<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226105545660.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226105545660.png" alt="image-20200226105545660"></a></p><blockquote><p><strong>#DaemonSet资源对象：weave-scope-agent（代理）：负责收集节点的信息；</strong><br><strong>#deployment资源对象:weave-scope-app(应用)：从agent获取数据，通过web UI展示并与用户交互；</strong><br><strong>#DaemonSet资源对象的特性和deployment相比，就是DaemonSet资源对象会在每个节点上都运行且只能运行一个pod。</strong><br><strong>#由于每个节点都需要监控，所以用到了DaemonSet这种资源对象</strong></p></blockquote><h2 id="3、浏览器访问一下http-192-168-1-21-31841">3、浏览器访问一下http://192.168.1.21:31841/</h2><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226105729990.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226105729990.png" alt="image-20200226105729990"></a></p><p><strong>在scope的web界面中，可以查看很多的东西，pod、node节点等详细信息，包括打开容器的终端，查看其日志信息等等</strong></p><h2 id="总结">总结</h2><p>• <strong>weave scope可以以其简洁的可视化为我们更生动形象的展现出service/controller/pod等资源对象的管理及简单的web ui操作，方便故障排除及时定位</strong><br>• <strong>weave scope作为web ui目前缺少登录验证，可以利用其他方式里面web服务器的验证做安全管控。</strong></p><h1>三、部署Prometheus服务</h1><p><em><strong>PS:在这里部署的prometheus,并不是Prometheus官网提供的，而是使用的coreos提供的prometheus项目。</strong></em></p><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607215313.png" alt="k8s群集的三种的Web-UI界面部署（dashboard、scope、Prometheus）"></p><h3 id="在部署之前，先来了解一下Prometheus各个组件的作用吧！"><strong>在部署之前，先来了解一下Prometheus各个组件的作用吧！</strong></h3><ul><li><strong>MetricsServer:</strong> 是k8s集群资源使用情况的聚合器，收集数据给k8s集群内使用，如kubectl,hpa,scheduler等。</li><li><strong>Prometheus Operator</strong> : 是一个系统检测和警报工具箱，用来存储监控数据。</li><li><strong>Prometheus node-exporter</strong> ：收集k8s集群资源的数据，指定告警规则。</li><li><strong>Prometheus</strong> ：收集apiserver，scheduler，controller-manager，kubelet组件的数据，通过http协议传输。</li><li><strong>Grafana:</strong> 可视化数据统计和监控平台。</li></ul><h3 id="特征">特征</h3><p><strong>Prometheus 相比于其他传统监控工具主要有以下几个特点：</strong></p><ul><li><strong>具有由 metric 名称和键/值对标识的时间序列数据的多维数据模型</strong></li><li><strong>有一个灵活的查询语言</strong></li><li><strong>不依赖分布式存储，只和本地磁盘有关</strong></li><li><strong>通过 HTTP 的服务拉取时间序列数据</strong></li><li><strong>也支持推送的方式来添加时间序列数据</strong></li><li><strong>还支持通过服务发现或静态配置发现目标</strong></li><li><strong>多种图形和仪表板支持</strong></li></ul><h2 id="1、在github上搜索coreos-prometheus">1、在github上搜索coreos/prometheus</h2><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226111843047.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226111843047.png" alt="image-20200226111843047"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226112039813.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226112039813.png" alt="img"></a></p><p><strong>复制链接</strong></p><h2 id="2、克隆github上的promethes项目">2、克隆github上的promethes项目</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master promethes]# yum -y install git<br>//下载git命令<br>[root@master promethes]# git clone  https://github.com/coreos/kube-prometheus.git<br>//克隆github上的项目<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226114748815.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226114748815.png" alt="image-20200226114748815"></a></p><h2 id="3、修改grafapa-service-yaml文件-更改为nodePort的暴露方式，暴露端口为31001-。">3、修改grafapa-service.yaml文件, 更改为nodePort的暴露方式，暴露端口为31001.。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master promethes]# cd kube-prometheus/manifests/<br>//进入kube-prometheus的manifests目录<br>[root@master manifests]# vim grafana-service.yaml    #修改grafana的yaml文件<br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  labels:<br>    app: grafana<br>  name: grafana<br>  namespace: monitoring<br>spec:<br>  type: NodePort       #改为NodePort类型<br>  ports:<br>  - name: http<br>    port: 3000<br>    targetPort: http<br>    nodePort: 31001    #映射到宿主机31001端口<br>  selector:<br>    app: grafana<br></code></pre></td></tr></table></figure><h2 id="3-修改prometheus-service-yaml文件，-更改为nodePort的暴露方式，暴露端口为31002">3.修改prometheus-service.yaml文件， 更改为nodePort的暴露方式，暴露端口为31002.</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master manifests]# vim prometheus-service.yaml    #修改prometheus的yaml文件<br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  labels:<br>    prometheus: k8s<br>  name: prometheus-k8s<br>  namespace: monitoring<br>spec:<br>  type: NodePort      #改为NodePort类型<br>  ports:<br>  - name: web<br>    port: 9090<br>    targetPort: web<br>    nodePort: 31002    #映射到宿主机31002端口<br>  selector:<br>    app: prometheus<br>    prometheus: k8s<br>  sessionAffinity: ClientIP<br></code></pre></td></tr></table></figure><h2 id="4、修改alertmanager-service-yaml文件，-更改为nodePort的暴露方式，暴露端口为31003">4、修改alertmanager-service.yaml文件， 更改为nodePort的暴露方式，暴露端口为31003</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master manifests]# vim alertmanager-service.yaml    #修改alertmanager的yaml文件<br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  labels:<br>    alertmanager: main<br>  name: alertmanager-main<br>  namespace: monitoring<br>spec:<br>  type: NodePort             #改为NodePort类型<br>  ports:<br>  - name: web<br>    port: 9093<br>    targetPort: web<br>    nodePort: 31003         #映射到宿主机31003端口<br>  selector:<br>    alertmanager: main<br>    app: alertmanager<br>  sessionAffinity: ClientIP<br></code></pre></td></tr></table></figure><h2 id="5、将setup目录中所有的yaml文件-全部运行。是运行以上yaml文件的基础环境配置。">5、将setup目录中所有的yaml文件,全部运行。是运行以上yaml文件的基础环境配置。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master manifests]# cd setup/<br>//进入setup/目录<br>[root@master manifests]# kubectl apply -f setup/<br>//运行setup目录中所有的yaml文件<br></code></pre></td></tr></table></figure><h2 id="6、将主目录-kube-prometheus-中所有的yaml文件-全部运行。">6、将主目录(kube-prometheus)中所有的yaml文件,全部运行。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master manifests]# cd ..<br>//返回上一级目录（kube-prometheus）<br>[root@master kube-prometheus]# kubectl apply -f manifests/<br>//运行kube-prometheus目录中所有的yaml文件<br></code></pre></td></tr></table></figure><h3 id="查看一下-2">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -n monitoring<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226203237647.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226203237647.png" alt="image-20200226203237647"></a></p><p><strong>部署成功之后，可以运行一条命令， 查看资源使用情况(MetricsServer必须部署成功)</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master images]# kubectl top node<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228085819377.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228085819377.png" alt="image-20200228085819377"></a></p><h2 id="7、浏览器访问一下http-192-168-1-21-31001">7、浏览器访问一下http://192.168.1.21:31001</h2><p><strong>客户端访问群集中任意节点的IP+30100端口，即可看到以下界面（默认用户名和密码都是admin）</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226203416325.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226203416325.png" alt="image-20200226203416325"></a></p><p><strong>根据提示更改密码：</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226203613578.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226203613578.png" alt="image-20200226203613578"></a></p><h3 id="（1）添加模板">（1）添加模板</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226203911457.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226203911457.png" alt="image-20200226203911457"></a></p><p><strong>依次点击“import”进行导入下面三个模板：</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204011409.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204011409.png" alt="image-20200226204011409"></a></p><h3 id="（2）进行以下点击，即可查看群集内的监控状态">（2）进行以下点击，即可查看群集内的监控状态</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204247627.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204247627.png" alt="image-20200226204247627"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204306014.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204306014.png" alt="image-20200226204306014"></a></p><p><strong>以下可看到监控状态</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204632455.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204632455.png" alt="image-20200226204632455"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204638784.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200226204638784.png" alt="image-20200226204638784"></a></p><h2 id="8、导入监控模板">8、导入监控模板</h2><p><strong>从grafana的官网搜索</strong><a href="https://grafana.com/" target="_blank" rel="noopener">https://grafana.com/</a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228093639900.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228093639900.png" alt="image-20200228093639900"></a></p><p><strong>复制以下这个模板的id</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228093854640.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228093854640.png" alt="img"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228094048611.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228094048611.png" alt="image-20200228094048611"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228094320274.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228094320274.png" alt="image-20200228094320274"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228094224276.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228094224276.png" alt="image-20200228094224276"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228094348407.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200228094348407.png" alt="image-20200228094348407"></a></p><p><strong>现在可以看到监控画面了</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;一、k8s的UI访问界面-dashboard&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;在dashboard中，虽然可以做到创建、删除、修改资源等操作，但通常情况下，我们会把它当做健康k8s集群的软件。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作为Kubernetes的We
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="dashboard" scheme="https://wsdlxgp.top/tags/dashboard/"/>
    
      <category term="weave-scope" scheme="https://wsdlxgp.top/tags/weave-scope/"/>
    
      <category term="Prometheus" scheme="https://wsdlxgp.top/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>k8s中ingress资源的应用</title>
    <link href="https://wsdlxgp.top/posts/7f86.html"/>
    <id>https://wsdlxgp.top/posts/7f86.html</id>
    <published>2020-06-07T12:10:15.059Z</published>
    <updated>2020-06-07T14:35:40.150Z</updated>
    
    <content type="html"><![CDATA[<h1>Ingress实现虚拟主机的方案</h1><h2 id="环境介绍">环境介绍</h2><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td><strong>master</strong></td><td><strong>192.168.1.21</strong></td><td><strong>k8s</strong></td></tr><tr><td><strong>node01</strong></td><td><strong>192.168.1.22</strong></td><td><strong>k8s</strong></td></tr><tr><td><strong>node02</strong></td><td><strong>192.168.1.23</strong></td><td><strong>k8s</strong></td></tr></tbody></table><p><strong>基于<a href> https://blog.51cto.com/14320361/2464655</a> 的实验继续进行</strong></p><h2 id="1、首先确定要运行ingress-nginx-controller服务。"><strong>1、首先确定要运行ingress-nginx-controller服务。</strong></h2><h3 id="在gitbub上找到所需的ingress的yaml文件">在gitbub上找到所需的ingress的yaml文件</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103818065.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103818065.png" alt="image-20200219103818065"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103248246.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103248246.png" alt="image-20200219103248246"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103252620.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103252620.png" alt="image-20200219103252620"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103537536.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103537536.png" alt="image-20200219103537536"></a></p><h3 id="4-master下载">4. master下载</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml<br></code></pre></td></tr></table></figure><h3 id="5-修改-mandatory-yaml-文件">5. 修改 mandatory.yaml 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# vim mandatory.yaml<br>      hostNetwork: true   #213<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219104346146.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219104346146.png" alt="image-20200219104346146"></a></p><h4 id="（1）执行一下">（1）执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl apply -f mandatory.yaml<br></code></pre></td></tr></table></figure><h4 id="（2）查看一下">（2）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl get pod -n ingress-nginx<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224123916253.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224123916253.png" alt="image-20200224123916253"></a></p><h2 id="2、将ingress-nginx-controller暴露为一个Service资源对象。"><strong>2、将ingress-nginx-controller暴露为一个Service资源对象。</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim service-nodeport.yaml <br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: ingress-nginx<br>  namespace: ingress-nginx<br>  labels:<br>    app.kubernetes.io/name: ingress-nginx<br>    app.kubernetes.io/part-of: ingress-nginx<br>spec:<br>  type: NodePort<br>  ports:<br>    - name: http<br>      port: 80<br>      targetPort: 80<br>      protocol: TCP<br>    - name: https<br>      port: 443<br>      targetPort: 443<br>      protocol: TCP<br>  selector:<br>    app.kubernetes.io/name: ingress-nginx<br>    app.kubernetes.io/part-of: ingress-nginx<br><br>---<br></code></pre></td></tr></table></figure><h4 id="（1）执行一下-2"><strong>（1）执行一下</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl apply -f service-nodeport.yaml<br></code></pre></td></tr></table></figure><h4 id="（2）查看一下-2"><strong>（2）查看一下</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl get svc -n ingress-nginx<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219111029408.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219111029408.png" alt="image-20200219111029408"></a></p><h2 id="3、创建一个deployment资源，和一个service资源，-并相互关联。">3、创建一个deployment资源，和一个service资源， 并相互关联。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim deploy1.yaml<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: deploy1<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx1<br>    spec:<br>      containers:<br>      - name: nginx1<br>        image: nginx<br>---<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: svc-1<br>spec:<br>  selector:<br>    app: nginx1<br>  ports:<br>    - port: 80<br>      targetPort: 80<br></code></pre></td></tr></table></figure><h4 id="执行一下">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f deploy1.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224091013907.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224091013907.png" alt="image-20200224091013907"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224091036678.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224091036678.png" alt="image-20200224091036678"></a></p><h3 id="然后复制deploy1-yaml资源工创建另外”一对“服务。">然后复制deploy1.yaml资源工创建另外”一对“服务。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim deploy2.yaml<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: deploy2<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx2<br>    spec:<br>      containers:<br>      - name: nginx2<br>        image: nginx<br>---<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: svc-2<br>spec:<br>  selector:<br>    app: nginx2<br>  ports:<br>    - port: 80<br>      targetPort: 80<br></code></pre></td></tr></table></figure><h4 id="执行一下-2">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f deploy2.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-2">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get deployments.<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224091747509.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224091747509.png" alt="image-20200224091747509"></a></p><h2 id="4-创建ingress的yaml文件，关联是svc1和svc2">4. 创建ingress的yaml文件，关联是svc1和svc2</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim ingress.yaml<br>apiVersion: extensions/v1beta1<br>kind: Ingress<br>metadata:<br>  name: ingress-1<br>spec:<br>  rules:<br>    - host: www1.bdqn.com<br>      http:<br>        paths:<br>        - path: /<br>          backend:<br>            serviceName: svc-1<br>            servicePort: 80<br>---<br>apiVersion: extensions/v1beta1<br>kind: Ingress<br>metadata:<br>  name: ingress-2<br>spec:<br>  rules:<br>    - host: www2.bdqn.com<br>      http:<br>        paths:<br>        - path: /<br>          backend:<br>            serviceName: svc-2<br>            servicePort: 80<br></code></pre></td></tr></table></figure><h4 id="执行一下-3">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f ingress.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-3">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get ingresses.<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224092438021.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224092438021.png" alt="image-20200224092438021"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe ingresses. ingress-1<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224092823654.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224092823654.png" alt="image-20200224092823654"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe ingresses. ingress-2<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224092846086.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224092846086.png" alt="image-20200224092846086"></a></p><h2 id="5、由于实验环境限制，所以自己用来模拟-一个域名。">5、由于实验环境限制，所以自己用来模拟-一个域名。</h2><h4 id="进入本机的-C-Windows-System32-drivers-etc-，-修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。">进入本机的 C:\Windows\System32\drivers\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224092744445.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224092744445.png" alt="image-20200224092744445"></a></p><h4 id="访问一下">访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get svc -n ingress-nginx <br>//查看映射的端口<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224093328158.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224093328158.png" alt="image-20200224093328158"></a></p><p><a href="http://www1.bdqn.com:30817/" target="_blank" rel="noopener">http://www1.bdqn.com:30817/</a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224094944536.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224094944536.png" alt="image-20200224094944536"></a></p><p><a href="http://www2.bdqn.com:30817/" target="_blank" rel="noopener">http://www2.bdqn.com:30817/</a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224095008674.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224095008674.png" alt="image-20200224095008674"></a></p><h4 id="总结上述示例的pod是如何一步一步可以使client访问到的，总结如下：">总结上述示例的pod是如何一步一步可以使client访问到的，总结如下：</h4><p><strong>后端pod===》service====》ingress规则====》写入Ingress-nginx-controller配置文件并自动重载使更改生效===》对本机进行域名解析====》实现client通过域名的IP+端口都可以访问到后端pod</strong></p><h1>Ingress资源实现https代理安全访问。</h1><p><strong>在上面的操作中，实现了使用ingress-nginx为后端所有pod提供一个统一的入口，那么，有一个非常严肃的问题需要考虑，就是如何为我们的pod配置CA证书来实现HTTPS访问？在pod中直接配置CA么？那需要进行多少重复性的操作？而且，pod是随时可能被kubelet杀死再创建的。当然这些问题有很多解决方法，比如直接将CA配置到镜像中，但是这样又需要很多个CA证书。</strong></p><p><strong>这里有更简便的一种方法，就拿上面的情况来说，后端有多个pod，pod与service进行关联，service又被ingress规则发现并动态写入到ingress-nginx-controller容器中，然后又为ingress-nginx-controller创建了一个Service映射到群集节点上的端口，来供client来访问。</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224143045045.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224143045045.png" alt="image-20200224143045045"></a></p><p><strong>在上面的一系列流程中，关键的点就在于ingress规则，我们只需要在ingress的yaml文件中，为域名配置CA证书即可，只要可以通过HTTPS访问到域名，至于这个域名是怎么关联到后端提供服务的pod，这就是属于k8s群集内部的通信了，即便是使用http来通信，也无伤大雅。</strong></p><h2 id="1-生成证书">1. 生成证书</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# mkdir https<br>//创建一个放置证书的目录<br>[root@master yaml]# cd https/<br>[root@master https]# openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj "/CN=testsvc /O=testsvc"<br>//生成证书<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224100716121.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224100716121.png" alt="image-20200224100716121"></a></p><h2 id="2-创建secret资源，-保存证书。">2. 创建secret资源， 保存证书。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl create secret tls tls-secret --key=tls.key --cert tls.crt<br></code></pre></td></tr></table></figure><h2 id="3、创建一个deploy3-yaml文件，模拟一个web服务。">3、创建一个deploy3.yaml文件，模拟一个web服务。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim deploy3.yaml<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: deploy3<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx3<br>    spec:<br>      containers:<br>      - name: nginx3<br>        image: nginx<br>---<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: svc-3<br>spec:<br>  selector:<br>    app: nginx3<br>  ports:<br>    - port: 80<br>      targetPort: 80<br></code></pre></td></tr></table></figure><h4 id="执行一下-4">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl apply -f deploy3.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-4">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224104212886.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224104212886.png" alt="image-20200224104212886"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224104240133.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224104240133.png" alt="image-20200224104240133"></a></p><h2 id="4、创建对应的ingress规则。">4、创建对应的ingress规则。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# vim ingress.yaml<br><br>apiVersion: extensions/v1beta1<br>kind: Ingress<br>metadata:<br>  name: ingress-3<br>spec:<br>  tls:<br>    - hosts:<br>      - www3.bdqn.com           #域名<br>      secretName: tls-secret    #保存的证书<br>  rules:<br>    - host: www3.bdqn.com<br>      http:<br>        paths:<br>        - path: /<br>          backend:<br>            serviceName: svc-3<br>            servicePort: 80<br></code></pre></td></tr></table></figure><h3 id="执行一下-5">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl apply -f ingress.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-5">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get ingresses.<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224105525215.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224105525215.png" alt="image-20200224105525215"></a></p><h2 id="5-查找对应service-nodePort的443端口映射的端口，直接用浏览器访问即可。">5.查找对应service nodePort的443端口映射的端口，直接用浏览器访问即可。</h2><h4 id="进入本机的-C-Windows-System32-drivers-etc-，-修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。-2">进入本机的 C:\Windows\System32\drivers\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224105118183.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224105118183.png" alt="image-20200224105118183"></a></p><h4 id="查看映射端口">查看映射端口</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master https]# kubectl get svc -n ingress-nginx<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224105347424.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224105347424.png" alt="image-20200224105347424"></a></p><p><a href="https://www3.bdqn.com:31372/" target="_blank" rel="noopener">https://www3.bdqn.com:31372/</a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224105409448.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200224105409448.png" alt="image-20200224105409448"></a></p><p><strong>k8s集群利用了“一切皆为资源”的原理，把生成的ca证书当成一个公共的资源来使用，使用时只需绑定保存的ca证书即可，不像之前一样，需要一个一个的创建ca证书，然后在关联起来，方便好用又快捷。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;Ingress实现虚拟主机的方案&lt;/h1&gt;
&lt;h2 id=&quot;环境介绍&quot;&gt;环境介绍&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;服务&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="ingress-nginx" scheme="https://wsdlxgp.top/tags/ingress-nginx/"/>
    
      <category term="https" scheme="https://wsdlxgp.top/tags/https/"/>
    
      <category term="ca" scheme="https://wsdlxgp.top/tags/ca/"/>
    
  </entry>
  
  <entry>
    <title>K8S的inress-nginx</title>
    <link href="https://wsdlxgp.top/posts/c92f.html"/>
    <id>https://wsdlxgp.top/posts/c92f.html</id>
    <published>2020-06-07T12:10:13.011Z</published>
    <updated>2020-06-07T14:35:40.141Z</updated>
    
    <content type="html"><![CDATA[<h1>一、Ingress 及 Ingress Controller 简介</h1><p><em><strong>Ingress简单的理解: 原先暴露的service,现在给定个统一的访问入口。</strong></em></p><p><strong>Ingress 是 k8s 资源对象，用于对外暴露服务，该资源对象定义了不同主机名（域名）及 URL 和对应后端 Service（k8s Service）的绑定，根据不同的路径路由 http 和 https 流量。而 Ingress Contoller 是一个 pod 服务，封装了一个 web 前端负载均衡器，同时在其基础上实现了动态感知 Ingress 并根据 Ingress 的定义动态生成 前端 web 负载均衡器的配置文件，比如 Nginx Ingress Controller 本质上就是一个 Nginx，只不过它能根据 Ingress 资源的定义动态生成 Nginx 的配置文件，然后动态 Reload。个人觉得 Ingress Controller 的重大作用是将前端负载均衡器和 Kubernetes 完美地结合了起来，一方面在云、容器平台下方便配置的管理，另一方面实现了集群统一的流量入口，而不是像 nodePort 那样给集群打多个孔。</strong>。</p><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607214201.png" alt="K8S的inress-nginx"></p><p><strong>所以，总的来说要使用 Ingress，得先部署 Ingress Controller 实体（相当于前端 Nginx），然后再创建 Ingress （相当于 Nginx 配置的 k8s 资源体现），Ingress Controller 部署好后会动态检测 Ingress 的创建情况生成相应配置。Ingress Controller 的实现有很多种：有基于 Nginx 的，也有基于 HAProxy的，还有基于 OpenResty 的 Kong Ingress Controller 等，更多 Controller 见：<a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/%EF%BC%8C%E6%9C%AC%E6%96%87%E4%BD%BF%E7%94%A8%E5%9F%BA%E4%BA%8E" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/，本文使用基于</a> Nginx 的 Ingress Controller：ingress-nginx。</strong></p><h1>二、Ingress 组成</h1><ul><li><strong>将Nginx的配置抽象成一个Ingress对象，每添加一个新的服务只需写一个新的Ingress的yaml文件即可</strong></li><li><strong>将新加入的Ingress转化成Nginx的配置文件并使之生效</strong></li><li><strong>ingress controller</strong></li><li><strong>ingress服务</strong></li></ul><h1>三、ingress的工作原理</h1><h2 id="ingress具体的工作原理如下"><strong>ingress具体的工作原理如下:</strong></h2><p><strong>ingress contronler通过与k8s的api进行交互，动态的去感知k8s集群中ingress服务规则的变化，然后读取它，并按照定义的ingress规则，转发到k8s集群中对应的service。</strong></p><p><strong>而这个ingress规则写明了哪个域名对应k8s集群中的哪个service，然后再根据ingress-controller中的nginx配置模板，生成一段对应的nginx配置。</strong></p><p><strong>然后再把该配置动态的写到ingress-controller的pod里，该ingress-controller的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入到nginx的配置文件中，然后reload一下，使其配置生效。以此来达到域名分配置及动态更新的效果。</strong></p><h1>四、Ingress 可以解决什么问题？</h1><h2 id="动态配置服务">动态配置服务</h2><p><strong>如果按照传统方式, 当新增加一个服务时, 我们可能需要在流量入口加一个反向代理指向我们新的k8s服务. 而如果用了Ingress, 只需要配置好这个服务, 当服务启动时, 会自动注册到Ingress的中, 不需要而外的操作.</strong></p><h2 id="减少不必要的暴露端口">减少不必要的暴露端口</h2><p><strong>配置过k8s的都清楚, 第一步是要关闭防火墙的, 主要原因是k8s的很多服务会以NodePort方式映射出去, 这样就相当于给宿主机打了很多孔, 既不安全也不优雅. 而Ingress可以避免这个问题, 除了Ingress自身服务可能需要映射出去, 其他服务都不要用NodePort方式</strong></p><h1>五、Ingress-nginx配置示例</h1><h2 id="1-创建一个web服务，用deployment资源，-用httpd镜像，然后创建一个service资源与之关联。">1) 创建一个web服务，用deployment资源， 用httpd镜像，然后创建一个service资源与之关联。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# vim deploy_1.yaml<br>apiVersion: v1<br>kind: Namespace<br>metadata:<br>  name: bdqn-ns<br>  labels:<br>    name: bdqn-ns<br>---<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: httpd-deploy<br>  namespace: bdqn-ns<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: bdqn-ns<br>    spec:<br>      containers:<br>      - name: httpd<br>        image: httpd<br>---<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: httpd-svc<br>  namespace: bdqn-ns<br>spec:<br>  type: NodePort<br>  selector:<br>    app: bdqn-ns<br>  ports:<br>  - name: http-port<br>    port: 80<br>    targetPort: 80<br>    nodePort: 31033<br></code></pre></td></tr></table></figure><h3 id="执行一下">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl apply -f deploy_1.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl get svc -n bdqn-ns<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219093450798.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219093450798.png" alt="image-20200219093450798"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl get pod -n bdqn-ns<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219093511785.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219093511785.png" alt="image-20200219093511785"></a></p><h3 id="访问一下">访问一下</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219093653692.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219093653692.png" alt="image-20200219093653692"></a></p><h2 id="2-创建一个web服务，用deployment-资源，用tomcat-8-5-45镜像。">2) 创建一个web服务，用deployment 资源，用tomcat:8.5.45镜像。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# vim deploy_2.yaml <br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: tomcat-deploy<br>  namespace: bdqn-ns<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: bdqn-tomcat<br>    spec:<br>      containers:<br>      - name: tomcat<br>        image: tomcat:8.5.45<br>---<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: tomcat-svc<br>  namespace: bdqn-ns<br>spec:<br>  type: NodePort<br>  selector:<br>    app: bdqn-tomcat<br>  ports:<br>  - name: tomcat-port<br>    port: 8080<br>    targetPort: 8080<br>    nodePort: 32033<br></code></pre></td></tr></table></figure><h3 id="执行一下-2">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl apply -f deploy_2.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-2">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl get pod -n bdqn-ns<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219094056123.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219094056123.png" alt="image-20200219094056123"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl get svc -n bdqn-ns<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219094146341.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219094146341.png" alt="image-20200219094146341"></a></p><h3 id="访问一下-2">访问一下</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219100037136.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219100037136.png" alt="image-20200219100037136"></a></p><h2 id="3-在k8s集群前边部署一个反向代理服务器，这个服务器代理这k8s集群内部的service资源。">3) 在k8s集群前边部署一个反向代理服务器，这个服务器代理这k8s集群内部的service资源。</h2><h3 id="1-Ingress"><strong>1. Ingress:</strong></h3><p><strong>（1）Ingress controller:</strong></p><p><strong>将新加入的Ingress转化为反向代理服务器的配置文件，并使之生效。(动态的感知k8s集群内Ingress资源的变化。）</strong></p><p><strong>（2）Ingress :</strong></p><p><strong>Ingress:将反向代理服务器的配置抽象成一个Ingress对象，每添加一个新的服务，只需要写一个新的Ingress的yaml文件即可。</strong></p><h3 id="2-Nginx-反向代理服务器。">2. Nginx :反向代理服务器。</h3><p><strong>需要解决了两个问题:</strong></p><p><strong>1、动态的配置服务。</strong></p><p><strong>2、减少不必要的端口暴露。</strong></p><p><strong>基于nginx的ingress controller根据不同的开发公司，又分为两种:<br>​ 1、k8s社区版的: Ingerss - nginx.<br>​ 2、nginx公司自己开发的: nginx- ingress .</strong></p><h3 id="3-在gitbub上找到所需的ingress的yaml文件">3. 在gitbub上找到所需的ingress的yaml文件</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103818065.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103818065.png" alt="image-20200219103818065"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103248246.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103248246.png" alt="image-20200219103248246"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103252620.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103252620.png" alt="image-20200219103252620"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103537536.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103537536.png" alt="image-20200219103537536"></a></p><h3 id="4-master下载">4. master下载</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml<br></code></pre></td></tr></table></figure><h3 id="5-修改-mandatory-yaml-文件">5. 修改 mandatory.yaml 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# vim mandatory.yaml<br>      hostNetwork: true   #213<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219104346146.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219104346146.png" alt="image-20200219104346146"></a></p><p><strong>---------如果ingress-controller镜像下载不成功，可以直接使用下边的镜像。</strong><br><strong>docker pull <a href="http://registry.cn-hangzhou.aliyuncs.com/ilanni/nginx-ingress-controller:0.22.0" target="_blank" rel="noopener">registry.cn-hangzhou.aliyuncs.com/ilanni/nginx-ingress-controller:0.22.0</a></strong></p><p><strong>需要注意的是，如果使用上述镜像，需要将deployment资源指定的镜像名称进行修改。</strong></p><p><strong>修改的是madatory.yaml文件里的deployment资源。</strong></p><p><strong>在deployment资源中，如果添加了此字段，意味着Pod中运行的应用可以直接使用node节点的端口，这样node节 点主机所在网络的其他主机，就可以通过访问该端口访问此应用。(类似于docker映射到宿主机 上的端口。)</strong></p><h4 id="（1）执行一下">（1）执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl apply -f mandatory.yaml<br></code></pre></td></tr></table></figure><h4 id="（2）查看一下">（2）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl get pod -n ingress-nginx<br></code></pre></td></tr></table></figure><h3 id="6-创建一个service的yaml文件">6. 创建一个service的yaml文件</h3><h4 id="（1）执行一下-2">（1）执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl apply -f mandatory.yaml<br></code></pre></td></tr></table></figure><h4 id="（2）查看一下-2">（2）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# vim mandatory-svc.yaml <br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: ingress-nginx<br>  namespace: ingress-nginx<br>spec:<br>  type: NodePort<br>  ports:<br>  - name: httpd<br>    port: 80<br>    targetPort: 80<br>  - name: https<br>    port: 443<br>  selector:<br>    app: ingress-nginx<br></code></pre></td></tr></table></figure><p><strong>（1）执行一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl apply -f mandatory-svc.yaml<br></code></pre></td></tr></table></figure><p><strong>（2）查看一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ingress]# kubectl get svc -n ingress-nginx<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219111029408.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219111029408.png" alt="image-20200219111029408"></a></p><h2 id="4）创建Ingress资源。">4）创建Ingress资源。</h2><p><strong>ingress ：</strong><br><strong>ingress-nginx-controller: 动态感知ingress 资源的变化</strong><br><strong>ingress: 创建svc与ingress-nginx-controller 关联的规则</strong></p><h3 id="（1）编写ingress的yaml文件">（1）编写ingress的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim ingress.yaml <br>apiVersion: extensions/v1beta1<br>kind: Ingress<br>metadata:<br>  name: bdqn-ingress<br>  namespace: bdqn-ns<br>  annotations:<br>    nginx.ingress.kubernetes.io/rewrite-target: /<br>spec:<br>  rules:             #规则 <br>  - host: ingress.bdqn.com   #域名<br>    http:<br>      paths:<br>      - path: /<br>        backend:<br>          serviceName: httpd-svc       #关联service<br>          servicePort: 80              #关联service的映射端口<br>      - path: /tomcat<br>        backend:<br>          serviceName: tomcat-svc      #关联service<br>          servicePort: 8080           #关联service的映射端口<br></code></pre></td></tr></table></figure><h4 id="执行一下-3">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f ingress.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-3">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -n ingress-nginx -o wide<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221094602218.png" alt="image-20200221094602218"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get ingresses. -n bdqn-ns<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221092912191.png" alt="image-20200221092912191"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe ingresses. -n bdqn-ns<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221093013134.png" alt="image-20200221093013134"></p><h4 id="进入pod查看一下">进入pod查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it -n ingress-nginx nginx-ingress-controller-5954d475b6-24k92 /bin/sh<br>/etc/nginx $ cat nginx.conf<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221094404491.png" alt="image-20200221094404491"></p><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221094408211.png" alt="image-20200221094408211"></p><h3 id="（2）访问一下">（2）访问一下</h3><h4 id="进入本机的-C-Windows-System32-drivers-etc-，-修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。"><strong>进入本机的 C:\Windows\System32\drivers\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。</strong></h4><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221103807318.png" alt="image-20200221103807318"></p><h4 id="访问http-ingress-bdqn-com">访问http://ingress.bdqn.com/</h4><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221095323635.png" alt="image-20200221095323635"></p><h4 id="访问http-ingress-bdqn-com-tomcat">访问http://ingress.bdqn.com/tomcat</h4><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221102354657.png" alt="image-20200221102354657"></p><h2 id="5）为ingress-nginx创建一个service（使用官网的service文件就可以）">5）为ingress-nginx创建一个service（使用官网的service文件就可以）</h2><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103818065.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103818065.png" alt="image-20200219103818065"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103248246.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103248246.png" alt="image-20200219103248246"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103252620.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200219103252620.png" alt="image-20200219103252620"></a></p><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221103351973.png" alt="image-20200221103351973"></p><p><em><strong>复制上面的网址</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# wget  https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/provider/baremetal/service-nodeport.yaml<br>//下载文件到master节点<br></code></pre></td></tr></table></figure><h3 id="执行一下，下载的service文件">执行一下，下载的service文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f service-nodeport.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-4">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get service -n ingress-nginx<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221103644779.png" alt="image-20200221103644779"></p><h3 id="访问一下-3">访问一下</h3><h4 id="进入本机的-C-Windows-System32-drivers-etc-，-修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。-2">进入本机的 C:\Windows\System32\drivers\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。</h4><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221103835847.png" alt="image-20200221103835847"></p><h3 id="访问http-ingress-bdqn-com-30817">访问http://ingress.bdqn.com:30817/</h3><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221103927247.png" alt="image-20200221103927247"></p><h3 id="访问http-ingress-bdqn-com-30817-tomcat">访问http://ingress.bdqn.com:30817/tomcat</h3><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221103950477.png" alt="image-20200221103950477"></p><p><strong>Service -Nodeport:因为ingress - nginx - controller运行在了集群内的其中一个节点，为了保证即使这个节点宕机，我们对应的域名仍然能够正常访问服务，所以我们将ingress -nginx- controller也暴露为一个service资源。</strong></p><h2 id="六、练习">六、练习:</h2><p><strong>创建一个deploymen资源，基于nginx镜像，repolicas：2个.然后创建一个service资源关联这个deployment资源。最后创建一个ingress资源，<a href="http://xn--svcingress-ui2pp14ahmcbv2dk27ivg4b.bdqn.com/nginx" target="_blank" rel="noopener">将上述svc关联到ingress.bdqn.com/nginx</a> 目录下。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim lianxi.yaml<br>apiVersion: v1<br>kind: Namespace<br>metadata:<br>  name: xgp-666<br>  labels:<br>    name: xgp-666<br>---<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: xgp<br>  namespace: xgp-666<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-nginx<br>    spec:<br>      containers:<br>        - name: xgp-nginx<br>          image: nginx<br>---<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: xgp-svc<br>  namespace: xgp-666<br>spec:<br>  type: NodePort<br>  selector:<br>    app: xgp-nginx<br>  ports:<br>  - name: xgp-port<br>    port: 80<br>    targetPort: 80<br>    nodePort: 30000<br>---<br>apiVersion: extensions/v1beta1<br>kind: Ingress<br>metadata:<br>  name: xgp-ingress<br>  namespace: xgp-666<br>  annotations:<br>    nginx.ingress.kubernetes.io/rewrite-target: /<br>spec:<br>  rules:<br>  - host: ingress.xgp.com<br>    http:<br>      paths:<br>      - path: /<br>        backend:<br>          serviceName: xgp-svc<br>          servicePort: 80<br></code></pre></td></tr></table></figure><h3 id="执行一下-4">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f lianxi.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-5">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe ingresses. -n xgp-666<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221112302483.png" alt="image-20200221112302483"></p><h3 id="进入本机的-C-Windows-System32-drivers-etc-，-修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。-3"><strong>进入本机的 C:\Windows\System32\drivers\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。</strong></h3><h3 id="添加完之后访问一下http-ingress-xgp-com">添加完之后访问一下http://ingress.xgp.com/</h3><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200221112416946.png" alt="image-20200221112416946"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;一、Ingress 及 Ingress Controller 简介&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Ingress简单的理解: 原先暴露的service,现在给定个统一的访问入口。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ingress 是 k8
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="nginx" scheme="https://wsdlxgp.top/tags/nginx/"/>
    
      <category term="ingress" scheme="https://wsdlxgp.top/tags/ingress/"/>
    
      <category term="ingress controller" scheme="https://wsdlxgp.top/tags/ingress-controller/"/>
    
  </entry>
  
  <entry>
    <title>k8s的Secret（密文）和configmap（明文）的使用教程</title>
    <link href="https://wsdlxgp.top/posts/a387.html"/>
    <id>https://wsdlxgp.top/posts/a387.html</id>
    <published>2020-06-07T12:10:09.562Z</published>
    <updated>2020-06-07T14:35:40.142Z</updated>
    
    <content type="html"><![CDATA[<h1>一、Secret</h1><p><em><strong>Secret :用来保存一些敏感信息，比如数据库的用户名密码或者秘钥。</strong></em></p><h2 id="概览">概览</h2><p><strong>Secret是用来保存小片敏感数据的k8s资源，例如密码，token，或者秘钥。这类数据当然也可以存放在Pod或者镜像中，但是放在Secret中是为了更方便的控制如何使用数据，并减少暴露的风险。<br>用户可以创建自己的secret，系统也会有自己的secret。<br>Pod需要先引用才能使用某个secret，Pod有2种方式来使用secret：作为volume的一个域被一个或多个容器挂载；在拉取镜像的时候被kubelet引用。</strong></p><h3 id="內建的Secrets">內建的Secrets</h3><p><strong>由ServiceAccount创建的API证书附加的秘钥<br>k8s自动生成的用来访问apiserver的Secret，所有Pod会默认使用这个Secret与apiserver通信</strong></p><h2 id="1-Secret类型">1. Secret类型</h2><p><strong>Secret有三种类型：</strong></p><ul><li><strong>Opaque：使用base64编码存储信息，可以通过base64 --decode解码获得原始数据，因此安全性弱。</strong></li><li><strong><a href="http://kubernetes.io/dockerconfigjson%EF%BC%9A%E7%94%A8%E4%BA%8E%E5%AD%98%E5%82%A8docker" target="_blank" rel="noopener">kubernetes.io/dockerconfigjson：用于存储docker</a> registry的认证信息。</strong></li><li><strong><a href="http://kubernetes.io/service-account-token%EF%BC%9A%E7%94%A8%E4%BA%8E%E8%A2%AB" target="_blank" rel="noopener">kubernetes.io/service-account-token：用于被</a> serviceaccount 引用。serviceaccout 创建时 Kubernetes 会默认创建对应的 secret。Pod 如果使用了 serviceaccount，对应的 secret 会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中</strong>。</li></ul><h2 id="举例-保存数据库的用户名和密码">举例:保存数据库的用户名和密码</h2><blockquote><p><strong>用户名：</strong> <strong>root</strong><br><strong>密码：</strong> <strong><a href="http://123.com/" target="_blank" rel="noopener">123.com</a></strong></p></blockquote><h3 id="1、通过–from-literal（文字的）">1、通过–from-literal（文字的）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl create secret generic mysecret1 --from-literal=username=root --from-literal=password=123.com<br></code></pre></td></tr></table></figure><blockquote><p><strong>generic：通用的，一般的加密方式</strong></p></blockquote><h4 id="查看一下">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl get secrets<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214100419966.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214100419966.png" alt="img"></a></p><p><strong>类型是Opaque（不透明的）</strong></p><h3 id="2、通过from-file（文件）">2、通过from-file（文件）</h3><h4 id="新建两个文件并分别写入用户名和密码">新建两个文件并分别写入用户名和密码</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# echo root &gt; username<br>[root@master secret]# echo 123.com  &gt; password<br></code></pre></td></tr></table></figure><h4 id="创建一个secret">创建一个secret</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]#  kubectl create secret generic mysecret2 --from-file=username --from-file=password<br></code></pre></td></tr></table></figure><h4 id="查看一下-2">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl get secrets<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214103506842.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214103506842.png" alt="image-20200214103506842"></a></p><h3 id="3、通过-from-env-file">3、通过-- from- env-file:</h3><h4 id="创建一个文件写入用户名和密码">创建一个文件写入用户名和密码</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]#vim env.txt <br>username=root<br>password=123.com<br></code></pre></td></tr></table></figure><h4 id="创建一个secret-2">创建一个secret</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl create secret generic mysecret3 --from-env-file=env.txt<br></code></pre></td></tr></table></figure><h4 id="查看一下-3">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl get secrets<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214103905956.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214103905956.png" alt="image-20200214103905956"></a></p><h3 id="4、通过yaml配置文件">4、通过yaml配置文件</h3><h4 id="（1）把需要保存的数据加密（”base64“的方式）">（1）把需要保存的数据加密（”base64“的方式）</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# echo root | base64<br>cm9vdAo=<br>[root@master secret]# echo 123.com | base64<br>MTIzLmNvbQo=<br></code></pre></td></tr></table></figure><blockquote><p><strong>解码：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# echo -n cm9vdAo | base64 --decode <br>root<br>[root@master secret]# echo -n MTIzLmNvbQo | base64 --decode <br>123.com<br></code></pre></td></tr></table></figure></blockquote><h4 id="（2）编写secre4的yaml文件">（2）编写secre4的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# vim secret4.yaml<br>apiVersion: v1<br>kind: Secret<br>metadata:<br>  name: mysecret4<br>data:<br>  username: cm9vdAo=<br>  password: MTIzLmNvbQo=<br></code></pre></td></tr></table></figure><h5 id="执行一下">执行一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl apply -f secret4.yaml<br></code></pre></td></tr></table></figure><h4 id="（3）查看一下">（3）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl get secrets<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214104544899.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214104544899.png" alt="image-20200214104544899"></a></p><h2 id="如果来使用Secret资源">如果来使用Secret资源</h2><h3 id="1-以Volume挂载的方式">1. 以Volume挂载的方式</h3><h3 id="使用Secret">使用Secret</h3><p><strong>secret可以作为数据卷挂载或者作为环境变量暴露给Pod中的容器使用，也可以被系统中的其他资源使用。比如可以用secret导入与外部系统交互需要的证书文件等。</strong></p><p><strong>在Pod中以文件的形式使用secret</strong></p><blockquote><ol><li><strong>创建一个Secret，多个Pod可以引用同一个Secret</strong></li><li><strong>修改Pod的定义，在spec.volumes[]加一个volume，给这个volume起个名字，spec.volumes[].secret.secretName记录的是要引用的Secret名字</strong></li><li><strong>在每个需要使用Secret的容器中添加一项spec.containers[].volumeMounts[]，指定spec.containers[].volumeMounts[].readOnly = true，spec.containers[].volumeMounts[].mountPath要指向一个未被使用的系统路径。</strong></li><li><strong>修改镜像或者命令行使系统可以找到上一步指定的路径。此时Secret中data字段的每一个key都是指定路径下面的一个文件名</strong></li></ol></blockquote><h4 id="编写pod的yaml文件"><strong>编写pod的yaml文件</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# vim pod.yaml <br><br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: mypod<br>spec:<br>  containers:<br>  - name: mypod<br>    image: busybox<br>    args:<br>      - /bin/sh<br>      - -c<br>      - sleep 300000<br>    volumeMounts:<br>    - name: secret-test<br>      mountPath: "/etc/secret-test"  #pod中的路径<br>      readOnly: true                 #是否只读<br>  volumes:<br>  - name: secret-test<br>    secret:<br>      secretName: mysecret1<br></code></pre></td></tr></table></figure><p><strong>还可以自定义存放数据的文件名</strong></p><h4 id="执行一下-2">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h3 id="Secret文件权限">Secret文件权限</h3><p><strong>可以指定secret文件的权限，类似linux系统文件权限，如果不指定默认权限是0644，等同于linux文件的-rw-r–r--权限</strong></p><h4 id="进入容器查看保存的数据">进入容器查看保存的数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl exec -it mypod /bin/sh<br>/ # cd /etc/secret-test/<br>/etc/secret-test # ls<br>pasword   username<br>/etc/secret-test # cat username <br>root<br>/etc/secret-test # cat pasword <br>123.com<br></code></pre></td></tr></table></figure><h4 id="测试是否有只读权限">测试是否有只读权限</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">123.com/etc/secret-test # echo admin &gt; username<br>/bin/sh: can't create username: Read-only file system<br></code></pre></td></tr></table></figure><h3 id="1-1-自定义存放数据的文件名的yaml文件">1.1 自定义存放数据的文件名的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]#  vim pod.yaml <br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: mypod<br>spec:<br>  containers:<br>  - name: mypod<br>    image: busybox<br>    args:<br>      - /bin/sh<br>      - -c<br>      - sleep 300000<br>    volumeMounts:<br>    - name: secret-test<br>      mountPath: "/etc/secret-test"  #pod中的路径<br>      readOnly: true                 #是否只读<br>  volumes:<br>  - name: secret-test<br>    secret:<br>      secretName: mysecret1<br>      items:<br>      - key: username<br>        path: my-group/my-username   #自定义的容器中的目录<br>      - key: password<br>        path: my-group/my-password   #自定义的容器中的目录<br></code></pre></td></tr></table></figure><h4 id="执行一下-3">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-4">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl exec -it mypod /bin/sh<br>//进入容器查看<br><span class="hljs-meta"> #</span><span class="bash"> cat /etc/secret-test/my-group/my-password </span><br>123.com <br><span class="hljs-meta"> #</span><span class="bash"> cat /etc/secret-test/my-group/my-username </span><br>root<br></code></pre></td></tr></table></figure><h3 id="1-2-如果，现在将secret资源内保存的数据进行更新，请问，使用此数据的应用内，数据是是否也会更新">1.2 如果，现在将secret资源内保存的数据进行更新，请问，使用此数据的应用内，数据是是否也会更新?</h3><p><strong>会实时更新(这里引用数据，是以volumes挂 载使用数据的方式)。</strong></p><p><strong>更新mysecret1的数据: password —&gt; admin YWRtaW4K (base64)</strong></p><p><strong>可以通过edit 命令，直接修改。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl edit secrets mysecret1<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217162834490.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217162834490.png" alt="image-20200217162834490"></a></p><h4 id="查看一下-5">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl exec -it mypod /bin/sh<br>//进入容器查看<br><span class="hljs-meta"> #</span><span class="bash"> cat /etc/secret-test/my-group/my-password </span><br>admin<br><span class="hljs-meta"> #</span><span class="bash"> cat /etc/secret-test/my-group/my-username </span><br>root<br></code></pre></td></tr></table></figure><p><em><strong>数据已经成功更新了</strong></em></p><h3 id="2、以环境变量的方式">2、以环境变量的方式</h3><blockquote><p><strong>创建一个Secret，多个Pod可以引用同一个Secret</strong><br><strong>修改pod的定义，定义环境变量并使用env[].valueFrom.secretKeyRef指定secret和相应的key</strong><br><strong>修改镜像或命令行，让它们可以读到环境变量</strong></p></blockquote><p><strong>编写pod的yaml文件</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# vim pod-env.yaml <br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: mypod2<br>spec:<br>  containers:<br>  - name: mypod<br>    image: busybox<br>    args:<br>      - /bin/sh<br>      - -c<br>      - sleep 300000<br>    env:<br>      - name: SECRET_USERNAME<br>        valueFrom:<br>          secretKeyRef:<br>            name: mysecret2<br>            key: username<br>      - name: SECRET_PASSWORD<br>        valueFrom:<br>          secretKeyRef:<br>            name: mysecret2<br>            key: password<br></code></pre></td></tr></table></figure><h4 id="执行一下-4">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl apply -f pod-env.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-6">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214111931566.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200214111931566.png" alt="image-20200214111931566"></a></p><h4 id="进入容器查看保存的数据-2">进入容器查看保存的数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl exec -it mypod2 /bin/sh<br>/ # echo $SECRET_USERNAME<br>root<br>/ # echo $SECRET_PASSWORD<br>123.com<br></code></pre></td></tr></table></figure><h3 id="2-1-更新sevret文件的内容">2.1 更新sevret文件的内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl edit secrets mysecret2<br>//修改保存文件的内容<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217162834490.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217162834490.png" alt="image-20200217162834490"></a></p><h4 id="查看一下-7">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master secret]# kubectl exec -it mypod2 /bin/sh<br>/ # echo $SECRET_USERNAME<br>root<br>/ # echo $SECRET_PASSWORD<br>123.com<br></code></pre></td></tr></table></figure><p><em><strong>等待了一定时间后，可以看到这个数据并没有没有改变</strong></em></p><h2 id="总结">总结</h2><p><strong>如果引用secret数据的应用， 要求会随着secret资源对象内保存的数据的更新，而实时更新，那么应该使用volumes挂载的方式引用资源因为用环境变量的方式引用不会实时更新数据。</strong></p><h1>二、ConfigMap</h1><p><strong>和Secret资源类似，不同之处在于，secret 资源保存的是敏感信息，而Configmap保存的是以明文方式存放的数据。</strong></p><p><strong>Configmap的创建与使用方式与Secret非常类似，不同点只在于数据以明文形式存放（不过，我觉得Secret的密文形式也并不密文，只能算得上是简单编码）。</strong></p><p><strong>和Secret资源类似，不同之处在于，secret 资源保存的是敏感信息，而Configmap保存的是以明文方式存放的数据。</strong><br><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607213735.png" alt="k8s的Secret（密文）和configmap（明文）的使用教程"></p><blockquote><p><strong>username：adam</strong></p><p><strong>age：18</strong></p></blockquote><h2 id="创建的四种方式">创建的四种方式</h2><h3 id="1、通过-from-literal-文字的">1、通过-- from- literal(文字的):</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl create configmap myconfigmap1 --from-literal=username=adam --from-literal=age=18<br></code></pre></td></tr></table></figure><h4 id="查看一下-8">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get cm<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217103048235.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217103048235.png" alt="image-20200217103048235"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe cm<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217103123130.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217103123130.png" alt="image-20200217103123130"></a></p><h3 id="2、通过–from-file-文件">2、通过–from-file (文件) :</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# echo adam &gt; username<br>[root@master yaml]# echo 18 &gt; age<br></code></pre></td></tr></table></figure><h4 id="创建">创建</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl create configmap myconfigmap2 --from-file=username --from-file=age<br></code></pre></td></tr></table></figure><h4 id="查看一下-9">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe cm<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217103509006.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217103509006.png" alt="image-20200217103509006"></a></p><h3 id="3、通过–from-env-file">3、通过–from- env-file:</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim env.txt <br>username=adam<br>age=18<br></code></pre></td></tr></table></figure><h4 id="创建-2">创建</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl create configmap  myconfigmap3 --from-env-file=env.txt<br></code></pre></td></tr></table></figure><h4 id="查看一下-10">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl describe cm<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217165039190.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217165039190.png" alt="image-20200217165039190"></a></p><h3 id="4、通过yaml配置文件-2">4、通过yaml配置文件:</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim configmap.yaml<br>apiVersion: v1<br>kind: ConfigMap<br>metadata:<br>  name: myconfigmap4<br>data:<br>  username: 'adam'<br>  age: '18'<br></code></pre></td></tr></table></figure><h4 id="创建-3">创建</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f configmap.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-11">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe cm<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217104428521.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217104428521.png" alt="image-20200217104428521"></a></p><h2 id="如何来使用configmap资源">如何来使用configmap资源</h2><h3 id="1-以Volume挂载的方式-2">1. 以Volume挂载的方式</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim v-pod.yaml <br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: pod1<br>spec:<br>  containers:<br>  - name: mypod<br>    image: busybox<br>    args:<br>      - /bin/sh<br>      - -c<br>      - sleep 300000<br>    volumeMounts:<br>    - name: cmp-test<br>      mountPath: "/etc/cmp-test"<br>      readOnly: true<br>    volumes:<br>  - name: cmp-test<br>    configMap:<br>      name: myconfigmap1<br></code></pre></td></tr></table></figure><h4 id="执行一下-5">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl apply -f v-pod.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-12">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl exec -it pod1 /bin/sh<br>//进入容器查看一下<br><span class="hljs-meta"> #</span><span class="bash"> cat /etc/cmp-test/age </span><br>18/ <br><span class="hljs-meta"> #</span><span class="bash"> cat /etc/cmp-test/username </span><br>adam/<br></code></pre></td></tr></table></figure><h3 id="1-1-自定义存放数据的文件名的yaml文件-2">1.1 自定义存放数据的文件名的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# vim v-pod2.yaml <br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: pod3<br>spec:<br>  containers:<br>  - name: mypod<br>    image: busybox<br>    args:<br>      - /bin/sh<br>      - -c<br>      - sleep 300000<br>    volumeMounts:<br>    - name: cmp-test<br>      mountPath: "/etc/cmp-test"<br>      readOnly: true<br>    volumes:<br>  - name: cmp-test<br>    configMap:<br>      name: myconfigmap1<br>      items:<br>      - key: username<br>        path: my-group/my-username   #自定义的容器中的目录<br>      - key: age<br>        path: my-group/my-age   #自定义的容器中的目录<br></code></pre></td></tr></table></figure><h4 id="执行一下-6">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl apply -f v-pod2.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-13">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl exec -it pod3 /bin/sh<br>//进入容器查看<br><span class="hljs-meta">#</span><span class="bash"> cat /etc/cmp-test/my-group/my-username </span><br>adam/ <br><span class="hljs-meta">#</span><span class="bash"> cat /etc/cmp-test/my-group/my-age </span><br>18/<br></code></pre></td></tr></table></figure><h3 id="1-2-如果，现在将secret资源内保存的数据进行更新，请问，使用此数据的应用内，数据是是否也会更新-2">1.2 如果，现在将secret资源内保存的数据进行更新，请问，使用此数据的应用内，数据是是否也会更新?</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl edit cm myconfigmap1<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217172107999.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217172107999.png" alt="image-20200217172107999"></a></p><h4 id="查看一下-14">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl exec -it pod3 /bin/sh<br>//进入容器查看<br><span class="hljs-meta">#</span><span class="bash"> cat /etc/cmp-test/my-group/my-username </span><br>adam/ <br><span class="hljs-meta">#</span><span class="bash"> cat /etc/cmp-test/my-group/my-age </span><br>10<br></code></pre></td></tr></table></figure><p><em><strong>可以看到更新成功</strong></em></p><h3 id="2-以环境变量的方式">2.以环境变量的方式</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# vim e-pod.yaml <br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: pod2<br>spec:<br>  containers:<br>  - name: mypod<br>    image: busybox<br>    args:<br>      - /bin/sh<br>      - -c<br>      - sleep 300000<br>    env:<br>      - name: CONFIGMAP_NAME<br>        valueFrom:<br>          configMapKeyRef:<br>            name: myconfigmap2<br>            key: username<br>      - name: CONFIGMAP_AGE<br>        valueFrom:<br>          configMapKeyRef:<br>            name: myconfigmap2<br>            key: age<br></code></pre></td></tr></table></figure><h4 id="执行一下-7">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl apply -f e-pod.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-15">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl exec -it pod2 /bin/sh<br>//进入容器查看一下<br><span class="hljs-meta"> #</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$CONFIGMAP_NAME</span></span><br>adam<br><span class="hljs-meta"> #</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$CONFIGMAP_AGE</span></span><br>18<br></code></pre></td></tr></table></figure><h3 id="2-1-更新sevret文件的内容-2">2.1 更新sevret文件的内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl edit cm myconfigmap2<br> //修改保存文件的内容<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217172701793.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200217172701793.png" alt="image-20200217172701793"></a></p><h4 id="查看一下-16">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master configmap]# kubectl exec -it pod2 /bin/sh<br>//进入容器查看一下<br><span class="hljs-meta"> #</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$CONFIGMAP_NAME</span></span><br>adam<br><span class="hljs-meta"> #</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$CONFIGMAP_AGE</span></span><br>18<br></code></pre></td></tr></table></figure><p><em><strong>等待了一定时间后，可以看到这个数据并没有没有改变</strong></em></p><p><strong>可以看出这个configmap和secret的更新效果基本没有区别。</strong></p><h2 id="总结configmap、与secret资源有什么相同和不同之处。"><strong>总结configmap、与secret资源有什么相同和不同之处。</strong></h2><h3 id="Secret-与-ConfigMap-对比">Secret 与 ConfigMap 对比</h3><p><strong>相同点：</strong></p><blockquote><p><strong>key/value的形式</strong></p><p><strong>属于某个特定的namespace</strong></p><p><strong>可以导出到环境变量</strong></p><p><strong>可以通过目录/文件形式挂载</strong></p><p><strong>通过 volume 挂载的配置信息均可热更新</strong></p></blockquote><p><strong>不同点：</strong></p><blockquote><p><strong>Secret 可以被 ServerAccount 关联</strong></p><p><strong>Secret 可以存储 docker register 的鉴权信息，用在 ImagePullSecret 参数中，用于拉取私有仓库的镜像</strong></p><p><strong>Secret 支持 Base64 加密</strong></p><p><strong>Secret 分为 <a href="https://kubernetes.io/service-account-token%E3%80%81kubernetes.io/dockerconfigjson%E3%80%81Opaque" target="_blank" rel="noopener">kubernetes.io/service-account-token、kubernetes.io/dockerconfigjson、Opaque</a> 三种类型，而 Configmap 不区分类型</strong></p></blockquote><h2 id="总结以volumes挂载、和环境变量方式引用资源的相同和不同之处。">总结以volumes挂载、和环境变量方式引用资源的相同和不同之处。</h2><p><strong>volumes挂载(可根据更改数据更新)：引用自己创建的secret（密文）或configmap（明文），挂载到容器中指定的目录下。查看保存的文件时，根据自己所填路径和secret或configmap创建的文件，进行查看。</strong></p><p><strong>环境变量(不因更改数据更新)：引用自己创建的secret（密文）或configmap（明文），挂载到容器中指定的目录下。查看保存的文件时，根据自己环境变量，进行查看。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;一、Secret&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Secret :用来保存一些敏感信息，比如数据库的用户名密码或者秘钥。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;概览&quot;&gt;概览&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Secret是用来保存小片敏感数据的k8s资
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="secret" scheme="https://wsdlxgp.top/tags/secret/"/>
    
      <category term="pod" scheme="https://wsdlxgp.top/tags/pod/"/>
    
      <category term="configmap" scheme="https://wsdlxgp.top/tags/configmap/"/>
    
  </entry>
  
  <entry>
    <title>k8s的StatefulSet（有状态服务）实现</title>
    <link href="https://wsdlxgp.top/posts/af4b.html"/>
    <id>https://wsdlxgp.top/posts/af4b.html</id>
    <published>2020-06-07T12:10:07.542Z</published>
    <updated>2020-06-07T14:35:40.137Z</updated>
    
    <content type="html"><![CDATA[<h1>StatefulSet介绍</h1><h3 id="遇到的问题：">遇到的问题：</h3><p><strong>使用Deployment创建的Pod是无状态的，当挂在Volume之后，如果该Pod挂了，Replication Controller会再run一个来保证可用性，但是由于是无状态的，Pod挂了的时候与之前的Volume的关系就已经断开了，新起来的Pod无法找到之前的Pod。但是对于用户而言，他们对底层的Pod挂了没有感知，但是当Pod挂了之后就无法再使用之前挂载的磁盘了。</strong></p><h4 id="StatefulSet-是一种给Pod提供唯一标志的控制器，它可以保证部署和扩展的顺序。"><strong>StatefulSet: 是一种给Pod提供唯一标志的控制器，它可以保证部署和扩展的顺序。</strong></h4><blockquote><p><strong>Pod一致性：包含次序（启动、停止次序）、网络一致性。此一致性与Pod相关，与被调度到哪个node节点无关。</strong></p><p><strong>稳定的次序：对于N个副本的StatefulSet，每个Pod都在[0，N)的范围内分配一个数字序号，且是唯一的。</strong></p><p><strong>稳定的网络：Pod的hostname模式为(statefulset名称)- (序号)。</strong></p><p><strong>稳定的存储：通过VolumeClaimTemplate为每个Pod创建一个PV。删除、减少副本，不会删除相关的卷。</strong></p></blockquote><h4 id="1-RC、-RS、Deployment、DS。-无状态服务"><strong>(1) RC、 RS、Deployment、DS。-----&gt; 无状态服务</strong></h4><blockquote><p><strong>template(模板):根据模板 创建出来的Pod,它们J的状态都是一模一样的(除了名称，IP, 域名之外)</strong></p><p><strong>可以理解为:任何一个Pod, 都可以被删除，然后用新生成的Pod进行替换。</strong></p></blockquote><h4 id="2-有状态的服务-需要记录前一-次或者多次通信中的相关事件，以作为一下通信的分类标准。比如-mysql等数据库服务。-Pod的名称，不能随意变化。数据持久化的目录也是不一样，每一个Pod都有自己独有的数据持久化存储目录。"><strong>(2) 有状态的服务: 需要记录前一 次或者多次通信中的相关事件，以作为一下通信的分类标准。比如: mysql等数据库服务。(Pod的名称，不能随意变化。数据持久化的目录也是不一样，每一个Pod都有自己独有的数据持久化存储目录。)</strong></h4><blockquote><p><strong>mysql:主从关系。</strong></p></blockquote><p><strong>如果把之前无状态的服务比喻为牛、羊等牲畜，因为，这些到一定时候就可以出售。那么，有状态就比喻为:宠物，而宠物不像牲畜一样到达一定时候出售，人们往往会照顾宠物的一生。</strong></p><h4 id="3-每一个Pod-对应一个PVC-每一个PVC对应一个PV。"><strong>(3) 每一个Pod----&gt;对应一个PVC----&gt;每一个PVC对应一个PV。</strong></h4><blockquote><p><strong>storageclass:自动创建PV</strong></p><p><strong>需要解决:自动创建PVC。</strong></p></blockquote><h1>实现原理</h1><p><strong>与 ReplicaSet 和 Deployment 资源一样，StatefulSet 也使用控制器的方式实现，它主要由 StatefulSetController、StatefulSetControl 和 StatefulPodControl 三个组件协作来完成 StatefulSet 的管理，StatefulSetController 会同时从 PodInformer 和 ReplicaSetInformer 中接受增删改事件并将事件推送到队列中：</strong><br><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607212629.png" alt="k8s的StatefulSet（有状态服务）实现"><br><strong>控制器 StatefulSetController 会在 Run 方法中启动多个 Goroutine 协程，这些协程会从队列中获取待处理的 StatefulSet 资源进行同步，接下来我们会先介绍 Kubernetes 同步 StatefulSet 的过程。</strong></p><h2 id="1，例子">1，例子</h2><h3 id="（1）创建一个statefulset的yaml文件">（1）创建一个statefulset的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim statefulset.yaml<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: headless-svc<br>  labels:<br>    app: headless-svc<br>spec:<br>  ports:<br>  - port: 80<br>  selector:<br>    app: headless-pod<br>  clusterIP: None     #没有同一的ip<br>---<br>apiVersion: apps/v1<br>kind: StatefulSet<br>metadata:<br>  name: statefulset-test<br>spec:<br>  serviceName: headless-svc<br>  replicas: 3<br>  selector:<br>    matchLabels:<br>      app: headless-pod<br>  template:<br>    metadata:<br>      labels:<br>        app: headless-pod<br>    spec:<br>      containers:<br>      - name: myhttpd<br>        image: httpd<br>        ports:<br>        - containerPort: 80<br></code></pre></td></tr></table></figure><p><strong>Deployment : Deploy+RS+随机字符串(Pod的名称。)没有顺序的，可</strong><br><strong>以没随意替代的。</strong></p><blockquote><p><strong>1、headless-svc :无头服务。因为没有IP地址，所以它不具备负载均衡的功能了。因为statefulset要求Pod的名称是有顺序的，每一个Pod都不能被随意取代，也就是即使Pod重建之后，名称依然不变。为后端的每一个Pod去命名。</strong></p><p><strong>2、statefulSet:定义具体的应用</strong></p><p><strong>3、volumeClaimT emplates:自动创建PVC，为后端的Pod提供专有的存储。</strong></p></blockquote><h3 id="执行一下">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f statefulset.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212100101082.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212100101082.png" alt="image-20200212100101082"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br>//可看到这些pod是有顺序的<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212102001181.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212102001181.png" alt="image-20200212102001181"></a></p><h1>一、创建StorageClass资源对象。</h1><h2 id="1、基于NFS服务，创建NFS服务。">1、基于NFS服务，创建NFS服务。</h2><p><strong>下载nfs所需安装包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node02 ~]# yum -y install nfs-utils  rpcbind<br></code></pre></td></tr></table></figure><p><strong>创建共享目录</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# mkdir /nfsdata<br></code></pre></td></tr></table></figure><p><strong>创建共享目录的权限</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim /etc/exports<br>/nfsdata *(rw,sync,no_root_squash)<br></code></pre></td></tr></table></figure><p><strong>开启nfs和rpcbind</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# systemctl start nfs-server.service <br>[root@master ~]# systemctl start rpcbind<br></code></pre></td></tr></table></figure><p><strong>测试一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# showmount -e<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205105654925.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205105654925.png" alt="image-20200205105654925"></a></p><h2 id="2、创建rbac权限。">2、创建rbac权限。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim rbac-rolebind.yaml <br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: nfs-provisioner<br>  namespace: default<br>---<br>apiVersion: rbac.authorization.k8s.io/v1<br>kind: ClusterRole<br>metadata:<br>  name: nfs-provisioner-runner<br>  namespace: default<br>rules:<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumes"]<br>      verbs: ["get", "list", "watch", "create", "delete"]<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumeclaims"]<br>      verbs: ["get", "list", "watch", "update"]<br>   -  apiGroups: ["storage.k8s.io"]<br>      resources: ["storageclasses"]<br>      verbs: ["get", "list", "watch"]<br>   -  apiGroups: [""]<br>      resources: ["events"]<br>      verbs: ["watch", "create", "update", "patch"]<br>   -  apiGroups: [""]<br>      resources: ["services", "endpoints"]<br>      verbs: ["get","create","list", "watch","update"]<br>   -  apiGroups: ["extensions"]<br>      resources: ["podsecuritypolicies"]<br>      resourceNames: ["nfs-provisioner"]<br>      verbs: ["use"]<br>---<br>kind: ClusterRoleBinding<br>apiVersion: rbac.authorization.k8s.io/v1<br>metadata:<br>  name: run-nfs-provisioner<br>subjects:<br>  - kind: ServiceAccount<br>    name: nfs-provisioner<br>    namespace: default        #必写字段<br>roleRef:<br>  kind: ClusterRole<br>  name: nfs-provisioner-runner<br>  apiGroup: rbac.authorization.k8s.io<br></code></pre></td></tr></table></figure><h3 id="执行一下-2">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f rbac-rolebind.yaml<br></code></pre></td></tr></table></figure><h2 id="3、创建Deployment资源对象，用Pod代替-真正的NFS服务。">3、创建Deployment资源对象，用Pod代替 真正的NFS服务。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nfs-deployment.yaml <br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nfs-client-provisioner<br>spec:<br>  replicas: 1<br>  strategy:<br>    type: Recreate<br>  template:<br>    metadata:<br>      labels:<br>        app: nfs-client-provisioner<br>    spec:<br>      serviceAccount: nfs-provisioner<br>      containers:<br>        - name: nfs-client-provisioner<br>          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner<br>          volumeMounts:<br>            - name: nfs-client-root<br>              mountPath:  /persistentvolumes<br>          env:<br>            - name: PROVISIONER_NAME<br>              value: bdqn<br>            - name: NFS_SERVER<br>              value: 192.168.1.21<br>            - name: NFS_PATH<br>              value: /nfsdata<br>      volumes:<br>        - name: nfs-client-root<br>          nfs:<br>            server: 192.168.1.21<br>            path: /nfsdata<br></code></pre></td></tr></table></figure><h3 id="执行一下-3">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-deployment.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-2">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212104037272.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212104037272.png" alt="image-20200212104037272"></a></p><h2 id="4、创建storageclass的yaml文件">4、创建storageclass的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim test-storageclass.yaml <br>apiVersion: storage.k8s.io/v1<br>kind: StorageClass<br>metadata:<br>  name: stateful-nfs<br>provisioner: bdqn  #通过provisioner字段关联到上述Deploy<br>reclaimPolicy: Retain<br></code></pre></td></tr></table></figure><h3 id="执行一下-4">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f test-storageclass.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-3">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get sc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212104551911.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212104551911.png" alt="image-20200212104551911"></a></p><h1>二，解决自动创建pvc</h1><h2 id="1、创建statefulset的yaml文件">1、创建statefulset的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim statefulset.yaml <br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: headless-svc<br>  labels:<br>    app: headless-svc<br>spec:<br>  ports:<br>  - port: 80<br>    name: myweb<br>  selector:<br>    app: headless-pod<br>  clusterIP: None<br>---<br>apiVersion: apps/v1<br>kind: StatefulSet<br>metadata:<br>  name: statefulset-test<br>spec:<br>  serviceName: headless-svc<br>  replicas: 3<br>  selector:<br>    matchLabels:<br>      app: headless-pod<br>  template:<br>    metadata:<br>      labels:<br>        app: headless-pod<br>    spec:<br>      containers:<br>      - image: httpd<br>        name: myhttpd<br>        ports:<br>        - containerPort: 80<br>          name: httpd<br>        volumeMounts:<br>        - mountPath: /mnt<br>          name: test<br>  volumeClaimTemplates:  #&gt; 自动创建PVC，为后端的Pod提供专有的存储。**<br>  - metadata:<br>      name: test<br>      annotations:   #这是指定storageclass<br>        volume.beta.kubernetes.io/storage-class: stateful-nfs<br>    spec:<br>      accessModes:<br>        - ReadWriteOnce<br>      resources:<br>        requests:<br>          storage: 100Mi<br></code></pre></td></tr></table></figure><p><strong>在此示例中：</strong></p><ul><li><strong>创建了一个名为 <code>headless-svc</code> 的 <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/service?hl=zh-cn" target="_blank" rel="noopener">Service</a> 对象，由 <code>metadata: name</code> 字段指示。该 Service 会定位一个名为 <code>headless-svc</code> 的应用，由 <code>labels: app: headless-svc</code> 和 <code>selector: app: headless-pod</code> 指示。该 Service 会公开端口 80 并将其命名为 <code>web</code>。而且该 Service 会控制网域并将互联网流量路由到 StatefulSet 部署的容器化应用。</strong></li><li><strong>使用三个副本 Pod (<code>replicas: 3</code>) 创建了一个名为 <code>web</code> 的 StatefulSet。</strong></li><li><strong>Pod 模板 (<code>spec: template</code>) 指示其 Pod 标记为 <code>app: headless-pod</code>。</strong></li><li><strong>Pod 规范 (<code>template: spec</code>) 指示 StatefulSet 的 Pod 运行一个容器 <code>myhttpd</code>，该容器运行版本为 <code>httpd</code> 映像。容器映像由 <a href="https://cloud.google.com/container-registry/docs/concepts/overview?hl=zh-cn" target="_blank" rel="noopener">Container Registry</a> 托管。</strong></li><li><strong>Pod 规范使用由 Service 打开的 <code>web</code> 端口。</strong></li><li><strong><code>template: spec: volumeMounts</code> 指定一个名为 <code>test</code> 的 <code>mountPath</code>。<code>mountPath</code> 是容器中应装载存储卷的路径。</strong></li><li><strong>StatefulSet 预配了一个具有 100mb 预配存储空间的 <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/persistent-volumes?hl=zh-cn" target="_blank" rel="noopener">PersistentVolumeClaim</a>：<code>test</code>。</strong></li></ul><h3 id="执行一下-5">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f statefulset.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-4">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212105434510.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212105434510.png" alt="image-20200212105434510"></a></p><p><em><strong>如果第一个pod出现了问题，后面的pod就不会生成。</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get statefulsets<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212105502430.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212105502430.png" alt="image-20200212105502430"></a></p><h2 id="2、-验证一下数据存储">2、 验证一下数据存储</h2><h4 id="容器中创建文件">容器中创建文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it statefulset-test-0 /bin/sh<br><span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">cd</span> /mnt</span><br><span class="hljs-meta">#</span><span class="bash"> touch testfile</span><br><span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">exit</span></span><br></code></pre></td></tr></table></figure><h4 id="宿主机查看一下">宿主机查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# ls /nfsdata/default-test-statefulset-test-0-pvc-bf1ae1d0-f496-4d69-b33b-39e8aa0a6e8d/<br>testfile<br></code></pre></td></tr></table></figure><h1>三、小实验</h1><p><strong>以自己的名称创建一个名称空间，以下所有资源都运行在此空间中。用statefuset资源运行一个httpd web服务，要求3个Pod，但是每个Pod的主界面内容不一样，并且都要做专有的数据持久化，尝试删除其中一个Pod，查看新生成的Pod，总结对比与之前Deployment资源控制器控制的Pod有什么不同之处？</strong></p><h2 id="（一）创建StorageClass资源对象。">（一）创建StorageClass资源对象。</h2><p><em><strong>注意：nfs服务要开启</strong></em></p><h3 id="1、创建namespace的yaml文件">1、创建namespace的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim namespace.yaml <br>kind: Namespace<br>apiVersion: v1<br>metadata:<br>  name: xgp-lll    #namespave的名称<br></code></pre></td></tr></table></figure><h4 id="执行一下-6">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f namespace.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-5">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get namespaces<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212113542729.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212113542729.png" alt="image-20200212113542729"></a></p><h3 id="2-创建rbac权限。">2. 创建rbac权限。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim rbac-rolebind.yaml<br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: nfs-provisioner<br>  namespace: xgp-lll<br>---<br>apiVersion: rbac.authorization.k8s.io/v1<br>kind: ClusterRole<br>metadata:<br>  name: nfs-provisioner-runner<br>  namespace: xgp-lll<br>rules:<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumes"]<br>      verbs: ["get", "list", "watch", "create", "delete"]<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumeclaims"]<br>      verbs: ["get", "list", "watch", "update"]<br>   -  apiGroups: ["storage.k8s.io"]<br>      resources: ["storageclasses"]<br>      verbs: ["get", "list", "watch"]<br>   -  apiGroups: [""]<br>      resources: ["events"]<br>      verbs: ["watch", "create", "update", "patch"]<br>   -  apiGroups: [""]<br>      resources: ["services", "endpoints"]<br>      verbs: ["get","create","list", "watch","update"]<br>   -  apiGroups: ["extensions"]<br>      resources: ["podsecuritypolicies"]<br>      resourceNames: ["nfs-provisioner"]<br>      verbs: ["use"]<br>---<br>kind: ClusterRoleBinding<br>apiVersion: rbac.authorization.k8s.io/v1<br>metadata:<br>  name: run-nfs-provisioner<br>subjects:<br>  - kind: ServiceAccount<br>    name: nfs-provisioner<br>    namespace: xgp-lll<br>roleRef:<br>  kind: ClusterRole<br>  name: nfs-provisioner-runner<br>  apiGroup: rbac.authorization.k8s.io<br></code></pre></td></tr></table></figure><h4 id="执行一下-7">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f rbac-rolebind.yaml<br></code></pre></td></tr></table></figure><h3 id="3、创建Deployment资源对象，用Pod代替-真正的NFS服务。-2">3、创建Deployment资源对象，用Pod代替 真正的NFS服务。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nfs-deployment.yaml <br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nfs-client-provisioner<br>  namespace: xgp-lll<br>spec:<br>  replicas: 1<br>  strategy:<br>    type: Recreate<br>  template:<br>    metadata:<br>      labels:<br>        app: nfs-client-provisioner<br>    spec:<br>      serviceAccount: nfs-provisioner<br>      containers:<br>        - name: nfs-client-provisioner<br>          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner<br>          volumeMounts:<br>            - name: nfs-client-root<br>              mountPath:  /persistentvolumes<br>          env:<br>            - name: PROVISIONER_NAME<br>              value: xgp<br>            - name: NFS_SERVER<br>              value: 192.168.1.21<br>            - name: NFS_PATH<br>              value: /nfsdata<br>      volumes:<br>        - name: nfs-client-root<br>          nfs:<br>            server: 192.168.1.21<br>            path: /nfsdata<br></code></pre></td></tr></table></figure><h4 id="执行一下-8">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-deployment.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-6">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod  -n xgp-lll<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212115808607.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212115808607.png" alt="image-20200212115808607"></a></p><h3 id="4、创建storageclass的yaml文件-2">4、创建storageclass的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim test-storageclass.yaml <br>apiVersion: storage.k8s.io/v1<br>kind: StorageClass<br>metadata:<br>  name: stateful-nfs<br>  namespace: xgp-lll<br>provisioner: xgp  #通过provisioner字段关联到上述Deploy<br>reclaimPolicy: Retain<br></code></pre></td></tr></table></figure><h4 id="执行一下-9">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f test-storageclass.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-7">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get sc -n  xgp-lll<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212120207679.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212120207679.png" alt="image-20200212120207679"></a></p><h2 id="（二）解决自动创建pvc">（二）解决自动创建pvc</h2><h3 id="1、创建statefulset的yaml文件-2">1、创建statefulset的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs shell">apiVersion: v1<br>kind: Service<br>metadata:<br>  name: headless-svc<br>  namespace: xgp-lll<br>  labels:<br>    app: headless-svc<br>spec:<br>  ports:<br>  - port: 80<br>    name: myweb<br>  selector:<br>    app: headless-pod<br>  clusterIP: None<br>---<br>apiVersion: apps/v1<br>kind: StatefulSet<br>metadata:<br>  name: statefulset-test<br>  namespace: xgp-lll<br>spec:<br>  serviceName: headless-svc<br>  replicas: 3<br>  selector:<br>    matchLabels:<br>      app: headless-pod<br>  template:<br>    metadata:<br>      labels:<br>        app: headless-pod<br>    spec:<br>      containers:<br>      - image: httpd<br>        name: myhttpd<br>        ports:<br>        - containerPort: 80<br>          name: httpd<br>        volumeMounts:<br>        - mountPath: /usr/local/apache2/htdocs<br>          name: test<br>  volumeClaimTemplates:  #&gt; 自动创建PVC，为后端的Pod提供专有的存储。**<br>  - metadata:<br>      name: test<br>      annotations:   #这是指定storageclass<br>        volume.beta.kubernetes.io/storage-class: stateful-nfs<br>    spec:<br>      accessModes:<br>        - ReadWriteOnce<br>      resources:<br>        requests:<br>          storage: 100Mi<br></code></pre></td></tr></table></figure><h3 id="执行一下-10">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f statefulset.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-8">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -n xgp-lll<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212121256221.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212121256221.png" alt="image-20200212121256221"></a></p><h3 id="2、-验证一下数据存储-2">2、 验证一下数据存储</h3><h4 id="容器中创建文件-2">容器中创建文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">第一个<br>[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-0 /bin/bash <br>root@statefulset-test-0:/usr/local/apache2# echo 123 &gt; /usr/local/apache2/htdocs/index.html<br><br>第二个<br>[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-1 /bin/bash <br>root@statefulset-test-2:/usr/local/apache2# echo 456 &gt; /usr/local/apache2/htdocs/index.html<br><br>第三个<br>[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-2 /bin/bash <br>root@statefulset-test-1:/usr/local/apache2# echo 789 &gt; /usr/local/apache2/htdocs/index.html<br></code></pre></td></tr></table></figure><h4 id="宿主机查看一下-2">宿主机查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">第一个<br>[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-0-pvc-ccaa02df-4721-4453-a6ec-4f2c928221d7/index.html <br>123<br><br>第二个<br>[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-1-pvc-88e60a58-97ea-4986-91d5-a3a6e907deac/index.html <br>456<br><br><br>第三个<br>[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-2-pvc-4eb2bbe2-63d2-431a-ba3e-b7b8d7e068d3/index.html <br>789<br></code></pre></td></tr></table></figure><h4 id="访问一下">访问一下</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212131705416.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200212131705416.png" alt="image-20200212131705416"></a></p><p><strong>扩容、缩容:在此过程中，Pod的生成或删除操作也是有顺序性的。</strong></p><p><strong>升级操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">kubectl explain sts.spec.updateStrategy.rollingUpdate.partition<br></code></pre></td></tr></table></figure><p><strong>partition：如果partition后面的值等于N, N+的都会更新。默认值为0（所有都会更新）。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;StatefulSet介绍&lt;/h1&gt;
&lt;h3 id=&quot;遇到的问题：&quot;&gt;遇到的问题：&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;使用Deployment创建的Pod是无状态的，当挂在Volume之后，如果该Pod挂了，Replication Controller会再run一个来保证可
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="StatefulSet" scheme="https://wsdlxgp.top/tags/StatefulSet/"/>
    
      <category term="nfs-deployment" scheme="https://wsdlxgp.top/tags/nfs-deployment/"/>
    
      <category term="StorageClass" scheme="https://wsdlxgp.top/tags/StorageClass/"/>
    
  </entry>
  
  <entry>
    <title>k8s的存储类</title>
    <link href="https://wsdlxgp.top/posts/15ab.html"/>
    <id>https://wsdlxgp.top/posts/15ab.html</id>
    <published>2020-06-07T12:10:05.534Z</published>
    <updated>2020-06-07T14:35:40.133Z</updated>
    
    <content type="html"><![CDATA[<h4 id="k8s有很多的服务，很多的资源对象。">k8s有很多的服务，很多的资源对象。</h4><p><strong>如果要去创建服务，做数据持久化，需要预先知道可用<code>PV</code>有哪些?</strong></p><p><strong>如果为了这个服务去提前创建<code>PV</code>，那么我们还需要知道，这个服务，大概需要多大的空间?</strong></p><h3 id="环境介绍">环境介绍</h3><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>k8s</td></tr><tr><td>node01</td><td>192.168.1.22</td><td>k8s</td></tr><tr><td>node02</td><td>192.168.1.23</td><td>k8s</td></tr></tbody></table><p>基于<a href> https://blog.51cto.com/14320361/2464655</a> 的实验继续进行</p><h1>存储类介绍</h1><p><strong>Kubernetes集群管理员通过提供不同的存储类，可以满足用户不同的服务质量级别、备份策略和任意策略要求的存储需求。动态存储卷供应使用StorageClass进行实现，其允许存储卷按需被创建。如果没有动态存储供应，Kubernetes集群的管理员将不得不通过手工的方式类创建新的存储卷。通过动态存储卷，Kubernetes将能够按照用户的需要，自动创建其需要的存储。</strong></p><p><strong>基于StorageClass的动态存储供应整体过程如下图所示：</strong></p><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607211947.png" alt></p><blockquote><p><strong>1）集群管理员预先创建存储类（StorageClass）；</strong><br><strong>2）用户创建使用存储类的持久化存储声明(PVC：PersistentVolumeClaim)；</strong><br><strong>3）存储持久化声明通知系统，它需要一个持久化存储(PV: PersistentVolume)；</strong><br><strong>4）系统读取存储类的信息；</strong><br><strong>5）系统基于存储类的信息，在后台自动创建PVC需要的PV；</strong><br><strong>6）用户创建一个使用PVC的Pod；</strong><br><strong>7）Pod中的应用通过PVC进行数据的持久化；</strong><br><strong>8）而PVC使用PV进行数据的最终持久化处理。</strong></p></blockquote><h2 id="先来简单看一下这张图实现的过程，然后我们再来研究一下">先来简单看一下这张图实现的过程，然后我们再来研究一下</h2><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607212122.png" alt="k8s的存储类"></p><blockquote><p><strong>说在前面的话，静态供给的话，会需要我们手动去创建pv，如果没有足够的资源，找不到合适的pv，那么pod就会处于pending等待的状态，就是说找不到合适的伴侣了，所以解决这两种问题，就给出了这种动态供给，主要是能够自动帮你创建pv<br>，就是你需要多大的容量，就自动给你创建多大的容量，也就是pv，k8s帮你创建了，创建pvc的时候就需要找pv了，这个时候就交给这个存储类了，而存储类呢，去帮你创建这些pv,存储类呢，就是实现了对指定存储的一个支持，直接帮你去调用api去创建存储类，所以就不需要人工的去帮你创建pv了。<br>而你去想想，当节点比较多，业务比较多的时候，再去人工手动创建pv，量还是很大的，而且也不是很好去维护。<br>而动态供给主要的一个实现就是StorageClass存储对象，其实它就是声明你使用哪个存储，然后呢帮你去连接，再帮你去自动创建pv。</strong></p></blockquote><p>举个例子更好去理解<br>话不多说下图<br><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607212132.png" alt="k8s的存储类"></p><blockquote><p><strong>其实它是一个基于NFS实现的一个pv供给，它大概流程是这样的，我们可能会创建一个statefulset有状态的应用存储，然后有一个管理的nfs-storageClass，因为nfs目前是不支持这个自动的创建pv的，我们可以利用社区实现的插件来完成这个pv的自动创建，也就是StorageClass这一块，创建完之后，然后pod再去引用。</strong></p></blockquote><h1>一，Storage Class（存储类）</h1><p><em><strong>作用：它可以动态的自动的创建所需要的PV</strong></em></p><p><strong>Provisioner（供给方，提供者）：及提供了存储资源的存储系统。k8s内建有多重供给方，这些供给方的名字都以“<a href="https://kubernetes.io/" target="_blank" rel="noopener">kubernetes.io</a>”为前缀。并且还可以自定义。</strong></p><p><strong>Parameters（参数）：存储类使用参数描述要关联到的存储卷，注意不同的供给方参数也不同。</strong></p><p><strong>ReclaimPlicy: PV的回收策略，可用值有Delete(默认)和Retain</strong></p><h3 id="（1）确定基于NFS服务来做的SC。NFS开启">（1）确定基于NFS服务来做的SC。NFS开启</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# showmount -e<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210102349600.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210102349600.png" alt="image-20200210102349600"></a></p><h3 id="（2）需要RBAC权限。">（2）需要RBAC权限。</h3><p><em><strong>RBAC：rbac是k8s的API的安全策略，是基于用户的访问权限的控制。规定了谁，可以有什么样的权限。</strong></em></p><p><strong>为了给SC资源操作k8s集群的权限。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim rbac-rolebind.yaml<br>kind: Namespace<br>apiVersion: v1<br>metadata:<br>  name: bdqn-test<br>---<br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: nfs-provisioner<br>  namespace: bdqn-test<br>---<br>apiVersion: rbac.authorization.k8s.io/v1<br>kind: ClusterRole<br>metadata:<br>  name: nfs-provisioner-runner<br>  namespace: bdqn-test<br>rules:<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumes"]<br>      verbs: ["get", "list", "watch", "create", "delete"]<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumeclaims"]<br>      verbs: ["get", "list", "watch", "update"]<br>   -  apiGroups: ["storage.k8s.io"]<br>      resources: ["storageclasses"]<br>      verbs: ["get", "list", "watch"]<br>   -  apiGroups: [""]<br>      resources: ["events"]<br>      verbs: ["watch", "create", "update", "patch"]<br>   -  apiGroups: [""]<br>      resources: ["services", "endpoints"]<br>      verbs: ["get","create","list", "watch","update"]<br>   -  apiGroups: ["extensions"]<br>      resources: ["podsecuritypolicies"]<br>      resourceNames: ["nfs-provisioner"]<br>      verbs: ["use"]<br>---<br>kind: ClusterRoleBinding<br>apiVersion: rbac.authorization.k8s.io/v1<br>metadata:<br>  name: run-nfs-provisioner<br>subjects:<br>  - kind: ServiceAccount<br>    name: nfs-provisioner<br>    namespace: bdqn-test<br>roleRef:<br>    kind: ClusterRole<br>    name: nfs-provisioner-runner<br>    apiGroup: rbac.authorization.k8s.io<br></code></pre></td></tr></table></figure><p><strong>运行一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f rbac-rolebind.yaml<br></code></pre></td></tr></table></figure><h3 id="（3）nfs-deployment">（3）nfs-deployment</h3><p><em><strong>作用：其实它是一个NFS客户端。但它通过K8S的内置的NFS驱动挂载远端的NFS服务器到本地目录；然后将自身作为storage provider，关联storage class。</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nfs-deployment.yaml<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nfs-client-provisioner<br>  namespace: bdqn-test<br>spec:<br>  replicas: 1<br>  strategy:<br>    type: Recreate<br>  template:<br>    metadata:<br>      labels:<br>        app: nfs-client-provisioner<br>    spec:<br>      serviceAccount: nfs-provisioner    #指定账户<br>      containers:<br>        - name: nfs-client-provisioner<br>          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner<br>          volumeMounts:<br>            - name: nfs-client-root<br>              mountPath:  /persistentvolumes   #指定容器内的挂载目录<br>          env:<br>            - name: PROVISIONER_NAME            #这是这个容器内置的变量<br>              value: bdqn-test                  #这是上面变量的值（名字）<br>            - name: NFS_SERVER                  #内置变量，用于指定nfs服务的IP<br>              value: 192.168.1.21<br>            - name: NFS_PATH                    #内置变量，指定的是nfs共享的目录<br>              value: /nfsdata<br>      volumes:                                  #这下面是指定上面挂载到容器内的nfs的路径及IP<br>        - name: nfs-client-root<br>          nfs:<br>            server: 192.168.1.21<br>            path: /nfsdata<br></code></pre></td></tr></table></figure><p><strong>执行一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-deployment.yaml<br></code></pre></td></tr></table></figure><h3 id="（4）创建storageclass">（4）创建storageclass</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim test-storageclass.yaml<br><br>apiVersion: storage.k8s.io/v1<br>kind: StorageClass<br>metadata:<br>  name: stateful-nfs<br>  namespace: bdqn-test<br>provisioner: bdqn-test  #这里要和第三个nfs-client-provisioner的env环境变量中的value值对应。<br>reclaimPolicy: Retain   #回收策略为：retain，还有一个默认的值为“default”<br></code></pre></td></tr></table></figure><p><strong>执行一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f test-storageclass.yaml<br></code></pre></td></tr></table></figure><h3 id="（5）创建PVC">（5）创建PVC</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim test-pvc.yaml<br><br>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: test-claim<br>  namespace: bdqn-test<br>spec:<br>  storageClassName: stateful-nfs   #定义存储类的名字，要和SC的名字对应<br>  accessModes:<br>    - ReadWriteMany         #访问模式为RWM<br>  resources:<br>    requests:<br>      storage: 500Mi<br></code></pre></td></tr></table></figure><p><strong>执行一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f test-pvc.yaml<br></code></pre></td></tr></table></figure><p><strong>查看一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pvc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210221418144.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210221418144.png" alt="image-20200210221418144"></a></p><h3 id="（6）创建一个Pod">（6）创建一个Pod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim test-pod.yaml<br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: test-pod<br>  namespace: bdqn-test<br>spec:<br>  containers:<br>  - name: test-pod<br>    image: busybox<br>    args:<br>      - /bin/sh<br>      - -c<br>      - sleep 30000<br>    volumeMounts:<br>      - name: nfs-pvc<br>        mountPath: /test<br>  restartPolicy: OnFailure<br>  volumes:<br>    - name: nfs-pvc<br>      persistentVolumeClaim:<br>        claimName: test-claim  #这的名字要和PVC的名字一致<br></code></pre></td></tr></table></figure><p><strong>执行一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f  test-pod.yaml<br></code></pre></td></tr></table></figure><p><strong>查看一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -n bdqn-test<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210111008028.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210111008028.png" alt="image-20200210111008028"></a></p><h3 id="（7）容器中添加内容，并查看挂载目录">（7）容器中添加内容，并查看挂载目录</h3><p><strong>进入容器修改页面内容</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it test-pod -n bdqn-test /bin/sh<br>/ # cd test/<br>/test # touch test-file<br>/test # echo 123456 &gt; test-file <br>/test # cat test-file <br>123456<br></code></pre></td></tr></table></figure><p><strong>查看挂载目录</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# ls /nfsdata/<br>bdqn-test-test-claim-pvc-79ddfcf1-65ae-455f-9e03-5bcfe6c6ce15<br>web1<br>web2<br>[root@master yaml]# cat /nfsdata/bdqn-test-test-claim-pvc-79ddfcf1-65ae-455f-9e03-5bcfe6c6ce15/test-file <br>123456<br></code></pre></td></tr></table></figure><h1>二，如果，K8S集群中， 有很多类似的PV, PVC在去向PV申请空间的时候，不仅会考虑名称以及访问控制模式，还会考虑你申请空间的大小，会分配给你最合适大小的PV。</h1><h3 id="运行一个web服务，采用Deployment资源，基于nginx镜像，replicas为3个。数据持久化目录为nginx服务的主访问目录：-usr-share-nginx-html"><em>运行一个web服务，采用Deployment资源，基于nginx镜像，replicas为3个。数据持久化目录为nginx服务的主访问目录：/usr/share/nginx/html</em></h3><p><strong>创建一个PVC,与上述资源进行关联。</strong></p><h4 id="1-基于nfs服务来做的PV和pvc">1. 基于nfs服务来做的PV和pvc</h4><p><strong>下载nfs所需安装包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node02 ~]# yum -y install nfs-utils  rpcbind<br></code></pre></td></tr></table></figure><p><strong>创建共享目录</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# mkdir /nfsdata<br></code></pre></td></tr></table></figure><p><strong>创建共享目录的权限</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim /etc/exports<br>/nfsdata *(rw,sync,no_root_squash)<br></code></pre></td></tr></table></figure><p><strong>开启nfs和rpcbind</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# systemctl start nfs-server.service <br>[root@master ~]# systemctl start rpcbind<br></code></pre></td></tr></table></figure><p><strong>测试一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# showmount -e<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205105654925.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205105654925.png" alt="image-20200205105654925"></a></p><h4 id="2-先创建两个PV-web-pV1-1G-web-pv2-2G">2.先创建两个PV, web- pV1(1G) ,web-pv2 (2G)</h4><p><strong>web1</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim web.yaml <br><br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: web-pv<br>spec :<br>  capacity:<br>    storage: 1Gi<br>  accessModes:<br>    - ReadWriteOnce<br>  persistentVolumeReclaimPolicy: Recycle<br>  storageClassName: nfs<br>  nfs:<br>    path: /nfsdata/web1<br>    server: 192.168.1.21<br></code></pre></td></tr></table></figure><p><strong>web2</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim web2.yaml <br><br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: web-pv2<br>spec :<br>  capacity :<br>    storage: 2Gi<br>  accessModes:<br>    - ReadWriteOnce<br>  persistentVolumeReclaimPolicy: Recycle<br>  storageClassName: nfs<br>  nfs:<br>    path: /nfsdata/web2<br>    server: 192.168.1.21<br></code></pre></td></tr></table></figure><h4 id="3-创建所需文件夹">3.创建所需文件夹</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# mkdir /nfsdata/web1<br>[root@master yaml]# mkdir /nfsdata/web2<br></code></pre></td></tr></table></figure><h4 id="4-执行一下web和web2">4.执行一下web和web2</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f web.yaml <br>[root@master yaml]# kubectl apply -f web2.yaml<br></code></pre></td></tr></table></figure><h4 id="5-查看一下">5.查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210094332726.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210094332726.png" alt="image-20200210094332726"></a></p><h4 id="6-创建web的pvc的yaml文件">6.创建web的pvc的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim web-pvc.yaml <br><br>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: web-pvc<br>spec:<br>  accessModes:<br>  - ReadWriteOnce<br>  resources:<br>    requests:<br>      storage: 1Gi<br>  storageClassName: nfs<br></code></pre></td></tr></table></figure><p>执行一下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f web-pvc.yaml<br></code></pre></td></tr></table></figure><p>查看一下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pvc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210094701343.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210094701343.png" alt="image-20200210094701343"></a></p><p><strong>系统会自动给pvc一个相近内存的pv，所以选择了1G的那个</strong></p><h4 id="7-创建pod的yaml文件">7.创建pod的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim web-pod.yaml<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: web-pod<br>spec:<br>  selector:<br>    matchLabels:<br>      app: nginx<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx<br>    spec:<br>      containers:<br>      - image: nginx<br>        name: nginx<br>        volumeMounts:<br>        - name: web-test<br>          mountPath: /usr/share/nginx/html<br>      volumes:<br>      - name: web-test<br>        persistentVolumeClaim:<br>          claimName: web-pvc<br></code></pre></td></tr></table></figure><h5 id="执行一下">执行一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f web-pod.yaml<br></code></pre></td></tr></table></figure><h5 id="查看一下">查看一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210125236332.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210125236332.png" alt="image-20200210125236332"></a></p><h4 id="8-访问一下nginx的网页">8. 访问一下nginx的网页</h4><h5 id="查看一下nginx的ip">查看一下nginx的ip</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210134937483.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210134937483.png" alt="image-20200210134937483"></a></p><h5 id="进入容器设置网页内容">进入容器设置网页内容</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">root@master yaml]# kubectl exec -it web-pod-8686d9c594-qxhr9 /bin/bash<br>root@web-pod-8686d9c594-qxhr9:/# cd /usr/share/nginx/html/<br>root@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# ls<br>root@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# echo 123456 &gt; index.html<br>root@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# exit<br></code></pre></td></tr></table></figure><h5 id="访问一下">访问一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# curl 10.244.2.17<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210135153791.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210135153791.png" alt="image-20200210135153791"></a></p><h1>三，如果两个PV，大小一样，名称一样，访问控制模式不一样，PVC会关联哪一个? (验证PV和PVC 关联的时候，访问模式必须一样)</h1><h3 id="两个PV，大小一样，名称一样，访问控制模式不一样">两个PV，大小一样，名称一样，访问控制模式不一样</h3><h4 id="1-创建两个pv">&lt;1&gt;创建两个pv</h4><h5 id="web1">web1</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim web1.yaml <br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: web-pv<br>spec :<br>  capacity:<br>    storage: 1Gi<br>  accessModes:<br>    - ReadWriteOnce  #能以读-写mount到单个的节点<br>  persistentVolumeReclaimPolicy: Recycle<br>  storageClassName: nfs<br>  nfs:<br>    path: /nfsdata/web1<br>    server: 192.168.1.21<br></code></pre></td></tr></table></figure><h5 id="web2">web2</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim web2.yaml <br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: web-pv<br>spec :<br>  capacity:<br>    storage: 1Gi<br>  accessModes:<br>    - ReadWriteMany        #能以读-写mount到多个的节点<br>  persistentVolumeReclaimPolicy: Recycle<br>  storageClassName: nfs<br>  nfs:<br>    path: /nfsdata/web1<br>    server: 192.168.1.21<br></code></pre></td></tr></table></figure><h5 id="创建所需文件">创建所需文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# mkdir /nfsdata/web1<br></code></pre></td></tr></table></figure><h5 id="执行一下-2">执行一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f web1.yaml <br>[root@master yaml]# kubectl apply -f web2.yaml<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210140007119.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210140007119.png" alt="image-20200210140007119"></a></p><h4 id="2-创建pvc">&lt;2&gt;创建pvc</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim web-pvc.yaml <br>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: web-pvc<br>spec:<br>  accessModes:<br>  - ReadWriteMany    #能以读-写mount到多个的节点<br>  resources:<br>    requests:<br>      storage: 1Gi<br>  storageClassName: nfs<br></code></pre></td></tr></table></figure><h5 id="执行一下-3">执行一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f web-pvc.yaml<br></code></pre></td></tr></table></figure><h4 id="3-查看一下">&lt;3&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210140227667.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210140227667.png" alt="image-20200210140227667"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pvc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210140258049.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210140258049.png" alt="image-20200210140258049"></a></p><p><strong>现在可以看到pv和pvc关联成功，但是为什么只有一个pv呢？（pv挂载的目录要相同）</strong></p><p><strong>那是因为当创建了两个相同名字的pv时它并不会认为这是两个不同的pv，而会把他们当成是同一个pv，后创建的pv会刷新前面创建的pv。然后，当创建了pvc，并且pvc的访问模式和后面创建pv的访问模式一样，他们就会关联成功，反之不成功。（当然这些条件下还需要考虑，pv的内存）</strong></p><h1>三，小实验</h1><h2 id="（1）以自己的名称创建一个名称空间。以下所有资源都在此名称空间之下。">（1）以自己的名称创建一个名称空间。以下所有资源都在此名称空间之下。</h2><h3 id="1-编写namespace的yam文件">&lt;1&gt;编写namespace的yam文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim namespace.yaml <br>kind: Namespace<br>apiVersion: v1<br>metadata:<br>  name: xgp-znb<br></code></pre></td></tr></table></figure><h3 id="2-执行一下">&lt;2&gt;执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f namespace.yaml<br></code></pre></td></tr></table></figure><h3 id="3-查看一下-2">&lt;3&gt;查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get ns<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210141843553.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210141843553.png" alt="image-20200210141843553"></a></p><h2 id="（2）设置rbac权限。">（2）设置rbac权限。</h2><p><strong>下载所需镜像</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">docker pull registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner<br></code></pre></td></tr></table></figure><h3 id="1-编写rbac的yam文件">&lt;1&gt;编写rbac的yam文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim rbac-rolebind.yaml<br>kind: Namespace<br>apiVersion: v1<br>metadata:<br>  name: xgp-znb<br>---<br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: nfs-provisioner<br>  namespace: xgp-znb<br>---<br>apiVersion: rbac.authorization.k8s.io/v1<br>kind: ClusterRole<br>metadata:<br>  name: nfs-provisioner-runner<br>  namespace: xgp-znb<br>rules:<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumes"]<br>      verbs: ["get", "list", "watch", "create", "delete"]<br>   -  apiGroups: [""]<br>      resources: ["persistentvolumeclaims"]<br>      verbs: ["get", "list", "watch", "update"]<br>   -  apiGroups: ["storage.k8s.io"]<br>      resources: ["storageclasses"]<br>      verbs: ["get", "list", "watch"]<br>   -  apiGroups: [""]<br>      resources: ["events"]<br>      verbs: ["watch", "create", "update", "patch"]<br>   -  apiGroups: [""]<br>      resources: ["services", "endpoints"]<br>      verbs: ["get","create","list", "watch","update"]<br>   -  apiGroups: ["extensions"]<br>      resources: ["podsecuritypolicies"]<br>      resourceNames: ["nfs-provisioner"]<br>      verbs: ["use"]<br>---<br>kind: ClusterRoleBinding<br>apiVersion: rbac.authorization.k8s.io/v1<br>metadata:<br>  name: run-nfs-provisioner<br>subjects:<br>  - kind: ServiceAccount<br>    name: nfs-provisioner<br>    namespace: xgp-znb<br>roleRef:<br>  kind: ClusterRole<br>  name: nfs-provisioner-runner<br>  apiGroup: rbac.authorization.k8s.io<br></code></pre></td></tr></table></figure><h3 id="2-执行一下-2">&lt;2&gt;执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f  rbac-rolebind.yaml<br></code></pre></td></tr></table></figure><h2 id="（3）创建nfs-deployment-yaml">（3）创建nfs-deployment.yaml</h2><h3 id="1-编写deployment的yam文件">&lt;1&gt;编写deployment的yam文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nfs-deployment.yaml<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: nfs-client-provisioner<br>  namespace: xgp-znb<br>spec:<br>  replicas: 1<br>  strategy:<br>    type: Recreate<br>  template:<br>    metadata:<br>      labels:<br>        app: nfs-client-provisioner<br>    spec:<br>      serviceAccount: nfs-provisioner<br>      containers:<br>        - name: nfs-client-provisioner<br>          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner<br>          volumeMounts:<br>            - name: nfs-client-root<br>              mountPath:  /persistentvolumes<br>          env:<br>            - name: PROVISIONER_NAME<br>              value: xgp-znb<br>            - name: NFS_SERVER<br>              value: 192.168.1.21<br>            - name: NFS_PATH<br>              value: /nfsdata<br>      volumes:<br>        - name: nfs-client-root<br>          nfs:<br>            server: 192.168.1.21<br>            path: /nfsdata<br></code></pre></td></tr></table></figure><h3 id="2-执行一下-3">&lt;2&gt;执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-deployment.yaml<br></code></pre></td></tr></table></figure><h2 id="（4）创建storageclass自动创建PV。">（4）创建storageclass自动创建PV。</h2><h3 id="1-编写storageclass的yam文件">&lt;1&gt;编写storageclass的yam文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim storageclass.yaml<br>apiVersion: storage.k8s.io/v1<br>kind: StorageClass<br>metadata:<br>  name: test-sc<br>provisioner: xgp-znb   #通过provisioner字段关联到上述Deploy<br>reclaimPolicy: Retain<br></code></pre></td></tr></table></figure><h3 id="2-执行一下-4">&lt;2&gt;执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f storageclass.yaml<br></code></pre></td></tr></table></figure><h2 id="（5）创建PVC-2">（5）创建PVC</h2><h3 id="1-编写PVC的yaml文件">&lt;1&gt;编写PVC的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim pvc.yaml<br>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: test-claim<br>  namespace: xgp-znb<br>spec:<br>  storageClassName: test-sc<br>  accessModes:<br>    - ReadWriteMany<br>  resources:<br>    requests:<br>      storage: 500Mi<br></code></pre></td></tr></table></figure><h3 id="2-执行一下-5">&lt;2&gt;执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f pvc.yaml<br></code></pre></td></tr></table></figure><h3 id="3-查看一下-3">&lt;3&gt;查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pvc -n xgp-znb<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210144220121.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210144220121.png" alt="image-20200210144220121"></a></p><h2 id="（6）创建一个Pod-基于nginx运行一个web服务，使用Deployment资源对象，replicas-3-持久化存储目录为默认主目录">（6）创建一个Pod, 基于nginx运行一个web服务，使用Deployment资源对象，replicas=3.持久化存储目录为默认主目录</h2><h3 id="1-编写deployment的yam文件-2">&lt;1&gt;编写deployment的yam文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim pod.yaml <br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: web-pod<br>  namespace: xgp-znb<br>spec:<br>  replicas: 3<br>  selector:<br>    matchLabels:<br>      app: nginx<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx<br>    spec:<br>      containers:<br>      - image: nginx<br>        name: nginx<br>        volumeMounts:<br>        - name: web-test<br>          mountPath: /usr/share/nginx/html<br>      volumes:<br>      - name: web-test<br>        persistentVolumeClaim:<br>          claimName: test-claim<br></code></pre></td></tr></table></figure><h3 id="2-执行一下-6">&lt;2&gt;执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f pvc.yaml<br></code></pre></td></tr></table></figure><h3 id="3-查看一下-4">&lt;3&gt;查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -n xgp-znb<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210211126708.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210211126708.png" alt="image-20200210211126708"></a></p><h2 id="（7）访问nginx页面">（7）访问nginx页面</h2><h3 id="修改nginx主页">修改nginx主页</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it web-pod-8cd956cc7-6szjb -n xgp-znb /bin/bash<br>//进入容器之中<br>root@web-pod-8cd956cc7-6szjb:/# echo  xgp-znb &gt; /usr/share/nginx/html/index.html<br>//添加自定义内容主机<br></code></pre></td></tr></table></figure><h3 id="访问一下-2">访问一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# curl 10.244.2.18<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210211901467.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200210211901467.png" alt="image-20200210211901467"></a></p><h1>四，五个可移植性建议</h1><ol><li><strong>把你的 pvc，和 其它一系列配置放一起， 比如说deployment，configmap</strong></li><li><strong>不要把你的pv放在其它配置里， 因为用户可能没有权限创建pv</strong></li><li><strong>初始化pvc 模版的时候， 提供一个storageclass</strong></li><li><strong>在你的工具软件中，watch那些没有bound的pvc，并呈现给用户</strong></li><li><strong>集群启动的时候启用DefaultStorageClass， 但是不要指定某一类特定的class， 因为不同provisioner的class，参数很难一致</strong></li></ol><h1>五，四个阶段(volumn phase)</h1><h4 id="1-在PVC中绑定一个PV，可以根据下面几种条件组合选择"><strong>1. 在PVC中绑定一个PV，可以根据下面几种条件组合选择</strong></h4><ul><li><strong>Access Modes， 按照访问模式选择pv</strong></li><li><strong>Resources， 按照资源属性选择， 比如说请求存储大小为8个G的pv</strong></li><li><strong>Selector， 按照pv的label选择</strong></li><li><strong>Class， 根据StorageClass的class名称选择, 通过annotation指定了Storage Class的名字, 来绑定特定类型的后端存储</strong></li></ul><h4 id="2-关于根据class过滤出pv的说明：">2. 关于根据class过滤出pv的说明：</h4><blockquote><p><strong>所有的 PVC 都可以在不使用 StorageClass 注解的情况下，直接使用某个动态存储。把一个StorageClass 对象标记为 “default” 就可以了。StorageClass 用注解<a href="https://link.zhihu.com/?target=http%3A//storageclass.beta.kubernetes.io/is-default-class">http://storageclass.beta.kubernetes.io/is-default-class</a> 就可以成为缺省存储。有了缺省的 StorageClass，用户创建 PVC 就不用 storage-class 的注解了，1.4 中新加入的DefaultStorageClass 准入控制器会自动把这个标注指向缺省存储类。PVC 指定特定storageClassName，如fast时， 绑定名称为fast的storageClassPVC中指定storageClassName为“”时， 绑定no class的pv（pv中无class annotation， 或者其值为“”）PVC不指定storageClassName时， DefaultStorageClass admission plugin 开启与否（在apiserver启动时可以指定）， 对default class的解析行为是不同的。当DefaultStorageClass admission plugin启用时， 针对没有storageClass annotation的pvc，DefaultStorageClass会分配一个默认的class， 这个默认的class需要用户指定，比如在创建storageclass对象时加入annotation,如 <a href="https://link.zhihu.com/?target=http%3A//storageclass.beta.kubernetes.io/is-default-class%3A">http://storageclass.beta.kubernetes.io/is-default-class:</a> “true” 。如果有多个默认的class， 则pvc会被拒绝创建， 如果用户没有指定默认的class， 则这个DefaultStorageClass admission plugin不会起任何作用。 pvc会找那些no class的pv做绑定。当DefaultStorageClass admission plugin没有启用时， 针对没有storageClass annotation的pvc， 会绑定no class的pv（pv中无class annotation， 或者其值为“”）</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;k8s有很多的服务，很多的资源对象。&quot;&gt;k8s有很多的服务，很多的资源对象。&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;如果要去创建服务，做数据持久化，需要预先知道可用&lt;code&gt;PV&lt;/code&gt;有哪些?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果为了这个服务去
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="pv" scheme="https://wsdlxgp.top/tags/pv/"/>
    
      <category term="Storage Class" scheme="https://wsdlxgp.top/tags/Storage-Class/"/>
    
  </entry>
  
  <entry>
    <title>k8s存储方式的介绍及应用 （持久化，mysql对数据持久化的应用）</title>
    <link href="https://wsdlxgp.top/posts/ba49.html"/>
    <id>https://wsdlxgp.top/posts/ba49.html</id>
    <published>2020-06-07T12:10:03.469Z</published>
    <updated>2020-06-07T14:35:40.135Z</updated>
    
    <content type="html"><![CDATA[<h1>k8s存储: (持久化)</h1><p><strong>docker容器是有生命周期的。</strong></p><p><strong>volume</strong></p><p><strong>1，存储类（Storage class）是k8s资源类型的一种，它是有管理员为管理PV更加方便创建的一个逻辑组，可以按照存储系统的性能高低，或者综合服务质量，备份策略等分类。不过k8s本身不知道类别到底是什么，它这是作为一个描述。</strong></p><p><strong>2，存储类的好处之一就是支持PV的动态创建，当用户用到持久性存储时，不必再去提前创建PV，而是直接创建PVC就可以了，非常的方便。</strong></p><p><strong>3，存储类对象的名称很重要，并且出了名称之外，还有3个关键字段<br>Provisioner（供给方）:<br>及提供了存储资源的存储系统。k8s内建有多重供给方，这些供给方的名字都以“<a href="http://kubernetes.io" target="_blank" rel="noopener">kubernetes.io</a>”为前缀。并且还可以自定义。<br>Parameters(参数)：存储类使用参数描述要关联到的存储卷，注意不同的供给方参数也不同。<br>reclaimPolicy:PV的回收策略，可用值有Delete(默认)和Retain</strong></p><h1>简介</h1><p><strong>1, 由于容器本身是非持久化的，因此需要解决在容器中运行应用程序遇到的一些问题。首先，当容器崩溃时，kubelet将重新启动容器，但是写入容器的文件将会丢失，容器将会以镜像的初始状态重新开始；第二，在通过一个Pod中一起运行的容器，通常需要共享容器之间一些文件。Kubernetes通过存储卷解决上述的两个问题。</strong></p><p><strong>2, 在Docker有存储卷的概念卷，但Docker中存储卷只是磁盘的或另一个容器中的目录，并没有对其生命周期进行管理。Kubernetes的存储卷有自己的生命周期，它的生命周期与使用的它Pod生命周期一致。因此，相比于在Pod中运行的容器来说，存储卷的存在时间会比的其中的任何容器都长，并且在容器重新启动时会保留数据。当然，当Pod停止存在时，存储卷也将不再存在。在Kubernetes支持多种类型的卷，而Pod可以同时使用各种类型和任意数量的存储卷。在Pod中通过指定下面的字段来使用存储卷：</strong><br><strong>spec.volumes：通过此字段提供指定的存储卷<br>spec.containers.volumeMounts：通过此字段将存储卷挂接到容器中</strong></p><h2 id="环境介绍">环境介绍</h2><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>k8s</td></tr><tr><td>node01</td><td>192.168.1.22</td><td>k8s</td></tr><tr><td>node02</td><td>192.168.1.23</td><td>k8s</td></tr></tbody></table><h2 id="1-emptyDir（空目录）-类似docker-数据持久化的-docer-manager-volume">1.emptyDir（空目录）:类似docker 数据持久化的:docer manager volume</h2><p><strong>使用场景:在同一 个Pod里，不同的容器，共享数据卷。</strong></p><p><strong>如果容器被删除，数据仍然存在，如果Pod被 删除，数据也会被删除。</strong></p><h3 id="1-介绍">&lt;1&gt; 介绍</h3><p><strong>一个emptyDir 第一次创建是在一个pod被指定到具体node的时候，并且会一直存在在pod的生命周期当中，正如它的名字一样，它初始化是一个空的目录，pod中的容器都可以读写这个目录，这个目录可以被挂在到各个容器相同或者不相同的的路径下。当一个pod因为任何原因被移除的时候，这些数据会被永久删除。注意：一个容器崩溃了不会导致数据的丢失，因为容器的崩溃并不移除pod.</strong></p><h3 id="emptyDir的使用场景如下：">emptyDir的使用场景如下：</h3><blockquote><ul><li>空白的初始空间，例如合并/排序算法中，临时将数据保存在磁盘上。</li><li>长时间计算中存储检查点（中间结果），以便容器崩溃时，可以从上一次存储的检查点（中间结果）继续进行，而不是从头开始。</li><li>作为两个容器的共享存储，使得第一个内容管理的容器可以将生成的数据存入其中，同时由一个webserver容器对外提供这些页面。</li><li>默认情况下，emptyDir数据卷存储在node节点的存储介质（机械硬盘、SSD或网络存储）上。</li></ul></blockquote><h3 id="2-emptyDir-磁盘的作用：">&lt;2&gt;emptyDir 磁盘的作用：</h3><p><strong>（1）普通空间，基于磁盘的数据存储<br>（2）作为从崩溃中恢复的备份点<br>（3）存储那些那些需要长久保存的数据，例web服务中的数据<br>默认的，emptyDir 磁盘会存储在主机所使用的媒介上，可能是SSD，或者网络硬盘，这主要取决于你的环境。当然，我们也可以将emptyDir.medium的值设置为Memory来告诉Kubernetes 来挂在一个基于内存的目录tmpfs，因为<br>tmpfs速度会比硬盘块度了，但是，当主机重启的时候所有的数据都会丢失。</strong></p><blockquote><p><strong>测试编写一个yaml文件</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim emptyDir.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: producer-consumer<br>spec:<br>  containers:<br>  - image: busybox<br>    name: producer<br>    volumeMounts:<br>    - mountPath: /producer_dir<br>      name: shared-volume<br>    args:<br>    - /bin/sh<br>    - -c<br>    - echo "hello k8s" &gt; /producer_dir/hello; sleep 30000<br>  - image: busybox<br>    name: consumer<br>    volumeMounts:<br>    - mountPath: /consumer_dir<br>      name: shared-volume<br>    args:<br>    - /bin/sh<br>    - -c<br>    - cat /consumer_dir/hello; sleep 30000<br>  volumes:<br>  - name: shared-volume<br>    emptyDir: &#123;&#125;<br></code></pre></td></tr></table></figure><p><strong>执行一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f emptyDir.yaml <br></code></pre></td></tr></table></figure><p><strong>查看一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod  <br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205095431565.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205095431565.png" alt="image-20200205095431565"></a></p><p><strong>查看日志</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl logs  producer-consumer producer<br>[root@master yaml]# kubectl logs  producer-consumer consumer<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205095543780.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205095543780.png" alt="image-20200205095543780"></a></p><p><strong>查看挂载的目录</strong></p><p><strong>node节点查看容器名，并通过容器名查看挂载的目录</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node01 shared-volume]# docker ps <br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205102007328.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205102007328.png" alt="image-20200205102007328"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node01 shared-volume]# docker inspect k8s_consumer_producer-consumer_default_9ec83f9e-e58b-4bf8-8e16-85b0f83febf9_0<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205102048470.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205102048470.png" alt="image-20200205102048470"></a></p><p><strong>进入挂载目录查看一下</strong></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205102128953.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205102128953.png" alt="image-20200205102128953"></a></p></blockquote><h2 id="2-hostPath-Volume-类似docker-数据持久化的-bind-mount">2.hostPath Volume:类似docker 数据持久化的:bind mount</h2><p><strong>如果Pod被删除，数据会保留，相比较emptyDir要好一点。不过一旦host崩溃，hostPath也无法访问 了。</strong></p><p><strong>docker或者k8s集群本身的存储会采用hostPath这种方式。</strong></p><h3 id="1-介绍-2">&lt;1&gt; 介绍</h3><p><strong>hostPath宿主机路径，就是把pod所在的宿主机之上的脱离pod中的容器名称空间的之外的宿主机的文件系统的某一目录和pod建立关联关系，在pod删除时，存储数据不会丢失。</strong></p><h3 id="2-作用">&lt;2&gt; 作用</h3><p><strong>如果Pod被删除，数据会保留，相比较emptyDir要好一点。不过一旦host崩溃，hostPath也无法访问 了。</strong></p><p><strong>docker或者k8s集群本身的存储会采用hostPath这种方式。</strong></p><h4 id="适用场景如下：">适用场景如下：</h4><blockquote><p>某容器需要访问 Docker，可使用 hostPath 挂载宿主节点的 /var/lib/docker<br>在容器中运行 cAdvisor，使用 hostPath 挂载宿主节点的 /sys</p></blockquote><h2 id="3-Persistent-Volume-PV-持久卷-提前做好的，数据持久化的数据存放目录。">3.Persistent Volume| PV(持久卷) 提前做好的，数据持久化的数据存放目录。</h2><h3 id="Psesistent-Volume-Claim-PVC-持久卷使用声明-申请"><strong>Psesistent Volume Claim| PVC( 持久卷使用声明|申请)</strong></h3><h2 id="Psesistent-Volume-Claim-PVC-持久卷使用声明-申请-2"><strong>Psesistent Volume Claim| PVC( 持久卷使用声明|申请)</strong></h2><p><strong>PersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 该API对象捕获存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统。</strong></p><h2 id="PVC和PV的概念">PVC和PV的概念</h2><p><strong>我们前面提到kubernetes提供那么多存储接口，但是首先kubernetes的各个Node节点能管理这些存储，但是各种存储参数也需要专业的存储工程师才能了解，由此我们的kubernetes管理变的更加复杂的。由此kubernetes提出了PV和PVC的概念，这样开发人员和使用者就不需要关注后端存储是什么，使用什么参数等问题。如下图：</strong><br><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607210917.png" alt="k8s存储方式的介绍及应用 （持久化，mysql对数据持久化的应用）"></p><blockquote><p><strong>PersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 该API对象捕获存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统。</strong><br><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/20200607210935.png" alt="k8s存储方式的介绍及应用 （持久化，mysql对数据持久化的应用）"></p><blockquote><p><strong>PersistentVolumeClaim（PVC）是用户存储的请求。PVC的使用逻辑：在pod中定义一个存储卷（该存储卷类型为PVC），定义的时候直接指定大小，pvc必须与对应的pv建立关系，pvc会根据定义去pv申请，而pv是由存储空间创建出来的。pv和pvc是kubernetes抽象出来的一种存储资源。</strong></p><p><strong>虽然PersistentVolumeClaims允许用户使用抽象存储资源，但是常见的需求是，用户需要根据不同的需求去创建PV，用于不同的场景。而此时需要集群管理员提供不同需求的PV，而不仅仅是PV的大小和访问模式，但又不需要用户了解这些卷的实现细节。 对于这样的需求，此时可以采用StorageClass资源。这个在前面就已经提到过此方案。</strong></p><p><strong>PV是集群中的资源。 PVC是对这些资源的请求，也是对资源的索赔检查。 PV和PVC之间的相互作用遵循这个生命周期：</strong></p></blockquote></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">Provisioning（配置）---&gt; Binding（绑定）---&gt;Using（使用）---&gt; Releasing（释放） ---&gt; Recycling（回收）<br></code></pre></td></tr></table></figure><h3 id="（1）基于nfs服务来做的PV和pvc"><strong>（1）基于nfs服务来做的PV和pvc</strong></h3><p><strong>nfs使的我们可以挂在已经存在的共享到的我们的Pod中，和emptyDir不同的是，emptyDir会被删除当我们的Pod被删除的时候，但是nfs不会被删除，仅仅是解除挂在状态而已，这就意味着NFS能够允许我们提前对数据进行处理，而且这些数据可以在Pod之间相互传递.并且，nfs可以同时被多个pod挂在并进行读写</strong><br><em>注意：必须先保证NFS服务器正常运行在我们进行挂在nfs的时候</em></p><p><strong>下载nfs所需安装包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node02 ~]# yum -y install nfs-utils  rpcbind<br></code></pre></td></tr></table></figure><p><strong>创建共享目录</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# mkdir /nfsdata<br></code></pre></td></tr></table></figure><p><strong>创建共享目录的权限</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim /etc/exports<br>/nfsdata *(rw,sync,no_root_squash)<br></code></pre></td></tr></table></figure><p><strong>开启nfs和rpcbind</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# systemctl start nfs-server.service <br>[root@master ~]# systemctl start rpcbind<br></code></pre></td></tr></table></figure><p><strong>测试一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# showmount -e<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205105654925.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205105654925.png" alt="image-20200205105654925"></a></p><h4 id="1-创建nfs-pv的yaml文件"><strong>&lt;1&gt;创建nfs-pv的yaml文件</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# cd yaml/<br>[root@master yaml]# vim nfs-pv.yaml<br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: test-pv<br>spec:<br>  capacity:   #pv容量的大小<br>    storage: 1Gi<br>  accessModes:  #访问pv的模式<br>    - ReadWriteOnce #能以读-写mount到单个的节点<br>  persistentVolumeReclaimPolicy: Recycle<br>  storageClassName: nfs<br>  nfs:<br>    path: /nfsdata/pv1<br>    server: 192.168.1.21<br></code></pre></td></tr></table></figure><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"> accessModes:(PV支持的访问模式)<br>   - ReadWriteOnce: 能以读-写mount到单个的节点<br>   - ReadWriteMany: 能以读-写mount到多个的节点。<br>- ReadOnlyMnce:  能以只读的方式mount到多个节点。<br></code></pre></td></tr></table></figure></blockquote><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">persistentVolumeReclaimPolicy : (PV存储空间的回收策略是什么)<br>trueRecycle: 自动清除数据。<br>trueRetain: 需要管理员手动回收。<br>trueDelete: 云存储专用。<br></code></pre></td></tr></table></figure></blockquote><h4 id="2-执行一下"><strong>&lt;2&gt;执行一下</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-pv.yaml<br></code></pre></td></tr></table></figure><h4 id="3-查看一下">&lt;3&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205111307317.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205111307317.png" alt="image-20200205111307317"></a></p><h4 id="1-创建nfs-pvc的yaml文件"><strong>&lt;1&gt;创建nfs-pvc的yaml文件</strong></h4><p><strong>PersistentVolumeClaim（PVC）是用户存储的请求。PVC的使用逻辑：在pod中定义一个存储卷（该存储卷类型为PVC），定义的时候直接指定大小，pvc必须与对应的pv建立关系，pvc会根据定义去pv申请，而pv是由存储空间创建出来的。pv和pvc是kubernetes抽象出来的一种存储资源。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nfs-pvc.yaml<br><br>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: test-pvc<br>spec:<br>  accessModes:<br>    - ReadWriteOnce<br>  resources:<br>    requests:<br>      storage: 1Gi<br>  storageClassName: nfs<br></code></pre></td></tr></table></figure><h4 id="2-执行一下-2"><strong>&lt;2&gt;执行一下</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-pvc.yaml<br></code></pre></td></tr></table></figure><h4 id="3-查看一下-2">&lt;3&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pvc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205113407860.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205113407860.png" alt="image-20200205113407860"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205113512580.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200205113512580.png" alt="image-20200205113512580"></a></p><h3 id="（2）创建一个pod资源">（2）创建一个pod资源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim pod.yaml<br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: test-pod<br>spec:<br>  containers:<br>    - name: pod1<br>      image: busybox<br>      args:<br>      - /bin/sh<br>      - -c<br>      - sleep 30000<br>      volumeMounts:<br>      - mountPath: "/mydata"<br>        name: mydata<br>  volumes:<br>    - name: mydata<br>      persistentVolumeClaim:<br>        claimName: test-pvc<br></code></pre></td></tr></table></figure><h4 id="1-执行一下">&lt;1&gt; 执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h4 id="2-查看一下">&lt;2&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207100212328.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207100212328.png" alt="image-20200207100212328"></a></p><p><strong>可以看到现在没有开启成功</strong></p><h5 id="查看一下test-pod的信息看看是哪里的问题">查看一下test-pod的信息看看是哪里的问题</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe pod test-pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207123950227.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207123950227.png" alt="image-20200207123950227"></a></p><h5 id="那是因为pv的本地挂载目录没有创建好">那是因为pv的本地挂载目录没有创建好</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# mkdir /nfsdata/pv1/<br>//要和nfs-pv.yaml的名字一样<br></code></pre></td></tr></table></figure><h5 id="重新创建一下pod">重新创建一下pod</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl delete -f pod.yaml <br>[root@master yaml]# kubectl apply -f pod.yaml <br>[root@master yaml]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207102822785.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207102822785.png" alt="image-20200207102822785"></a></p><h3 id="（3）test-pod创建hello创建文件并添加内容">（3）test-pod创建hello创建文件并添加内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec test-pod touch /mydata/hello<br></code></pre></td></tr></table></figure><p><strong>进入容器</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it test-pod  /bin/sh<br>/ # echo 123 &gt; /mydata/hello<br>/ # exit<br></code></pre></td></tr></table></figure><p><strong>挂载目录查看一下</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# cat  /nfsdata/pv1/hello<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207104239153.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207104239153.png" alt="image-20200207104239153"></a></p><p><strong>和刚刚的一样</strong></p><h3 id="（4）测试回收策略">（4）测试回收策略</h3><h4 id="删除pod和pvc，pv">删除pod和pvc，pv</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl delete pod test-pod <br>[root@master yaml]# kubectl delete pvc test-pvc <br>[root@master yaml]# kubectl delete pv test-pv<br></code></pre></td></tr></table></figure><h4 id="查看一下">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207104454636.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207104454636.png" alt="image-20200207104454636"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# cat  /nfsdata/pv1/hello<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207104520048.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207104520048.png" alt="image-20200207104520048"></a></p><p><em><strong>文件已被回收</strong></em></p><h3 id="（5）修改pv的回收策略为手动">（5）修改pv的回收策略为手动</h3><h4 id="修改">修改</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nfs-pv.yaml <br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>  name: test-pv<br>spec :<br>  capacity :<br>    storage: 1Gi<br>  accessModes:<br>    - ReadWriteOnce<br>  persistentVolumeReclaimPolicy: Retain   #修改<br>  storageClassName: nfs<br>  nfs:<br>    path: /nfsdata/pv1<br>    server: 192.168.1.21<br></code></pre></td></tr></table></figure><h4 id="执行一下">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-pv.yaml<br></code></pre></td></tr></table></figure><h4 id="创建pod">创建pod</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-2">查看一下</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105203009.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105203009.png" alt="image-20200207105203009"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl describe pod test-pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105248025.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105248025.png" alt="image-20200207105248025"></a></p><h4 id="创建pvc">创建pvc</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nfs-pvc.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下pod">查看一下pod</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105402354.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105402354.png" alt="image-20200207105402354"></a></p><h3 id="（6）test-pod创建hello创建文件并添加内容">（6）test-pod创建hello创建文件并添加内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec test-pod touch /mydata/k8s<br></code></pre></td></tr></table></figure><h4 id="查看一下挂载目录">查看一下挂载目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# ls /nfsdata/pv1/<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105618318.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105618318.png" alt="image-20200207105618318"></a></p><h4 id="删除pod和pvc，pv，再次查看挂载目录">删除pod和pvc，pv，再次查看挂载目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl delete pod test-pod <br>[root@master yaml]# kubectl delete pvc test-pvc<br>[root@master yaml]# kubectl delete pv test-pv<br></code></pre></td></tr></table></figure><h4 id="查看挂载目录">查看挂载目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# ls /nfsdata/pv1/<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105757641.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207105757641.png" alt="image-20200207105757641"></a></p><p><em><strong>内容还在</strong></em></p><h2 id="4-mysql对数据持久化的应用">4.mysql对数据持久化的应用</h2><p><strong>下面演示如何为 MySQL 数据库提供持久化存储，步骤为：</strong></p><ul><li><strong>创建 PV 和 PVC。</strong></li><li><strong>部署 MySQL。</strong></li><li><strong>向 MySQL 添加数据。</strong></li><li><strong>模拟节点宕机故障，Kubernetes 将 MySQL 自动迁移到其他节点。</strong></li><li><strong>验证数据一致性。</strong></li></ul><p><strong>最小化安装系统需要</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum -y install mariadb<br></code></pre></td></tr></table></figure><h2 id="（1）通过之前的yaml文件，创建pv和pvc">（1）通过之前的yaml文件，创建pv和pvc</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f  nfs-pv.yaml <br>[root@master yaml]# kubectl apply -f  nfs-pvc.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-3">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pv<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207110132199.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207110132199.png" alt="image-20200207110132199"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pvc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207110140002.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207110140002.png" alt="image-20200207110140002"></a></p><h2 id="（2）编写一个mysql的yaml文件">（2）编写一个mysql的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim mysql.yaml<br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: test-mysql<br>spec:<br>  selector:<br>    matchLabels:    #支持等值的标签<br>      app: mysql<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: test-mysql<br>spec:<br>  selector:<br>    matchLabels:<br>      app: mysql<br>  template:<br>    metadata:<br>      labels:<br>        app: mysql<br>    spec:<br>      containers:<br>      - image: mysql:5.6<br>        name: mysql<br>        env:<br>        - name: MYSQL_ROOT_PASSWORD<br>          value: 123.com<br>        volumeMounts:<br>        - name: mysql-storage<br>          mountPath: /var/lib/mysql<br>      volumes:<br>      - name: mysql-storage<br>        persistentVolumeClaim:<br>          claimName: test-pvc<br></code></pre></td></tr></table></figure><h3 id="执行一下-2">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f mysql.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-4">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207110741833.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207110741833.png" alt="image-20200207110741833"></a></p><h2 id="（3）进入mysql容器">（3）进入mysql容器</h2><p><strong>① 切换到数据库 mysql。<br>② 创建数据库表 my_id。<br>③ 插入一条数据。<br>④ 确认数据已经写入。<br>关闭 k8s-node2，模拟节点宕机故障。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it test-mysql-569f8df4db-rkpwm  -- mysql -u root -p123.com<br></code></pre></td></tr></table></figure><h3 id="创建数据库">创建数据库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> create database yun33;</span><br></code></pre></td></tr></table></figure><h3 id="切换数据库">切换数据库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> use yun33;</span><br></code></pre></td></tr></table></figure><h3 id="创建表">创建表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> create table my_id( id int(4))；</span><br></code></pre></td></tr></table></figure><h3 id="在表中插入数据">在表中插入数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> insert my_id values(9527);</span><br></code></pre></td></tr></table></figure><h3 id="查看表">查看表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> select * from my_id;</span><br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207113808540.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207113808540.png" alt="image-20200207113808540"></a></p><h2 id="（4）查看本地的挂载目录">（4）查看本地的挂载目录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# ls /nfsdata/pv1/<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207113909796.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207113909796.png" alt="image-20200207113909796"></a></p><h3 id="查看一下pod-2">查看一下pod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -o wide -w<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207114050117.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207114050117.png" alt="image-20200207114050117"></a></p><h3 id="挂起node01">挂起node01</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207114607518.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207114607518.png" alt="image-20200207114607518"></a></p><h2 id="（5）查看node02上面数据是否和刚才一样（验证数据的一致性）">（5）查看node02上面数据是否和刚才一样（验证数据的一致性）</h2><h3 id="进入数据库">进入数据库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]#  kubectl exec -it test-mysql-569f8df4db-nsdnz  -- mysql -u root -p123.com<br></code></pre></td></tr></table></figure><h3 id="查看数据库">查看数据库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">mysql&gt;</span><span class="bash"> show databases;</span><br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207115253123.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207115253123.png" alt="image-20200207115253123"></a></p><h3 id="查看表-2">查看表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; show tables;<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207115352727.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207115352727.png" alt="image-20200207115352727"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; select * from my_id;<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207113808540.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200207113808540.png" alt="image-20200207113808540"></a></p><p><em><strong>可以看到数据还在</strong></em></p><h2 id="5-排错方法">5. 排错方法</h2><blockquote><p><strong>kubectl describe</strong><br><strong>//查看详细信息，找出问题</strong><br><strong>kubectl logs</strong><br><strong>//查看日志，找出问题</strong><br><strong>/var/ log/messages</strong><br><strong>//查看该节点的kubelet的日志。</strong></p></blockquote><h2 id="5-总结">5. 总结</h2><p><strong>本章我们讨论了 Kubernetes 如何管理存储资源。<br>emptyDir 和 hostPath 类型的 Volume 很方便，但可持久性不强，Kubernetes 支持多种外部存储系统的 Volume。<br>PV 和 PVC 分离了管理员和普通用户的职责，更适合生产环境。我们还学习了如何通过 StorageClass 实现更高效的动态供给。<br>最后，我们演示了如何在 MySQL 中使用 PersistentVolume 实现数据持久性。</strong></p><h4 id="PV的访问控制类型"><strong>PV的访问控制类型</strong></h4><p><strong>accessModes:(PV支持的访问模式)</strong></p><ul><li><strong>ReadWriteOnce: 能以读-写mount到单个的节点</strong></li><li><strong>ReadWriteMany: 能以读-写mount到多个的节点。</strong></li><li><strong>ReadOnlyOnce: 能以只读的方式mount到单个节点。</strong></li></ul><h4 id="PV的空间回收策略"><strong>PV的空间回收策略</strong></h4><p><strong>persistentVolumeReclaimPolicy : (PV存储空间的回收策略是什么)</strong></p><p><strong>Recycle: 自动清除数据。</strong></p><p><strong>Retain: 需要管理员手动回收。</strong></p><p><strong>Delete: 云存储专用。</strong></p><h4 id="PV和PVC相互关联"><strong>PV和PVC相互关联</strong></h4><p><strong>是通过accessModes和storageClassName模块关联的</strong></p><h4 id="Pod不断的重启">Pod不断的重启:</h4><p><strong>1、swap,没有关闭，导致集群运行不正常。</strong><br><strong>2、内存不足，运行服务也会重后。</strong></p><p><strong>kubectl describe</strong><br><strong>kubectl logs</strong><br><strong>/var/ log/messages</strong><br><strong>查看该节点的kubelet的日志。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;k8s存储: (持久化)&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;docker容器是有生命周期的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;volume&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1，存储类（Storage class）是k8s资源类型的一种，它是有
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="pv" scheme="https://wsdlxgp.top/tags/pv/"/>
    
      <category term="pvc" scheme="https://wsdlxgp.top/tags/pvc/"/>
    
      <category term="emptyDir" scheme="https://wsdlxgp.top/tags/emptyDir/"/>
    
  </entry>
  
  <entry>
    <title>k8s的Job/CronJob资源对象及添加api版本</title>
    <link href="https://wsdlxgp.top/posts/fbf7.html"/>
    <id>https://wsdlxgp.top/posts/fbf7.html</id>
    <published>2020-06-07T12:09:58.388Z</published>
    <updated>2020-06-07T14:35:40.131Z</updated>
    
    <content type="html"><![CDATA[<h1>Job资源对象</h1><blockquote><p>**服务类的Pod容器：**RC、RS、DS、Deployment</p><p>**工作类的Pod容器：**Job—&gt;执行一次，或者批量执行处理程序，完成之后退出容器。</p></blockquote><p><strong>注意： 如果容器内执行任务有误，会根据容器的重启策略操作容器，不过这里</strong><br><strong>的容器重启策略只能是: Never和 OnFailure。</strong></p><h1>概念</h1><p><strong>在有些场景下，是想要运行一些容器执行某种特定的任务，任务一旦执行完成，容器也就没有存在的必要了。在这种场景下，创建pod就显得不那么合适。于是就是了Job，Job指的就是那些一次性任务。通过Job运行一个容器，当其任务执行完以后，就自动退出，集群也不再重新将其唤醒。</strong></p><p><strong>从程序的运行形态上来区分，可以将Pod分为两类：长时运行服务（jboss、mysql等）和一次性任务（数据计算、测试）。RC创建的Pod都是长时运行的服务，Job多用于执行一次性任务、批处理工作等，执行完成后便会停止（status.phase变为Succeeded）。</strong></p><h1>环境介绍</h1><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>k8s</td></tr><tr><td>node01</td><td>192.168.1.22</td><td>k8s</td></tr><tr><td>node02</td><td>192.168.1.23</td><td>k8s</td></tr></tbody></table><p><strong>基于<a href> https://blog.51cto.com/14320361/2464655</a> 的实验继续进行</strong></p><h1>一、kubernetes支持以下几种job</h1><blockquote><ul><li><strong>非并行job：通常创建一个pod直至其成功结束。</strong></li><li><strong>固定结束次数的job：设置spec.completions,创建多个pod，直到.spec.completions个pod成功结束。</strong></li><li><strong>带有工作队列的并行job：设置.spec.Parallelism但不设置.spec.completions,当所有pod结束并且至少一个成功时，job就认为是成功。</strong></li></ul></blockquote><h2 id="Job-Controller">Job Controller</h2><p><strong>Job Controller负责根据Job Spec创建pod，并持续监控pod的状态，直至其成功结束，如果失败，则根据restartPolicy（只支持OnFailure和Never，不支持Always）决定是否创建新的pod再次重试任务。</strong></p><h2 id="例子"><strong>例子</strong></h2><h3 id="（1）编写一个job的yaml文件">（1）编写一个job的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim jop.yaml<br>kind: Job<br>apiVersion: batch/v1<br>metadata:<br>  name: test-job<br>spec:<br>  template:<br>    metadata:<br>      name: test-job<br>    spec:<br>      containers:<br>      - name: hello<br>        image: busybox<br>        command: ["echo","hello k8s job!"]<br>      restartPolicy: Never<br></code></pre></td></tr></table></figure><h3 id="（2）执行一下">（2）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f jop.yaml<br></code></pre></td></tr></table></figure><h3 id="（3）查看一下">（3）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200115090831524.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200115090831524.png" alt="image-20200115090831524"></a></p><h4 id="查看日志">查看日志</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl logs test-job-gs45w<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200115091213349.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200115091213349.png" alt="image-20200115091213349"></a></p><p><strong>我们可以看到job与其他资源对象不同，仅执行一次性任务，默认pod借宿运行后job即结束，状态为Completed。</strong></p><h3 id="（4）修改一下jop的yaml文件，把echo命令换成乱码">（4）修改一下jop的yaml文件，把echo命令换成乱码</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim jop.yaml<br>kind: Job<br>apiVersion: batch/v1<br>metadata:<br>  name: test-job<br>spec:<br>  template:<br>    metadata:<br>      name: test-job<br>    spec:<br>      containers:<br>      - name: hello<br>        image: busybox<br>        command: ["asdasxsddwefew","hello k8s job!"] #修改<br>      restartPolicy: Never<br></code></pre></td></tr></table></figure><h3 id="（5）先删除之前的pod">（5）先删除之前的pod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl delete jobs.batch test-job<br></code></pre></td></tr></table></figure><h3 id="（6）执行一下">（6）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f jop.yaml<br></code></pre></td></tr></table></figure><h3 id="（7）查看一下">（7）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200115091647925.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200115091647925.png" alt="image-20200115091647925"></a></p><p><em><strong>它会一直创建pod直到完成命令。</strong></em></p><h3 id="（8）修改一下jop的yaml文件，修改重启策略">（8）修改一下jop的yaml文件，修改重启策略</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim jop.yaml <br>kind: Job<br>apiVersion: batch/v1<br>metadata:<br>  name: test-job<br>spec:<br>  template:<br>    metadata:<br>      name: test-job<br>    spec:<br>      containers:<br>      - name: hello<br>        image: busybox<br>        command: ["asdasxsddwefew","hello k8s job!"]<br>      restartPolicy: OnFailure<br></code></pre></td></tr></table></figure><h3 id="（9）先删除之前的pod">（9）先删除之前的pod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl delete jobs.batch test-job<br></code></pre></td></tr></table></figure><h3 id="（10）执行一下">（10）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f jop.yaml<br></code></pre></td></tr></table></figure><h3 id="（11）查看一下">（11）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115092801882.png" alt="image-20200115092801882"></p><p><em><strong>它会一直重启pod完成命令，直到重启到一定次数就会删除job。</strong></em></p><h1>二、提高Job的执行效率</h1><h2 id="1-我们可以在Job-spec字段下加上parallelism选项。表示同时运行多少个Pod执行任务。">1. 我们可以在Job.spec字段下加上<a href="https://wsdlxgp.top/posts/e9be.html">parallelism</a>选项。表示同时运行多少个Pod执行任务。</h2><hr><h3 id="（1）编写一个job的yaml文件-2">（1）编写一个job的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim jop.yaml<br>kind: Job<br>apiVersion: batch/v1<br>metadata:<br>  name: test-job<br>spec:<br>  parallelism: 2    #同时启用几个pod<br>  template:<br>    metadata:<br>      name: test-job<br>    spec:<br>      containers:<br>      - name: hello<br>        image: busybox<br>        command: ["echo","hello k8s job!"]<br>      restartPolicy: OnFailure<br></code></pre></td></tr></table></figure><h3 id="（3）执行一下">（3）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f jop.yaml<br></code></pre></td></tr></table></figure><h3 id="（4）查看一下">（4）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115093854913.png" alt="image-20200115093854913"></p><h4 id="查看日志-2">查看日志</h4><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115094002236.png" alt="image-20200115094002236"></p><h2 id="2-我们可以在Job-spec字段下加上complations选项。表示总共需要完成Pod的数量">2. 我们可以在Job.spec字段下加上complations选项。表示总共需要完成Pod的数量</h2><h3 id="（1）编写一个job的yaml文件-3">（1）编写一个job的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim jop.yaml<br>kind: Job<br>apiVersion: batch/v1<br>metadata:<br>  name: test-job<br>spec:<br>  complations: 8            #运行pod的总数量8个<br>  parallelism: 2            #同时运行2个pod<br>  template:<br>    metadata:<br>      name: test-job<br>    spec:<br>      containers:<br>      - name: hello<br>        image: busybox<br>        command: ["echo","hello k8s job!"]<br>      restartPolicy: OnFailure<br></code></pre></td></tr></table></figure><p><strong>job 字段解释：</strong></p><blockquote><p><strong>标志Job结束需要成功运行的Pod个数，默认为1</strong><br><strong>parallelism：标志并行运行的Pod的个数，默认为1</strong><br><strong>activeDeadlineSeconds：标志失败Pod的重试最大时间，超过这个时间不会继续重试.</strong></p></blockquote><h3 id="（2）先删除之前的pod">（2）先删除之前的pod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl delete jobs.batch test-job<br></code></pre></td></tr></table></figure><h3 id="（3）执行一下-2">（3）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f jop.yaml<br></code></pre></td></tr></table></figure><h3 id="（4）查看一下-2">（4）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115094519494.png" alt="image-20200115094519494"></p><p><strong>可以看到pod是两个两个的启动的。</strong></p><h2 id="3-如何定时执行Job">3. 如何定时执行Job</h2><h3 id="（1）编写一个cronjob的yaml文件">（1）编写一个cronjob的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim cronjop.yaml<br>kind: CronJob<br>apiVersion: batch/v1beta1<br>metadata:<br>  name: hello<br>spec:<br>  schedule: "*/1 * * * *" #限定时间<br>  jobTemplate:<br>    spec:<br>      template:<br>        spec:<br>          containers:<br>          - name: hello<br>            image: busybox<br>            command: ["echo","hello","cronjob"]<br>          restartPolicy: OnFailure<br></code></pre></td></tr></table></figure><h3 id="（2）先删除之前的pod-2">（2）先删除之前的pod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl delete jobs.batch test-job<br></code></pre></td></tr></table></figure><h3 id="（3）执行一下-3">（3）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f jop.yaml<br></code></pre></td></tr></table></figure><h3 id="（4）查看一下-3">（4）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115095857428.png" alt="image-20200115095857428"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get cronjobs.batch<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115095920740.png" alt="image-20200115095920740"></p><p><strong>此时查看Pod的状态，会发现，每分钟都会运行一个新的Pod来执行命令规定的任</strong><br><strong>务。</strong></p><h2 id="练习：规定2020-1-15-10-5分运行上面的crontab任务。">练习：规定2020.1.15.10.5分运行上面的crontab任务。</h2><h3 id="（1）编写一个cronjob的yaml文件-2">（1）编写一个cronjob的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim cronjop.yaml<br>kind: CronJob<br>apiVersion: batch/v1beta1<br>metadata:<br>  name: hello<br>spec:<br>  schedule: "5 10 15 1 *" #限定时间<br>  jobTemplate:<br>    spec:<br>      template:<br>        spec:<br>          containers:<br>          - name: hello<br>            image: busybox<br>            command: ["echo","hello","cronjob"]<br>          restartPolicy: OnFailure<br></code></pre></td></tr></table></figure><h3 id="（2）先删除之前的pod-3">（2）先删除之前的pod</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl delete cronjobs.batch hello<br></code></pre></td></tr></table></figure><h3 id="（3）执行一下-4">（3）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f jop.yaml<br></code></pre></td></tr></table></figure><h3 id="（4）查看一下-4">（4）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115100855819.png" alt="image-20200115100855819"></p><p><strong>这时会发现，如果规定具体时间，可能并不会执行任务。</strong></p><h3 id="（5）添加apiVersion库">（5）添加apiVersion库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim /etc/kubernetes/manifests/kube-apiserver.yaml <br>spec:<br>  containers:<br>  - command:<br>    - kube-apiserver<br>    - --runtime-config=batch/v2alpha1=true    #添加<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115104218361.png" alt="image-20200115104218361"></p><h3 id="（6）重启kubelet">（6）重启kubelet</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# systemctl restart kubelet.service<br></code></pre></td></tr></table></figure><h3 id="（7）查看api版本">（7）查看api版本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl api-versions<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115104521662.png" alt="image-20200115104521662"></p><h3 id="（8）编写一个cronjob的yaml文件">（8）编写一个cronjob的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim cronjop.yaml<br>kind: CronJob<br>apiVersion: batch/v1beta1<br>metadata:<br>  name: hello<br>spec:<br>  schedule: "47 10 15 1 *" #限定时间<br>  jobTemplate:<br>    spec:<br>      template:<br>        spec:<br>          containers:<br>          - name: hello<br>            image: busybox<br>            command: ["echo","hello","cronjob"]<br>          restartPolicy: OnFailure<br></code></pre></td></tr></table></figure><h3 id="（9）执行一下">（9）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f jop.yaml<br></code></pre></td></tr></table></figure><h3 id="（4）查看一下-5">（4）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200115100855819.png" alt="image-20200115100855819"></p><p><strong>注意：此时仍然不能正常运行指定时间的Job，这是因为K8s官方在cronjob这个资源对象的支持中还没有完善此功能，还待开发。</strong></p><p><strong>跟Job资源一样在cronjob.spec.jobTemplate.spec 下同样支持并发Job参数:</strong><br><strong>parallelism，也支持完成Pod的总数参数: completionsr</strong></p><h1>总结</h1><p><strong>Job 作为 Kubernetes 中用于处理任务的资源，与其他的资源没有太多的区别，它也使用 Kubernetes 中常见的控制器模式，监听 Informer 中的事件并运行 <code>syncHandler</code> 同步任务</strong></p><p><strong>而 CronJob 由于其功能的特殊性，每隔 10s 会从 apiserver 中取出资源并进行检查是否应该触发调度创建新的资源，需要注意的是 CronJob 并不能保证在准确的目标时间执行，执行会有一定程度的滞后。</strong></p><p><strong>两个控制器的实现都比较清晰，只是边界条件比较多，分析其实现原理时一定要多注意。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;Job资源对象&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;**服务类的Pod容器：**RC、RS、DS、Deployment&lt;/p&gt;
&lt;p&gt;**工作类的Pod容器：**Job—&amp;gt;执行一次，或者批量执行处理程序，完成之后退出容器。&lt;/p&gt;
&lt;/blockquote&gt;

      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="Job" scheme="https://wsdlxgp.top/tags/Job/"/>
    
      <category term="apiVersion" scheme="https://wsdlxgp.top/tags/apiVersion/"/>
    
      <category term="CronJob" scheme="https://wsdlxgp.top/tags/CronJob/"/>
    
  </entry>
  
  <entry>
    <title>k8s的ReplicaSet，DaemonSet及标签</title>
    <link href="https://wsdlxgp.top/posts/5281.html"/>
    <id>https://wsdlxgp.top/posts/5281.html</id>
    <published>2020-06-07T12:09:47.132Z</published>
    <updated>2020-06-07T14:35:40.127Z</updated>
    
    <content type="html"><![CDATA[<h1>环境介绍</h1><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>k8s</td></tr><tr><td>node01</td><td>192.168.1.22</td><td>k8s</td></tr><tr><td>node02</td><td>192.168.1.23</td><td>k8s</td></tr></tbody></table><p>基于<a href> https://blog.51cto.com/14320361/2464655</a> 的实验继续进行</p><h1>ReplicaSet简单介绍</h1><h2 id="1-RC：ReplicationController（老一代的pod控制器）">1. RC：ReplicationController（老一代的pod控制器）</h2><p><strong>用来确保由其管控的Pod对象副本数量，能够满足用户期望，多则删除，少则通过模本创建</strong></p><h3 id="特点：">特点：</h3><ul><li><strong>确保Pod资源对象的数量精准。</strong></li><li><strong>确保pod健康运行。</strong></li><li><strong>弹性伸缩</strong></li></ul><p><strong>同样，它也可以通过yaml或json格式的资源清单来创建。其中spec字段一般嵌套以下字段：</strong></p><ul><li><strong>replicas：期望的Pod对象副本数量。</strong></li><li><strong>selector：当前控制器匹配Pod对此项副本的标签选择器</strong></li><li><strong>template：pod副本的模板</strong></li></ul><p><strong>与RC相比而言，RS不仅支持*基于等值*的标签选择器，而且还支持*基于集合*的标签选择器。</strong></p><h2 id="2-标签：解决同类型的资源对象，为了更好的管理，按照标签分组。">2. 标签：解决同类型的资源对象，为了更好的管理，按照标签分组。</h2><h3 id="常用的标签分类：">常用的标签分类：</h3><ul><li><strong>release（版本）：stable（稳定版）、canary（金丝雀版本）、beta（测试版本）</strong></li><li><strong>environment（环境变量）：dev（开发）、qa（测试）、production（生产）</strong></li><li><strong>application（应用）：ui、as（application software应用软件）、pc、sc</strong></li><li><strong>tier（架构层级）：frontend（前端）、backend（后端）、cache（缓存）</strong></li><li><strong>partition（分区）：customerA（客户A）、customerB（客户B）</strong></li><li><strong>track（品控级别）：daily（每天）、weekly（每周）</strong></li></ul><p><strong>标签要做到：见名知意。</strong></p><h2 id="3-测试">3.测试</h2><h3 id="（1）编写一个pod的yaml文件">（1）编写一个pod的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim label.yaml <br><br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: labels<br>  labels:<br>    env: qa<br>    tier: frontend<br>spec:<br>  containers:<br>  - name: myapp<br>    image: httpd<br></code></pre></td></tr></table></figure><h4 id="1-执行一下">&lt;1&gt;执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f label.yaml  --record<br></code></pre></td></tr></table></figure><h4 id="2-查看一下">&lt;2&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod  --show-labels <br>//通过--show-labels显示资源对象的<br></code></pre></td></tr></table></figure><p><a href="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114095943595.png" target="_blank" rel="noopener"><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114095943595.png" alt="image-20200114095943595"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get po -L env,tier<br>//显示某个键对应的值<br></code></pre></td></tr></table></figure><p><a href="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114100043922.png" target="_blank" rel="noopener"><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114100043922.png" alt="image-20200114100043922"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get po -l env,tier<br>//通过-l 查看仅包含某个标签的资源。<br></code></pre></td></tr></table></figure><p><a href="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114100200895.png" target="_blank" rel="noopener"><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114100200895.png" alt="image-20200114100200895"></a></p><h3 id="（2）添加标签">（2）添加标签</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl label pod  labels app=pc<br>//给pod资源添加标签<br></code></pre></td></tr></table></figure><h3 id="（3）修改标签">（3）修改标签</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl label pod labels env=dev --overwrite<br>//修改标签<br>[root@master ~]# kubectl get pod -l tier --show-labels <br>//查看标签<br></code></pre></td></tr></table></figure><p><a href="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114100607585.png" target="_blank" rel="noopener"><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114100607585.png" alt="image-20200114100607585"></a></p><h3 id="（4）编写一个service的yaml文件">（4）编写一个service的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim service.yaml<br>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: service<br>spec:<br>  type: NodePort<br>  selector:<br>    env: qa<br>  ports:<br>  - protocol: TCP<br>    port: 90<br>    targetPort: 80<br>    nodePort: 30123<br></code></pre></td></tr></table></figure><h4 id="1-执行一下-2">&lt;1&gt;执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f service.yaml<br></code></pre></td></tr></table></figure><h4 id="2-查看一下-2">&lt;2&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl describe svc<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114101837151.png" alt="image-20200114101837151"></p><h4 id="3-访问一下">&lt;3&gt;访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30123<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114101915248.png" alt="image-20200114101915248"></p><p><strong>如果标签有多个，标签选择器选择其中一个，也可以关联成功。相反，如果选择器有多个，那么标签必须完全满足条件，才可以关联成功。</strong></p><h2 id="4-标签选择器：标签的查询过滤条件。">4. 标签选择器：标签的查询过滤条件。</h2><p><strong><a href="https://wsdlxgp.top/posts/7772.html">基于等值关系的（equality-based）</a>：“=”，“==”，“！ =”前面两个都是相等，最后一个是不等于。</strong></p><p><strong><a href="https://wsdlxgp.top/posts/7772.html">基于集合关系（set-based）</a>:in、notin、exists三种。选择器列表间为“逻辑与”关系，使用ln或者NotIn操作时，其valuas不强制要求为非空的字符串列表，而使用Exists或DostNotExist时，其values必须为空</strong></p><h4 id="使用标签选择器的逻辑：">使用标签选择器的逻辑：</h4><ul><li><strong>同时指定的多个选择器之间的逻辑关系为“与”操作。</strong></li><li><strong>使用空值的标签选择器意味着每个资源对象都将把选中。</strong></li><li><strong>空的标签选择器无法选中任何资源。</strong></li></ul><h3 id="（1）例子">（1）例子</h3><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114110334223.png" alt="image-20200114110334223"></p><h4 id="编写一个selector的yaml’文件">编写一个selector的yaml’文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim selector.yaml<br>selector:<br>  matchLabels:<br>    app: nginx<br>  mathExpressions:<br>    - &#123;key: name,operator: In,values: [zhangsan,lisi]&#125;<br>    - &#123;key: age,operator: Exists,values:&#125;<br></code></pre></td></tr></table></figure><ul><li><strong>selector：当前控制器匹配Pod对此项副本的标签选择器</strong></li><li><strong>matchLabels: 指定键值对表示的标签选择器。</strong></li><li><strong>mathExpressions:：基于表达式来指定的标签选择器。</strong></li></ul><h1>DaemonSet</h1><p><em><strong>它也是一种pod控制器。</strong></em></p><p><em><strong>RC，RS , deployment , daemonset.都是pod控制器。statfukSet，RBAC</strong></em></p><h3 id="1-使用场景：">1. 使用场景：</h3><p><strong>如果必须将pod运行在固定的某个或某几个节点，且要优先于其他的pod的启动。通常情况下，默认会将每一个节点都运行，并且只能运行一个pod。这种情况推荐使用DeamonSet资源对象。</strong></p><ul><li><strong>监控程序；</strong></li><li><strong>日志收集程序；</strong></li><li><strong>集群存储程序；</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get ds -n kube-system <br>//查看一下DaemonSet<br></code></pre></td></tr></table></figure><h3 id="2-DaemonSet-与-Deployment-的区别">2. DaemonSet 与 Deployment 的区别</h3><ul><li><strong>Deployment 部署的副本 Pod 会分布在各个 Node 上，每个 Node 都可能运行好几个副本。</strong></li><li><strong>DaemonSet 的不同之处在于：每个 Node 上最多只能运行一个副本。</strong></li></ul><h3 id="3-运行一个web服务，在每一个节点运行一个pod。">3. 运行一个web服务，在每一个节点运行一个pod。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim daemonset.yaml<br><br>kind: DaemonSet<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: test-ds<br>spec:<br>  template:<br>    metadata:<br>      labels:<br>        name: test-ds<br>    spec:<br>      containers:<br>      - name: test-ds<br>        image: httpd<br></code></pre></td></tr></table></figure><h4 id="1-执行一下-3">&lt;1&gt;执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f daemonset.yaml<br></code></pre></td></tr></table></figure><h4 id="2-查看一下-3">&lt;2&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get ds<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114112936161.png" alt="image-20200114112936161"></p><h1>总结</h1><h2 id="1）总结RC、RS、Deplyment、DaemonSet控制器的特点及使用场景。"><strong>1）总结RC、RS、Deplyment、DaemonSet控制器的特点及使用场景。</strong></h2><h3 id="1-Replication-Controller（RC）">&lt;1&gt;Replication Controller（RC）</h3><h4 id="介绍及使用场景">介绍及使用场景</h4><p><strong><code>Replication Controller</code>简称<code>RC</code>，<code>RC</code>是<code>Kubernetes</code>系统中的核心概念之一，简单来说，<code>RC</code>可以保证在任意时间运行<code>Pod</code>的副本数量，能够保证<code>Pod</code>总是可用的。如果实际<code>Pod</code>数量比指定的多那就结束掉多余的，如果实际数量比指定的少就新启动一些<code>Pod</code>，当<code>Pod</code>失败、被删除或者挂掉后，<code>RC</code>都会去自动创建新的<code>Pod</code>来保证副本数量，所以即使只有一个<code>Pod</code>，我们也应该使用<code>RC</code>来管理我们的<code>Pod</code>。</strong></p><h4 id="主要功能">主要功能</h4><ul><li><strong>确保pod数量：RC用来管理正常运行Pod数量，一个RC可以由一个或多个Pod组成，在RC被创建后，系统会根据定义好的副本数来创建Pod数量。在运行过程中，如果Pod数量小于定义的，就会重启停止的或重新分配Pod，反之则杀死多余的。</strong></li><li><strong>确保pod健康：当pod不健康，运行出错或者无法提供服务时，RC也会杀死不健康的pod，重新创建新的。</strong></li><li><strong>弹性伸缩 ：在业务高峰或者低峰期的时候，可以通过RC动态的调整pod的数量来提高资源的利用率。同时，配置相应的监控功能（Hroizontal Pod Autoscaler），会定时自动从监控平台获取RC关联pod的整体资源使用情况，做到自动伸缩。</strong></li><li><strong>滚动升级：滚动升级为一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定，在初始化升级的时候就可以及时发现和解决问题，避免问题不断扩大。</strong></li></ul><h3 id="2-Replication-Set（RS）">&lt;2&gt;Replication Set（RS）</h3><p><strong>被认为 是“升级版”的RC。RS也是用于保证与label selector匹配的pod数量维持在期望状态。</strong></p><blockquote><p><strong>实际上<code>RS</code>和<code>RC</code>的功能基本一致，目前唯一的一个区别就是<code>RC</code>只支持基于等式的<code>selector</code>（env=dev或app=nginx），但<code>RS</code>还支持基于集合的<code>selector</code>（version in (v1, v2)），这对复杂的运维管理就非常方便了。</strong></p><p><strong><code>kubectl</code>命令行工具中关于<code>RC</code>的大部分命令同样适用于我们的<code>RS</code>资源对象。不过我们也很少会去单独使用<code>RS</code>，它主要被<code>Deployment</code>这个更加高层的资源对象使用，除非用户需要自定义升级功能或根本不需要升级<code>Pod</code>，在一般情况下，我们推荐使用<code>Deployment</code>而不直接使用<code>Replica Set</code>。</strong></p></blockquote><h4 id="区别在于">区别在于</h4><p><strong>1、RC只支持基于等式的selector（env=dev或environment!=qa），但RS还支持新的，基于集合的selector（version in (v1.0, v2.0)或env notin (dev, qa)），这对复杂的运维管理很方便。</strong></p><p><strong>2、升级方式</strong></p><ul><li><strong>RS不能使用kubectlrolling-update进行升级</strong></li><li><strong>kubectl rolling-update专用于rc</strong></li><li><strong>RS升级使用deployment或者kubectl replace命令</strong></li><li><strong>社区引入这一API的初衷是用于取代vl中的RC，也就是说当v1版本被废弃时，RC就完成了它的历史使命，而由RS来接管其工作</strong></li></ul><h3 id="3-DaemonSet">&lt;3&gt;DaemonSet</h3><h4 id="1-特点：">1. 特点：</h4><p><strong>如果必须将pod运行在固定的某个或某几个节点，且要优先于其他的pod的启动。通常情况下，默认会将每一个节点都运行，并且只能运行一个pod。这种情况推荐使用DeamonSet资源对象。</strong></p><p><strong>一个DaemonSet对象能确保其创建的Pod在集群中的每一台（或指定）Node上都运行一个副本。如果集群中动态加入了新的Node，DaemonSet中的Pod也会被添加在新加入Node上运行。删除一个DaemonSet也会级联删除所有其创建的Pod。</strong></p><h4 id="2-使用环境"><strong>2. 使用环境</strong></h4><ul><li><strong>监控程序；</strong></li><li><strong>日志收集程序；</strong></li><li><strong>集群存储程序；</strong></li></ul><h3 id="4-Deployment">&lt;4&gt;Deployment</h3><h4 id="1-什么是Deployment">1. 什么是Deployment</h4><p><strong>Kubernetes Deployment提供了官方的用于更新Pod和Replica Set（下一代的Replication Controller）的方法，您可以在Deployment对象中只描述您所期望的理想状态（预期的运行状态），Deployment控制器为您将现在的实际状态转换成您期望的状态，例如，您想将所有的webapp:v1.0.9升级成webapp:v1.1.0，您只需创建一个Deployment，Kubernetes会按照Deployment自动进行升级。现在，您可以通过Deployment来创建新的资源（pod，rs，rc），替换已经存在的资源等。</strong></p><p><strong>你只需要在Deployment中描述你想要的目标状态是什么，Deployment controller就会帮你将Pod和Replica Set的实际状态改变到你的目标状态。你可以定义一个全新的Deployment，也可以创建一个新的替换旧的Deployment。</strong></p><h4 id="2-典型的用例">2. 典型的用例</h4><ul><li><strong>使用Deployment来创建ReplicaSet。ReplicaSet在后台创建pod。检查启动状态，看它是成功还是失败。</strong></li><li><strong>然后，通过更新Deployment的PodTemplateSpec字段来声明Pod的新状态。这会创建一个新的ReplicaSet，Deployment会按照控制的速率将pod从旧的ReplicaSet移动到新的ReplicaSet中。</strong></li><li><strong>如果当前状态不稳定，回滚到之前的Deployment revision。每次回滚都会更新Deployment的revision。</strong></li><li><strong>扩容Deployment以满足更高的负载。</strong></li><li><strong>暂停Deployment来应用PodTemplateSpec的多个修复，然后恢复上线。</strong></li><li><strong>根据Deployment 的状态判断上线是否hang住了。</strong></li><li><strong>清除旧的不必要的ReplicaSet。</strong></li></ul><h4 id="3-使用环境">3. 使用环境</h4><p><strong>Deployment集成了上线部署、滚动升级、创建副本、暂停上线任务，恢复上线任务，回滚到以前某一版本（成功/稳定）的Deployment等功能，在某种程度上，Deployment可以帮我们实现无人值守的上线，大大降低我们的上线过程的复杂沟通、操作风险。</strong></p><ul><li><strong>定义Deployment来创建Pod和ReplicaSet</strong></li><li><strong>滚动升级和回滚应用</strong></li><li><strong>扩容和缩容</strong></li><li><strong>暂停和继续Deployment</strong></li></ul><h4 id="3-DaemonSet-与-Deployment-的区别">3. DaemonSet 与 Deployment 的区别</h4><ul><li><strong>Deployment 部署的副本 Pod 会分布在各个 Node 上，每个 Node 都可能运行好几个副本。</strong></li><li><strong>DaemonSet 的不同之处在于：每个 Node 上最多只能运行一个副本。</strong></li></ul><h2 id="2）使用DaemonSet控制器运行httpd服务，要求名称以自己的名称命名。标签为：tier-backend-env-dev"><strong>2）使用DaemonSet控制器运行httpd服务，要求名称以自己的名称命名。标签为：tier=backend,env=dev.</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim daemonset.yaml <br>kind: DaemonSet<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-ds<br>spec:<br>  template:<br>    metadata:<br>      labels:<br>        tier: backend<br>        env: dev<br>    spec:<br>      containers:<br>      - name: xgp-ds<br>        image: httpd<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod  --show-labels<br></code></pre></td></tr></table></figure><p><a href="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114100043922.png" target="_blank" rel="noopener"><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114100043922.png" alt="image-20200114100043922"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -L env,tier<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114095943595.png" alt="image-20200114095943595"></p><h2 id="3-创建service资源对象与上述资源进行关联，要有验证。"><strong>3) 创建service资源对象与上述资源进行关联，要有验证。</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim service.yaml <br>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: service<br>spec: <br>  type: NodePort<br>  selector: <br>    env: dev<br>  ports:    <br>  - protocol: TCP<br>    port: 90 <br>    targetPort: 80<br>    nodePort: 30123<br></code></pre></td></tr></table></figure><h3 id="执行一下">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f service.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下-2">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl describe svc<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114120345596.png" alt="image-20200114120345596"></p><h3 id="访问一下">访问一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30123<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200114120444524.png" alt="image-20200114120444524"></p><h2 id="4）整理关于标签和标签选择器都有什么作用？"><strong>4）整理关于标签和标签选择器都有什么作用？</strong></h2><p><strong>&lt;1&gt;标签：解决同类型的资源对象，为了更好的管理，按照标签分组。</strong></p><p><strong>&lt;2&gt;标签选择器：标签的查询过滤条件。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;环境介绍&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;服务&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;master&lt;/td&gt;
&lt;td&gt;192.168.1.21&lt;/td&gt;
&lt;
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="Replica" scheme="https://wsdlxgp.top/tags/Replica/"/>
    
      <category term="SetDaemonSet" scheme="https://wsdlxgp.top/tags/SetDaemonSet/"/>
    
      <category term="标签" scheme="https://wsdlxgp.top/tags/%E6%A0%87%E7%AD%BE/"/>
    
  </entry>
  
  <entry>
    <title>pod健康检查详解（liveness，readiness，滚动更新）</title>
    <link href="https://wsdlxgp.top/posts/af5b.html"/>
    <id>https://wsdlxgp.top/posts/af5b.html</id>
    <published>2020-06-07T12:09:44.111Z</published>
    <updated>2020-06-07T14:35:40.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境介绍">环境介绍</h2><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>k8s+httpd+nginx</td></tr><tr><td>node01</td><td>192.168.1.22</td><td>k8s</td></tr><tr><td>node02</td><td>192.168.1.23</td><td>k8s</td></tr></tbody></table><p><strong>基于<a href> https://blog.51cto.com/14320361/2464655</a> 的实验继续进行</strong></p><h2 id="一、Pod的liveness和readiness探针">一、Pod的liveness和readiness探针</h2><p><strong>Kubelet使用liveness probe（存活探针）来确定何时重启容器。例如，当应用程序处于运行状态但无法做进一步操作，liveness探针将捕获到deadlock，重启处于该状态下的容器，使应用程序在存在bug的情况下依然能够继续运行下去</strong><br><strong>Kubelet使用readiness probe（就绪探针）来确定容器是否已经就绪可以接受流量。只有当Pod中的容器都处于就绪状态时kubelet才会认定该Pod处于就绪状态。该信号的作用是控制哪些Pod应该作为service的后端。如果Pod处于非就绪状态，那么它们将会被从service的load balancer中移除。</strong></p><h2 id="Probe支持以下三种检查方法：">Probe支持以下三种检查方法：</h2><h4 id="1-exec-命令">&lt;1&gt;exec-命令</h4><p><strong>在用户容器内执行一次命令，如果命令执行的退出码为0，则认为应用程序正常运行，其他任务应用程序运行不正常。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">livenessProbe:<br>  exec:<br>    command:<br>    - cat<br>    - /home/laizy/test/hostpath/healthy<br></code></pre></td></tr></table></figure><h4 id="2-TCPSocket">&lt;2&gt;TCPSocket</h4><p><strong>将会尝试打开一个用户容器的Socket连接（就是IP地址：端口）。如果能够建立这条连接，则认为应用程序正常运行，否则认为应用程序运行不正常。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">livenessProbe:<br>tcpSocket:<br>   port: 8080<br></code></pre></td></tr></table></figure><h4 id="3-HTTPGet">&lt;3&gt;HTTPGet</h4><p><strong>调用容器内Web应用的web hook，如果返回的HTTP状态码在200和399之间，则认为应用程序正常运行，否则认为应用程序运行不正常。每进行一次HTTP健康检查都会访问一次指定的URL。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常<br>  path: / #URI地址<br>  port: 80 #端口号<br><span class="hljs-meta">  #</span><span class="bash">host: 127.0.0.1 <span class="hljs-comment">#主机地址</span></span><br>  scheme: HTTP #支持的协议，http或者https<br>httpHeaders：’’ #自定义请求的header<br></code></pre></td></tr></table></figure><h2 id="参数说明">参数说明</h2><blockquote><p>**initialDelaySeconds：**容器启动后第一次执行探测是需要等待多少秒。</p><p>**periodSeconds：**执行探测的频率。默认是10秒，最小1秒。</p><p>**timeoutSeconds：**探测超时时间。默认1秒，最小1秒。</p><p>**successThreshold：**探测失败后，最少连续探测成功多少次才被认定为成功。默认是1。对于liveness必须是1。最小值是1。</p></blockquote><h2 id="探针探测的结果有以下三者之一：">探针探测的结果有以下三者之一：</h2><blockquote><p>Success：Container通过了检查。<br>Failure：Container未通过检查。<br>Unknown：未能执行检查，因此不采取任何措施。</p></blockquote><h3 id="1-LivenessProbe（活跃度）">1. LivenessProbe（活跃度）</h3><h4 id="（1）编写一个livenss的yaml文件">（1）编写一个livenss的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@node02 ~]# vim livenss.yaml<br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: liveness<br>  labels:<br>    test: liveness<br>spec:<br>  restartPolicy: OnFailure<br>  containers:<br>  - name: liveness<br>    image: busybox<br>    args:<br>    - /bin/sh<br>    - -c<br>    - touch /tmp/test; sleep 60; rm -rf /tmp/test; sleep 300<br>    livenessProbe:              #存活探测<br>      exec:                     #通过执行命令来检查服务是否正常<br>        command:                #命令模式<br>        - cat<br>        - /tmp/test<br>      initialDelaySeconds: 10    #pod运行10秒后开始探测<br>      periodSeconds: 5           #检查的频率，每5秒探测一次<br></code></pre></td></tr></table></figure><p><strong>该配置文件给Pod配置了一个容器。periodSeconds 规定kubelet要每隔5秒执行一次liveness probe。initialDelaySeconds 告诉kubelet在第一次执行probe之前要的等待10秒钟。探针检测命令是在容器中执行 cat /tmp/healthy 命令。如果命令执行成功，将返回0，kubelet就会认为该容器是活着的并且很健康。如果返回非0值，kubelet就会杀掉这个容器并重启它。</strong></p><h4 id="（2）运行一下">（2）运行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f liveness.yaml<br></code></pre></td></tr></table></figure><h4 id="（3）查看一下">（3）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113091518720.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113091518720.png" alt="image-20200113091518720"></a></p><p><strong>Liveness活跃度探测，根据探测某个文件是否存在，来确定某个服务是否正常运行，如果存在则正常，负责，它会根据你设置的Pod的重启策略操作Pod。</strong></p><h3 id="2-Readiness（敏感探测、就绪性探测）">2. Readiness（敏感探测、就绪性探测）</h3><p><strong>ReadinessProbe探针的使用场景livenessProbe稍有不同，有的时候应用程序可能暂时无法接受请求，比如Pod已经Running了，但是容器内应用程序尚未启动成功，在这种情况下，如果没有ReadinessProbe，则Kubernetes认为它可以处理请求了，然而此时，我们知道程序还没启动成功是不能接收用户请求的，所以不希望kubernetes把请求调度给它，则使用ReadinessProbe探针。<br>ReadinessProbe和livenessProbe可以使用相同探测方式，只是对Pod的处置方式不同，ReadinessProbe是将Pod IP:Port从对应的EndPoint列表中删除，而livenessProbe则Kill容器并根据Pod的重启策略来决定作出对应的措施。<br>ReadinessProbe探针探测容器是否已准备就绪，如果未准备就绪则kubernetes不会将流量转发给此Pod。<br>ReadinessProbe探针与livenessProbe一样也支持exec、httpGet、TCP的探测方式，配置方式相同，只不过是将livenessProbe字段修改为ReadinessProbe。</strong></p><h4 id="（1）编写一个readiness的yaml文件">（1）编写一个readiness的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim readiness.yaml <br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: readiness<br>  labels:<br>    test: readiness<br>spec:<br>  restartPolicy: Never<br>  containers:<br>  - name: readiness<br>    image: busybox<br>    args:<br>    - /bin/sh<br>    - -c<br>    - touch /tmp/test; sleep 60; rm -rf /tmp/test; sleep 300<br>    readinessProbe:<br>      exec:<br>        command:<br>        - cat<br>        - /tmp/test<br>      initialDelaySeconds: 10<br>      periodSeconds: 5<br></code></pre></td></tr></table></figure><h4 id="（2）运行一下-2">（2）运行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f readiness.yaml<br></code></pre></td></tr></table></figure><h4 id="（3）查看一下-2">（3）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113095301156.png" alt="image-20200113095301156"></p><h3 id="3-总结liveness和readiness探测">3. 总结liveness和readiness探测</h3><blockquote><p><strong>（1）liveness和readiness是两种健康检查机制，k8s将两种探测采取相同的默认行为，即通过判断容器启动进程的返回值是否为零，来判断探测是否成功。</strong></p><p><strong>（2）两种探测配置方法完全一样，不同之处在于探测失败后的行为。</strong></p><blockquote><p><strong>liveness探测是根据重启策略操作容器，大多数是重启容器。</strong></p><p><strong>readiness则是将容器设置为不可用，不接收Service转发的请求。</strong></p></blockquote><p><strong>（3）两种探测方法可建议独立存在，也可以同时存在。用livensess判断是否需要重启，实现自愈；用readiness判断容器是否已经准备好对外提供服务。</strong></p></blockquote><h1>二、 检测的应用</h1><h2 id="1-在scale-扩容-缩容-中的应用。">1. 在scale(扩容/缩容) 中的应用。</h2><h4 id="（1）编写一个readiness的yaml文件-2">（1）编写一个readiness的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim hcscal.yaml<br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: web<br>spec:<br>  replicas: 3<br>  template: <br>    metadata:<br>      labels:<br>        run: web<br>    spec:<br>      containers:<br>      - name: web<br>        image: httpd<br>        ports:<br>        - containerPort: 80<br>        readinessProbe:<br>          httpGet:<br>            scheme: HTTP   #探测的协议<br>            path: /healthy  #访问的目录<br>            port: 80<br>          initialDelaySeconds: 10<br>          periodSeconds: 5<br><br>---<br>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: web-svc<br>spec:<br>  type: NodePort<br>  selector:<br>    run: web<br>  ports:<br>  - protocol: TCP<br>    port: 90<br>    targetPort: 80<br>    nodePort: 30321<br></code></pre></td></tr></table></figure><p><strong>在配置文件中，使用httpd镜像，创建出一个Pod，其中periodSeconds字段指定kubelet每5秒执行一次探测，initialDelaySeconds字段告诉kubelet延迟等待10秒，探测方式为向容器中运行的服务发送HTTP GET请求，请求8080端口下的/healthz, 任何大于或等于200且小于400的代码表示成功。任何其他代码表示失败。</strong></p><h4 id="httpGet探测方式有如下可选的控制字段">httpGet探测方式有如下可选的控制字段</h4><blockquote><p><strong>host：要连接的主机名，默认为Pod IP，可以在http request head中设置host头部。</strong><br><strong>scheme: 用于连接host的协议，默认为HTTP。</strong><br><strong>path：http服务器上的访问URI。</strong><br><strong>httpHeaders：自定义HTTP请求headers，HTTP允许重复headers。</strong><br><strong>port： 容器上要访问端口号或名称。</strong></p></blockquote><h4 id="（2）运行一下-3">（2）运行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f readiness.yaml<br></code></pre></td></tr></table></figure><h4 id="（3）查看一下-3">（3）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113102400721.png" alt="image-20200113102400721"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113104819603.png" alt="image-20200113104819603"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get service -o wide<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113104858861.png" alt="image-20200113104858861"></p><h4 id="（4）访问一下">（4）访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl  10.244.1.21/healthy<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113104931451.png" alt="image-20200113104931451"></p><h4 id="（5）pod在指定目录创建一个文件">（5）pod在指定目录创建一个文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl exec web-69d659f974-7s9bc touch /usr/local/apache2/htdocs/healthy<br></code></pre></td></tr></table></figure><h4 id="（6）查看一下">（6）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113105045616.png" alt="image-20200113105045616"></p><h2 id="2-在更新过程中的使用">2. 在更新过程中的使用</h2><h4 id="（1）编写一个readiness的yaml文件-3">（1）编写一个readiness的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim app.v1.yaml<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: app<br>spec:<br>  replicas: 10<br>  template:<br>    metadata:<br>      labels:<br>        run: app<br>    spec:<br>      containers:<br>      - name: app<br>        image: busybox<br>        args:<br>        - /bin/sh<br>        - -c<br>        - sleep 10; touch /tmp/healthy; sleep 3000<br>        readinessProbe:<br>          exec:<br>            command:<br>            - cat<br>            - /tmp/healthy<br>          initialDelaySeconds: 10<br>          periodSeconds: 5<br></code></pre></td></tr></table></figure><h4 id="（2）运行一下并记录版本信息">（2）运行一下并记录版本信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f readiness.yaml --record<br></code></pre></td></tr></table></figure><h5 id="查看一下">查看一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment app<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113110638083.png" alt="image-20200113110638083"></p><h4 id="（3）查看一下-4">（3）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113110659355.png" alt="image-20200113110659355"></p><h2 id="3-升级一下Deployment">3.升级一下Deployment</h2><h4 id="（1）编写一个readiness的yaml文件-4">（1）编写一个readiness的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# cp app.v1.yaml app.v2.yaml<br>[root@master ~]# vim app.v2.yaml <br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: app<br>spec:<br>  replicas: 10<br>  template:<br>    metadata:<br>      labels:<br>        run: app<br>    spec:<br>      containers:<br>      - name: app<br>        image: busybox<br>        args:<br>        - /bin/sh<br>        - -c<br>        - sleep 3000        #修改命令<br>        readinessProbe:<br>          exec:<br>            command:<br>            - cat<br>            - /tmp/healthy<br>          initialDelaySeconds: 10<br>          periodSeconds: 5<br></code></pre></td></tr></table></figure><h4 id="（2）运行一下并记录版本信息-2">（2）运行一下并记录版本信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f readiness.yaml --record<br></code></pre></td></tr></table></figure><h5 id="查看一下-2">查看一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment app<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113111024791.png" alt="image-20200113111024791"></p><h4 id="（3）查看一下-5">（3）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113111125387.png" alt="image-20200113111125387"></p><h4 id="（4）再次升级一下deployment">（4）再次升级一下deployment</h4><h5 id="1-编写一个readiness的yaml文件">&lt;1&gt; 编写一个readiness的yaml文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# cp app.v1.yaml app.v3.yaml<br>[root@master ~]# vim app.v2.yaml <br><br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: app<br>spec:<br>  replicas: 10<br>  template:<br>    metadata:<br>      labels:<br>        run: app<br>    spec:<br>      containers:<br>      - name: app<br>        image: busybox<br>        args:<br>        - /bin/sh<br>        - -c<br>        - sleep 3000        #修改命令<br></code></pre></td></tr></table></figure><h5 id="2-运行一下并记录版本信息">&lt;2&gt; 运行一下并记录版本信息</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f readiness.yaml --record<br></code></pre></td></tr></table></figure><h5 id="查看一下-3">查看一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment app<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113111559864.png" alt="image-20200113111559864"></p><h5 id="3-查看一下">&lt;3&gt; 查看一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113111625947.png" alt="image-20200113111625947"></p><h2 id="4-回滚v2版本">4. 回滚v2版本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout undo deployment app --to-revision=2<br></code></pre></td></tr></table></figure><h3 id="查看一下-4">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113112216777.png" alt="image-20200113112216777"></p><h3 id="（1）编写一个readiness的yaml文件-5">（1）编写一个readiness的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim app.v2.yaml <br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: app<br>spec:<br>  strategy:<br>    rollingUpdate:<br>      maxSurge: 2<br>      maxUnavailable: 2<br>  replicas: 10<br>  template:<br>    metadata:<br>      labels:<br>        run: app<br>    spec:<br>      containers:<br>      - name: app<br>        image: busybox<br>        args:<br>        - /bin/sh<br>        - -c<br>        - sleep 3000<br>        readinessProbe:<br>          exec:<br>            command:<br>            - cat<br>            - /tmp/healthy<br>          initialDelaySeconds: 10<br>          periodSeconds: 5<br></code></pre></td></tr></table></figure><p><strong>maxSurge：此参数控制滚动更新过程中，副本总数超过预期数的值。可以是整数，也可以是百分比，默认是1。</strong></p><p><strong>maxUnavailable：不可用pod的值，默认为1，可以是整数，也可以是百分比。</strong></p><p><strong>参数介绍</strong></p><blockquote><h4 id="minReadySeconds">minReadySeconds:</h4><p><strong>Kubernetes在等待设置的时间后才进行升级</strong><br><strong>如果没有设置该值，Kubernetes会假设该容器启动起来后就提供服务了</strong><br><strong>如果没有设置该值，在某些极端情况下可能会造成服务服务正常运行</strong></p><h4 id="maxSurge">maxSurge:</h4><p><strong>升级过程中最多可以比原先设置多出的POD数量</strong><br><strong>例如：maxSurage=1，replicas=5,则表示Kubernetes会先启动1一个新的Pod后才删掉一个旧的POD，整个升级过程中最多会有5+1个POD。</strong></p><h4 id="maxUnavaible">maxUnavaible:</h4><p><strong>升级过程中最多有多少个POD处于无法提供服务的状态</strong><br><strong>当maxSurge不为0时，该值也不能为0</strong><br><strong>例如：maxUnavaible=1，则表示Kubernetes整个升级过程中最多会有1个POD处于无法服务的状态</strong></p></blockquote><h4 id="（2）-运行一下并记录版本信息">（2） 运行一下并记录版本信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f app.v2.yaml --record<br></code></pre></td></tr></table></figure><h5 id="查看一下-5">查看一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment app<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113114726856.png" alt="image-20200113114726856"></p><h4 id="（3）-查看一下">（3） 查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113114755658.png" alt="image-20200113114755658"></p><h2 id="三、小实验">三、小实验</h2><h3 id="1）写一个Deployment资源对象，要求2个副本，nginx镜像。使用Readiness探测，自定义文件-test是否存在，容器开启之后10秒开始探测，时间间隔为10秒。"><strong>1）写一个Deployment资源对象，要求2个副本，nginx镜像。使用Readiness探测，自定义文件/test是否存在，容器开启之后10秒开始探测，时间间隔为10秒。</strong></h3><h5 id="（1）编写一个readiness的yaml文件-6">（1）编写一个readiness的yaml文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nginx.yaml<br><br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: web<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        run: web<br>    spec:<br>      containers:<br>      - name: readiness<br>        image: 192.168.1.21:5000/nginx:v1<br>        readinessProbe:<br>          exec:<br>            command:<br>            - cat<br>            - /usr/share/nginx/html/test<br>          initialDelaySeconds: 10<br>          periodSeconds: 10<br></code></pre></td></tr></table></figure><h5 id="（2）运行一下并记录版本信息-3">（2）运行一下并记录版本信息</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f nginx.yaml --record<br></code></pre></td></tr></table></figure><h5 id="查看一下-6">查看一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment web<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113122256692.png" alt="image-20200113122256692"></p><h5 id="（3）查看一下-6">（3）查看一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113141908252.png" alt="image-20200113141908252"></p><h3 id="2）在运行之后两个Pod里，进入一个Pod，创建文件-test。"><strong>2）在运行之后两个Pod里，进入一个Pod，创建文件/test。</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it web-864c7cf7fc-gpxq4  /bin/bash<br>root@web-68444bff8-xm22z:/# touch /usr/share/nginx/html/test<br></code></pre></td></tr></table></figure><h4 id="查看一下-7">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113142148105.png" alt="image-20200113142148105"></p><h3 id="3）创建一个Service资源对象，跟上述Deployment进行关联，运行之后，查看Service资源详细信息，确认EndPoint负载均衡后端Pod。"><strong>3）创建一个Service资源对象，跟上述Deployment进行关联，运行之后，查看Service资源详细信息，确认EndPoint负载均衡后端Pod。</strong></h3><h4 id="（1）编写service的yaml文件">（1）编写service的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nginx-svc.yaml<br>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: web-svc<br>spec:<br>  type: NodePort<br>  selector:<br>    run: web<br>  ports:<br>  - protocol: TCP<br>    port: 90<br>    targetPort: 80<br>    nodePort: 30321<br></code></pre></td></tr></table></figure><h4 id="（2）执行一下">（2）执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nginx-svc.yaml<br></code></pre></td></tr></table></figure><h4 id="（3）给两个pod刚更改页面">（3）给两个pod刚更改页面</h4><h5 id="查看一下pod">查看一下pod</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><h5 id="更改页面">更改页面</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl exec -it  web-864c7cf7fc-gpxq4  /bin/bash<br>root@web-864c7cf7fc-gpxq4:/# echo "123"&gt;/usr/share/nginx/html/test<br>root@web-864c7cf7fc-gpxq4:/# exit<br><br>[root@master yaml]# kubectl exec -it  web-864c7cf7fc-pcrs9   /bin/bash<br>root@web-864c7cf7fc-pcrs9:/# echo "321"&gt;/usr/share/nginx/html/test<br>root@web-864c7cf7fc-pcrs9:/# exit<br></code></pre></td></tr></table></figure><h3 id="4）观察状态之后，尝试将另一个Pod也写入-test文件，然后再去查看SVC对应的EndPoint的负载均衡情况。"><strong>4）观察状态之后，尝试将另一个Pod也写入/test文件，然后再去查看SVC对应的EndPoint的负载均衡情况。</strong></h3><h4 id="（1）查看一下service">（1）查看一下service</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get service<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113144624099.png" alt="image-20200113144624099"></p><h4 id="（2）访问一下">（2）访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 192.168.1.21:30321/test<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113144514174.png" alt="image-20200113144514174"></p><h3 id></h3><h3 id="5）通过httpGet的探测方式，重新运行一下deployment资源，总结对比一下这两种Readiness探测方式。"><strong>5）通过httpGet的探测方式，重新运行一下deployment资源，总结对比一下这两种Readiness探测方式。</strong></h3><h4 id="（1）修改deployment的yaml文件">（1）修改deployment的yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# vim nginx.yaml <br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: web<br>spec:<br>  replicas: 2<br>  template:<br>    metadata:<br>      labels:<br>        run: web<br>    spec:<br>      containers:<br>      - name: readiness<br>        image: 192.168.1.21:5000/nginx:v1<br>        readinessProbe:<br>          httpGet:<br>            scheme: HTTP<br>            path: /usr/share/nginx/html/test<br>            port: 80<br>          initialDelaySeconds: 10<br>          periodSeconds: 10<br></code></pre></td></tr></table></figure><h4 id="（2）执行一下-2">（2）执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl apply -f nginx.yaml<br></code></pre></td></tr></table></figure><h4 id="（3）查看一下pod">（3）查看一下pod</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# kubectl get pod -w<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113151034766.png" alt="image-20200113151034766"></p><p><em><strong>maxSurge：此参数控制滚动更新过程中，副本总数超过预期数的值。可以是整数，也可以是百分比，默认是1。所以现在是3台pod</strong></em></p><h4 id="（4）访问一下-2">（4）访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master yaml]# curl 192.168.1.21:30321/test<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200113151225572.png" alt="image-20200113151225572"></p><h3 id="6）总结对比liveness和readiness探测的相同和不同之处，以及它们的使用场景。"><strong>6）总结对比liveness和readiness探测的相同和不同之处，以及它们的使用场景。</strong></h3><h3 id="1-readiness和liveness的核心区别">&lt;1&gt;readiness和liveness的核心区别</h3><p>实际上readiness 和liveness 就如同字面意思。readiness 就是意思是否可以访问，liveness就是是否存活。如果一个readiness 为fail 的后果是把这个pod 的所有service 的endpoint里面的改pod ip 删掉，意思就这个pod对应的所有service都不会把请求转到这pod来了。但是如果liveness 检查结果是fail就会直接kill container，当然如果你的restart policy 是always 会重启pod。</p><h3 id="2-什么样才叫readiness／liveness检测失败呢">&lt;2&gt;什么样才叫readiness／liveness检测失败呢?</h3><p><strong>实际上k8s提供了3中检测手段，</strong></p><blockquote><p>http get 返回200-400算成功，别的算失败<br>tcp socket 你指定的tcp端口打开，比如能telnet 上<br>cmd exec 在容器中执行一个命令 推出返回0 算成功。<br>每中方式都可以定义在readiness 或者liveness 中。比如定义readiness 中http get 就是意思说如果我定义的这个path的http get 请求返回200-400以外的http code 就把我从所有有我的服务里面删了吧，如果定义在liveness里面就是把我kill 了。</p></blockquote><h3 id="3-readiness和readiness的使用环境">&lt;3&gt;readiness和readiness的使用环境</h3><p><strong>比如如果一个http 服务你想一旦它访问有问题我就想重启容器。那你就定义个liveness 检测手段是http get。反之如果有问题我不想让它重启，只是想把它除名不要让请求到它这里来。就配置readiness。</strong></p><blockquote><p>注意，liveness不会重启pod，pod是否会重启由你的restart policy（重启策略）控制。</p></blockquote><p>参考：<br><a href="https://www.jianshu.com/p/16a375199cf2" target="_blank" rel="noopener">https://www.jianshu.com/p/16a375199cf2</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;环境介绍&quot;&gt;环境介绍&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;服务&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;master&lt;/td&gt;
&lt;td&gt;192.168.1
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="liveness" scheme="https://wsdlxgp.top/tags/liveness/"/>
    
      <category term="readiness" scheme="https://wsdlxgp.top/tags/readiness/"/>
    
      <category term="滚动更新" scheme="https://wsdlxgp.top/tags/%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>k8s中pod的资源对象（名称空间，获取策略，重启策略，健康检查）</title>
    <link href="https://wsdlxgp.top/posts/74b2.html"/>
    <id>https://wsdlxgp.top/posts/74b2.html</id>
    <published>2020-06-07T12:09:41.156Z</published>
    <updated>2020-06-07T14:35:40.124Z</updated>
    
    <content type="html"><![CDATA[<h1>一，k8s的资源对象</h1><p><em><strong>Deployment、Service、Pod是k8s最核心的3个资源对象</strong></em></p><blockquote><p>**Deployment：**最常见的无状态应用的控制器，支持应用的扩缩容、滚动升级等操作。</p><p>**Service：**为弹性变动且存在生命周期的Pod对象提供了一个固定的访问接口，用于服务发现和服务访问。</p><p>**Pod：**是运行容器以及调度的最小单位。同一个pod可以同时运行多个容器，这些容器共享net、UTS、IPC，除此之外还有USER、PID、MOUNT。</p><p>**ReplicationController：**用于确保每个Pod副本在任意时刻都能满足目标数量，简单来说，它用于每个容器或容器组总是运行并且可以访问的：老一代无状态的Pod应用控制器。</p><p>**RwplicatSet：**新一代的无状态的Pod应用控制器，它与RC的不同之处在于支持的标签选择器不同，RC只支持等值选择器（键值对），RS还额外支持基于集合的选择器。</p><p>**StatefulSet：**用于管理有状态的持久化应用，如database服务程序，它与Deployment不同之处在于，它会为每一个pod创建一个独有的持久性标识符，并确保每个pod之间的顺序性。</p><p>**DaemonSet：**用于确保每一个节点都运行了某个pod的一个副本，新增的节点一样会被添加到此类pod，在节点移除时，此pod会被回收。</p><p>**Job：**用于管理运行完成后即可终止的应用，例如批量处理做作业任务；</p><p>**volume：**pv pvc<br><strong>ConfigMap：</strong><br><strong>Secret：</strong><br><strong>Role：</strong><br><strong>ClusterRole：</strong><br><strong>RoleBinding：</strong><br><strong>cluster RoleBinding：</strong><br><strong>service account：</strong><br><strong>Helm：</strong></p></blockquote><h2 id="Pod的生命周期被定义为以下几个阶段。">Pod的生命周期被定义为以下几个阶段。</h2><blockquote><ul><li><strong>Pending：Pod已经被创建，但是一个或者多个容器还未创建，这包括Pod调度阶段，以及容器镜像的下载过程。</strong></li><li><strong>Running：Pod已经被调度到Node，所有容器已经创建，并且至少一个容器在运行或者正在重启。</strong></li><li><strong>Succeeded：Pod中所有容器正常退出。</strong></li><li><strong>Failed：Pod中所有容器退出，至少有一个容器是一次退出的。</strong></li></ul></blockquote><h1>环境介绍</h1><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>k8s</td></tr><tr><td>node01</td><td>192.168.1.22</td><td>k8s</td></tr><tr><td>node02</td><td>192.168.1.23</td><td>k8s</td></tr></tbody></table><h1>二，Namespace：名称空间</h1><p><strong>默认的名称空间：</strong></p><blockquote><p><strong>Namespace（命名空间）是kubernetes系统中的另一个重要的概念，通过将系统内部的对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理。</strong></p><p><strong>Kubernetes集群在启动后，会创建一个名为“default”的Namespace，如果不特别指明Namespace，则用户创建的Pod、RC、Service都被系统创建到“default”的Namespace中。</strong></p></blockquote><h2 id="1-查看名称空间">1.查看名称空间</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get namespaces<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109094700728.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109094700728.png" alt="image-20200109094700728"></a></p><h2 id="2-查看名称空间详细信息">2.查看名称空间详细信息</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl describe ns default<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109095006067.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109095006067.png" alt="image-20200109095006067"></a></p><h2 id="3-创建名称空间">3.创建名称空间</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl create ns bdqn<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get namespaces<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109095153448.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109095153448.png" alt="image-20200109095153448"></a></p><h2 id="4-创建namespace的yaml文件">4.创建namespace的yaml文件</h2><h3 id="（1）查看格式">（1）查看格式</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl explain ns<br>//查看nasespace的yaml文件的格式<br></code></pre></td></tr></table></figure><h3 id="（2）创建namespace的yaml文件">（2）创建namespace的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim test-ns.yaml<br>apiVersion: v1<br>kind: Namespace<br>metadata:<br>  name: test<br></code></pre></td></tr></table></figure><h3 id="（3）运行namespace的yaml文件">（3）运行namespace的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f test-ns.yaml<br></code></pre></td></tr></table></figure><h3 id="（4）查看一下">（4）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get ns<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109095808777.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109095808777.png" alt="image-20200109095808777"></a></p><h2 id="4-删除名称空间">4.删除名称空间</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl delete ns test <br>[root@master ~]# kubectl delete -f test-ns.yaml<br></code></pre></td></tr></table></figure><p><strong>注意：namespace资源对象进用于资源对象的隔离，并不能隔绝不同名称空间的Pod之间的通信。那是网络策略资源的功能。</strong></p><h2 id="5-查看指定名称空间">5.查看指定名称空间</h2><p><strong>可使用–namespace或-n选项</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -n kube-system <br>[root@master ~]# kubectl get pod --namespace kube-system<br></code></pre></td></tr></table></figure><h1>三，Pod</h1><h2 id="1-编写一个pod的yaml文件">1.编写一个pod的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim pod.yaml<br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: test-pod<br>spec:<br>  containers:<br>  - name: test-app<br>    image: 192.168.1.21:5000/web:v1<br></code></pre></td></tr></table></figure><p><em><strong>pod的yaml文件不支持replicas字段</strong></em></p><h3 id="（1）运行一下">（1）运行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）查看一下">（2）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109100836911.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109100836911.png" alt="image-20200109100836911"></a></p><p><em><strong>ps：这个pod因为是自己创建的，所以删除之后k8s并不会自动生成，相当于docker中创建</strong></em></p><h2 id="2-指定pod的namespace名称空间">2.指定pod的namespace名称空间</h2><h3 id="（1）修改pod的yaml文件">（1）修改pod的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim pod.yaml<br>kind: Pod        #资源类型<br>apiVersion: v1   #api版本<br>metadata:<br>  name: test-pod    #指定控制器名称<br>  namespace: bdqn   #指定namespace（名称空间）<br>spec:<br>  containers:      #容器<br>  - name: test-app  #容器名称<br>    image: 192.168.1.21:5000/web:v1  #镜像<br></code></pre></td></tr></table></figure><h5 id="执行一下">执行一下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）查看一下-2">（2）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]#  kubectl get pod -n bdqn <br>//根据namespace名称查看<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109101521992.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109101521992.png" alt="image-20200109101521992"></a></p><h2 id="3-pod中镜像获取策略">3.pod中镜像获取策略</h2><blockquote><p>**Always：**镜像标签为“laster”或镜像不存在时，总是从指定的仓库中获取镜像。</p><p>**IfNotPresent：**仅当本地镜像不存在时才从目标仓库下载。</p><p>**Never：**禁止从仓库中下载镜像，即只使用本地镜像。</p></blockquote><p><em><strong>注意：对于标签为“laster”或者标签不存在，其默认的镜像下载策略为“Always”，而对于其他的标签镜像，默认策略为“IfNotPresent”。</strong></em></p><h2 id="4-观察pod和service的不同并关联">4.观察pod和service的不同并关联</h2><h3 id="（1）pod的yaml文件（指定端口）">（1）pod的yaml文件（指定端口）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim pod.yaml <br>kind: Pod          #资源类型<br>apiVersion: v1      #api版本<br>metadata:<br>  name: test-pod       #指定控制器名称<br>  namespace: bdqn   #指定namespace（名称空间）<br>spec:<br>  containers:                          #容器<br>  - name: test-app                    #容器名称<br>    image: 192.168.1.21:5000/web:v1   #镜像<br>    imagePullPolicy: IfNotPresent   #获取的策略<br>    ports:<br>    - protocol: TCP<br>      containerPort: 80<br></code></pre></td></tr></table></figure><h4 id="1-删除之前的pod">&lt;1&gt;删除之前的pod</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl delete pod -n bdqn test-pod<br></code></pre></td></tr></table></figure><h4 id="2-执行一下">&lt;2&gt;执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h4 id="3-查看一下">&lt;3&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -n bdqn<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109110215669.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109110215669.png" alt="image-20200109110215669"></a></p><h3 id="（2）pod的yaml文件（修改端口）">（2）pod的yaml文件（修改端口）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim pod.yaml <br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: test-pod<br>  namespace: bdqn<br>spec:<br>  containers:<br>  - name: test-app<br>    image: 192.168.1.21:5000/web:v1<br>    imagePullPolicy: IfNotPresent<br>    ports:<br>    - protocol: TCP<br>      containerPort: 90   #改一下端口<br></code></pre></td></tr></table></figure><h4 id="1-删除之前的pod-2">&lt;1&gt;删除之前的pod</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl delete pod -n bdqn test-pod<br></code></pre></td></tr></table></figure><h4 id="2-执行一下-2">&lt;2&gt;执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h4 id="3-查看一下-2">&lt;3&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -n bdqn -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109110409584.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109110409584.png" alt="image-20200109110409584"></a></p><h4 id="4-访问一下">&lt;4&gt;访问一下</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109110430334.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109110430334.png" alt="image-20200109110430334"></a></p><p><strong>会发现修改的90端口并不生效，他只是一个提示字段并不生效。</strong></p><h3 id="（3）pod的yaml文件（添加标签）">（3）pod的yaml文件（添加标签）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim pod.yaml <br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: test-pod<br>  namespace: bdqn<br>  labels:                 #标签<br>    app: test-web          #标签名称<br>spec:<br>  containers:<br>  - name: test-app<br>    image: 192.168.1.21:5000/web:v1<br>    imagePullPolicy: IfNotPresent<br>    ports:<br>    - protocol: TCP<br>      containerPort: 90   #改一下端口<br></code></pre></td></tr></table></figure><h4 id="pod">--------------------------------------pod---------------------------------------------</h4><h2 id="（4）编写一个service的yaml文件">（4）编写一个service的yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim test-svc.yaml <br>apiVersion: v1      #api版本<br>kind: Service          #资源类型<br>metadata:<br>  name: test-svc       #指定控制器名称<br>  namespace: bdqn   #指定namespace（名称空间）<br>spec:<br>  selector:          #标签<br>    app: test-web    #标签名称（须和pod的标签名称一致）<br>  ports:              <br>  - port: 80          #宿主机端口<br>    targetPort: 80    #容器端口<br></code></pre></td></tr></table></figure><p><em><strong>会发现添加的80端口生效了，所以不能乱改。</strong></em></p><h4 id="1-执行一下">&lt;1&gt;执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f test-svc.yaml<br></code></pre></td></tr></table></figure><h4 id="2-查看一下">&lt;2&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc -n bdqn<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121106859.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121106859.png" alt="image-20200109121106859"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl describe svc -n bdqn test-svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121139399.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121139399.png" alt="image-20200109121139399"></a></p><h4 id="4-访问一下-2">&lt;4&gt;访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 10.98.57.97<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121205607.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121205607.png" alt="image-20200109121205607"></a></p><h4 id="service">--------------------------------------service---------------------------------------------</h4><h1>四，容器的重启策略</h1><p><strong>Pod的重启策略（RestartPolicy）应用与Pod内所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或者健康检查失败时，kubelet将根据RestartPolicy的设置来进行相应的操作。</strong></p><blockquote><p><strong>Always：</strong>（默认情况下使用）但凡Pod对象终止就将其重启；<br>**OnFailure：**仅在Pod对象出现错误时才将其重启；<br>**Never：**从不重启；</p></blockquote><h1>五，pod的默认健康检查</h1><p><strong>每个容器启动时都会执行一个进程，此进程由 Dockerfile 的 CMD 或 ENTRYPOINT 指定。如果进程退出时返回码非零，则认为容器发生故障，Kubernetes 就会根据 <code>restartPolicy</code> 重启容器。</strong></p><h2 id="（1）编写健康检查的yaml文件">（1）编写健康检查的yaml文件</h2><p><strong>下面我们模拟一个容器发生故障的场景，Pod 配置文件如下：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim healcheck.yaml <br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  labels:<br>    test: healcheck<br>  name:  healcheck<br>spec:<br>  restartPolicy: OnFailure  #指定重启策略<br>  containers:<br>  - name:  healcheck<br>    image: busybox:latest<br>    args:                   #生成pod时运行的命令<br>    - /bin/sh<br>    - -c<br>    - sleep 20; exit 1<br></code></pre></td></tr></table></figure><h3 id="1-执行一下-2">&lt;1&gt;执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f  healcheck.yaml<br></code></pre></td></tr></table></figure><h3 id="2-查看一下-2">&lt;2&gt;查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121809350.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121809350.png" alt="image-20200109121809350"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -w | grep healcheck<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121817775.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109121817775.png" alt="image-20200109121817775"></a></p><p><strong>在上面的例子中，容器进程返回值非零，Kubernetes 则认为容器发生故障，需要重启。但有不少情况是发生了故障，但进程并不会退出。</strong></p><h1>六，小实验</h1><h2 id="1）以自己的名称创建一个k8s名称空间，以下所有操作都在此名称空间中。">1）以自己的名称创建一个k8s名称空间，以下所有操作都在此名称空间中。</h2><h3 id="（1）创建名称空间">（1）创建名称空间</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl create ns xgp<br></code></pre></td></tr></table></figure><h3 id="（2）查看一下-3">（2）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get ns xgp<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109133106300.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109133106300.png" alt="image-20200109133106300"></a></p><h2 id="2）创建一个Pod资源对象，使用的是私有仓库中私有镜像，其镜像的下载策略为：NEVER。-Pod的重启策略为：-Never">2）创建一个Pod资源对象，使用的是私有仓库中私有镜像，其镜像的下载策略为：NEVER。 Pod的重启策略为： Never.</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim pod.yaml<br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: test-pod<br>  namespace: xgp<br>  labels:<br>    app: test-web<br>spec:<br>  restartPolicy: Never<br>  containers:<br>  - name: www<br>    image: 192.168.1.21:5000/web:v1<br>    imagePullPolicy: Never<br>    args:                   <br>    - /bin/sh<br>    - -c<br>    - sleep 90; exit 1<br>    ports:<br>    - protocol: TCP<br>      containerPort: 80<br></code></pre></td></tr></table></figure><h2 id="3）创建出容器之后，执行非正常退出，查看Pod的最终状态。">3）创建出容器之后，执行非正常退出，查看Pod的最终状态。</h2><h3 id="（1）执行一下上面pod的yaml文件">（1）执行一下上面pod的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f pod.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）动态查看ns中test-pod的信息">（2）动态查看ns中test-pod的信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -n xgp  -w | grep test-pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109135543482.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109135543482.png" alt="image-20200109135543482"></a></p><blockquote><p><strong>删除test-pod</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl delete pod -n xgp test-pod <br></code></pre></td></tr></table></figure></blockquote><h2 id="4-创建一个Service资源对象，与上述Pod对象关联，验证他们的关联性。">4) 创建一个Service资源对象，与上述Pod对象关联，验证他们的关联性。</h2><h3 id="（1）修改pod的yaml文件-2">（1）修改pod的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim pod.yaml<br>kind: Pod<br>apiVersion: v1<br>metadata:<br>  name: test-pod<br>  namespace: xgp<br>  labels:<br>    app: test-web<br>spec:<br>  restartPolicy: Never<br>  containers:<br>  - name: www<br>    image: 192.168.1.21:5000/web:v1<br>    imagePullPolicy: Never<br>    ports:<br>    - protocol: TCP<br>      containerPort: 80<br></code></pre></td></tr></table></figure><h3 id="（1）编写service的yaml文件">（1）编写service的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim svc.yaml <br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: test-svc<br>  namespace: xgp<br>spec:<br>  selector:<br>    app: test-web<br>  ports:<br>  - port: 80<br>    targetPort: 80<br></code></pre></td></tr></table></figure><h3 id="（2）执行一下">（2）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f svc.yaml<br></code></pre></td></tr></table></figure><h3 id="（3）查看一下">（3）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get  pod -o wide -n xgp<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109141712910.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109141712910.png" alt="image-20200109141712910"></a></p><h3 id="（4）访问一下">（4）访问一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 10.244.1.21<br></code></pre></td></tr></table></figure><p><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200109141749352.png" alt="image-20200109141749352"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;一，k8s的资源对象&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Deployment、Service、Pod是k8s最核心的3个资源对象&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;**Deployment：**最常见的无状态应用的控制器，支持应用的
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="Namespace" scheme="https://wsdlxgp.top/tags/Namespace/"/>
    
      <category term="PodRestart" scheme="https://wsdlxgp.top/tags/PodRestart/"/>
    
      <category term="Policy" scheme="https://wsdlxgp.top/tags/Policy/"/>
    
  </entry>
  
  <entry>
    <title>k8d创建资源(3)（负载均衡原理，回滚指定版本，label控制pod的位置）</title>
    <link href="https://wsdlxgp.top/posts/c3bf.html"/>
    <id>https://wsdlxgp.top/posts/c3bf.html</id>
    <published>2020-06-07T12:09:35.280Z</published>
    <updated>2020-06-07T14:35:40.120Z</updated>
    
    <content type="html"><![CDATA[<h1>Deployment介绍</h1><p><strong>Deployment是kubernetes 1.2引入的概念，用来解决Pod的编排问题。Deployment可以理解为RC的升级版（RC+Reolicat Set）。特点在于可以随时知道Pod的部署进度，即对Pod的创建、调度、绑定节点、启动容器完整过程的进度展示。</strong></p><h2 id="使用场景">使用场景</h2><blockquote><p>创建一个Deployment对象来生成对应的Replica Set并完成Pod副本的创建过程。<br>检查Deployment的状态来确认部署动作是否完成（Pod副本的数量是否达到预期值）。<br>更新Deployment以创建新的Pod(例如镜像升级的场景)。<br>如果当前Deployment不稳定，回退到上一个Deployment版本。<br>挂起或恢复一个Deployment。</p></blockquote><h1>Service介绍</h1><p><a href="https://img-blog.csdn.net/20170809212910268?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaHV3aF8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" target="_blank" rel="noopener"><img src="https://img-blog.csdn.net/20170809212910268?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaHV3aF8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></a></p><p><strong>Service定义了一个服务的访问入口地址，前端应用通过这个入口地址访问其背后的一组由Pod副本组成的集群实例，Service与其后端的Pod副本集群之间是通过Label Selector来实现“无缝对接”。RC保证Service的Pod副本实例数目保持预期水平。</strong></p><h2 id="外部系统访问Service的问题">外部系统访问Service的问题</h2><table><thead><tr><th style="text-align:left">IP类型</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">Node IP</td><td style="text-align:left">Node节点的IP地址</td></tr><tr><td style="text-align:left">Pod IP</td><td style="text-align:left">Pod的IP地址</td></tr><tr><td style="text-align:left">Cluster IP</td><td style="text-align:left">Service的IP地址</td></tr></tbody></table><h1>环境介绍</h1><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td><strong>master</strong></td><td><strong>192.168.1.21</strong></td><td><strong>k8s</strong></td></tr><tr><td><strong>node01</strong></td><td><strong>192.168.1.22</strong></td><td><strong>k8s</strong></td></tr><tr><td><strong>node02</strong></td><td><strong>192.168.1.23</strong></td><td><strong>k8s</strong></td></tr></tbody></table><h1>一，Delpoyment和service的简单使用</h1><h2 id="1-练习写一个yaml文件，要求使用自己的私有镜像，要求副本数量为三个。">1.练习写一个yaml文件，要求使用自己的私有镜像，要求副本数量为三个。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp.yaml<br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-web<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v1<br></code></pre></td></tr></table></figure><h3 id="（1）执行一下">（1）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp.yaml  --recore<br></code></pre></td></tr></table></figure><h3 id="（2）查看一下">（2）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108090638488.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108090638488.png" alt="image-20200108090638488"></a></p><h3 id="（3）访问一下">（3）访问一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 10.244.2.16<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108090817058.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108090817058.png" alt="image-20200108090817058"></a></p><h3 id="（4）更新一下yaml文件，副本加一">（4）更新一下yaml文件，副本加一</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp.yaml<br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-web<br>spec:<br>  replicas: 4<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v1<br></code></pre></td></tr></table></figure><h4 id="1-执行一下">&lt;1&gt;执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp.yaml --recore<br></code></pre></td></tr></table></figure><h4 id="2-查看一下">&lt;2&gt;查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108091104534.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108091104534.png" alt="image-20200108091104534"></a></p><p><em><strong>副本数量加一，如果yaml文件的副本为0，则副本数量还是之前的状态，并不会更新。</strong></em></p><h2 id="2-练习写一个service文件">2.练习写一个service文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp-svc.yaml<br>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: xgp-svc<br>spec:<br>  selector:<br>    app: xgp-server<br>  ports:<br>    - protocol: TCP<br>      port: 80<br>      targetPort: 80<br></code></pre></td></tr></table></figure><h3 id="（1）执行一下-2">（1）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp-svc.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）查看一下-2">（2）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108091909396.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108091909396.png" alt="image-20200108091909396"></a></p><h3 id="（3）访问一下-2">（3）访问一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 10.107.119.49<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108092011164.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108092011164.png" alt="image-20200108092011164"></a></p><h2 id="3-修改yaml文件">3.修改yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp.yaml <br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-web<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v1<br>        ports:<br>          - containerPort: 80  #提示端口<br></code></pre></td></tr></table></figure><p><em><strong>注意：在Delpoyment资源对象中，可以添加Port字段，但此字段仅供用户查看，并不实际生效</strong></em></p><h3 id="执行一下">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp.yaml --recore<br></code></pre></td></tr></table></figure><h2 id="4-service文件映射端口">4.service文件映射端口</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp-svc.yaml <br>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: xgp-svc<br>spec:<br>  type: NodePort<br>  selector:<br>    app: xgp-server<br>  ports:<br>    - protocol: TCP<br>      port: 80<br>      targetPort: 80<br>      nodePort: 30123<br></code></pre></td></tr></table></figure><h3 id="执行一下-2">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp-svc.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108094404773.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108094404773.png" alt="image-20200108094404773"></a></p><h3 id="访问一下">访问一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30123<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108094439682.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108094439682.png" alt="image-20200108094439682"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108094501253.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108094501253.png" alt="image-20200108094501253"></a></p><h2 id="5-修改三个pod页面内容">5.修改三个pod页面内容</h2><h3 id="（1）查看一下pod信息">（1）查看一下pod信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108094953119.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108094953119.png" alt="image-20200108094953119"></a></p><h3 id="（2）修改POD页面内容（三台不一样）">（2）修改POD页面内容（三台不一样）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl exec -it xgp-web-8d5f9656f-8z7d9 /bin/bash<br>//根据pod名称进入pod之中<br></code></pre></td></tr></table></figure><h3 id="进入容器后修改页面内容">进入容器后修改页面内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">root@xgp-web-8d5f9656f-8z7d9:/usr/local/apache2# echo xgp-v1 &gt; htdocs/index.html <br>root@xgp-web-8d5f9656f-8z7d9:/usr/local/apache2# exit<br></code></pre></td></tr></table></figure><h3 id="访问一下-2">访问一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30123<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108095626532.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108095626532.png" alt="image-20200108095626532"></a></p><h1>二.分析一下k8s负载均衡原理</h1><h3 id="（1）查看service的暴露IP">（1）查看service的暴露IP</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108101539835.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108101539835.png" alt="image-20200108101539835"></a></p><h3 id="（2）查看一下iptabes规则">（2）查看一下iptabes规则</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# iptables-save <br>//查看已配置的规则<br></code></pre></td></tr></table></figure><blockquote><p>SNAT：Source NAT（源地址转换）</p><p>DNAT：Destination NAT（目标地址转换）</p><p>MASQ：动态的源地址转换</p></blockquote><h3 id="（3）根据service的暴露IP，查看对应的iptabes规则">（3）根据service的暴露IP，查看对应的iptabes规则</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# iptables-save | grep 10.107.119.49<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108101726315.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108101726315.png" alt="image-20200108101726315"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# iptables-save | grep KUBE-SVC-ESI7C72YHAUGMG5S<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108102003596.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108102003596.png" alt="image-20200108102003596"></a></p><h3 id="（4）对应一下IP是否一致">（4）对应一下IP是否一致</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# iptables-save | grep KUBE-SEP-ZHDQ73ZKUBMELLJB<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108102137062.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108102137062.png" alt="image-20200108102137062"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108102203144.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108102203144.png" alt="image-20200108102203144"></a></p><p><strong>Service实现的负载均衡：默认使用的是iptables规则。IPVS</strong></p><h1>三.回滚到指定版本</h1><h3 id="（1）删除之前创建的delpoy和service">（1）删除之前创建的delpoy和service</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl  delete -f xgp.yaml <br>[root@master ~]# kubectl  delete -f xgp-svc.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）准备三个版本所使用的私有镜像，来模拟每次升级不同的镜像">（2）准备三个版本所使用的私有镜像，来模拟每次升级不同的镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp1.yaml  （三个文件名不相同）<br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-web<br>spec:<br>  revisionHistoryLimit: 10<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v1  （三台版本不同）<br>        ports:<br>          - containerPort: 80<br></code></pre></td></tr></table></figure><p>此处3个yaml文件 指定不同版本的镜像</p><h3 id="（3）运行三个服务，并记录三个版本信息">（3）运行三个服务，并记录三个版本信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp-1.yaml --record <br>[root@master ~]# kubectl apply -f xgp-2.yaml --record <br>[root@master ~]# kubectl apply -f xgp-3.yaml --record<br></code></pre></td></tr></table></figure><h3 id="（4）查看有哪些版本信息">（4）查看有哪些版本信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment xgp-web<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108105842447.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108105842447.png" alt="image-20200108105842447"></a></p><h3 id="（5）运行之前的service文件">（5）运行之前的service文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp-svc.yaml<br></code></pre></td></tr></table></figure><h3 id="（6）查看service暴露端口">（6）查看service暴露端口</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110014614.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110014614.png" alt="image-20200108110014614"></a></p><h3 id="（7）测试访问">（7）测试访问</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30123<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110049396.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110049396.png" alt="image-20200108110049396"></a></p><h3 id="（8）回滚到指定版本">（8）回滚到指定版本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout undo deployment xgp-web --to-revision=1<br>//这里指定的是版本信息的编号<br></code></pre></td></tr></table></figure><h4 id="1-访问一下">&lt;1&gt;访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30123<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110337266.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110337266.png" alt="image-20200108110337266"></a></p><h4 id="2-查看有哪些版本信息">&lt;2&gt;查看有哪些版本信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment xgp-web<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110443558.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110443558.png" alt="image-20200108110443558"></a></p><p><em><strong>编号1已经被编号2替代，从而生的是一个新的编号4</strong></em></p><h1>四.用label控制pod的位置</h1><blockquote><p>默认情况下，scheduler会将pod调度到所有可用的Node，不过有些情况我们希望将 Pod 部署到指定的 Node，比如将有大量磁盘 I/O 的 Pod 部署到配置了 SSD 的 Node；或者 Pod 需要 GPU，需要运行在配置了 GPU 的节点上。</p><p>kubernetes通过label来实现这个功能</p><p>label 是 key-value 对，各种资源都可以设置 label，灵活添加各种<strong>自定义属性</strong>。比如执行如下命令标注 k8s-node1 是配置了 SSD 的节点</p></blockquote><h4 id="首先我们给node1节点打上一个ssd的标签">首先我们给node1节点打上一个ssd的标签</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl label nodes node02 disk=ssd<br></code></pre></td></tr></table></figure><h3 id="（1）查看标签">（1）查看标签</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get nodes --show-labels | grep node02<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108111354832.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108111354832.png" alt="image-20200108111354832"></a></p><h3 id="（2）删除副本一">（2）删除副本一</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl delete -f xgp-1.yaml <br>deployment.extensions "xgp-web" deleted<br>[root@master ~]# kubectl delete svc xgp-svc<br></code></pre></td></tr></table></figure><h3 id="（3）修改副本一的yaml文件">（3）修改副本一的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp-1.yaml <br><br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-web<br>spec:<br>  revisionHistoryLimit: 10<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v1<br>        ports:<br>          - containerPort: 80<br>      nodeSelector:    #添加节点选择器<br>        disk: ssd      #和标签内容一致<br></code></pre></td></tr></table></figure><h3 id="（4）执行一下">（4）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp-1.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-2">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108112059395.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108112059395.png" alt="image-20200108112059395"></a></p><p><em><strong>现在pod都在node02上运行</strong></em></p><h3 id="（5）删除标签">（5）删除标签</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl  label nodes node02 disk-<br></code></pre></td></tr></table></figure><h4 id="查看一下-3">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get nodes --show-labels | grep node02<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108112245347.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108112245347.png" alt="image-20200108112245347"></a></p><p><em><strong>没有disk标签了</strong></em></p><h1>五，小实验</h1><h3 id="1）使用私有镜像v1版本部署一个Deployment资源对象，要求副本Pod数量为3个，并创建一个Service资源对象相互关联，指定要求3个副本Pod全部运行在node01节点上，记录一个版本。"><strong>1）使用私有镜像v1版本部署一个Deployment资源对象，要求副本Pod数量为3个，并创建一个Service资源对象相互关联，指定要求3个副本Pod全部运行在node01节点上，记录一个版本。</strong></h3><h4 id="（1）用label控制pod的位置">（1）用label控制pod的位置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl label nodes node01 disk=ssd<br></code></pre></td></tr></table></figure><h4 id="（2）编写源yaml文件">（2）编写源yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp.yaml<br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-web<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v1<br>        ports:<br>          - containerPort: 80<br>      nodeSelector:    <br>        disk: ssd<br></code></pre></td></tr></table></figure><h4 id="（3）编写源service文件">（3）编写源service文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp-svc.yaml<br>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: xgp-svc<br>spec:<br>  type: NodePort<br>  selector:<br>    app: xgp-server<br>  ports:<br>    - protocol: TCP<br>      port: 80<br>      targetPort: 80<br>      nodePort: 30123<br></code></pre></td></tr></table></figure><h4 id="（4）执行yaml文件，创建控制器。执行service文件创建映射端口">（4）执行yaml文件，创建控制器。执行service文件创建映射端口</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f  xgp.yaml <br>[root@master ~]# kubectl apply -f xgp-svc.yaml<br></code></pre></td></tr></table></figure><h4 id="（5）查看一下pod节点">（5）查看一下pod节点</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108122424654.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108122424654.png" alt="image-20200108122424654"></a></p><h4 id="（6）记录一个版本">（6）记录一个版本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment xgp-web &gt; pod.txt<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108142016701.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108142016701.png" alt="image-20200108142016701"></a></p><h4 id="（7）访问一下">（7）访问一下</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108122518278.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108122518278.png" alt="image-20200108122518278"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108122534683.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108122534683.png" alt="image-20200108122534683"></a></p><h3 id="2）根据上述Deployment，升级为v2版本，记录一个版本。"><strong>2）根据上述Deployment，升级为v2版本，记录一个版本。</strong></h3><h4 id="（1）修改yaml文件镜像版本">（1）修改yaml文件镜像版本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp.yaml <br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-web<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v2    #修改版本为二<br>        ports:<br>          - containerPort: 80<br>      nodeSelector:<br>        disk: ssd<br></code></pre></td></tr></table></figure><h4 id="（2）刷新一下yaml文件">（2）刷新一下yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp.yaml --recore<br></code></pre></td></tr></table></figure><h4 id="（3）访问一下-3">（3）访问一下</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108141825924.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108141825924.png" alt="image-20200108141825924"></a></p><h4 id="（4）记录一个版本">（4）记录一个版本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout history deployment xgp-web &gt; pod.txt<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108142030157.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108142030157.png" alt="image-20200108142030157"></a></p><h3 id="3）最后升级到v3版本，这时，查看Service关联，并且分析访问流量的负载均衡详细情况。"><strong>3）最后升级到v3版本，这时，查看Service关联，并且分析访问流量的负载均衡详细情况。</strong></h3><h4 id="1）修改yaml文件镜像版本">1）修改yaml文件镜像版本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim xgp.yaml <br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp-web<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: xgp-server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v3   #修改版本为二<br>        ports:<br>          - containerPort: 80<br>      nodeSelector:<br>        disk: ssd<br></code></pre></td></tr></table></figure><h4 id="（2）刷新一下yaml文件-2">（2）刷新一下yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f xgp.yaml --recore<br></code></pre></td></tr></table></figure><h4 id="（3）访问一下-4">（3）访问一下</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108142329749.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108142329749.png" alt="image-20200108142329749"></a></p><h4 id="（5）分析访问流量的负载均衡详细情况">（5）分析访问流量的负载均衡详细情况</h4><h5 id="1-查看一下service映射端口">&lt;1&gt;查看一下service映射端口</h5><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108142504637.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108142504637.png" alt="image-20200108142504637"></a></p><h5 id="2-以ip为起点，分析访问流量的负载均衡详细情况">&lt;2&gt;以ip为起点，分析访问流量的负载均衡详细情况</h5><p><strong>Service实现的负载均衡：默认使用的是iptables规则。IPVS</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# iptables-save | grep 10.107.27.229<br>//根据service的暴露IP，查看对应的iptabes规则<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108143052433.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108143052433.png" alt="image-20200108143052433"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# iptables-save | grep KUBE-SVC-ESI7C72YHAUGMG5S<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108143359463.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108143359463.png" alt="image-20200108143359463"></a></p><p><em><strong>这里显示了各节点的负载比例</strong></em></p><h5 id="3-对应一下IP是否一致">&lt;3&gt;对应一下IP是否一致</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# iptables-save | grep KUBE-SEP-VDKW5WQIWOLZMJ6G<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108143547946.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108143547946.png" alt="image-20200108143547946"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108143608942.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108143608942.png" alt="image-20200108143608942"></a></p><h3 id="4）回滚到指定版本v1，并作验证。"><strong>4）回滚到指定版本v1，并作验证。</strong></h3><h4 id="1-回滚到指定版本">&lt;1&gt;回滚到指定版本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout undo deployment xgp-web --to-revision=1<br>//这里指定的是版本信息的编号<br></code></pre></td></tr></table></figure><h4 id="2-访问一下">&lt;2&gt;访问一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30123<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110337266.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200108110337266.png" alt="image-20200108110337266"></a></p><blockquote><p><strong>排错思路</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# less /var/log/messages  | grep kubelet<br>[root@master ~]# kubectl  logs -n  kube-system kube-scheduler-master <br>[root@master ~]# kubectl describe pod xgp-web-7d478f5bb7-bd4bj <br></code></pre></td></tr></table></figure></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;Deployment介绍&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Deployment是kubernetes 1.2引入的概念，用来解决Pod的编排问题。Deployment可以理解为RC的升级版（RC+Reolicat Set）。特点在于可以随时知道Pod的部署进度，即对Pod
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="service" scheme="https://wsdlxgp.top/tags/service/"/>
    
      <category term="Deployment" scheme="https://wsdlxgp.top/tags/Deployment/"/>
    
  </entry>
  
  <entry>
    <title>k8s创建资源(2)&lt;基于配置清单&gt;</title>
    <link href="https://wsdlxgp.top/posts/9569.html"/>
    <id>https://wsdlxgp.top/posts/9569.html</id>
    <published>2020-06-07T12:09:31.887Z</published>
    <updated>2020-06-07T14:35:40.122Z</updated>
    
    <content type="html"><![CDATA[<h1>一，两种创建资源的方法</h1><h2 id="1-基于命令的方式：">1. 基于命令的方式：</h2><ol><li><strong>简单直观快捷，上手快。</strong></li><li><strong>适合临时测试或实验。</strong></li></ol><h2 id="2-基于配置清单的方式：">2. 基于配置清单的方式：</h2><ol><li><strong>配置文件描述了 <code>What</code>，即应用最终要达到的状态。</strong></li><li><strong>配置文件提供了创建资源的模板，能够重复部署。</strong></li><li><strong>可以像管理代码一样管理部署。</strong></li><li><strong>适合正式的、跨环境的、规模化部署。</strong></li><li><strong>这种方式要求熟悉配置文件的语法，有一定难度。</strong></li></ol><h2 id="环境介绍">环境介绍</h2><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>k8s</td></tr><tr><td>node01</td><td>192.168.1.22</td><td>k8s</td></tr><tr><td>node02</td><td>192.168.1.23</td><td>k8s</td></tr></tbody></table><h1>二. 配置清单（yam，yaml）</h1><p><strong>在k8s中，一般使用yaml格式的文件来创建符合我们预期期望的pod，这样的yaml文件我们一般称为资源清单</strong></p><blockquote><p><strong>/etc/kubernetes/manifests/</strong> k8s存放（yam、yaml）文件的地方</p><p><strong>kubectl explain deployment（通过explain参数加上资源类别就能看到该资源应该怎么定义）</strong></p><p><strong>kubectl explain deployment.metadata</strong> 通过资源类别加上带有Object标记的字段，我们就可以看到一级字段下二级字段的内容有那些怎么去定义等</p><p><strong>kubectl explain deployment.metadata.ownerReferences</strong> 通过加上不同级别的字段名称来看下字段下的内容，而且前面的[]号代表对象列表</p></blockquote><h2 id="1-常见yaml文件写法，以及字段的作用">1.常见yaml文件写法，以及字段的作用</h2><p><strong>(1) apiVersion：api版本信息</strong></p><p><em><strong>（用来定义当前属于哪个组和那个版本，这个直接关系到最终提供使用的是那个版本）</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master manifests]# kubectl api-versions<br>//查看到当前所有api的版本<br></code></pre></td></tr></table></figure><p><strong>(2) kind: 资源对象的类别</strong></p><p><em><strong>(用来定义创建的对象是属于什么类别，是pod，service，还是deployment等对象，可以按照其固定的语法格式来自定义。)</strong></em><br><strong>(3) metadata: 元数据 名称字段（必写）</strong></p><blockquote><p><strong>提供以下几个字段</strong>：<br>　　<strong>creationTimestamp: &quot;2019-06-24T12:18:48Z&quot;</strong><br>　　<strong>generateName: myweb-5b59c8b9d-</strong><br>　　<strong>labels: （对象标签）</strong><br>　　　　<strong>pod-template-hash: 5b59c8b9d</strong><br>　　　　<strong>run: myweb</strong><br>　　<strong>name: myweb-5b59c8b9d-gwzz5 （pods对象的名称，同一个类别当中的pod对象名称是唯一的，不能重复）</strong><br>　　<strong>namespace: default （对象所属的名称空间，同一名称空间内可以重复，这个名称空间也是k8s级别的名称空间，不和容器的名称空间混淆）</strong><br>　　<strong>ownerReferences:</strong></p><p>- <strong>apiVersion: apps/v1</strong><br>　　　　<strong>blockOwnerDeletion: true</strong><br>　　　　<strong>controller: true</strong><br>　　　　<strong>kind: ReplicaSet</strong><br>　　　　<strong>name: myweb-5b59c8b9d</strong><br>　　　　<strong>uid: 37f38f64-967a-11e9-8b4b-000c291028e5</strong><br>　　<strong>resourceVersion: &quot;943&quot;</strong><br>　　<strong>selfLink: /api/v1/namespaces/default/pods/myweb-5b59c8b9d-gwzz5</strong><br>　　<strong>uid: 37f653a6-967a-11e9-8b4b-000c291028e5</strong><br>　　<strong>annotations（资源注解，这个需要提前定义，默认是没有的）</strong><br><strong>通过这些标识定义了每个资源引用的path：即/api/group/version/namespaces/名称空间/资源类别/对象名称</strong></p></blockquote><p><strong>(4) spec： 用户期望的状态</strong></p><p><em><strong>（这个字段最重要，因为spec是用来定义目标状态的‘disired state’，而且资源不通导致spec所嵌套的字段也各不相同，也就因为spec重要且字段不相同，k8s在内部自建了一个spec的说明用于查询）</strong></em></p><p><strong>(5) status：资源现在处于什么样的状态</strong></p><p><em><strong>（当前状态，’current state‘，这个字段有k8s集群来生成和维护，不能自定义，属于一个只读字段）</strong></em></p><h2 id="2-编写一个yaml文件">2.编写一个yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim web.yaml<br>kind: Deployment  #资源对象是控制器<br>apiVersion: extensions/v1beta1   #api的版本<br>metadata:      #描述kind（资源类型）<br>  name: web   #定义控制器名称<br>spec:<br>  replicas: 2   #副本数量<br>  template:     #模板<br>    metadata:    <br>      labels:   #标签<br>        app: web_server<br>    spec:<br>      containers:   #指定容器<br>      - name: nginx  #容器名称<br>        image: nginx   #使用的镜像<br></code></pre></td></tr></table></figure><h3 id="执行一下">执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f web.yaml<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments.  -o wide<br>//查看控制器信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107100450262.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107100450262.png" alt="image-20200107100450262"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br>//查看pod节点信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107101803209.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107101803209.png" alt="image-20200107101803209"></a></p><h2 id="3-编写一个service-yaml文件">3.编写一个service.yaml文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim web-svc.yaml<br>kind: Service  #资源对象是副本<br>apiVersion: v1   #api的版本<br>metadata:<br>  name: web-svc<br>spec:<br>  selector:     #标签选择器<br>    app: web-server  #须和web.yaml的标签一致<br>  ports:              #端口<br>  - protocol: TCP<br>    port: 80            #宿主机的端口<br>    targetPort: 80      #容器的端口<br></code></pre></td></tr></table></figure><blockquote><p><strong>使用相同标签和标签选择器内容，使两个资源对象相互关联。</strong></p><p><strong>创建的service资源对象，默认的type为ClusterIP，意味着集群内任意节点都可访问。它的作用是为后端真正服务的pod提供一个统一的接口。如果想要外网能够访问服务，应该把type改为NodePort</strong></p></blockquote><h3 id="（1）执行一下">（1）执行一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f web-svc.yaml<br></code></pre></td></tr></table></figure><h3 id="（2）查看一下">（2）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc<br>//查看控制器信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107110717972.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107110717972.png" alt="image-20200107110717972"></a></p><h3 id="（3）访问一下">（3）访问一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 10.111.193.168<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107110837353.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107110837353.png" alt="image-20200107110837353"></a></p><h2 id="4-外网能够访问服务">4.外网能够访问服务</h2><h3 id="（1）修改web-svc-yaml文件">（1）修改web-svc.yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">kind: Service  #资源对象是副本<br>apiVersion: v1   #api的版本<br>metadata:<br>  name: web-svc<br>spec:<br>  type: NodePort    #添加 更改网络类型<br>  selector:     #标签选择器<br>    app: web_server  #须和web.yaml的标签一致<br>  ports:              #端口<br>  - protocol: TCP<br>    port: 80            #宿主机的端口<br>    targetPort: 80      #容器的端口<br>    nodePort: 30086     #指定群集映射端口，范围是30000-32767<br></code></pre></td></tr></table></figure><h3 id="（2）刷新一下">（2）刷新一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]#  kubectl apply -f web-svc.yaml<br></code></pre></td></tr></table></figure><h3 id="（3）查看一下">（3）查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107111338940.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107111338940.png" alt="image-20200107111338940"></a></p><h3 id="（4）浏览器测试">（4）浏览器测试</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107111451952.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107111451952.png" alt="image-20200107111451952"></a></p><h1>三、小实验</h1><blockquote><p><strong>基于上一篇博客实验继续进行</strong></p></blockquote><h3 id="1-使用yaml文件的方式创建一个Deployment资源对象，要求镜像使用个人私有镜像v1版本。replicas为3个。">1.使用yaml文件的方式创建一个Deployment资源对象，要求镜像使用个人私有镜像v1版本。replicas为3个。</h3><h3 id="编写yaml文件">编写yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim www.yaml<br>kind: Deployment<br>apiVersion: extensions/v1beta1<br>metadata:<br>  name: xgp<br>spec:<br>  replicas: 3<br>  template:<br>    metadata:<br>      labels:<br>        app: www_server<br>    spec:<br>      containers:<br>      - name: web<br>        image: 192.168.1.21:5000/web:v1<br></code></pre></td></tr></table></figure><h4 id="（1）执行一下-2">（1）执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f web-svc.yaml<br></code></pre></td></tr></table></figure><h4 id="（2）查看一下-2">（2）查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br>//查看控制器信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107120901208.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107120901208.png" alt="image-20200107120901208"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br>//查看pod节点信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107121002152.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107121002152.png" alt="image-20200107121002152"></a></p><h4 id="（3）访问一下-2">（3）访问一下</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107121147669.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107121147669.png" alt="image-20200107121147669"></a></p><h3 id="2-使用yaml文件的方式创建一个Service资源对象，要与上述Deployment资源对象关联，type类型为：-NodePort，端口为-30123"><strong>2.</strong> 使用yaml文件的方式创建一个Service资源对象，要与上述Deployment资源对象关联，type类型为： NodePort，端口为:30123.</h3><h4 id="编写service文件">编写service文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# vim www-svc.yaml<br>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: www-svc<br>spec:<br>  type: NodePort<br>  selector:<br>    app: www_server<br>  ports:<br>  - protocol: TCP<br>    port: 80<br>    targetPort: 80<br>    nodePort: 30123<br></code></pre></td></tr></table></figure><h4 id="执行一下-2">执行一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl apply -f www-svc.yaml<br></code></pre></td></tr></table></figure><h4 id="查看一下-2">查看一下</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107121929525.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107121929525.png" alt="image-20200107121929525"></a></p><h4 id="访问一下">访问一下</h4><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107122015559.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200107122015559.png" alt="image-20200107122015559"></a></p><h1>四. 总结</h1><h2 id="1-Pod的作用"><strong>1. Pod的作用</strong></h2><blockquote><p>在k8s中pod是最小的管理单位，在一个pod中通常会包含一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。<br>在每一个Pod中都有一个特殊的Pause容器和一个或多个业务容器，Pause来源于pause-amd64镜像,Pause容器在Pod中具有非常重要的作用：</p><ul><li>Pause容器作为Pod容器的根容器，其本地于业务容器无关，它的状态代表了整个pod的状态。</li><li>Pod里的多个业务容器共享Pause容器的IP，每个Pod被分配一个独立的IP地址，Pod中的每个容器共享网络命名空间，包括IP地址和网络端口。Pod内的容器可以使用localhost相互通信。k8s支持底层网络集群内任意两个Pod之间进行通信。</li><li>Pod中的所有容器都可以访问共享volumes，允许这些容器共享数据。volumes还用于Pod中的数据持久化，以防其中一个容器需要重新启动而丢失数据。</li></ul></blockquote><h2 id="2-Service的作用"><strong>2. Service的作用</strong></h2><p><strong>Service 是后端真实服务的抽象，一个 Service 可以代表多个相同的后端服务</strong></p><p><strong>Service 为 POD 控制器控制的 POD 集群提供一个固定的访问端点，Service 的工作还依赖于 K8s 中的一个附件，就是 CoreDNS ，它将 Service 地址提供一个域名解析。</strong></p><h3 id="NodePort-类型的-service">NodePort 类型的 service</h3><blockquote><p><strong>clusterIP</strong>：指定 Service 处于 service 网络的哪个 IP，默认为动态分配</p><p><strong>NodePort 是在 ClusterIP 类型上增加了一个暴露在了 node 的网络命名空间上的一个 nodePort，所以用户可以从集群外部访问到集群了，因而用户的请求流程是：Client -&gt; NodeIP:NodePort -&gt; ClusterIP:ServicePort -&gt; PodIP:ContainerPort。</strong></p><p><strong>可以理解为 NodePort 增强了 ClusterIP 的功能，让客户端可以在每个集群外部访问任意一个 nodeip 从而访问到 clusterIP，再由 clusterIP 进行负载均衡至 POD。</strong></p></blockquote><h2 id="3-流量走向">3.流量走向</h2><p><strong>我们在创建完成一个服务之后，用户首先应该访问的是nginx反向代理的ip，然后通过nginx访问到后端的k8s服务器（master节点）的“NodePort暴露IP 及 映射的端口“，master的apiserver接受到客户端发送来的访问指令，将访问指令通知Controller Manager控制器，Scheduler执行调度任务，将访问指令分发到各节点之上，通过”master节点“的“ip+映射端口”访问到后端k8s节点的信息，节点的Kubelet（pod代理）当Scheduler确定让那个节点返回访问信息之后，kube-proxy将访问信息负载均衡到该节点的容器上，各容器返回信息，并向Master报告运行状态</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;一，两种创建资源的方法&lt;/h1&gt;
&lt;h2 id=&quot;1-基于命令的方式：&quot;&gt;1. 基于命令的方式：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;简单直观快捷，上手快。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;适合临时测试或实验。&lt;/strong&gt;&lt;/li&gt;
&lt;/
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="service" scheme="https://wsdlxgp.top/tags/service/"/>
    
      <category term="yaml" scheme="https://wsdlxgp.top/tags/yaml/"/>
    
  </entry>
  
  <entry>
    <title>k8s创建资源(1)、&lt;扩容与缩容&gt;和&lt;升级与回滚&gt;</title>
    <link href="https://wsdlxgp.top/posts/dbea.html"/>
    <id>https://wsdlxgp.top/posts/dbea.html</id>
    <published>2020-06-07T12:09:29.666Z</published>
    <updated>2020-06-07T14:35:40.118Z</updated>
    
    <content type="html"><![CDATA[<h1>两种创建资源的方法</h1><h2 id="基于命令的方式：">基于命令的方式：</h2><ol><li><strong>简单直观快捷，上手快。</strong></li><li><strong>适合临时测试或实验。</strong></li></ol><h2 id="基于配置文件的方式：">基于配置文件的方式：</h2><ol><li><strong>配置文件描述了 <code>What</code>，即应用最终要达到的状态。</strong></li><li><strong>配置文件提供了创建资源的模板，能够重复部署。</strong></li><li><strong>可以像管理代码一样管理部署。</strong></li><li><strong>适合正式的、跨环境的、规模化部署。</strong></li><li><strong>这种方式要求熟悉配置文件的语法，有一定难度。</strong></li></ol><h1>一，用命令行的方式创建资源</h1><table><thead><tr><th>主机</th><th>IP地址</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td></tr><tr><td>node01</td><td>192.168.1.22</td></tr><tr><td>node02</td><td>192.168.1.23</td></tr></tbody></table><h3 id="仅接受json格式"><em>仅接受json格式</em></h3><h2 id="配置清单（yml、yaml）">配置清单（yml、yaml）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# cd /etc/kubernetes/manifests/<br>//k8s的yml、yaml文件<br></code></pre></td></tr></table></figure><h2 id="1-node01和node02下载nginx镜像">1.node01和node02下载nginx镜像</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">docker pull nginx<br>//下载nginx镜像<br></code></pre></td></tr></table></figure><h2 id="2-master创建Pod控制器（test-web），deployment">2.master创建Pod控制器（test-web），deployment</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl run test-web --image=nginx --replicas=5<br>//创建Pod控制器，deployment<br></code></pre></td></tr></table></figure><h2 id="3-查看控制器情况">3.查看控制器情况</h2><h3 id="（1）">（1）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments.<br>//查看控制器情况<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106093615852.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106093615852.png" alt="image-20200106093615852"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod --all-namespaces -o wide<br>//显示pod的节点信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106093922849.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106093922849.png" alt="image-20200106093922849"></a></p><h3 id="（2）">（2）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get namespaces <br>//查看k8s名称空间<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106093850247.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106093850247.png" alt="image-20200106093850247"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl describe deployments. test-web<br>//查看资源详细信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106093723330.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106093723330.png" alt="image-20200106093723330"></a></p><p><em><strong>查看某种资源对象，没有指定名称空间，默认是在default名称空间。可以加上-n选项，查看指定名称空间的资源。</strong></em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -n kube-system<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106094343401.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106094343401.png" alt="image-20200106094343401"></a></p><h2 id="3-删除test-web控制器">3.删除test-web控制器</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl delete deployments. test-web<br></code></pre></td></tr></table></figure><h2 id="4-master创建Pod控制器（web），deployment">4.master创建Pod控制器（web），deployment</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl run web --image=nginx --replicas=5<br></code></pre></td></tr></table></figure><h3 id="查看一下pod信息">查看一下pod信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get pod -o wide<br>//查看一下pod的节点信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106095722353.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106095722353.png" alt="image-20200106095722353"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl describe deployments. web <br>//查看资源详细信息<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106100606861.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106100606861.png" alt="image-20200106100606861"></a></p><p><em><strong>注意：直接运行创建的deployment资源对象，是经常使用的一个控制器资源类型，除了deployment，还有rc、rs等等pod控制器，deployment是一个高级的pod控制器。</strong></em></p><h3 id="本机测试访问nginx">本机测试访问nginx</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 10.244.1.7<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106100827131.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106100827131.png" alt="image-20200106100827131"></a></p><h2 id="5-创建service资源类型">5.创建service资源类型</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl expose deployment web --name=web-xgp --port=80 --type=NodePort<br>//创建service资源类型，这里我们设置了映射端口<br></code></pre></td></tr></table></figure><p><em><strong>如果想要外网能够访问服务，可以暴露deployment资源，得到service资源，但svc资源的类型必须为NodePort。</strong></em></p><p><strong>映射端口范围：30000-32767</strong></p><h3 id="查看service信息">查看service信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106101443348.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106101443348.png" alt="image-20200106101443348"></a></p><h3 id="浏览器测试访问http-192-168-1-21-30493">浏览器测试访问http://192.168.1.21:30493/</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106101624954.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106101624954.png" alt="image-20200106101624954"></a></p><h1>二、服务的扩容与缩容</h1><h2 id="1-查看控制器信息">1. 查看控制器信息</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106104638757.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106104638757.png" alt="image-20200106104638757"></a></p><h2 id="2-扩容">2.扩容</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl scale deployment web --replicas=8<br></code></pre></td></tr></table></figure><h3 id="查看一下">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106104757123.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106104757123.png" alt="image-20200106104757123"></a></p><h2 id="3-缩容">3.缩容</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl scale deployment web --replicas=4<br></code></pre></td></tr></table></figure><h3 id="查看一下-2">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106105536316.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106105536316.png" alt="image-20200106105536316"></a></p><h2 id="3-通过修改web的yaml文件进行扩容缩容">3.通过修改web的yaml文件进行扩容缩容</h2><h3 id="备份web的yaml文件">备份web的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o yaml &gt; web.yaml<br></code></pre></td></tr></table></figure><h3 id="使用edit修改web的yaml文件">使用edit修改web的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl edit deployments. web<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106105924531.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106105924531.png" alt="image-20200106105924531"></a></p><h3 id="查看一下-3">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106105816339.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106105816339.png" alt="image-20200106105816339"></a></p><h1>三、服务的升级与回滚</h1><h2 id="node01和node02下载1-15版本的nginx">node01和node02下载1.15版本的nginx</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# docker pull nginx:1.15<br></code></pre></td></tr></table></figure><h2 id="1-master设置服务升级">1.master设置服务升级</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]#  kubectl set image deployment web web=nginx:1.15<br></code></pre></td></tr></table></figure><h3 id="查看一下-4">查看一下</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106111227960.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106111227960.png" alt="image-20200106111227960"></a></p><h2 id="2-master设置服务回滚">2.master设置服务回滚</h2><h3 id="（1）修改配置文件回滚">（1）修改配置文件回滚</h3><h3 id="使用edit修改web的yaml文件-2">使用edit修改web的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl edit deployments. web<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106111523148.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106111523148.png" alt="image-20200106111523148"></a></p><h3 id="查看一下-5">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106111319699.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106111319699.png" alt="image-20200106111319699"></a></p><h3 id="（2）命令回滚">（2）命令回滚</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout undo deployment web<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106111733617.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106111733617.png" alt="image-20200106111733617"></a></p><p><em><strong>注意:只能回滚到上一次操作的状态</strong></em></p><h1>四、实验环境</h1><table><thead><tr><th>主机</th><th>IP地址</th><th>服务</th></tr></thead><tbody><tr><td>master</td><td>192.168.1.21</td><td>registry+Deployment</td></tr><tr><td>node01</td><td>192.168.1.22</td><td></td></tr><tr><td>node02</td><td>192.168.1.23</td><td></td></tr></tbody></table><h2 id="1-master-基于httpd制作自己的镜像，需要3个版本，v1-v2-v3-并且对应的版本镜像，访问的主目录内容不一样">1.master 基于httpd制作自己的镜像，需要3个版本，v1,v2,v3.并且对应的版本镜像，访问的主目录内容不一样</h2><h3 id="（1）master下载httpd镜像">（1）master下载httpd镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# docker pull httpd<br></code></pre></td></tr></table></figure><h3 id="（2）编写Dockerfile">（2）编写Dockerfile</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# vim Dockerfile<br>FROM httpd<br>COPY index.html /usr/local/apache2/htdocs/index.html<br></code></pre></td></tr></table></figure><h3 id="（3）创建测试网页v1">（3）创建测试网页v1</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]#echo "&lt;h1&gt;xgp | test-web | httpd:v1&lt;h1&gt;" &gt; index.html<br></code></pre></td></tr></table></figure><h3 id="（4）基于Dockerfile创建镜像-web1">（4）基于Dockerfile创建镜像 web1</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# docker build -t web1 .<br></code></pre></td></tr></table></figure><h3 id="（5）创建测试网页v2">（5）创建测试网页v2</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]#echo "&lt;h1&gt;xgp | test-web | httpd:v1&lt;h1&gt;" &gt; index.html<br></code></pre></td></tr></table></figure><h3 id="（6）基于Dockerfile创建镜像-web2">（6）基于Dockerfile创建镜像 web2</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# docker build -t web2 .<br></code></pre></td></tr></table></figure><h3 id="（7）创建测试网页v3">（7）创建测试网页v3</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# echo "&lt;h1&gt;xgp | test-web | httpd:v3&lt;h1&gt;" &gt; index.html<br></code></pre></td></tr></table></figure><h3 id="（8）基于Dockerfile创建镜像-web3">（8）基于Dockerfile创建镜像 web3</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# docker build -t web3 .<br></code></pre></td></tr></table></figure><h2 id="2-master部署私有仓库">2.master部署私有仓库</h2><h3 id="（1）master下载registry镜像">（1）master下载registry镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# docker pull registry<br></code></pre></td></tr></table></figure><h3 id="（2）启动registry">（2）启动registry</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# docker run -itd --name registry -p 5000:5000 --restart=always registry:latest<br></code></pre></td></tr></table></figure><h3 id="（3）修改docker配置文件，加入私有仓库（三台）">（3）修改docker配置文件，加入私有仓库（三台）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# vim /usr/lib/systemd/system/docker.service<br>ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.21:5000<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106120848869.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106120848869.png" alt="image-20200106120848869"></a></p><h3 id="（4）重启docker（三台）">（4）重启docker（三台）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# systemctl daemon-reload <br>[root@master xgp]# systemctl restart docker<br></code></pre></td></tr></table></figure><h2 id="3-上传之前创建的三个web镜像到私有仓库">3.上传之前创建的三个web镜像到私有仓库</h2><h3 id="（1）修改镜像标签">（1）修改镜像标签</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# docker tag web1:latest 192.168.1.21:5000/web1:latest<br>[root@master xgp]# docker tag web2:latest 192.168.1.21:5000/web2:latest<br>[root@master xgp]# docker tag web3:latest 192.168.1.21:5000/web3:latest<br></code></pre></td></tr></table></figure><h3 id="（2）将三个web镜像上传到私有仓库">（2）将三个web镜像上传到私有仓库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# docker push  192.168.1.21:5000/web1:latest <br>[root@master xgp]# docker push  192.168.1.21:5000/web2:latest<br>[root@master xgp]# docker push  192.168.1.21:5000/web3:latest<br></code></pre></td></tr></table></figure><h2 id="4-部署一个Deployment资源对象，要求镜像使用上述私有镜像v1版本。6个副本Pod。">4.部署一个Deployment资源对象，要求镜像使用上述私有镜像v1版本。6个副本Pod。</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl run www1 --image=192.168.1.21:5000/web1:latest --replicas=6<br></code></pre></td></tr></table></figure><h3 id="查看一下-6">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl get pod<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122026271.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122026271.png" alt="image-20200106122026271"></a></p><h3 id="本地访问一下">本地访问一下</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122426308.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122426308.png" alt="image-20200106122426308"></a></p><h3 id="5-将上述Deployment暴露一个service资源对象，使外网能否访问服务。">5.将上述Deployment暴露一个service资源对象，使外网能否访问服务。</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]#  kubectl expose deployment www1 --name=web-xgp --port=80 --type=NodePort<br></code></pre></td></tr></table></figure><h3 id="查看一下-7">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl get svc<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122313996.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122313996.png" alt="image-20200106122313996"></a></p><h3 id="浏览器访问一下">浏览器访问一下</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122340747.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122340747.png" alt="image-20200106122340747"></a></p><h2 id="6-将上述Deployment进行扩容和缩容操作，扩容为8个副本Pod，然后缩容为4个副本Pod。">6.将上述Deployment进行扩容和缩容操作，扩容为8个副本Pod，然后缩容为4个副本Pod。</h2><h2 id="（1）扩容">（1）扩容</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl scale deployment www1 --replicas=8<br></code></pre></td></tr></table></figure><h3 id="查看一下-8">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122722977.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122722977.png" alt="image-20200106122722977"></a></p><h2 id="（2）缩容">（2）缩容</h2><h3 id="修改k8s配置文件">修改k8s配置文件</h3><h3 id="备份web的yaml文件-2">备份web的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o yaml &gt; www1.yaml<br></code></pre></td></tr></table></figure><h3 id="使用edit修改web的yaml文件-3">使用edit修改web的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl edit deployments. www1<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106105924531.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106105924531.png" alt="image-20200106105924531"></a></p><h3 id="查看一下-9">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master xgp]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122953397.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106122953397.png" alt="image-20200106122953397"></a></p><h2 id="7-将上述Deployment进行升级与回滚操作，将v1版本，升级到v2版本。">7.将上述Deployment进行升级与回滚操作，将v1版本，升级到v2版本。</h2><h2 id="（1）升级版本为web2">（1）升级版本为web2</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl set image deployment www1 www1=192.168.1.21:5000/web2<br></code></pre></td></tr></table></figure><h3 id="本机测试访问">本机测试访问</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# curl 127.0.0.1:30996<br>&lt;h1&gt;xgp | test-web | httpd:v2&lt;h1&gt;<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106125722931.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106125722931.png" alt="image-20200106125722931"></a></p><h3 id="浏览器测试访问">浏览器测试访问</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106125750021.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106125750021.png" alt="image-20200106125750021"></a></p><h2 id="（2）回滚版本到web1">（2）回滚版本到web1</h2><h3 id="1-修改配置文件回滚">&lt;1&gt;修改配置文件回滚</h3><h3 id="使用edit修改web的yaml文件-4">使用edit修改web的yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl edit deployments. www1<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130010344.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130010344.png" alt="image-20200106130010344"></a></p><h3 id="查看一下-10">查看一下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl get deployments. -o wide<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130304423.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130304423.png" alt="image-20200106130304423"></a></p><h3 id="访问一下">访问一下</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130435212.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130435212.png" alt="image-20200106130435212"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130447693.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130447693.png" alt="image-20200106130447693"></a></p><h3 id="2-命令回滚">&lt;2&gt;命令回滚</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@master ~]# kubectl rollout undo deployment www1<br></code></pre></td></tr></table></figure><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130317956.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130317956.png" alt="image-20200106130317956"></a></p><p><em><strong>注意:只能回滚到上一次操作的状态</strong></em></p><h3 id="访问一下-2">访问一下</h3><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130357339.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130357339.png" alt="image-20200106130357339"></a></p><p><a href="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130414060.png" target="_blank" rel="noopener"><img src="http://xgp-cunchu.test.upcdn.net/k8s/image-20200106130414060.png" alt="image-20200106130414060"></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;两种创建资源的方法&lt;/h1&gt;
&lt;h2 id=&quot;基于命令的方式：&quot;&gt;基于命令的方式：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;简单直观快捷，上手快。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;适合临时测试或实验。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://wsdlxgp.top/categories/Kubernetes/"/>
    
    
      <category term="deployments" scheme="https://wsdlxgp.top/tags/deployments/"/>
    
      <category term="registry" scheme="https://wsdlxgp.top/tags/registry/"/>
    
  </entry>
  
</feed>
