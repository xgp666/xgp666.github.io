{"meta":{"title":"Xgp & Blog","subtitle":"Today is still beautiful","description":"Small steel gun article","author":"Wu Shao Dong","url":"https://wsdlxgp.top","root":"/"},"pages":[{"title":"可爱的我","text":"","path":"about/index.html","date":"05-30","excerpt":""},{"title":"网站感想","text":"","path":"about/site.html","date":"05-30","excerpt":""},{"title":"categories","text":"","path":"categories/index.html","date":"03-11","excerpt":""},{"title":"contact","text":"","path":"contact/index.html","date":"03-30","excerpt":""},{"title":"链接","text":"","path":"link/index.html","date":"06-08","excerpt":""},{"title":"","text":"/* Name: Kimbie (dark) Author: Jan T. Sott License: Creative Commons Attribution-ShareAlike 4.0 Unported License URL: https://github.com/idleberg/Kimbie-highlight.js */ /* 新添加的内容 */ /* ------------------------------------- */ /* 代码框背景色和字体顔色,与hljs一样就行 */ /* 必须配置(把下面.hljs的color和background复製到这里来) */ #article-container pre, #article-container figure.highlight { background: #221a0f; color: #d3af86 } /* 代码框工具栏 (如果你关掉了copy、lang和shrink,可不用配置这个 */ #article-container figure.highlight .highlight-tools { color: #fff; background: #321a0f } /* 代码框行数(如果已经关掉line_number,可以不用配置这个) */ #article-container figure.highlight .gutter pre { background-color: #221a0f; color: #fff } /* 代码块figcaption配置(hexo自带标签https://hexo.io/zh-tw/docs/tag-plugins.html#Code-Block) */ /* 不需要可以不用配置这个 */ #article-container figure.highlight figcaption a { color: #d3af86 !important } /* ------------------------------------- */ /* Kimbie Comment */ .hljs-comment, .hljs-quote { color: #d6baad; } /* Kimbie Red */ .hljs-variable, .hljs-template-variable, .hljs-tag, .hljs-name, .hljs-selector-id, .hljs-selector-class, .hljs-regexp, .hljs-meta { color: #dc3958; } /* Kimbie Orange */ .hljs-number, .hljs-built_in, .hljs-builtin-name, .hljs-literal, .hljs-type, .hljs-params, .hljs-deletion, .hljs-link { color: #f79a32; } /* Kimbie Yellow */ .hljs-title, .hljs-section, .hljs-attribute { color: #f06431; } /* Kimbie Green */ .hljs-string, .hljs-symbol, .hljs-bullet, .hljs-addition { color: #889b4a; } /* Kimbie Purple */ .hljs-keyword, .hljs-selector-tag, .hljs-function { color: #98676a; } /* 更改的内容 把.hljs改为 #article-container figure.highlight .hljs *、 /* ------------------------------------- */ #article-container figure.highlight .hljs { display: block; overflow-x: auto; background: #221a0f; color: #d3af86; padding: 0.5em; } .hljs-emphasis { font-style: italic; } .hljs-strong { font-weight: bold; }","path":"self/Kimbiedark.css","date":"06-30","excerpt":""},{"title":"tags","text":"","path":"tags/index.html","date":"03-11","excerpt":""},{"title":"","text":"!function(){ var userAgentInfo = navigator.userAgent; var Agents = [\"iPad\", \"iPhone\", \"Android\", \"SymbianOS\", \"Windows Phone\", \"iPod\", \"webOS\", \"BlackBerry\", \"IEMobile\"]; for (var v = 0; v < Agents.length; v++) { if (userAgentInfo.indexOf(Agents[v]) > 0) { return; } } function o(w,v,i){return w.getAttribute(v)||i}function j(i){return document.getElementsByTagName(i)}function l(){var i=j(\"script\"),w=i.length,v=i[w-1];return{l:w,z:o(v,\"zIndex\",-1),o:o(v,\"opacity\",0.5),c:o(v,\"color\",\"0,0,0\"),n:o(v,\"count\",99)}}function k(){r=u.width=window.innerWidth||document.documentElement.clientWidth||document.body.clientWidth,n=u.height=window.innerHeight||document.documentElement.clientHeight||document.body.clientHeight}function b(){e.clearRect(0,0,r,n);var w=[f].concat(t);var x,v,A,B,z,y;t.forEach(function(i){i.x+=i.xa,i.y+=i.ya,i.xa*=i.x>r||i.xn||i.y","path":"lib/canvas-nest/canvas-nest-nomobile.min.js","date":"03-28","excerpt":""},{"title":"","text":"Theme NexT Canvas Nest canvas-nest.js for NexT. Install Step 1 → Go to Hexo dir Change dir to Hexo directory. There must be scaffolds, source, themes and other directories: 123$ cd hexo$ lsscaffolds source themes _config.yml package.json Step 2 → Create footer.swig Create a file named footer.swig in hexo/source/_data directory (create _data directory if it does not exist). Edit this file and add the following content: 1&lt;script color=\"0,0,255\" opacity=\"0.5\" zIndex=\"-1\" count=\"99\" src=\"https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\"&gt;&lt;/script&gt; You can customize these options. Step 3 → Set it up In the NexT _config.yml, uncomment footer under the custom_file_path section. 12345678910111213# Define custom file paths.# Create your custom files in site directory `source/_data` and uncomment needed files below.custom_file_path: #head: source/_data/head.swig #header: source/_data/header.swig #sidebar: source/_data/sidebar.swig #postMeta: source/_data/post-meta.swig #postBodyEnd: source/_data/post-body-end.swig footer: source/_data/footer.swig #bodyEnd: source/_data/body-end.swig #variable: source/_data/variables.styl #mixin: source/_data/mixins.styl #style: source/_data/styles.styl","path":"lib/canvas-nest/README.html","date":"03-28","excerpt":""},{"title":"","text":"!function(){function o(w,v,i){return w.getAttribute(v)||i}function j(i){return document.getElementsByTagName(i)}function l(){var i=j(\"script\"),w=i.length,v=i[w-1];return{l:w,z:o(v,\"zIndex\",-1),o:o(v,\"opacity\",0.5),c:o(v,\"color\",\"0,0,0\"),n:o(v,\"count\",99)}}function k(){r=u.width=window.innerWidth||document.documentElement.clientWidth||document.body.clientWidth,n=u.height=window.innerHeight||document.documentElement.clientHeight||document.body.clientHeight}function b(){e.clearRect(0,0,r,n);var w=[f].concat(t);var x,v,A,B,z,y;t.forEach(function(i){i.x+=i.xa,i.y+=i.ya,i.xa*=i.x>r||i.xn||i.y","path":"lib/canvas-nest/canvas-nest.min.js","date":"03-28","excerpt":""}],"posts":[{"title":"131","text":"一、 安装 apache2.4.23 新版本的 httpd-2.4 新增以下特性；新增模块； mod_proxy_fcgi(可提供 fcgi 代理） mod_ratelimit（限制用户带宽） mod_request（请求模块，对请求做过滤） mod_remoteip（匹配客户端的 IP 地址） 对于基于 IP 的访问控制做了修改，不再支持 allow,deny,order 机制，而是统一使用 requ进行 还新增以下几条新特性； MPM 支持在运行时装载;不过要开启这种特性，在编译安装要启用这三种功能； –enable-mpms-shared=all --with-mpm=event 支持 event 支持异步读写 在每个模块及每个目录上指定日志级别 增强版的表达式分析器 每请求配置： , 毫秒级别的 keepalive timeout 基于 FQDN 的虚拟主机不再需要 NameVirtualHost 指令 支持使用自定义变量 安装环境：操作系统： Centos7.2，关闭 selinux 检查 httpd 包是否安装，如查安装则卸载 1[root@www ~]# rpm -q httpd 1、 安装 apache2.4.23 下载源码包： httpd-2.4.23.tar.gz apr-1.7.0.tar.gz apr-util-1.6.1.tar.gz zlib-1.2.11.tar.gz pcre-8.44.tar.gz openssl-1.1.1g.tar.gz 123456789[root@www ~]# hostnamectl set-hostname www[root@www ~]# su -[root@www ~]# cd /usr/local/src/[root@www src]# wget https://mirror.bit.edu.cn/apache//httpd/httpd-2.4.43.tar.gz[root@www src]# wget https://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-1.7.0.tar.gz[root@www src]# wget https://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-util-1.6.1.tar.gz[root@www src]# wget http://zlib.net/zlib-1.2.11.tar.gz[root@www src]# wget https://ftp.pcre.org/pub/pcre/pcre-8.44.tar.gz[root@www src]# wget https://www.openssl.org/source/openssl-1.1.1g.tar.gz （1）安装 apr 和 apr-util 1234567891011121314151617[root@www src]# tar zxf apr-1.7.0.tar.gz [root@www src]# cd apr-1.7.0/[root@www apr-1.7.0]# ./configure --prefix=/usr/local/apr &amp;&amp; make &amp;&amp; make install[root@www apr-1.7.0]# cd ..[root@www src]# tar zxf apr-util-1.6.1.tar.gz [root@www src]# cd apr-util-1.6.1/[root@www apr-util-1.6.1]# ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr &amp;&amp; make &amp;&amp; make installxml/apr_xml.c:35:19: 致命错误：expat.h：没有那个文件或目录 #include &lt;expat.h&gt; ^编译中断。make[1]: *** [xml/apr_xml.lo] 错误 1make[1]: 离开目录“/usr/local/src/apr-util-1.6.1”make: *** [all-recursive] 错误 1[root@www apr-util-1.6.1]# yum -y install expat-devel[root@www apr-util-1.6.1]# ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr &amp;&amp; make &amp;&amp; make install （2）安装 zlib 1234[root@www apr-util-1.6.1]# cd ..[root@www src]# tar zxf zlib-1.2.11.tar.gz [root@www src]# cd zlib-1.2.11/[root@www zlib-1.2.11]# ./configure --prefix=/usr/local/zlib &amp;&amp; make&amp;&amp; make install （3）安装 pcre 1234[root@www zlib-1.2.11]# cd ..[root@www src]# tar zxf pcre-8.44.tar.gz [root@www src]# cd pcre-8.44/[root@www pcre-8.44]# ./configure --prefix=/usr/local/pcre &amp;&amp; make &amp;&amp; make install （4）安装 openssl 安装 apache2.4.23 时提示 openssl 版本过低， centos7 自带版本 openssl-1.0.1e 1234567[root@www pcre-8.44]# cd ..[root@www src]# tar zxf openssl-1.1.1g.tar.gz [root@www src]# cd openssl-1.1.1g/[root@www openssl-1.1.1g]# ./config -fPIC --prefix=/usr/local/openssl enable-shared &amp;&amp; make &amp;&amp; make install[root@www httpd-2.4.43]# rpm -qa| grep openssl[root@www openssl-1.1.1g]# mv /usr/bin/openssl /usr/bin/openssl.1.0.1e[root@www openssl-1.1.1g]# ln -s /usr/local/openssl /usr/bin/openssl （5）安装 apache 12345[root@www src]# tar zxf httpd-2.4.43.tar.gz [root@www src]# cd httpd-2.4.43/[root@www httpd-2.4.43]# ./configure --help//查看安装的参数[root@www httpd-2.4.23]# ./configure --prefix=/usr/local/http-2.4.23 --enable-modules=most --enable-so --enable-cgi --enable-cgid --enable-ssl --with-ssl=/usr/local/openssl --enable-rewrite --with-pcre=/usr/local/pcre --with-z=/usr/local/zlib --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --enable-mods-shared=most --enable-mpms-shared=all --with-mpm=event --enable-proxy --enable-proxy-fcgi --enable-expires --enable-deflate 相关参数解释： –enable-so：支持动态共享模块（即打开 DSO 支持） –enable-rewrite：支持 url 重写 –enable-ssl：支持 ssl –with-ssl=/usr/local/openssl:指定 ssl 安装位置 –enable-cgi：启用 cgi –enable-cgid:MPM 使用的是 event 或 worker 要启用 cgid –enable-modules=most:明确指明要静态编译到 httpd 二进制文件的模块， 为空格分隔的模块名列表、 all 或者 most， all 表示包含所有模块， most 表示包含大部分常用模块 –enable-mods-shared=most:明确指明要以 DSO 方式编译的模块， 为空格分隔的模块名列表、 all 或者 most， all 表示包含所有模 块， most 表示包含大部分模块 –enable-mpms-shared=all:启用 MPM 所有支持的模式，这样 event、 worker、 prefork 就会以模块化的方式安装，要用哪个就在 httpd.conf 里配置就好了。 –with-mpm=event:指定启用的 mpm 模式， 默认使用 enevt 模式， 在 apache 的早期版本 2.0默认 prefork,2.2 版本是 worker， 2.4 版本是 event. –with-pcre=/usr/local/pcre:支持 pcre –with-z=/usr/local/zlib:使用 zlib 压缩库 –with-apr=/usr/local/apr:指定 apr 的安装路径 –with-apr-util=/usr/local/apr-util:指定 apr-util 的安装路径 –enable-expires:激活彧通过配置文件控制 HTTP 的“Expires:”和“Cache-Control:”头内容，即对网站图片、 js、 css 等内容，提供客户端浏览器缓存的设置。这个是 apache 调优的一个重要选项之一。 –enable-deflate:提供对内容的压缩传输编码支持，一般是 html、 js、 css 等内容的站点。使用此参数会打打提高传输速度，提升访问者访问的体验。在生产环境中，这是 apache 调优的一个重要选项之一。 1[root@www httpd-2.4.23]# make &amp;&amp; make install 优化 http 程序执行路径 1[root@www httpd-2.4.23]# ln -s /usr/local/http-2.4.23/bin/* /usr/local/bin/ 修改配置文件 httpd.conf，设置其中的 ServerName 值 12[root@www httpd-2.4.43]# vim /usr/local/http-2.4.23/conf/httpd.confServerName www.example.com:80 #203取消注释 2、开启 apache 服务器： 12[root@www httpd-2.4.43]# /usr/local/http-2.4.23/bin/apachectl starthttpd (pid 75297) already running （1）开机后自动启动 1[root@www httpd-2.4.43]# cp /usr/local/http-2.4.23/bin/apachectl /etc/init.d/httpd 编辑 /etc/init.d/httpd 文件，在首行 #!/bin/sh 下面加入两行： 123[root@www httpd-2.4.23]# vi /etc/init.d/httpd# chkconfig: 35 85 15 （在 3 和 5 启动模式下的--启动优先级）# description: apache 2.4.23 （2）将 Apache 加入开机自动启动 12[root@www httpd-2.4.23]# chkconfig --add httpd[root@www httpd-2.4.23]# chkconfig httpd on 启动编译好的 Apache 2.4.23： 123[root@www httpd-2.4.23]# service httpd start[root@www httpd-2.4.23]# netstat -anplt | grep 80tcp6 0 0 :::80 :::* LISTEN 4807/httpd （3）客户端测试访问（注意防火墙）","path":"posts/eb84.html","date":"07-08","excerpt":"","tags":[]},{"title":"130 httpd","text":"/fiddler_cn.rar 下载fiddler抓包工具 123456[root@www ~]# hostnamectl set-hostname www[root@www ~]# su -[root@www~]# yum -y install httpd//安装httpd[root@www ~]# systemctl start httpd//启动httpd 给本机防火墙开放80端口 12[root@www ~]# firewall-cmd --add-port=80/tcp --permanent[root@www ~]# firewall-cmd --add-port=80/tcp 访问一下 小练习 部署一个web （nginx、apache） （1）安装nginx依赖库 1[root@www ~]# yum -y install gcc pcre-devel zlib-devel openssl openssl-devel （2）解压安装 123456[root@www ~]# tar zxf nginx-1.2.4.tar.gz[root@www ~]# cd nginx-1.2.4/[root@www ~]# ./configure --prefix=/usr/local/nginx &amp;&amp; make &amp;&amp; make install//编译安装[root@www nginx-1.2.4]# ln -s /usr/local/nginx/sbin/nginx /usr/local/bin///配置下的目录做软链接 （3）启动nginx 1[root@www ~]# nginx 重启： 1[root@www ~]# nginx -s reload 测试nginx文件： 123[root@www ~]# nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful （4）编写页面 1[root@www ~]# vim /usr/local/nginx/html/test.html marydb your name: your password: L2Dwidget.init({\"log\":false,\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"pluginRootPath\":\"live2dw/\",\"tagMode\":false}); ![image-20200708145509971](E:\\软件\\博客\\Blog\\blog\\source_posts\\130 httpd.assets\\image-20200708145509971.png) 一次 Web 资源请求的具体过程 客户端在 Web 浏览器输入需要访问的地址 Web 浏览器会请求 DNS 服务器，查询解析到指定域名和 Web 服务器的地址 客户端与请求的 Web 服务器端建立连接（TCP 三次握手） TCP 建立成功之后，发起 HTTP 请求 服务器端收到客户端 HTTP 请求之后，会处理该请求 处理客户端指定请求的资源 服务器构建响应报文，响应给客户端 服务器端将此信息记录到日志中","path":"posts/fb33.html","date":"07-08","excerpt":"","tags":[]},{"title":"MySQL高可用之MHA+keepalived/脚本启动虚拟ip","text":"一、配置VIP： vip配置可以采用两种方式 一种通过keepalived的方式管理虚拟ip的浮动； 另外一种通过脚本方式启动虚拟ip的方式（即不需要keepalived或者heartbeat类似的软件）。 1、keepalived方式管理虚拟ip keepalived配置方法如下： 下载软件进行并进行安装 （两台master，准确的说一台是master，另外一台是备选master，在没有切换以前是slave） （1）在masterB和mysqlD上安装软件包keepalived 获取keepalived的安装包 1[root@masterA ~]# wget https://www.keepalived.org/software/keepalived-2.0.20.tar.gz 安装依赖库 安装keepalived软件包与服务控制 在编译安装Keepalived之前，必须先安装内核开发包kernel-devel以及openssl-devel、popt-devel等支持库。 1[root@masterA ~]# yum -y install kernel-devel openssl-devel popt-devel 若没有安装则通过rpm或yum工具进行安装，编译安装Keepalived 使用指定的linux内核位置对keepalived进行配置，并将安装路径指定为根目录，这样就无需额外创建链接文件了，配置完成后，依次执行make、makeinstall进行安装。 解压 1[root@masterA ~]# tar -zxf keepalived-2.0.20.tar.gz 安装 12[root@masterA ~]# cd keepalived-2.0.20/[root@masterA ~]# ./configure --prefix=/ &amp;&amp; make &amp;&amp; make install 注意：如不知道keepalived需要哪些依赖包，可到下载后的源码解压目录下查看INSTALL 文件内容， 执行make install操作之后，会自动生成/etc/init.d/keepalived脚本文件，但还需要手动添加为系统服务，这样就可以使用 service、chkconfig工具来对keepalived服务程序进行管理了。 可能出现的错误 1234567./configure 后显示checking forgcc... nochecking forcc... nochecking for cl.exe... noconfigure.sh:error:no acceptable C compiler found in$PATHSee 'config.log'for more details. 解决办法：yum -y install gcc 注意：如不知道keepalived需要哪些依赖包，可到下载后的源码解压目录下查看INSTALL 文件内容， 执行make install操作之后，会自动生成/etc/init.d/keepalived脚本文件，但还需要手动添加为系统服务，这样就可以使用 service、chkconfig工具来对keepalived服务程序进行管理了。 （2）使用keepalived服务 执行make install操作之后，会自动生成/etc/init.d/keepalived脚本文件，但还需要手动添加为系统服务，这样就可以使用service、chkconfig工具来对keepalived服务程序进行管理了。 1[root@masterB ~]# systemctl enable keepalived.service mysqlC主机也完成keepalived安装，与masterB一样，安装过程略 注：若开启了防火墙，需要关闭防火墙或创建规则。 123# firewall-cmd --direct --permanent --add-rule ipv4 filter OUTPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPT# firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPT# firewall-cmd --reload （3）修改Keepalived的配置文件（在master上配置） 在master上配置（192.168.1.11） 123456789101112131415161718192021[root@masterB ~]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; router_id mysql-ha1&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 100 nopreempt advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.200 &#125;&#125; 在Candicate master上配置（192.168.1.12） 12345678910111213141516171819202122[root@mysqlC ~]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; router_id mysql-ha2&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 50 nopreempt advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.200 &#125;&#125; （4）启动keepalived服务，在master上启动并查看日志 12345678910[root@masterB ~]# systemctl start keepalived.service[root@masterB ~]# ps -ef |grep keeproot 73024 1 0 16:48 ? 00:00:00 //sbin/keepalived -Droot 73025 73024 0 16:48 ? 00:00:00 //sbin/keepalived -Droot 73035 54421 0 16:48 pts/0 00:00:00 grep --color=auto keep[root@mysqlB ~]# ip a |grep 200 inet 192.168.1.200/32 scope global ens33# tail -f /var/log/messages查看ens33网卡是否绑定了VIP （5）在候选master上启动keepalived服务，并观察 12[root@mysqlC ~]# systemctl start keepalived.service[root@mysqlC ~]# tail -f /var/log/messages 查看ens33网卡绑定情况 从上面的信息可以看到keepalived已经配置成功 注意： 上面两台服务器的keepalived都设置为了BACKUP模式， 在keepalived中2种模式，分别是master-&gt;backup模式和backup-&gt;backup模式。这两种模式有很大区别。 在master-&gt;backup模式下，一旦主库宕机，虚拟ip会自动漂移到从库，当主库修复后，keepalived启动后，还会把虚拟ip抢占过来，即使设置了非抢占模式（nopreempt）抢占ip的动作也会发生。 在backup-&gt;backup模式下，当主库宕机后虚拟ip会自动漂移到从库上，当原主库恢复和keepalived服务启动后，并不会抢占新主的虚拟ip，即使是优先级高于从库的优先级别，也不会发生抢占。为了减少ip漂移次数，通常是把修复好的主库当做新的备库。 二、MHA引入keepalived（manager） （MySQL服务进程挂掉时通过MHA 停止keepalived）: 要想把keepalived服务引入MHA，我们只需要修改切换时触发的脚本文件master_ip_failover即可，在该脚本中添加在master发生宕机时对keepalived的处理。 1、编辑脚本/scripts/master_ip_failover，修改后如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788[root@masterA ~]# vim /scripts/master_ip_failover#!/usr/bin/env perluse strict;use warnings FATAL =&gt; 'all';use Getopt::Long;my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port);my $vip = '192.168.1.200';my $ssh_start_vip = \"systemctl start keepalived.service\";my $ssh_stop_vip = \"systemctl stop keepalived.service\";GetOptions( 'command=s' =&gt; \\$command, 'ssh_user=s' =&gt; \\$ssh_user, 'orig_master_host=s' =&gt; \\$orig_master_host, 'orig_master_ip=s' =&gt; \\$orig_master_ip, 'orig_master_port=i' =&gt; \\$orig_master_port, 'new_master_host=s' =&gt; \\$new_master_host, 'new_master_ip=s' =&gt; \\$new_master_ip, 'new_master_port=i' =&gt; \\$new_master_port);exit &amp;main();sub main &#123; print \"\\n\\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\\n\\n\"; if ( $command eq \"stop\" || $command eq \"stopssh\" ) &#123; my $exit_code = 1; eval &#123; print \"Disabling the VIP on old master: $orig_master_host \\n\"; &amp;stop_vip(); $exit_code = 0; &#125;; if ($@) &#123; warn \"Got Error: $@\\n\"; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq \"start\" ) &#123; my $exit_code = 10; eval &#123; print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; &amp;start_vip(); $exit_code = 0; &#125;; if ($@) &#123; warn $@; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq \"status\" ) &#123; print \"Checking the Status of the script.. OK \\n\"; # do nothing exit 0; &#125; else &#123; &amp;usage(); exit 1; &#125;&#125;# A simple system call that enable the VIP on the new mastersub start_vip() &#123; `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`;&#125;# A simple system call that disable the VIP on the old_mastersub stop_vip() &#123; return 0 unless ($ssh_user); `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`;&#125;sub usage &#123; print\"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\";&#125;[root@masterA ~]# chmod 777 /scripts/master_ip_failover 2、现在已经修改这个脚本了，接下来我们在/etc/masterha/app1.cnf 中调用故障切换脚本 （1）停止MHA： 123[root@masterA ~]# masterha_stop --conf=/etc/masterha/app1.cnfStopped app1 successfully.[1]+ 退出 1 nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/tmp/mha_manager.log 在配置文件/etc/masterha/app1.cnf 中启用下面的参数(在[server default下面添加]) 123456789101112[root@masterA ~]# vim /etc/masterha/app1.cnf[server default]manager_workdir=/masterha/app1manager_log=/masterha/app1/manager.loguser=managerpassword=xgp1234ssh_user=rootrepl_user=mhareprepl_password=xgp1234ping_interval=1master_ip_failover_script=/scripts/master_ip_failover #添加 （2）启动MHA： 123[root@masterA ~]# rm -fr /masterha/app1/app1.failover.complete[root@masterA ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/tmp/mha_manager.log &amp;[1] 55692 （3）检查状态： 12[root@masterA ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:60878) is running(0:PING_OK), master:192.168.1.11 （4）再检查集群状态，看是否会报错。 123456789101112131415[root@masterA ~]# rm -fr /masterha/app1/app1.failover.complete[root@masterA ~]# masterha_check_repl --conf=/etc/masterha/app1.cnfTue Jul 7 17:13:40 2020 - [info] Slaves settings check done.Tue Jul 7 17:13:40 2020 - [info] 192.168.1.12(192.168.1.12:3306) (current master) +--192.168.1.11(192.168.1.11:3306) +--192.168.1.13(192.168.1.13:3306)Tue Jul 7 17:13:40 2020 - [info] Checking replication health on 192.168.1.11..Tue Jul 7 17:13:40 2020 - [info] ok.Tue Jul 7 17:13:40 2020 - [info] Checking replication health on 192.168.1.13..Tue Jul 7 17:13:40 2020 - [info] ok.Tue Jul 7 17:13:40 2020 - [warning] master_ip_failover_script is not defined.Tue Jul 7 17:13:40 2020 - [warning] shutdown_script is not defined.Tue Jul 7 17:13:40 2020 - [info] Got exit code 0 (Not master dead). 可以看见已经没有报错了。 /scripts/master_ip_failover添加或者修改的内容意思是当主库数据库发生故障时，会触发MHA切换，MHA Manager会停掉主库上的keepalived服务，触发虚拟ip漂移到备选从库，从而完成切换。 当然可以在keepalived里面引入脚本，这个脚本监控mysql是否正常运行，如果不正常，则调用该脚本杀掉keepalived进程（参考MySQL 高可用性keepalived+mysql双主）。 3、测试： 在master上停止mysqld服务 到slave(192.168.1.13)查看slave的状态： 123456789101112131415161718[root@mysqlC ~]# systemctl stop mysqld//在192.168.1.11上操作mysql&gt; show slave status\\G//在192.168.1.12上操作*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.12 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes 从上图可以看出slave指向了新的master服务器192.168.1.12(在故障切换前指向的是192.168.1.11) 在192.168.1.11上查看vip绑定 1[root@mysqlC ~]# ip a | grep 200 在192.168.1.12上查看vip绑定 12[root@mysqlC ~]# ip a | grep 200 inet 192.168.1.200/32 scope global ens33 **从上面的显示结果可以看出vip地址漂移到了192.168.1.12 ** 三、主从切换后续工作（重构） 重构就是你的主挂了，切换到Candicate master上，Candicate master变成了主，因此重构的一种方案原主库修复成一个新的slave 主库切换后，把原主库修复成新从库，原主库数据文件完整的情况下，可通过以下方式找出最后执行的CHANGEMASTER命令： 123[root@masterA ~]# grep \"CHANGE MASTER TO MASTER\" /masterha/app1/manager.log | tail -1Tue Jul 7 20:32:26 2020 - [info] All other slaves should start replication from here. Statement should be: CHANGE MASTER TO MASTER_HOST='192.168.1.12', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=154, MASTER_USER='mharep', MASTER_PASSWORD='xxx'; 1、将192.168.1.11（原主库）修复成从库 12345678910111213141516171819202122[root@mysqlB ~]# systemctl start mysqld[root@mysqlB ~]# mysql -uroot -p123mysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.12', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=154, MASTER_USER='mharep', MASTER_PASSWORD='xgp1234';Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.12 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000006 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000004 Relay_Log_Pos: 367 Relay_Master_Log_File: mysql-bin.000006 Slave_IO_Running: Yes Slave_SQL_Running: Yes 2、重启mha manager: 12345678910111213141516171819[root@masterA ~]# rm -fr /masterha/app1/app1.failover.complete[root@masterA ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf --ignore_fail_on_start &amp;&gt;/tmp/mha_manager.log &amp;[1] 61968[root@masterA ~]# masterha_check_status --conf=/etc/masterha/app1.cnf.app1 (pid:61968) is running(0:PING_OK), master:192.168.1.12[root@masterA ~]# masterha_check_repl --conf=/etc/masterha/app1.cnfTue Jul 7 21:04:39 2020 - [info] Slaves settings check done.Tue Jul 7 21:04:39 2020 - [info] 192.168.1.12(192.168.1.12:3306) (current master) +--192.168.1.11(192.168.1.11:3306) +--192.168.1.13(192.168.1.13:3306)Tue Jul 7 21:04:39 2020 - [info] Checking replication health on 192.168.1.11..Tue Jul 7 21:04:39 2020 - [info] ok.Tue Jul 7 21:04:39 2020 - [info] Checking replication health on 192.168.1.13..Tue Jul 7 21:04:39 2020 - [info] ok.Tue Jul 7 21:04:39 2020 - [info] Checking master_ip_failover_script status:Tue Jul 7 21:04:39 2020 - [info] /scripts/master_ip_failover --command=status --ssh_user=root --orig_master_host=192.168.1.12 --orig_master_ip=192.168.1.12 --orig_master_port=3306 四、通过脚本实现VIP切换 通过脚本的方式管理VIP。这里是修改/scripts/master_ip_failover，也可以使用其他的语言完成，比如php语言。使用php脚本编写的failover这里就不介绍了。修改完成后内容如下，而且如果使用脚本管理vip的话，需要手动在目前的master服务器上绑定一个vip 1[root@masterC ~]# ifconfig ens33:0 192.168.1.200/24 1、在mha-manager上修改/scripts/master_ip_failover，内容如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889[root@masterA ~]# vim /scripts/master_ip_failover#!/usr/bin/env perluse strict;use warnings FATAL =&gt; 'all';use Getopt::Long;my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port);my $vip = '192.168.1.200';my $key = '0';my $ssh_start_vip = \"/sbin/ifconfig ens33:$key $vip\";my $ssh_stop_vip = \"/sbin/ifconfig ens33:$key down\";GetOptions( 'command=s' =&gt; \\$command, 'ssh_user=s' =&gt; \\$ssh_user, 'orig_master_host=s' =&gt; \\$orig_master_host, 'orig_master_ip=s' =&gt; \\$orig_master_ip, 'orig_master_port=i' =&gt; \\$orig_master_port, 'new_master_host=s' =&gt; \\$new_master_host, 'new_master_ip=s' =&gt; \\$new_master_ip, 'new_master_port=i' =&gt; \\$new_master_port);exit &amp;main();sub main &#123; print \"\\n\\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\\n\\n\"; if ( $command eq \"stop\" || $command eq \"stopssh\" ) &#123; my $exit_code = 1; eval &#123; print \"Disabling the VIP on old master: $orig_master_host \\n\"; &amp;stop_vip(); $exit_code = 0; &#125;; if ($@) &#123; warn \"Got Error: $@\\n\"; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq \"start\" ) &#123; my $exit_code = 10; eval &#123; print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; &amp;start_vip(); $exit_code = 0; &#125;; if ($@) &#123; warn $@; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq \"status\" ) &#123; print \"Checking the Status of the script.. OK \\n\"; # do nothing exit 0; &#125; else &#123; &amp;usage(); exit 1; &#125;&#125;# A simple system call that enable the VIP on the new mastersub start_vip() &#123; `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`;&#125;# A simple system call that disable the VIP on the old_mastersub stop_vip() &#123; return 0 unless ($ssh_user); `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`;&#125;sub usage &#123; print\"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\";&#125;[root@masterA ~]# chmod 777 /scripts/master_ip_failover 查看是否修改了/etc/masterha/app1.cnf，如果没有请添加 12[root@masterA ~]# grep \"master_ip_failover_script\" /etc/masterha/app1.cnfmaster_ip_failover_script=/scripts/master_ip_failover 2、停止MHA 123[root@masterA ~]# masterha_stop --conf=/etc/masterha/app1.cnfStopped app1 successfully.[1]+ 退出 1 nohup masterha_manager --conf=/etc/masterha/app1.cnf --ignore_fail_on_start &amp;&gt;/tmp/mha_manager.log 3、启动MHA 123[root@masterA ~]# rm -fr /masterha/app1/app1.failover.complete[root@masterA ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/tmp/mha_manager.log &amp;[1] 63215 4、检查状态： 12[root@masterA ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:63215) is running(0:PING_OK), master:192.168.1.12 再检查集群状态，看是否会报错。 1234567891011121314151617181920212223[root@masterA ~]# masterha_check_repl --conf=/etc/masterha/app1.cnfTue Jul 7 21:23:37 2020 - [info] 192.168.1.12(192.168.1.12:3306) (current master) +--192.168.1.11(192.168.1.11:3306) +--192.168.1.13(192.168.1.13:3306)Tue Jul 7 21:23:37 2020 - [info] Checking replication health on 192.168.1.11..Tue Jul 7 21:23:37 2020 - [info] ok.Tue Jul 7 21:23:37 2020 - [info] Checking replication health on 192.168.1.13..Tue Jul 7 21:23:37 2020 - [info] ok.Tue Jul 7 21:23:37 2020 - [info] Checking master_ip_failover_script status:Tue Jul 7 21:23:37 2020 - [info] /scripts/master_ip_failover --command=status --ssh_user=root --orig_master_host=192.168.1.12 --orig_master_ip=192.168.1.12 --orig_master_port=3306 IN SCRIPT TEST====systemctl stop keepalived.service==systemctl start keepalived.service===Checking the Status of the script.. OK Tue Jul 7 21:23:37 2020 - [info] OK.Tue Jul 7 21:23:37 2020 - [warning] shutdown_script is not defined.Tue Jul 7 21:23:37 2020 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. 5、测试 （1）在Candicate master上停掉mysql服务 1[root@mysqlC ~]# systemctl stop mysqld 到slave(192.168.1.13)查看slave的状态： 1234567891011121314mysql&gt; show slave status \\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.11 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000005 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000005 Slave_IO_Running: Yes Slave_SQL_Running: Yes 从上图可以看出slave指向了新的master服务器（192.168.1.11） 查看VIP 12[root@masterB ~]# ip a | grep 200 inet 192.168.1.200/24 brd 192.168.1.255 scope global secondary ens33:0 从上图可以看到mysqlC(原来的master)释放了VIP，masterB(新的master)接管了VIP地址 6、主从切换后续工作 主库切换后，把原主库修复成新从库，相关操作请参考前面相关操作。 为了防止脑裂发生，推荐生产环境采用脚本的方式来管理虚拟ip，而不是使用keepalived来完成。到此为止，基本MHA集群已经配置完毕。 12[root@masterA ~]# grep \"CHANGE MASTER TO MASTER\" /masterha/app1/manager.log | tail -1Tue Jul 7 22:43:34 2020 - [info] All other slaves should start replication from here. Statement should be: CHANGE MASTER TO MASTER_HOST='192.168.1.11', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000003', MASTER_LOG_POS=154, MASTER_USER='mharep', MASTER_PASSWORD='xxx'; （1）将192.168.1.12（原主库）修复成从库 12345678910111213141516171819202122[root@mysqlC ~]# systemctl start mysqld[root@mysqlC ~]# mysql -uroot -p123mysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.11', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000003', MASTER_LOG_POS=154, MASTER_USER='mharep', MASTER_PASSWORD='xgp1234';Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.11 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000003 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000001 Relay_Log_Pos: 4 Relay_Master_Log_File: mysql-bin.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes （2）重启mha manager: 12345678910111213141516171819[root@masterA ~]# rm -fr /masterha/app1/app1.failover.complete[root@masterA ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf --ignore_fail_on_start &amp;&gt;/tmp/mha_manager.log &amp;[1] 61968[root@masterA ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:55806) is running(0:PING_OK), master:192.168.1.11[root@masterA ~]# masterha_check_repl --conf=/etc/masterha/app1.cnfTue Jul 7 21:04:39 2020 - [info] Slaves settings check done.Tue Jul 7 21:04:39 2020 - [info] 192.168.1.12(192.168.1.12:3306) (current master) +--192.168.1.11(192.168.1.11:3306) +--192.168.1.13(192.168.1.13:3306)Tue Jul 7 21:04:39 2020 - [info] Checking replication health on 192.168.1.11..Tue Jul 7 21:04:39 2020 - [info] ok.Tue Jul 7 21:04:39 2020 - [info] Checking replication health on 192.168.1.13..Tue Jul 7 21:04:39 2020 - [info] ok.Tue Jul 7 21:04:39 2020 - [info] Checking master_ip_failover_script status:Tue Jul 7 21:04:39 2020 - [info] /scripts/master_ip_failover --command=status --ssh_user=root --orig_master_host=192.168.1.12 --orig_master_ip=192.168.1.12 --orig_master_port=3306 五、mysql必备技能掌握： 1、MySQL架构:对mysql的架构，整体有个印象，才能不断的加深对mysql的理解和后继的学习。 2、用各种姿势备份MySQL数据库 数据备份是DBA或运维工程师日常工作之一，如果让你来备份，你会用什么方式备份，在时间时间备份，使用什么策略备份 3、mysql主从复制及读写分离 mysql的主从复制及读写分离是DBA必备技能之一 4、MySQL/MariaDB数据库基于SSL实现主从复制 加强主从复制的安全性 5、MySQL高可用 数据的高可用如何保证 6、数据库Sharding的基本思想和切分策略 随着数据量的不断攀升，从性能和可维护的角度，需要进行一些Sharding**，也就是数据库的切分，有垂直切分和水平切分** 7、MySQL/MariaDB 性能调整和优化技巧 掌握优化思路和技巧，对数据库的不断优化是一项长期工程","path":"posts/ber8.html","date":"07-02","excerpt":"","tags":[]},{"title":"MySQL高可用之MHA(1)","text":"mha简介 MHA（Master High Availability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本DeNA公司youshimaton（现就职于Facebook公司）开发，是一套优秀的作为MySQL高可用性环境下故障切换和主从提升的高可用软件。在MySQL故障切换过程中，MHA能做到在0~30秒之内自动完成数据库的故障切换操作，并且在进行故障切换的过程中，MHA能在最大程度上保证数据的一致性，以达到真正意义上的高可用。 MHA里有两个角色一个是MHA Node（数据节点）另一个是MHA Manager（管理节点）。 MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明 MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。 注：从MySQL5.5开始，MySQL以插件的形式支持半同步复制 如何理解半同步呢？首先我们来看看异步，全同步的概念： 异步复制（Asynchronous replication） MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。 全同步复制（Fully synchronous replication） 指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 半同步复制（Semisynchronous replication） 介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。 下面来看看半同步复制的原理图： 总结：异步与半同步异同 默认情况下MySQL的复制是异步的，Master上所有的更新操作写入Binlog之后并不确保所有的更新都被复制到Slave之上。异步操作虽然效率高，但是在Master/Slave出现问题的时候，存在很高数据不同步的风险，甚至可能丢失数据。 MySQL5.5引入半同步复制功能的目的是为了保证在master出问题的时候，至少有一台Slave的数据是完整的。在超时的情况下也可以临时转入异步复制，保障业务的正常使用，直到一台salve追赶上之后，继续切换到半同步模式。 工作原理 相较于其它HA软件，MHA的目的在于维持MySQL Replication中Master库的高可用性，其最大特点是可以修复多个Slave之间的差异日志，最终使所有Slave保持数据一致，然后从中选择一个充当新的Master，并将其它Slave指向它。 -从宕机崩溃的master保存二进制日志事件(binlogevents)。 -识别含有最新更新的slave。应用差异的中继日志(relay log)到其它slave。 -应用从master保存的二进制日志事件(binlogevents)。 -提升一个slave为新master。 -使其它的slave连接新的master进行复制。 目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二 从，即一台充当master，一台充当备用master，另外一台充当从库，因为至少需要三台服务器。 角色 IP 主机名 Server ID 类型 os Manager 192.168.1.10 masterA 管理节点 centos7 Master 192.168.1.11 masterB 1 主mysql(写入) centos7 Candicate Master 192.168.1.12 mysqlC 2 从mysql(读) centos7 slave 192.168.1.13 mysqlD 3 从mysql(读) centos7 其中master对外提供写服务，备选master（实际的slave，主机名centos3）提供读服务，slave也提供相关的读服务，一旦master宕机，将会把备选master提升为新的master，slave指向新的master，manager作为管理服务器。 一、基础环境准备 在配置好IP地址后检查selinux，iptables设置， 关闭 selinux ，iptables 服务以便后期主从同步不出错 注：时间要同步 1、 在四台机器都配置epel源 123[root@masterA ~]# rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm[root@masterA ~]# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 2、配置hosts环境 12345678[root@masterA ~]# vim /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.1.10 masterA192.168.1.11 masterB192.168.1.12 mysqlC192.168.1.13 mysqlD 3、建立ssh无交互登录环境 Manager主机： MHA集群中的各节点彼此之间均需要基于ssh互信通信，以实现远程控制及数据管理功能。简单起见，可在Manager节点生成密钥对儿，并设置其可远程连接本地主机后， 将私钥文件及authorized_keys文件复制给余下的所有节点即可。 下面操作在所有节点上操作： 12[root@masterA ~]# ssh-keygen -t rsa[root@masterA ~]# ssh-copy-id -i .ssh/id_rsa.pub root@masterA 当四台机器都进行了上述操作以后，我们可以在 manager 机器上看到如下文件： 1[root@mysqlC ~]# cat .ssh/authorized_keys 四台机器的公钥都已经在authorized_keys这个文件中了，接着，我们只需要把这个文件发送至另外三台机器，这四台机器就可以实现 ssh 无密码互通了 123[root@masterA .ssh]# scp authorized_keys root@masterB:~/.ssh/[root@masterA .ssh]# scp authorized_keys root@mysqlC:~/.ssh/[root@masterA .ssh]# scp authorized_keys root@mysqlD:~/.ssh/ 二、配置mysql半同步复制 为了尽可能的减少主库硬件损坏宕机造成的数据丢失，因此在配置MHA的同时建议配置成MySQL的半同步复制。 注：mysql半同步插件是由谷歌提供，具体位置/usr/local/mysql/lib/plugin/下，一个是master用的semisync_master.so，一个是slave用的semisync_slave.so，下面我们就来具体配置一下。 如果不清楚Plugin的目录，用如下查找 1234567mysql&gt; show variables like '%plugin_dir%';+---------------+------------------------------+| Variable_name | Value |+---------------+------------------------------+| plugin_dir | /usr/local/mysql/lib/plugin/ |+---------------+------------------------------+1 row in set (0.02 sec) 1、分别在主从节点上安装相关的插件（master, Candicate master,slave） 在MySQL上安装插件需要数据库支持动态载入。检查是否支持，用如下检测： 1234567mysql&gt; show variables like '%have_dynamic%';+----------------------+-------+| Variable_name | Value |+----------------------+-------+| have_dynamic_loading | YES |+----------------------+-------+1 row in set (0.00 sec) 所有mysql数据库服务器，安装半同步插件(semisync_master.so,semisync_slave.so) 12345mysql&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';Query OK, 0 rows affected (0.01 sec)mysql&gt; INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';Query OK, 0 rows affected (0.00 sec) 其他mysql主机采用同样的方法安装 检查Plugin是否已正确安装： 123mysql&gt; show plugins;或mysql&gt; select * from information_schema.plugins; 查看半同步相关信息 1234567891011121314mysql&gt; show variables like '%rpl_semi_sync%';+-------------------------------------------+------------+| Variable_name | Value |+-------------------------------------------+------------+| rpl_semi_sync_master_enabled | OFF || rpl_semi_sync_master_timeout | 10000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_for_slave_count | 1 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_master_wait_point | AFTER_SYNC || rpl_semi_sync_slave_enabled | OFF || rpl_semi_sync_slave_trace_level | 32 |+-------------------------------------------+------------+8 rows in set (0.01 sec) 上图可以看到半同复制插件已经安装，只是还没有启用，所以是off 2、修改my.cnf文件，配置主从同步： 注：若主MYSQL服务器已经存在，只是后期才搭建从MYSQL服务器，在置配数据同步前应先将主MYSQL服务器的要同步的数据库拷贝到从MYSQL服务器上（如先在主MYSQL上备份数据库，再用备份在从MYSQL服务器上恢复） （1）master mysql主机： 1234567891011121314[root@masterB ~]# vim /etc/my.cnfserver-id = 1log-bin=mysql-binbinlog_format=mixedlog-bin-index=mysql-bin.indexrpl_semi_sync_master_enabled=1rpl_semi_sync_master_timeout=1000rpl_semi_sync_slave_enabled=1relay_log_purge=0relay-log = relay-binrelay-log-index = slave-relay-bin.index[root@masterB ~]# systemctl restart mysqld 注： rpl_semi_sync_master_enabled=1 1表是启用，0表示关闭 rpl_semi_sync_master_timeout=10000：毫秒单位 ，该参数主服务器等待确认消息10秒后，不再等待，变为异步方式。 （2）Candicate master主机： 12345678910111213[root@mysqlC ~]# vim /etc/my.cnfserver-id = 2log-bin=mysql-binbinlog_format=mixedlog-bin-index=mysql-bin.indexrelay_log_purge=0relay-log = relay-binrelay-log-index = slave-relay-bin.indexrpl_semi_sync_master_enabled=1rpl_semi_sync_master_timeout=10000rpl_semi_sync_slave_enabled=1[root@mysqlC ~]# systemctl restart mysqld 注：relay_log_purge=0，禁止 SQL 线程在执行完一个 relay log 后自动将其删除，对于MHA场景下，对于某些滞后从库的恢复依赖于其他从库的relay log，因此采取禁用自动删除功能机 （3）Slave主机： 123456789[root@mysqlD ~]# vim /etc/my.cnfserver-id = 3log-bin = mysql-binrelay-log = relay-binrelay-log-index = slave-relay-bin.indexread_only = 1rpl_semi_sync_slave_enabled=1[root@mysqlD ~]# systemctl restart mysqld （4）查看半同步相关信息 1234567891011121314mysql&gt; show variables like '%rpl_semi_sync%';+-------------------------------------------+------------+| Variable_name | Value |+-------------------------------------------+------------+| rpl_semi_sync_master_enabled | ON || rpl_semi_sync_master_timeout | 1000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_for_slave_count | 1 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_master_wait_point | AFTER_SYNC || rpl_semi_sync_slave_enabled | ON || rpl_semi_sync_slave_trace_level | 32 |+-------------------------------------------+------------+8 rows in set (0.01 sec) （5）查看半同步状态： 123456789101112131415161718192021mysql&gt; show status like '%rpl_semi_sync%';+--------------------------------------------+-------+| Variable_name | Value |+--------------------------------------------+-------+| Rpl_semi_sync_master_clients | 0 || Rpl_semi_sync_master_net_avg_wait_time | 0 || Rpl_semi_sync_master_net_wait_time | 0 || Rpl_semi_sync_master_net_waits | 0 || Rpl_semi_sync_master_no_times | 0 || Rpl_semi_sync_master_no_tx | 0 || Rpl_semi_sync_master_status | ON || Rpl_semi_sync_master_timefunc_failures | 0 || Rpl_semi_sync_master_tx_avg_wait_time | 0 || Rpl_semi_sync_master_tx_wait_time | 0 || Rpl_semi_sync_master_tx_waits | 0 || Rpl_semi_sync_master_wait_pos_backtraverse | 0 || Rpl_semi_sync_master_wait_sessions | 0 || Rpl_semi_sync_master_yes_tx | 0 || Rpl_semi_sync_slave_status | OFF |+--------------------------------------------+-------+15 rows in set (0.01 sec) 有几个状态参数值得关注的： rpl_semi_sync_master_status ：显示主服务是异步复制模式还是半同步复制模式 rpl_semi_sync_master_clients ：显示有多少个从服务器配置为半同步复制模式 rpl_semi_sync_master_yes_tx ：显示从服务器确认成功提交的数量 rpl_semi_sync_master_no_tx ：显示从服务器确认不成功提交的数量 rpl_semi_sync_master_tx_avg_wait_time ：事务因开启 semi_sync ，平均需要额外等待的时间 rpl_semi_sync_master_net_avg_wait_time ：事务进入等待队列后，到网络平均等待时间 （6）master主机（创建用户，查看状态码） 12345678910111213mysql&gt; grant replication slave on *.* to mharep@'192.168.1.%' identified by 'xgp1234';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; grant all privileges on *.* to manager@'192.168.1.%' identified by 'xgp1234'; Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 742 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 第一条grant命令是创建一个用于主从复制的帐号，在master和candicate master的主机上创建即可。 第二条grant命令是创建MHA管理账号，所有mysql服务器上都需要执行。MHA会在配置文件里要求能远程登录到数据库，所以要进行必要的赋权。 （7）Candicate master主机（配置从） 123456789101112131415mysql&gt; grant replication slave on *.* to mharep@'192.168.1.%' identified by '123';Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; grant all privileges on *.* to manager@'192.168.1.%' identified by '123'; Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; change master to master_host='192.168.1.11',master_port=3306,master_user='mharep',master_password='xgp1234',master_log_file='mysql-bin.000001',master_log_pos=742;Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; start slave;mysql&gt; show slave status \\G....... Slave_IO_Running: Yes Slave_SQL_Running: Yes...... 查看从的状态，以下两个值必须为yes,代表从服务器能正常连接主服务器 （8）Slave主机（配置从） 123456789101112mysql&gt; grant all privileges on *.* to manager@'192.168.1.%' identified by '123';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; change master to master_host='192.168.1.11',master_port=3306,master_user='mharep',master_password='xgp1234',master_log_file='mysql-bin.000001',master_log_pos=742;Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; start slave;mysql&gt; show slave status \\G....... Slave_IO_Running: Yes Slave_SQL_Running: Yes...... 查看从的状态，以下两个值必须为yes,代表从服务器能正常连接主服务器 查看master服务器的半同步状态： 123456789101112131415161718192021mysql&gt; show status like '%rpl_semi_sync%';+--------------------------------------------+-------+| Variable_name | Value |+--------------------------------------------+-------+| Rpl_semi_sync_master_clients | 2 || Rpl_semi_sync_master_net_avg_wait_time | 0 || Rpl_semi_sync_master_net_wait_time | 0 || Rpl_semi_sync_master_net_waits | 0 || Rpl_semi_sync_master_no_times | 1 || Rpl_semi_sync_master_no_tx | 2 || Rpl_semi_sync_master_status | ON || Rpl_semi_sync_master_timefunc_failures | 0 || Rpl_semi_sync_master_tx_avg_wait_time | 0 || Rpl_semi_sync_master_tx_wait_time | 0 || Rpl_semi_sync_master_tx_waits | 0 || Rpl_semi_sync_master_wait_pos_backtraverse | 0 || Rpl_semi_sync_master_wait_sessions | 0 || Rpl_semi_sync_master_yes_tx | 0 || Rpl_semi_sync_slave_status | OFF |+--------------------------------------------+-------+15 rows in set (0.00 sec) 三、配置mysql-mha mha包括manager节点和data节点 data节点包括原有的MySQL复制结构中的主机，至少3台，即1主2从，当masterfailover后，还能保证主从结构；只需安装node包。 manager server：运行监控脚本，负责monitoring 和 auto-failover；需要安装node包和manager包。 1、 在所有主机上安装mha所依赖的软件包（需要系统自带的yum源并联网） 1[root@masterA ~]# yum -y install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-ParallelForkManager perl-Config-IniFiles ncftp perl-Params-Validate perl-CPAN perl-TestMock-LWP.noarch perl-LWP-Authen-Negotiate.noarch perl-devel perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker 2、 以下操作管理节点需要两个都安装， 在3台数据库节点只要安装MHA的node节点： 软件下载 https://github.com/yoshinorim 在所有数据库节点上安装mha4mysql-node-0.56.tar.gz 1234[root@masterA src]# tar zxf mha4mysql-node-0.58.tar.gz[root@masterA src]# cd mha4mysql-node-0.58[root@masterA mha4mysql-node-0.58]# perl Makefile.PL[root@masterA mha4mysql-node-0.58]# make &amp;&amp; make install 在管理节点安装：mha4mysql-manager-0.56.tar.gz 1234[root@masterA ~]# tar zxf mha4mysql-manager-0.58.tar.gz [root@masterA ~]# cd mha4mysql-manager-0.58/[root@masterA mha4mysql-manager-0.58]# perl Makefile.PL[root@masterA mha4mysql-manager-0.58]# make &amp;&amp; make install 根据提示输入： 12345[root@masterA mha4mysql-manager-0.58]# mkdir /etc/masterha[root@masterA mha4mysql-manager-0.58]# mkdir -p /masterha/app1[root@masterA mha4mysql-manager-0.58]# mkdir /scripts[root@masterA mha4mysql-manager-0.58]# cp samples/conf/* /etc/masterha/[root@masterA mha4mysql-manager-0.58]# cp samples/scripts/* /scripts/ 3、 配置mha 与绝大多数Linux应用程序类似，MHA的正确使用依赖于合理的配置文件。MHA的配置文件与mysql的my.cnf文件配置相似，采取的是param=value的方式来配置，配置文件位于管理节点，通常包括每一个mysql server的主机名，mysql用户名，密码，工作目录等等。 编辑/etc/masterha/app1.conf，内容如下： 12345678910111213141516171819202122232425262728[root@masterA mha4mysql-manager-0.58]# vim /etc/masterha/app1.cnf[server default]manager_log=/masterha/app1/manager.loguser=managerpassword=xgp1234ssh_user=rootrepl_user=mhareprepl_password=xgp1234ping_interval=1[server1]hostname=192.168.1.11port=3306master_binlog_dir=/usr/local/mysql/datacandidate_master=1[server2]hostname=192.168.1.12port=3306master_binlog_dir=/usr/local/mysql/datacandidate_master=1[server3]hostname=192.168.1.13port=3306master_binlog_dir=/usr/local/mysql/datano_master=1 配关配置项的解释： manager_workdir=/masterha/app1 //设置manager的工作目录 manager_log=/masterha/app1/manager.log //设置manager的日志 user=manager //设置监控用户manager password=123456 //监控用户manager的密码 ssh_user=root //ssh连接用户 repl_user=mharep //主从复制用户 repl_password=123.abc //主从复制用户密码 ping_interval=1 //设置监控主库，发送ping包的时间间隔，默认是3秒，尝试三次没有回应的时候自动进railover master_binlog_dir=/usr/local/mysql/data //设置master 保存binlog的位置，以便MHA可以找到master的日志，我这里的也就是mysql的数据目录 candidate_master=1 //设置为候选master，如果设置该参数以后，发生主从切换以后将会将此从库提升为主库。 4、SSH 有效性验证： 1234567891011121314151617[root@masterA masterha]# masterha_check_ssh --global_conf=/etc/masterha/masterha_default.cnf --conf=/etc/masterha/app1.cnfMon Jul 6 18:41:51 2020 - [debug] Connecting via SSH from root@192.168.1.11(192.168.1.11:22) to root@192.168.1.12(192.168.1.12:22)..Mon Jul 6 18:41:51 2020 - [debug] ok.Mon Jul 6 18:41:51 2020 - [debug] Connecting via SSH from root@192.168.1.11(192.168.1.11:22) to root@192.168.1.13(192.168.1.13:22)..Mon Jul 6 18:41:52 2020 - [debug] ok.Mon Jul 6 18:41:52 2020 - [debug] Mon Jul 6 18:41:52 2020 - [debug] Connecting via SSH from root@192.168.1.12(192.168.1.12:22) to root@192.168.1.11(192.168.1.11:22)..Mon Jul 6 18:41:52 2020 - [debug] ok.Mon Jul 6 18:41:52 2020 - [debug] Connecting via SSH from root@192.168.1.12(192.168.1.12:22) to root@192.168.1.13(192.168.1.13:22)..Mon Jul 6 18:41:52 2020 - [debug] ok.Mon Jul 6 18:41:53 2020 - [debug] Mon Jul 6 18:41:52 2020 - [debug] Connecting via SSH from root@192.168.1.13(192.168.1.13:22) to root@192.168.1.11(192.168.1.11:22)..Mon Jul 6 18:41:52 2020 - [debug] ok.Mon Jul 6 18:41:52 2020 - [debug] Connecting via SSH from root@192.168.1.13(192.168.1.13:22) to root@192.168.1.12(192.168.1.12:22)..Mon Jul 6 18:41:53 2020 - [debug] ok.Mon Jul 6 18:41:53 2020 - [info] All SSH connection tests passed successfully. 5、集群复制的有效性验证： mysql必须都启动 123456789101112[root@masterA masterha]# masterha_check_repl --global_conf=/etc/masterha/masterha_default.cnf --conf=/etc/masterha/app1.cnf。。。省略好多数据Mon Jul 6 18:47:47 2020 - [info] Checking replication health on 192.168.1.12..Mon Jul 6 18:47:47 2020 - [info] ok.Mon Jul 6 18:47:47 2020 - [info] Checking replication health on 192.168.1.13..Mon Jul 6 18:47:47 2020 - [info] ok.Mon Jul 6 18:47:47 2020 - [warning] master_ip_failover_script is not defined.Mon Jul 6 18:47:47 2020 - [warning] shutdown_script is not defined.Mon Jul 6 18:47:47 2020 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. 验证成功的话会自动识别出所有服务器和主从状况 注：验证成功的话会自动识别出所有服务器和主从状况 在验证时，若遇到这个错误：Can’t exec “mysqlbinlog” … 解决方法是在所有服务器上执行： 1ln -s /usr/local/mysql/bin/* /usr/local/bin/ 四、mha的使用 1、启动 manager： 12[root@masterA masterha]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/tmp/mha_manager.log &amp;[1] 49677 注：在应用Unix/Linux时，我们一般想让某个程序在后台运行，于是我们将常会用 &amp; 在程序结尾来让程序自动运行。比如我们要运行mysql在后台： /usr/local/mysql/bin/mysqld_safe –user=mysql &amp;。可是*有很多程序并不想mysqld一样，这样我们就需要nohup命令， 2、状态检查： 12[root@masterA masterha]# masterha_check_status --conf=/etc/masterha/app1.cnf app1 (pid:49677) is running(0:PING_OK), master:192.168.1.11 3、故障转移验证： **(自动failover) master dead后，MHA当时已经开启，候选Master库（Slave）会自动failover为Master. 验证的方式是先停掉 master（masterB），因为之前的配置文件中，把Candicate master(mysqlC)作为了候选人，那么就到 slave(mysqlD) 上查看 master 的 IP 是否变为了 centos3 的 IP ** 1)停掉 master 在masterB（192.168.1.11） 上把 mysql 停掉 1[root@masterB ~]# systemctl stop mysqld 2)查看 MHA 日志 上面的配置文件中指定了日志位置为/masterha/app1/manager.log 123456789101112131415161718[root@masterA ~]# cat /masterha/app1/manager.log----- Failover Report -----app1: MySQL Master failover 192.168.1.11(192.168.1.11:3306) to 192.168.1.12(192.168.1.12:3306) succeededMaster 192.168.1.11(192.168.1.11:3306) is down!Check MHA Manager logs at masterA:/masterha/app1/manager.log for details.Started automated(non-interactive) failover.The latest slave 192.168.1.12(192.168.1.12:3306) has all relay logs for recovery.Selected 192.168.1.12(192.168.1.12:3306) as a new master.192.168.1.12(192.168.1.12:3306): OK: Applying all logs succeeded.192.168.1.13(192.168.1.13:3306): This host has the latest relay log events.Generating relay diff files from the latest slave succeeded.192.168.1.13(192.168.1.13:3306): OK: Applying all logs succeeded. Slave started, replicating from 192.168.1.12(192.168.1.12:3306)192.168.1.12(192.168.1.12:3306): Resetting slave info succeeded.Master failover to 192.168.1.12(192.168.1.12:3306) completed successfully. 从日志信息中可以看到 master failover 已经成功了，并可以看出故障转移的大体流程 3)检查 slave2 的复制 登录 slave（192.168.1.13） 的Mysql，查看 slave 状态 1234567891011121314mysql&gt; show slave status \\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.12 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 742 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes 可以看到 master 的 IP 现在为 192.168.1.12, 已经切换到和192.168.1.12同步了，本来是和192.168.1.11同步的，说明 MHA 已经把Candicate master(mysqlC) 提升为了新的 master，IO线程和SQL线程也正确运行，MHA搭建成功 五、MHA Manager 端日常主要操作步骤 1、检查是否有下列文件，有则删除。 发生主从切换后，MHAmanager服务会自动停掉，且在manager_workdir（/masterha/app1）目录下面生成文件app1.failover.complete，若要启动MHA，必须先确保无此文件) 如果有这个提示，那么删除此文件 /masterha/app1/app1.failover.complete [error] [/usr/share/perl5/vendor_perl/MHA/MasterFailover.pm, ln298] Last failover was done at 2015/01/09 10:00:47. Current time is too early to do failover again. If you want to do failover, manually remove / masterha/app1/app1.failover.complete and run this script again. 12[root@masterA ~]# ll /masterha/app1/app1.failover.complete[root@masterA ~]# ll /masterha/app1/app1.failover.error 2、检查MHA复制检查：（需要把master设置成candicatade的从服务器） 12345mysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.12', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000002', MASTER_LOG_POS=154, MASTER_USER='mharep', MASTER_PASSWORD='xgp1234';Query OK, 0 rows affected, 2 warnings (0.01 sec)[root@masterA ~]# masterha_check_repl --conf=/etc/masterha/app1.cnf//测试一下 3、停止MHA： 1[root@masterA ~]# masterha_stop --conf=/etc/masterha/app1.cnf 4、启动MHA： 1[root@masterA ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/tmp/mha_manager.log &amp; 当有slave 节点宕掉时，默认是启动不了的，加上 --ignore_fail_on_start 即使有节点宕掉也能启动MHA，如下： 1[root@masterA ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf --ignore_fail_on_start &amp;&gt;/tmp/mha_manager.log &amp; 5、检查状态： 1[root@masterA ~]# masterha_check_status --conf=/etc/masterha /app1.cnf 6、检查日志： 1[root@masterA ~]# tail -f /masterha/app1/manager.log 7、主从切换后续工作 重构： 重构就是你的主挂了，切换到Candicate master上，Candicate master变成了主，因此重构的一种方案原主库修复成一个新的slave 主库切换后，把原主库修复成新从库，然后重新执行以上5步。原主库数据文件完整的情况下，可通过以下方式找出最后执行的CHANGE MASTER命令： 1[root@masterA ~]# grep \"CHANGE MASTER TO MASTER\" /masterha/app1/manager.log | tail -1 配置从服务 12345678910[root@masterB ~]# mysql -u root -p123mysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.1.12', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=742, MASTER_USER='mharep',MASTER_PASSWORD='xgp1234';Query OK, 0 rows affected, 2 warnings (0.00 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; show slave status\\G Slave_IO_Running: Yes Slave_SQL_Running: Yes 启动manager 12345[root@masterA ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/tmp/mha_manager.log &amp;[1] 50826[root@masterA ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:50826) is running(0:PING_OK), master:192.168.1.12 注意：如果正常，会显示&quot;PING_OK&quot;，否则会显示&quot;NOT_RUNNING&quot;，这代表MHA监控没有开启。 定期删除中继日志 在配置主从复制中，slave上设置了参数relay_log_purge=0，所以slave节点需要定期删除中继日志，建议每个slave节点删除中继日志的时间错开。 1[root@masterA ~]# corntab -e 0 5 * * * /usr/local/bin/purge_relay_logs - -user=root --password=pwd123 --port=3306 --disable_relay_log_purge &gt;&gt; /var/log/purge_relay.log 2&gt;&amp;1","path":"posts/ber7.html","date":"07-01","excerpt":"","tags":[]},{"title":"MySQL高可用集群之MySQL-MMM（2）","text":"一 MMM 高可用mysql简介 MMM(Master-Master Replication mananger for mysql)，由一个管理端（monitor）和多个代理端（agent）构成。通过MMM可以实现监控和管理Mysql主主复制和服务状态，同时也可监控多个Slave节点的复制以及运行状态，并且可以做到任何节点发生故障时实现自动化切换的功能。 MMM套件三个主要脚本： mmm_mond:监控进程，运行在管理节点，主要负责对所有数据库的监控工作，同时决定和处理所有节点的角色切换。 mmm_agent:代理进程，运行在每台Mysql服务器，完成监控的测试工作和执行远程服务设置。 mmm_control:管理脚本，查看和管理集群运行状态，同时管理mmm_mond进程。 二 MMM典型应用架构 三 MMM双主多从Mysql架构配置 架构图如上图 双主双从应用架构读、写分离IP列表 角色 物理IP server_id 虚拟IP地址 IP角色 功能 Master1 192.168.1.166 1 192.168.1.150 writer IP 写入VIP,单点写入 192.168.1.151 reader IP 读查询VIP,每个节点一个读VIP,可通过负载均衡软件对读负载均衡 Master2 192.168.1.168 2 192.168.1.152 Slave1 192.168.1.186 3 192.168.1.153 Slave2 192.168.1.188 4 192.168.1.154 Monitor 192.168.1.180 1、配置前准备 （1）校时操作 1234#安装ntpdate工具yum install ntpdate -y#使用ntpdate校时（后面的是ntp服务器）ntpdate pool.ntp.org （2）关闭selinux 12setenforce 0sed -i 's/enforcing/disabled/g' /etc/selinux/config 2、MMM的安装配置 （1）MMM套件安装 在Monitor端安装所有MMM组件 12yum install epel-release.noarch -yyum install mysql-mmm mysql-mmm-agent mysql-mmm-tools mysql-mmm-monitor -y 在其他所有节点安装mysql-mmm-agent 12yum install epel-release.noarch -yyum install mysql-mmm-agent -y 三、masterB和mysqlC的主主配置和masterB和mysqlD的主从配置 首先在3台主机上安装mysql和搭建复制（192.168.1.11和192.168.1.12互为主从，192.168.1.13为192.168.1.11的从）具体的复制搭建这里就省略，要是这都不会，那么该文章对你就没意思了。然后在每个mysql的配置文件中加入以下内容，注意server_id 不能重复。 masterB（192.168.1.11）上： 12345678910111213[root@masterB ~]# vi /etc/my.cnf #添加如下[mysqld]binlog-do-db=test #需要记录二进制日志的数据库，多个用逗号隔开binlog-ignore-db=mysql，information_schema #不需要记录二进制日志的数据库，多个用逗号隔开auto_increment_increment=2 #字段一次递增多少auto_increment_offset=1 #自增字段的起始值，值设置不同replicate-do-db=test #同步的数据库，多个写多行replicate-ignore-db = information_schema #不同步的数据库，多个写多行server_id = 1 #每台设置不同log_bin = mysql-binlog_slave_updates #当一个主故障，另一个立即接管sync-binlog=1 #每条自动更新，安全性高，默认是0[root@masterB ~]# systemctl restart mysqld mysqlC（192.168.1.11）上： 12345678910111213[root@mysqlC ~]# vim /etc/my.cnf [mysqld]binlog-do-db=test binlog-ignore-db=mysql，information_schema auto_increment_increment=2 auto_increment_offset=2 replicate-do-db=test #同步的数据库，多个写多行replicate-ignore-db = information_schema server_id = 2 log_bin = mysql-binlog_slave_updates sync-binlog=1 [root@mysqlC ~]# systemctl restart mysqld mysqlD（192.168.1.11）上： 12345678910111213[root@mysqlD ~]# vim /etc/my.cnf [mysqld]binlog-do-db=test binlog-ignore-db=mysql，information_schema auto_increment_increment=2 auto_increment_offset=3 replicate-do-db=test replicate-ignore-db = information_schemaserver_id = 3 log_bin = mysql-binlog_slave_updates sync-binlog=1 [root@mysqlD ~]# systemctl restart mysqld 1、设置masterB和mysqlC双主复制 （1）masterB操作 查看log bin日志和pos值位置 1234567891011121314mysql&gt; grant replication slave ,replication client on *.* to repl@'192.168.1.12' identified by \"repl123\";mysql&gt; flush privileges;# 注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status; +------------------+----------+--------------+----------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+----------------------------+-------------------+| mysql-bin.000001 | 2058 | test | mysql，information_schema | |+------------------+----------+--------------+----------------------------+-------------------+1 row in set (0.00 sec) （2）mysqlC操作 查看log bin日志和pos值位置 12345678910111213mysql&gt; grant replication slave ,replication client on *.* to repl@'192.168.1.11' identified by \"repl123\";mysql&gt; flush privileges;# 注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status; +------------------+----------+--------------+----------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+----------------------------+-------------------+| mysql-bin.000001 | 630 | test | mysql，information_schema | |+------------------+----------+--------------+----------------------------+-------------------+1 row in set (0.00 sec) （3）mysqlC同步masterB 确保mysqlC上要同步的数据，提前在masterB上存在，最好双方数据保持一致。 123456789101112#先解锁，将对方数据同步到自己的数据库中mysql&gt; unlock tables; mysql&gt; stop slave;mysql&gt; change master to master_host='192.168.1.11',master_user='repl',master_password='repl123',master_log_file='mysql-bin.000001',master_log_pos=2058;mysql&gt; start slave;mysql&gt; show slave status \\Gtrue .................. Slave_IO_Running: Yes Slave_SQL_Running: Yes .................. 这样就实现了slave－&gt;master的同步环境。 （4）masterB同步mysqlC 确保mysqlC上要同步的数据，提前在masterB上存在，最好双方数据保持一致。 123456789101112#先解锁，将对方数据同步到自己的数据库中mysql&gt; unlock tables; mysql&gt; stop slave;mysql&gt; change master to master_host='192.168.1.12',master_user='repl',master_password='repl123',master_log_file='mysql-bin.000001',master_log_pos=630;mysql&gt; start slave;mysql&gt; show slave status \\Gtrue .................. Slave_IO_Running: Yes Slave_SQL_Running: Yes .................. 测试一下双主 masterB插入数据 12345mysql&gt; use testmysql&gt; create table xgp (xm int(10));mysql&gt; insert into xgp(xm) -&gt; VALUES(10);Query OK, 1 row affected (0.01 sec) mysqlC查看数据 1234567mysql&gt; select * from test.xgp;+------+| xm |+------+| 10 |+------+1 row in set (0.00 sec) 可以看到已经成功同步过去，同样在test插入到xgp表数据，也能同步过去。我们的双主就成功了，开始做主从复制。 2、设置mysqlD为masterB的从服务器 （1）查看一下masterB的log bin日志和pos值位置 12345678910111213mysql&gt; grant replication slave ,replication client on *.* to repl@'192.168.1.11' identified by \"repl123\";mysql&gt; flush privileges;# 注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status;+------------------+----------+--------------+----------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+----------------------------+-------------------+| mysql-bin.000001 | 2825 | test | mysql，information_schema | |+------------------+----------+--------------+----------------------------+-------------------+1 row in set (0.00 sec) （2）mysqlD的操作 12345678910mysql&gt; unlock tables; mysql&gt; stop slave; #执行同步前，要先关闭slavemysql&gt; change master to master_host='192.168.1.11',master_user='repl',master_password='repl123',master_log_file='mysql-bin.000001',master_log_pos=2825; mysql&gt; start slave;mysql&gt; show slave status \\G....... Slave_IO_Running: Yes Slave_SQL_Running: Yes...... 测试一下主从 masterB插入数据 12345mysql&gt; create table wer (xm int(10));Query OK, 0 rows affected (0.01 sec)mysql&gt; insert into wer(xm) VALUES(10);Query OK, 1 row affected (0.00 sec) mysqlD查看数据 1234567mysql&gt; select * from test.wer;+------+| xm |+------+| 10 |+------+1 row in set (0.00 sec) 3、在所有MySQL节点的/etc/my.cnf中增加参数（要重启） 123456[root@mysqlD ~]# vim /etc/my.cnfread_only=1#read_only是因为MMM对数据需严格的读写控制#此参数不影响replication;root用户依然可写。[root@mysqlD ~]# systemctl restart mysqld 4、所有MySQL节点创建monitor user（健康检测）和monitor agent（切换只读模式和同步Master信息）帐号（仅在mysql写入主节点,其他节点会自动复制） （1）mysql-mmm配置：在3台mysql节点上创建用户创建代理账号： 1mysql&gt; grant super,replication client,process on *.* to 'mmm_agent'@'192.168.1.%' identified by '123456'; （2）创建监控账号（3台mysql节点）： 1mysql&gt; grant replication client on *.* to 'mmm_monitor'@'192.168.1.%' identified by '123456'; 因为之前的主主复制，以及主从已经是ok的，所以我在masterB服务器执行就ok了。 检查mysqlC、mysqlD两台db上是否都存在监控和代理账号 123456789101112131415161718mysql&gt; select user,host from mysql.user where user in ('mmm_monitor','mmm_agent');+-------------+-------------+| user | host |+-------------+-------------+| mmm_agent | 192.168.1.% || mmm_monitor | 192.168.1.% |+-------------+-------------+2 rows in set (0.00 sec)或mysql&gt; show grants for 'mmm_agent'@'192.168.1.%';+------------------------------------------------------------------------------+| Grants for mmm_agent@192.168.1.% |+------------------------------------------------------------------------------+| GRANT PROCESS, SUPER, REPLICATION CLIENT ON *.* TO 'mmm_agent'@'192.168.1.%' |+------------------------------------------------------------------------------+1 row in set (0.00 sec) **mmm_monitor用户：mmm监控用于对mysql服务器进程健康检查 ** mmm_agent用户：mmm代理用来更改只读模式，复制的主服务器等。 5、在所有MMM节点配置mmm_common.conf （注意以下所有配置文件中不能以下注释，会报错 使用sed -i '/^#/d;s/#.*//g' file 清除注释） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#当设置此参数，所有mysql节点都设置为\"read_only=1\",MMM会根据Mysql角色来决定是否执行\"set global read_only=0\".active_master_role writer&lt;host default&gt; cluster_interface eno16777736 pid_path /var/run/mmm_agentd.pid bin_path /usr/libexec/mysql-mmm/ replication_user replication replication_password 123456 agent_user mmm_agent agent_password 123456&lt;/host&gt;&lt;host masterB&gt; ip 192.168.1.11 mode master peer mysqlC&lt;/host&gt;&lt;host mysqlC&gt; ip 192.168.1.12 mode master peer masterB&lt;/host&gt;&lt;host mysqlD&gt; ip 192.168.1.13 mode slave&lt;/host&gt;&lt;role writer&gt; hosts masterB,mysqlC ips 192.168.1.100 mode exclusive&lt;/role&gt;&lt;role reader&gt; hosts mysqlC,mysqlD ips 192.168.1.110,192.168.1.111 mode balanced&lt;/role&gt; 6、在仅在MMM管理节点配置mmm_mom.conf 123456789101112131415161718192021include mmm_common.conf&lt;monitor&gt; ip 127.0.0.1 pid_path /var/run/mysql-mmm/mmm_mond.pid bin_path /usr/libexec/mysql-mmm status_path /var/lib/mysql-mmm/mmm_mond.status ping_ips 192.168.1.11,192.168.1.12,192.168.1.13 auto_set_online 10 &lt;/monitor&gt;&lt;check default&gt;truecheck_period 5truetrap_period 10truetimeout 2true#restart_after 10000truemax_backlog 86400 &lt;/check&gt;&lt;host default&gt; monitor_user mmm_monitor monitor_password 123456&lt;/host&gt;debug 0","path":"posts/bert.html","date":"06-30","excerpt":"","tags":[]},{"title":"MySQL高可用集群之MySQL-MMM(1)","text":"一、MMM简介 MMM即Multi-Master Replication Manager for MySQL:mysql多主复制管理器,基于perl实现,关于mysql主主复制置的监控、故障转移和管理的一套可伸缩的脚本套件（在任何时候只有一个节点可以被写入），MMM也能对从服务器进行读负载均衡，所以可以用它来在一组用于复制的服务器启动虚拟ip，除此之外，它还有实现数 据备份、节点之间重新同步功能的脚本。MySQL本身没有提供replication failover的解决方案，通过MMM方案能实现服务器的故障转移，从而实现mysql的高可用。MMM不仅能提供浮动IP的功能，如果当前的主服务器挂掉后，会将你后端的从服务器自动转向新的主服务器进行同步复制，不用手工更改同步配置。这个方案是目前比较成熟的解决方案。详情请看官网：http://mysql-mmm.org 1、MySQL-MMM优缺点 优点： 高可用性，扩展性好，出现故障自动切换，对于主主同步，在同一时间只提供一台数据库写操作，保证的数据的一致性。 当主服务器挂掉以后，另一个主立即接管，其他的从服务器能自动切换，不用人工干预。 缺点： Monitor节点是单点，可以结合Keepalived或者haertbeat实现高可用。 至少三个节点，对主机的数量有要求，需要实现读写分离,还需要在前端编写读写分离程序。 在读写非常繁忙的业务系统下表现不是很稳定，可能会出现复制延时、切换失效等问题。 **MMM方案并不太适应于对数据安全性要求很高，并且读、写繁忙的环境中。 ** 适用场景: MMM的适用场景为数据库访问量大，并且能实现读写分离的场景。 Mmm主要功能由下面三个脚本提供: mmm_mond 负责所有的监控工作的监控守护进程，决定节点的移除(mmm_mond进程定时心跳检测，失败则将write ip浮动到另外一台master)等等 mmm_agentd 运行在mysql服务器上的代理守护进程，通过简单远程服务集提供给监控节点 mmm_control 通过命令行管理mmm_mond进程 在整个监管过程中，需要在mysql中添加相关授权用户，授权的用户包括一个mmm_monitor用户和一个mmm_agent用户，如果想使用mmm的备份工具则还要添加一个mmm_tools用户。 2、MySQL-MMM工作原理 MMM(Master-Master replication managerfor Mysql，Mysql主主复制管理器)是一套灵活的脚本程序，基于perl实现，用来对mysql replication进行监控和故障迁移，并能管理mysql Master-Master复制的配置(同一时间只有一个节点是可写的)。 mmm_mond：监控进程，负责所有的监控工作，决定和处理所有节点角色活动。此脚本需要在监管机上运行。 mmm_agentd：运行在每个mysql服务器上的代理进程，完成监控的探针工作和执行简单的远端服务设置。此脚本需要在被监管机上运行,通过简单远程服务集提供给监控节点。 mmm_control：一个简单的脚本，提供管理mmm_mond进程的命令(通过命令行管理mmm_mond进程 在整个监管过程中，需要在mysql中添加相关授权用户，授权的用户包括一个mmm_monitor用户和一个mmm_agent用户，如果想使用mmm的备份工具则还要添加一个mmm_tools用户)。 mysql-mmm的监管端会提供多个虚拟IP（VIP），包括一个可写VIP，多个可读VIP，通过监管的管理，这些IP会绑定在可用mysql之上，当某一台mysql宕机时，监管会将VIP迁移至其他mysql。 在整个监管过程中，需要在mysql中添加相关授权用户，以便让mysql可以支持监理机的维护。授权的用户包括一个mmm_monitor用户和一个mmm_agent用户，如果想使用mmm的备份工具则还要添加一个mmm_tools用户。 3、实验环境 主机 角色 IP server id Write IP Read IP 备注 masterA monitoring 192.168.1.10 —— 监控机，运行MMM Daemon程序 masterB master1 192.168.1.11 1 192.168.1.100 192.168.1.110 默认为active Master，运行mmm agent mysqlC master2 192.168.1.12 2 192.168.1.111 默认为passive Master，运行mmm agent mysqlD slave1 192.168.1.13 3 192.168.1.112 Slave，由MMM维护，运行mmm agent 业务中的服务ip信息如下所示： ip地址 角色 描述 192.168.1.100 write 应用程序连接该ip对主库进行写请求 192.168.1.110 read 应用程序连接该ip进行读请求 192.168.1.111 read 应用程序连接该ip进行读请求 192.168.1.112 read 应用程序连接该ip进行读请求 数据库同步需要的用户： function description privileges monitor user mmm监控用于对mysql服务器进程健康检查 REPLICATION CLIENT agent user mmm代理用来更改只读模式，复制的主服务器等 SUPER, REPLICATION CLIENT, PROCESS replication user 用于复制 REPLICATION SLAVE 二、部署主从服务 1、在所有主机上配置 （1）修改/etc/hosts文件 12345[root@masterA ~]# vim /etc/hosts192.168.1.10 masterA192.168.1.11 masterB192.168.1.12 mysqlC192.168.1.13 mysqlD （2）校时操作 1234#安装ntpdate工具yum install ntpdate -y#使用ntpdate校时（后面的是ntp服务器）ntpdate pool.ntp.org （3）关闭selinux 12setenforce 0sed -i 's/enforcing/disabled/g' /etc/selinux/config 2、首先在3台主机上安装mysql和搭建复制（192.168.1.11和192.168.1.12互为主从，192.168.1.13为192.168.1.11的从）具体的复制搭建这里就省略，要是这都不会，那么该文章对你就没意思了。然后在每个mysql的配置文件中加入以下内容，注意server_id 不能重复。 masterB（192.168.1.11）上： 12345678910111213[root@masterB ~]# vi /etc/my.cnf #添加如下[mysqld]binlog-do-db=test #需要记录二进制日志的数据库，多个用逗号隔开binlog-ignore-db=mysql，information_schema #不需要记录二进制日志的数据库，多个用逗号隔开auto_increment_increment=2 #字段一次递增多少auto_increment_offset=1 #自增字段的起始值，值设置不同replicate-do-db=test #同步的数据库，多个写多行replicate-ignore-db = information_schema #不同步的数据库，多个写多行server_id = 1 #每台设置不同log_bin = mysql-binlog_slave_updates #当一个主故障，另一个立即接管sync-binlog=1 #每条自动更新，安全性高，默认是0[root@masterB ~]# systemctl restart mysqld mysqlC（192.168.1.11）上： 12345678910111213[root@mysqlC ~]# vim /etc/my.cnf [mysqld]binlog-do-db=test binlog-ignore-db=mysql，information_schema auto_increment_increment=2 auto_increment_offset=2 replicate-do-db=test #同步的数据库，多个写多行replicate-ignore-db = information_schema server_id = 2 log_bin = mysql-binlog_slave_updates sync-binlog=1 [root@mysqlC ~]# systemctl restart mysqld mysqlD（192.168.1.11）上： 12345678910111213[root@mysqlD ~]# vim /etc/my.cnf [mysqld]binlog-do-db=test binlog-ignore-db=mysql，information_schema auto_increment_increment=2 auto_increment_offset=3 replicate-do-db=test replicate-ignore-db = information_schemaserver_id = 3 log_bin = mysql-binlog_slave_updates sync-binlog=1 [root@mysqlD ~]# systemctl restart mysqld 3、设置masterB和mysqlC双主复制 （1）masterB操作 查看log bin日志和pos值位置 1234567891011121314mysql&gt; grant replication slave ,replication client on *.* to repl@'192.168.1.12' identified by \"repl123\";mysql&gt; flush privileges;# 注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status; +------------------+----------+--------------+----------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+----------------------------+-------------------+| mysql-bin.000001 | 2058 | test | mysql，information_schema | |+------------------+----------+--------------+----------------------------+-------------------+1 row in set (0.00 sec) （2）mysqlC操作 查看log bin日志和pos值位置 12345678910111213mysql&gt; grant replication slave ,replication client on *.* to repl@'192.168.1.11' identified by \"repl123\";mysql&gt; flush privileges;# 注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status; +------------------+----------+--------------+----------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+----------------------------+-------------------+| mysql-bin.000001 | 630 | test | mysql，information_schema | |+------------------+----------+--------------+----------------------------+-------------------+1 row in set (0.00 sec) （3）mysqlC同步masterB 确保mysqlC上要同步的数据，提前在masterB上存在，最好双方数据保持一致。 123456789101112#先解锁，将对方数据同步到自己的数据库中mysql&gt; unlock tables; mysql&gt; stop slave;mysql&gt; change master to master_host='192.168.1.11',master_user='repl',master_password='repl123',master_log_file='mysql-bin.000001',master_log_pos=2058;mysql&gt; start slave;mysql&gt; show slave status \\Gtrue .................. Slave_IO_Running: Yes Slave_SQL_Running: Yes .................. 这样就实现了slave－&gt;master的同步环境。 （4）masterB同步mysqlC 确保mysqlC上要同步的数据，提前在masterB上存在，最好双方数据保持一致。 123456789101112#先解锁，将对方数据同步到自己的数据库中mysql&gt; unlock tables; mysql&gt; stop slave;mysql&gt; change master to master_host='192.168.1.12',master_user='repl',master_password='repl123',master_log_file='mysql-bin.000001',master_log_pos=630;mysql&gt; start slave;mysql&gt; show slave status \\Gtrue .................. Slave_IO_Running: Yes Slave_SQL_Running: Yes .................. 测试一下双主 masterB插入数据 12345mysql&gt; use testmysql&gt; create table xgp (xm int(10));mysql&gt; insert into xgp(xm) -&gt; VALUES(10);Query OK, 1 row affected (0.01 sec) mysqlC查看数据 1234567mysql&gt; select * from test.xgp;+------+| xm |+------+| 10 |+------+1 row in set (0.00 sec) 可以看到已经成功同步过去，同样在test插入到xgp表数据，也能同步过去。我们的双主就成功了，开始做主从复制。 4、设置mysqlD为masterB的从服务器 （1）查看一下masterB的log bin日志和pos值位置 12345678910111213mysql&gt; grant replication slave ,replication client on *.* to repl@'192.168.1.11' identified by \"repl123\";mysql&gt; flush privileges;# 注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status;+------------------+----------+--------------+----------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+----------------------------+-------------------+| mysql-bin.000001 | 2825 | test | mysql，information_schema | |+------------------+----------+--------------+----------------------------+-------------------+1 row in set (0.00 sec) （2）mysqlD的操作 12345678910mysql&gt; unlock tables; mysql&gt; stop slave; #执行同步前，要先关闭slavemysql&gt; change master to master_host='192.168.1.11',master_user='repl',master_password='repl123',master_log_file='mysql-bin.000001',master_log_pos=2825; mysql&gt; start slave;mysql&gt; show slave status \\G....... Slave_IO_Running: Yes Slave_SQL_Running: Yes...... 测试一下主从 masterB插入数据 12345mysql&gt; create table wer (xm int(10));Query OK, 0 rows affected (0.01 sec)mysql&gt; insert into wer(xm) VALUES(10);Query OK, 1 row affected (0.00 sec) mysqlD查看数据 1234567mysql&gt; select * from test.wer;+------+| xm |+------+| 10 |+------+1 row in set (0.00 sec) 三、在四台db节点授权monitor访问 1、mysql-mmm配置：在3台mysql节点上创建用户创建代理账号： 1mysql&gt; grant super,replication client,process on *.* to 'mmm_agent'@'192.168.1.%' identified by '123456'; 2、创建监控账号（3台mysql节点）： 1mysql&gt; grant replication client on *.* to 'mmm_monitor'@'192.168.1.%' identified by '123456'; 因为之前的主主复制，以及主从已经是ok的，所以我在masterB服务器执行就ok了。 检查mysqlC、mysqlD两台db上是否都存在监控和代理账号 123456789101112131415161718mysql&gt; select user,host from mysql.user where user in ('mmm_monitor','mmm_agent');+-------------+-------------+| user | host |+-------------+-------------+| mmm_agent | 192.168.1.% || mmm_monitor | 192.168.1.% |+-------------+-------------+2 rows in set (0.00 sec)或mysql&gt; show grants for 'mmm_agent'@'192.168.1.%';+------------------------------------------------------------------------------+| Grants for mmm_agent@192.168.1.% |+------------------------------------------------------------------------------+| GRANT PROCESS, SUPER, REPLICATION CLIENT ON *.* TO 'mmm_agent'@'192.168.1.%' |+------------------------------------------------------------------------------+1 row in set (0.00 sec) **mmm_monitor用户：mmm监控用于对mysql服务器进程健康检查 ** mmm_agent用户：mmm代理用来更改只读模式，复制的主服务器等。 四、MySQL-MMM安装配置 CentOS默认没有mysql-mmm软件包，官方推荐使用epel的网络源，四台都安装epel： 1rpm -ivh http://mirrors.ustc.edu.cn/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpm 安装方法一（目前可以） （1）在所有主机上安装perl perl-devel perl-CPAN libart_lgpl.x86_64 rrdtool.x86_64 rrdtool-perl.x86_64包 1234567891011121314151617181920212223242526# 安装阿里云的 网络yum 源 [root@masterA ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo#安装perl依赖（可能会失败）[root@masterA ~]# yum -y install perl-* libart_lgpl.x86_64 rrdtool.x86_64 rrdtool-perl.x86_64 #安装perl的相关库，默认为国外的源，可以直接使用如下命令进行安装[root@masterA ~]# cpan -i Algorithm::Diff Class::Singleton DBI DBD::mysql Log::Dispatch Log::Log4perl Mail::Send Net::Ping Proc::Daemon Time::HiRes Params::Validate Net::ARP#这里我使用的是阿里云的cpan，所以需要更改镜像源[root@masterA ~]# cpan # 初始化cpan[1]&gt; o conf urllist # 查看当前有的URL urllist 0 [http://mirror.navercorp.com/CPAN/] 1 [http://cpan.mirror.cdnetworks.com/] 2 [http://cpan.rinet.ru/]Type 'o conf' to view all configuration items#删除当前有的urlcpan[6]&gt; o conf urllist pop http://cpan.mirror.cdnetworks.com/cpan[10]&gt; o conf urllist pop http://mirror.navercorp.com/CPAN/cpan[13]&gt; o conf urllist pop http://cpan.rinet.ru/#添加阿里云的镜像源cpan[16]&gt; o conf urllist push https://mirrors.aliyun.com/CPAN/cpan[17]&gt; o conf commit # 提交#安装perl的相关库[root@masterA ~]# cpan -i Algorithm::Diff Class::Singleton DBI DBD::mysql Log::Dispatch Log::Log4perl Mail::Send Net::Ping Proc::Daemon Time::HiRes Params::Validate Net::ARP 哦。。。报错了，排查发现DBD-mysql、Net-ping、Net::ARP这是哪个没有安装成功，所以下载软件包手动安装试试 123456789101112131415[root@masterA ~]# wget https://cpan.metacpan.org/authors/id/C/CR/CRAZYDJ/Net-ARP-1.0.11.tgz[root@masterA ~]# wget https://cpan.metacpan.org/authors/id/R/RU/RURBAN/Net-Ping-2.73.tar.gz[root@masterA ~]# wget https://cpan.metacpan.org/authors/id/D/DV/DVEEDEN/DBD-mysql-4.050.tar.gz[root@masterA ~]# tar zxf DBD-mysql-4.050.tar.gz [root@masterA ~]# cd DBD-mysql-4.050/[root@masterA DBD-mysql-4.050]# perl Makefile.PL[root@masterA DBD-mysql-4.050]# make install [root@masterA ~]# tar zxf Net-Ping-2.73.tar.gz [root@masterA ~]# cd Net-Ping-2.73/[root@masterA Net-Ping-2.73]# perl Makefile.PL [root@masterA Net-Ping-2.73]# make install [root@masterA ~]# tar zxf Net-ARP-1.0.11.tgz [root@masterA ~]# cd Net-ARP-1.0.11/[root@masterA Net-ARP-1.0.11]# perl Makefile.PL [root@masterA Net-ARP-1.0.11]# make install perl的相关库安装成功如下所示 1[root@masterA ~]# cpan -i Algorithm::Diff Class::Singleton DBI DBD::mysql Log::Dispatch Log::Log4perl Mail::Send Net::Ping Proc::Daemon Time::HiRes Params::Validate Net::ARP （2）MMM套件安装 在Monitor端安装所有MMM组件 123[root@masterA ~]# yum install epel-release.noarch -y[root@masterA ~]# yum install mysql-mmm-monitor -y#mysql-mmm mysql-mmm-agent mysql-mmm-tools 这些也可以安装一下 在其他所有节点安装mysql-mmm-agent 12[root@masterB ~]# yum install epel-release.noarch -y[root@masterB ~]# yum install mysql-mmm-agent -y 安装方法二 1、monitor节点安装 12345[root@masterA ~]# wget http://pkgs.fedoraproject.org/repo/pkgs/mysql-mmm/mysql-mmm-2.2.1.tar.gz/f5f8b48bdf89251d3183328f0249461e/mysql-mmm-2.2.1.tar.gz[root@masterA ~]# tar -zxf mysql-mmm-2.2.1.tar.gz[root@masterA ~]# cd mysql-mmm-2.2.1[root@masterA ~]# make install 或 1[root@masterA ~]# yum -y install gcc gcc-c++ mysql-mmm-monitor 2、在数据库服务器(masterB、mysqlC、mysqlD)上安装代理 12345[root@masterB ~]# wget http://pkgs.fedoraproject.org/repo/pkgs/mysql-mmm/mysql-mmm-2.2.1.tar.gz/f5f8b48bdf89251d3183328f0249461e/mysql-mmm-2.2.1.tar.gz[root@masterB ~]# tar -zxf mysql-mmm-2.2.1.tar.gz[root@masterB ~]# cd mysql-mmm-2.2.1[root@masterB ~]# make install 或 1[root@masterB ~]# yum -y install gcc gcc-c++ mysql-mmm-agent mysql-mmm安装后的主要拓扑结构如下所示（注意：yum安装的和源码安装的路径有所区别）： 1234567目录 介绍/usr/lib/perl5/vendor_perl/5.8.8/MMM MMM使用的主要perl模块/usr/lib/mysql-mmm MMM使用的主要脚本/usr/sbin MMM使用的主要命令的路径/etc/init.d/ MMM的agent和monitor启动服务的目录/etc/mysql-mmm MMM配置文件的路径，默认所以的配置文件位于该目录下/var/log/mysql-mmm 默认的MMM保存日志的位置 到这里已经完成了MMM的基本需求，接下来需要配置具体的配置文件，其中mmm_common.conf，mmm_agent.conf为agent端的配置文件，mmm_mon.conf为monitor端的配置文件。 继续剩下的 3、修改mmm_common.conf文件（四台相同） 完成安装后，所有的配置文件都放到了/etc/mysql-mmm/下面。管理服务器和数据库服务器上都要包含一个共同的文件mmm_common.conf 范例 123456789101112131415161718192021222324252627282930313233343536373839[root@mysqlC ~]# vim /etc/mysql-mmm/mmm_common.confactive_master_role writer#积极的master角色的标示，所有的db服务器要开启read_only参数，对于writer服务器监控代理会自动将read_only属性关闭。&lt;host default&gt;truetruecluster_interface eno16777736#群集的网络接口truetruepid_path /var/run/mmm_agentd.pid#pid路径truetruebin_path /usr/lib/mysql-mmm/#可执行文件路径truetruereplication_user rep#复制用户truetruereplication_password 123456#复制用户密码truetrueagent_user mmm_agent#代理用户truetrueagent_password 123456#代理用户密码&lt;/host&gt;&lt;host master1&gt;#master1的host名truetrueip 192.168.31.83#master1的iptruetruemode master#角色属性，master代表是主truetruepeer master2#与master1对等的服务器的host名，也就是master2的服务器host名&lt;/host&gt;&lt;host master2&gt;#和master的概念一样truetrueip 192.168.31.141truetruemode mastertruetruepeer master1&lt;/host&gt;&lt;host slave1&gt;#从库的host名,如果存在多个从库可以重复一样的配置truetrueip 192.168.31.250#从的iptruetruemode slave#slave的角色属性代表当前host是从&lt;/host&gt;&lt;host slave2&gt;#和slave的概念一样truetrueip 192.168.31.225truetruemode slave&lt;/host&gt;&lt;role writer&gt;#writer角色配置 hosts master1,master2#能进行写操作的服务器的host名，如果不想切换写操作这里可以只配置master,这样也可以避免因为网络延时而进行write的切换，但是一旦master出现故障那么当前的MMM就没有writer了只有对外的read操作。 ips 192.168.31.2#对外提供的写操作的虚拟IP mode exclusive#exclusive代表只允许存在一个主，也就是只能提供一个写的IP&lt;/role&gt;&lt;role reader&gt;#read角色配置 truetruehosts master2,slave1,slave2#对外提供读操作的服务器的host名,当然这里也可以把master加进来truetrueips 192.168.31.3, 192.168.31.4, 192.168.31.5#对外提供读操作的虚拟ip，这三个ip和host不是一一对应的,并且ips也hosts的数目也可以不相同，如果这样配置的话其中一个hosts会分配两个ip mode balanced#balanced代表负载均衡&lt;/role&gt; 修改 1234567891011121314151617181920212223242526272829303132333435363738394041[root@mysqlC ~]# vim /etc/mysql-mmm/mmm_common.confactive_master_role writer&lt;host default&gt; cluster_interface ens33 pid_path /run/mysql-mmm-agent.pid bin_path /usr/libexec/mysql-mmm/ replication_user replicant replication_password 123456 agent_user mmm_agent agent_password 123456&lt;/host&gt;&lt;host masterB&gt; ip 192.168.1.11 mode master peer mysqlC&lt;/host&gt;&lt;host mysqlC&gt; ip 192.168.1.12 mode master peer masterB&lt;/host&gt;&lt;host mysqlD&gt; ip 192.168.1.13 mode slave&lt;/host&gt;&lt;role writer&gt; hosts masterB, mysqlC ips 192.168.1.100 mode exclusive&lt;/role&gt;&lt;role reader&gt; hosts masterB, mysqlC, mysqlD ips 192.168.1.110, 192.168.1.111, 192.168.1.112 mode balanced&lt;/role&gt; 通过scp命令传送到其他三台： 12345[root@masterA ~]# scp -r /etc/mysql-mmm/mmm_common.conf masterB:/etc/mysql-mmm/[root@masterA ~]# scp -r /etc/mysql-mmm/mmm_common.conf mysqlC:/etc/mysql-mmm/[root@masterA ~]# scp -r /etc/mysql-mmm/mmm_common.conf mysqlD:/etc/mysql-mmm/#也有一个更简便的方法[root@master1] for host in masterA masterB mysqlC mysqlD ; do scp /etc/mysql-mmm/mmm_common.conf $host:/etc/mysql-mmm/ ; done 4、修改三台db代理端mmm_agent.conf文件 1234[root@masterA ~]# vim /etc/mysql-mmm/mmm_agent.confinclude mmm_common.confthis mysqlD #分别修改为本机的主机名 注意：这个配置只配置db服务器，监控服务器不需要配置，this后面的host名改成当前服务器的主机名。 启动代理进程 在 /etc/init.d/mysql-mmm-agent的脚本文件的#!/bin/sh下面，加入如下内容（所有db服务器上） 1234[root@masterB ~]# vim /etc/init.d/mysql-mmm-agent #!/bin/shsource /root/.bash_profile 5、修改管理端mmm_mon.conf文件 范例 1234567891011121314151617181920212223[root@masterA ~]# vim /etc/mysql-mmm/mmm_mon.confinclude mmm_common.conf&lt;monitor&gt; ip 127.0.0.1 pid_path /var/run/mysql-mmm/mmm_mond.pid bin_path /usr/libexec/mysql-mmm status_path /var/lib/mysql-mmm/mmm_mond.status ping_ips 192.168.1.11,192.168.1.12,192.168.1.13 #真实数据库IP，来检测网络是否正常，这里不要写入本机地址 auto_set_online 10 #设置自动online的时间，默认是超过60s就将它设置为online，默认是60s， 这里将其设为0就是立即online&lt;/monitor&gt;&lt;check default&gt;truecheck_period 5 # 检查周期默认为5s truetrap_period 10 # 一个节点被检测不成功的时间持续trap_period秒，就慎重的认为这个节点失败了truetimeout 2 # 检查超时的时间 true#restart_after 10000 # 在完成restart_after次检查后，重启checker进程 truemax_backlog 86400 # 记录检查rep_backlog日志的最大次数 &lt;/check&gt;&lt;host default&gt; monitor_user mmm_monitor monitor_password 123456&lt;/host&gt;debug 0 # 0正常模式，1为debug模式 修改 123456789101112131415161718192021222324252627282930313233[root@masterA ~]# vim /etc/mysql-mmm/mmm_mon.confinclude mmm_common.conf&lt;monitor&gt; ip 127.0.0.1 pid_path /run/mysql-mmm-monitor.pid bin_path /usr/libexec/mysql-mmm status_path /var/lib/mysql-mmm/mmm_mond.status ping_ips 192.168.1.11, 192.168.1.12, 192.168.1.13 auto_set_online 60 # The kill_host_bin does not exist by default, though the monitor will # throw a warning about it missing. See the section 5.10 \"Kill Host # Functionality\" in the PDF documentation. # # kill_host_bin /usr/libexec/mysql-mmm/monitor/kill_host #&lt;/monitor&gt;&lt;check default&gt; check_period 5 trap_period 10 timeout 2 #restart_after 10000 max_backlog 86400&lt;/check&gt;&lt;host default&gt; monitor_user mmm_monitor monitor_password 123456&lt;/host&gt;debug 0 五、启动MySQL-MMM 无论是在db端还是在监控端如果有对配置文件进行修改操作都需要重启代理进程和监控进程。 MMM启动顺序：先启动monitor，再启动 agent 1、安装方法一的启动方式 （1）monitor管理端启动 1[root@masterA ~]# systemctl start mysql-mmm-monitor 查看状态 1[root@masterA ~]# systemctl status mysql-mmm-monitor 1[root@masterA ~]# netstat -anpt | grep 9988 （2）db代理端启动 1[root@masterB ~]# systemctl start mysql-mmm-agent 查看状态 1[root@masterB ~]# systemctl status mysql-mmm-agent 1[root@masterB ~]# netstat -anpt | grep 9989 安装方法二的启动方式 （1）monitor管理端启动 123456789101112#启动监控进程，加入如下内容[root@monitor ~]# vim /etc/init.d/mysql-mmm-monitor #!/bin/shsource /root/.bash_profile#添加成系统服务并设置为自启动[root@monitor ~]# chkconfig --add mysql-mmm-monitor[root@monitor ~]# chkconfig mysql-mmm-monitor on[root@monitor ~]# /etc/init.d/mysql-mmm-monitor start Daemon bin: '/usr/sbin/mmm_mond'Daemon pid: '/var/run/mmm_mond.pid'Starting MMM Monitor daemon: Ok 启动报错: 123456Starting MMM Monitor daemon: Can not locate Proc/Daemon.pm in @INC (@INC contains:/usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl/usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at/usr/sbin/mmm_mond line 11.BEGIN failed--compilation aborted at /usr/sbin/mmm_mond line 11.failed 解决方法：安装下列perl的库 123456789# yum -y install cpan# cpan Proc::Daemon# cpan Log::Log4perl# /etc/init.d/mysql-mmm-agent startDaemon bin: '/usr/sbin/mmm_agentd'Daemon pid: '/var/run/mmm_agentd.pid'Starting MMM Agent daemon... Ok # netstat -anpt | grep 9988tcp 0 0 127.0.0.1:9988 0.0.0.0:* LISTEN 8546/mmm_mond （2）db代理端启动 12345#启动代理进程 在 /etc/init.d/mysql-mmm-agent的脚本文件的#!/bin/sh下面，加入如下内容（所有db服务器上）[root@masterB ~]# vim /etc/init.d/mysql-mmm-agent #!/bin/shsource /root/.bash_profile#添加成系统服务并设置为自启动 添加成系统服务并设置为自启动 123456[root@masterB ~]# chkconfig --add mysql-mmm-agent[root@masterB ~]# chkconfig mysql-mmm-agent on[root@masterB ~]# /etc/init.d/mysql-mmm-agent start Daemon bin: '/usr/sbin/mmm_agentd'Daemon pid: '/var/run/mmm_agentd.pid'Starting MMM Agent daemon... Ok 注：添加source /root/.bash_profile目的是为了mysql-mmm-agent服务能启机自启。 自动启动和手动启动的唯一区别，就是激活一个console 。那么说明在作为服务启动的时候，可能是由于缺少环境变量 服务启动失败，报错信息如下： 12345678Daemon bin: '/usr/sbin/mmm_agentd'Daemon pid: '/var/run/mmm_agentd.pid'Starting MMM Agent daemon... Can't locate Proc/Daemon.pm in @INC (@INC conta/usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl/usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at/usr/sbin/mmm_agentd line 7.BEGIN failed--compilation aborted at /usr/sbin/mmm_agentd line 7.failed 解决方法： 123456789\\# yum -y install cpan\\# cpan Proc::Daemon\\# cpan Log::Log4perl\\# /etc/init.d/mysql-mmm-agent startDaemon bin: '/usr/sbin/mmm_agentd'Daemon pid: '/var/run/mmm_agentd.pid'Starting MMM Agent daemon... Ok # netstat -antp | grep mmm_agentdtcp 0 0 192.168.31.83:9989 0.0.0.0:* LISTEN 9693/mmm_agentd 3、启动成功后操作 （1）monitor查看群集的最新状态 1234[root@masterA ~]# mmm_control show masterB(192.168.1.11) master/HARD_OFFLINE. Roles: mysqlC(192.168.1.12) master/HARD_OFFLINE. Roles: mysqlD(192.168.1.13) slave/HARD_OFFLINE. Roles: 如果服务器状态不是ONLINE，可以用如下命令将服务器上线，例如： 1234#如果一直显示等待，可手动设置[root@masterA ~]# mmm_control set_online masterB[root@masterA ~]# mmm_control set_online mysqlC[root@masterA ~]# mmm_control set_online mysqlD","path":"posts/b9cm.html","date":"06-29","excerpt":"","tags":[]},{"title":"Keepalived高可用","text":"下面我们就完成keepalived的高可用性。 keepalived是集群管理中保证集群高可用的一个软件解决方案，其功 能类似于heartbeat，用来防止单点故障 keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。 虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即 将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个 对外提供服务的vip，master会发组播（组播地址为224.0.0.18），当backup收不到vrrp包时就认为master宕掉 了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 keepalived主要有三个模块，分别是core 、check和vrrp。core模块为keepalived的核心，负责主进程的启动、 维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现 VRRP协议的。 一、Keepalived高可用 1、Keepalived简介 keepalived是集群管理中保证集群高可用的一个软件解决方案，其功能类似于heartbeat，用来防止单点故障 keepalived是以VRRP协议为实现基础的，VRRP全称Virtual RouterRedundancy Protocol，即虚拟路由冗余协议。 2、Keepalived工作原理 虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip，master会发组播（组播地址为224.0.0.18），当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 keepalived主要有三个模块，分别是core 、check和vrrp。 123(1)core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。(2)check负责健康检查，包括常见的各种检查方式。(3)vrrp模块是来实现VRRP协议的。 3、keepalived的安装配置 （1）在master1和master2上安装软件包keepalived 在master1和master2上安装软件包keepalived，安装keepalived软件包与服务控制在编译安装Keepalived之前，必须先安装内核开发包kernel-devel以及openssl-devel、popt-devel等支持库。 1[root@masterA ~]# wget https://www.keepalived.org/software/keepalived-2.0.20.tar.gz 安装依赖库 1[root@masterA ~]# yum -y install kernel-devel openssl-devel popt-devel 解压 1[root@masterA ~]# tar -zxf keepalived-2.0.20.tar.gz 安装 12[root@masterA ~]# cd keepalived-2.0.20/[root@masterA ~]# ./configure --prefix=/ &amp;&amp; make &amp;&amp; make install 注意：如不知道keepalived需要哪些依赖包，可到下载后的源码解压目录下查看INSTALL 文件内容， 执行make install操作之后，会自动生成/etc/init.d/keepalived脚本文件，但还需要手动添加为系统服务，这样就可以使用 service、chkconfig工具来对keepalived服务程序进行管理了。 可能出现的错误 1234567./configure 后显示checking forgcc... nochecking forcc... nochecking for cl.exe... noconfigure.sh:error:no acceptable C compiler found in$PATHSee 'config.log'for more details. 解决办法：yum -y install gcc 注意：如不知道keepalived需要哪些依赖包，可到下载后的源码解压目录下查看INSTALL 文件内容， 执行make install操作之后，会自动生成/etc/init.d/keepalived脚本文件，但还需要手动添加为系统服务，这样就可以使用 service、chkconfig工具来对keepalived服务程序进行管理了。 另外：若开启了防火墙，需要关闭防火墙或创建规则。 创建防火墙规则： 12345# firewall-cmd --direct --permanent --add-rule ipv4 filter OUTPUT 0 --ininterface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPT# firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --ininterface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPT# firewall-cmd --reload （2）修改Keepalived的配置文件 keepalived只有一个配置文件keepalived.conf, 里面主要包括以下几个配置区域: global_defs：主要是配置故障发生时的通知对象以及 机器标识。 vrrp_instance：用来定义对外提供服务的VIP区域及其相关属性。 virtual_server：虚拟服务器定义 范例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172[root@mysqlA ~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalived //!表示注释global_defs &#123; router_id MYSQL-1 //表示运行keepalived服务器的一个标识&#125;vrrp_instance VI_1 &#123; # 指定keepalived的角色, 两台配置此处均是BACKUP,设为BACKUP将根据优先级决定主或从 state BACKUP # 指定HA监测网络的接口 interface ens33 # 虚拟路由标识，这个标识是一个数字(取值在0-255之间,用来区分多个instance的VRRP组播)， # 同一个vrrp实例使用唯一的标识,确保和master2相同，同网内不同集群此项必须不同,否则发生冲突。 virtual_router_id 51 # 用来选举master的，要成为master，该项取值范围是1-255（在此范围之外会被识别成默认值100）, # 此处master2上设置为50 priority 100 # 发VRRP包的时间间隔，即多久进行一次master选举（可以认为是健康查检时间间隔） advert_int 1 # 不抢占，即允许一个priority比较低的节点作为master，即使有priority更高的节点启动 nopreempt # 认证区域，认证类型有PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位） authentication &#123; auth_type PASS auth_pass 1111 &#125; # VIP区域，指定vip地址 virtual_ipaddress &#123; 192.168.1.100 &#125;&#125;# 设置虚拟服务器，需要指定虚拟IP地址和服务端口，IP与端口之间用空格隔开virtual_server 192.168.1.100 3306 &#123; # 设置运行情况检查时间，单位是秒 delay_loop 2 # 设置后端调度算法，这里设置为rr，即轮询算法 lb_algo rr # 设置LVS实现负载均衡的机制，有NAT、TUN、DR三个模式可选 lb_kind DR # 会话保持时间，单位是秒。 # 这个选项对动态网页是非常有用的，为集群系统中的session共享提供了一个很好的解决方案。 # 有了这个会话保持功能，用户的请求会被一直分发到某个服务节点，直到超过这个会话的保持时间。 persistence_timeout 60 # 指定转发协议类型，有TCP和UDP两种 protocol TCP # 配置服务节点1，需要指定real server的真实IP地址和端口，IP与端口之间用空格隔开 # 注：master 2上此处改为192.168.1.20(即master2本机ip) real_server 192.168.1.10 3306 &#123; # 配置服务节点的权值，权值大小用数字表示，数字越大，权值越高， # 设置权值大小为了区分不同性能的服务器 weight 3 # 检测到realserver的mysql服务down后执行的脚本 notify_down /etc/keepalived/bin/mysql.sh TCP_CHECK &#123; # 连接超时时间 connect_timeout 3 # 重连次数 nb_get_retry 3 # 重连间隔时间 delay_before_retry 3 # 健康检查端口 connect_port 3306 &#125; &#125;&#125;[root@mysql /]# systemctl start keepalived masterA的配置 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@mysqlA ~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; router_id mysql-1&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 100 advert_int 1 nopreempt authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.100 &#125;&#125;virtual_server 192.168.1.100 3306 &#123; delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 60 protocol TCP real_server 192.168.1.10 3306 &#123; weight 1 notify_down /etc/keepalived/bin/mysql.sh TCP_CHECK &#123; connect_port 3306 connect_timeout 3 retry 3 delay_before_retry 3 &#125; &#125;&#125;[root@mysql /]# systemctl start keepalived masterB的配置 将masterA配置好的文件复制给master，稍加修改即可 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@mysqlB ~]# scp /etc/keepalived/keepalived.conf root@192.168.171.145:/etc/keepalived/! Configuration File for keepalivedglobal_defs &#123; router_id mysql-2&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 50 advert_int 1 nopreempt authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.100 &#125;&#125;virtual_server 192.168.1.100 3306 &#123; delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 60 protocol TCP real_server 192.168.1.11 3306 &#123; weight 1 notify_down /etc/keepalived/bin/mysql.sh TCP_CHECK &#123; connect_port 3306 connect_timeout 3 retry 3 delay_before_retry 3 &#125; &#125;&#125;[root@mysql ~]# systemctl start keepalived （3）编写检测脚本 在两台master上进行如下操作： 123456[root@mysql ~]# mkdir /etc/keepalived/bin[root@mysql ~]# vim /etc/keepalived/bin/mysql.sh#!/bin/bashpkill keepalived#赋予执行权限[root@mysql ~]# chmod +x /etc/keepalived/bin/mysql.sh master1 和master2 上都添加此检测脚本，作用是当 mysql 停止工作时自动关闭本机的keepalived，从而实现将故障机器踢出（因每台机器上keepalived 只添加了本机为 realserver）。 当 mysqld 正常启动起来后，要手动启动 keepalived 服务 （4）测试 1）测试一 在master1和master2分别执行ip addr show dev ens33命令查看master1和 master2对VIP（群集虚拟 IP）的控制权。 master1主的查看结果： master2主的查看结果： 从上图可以看出master1 是主服务器，master2 为备用服务器 2）测试二 停止MySQL服务，看keepalived健康检查程序是 否会触发我们编写的脚本 停止master1主机的mysql服务 masterA： 12[root@masterA ~]# systemctl stop mysqld[root@masterA ~]# ip addr show dev ens33 masterB： 1[root@masterA ~]# ip addr show dev ens33 这说明在主服务上停止MySQL服务，触发了我们编写的脚本，进行自动故障切换 3）MySQL 远程登录测试 我们找一台安装有MySQL 客户端，然后登录 VIP，看是否能登录。 在登录的两台 MySQL 服务器都要授权允许从远程登录。例如： 123456789101112[root@masterA ~]# mysql -uroot -pmysql&gt; set global validate_password_policy&#x3D;LOW;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password_length&#x3D;4;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant all on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;1234&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 在客户端上测试登录 123[root@master1 ~]# mysql -uroot -p -h 192.168.206.100 -P3306mysql&gt; show variables like &#39;server_id&#39;; 上图显示说明在客户端访问 VIP 地址，由 master1 主机提供响应的，因为 master1 当前是主服务器，将 master1 的 mysql 服务停止，在客户端执行 show variableslike‘server_id’; 123[root@master1 ~]# systemctl stop mysqldmysql&gt; show variables like &#39;server_id&#39;; 上图显示说明在客户端的查询请求是由 master2 主机响应的，故障切换成功。 二、Keepalived使用总结 Keepalived+mysql双主一般来说，中小型规模的时候，采用这种架构是最省事的。 在master节点发生 故障后，利用keepalived的高可用机制实现快速切换到备用节点。 在这个方案里，有几个需要注意的地方： 采用 keepalived 作为高可用方案时，两个节点最好都设置成 BACKUP模式，避免因为意外情况下（比如 脑裂）相互抢占导致往两个节点写入相同数据而引发冲突； 把两个节点的 auto_increment_increment（自增步长）和 auto_increment_offset（自增起始值）设成不同值。其目的是为了避免master 节点意外宕机时，可能会有部分 binlog 未能及时复制到slave上被应用，从而会导致slave新写入数据的自增值和原先master上冲突了，因此一开始就使其错开；当然了，如果有合适的容错机制能解决主从自增ID 冲突的话，也可以不这么做； slave 节点服务器配置不要太差，否则更容易导致复制延迟。作为热备节点的 slave服务器，硬件配置不能低于 master 节点； 如果对延迟问题很敏感的话，可考虑使用 MariaDB 分支版本，或者直接上线 MySQL 5.7 最新版本，利用多线程复制的方式可以很大程度降低复制延迟。","path":"posts/b9c4.html","date":"06-28","excerpt":"","tags":[]},{"title":"MySQL 高可用：主主复制（双主复制）","text":"MySQL 高可用：主主复制（双主复制） 生产环境中一台mysql主机存在单点故障，所以我们要确保mysql的高可用性，即两台MySQL服务器如果其中有一台MySQL服务器挂掉后，另外一台能立马接替其进行工作。 MySQL的高可用方案一般有如下几种： keepalived+双主，MHA，PXC，MMM，Heartbeat+DRBD等，比较常用的是keepalived+双主，MHA和PXC。 本节主要介绍了利用 keepalived 实现 MySQL数据库的高可用。 Keepalived+mysql双主来实现MySQL-HA，我们必须保证两台MySQL数据库的数据完全一样，基本思路是两台MySQL互为主从关系，通过Keepalived配置虚拟IP，实现当其中的一台MySQL数据库宕机后，应用能够自动切换到另外一台MySQL数据库，保证系统的高可用。 一、实验环境 主机 服务 ip 安装目录 数据目录 masterA mysql5.7 192.168.1.10 /usr/local/mysql /usr/local/mysql/data masterB mysql5.7 192.168.1.11 /usr/local/mysql /usr/local/mysql/data 注意下面几点： 1231. 要保证同步服务期间之间的网络联通。即能相互ping通，能使用对方授权信息连接到对方数据库（防火墙开放3306端口）。2. 关闭selinux。3. 同步前，双方数据库中需要同步的数据要保持一致。这样，同步环境实现后，再次更新的数据就会如期同步了。 二、MySQL复制 1、MySQL支持哪些复制 （1）基于语句的复制 在主服务器上执行的sql语句，在从服务器上执行同样的语句。mysql默认采用基于语句的复制，效率比较高。一旦发现没法精确复制时，会自动选择基于行的复制。 （2）基于行的复制 把改变的内容复制过去，而不是把命令在从服务器上执行一遍，从mysql 5.0开始支持。 （3）混合类型的复制 默认采用基于语句的复制，一旦发现基于语句的无法精确复制时，就会采用基于行的复制。 2、MySQL复制解决的问题 数据分布（data distribution） 负载平衡（load balancing） 数据备份（backup），保证数据安全 高可用性与容错行（high availability and failover） 实现读写分离，缓解数据库压力 3、MySQL主从复制原理 master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变。如果发生改变，则开始一个I/O Thread请求master二进制事件，同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志 中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/O Thread和SQL Thread将进入睡眠状态，等待下一次被唤醒。 注意几点： master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）。 -slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和 master数据保持一致了。 Mysql复制至少需要两个Mysql的服务，当然Mysql服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。 Mysql复制最好确保master和slave服务器上的Mysql版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本）。 master和slave两节点间时间需同步。 4、MySQL复制流程 在开始之前，我们先来了解主从同步复制原理。 复制分成三步： master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； slave将master的binary log events拷贝到它的中继日志(relay log)； slave重做中继日志中的事件，将改变反映它自己的数据。 Mysql复制的流程图如下： Mysql复制过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 第二部分就是slave将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。 此外，在master中也有一个工作线程：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 5、MySQL复制的模式 （1）主从复制 主库授权从库远程连接，读取binlog日志并更新到本地数据库的过程；主库写数据后，从库会自动同步过来（从库跟着主库变）。 （2）主主复制 主从相互授权连接，读取对方binlog日志并更新到本地数据库的过程；只要对方数据改变，自己就跟着改变。 6、MySQL主从复制优点 在从服务器可以执行查询工作(即我们常说的读功能)，降低主服务器压力;（主库写，从库读，降压） 在从主服务器进行备份，避免备份期间影响主服务器服务;（确保数据安全） 当主服务器出现问题时，可以切换到从服务器。（提升性能） 7、MySQL主从复制工作流程细节 （1）MySQL支持单向、异步复制，复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。 MySQL复制基于主服务器在二进制日志中跟踪所有对数据库的更改(更新、删除等等)。因此，要进行复制，必须在主服务器上启用二进制日志。每个从服务器从主服务器接收主服务器上已经记录到其二进制日志的保存的更新。当一个从服务器连接主服务器时，它通知主服务器定位到从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，并在本机上执行相同的更新。然后封锁并等待主服务器通知新的更新。从服务器执行备份不会干扰主服务器，在备份过程中主服务器可以继续处理更新。 （2）MySQL使用3个线程来执行复制功能，其中两个线程(Sql线程和IO线程)在从服务器，另外一个线程(IO线程)在主服务器。 当发出START SLAVE时，从服务器创建一个I/O线程，以连接主服务器并让它发送记录在其二进制日志中的语句。主服务器创建一个线程将二进制日志中的内容发送到从服务器。该线程可以即为主服务器上SHOW PROCESSLIST的输出中的Binlog Dump线程。从服务器I/O线程读取主服务器Binlog Dump线程发送的内容并将该数据拷贝到从服务器数据目录中的本地文件中，即中继日志。第3个线程是SQL线程，由从服务器创建，用于读取中继日志并执行日志中包含的更新。在从服务器上，读取和执行更新语句被分成两个独立的任务。当从服务器启动时，其I/O线程可以很快地从主服务器索取所有二进制日志内容，即使SQL线程执行更新的远远滞后。 8、总结 （1）主从数据完成同步的过程 在Slave 服务器上执行sart slave命令开启主从复制开关，开始进行主从复制。 此时，Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容。 Master服务器接收到来自Slave服务器的IO线程的请求后，其上负责复制的IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在Master服务器端记录的IO线程。返回的信息中除了binlog中的下一个指定更新位置。 当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（Mysql-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容。 Slave服务器端的SQL线程会实时检测本地Relay Log 中IO线程新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点。 （2）主从复制条件 12341）开启Binlog功能2）主库要建立账号3）从库要配置master.info（CHANGE MASTER to...相当于配置密码文件和Master的相关信息）4）start slave 开启复制功能 （3）需要了解的 123451）3个线程，主库IO，从库IO和SQL及作用2）master.info（从库）作用3）relay-log 作用4）异步复制5）binlog作用（如果需要级联需要开启Binlog） （4）需要注意的 123451）主从复制是异步的逻辑的SQL语句级的复制2）复制时，主库有一个I/O线程，从库有两个线程，I/O和SQL线程3）实现主从复制的必要条件是主库要开启记录binlog功能4）作为复制的所有Mysql节点的server-id都不能相同5）binlog文件只记录对数据库有更改的SQL语句（来自主库内容的变更），不记录任何查询（select，show）语句 三、配置两台MySQL主从复制 1、主从复制实现过程 （1）master配置（masterA） 1）配置master数据库的my.cnf文件 在[mysqld]配置区域添加下面内容： 123456789[root@masterA ~]# vim /etc/my.cnf[mysqld] server-id=1 #数据库唯一ID，主从的标识号绝对不能重复。log-bin=mysql-bin #开启bin-log，并指定文件目录和文件名前缀binlog-do-db=aaa #需要同步liting数据库。如果是多个同步库，就以此格式另写几行即可。如果不指明对某个具体库同步，就去掉此行，表示同步所有库（除了ignore忽略的库）。binlog-ignore-db=mysql #不同步mysql系统数据库。如果是多个不同步库，就以此格式另写几行；也可以在一行，中间逗号隔开。sync_binlog = 1 #确保binlog日志写入后与硬盘同步binlog_checksum = none #跳过现有的采用checksum的事件，mysql5.6.5以后的版本中binlog_checksum=crc32,而低版本都是binlog_checksum=nonebinlog_format = mixed #bin-log日志文件格式，设置为MIXED可以防止主键重复。 重启mysqld服务 1[root@masterA ~]# systemctl restart mysqld 温馨提示： 在主服务器上最重要的二进制日志设置是sync_binlog，这使得mysql在每次提交事务的时候把二进制日志的内容同步到磁盘上，即使服务器崩溃也会把事件写入日志中。 sync_binlog这个参数是对于MySQL系统来说是至关重要的，他不仅影响到Binlog对MySQL所带来的性能损耗，而且还影响到MySQL中数据的完整性。对于&quot;sync_binlog&quot;参数的各种设置的说明如下： sync_binlog=0，当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。 sync_binlog=n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。 在MySQL中系统默认的设置是sync_binlog=0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦系统Crash，在binlog_cache中的所有binlog信息都会被丢失。而当设置为“1”的时候，是最安全但是性能损耗最大的设置。因为当设置为1的时候，即使系统Crash，也最多丢失binlog_cache中未完成的一个事务，对实际数据没有任何实质性影响。 从以往经验和相关测试来看，对于高并发事务的系统来说，“sync_binlog”设置为0和设置为1的系统写入性能差距可能高达5倍甚至更多。 2）保证master与slave数据库一致 导出master数据库多余slave数据库中的数据，然后导入到slave数据库中。保证双方在同步环境实现前的数据一致。 注意：新建环境可忽略此步骤 导出数据库之前先锁定数据库 12# 数据库只读锁定命令，防止导出数据库的时候有数据写入。unlock tables命令解除锁定mysql&gt; flush tables with read lock; 导出master数据库中需要同步的库(master数据库的root用户登陆密码：123) 1234[root@masterA ~]# mysqldump -uroot aaa -p123 &gt;/opt/aaa.sql# 将导出的sql文件上传到slave机器上[root@masterA ~]# scp -r /opt/aaa.sql root@192.168.1.11:/opt 3）设置数据同步权限 12345mysql&gt; grant replication slave,replication client on *.* to repl@&#39;192.168.1.11&#39; identified by &quot;repl123&quot;; #只允许192.168.1.11使用repl，且密码为&quot;repl123&quot;连接主库做数据同步 #若要所有网段则设置repl@&#39;%&#39; ；部分网段：repl@&#39;192.168.0.%&#39;mysql&gt; flush privileges; 温馨提示： 权限查看方式 12mysql&gt; show grants;mysql&gt; show grants for repl@&#39;192.168.1.11&#39;; 4）查看主服务器master状态 注意File与Position项，从服务器需要这两项参数。 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000002 | 600 | liting | mysql | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) （2）slave配置 下面是slave数据库上的操作： 1）设置slave数据库的my.cnf文件 在[mysqld]配置区域添加下面内容： 1234567[root@masterB ~]# vim /etc/my.cnf[mysqld]server-id=2 #设置从服务器id，必须于主服务器不同log-bin=mysql-bin #启动MySQ二进制日志系统replicate-do-db=aaa #需要同步的数据库名。如果不指明同步哪些库，就去掉这行，表示所有库的同步（除了ignore忽略的库）。replicate-ignore-db=mysql #不同步test数据库slave-skip-errors = all #跳过所有的错误，继续执行复制操作 重启mysqld服务 1[root@masterB ~]# systemctl restart mysqld 温馨提示： 当只针对某些库的某张表进行同步时，如下，只同步aaa库的haha表和test库的heihei表： 1234replicate-do-db = aaareplicate-wild-do-table = aaa.haha ``//``当只同步几个或少数表时，可以这样设置。注意这要跟上面的库指定配合使用；replicate-do-db = testreplicate-wild-do-table = test.heihei ``//``如果同步的库的表比较多时，就不能这样一一指定了，就把这个选项配置去掉，直接根据指定的库进行同步。 2）保证master与slave数据库一致 在slave数据库中导入从master传过来的数据。 123456# 先创建一个aaa空库，否则下面导入数据时会报错说此库不存在。mysql&gt; CREATE DATABASE aaa CHARACTER SET utf8 COLLATE utf8_general_ci;mysql&gt; use aaa;# 导入master中多余的数据。mysql&gt; source &#x2F;opt&#x2F;aaa.sql; 或 1[root@masterB ~]# mysql -u root -p123&lt; /opt/aaa.sql 3）配置主从同步指令 123456789mysql&gt; stop slave; #执行同步前，要先关闭slavemysql&gt; change master to master_host&#x3D;&#39;192.168.1.10&#39;,master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;repl123&#39;,master_log_file&#x3D;&#39;mysql-bin.000002&#39;,master_log_pos&#x3D;600; mysql&gt; start slave;mysql&gt; show slave status \\G....... Slave_IO_Running: Yes Slave_SQL_Running: Yes...... 如上，当IO和SQL线程的状态均为Yes，则表示主从已实现同步了！ 4）异常解决— Slave_IO_Running: NO &lt;1&gt;解决问题的思路： 12341. 找到mysql配置的这个文件/etc/my.cnf2. 在文件中找到mysql错误异常日志文件的路径，我配置的是log-error=/var/log/mysqld.log3. 编辑/var/log/mysqld.log文件4. 查看具体异常信息 &lt;2&gt;异常信息： &lt;3&gt;问题定位：由于uuid相同，而导致触发此异常 &lt;4&gt;解决方案： 把uuid修改即可 &lt;5&gt;服务器背景： 环境：Centos7 , 5.7.25 MySQL 首先我只安装了一台linux 又克隆了两台，一主一从 , 关键点就在于我是克隆的，才导致了报Slave_IO_Running: NO 原因：mysql 有个uuid , 然而uuid 是唯一标识的，所以我克隆过来的uuid是一样的，只需要修改一下uuid 就ok了，找到auto.cnf 文件修改uuid &lt;6&gt;具体解决方案： 查询命令找此auto.cnf修改uuid即可： 1find -name auto.cnf &lt;7&gt;重新启动mysql 1service myqld restart &lt;8&gt;登录mysql，重启slave，再次验证 123456#停止链路stop slave;#启动链路start slave;#查看链路show slave status \\G ![image-20200630230616151](E:\\软件\\博客\\Blog\\blog\\source_posts\\124 MySQL 高可用：主主复制（双主复制）.assets\\image-20200630230616151.png) 2、测试 下面测试下Mysql主从同步的效果，在master主数据库上写入新数据 12345mysql&gt; use aaa;mysql&gt; create table if not exists haha (id int(10) PRIMARY KEY AUTO_INCREMENT,name varchar(50) NOT NULL);Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into haha values(100,&#39;anhui&#39;);Query OK, 1 row affected (0.00 sec) 然后在slave数据库上查看，发现master上新写入的数据已经同步过来了。 1234567mysql&gt; select * from aaa.haha;+-----+-----------+| id | name |+-----+-----------+| 100 | anhui |+-----+-----------+1 rows in set(0.00 sec) 至此，主从同步环境已经实现！ 四、配置两台MySQL主主复制 根据上面的主从环境部署，master和slave已经实现同步，即在master上写入新数据，自动同步到slave。而从库只能读不能写，一旦从库有写入数据，就会造成主从数据不一致！ 下面就说下Mysql主主复制环境，在slave上更新数据时，master也能自动同步过来。 1、温馨提示 在做主主同步前，提醒下需要特别注意的一个问题： 主主复制和主从复制有一些区别，因为多主中都可以对服务器有写权限，所以设计到自增长重复问题，例如： 出现的问题（多主自增长ID重复） 12341）首先在A和B两个库上创建test表结构;2）停掉A，在B上对数据表test(存在自增长属性的ID字段)执行插入操作，返回插入ID为1;3）然后停掉B，在A上对数据表test(存在自增长属性的ID字段)执行插入操作，返回的插入ID也是1;4）然后同时启动A,B，就会出现主键ID重复 2、解决方法 只要保证两台服务器上的数据库里插入的自增长数据不同就可以了。 如：A插入奇数ID，B插入偶数ID，当然如果服务器多的话，还可以自定义算法，只要不同就可以了。 在下面例子中，在两台主主服务器上加入参数，以实现奇偶插入！ 记住：在做主主同步时需要设置自增长的两个相关配置，如下： 12auto_increment_offset 表示自增长字段从那个数开始，取值范围是1 .. 65535。这个就是序号。如果有n台mysql机器，则从第一台开始分为设1，2...nauto_increment_increment 表示自增长字段每次递增的量，其默认值是1，取值范围是1 .. 65535。如果有n台mysql机器，这个值就设置为n。 在主主同步配置时，两台服务器的自增长参数设置如下： 12auto_increment_increment 增长量都配置为2auto_increment_offset 分别配置为1和2。这是序号，第一台从1开始，第二台就是2，以此类推..... 这样才可以避免两台服务器同时做更新时自增长字段的值之间发生冲突。（针对的是有自增长属性的字段） 3、master配置（masterA） 1) 配置master数据库的my.cnf文件 在[mysqld]配置区域添加下面内容: 12345678910111213[root@masterA ~]# vim /etc/my.cnf server-id = 1 #两台mysql要不同（1/2）log-bin = mysql-binbinlog-ignore-db = mysql,information_schemasync_binlog = 1binlog_checksum = nonebinlog_format = mixed#auto-increment-increment = 2 # 增长起始设置为2#auto-increment-offset = 1slave-skip-errors = all 2) 重启mysql 1[root@masterA ~]# systemctl restart mysqld 3) 设置数据同步授权 防火墙开启3306端口 12[root@masterA ~]# firewall-cmd --zone=public --add-port=3306/tcp --permanent[root@masterA ~]# firewall-cmd --reload 4）要确保对方机器能使用下面权限连接到本机mysql。 两台主机写互相的IP 12345mysql&gt; grant replication slave,replication client on *.* to repl@&#39;192.168.1.11&#39; identified by&#39;repl123&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 最好将库锁住，仅仅允许读，以保证数据一致性；待主主同步环境部署后再解锁；锁住后，就不能往表里写数据，但是重启mysql服务后就会自动解锁！ 12345678910# 注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！mysql&gt; FLUSH TABLES WITH READ LOCK;Query OK, 0 rows affected (0.00 sec)mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 158 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set(0.00 sec) （2）slave配置（masterB） 1）配置slave数据库的my.cnf文件 12345678910111213[root@slave ~]# vim /etc/my.cnf#server-id= 2 log-bin = mysql-bin binlog-ignore-db = mysql,information_schemasync_binlog = 1binlog_checksum = nonebinlog_format = mixed#auto-increment-increment = 2 #auto-increment-offset = 2 slave-skip-errors = all 2）重启MySQL 1[root@masterB ~]# systemctl restart mysqld 3）设置数据同步授权 防火墙开启3306端口 12[root@masterB ~]# firewall-cmd --zone=public --add-port=3306/tcp --permanent[root@masterB ~]# firewall-cmd --reload 要确保对方机器能使用下面权限连接到本机mysql。 同理，slave也要授权给master机器远程同步数据的权限。 12345678910mysql&gt; grant replication slave ,replication client on *.* to repl@&#39;192.168.1.10&#39; identified by &quot;repl123&quot;;mysql&gt; flush privileges;mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 256 | | | |+------------------+----------+--------------+------------------+-------------------+1 row &#96;&#96;in&#96; &#96;set&#96; &#96;(0.00 sec) 4、测试 （1）主主双向同步 1）slave同步master 确保slave上要同步的数据，提前在master上存在，最好双方数据保持一致。 123456789101112#先解锁，将对方数据同步到自己的数据库中mysql&gt; unlock tables; mysql&gt; stop slave;mysql&gt; change master to master_host&#x3D;&#39;192.168.1.10&#39;,master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;repl123&#39;,master_log_file&#x3D;&#39;mysql-bin.000001&#39;,master_log_pos&#x3D;158;mysql&gt; start slave;mysql&gt; show slave status \\G;true .................. Slave_IO_Running: Yes Slave_SQL_Running: Yes .................. 这样就实现了slave－&gt;master的同步环境。 2）master同步slave 确保slave上要同步的数据，提前在master上存在，最好双方数据保持一致。 1234567891011mysql&gt; unlock tables;mysql&gt; stop slave;mysql&gt; change master to master_host&#x3D;&#39;192.168.1.11&#39;,master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;repl123&#39;,master_log_file&#x3D;&#39;mysql-bin.000001&#39;,master_log_pos&#x3D;256;mysql&gt; start slave;mysql&gt; show slave status \\G .................. Slave_IO_Running: Yes Slave_SQL_Running: Yes .................. 这样就实现了master－&gt;slave的同步环境。至此，主主双向同步环境已经实现！ （2）主主同步 1）在master上写入新数据 12345678910mysql&gt; select * from liting.haha;+-----+-----------+| id | name |+-----+-----------+| 100 | anhui |+-----+-----------+1 rows in set(0.00 sec)mysql&gt; insert into huanqiu.haha values(10,'beijing'); 2）在slave数据库中查看 发现master新写入的数据已经同步过来了。 12345678mysql&gt; select * from liting.haha;+-----+------------+| id | name |+-----+------------+| 10 | beijing || 100 | anhui |+-----+------------+2 rows in set (0.00 sec) 3） 在slave上删除数据 1mysql&gt; delete from liting.haha where id&#x3D;100; 在master数据库中查看 1234567mysql&gt; select * from liting.haha;+-----+------------+| id | name |+-----+------------+| 10 | beijing |+-----+------------+3 rows in set (0.00 sec) 现在任何一台MySQL上更新数据都会同步到另一台MySQL，MySQL同步完成。 注：若主MYSQL服务器已经存在，只是后期才搭建从MYSQL服务器，在置配数据同步前应先将主 MYSQL服务器的要同步的数据库拷贝到从MYSQL服务器上（如先在主MYSQL上备份数据库，再用备份 在从MYSQL服务器上恢复）","path":"posts/b894.html","date":"06-27","excerpt":"","tags":[]},{"title":"nnobackupex全库备份+innobackupex增量备份","text":"测试环境准备 创建一个测试数据库，并创建一张表输入几行数据 12345mysql&gt; create database test2;mysql&gt; use test2;mysql&gt; create table yy(id int,name varchar(20));mysql&gt; insert into yy values(1,&#39;kim1&#39;);mysql&gt; insert into yy values(2,&#39;kim2&#39;); 1、innobackupex先做完全备份 命令如下： 1\\# innobackupex --defaults-file=/etc/my.cnf --user=root --password=\"123456\" /opt/mysqlbackup/full/full_incre_$(date +%Y%m%d_%H%M%S) --no-timestamp 查看完全备份文件 123# ll /opt/mysqlbackup/full/drwxr-x---. 10 root root 4096 Sep 12 23:52 full_incre_20160912_235237innobackupex做增量备份 （1）做第一次增量备份 先录入增量数据 12mysql&gt; use test2;mysql&gt; insert into yy values(3,&#39;kim3&#39;); （2）再进行增量备份，命令如下： 1# innobackupex --incremental /opt/mysqlbackup/inc/incre_$(date +%Y%m%d_%H%M%S) --incremental-basedir=/opt/mysqlbackup/full/full_incre_20160912_235237/ --user=root --password=\"123456\" --no-timestamp 查看增量备份文件 12# ll /opt/mysqlbackup/inc/drwxr-x---. 10 root root 4096 Sep 12 23:56 incre_20160912_235636 基于全备和第一个增量备份来做第二次增量备份 先录入增量数据录入 12mysql&gt; use test2;mysql&gt; insert into yy values(4,&#39;kim4&#39;); 查看增量备份文件 1234# ll /opt/mysqlbackup/inc/drwxr-x---. 10 root root 4096 Sep 12 23:56 incre_20160912_235636drwxr-x---. 10 root root 4096 Sep 12 23:59 incre_20160912_2359422、innobackupex做增量恢复 （3）先删除两次增量数据，用来查看验证恢复结果 12mysql&gt; use test2;mysql&gt; delete from yy where id&#x3D;3; （4）开始做恢复，恢复全备份 命令如下 12# innobackupex --apply-log --redo-only/opt/mysqlbackup/full/full_incre_20160912_235237/ –redo-only 用于准备增量备份内容把数据合并到全备份目录，配合incremental-dir 增量备份目录使用 基于全备份进行第一次增量备份的恢复 命令如下： 1# innobackupex --apply-log --redo-only /opt/mysqlbackup/full/full_incre_20160912_235237/ --incrementaldir=/opt/mysqlbackup/inc/incre_20160912_235636/ 基于全备份和第一次增量备份，恢复第二次增量备份 命令如下： 1# innobackupex --apply-log --redo-only /opt/mysqlbackup/full/full_incre_20160912_235237/ --incrementaldir=/opt/mysqlbackup/inc/incre_20160912_235942/ （5）恢复整个数据库 停止数据库 1# systemctl stop mysqld （6）清空数据目录下所有文件 12# mkdir -p /tmp/mysqldatabak# mv /usr/local/mysql/data/* /tmp/mysqldatabak/ （7）将恢复好的数据按照配置文件的需求拷贝到相应目录 1# innobackupex --defaults-file=/etc/my.cnf --user=root --password=\"123456\" --copyback /opt/mysqlbackup/full/full_incre_20160912_235237/ 当数据恢复至DATADIR目录以后，还需要确保所有数据文件的属主和属组均为正确的用户，如mysql，否则，在启动mysqld之前还需要事先修改数据文件的属主和属组。 赋予mysql账号权限 1# chown -R mysql:mysql /usr/local/mysql/data/ （8）启动mysql服务 1\\# systemctl start mysqld （9）登录mysql界面，查看数据是否已经恢复，如下所示： 12345678910mysql&gt; use test2;mysql&gt; select * from yy;+------+------+| id | name |+------+------+| 1 | kim1 || 2 | kim2 || 3 | kim3 || 4 | kim4 |+------+------+ 附：Xtrabackup的“流”及“备份压缩”功能 Xtrabackup对备份的数据文件支持“流”功能，即可以将备份的数据通过STDOUT传输给tar程序进行归档，而不是默认的直接保存至某备份目录中。要使用此功能，仅需要使用–stream选项即可。如： 1# innobackupex --user=root --password=\"123456\" --stream=tar /opt/mysqlbackup/full/ | gzip &gt;/opt/mysqlbackup/full/full_`date +%F_%H%M%S`.tar.gz","path":"posts/49er.html","date":"06-26","excerpt":"","tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"}]},{"title":"Xtrabackup备份还原","text":"一、Xtrabackup介绍 MySQL冷备、mysqldump、MySQL热拷贝都无法实现对数据库进行增量备份。在实际生产环境中增量备份是非常实用的，如果数据大于50G或100G，存储空间足够的情况下，可以每天进行完整备份，如果每天产生的数据量较大，需要定制数据备份策略。例如每周实用完整备份，周一到周六实用增量备份。而Percona-Xtrabackup就是为了实现增量备份而出现的一款主流备份工具，xtrabakackup有2个工具，分别是xtrabakup、innobakupe。 Percona-xtrabackup是 Percona公司开发的一个用于MySQL数据库物理热备的备份工具，支持MySQL、Percona server和MariaDB，开源免费，是目前较为受欢迎的主流备份工具。xtrabackup只能备份innoDB和xtraDB两种数据引擎的表，而不能备份MyISAM数据表。 1、Xtrabackup优点 （1）备份速度快，物理备份可靠 （2）备份过程不会打断正在执行的事务（无需锁表） （3）能够基于压缩等功能节约磁盘空间和流量 （4）自动备份校验 （5）还原速度快 （6）可以流传将备份传输到另外一台机器上 （7）在不增加服务器负载的情况备份数据 2、Xtrabackup备份原理 （1）innobackupex启动后，会先fork一个进程，用于启动xtrabackup，然后等待xtrabackup备份ibd数据文件； （2）xtrabackup在备份innoDB数据是，有2种线程：redo拷贝线程和ibd数据拷贝线程。xtrabackup进程开始执行后，会启动一个redo拷贝的线程，用于从最新的checkpoint点开始顺序拷贝redo.log；再启动ibd数据拷贝线程，进行拷贝ibd数据。这里是先启动redo拷贝线程的。在此阶段，innobackupex进行处于等待状态（等待文件被创建） （4）xtrabackup拷贝完成ibd数据文件后，会通知innobackupex（通过创建文件），同时xtrabackup进入等待状态（redo线程依旧在拷贝redo.log） （5）innobackupex收到xtrabackup通知后哦，执行FLUSH TABLES WITH READ LOCK（FTWRL），取得一致性位点，然后开始备份非InnoDB文件（如frm、MYD、MYI、CSV、opt、par等格式的文件），在拷贝非InnoDB文件的过程当中，数据库处于全局只读状态。 （6）当innobackup拷贝完所有的非InnoDB文件后，会通知xtrabackup，通知完成后，进入等待状态； （7）xtrabackup收到innobackupex备份完成的通知后，会停止redo拷贝线程，然后通知innobackupex，redo.log文件拷贝完成； （8）innobackupex收到redo.log备份完成后，就进行解锁操作，执行：UNLOCK TABLES； （9）最后innbackupex和xtrabackup进程各自释放资源，写备份元数据信息等，innobackupex等xtrabackup子进程结束后退出。 3、xtrabackup的安装部署以及备份恢复实现 （1）下载xtrabackup 1wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.4/binary/tarball/percona-xtrabackup-2.4.4-Linux-x86_64.tar.gz （2）解压 1tar zxf percona-xtrabackup-2.4.4-Linux-x86_64.tar.gz （3）进入解压目录 1cd percona-xtrabackup-2.4.4-Linux-x86_64/ （4）复制bin下的所有程序到/usr/bin 1[root@localhost percona-xtrabackup-2.4.4-Linux-x86_64]# cp bin/* /usr/bin/ Xtrabackup中主要包含两个工具： xtrabackup：是用于热备份innodb, xtradb表中数据的工具，支持在线热备份，可以在不加锁的情况下备份Innodb数据表，不过此工具不能操作Myisam引擎表； innobackupex：是将xtrabackup进行封装的perl脚本，能同时处理Innodb和Myisam，但在处理Myisam时需要加一个读锁。 由于操作Myisam时需要加读锁，这会堵塞线上服务的写操作，而Innodb没有这样的限制，所以数据库中Innodb表类型所占的比例越大，则越有利。 安装相关插件 1#yum install perl-DBI perl-DBD-MySQL perl-Time-HiRes perl-IO-Socket-SSL perl-TermReadKey.x86_64 perl-Digest-MD5 –y 常用选项: 1234567891011121314--host 指定主机--user 指定用户名--password 指定密码--port 指定端口--databases 指定数据库--incremental 创建增量备份--incremental-basedir 指定包含完全备份的目录--incremental-dir 指定包含增量备份的目录 --apply-log 对备份进行预处理操作 一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。“准备”的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。--redo-only 不回滚未提交事务--copy-back 恢复备份目录 使用innobackupex备份时，其会调用xtrabackup备份所有的InnoDB表，复制所有关于表结构定义的相关文件(.frm)、以及MyISAM、MERGE、CSV和ARCHIVE表的相关文件，同时还会备份触发器和数据库配置信息相关的文件，这些文件会被保存到一个以时间命名的目录当中。在备份的同时，innobackupex还会在备份目录中创建如下文件： 1234567891011121314(1)xtrabackup_checkpoints -- 备份类型(如完全或增量)、备份状态(如是否已经为prepared状态)和LSN(日志序列号)范围信息：每个InnoDB页(通常为16k大小)都会包含一个日志序列号，即LSN，LSN是整个数据库系统的系统版本号，每个页面相关的LSN能够表明此页面最近是如何发生改变的。(2)xtrabackup_binlog_info -- mysql服务器当前正在使用的二进制日志文件及备份这一刻位置二进制日志时间的位置。(3)xtrabackup_binlog_pos_innodb -- 二进制日志文件及用于InnoDB或XtraDB表的二进制日志文件的当前position。(4)xtrabackup_binary -- 备份中用到的xtrabackup的可执行文件；(5)backup-my.cnf -- 备份命令用到的配置选项信息：在使用innobackupex进行备份时，还可以使用--no-timestamp选项来阻止命令自动创建一个以时间命名的目录：如此一来，innobackupex命令将会创建一个BACKUP-DIR目录来存储备份数据。 如果要使用一个最小权限的用户进行备份，则可基于如下命令创建此类用户： 1234567891011mysql&gt; CREATE USER 'bkpuser'@'localhost' IDENTIFIED BY '123456'; #创建用户mysql&gt; REVOKE ALL PRIVILEGES,GRANT OPTION FROM 'bkpuser'; #回收此用户所有权限mysql&gt; GRANT RELOAD,LOCK TABLES,RELICATION CLIENT ON *.* TO 'bkpuser'@'localhost'; #授权刷新、锁定表、用户查看服务器状态mysql&gt; FLUSH PRIVILEGES; #刷新授权表 1注意：备份时需启动MySQL,恢复时需关闭MySQL,清空mysql数据目录且不能重新初始化,恢复数据后应该立即进行一次完全备份 （5）下载percona-toolkit并安装 12#wget https://www.percona.com/downloads/percona-toolkit/2.2.19/RPM/perconatoolkit-2.2.19-1.noarch.rpm# rpm -vih percona-toolkit-2.2.19-1.noarch.rpm 下面就可以启动备份了 二、xtrabackup全量备份与恢复 命令语法格式 123456备份：innobackupex --user=DBUSER --password=DBUSERPASS --defaults-file=/etc/my.cnf /path/to/BACKUP-DIR/恢复：innobackupex --apply-log /backups/2018-07-30_11-04-55/innobackupex --copy-back --defaults-file=/etc/my.cnf /backups/2018-07-30_11-04-55/ 1、准备(prepare)一个完全备份 一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或者已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处于不一致状态。&quot;准备&quot;的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使用得数据文件处于一致性状态。 innobackupex命令的–apply-log选项可用于实现上述功能，如下面的命令： 1234# innobackupex --apply-log /path/to/BACKUP-DIR如果执行正确，其最后输出的几行信息通常如下：120407 09:01:04 innobackupex: completed OK! 在实现&quot;准备&quot;的过程中，innobackupex通常还可以使用–user-memory选项来指定其可以使用的内存的大小，默认为100M.如果有足够的内存空间可用，可以多划分一些内存给prepare的过程，以提高其完成备份的速度。 2、从一个完全备份中恢复数据 注意：恢复不用启动MySQL innobackupex命令的–copy-back选项用于恢复操作，其通过复制所有数据相关的文件至mysql服务器DATADIR目录中来执行恢复过程。innobackupex通过backup-my.cnf来获取DATADIR目录的相关信息。 1# innobackupex --copy-back /path/to/BACKUP-DIR 当数据恢复至DATADIR目录以后，还需要确保所有的数据文件的属主和属组均为正确的用户，如mysql，否则，在启动mysqld之前还需要事先修改数据文件的属主和属组。如： 1# chown -R mysql.mysql /mydata/data/ 3、实战练习 （1）全量备份 1234567891011121314151617181920212223242526272829[root@master backups]# innobackupex --user=root --password=123 --host=127.0.0.1 /backups/ #在master上进行全库备份#语法解释说明：#--user=root 指定备份用户#--password=123456 指定备份用户密码#--host 指定主机#/backups 指定备份目录[root@master backups]# lltotal 0drwxr-x--- 7 root root 232 Jul 30 11:01 2018-07-30_11-01-37[root@master backups]# ll 2018-07-30_11-01-37/ #查看备份数据total 77856-rw-r----- 1 root root 418 Jul 30 11:01 backup-my.cnf #备份用到的配置选项信息文件-rw-r----- 1 root root 79691776 Jul 30 11:01 ibdata1 #数据文件drwxr-x--- 2 root root 20 Jul 30 11:01 kimdrwxr-x--- 2 root root 4096 Jul 30 11:01 mysqldrwxr-x--- 2 root root 4096 Jul 30 11:01 performance_schemadrwxr-x--- 2 root root 20 Jul 30 11:01 reppppdrwxr-x--- 2 root root 4096 Jul 30 11:01 wordpress-rw-r----- 1 root root 21 Jul 30 11:01 xtrabackup_binlog_info #mysql服务器当前正在使用的二进制日志文件和此时二进制日志时间的位置信息文件-rw-r----- 1 root root 113 Jul 30 11:01 xtrabackup_checkpoints #备份的类型、状态和LSN状态信息文件-rw-r----- 1 root root 482 Jul 30 11:01 xtrabackup_info-rw-r----- 1 root root 2560 Jul 30 11:01 xtrabackup_logfile #备份的日志文件 （2）恢复 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960[root@slave ~]# /etc/init.d/mysqld stop #停止slave上的mysqlShutting down MySQL.. SUCCESS! [root@slave tools]# yum install -y percona-xtrabackup-24-2.4.9-1.el7.x86_64.rpm #安装xtrabackup[root@master backups]# scp -r 2018-07-30_11-01-37/ root@192.168.56.12:/backups/ #从master上拷贝备份数据[root@slave tools]# innobackupex --apply-log /backups/2018-07-30_11-01-37/ #合并数据，使数据文件处于一致性的状态180729 23:18:23 innobackupex: Starting the apply-log operationIMPORTANT: Please check that the apply-log run completes successfully. At the end of a successful apply-log run innobackupex prints \"completed OK!\".innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4)xtrabackup: cd to /backups/2018-07-30_11-01-37/xtrabackup: This target seems to be not prepared yet.InnoDB: Number of pools: 1xtrabackup: xtrabackup_logfile detected: size=8388608, start_lsn=(3127097)......InnoDB: FTS optimize thread exiting.InnoDB: Starting shutdown...InnoDB: Shutdown completed; log sequence number 3129915180729 23:18:30 completed OK![root@slave ~]# rm -rf /usr/local/mysql/data/ #在slave上删除原有的数据[root@slave ~]# vim /etc/my.cnf #配置my.cnf的数据目录路径，否则会报错，要和master一致datadir=/usr/local/mysql/data[root@slave ~]# innobackupex --copy-back /backups/2018-07-30_11-01-37/ #在slave上数据恢复180729 23:32:03 innobackupex: Starting the copy-back operationIMPORTANT: Please check that the copy-back run completes successfully. At the end of a successful copy-back run innobackupex prints \"completed OK!\".......180729 23:32:08 completed OK! #看到completed OK就是恢复正常了[root@slave ~]# ll /usr/local/mysql/data/ #slave上查看数据目录，可以看到数据已经恢复，但是属主会有问题，需要进行修改，所以一般使用mysql的运行用户进行恢复，否则需要进行修改属主和属组信息total 188432-rw-r----- 1 root root 79691776 Jul 29 23:32 ibdata1-rw-r----- 1 root root 50331648 Jul 29 23:32 ib_logfile0-rw-r----- 1 root root 50331648 Jul 29 23:32 ib_logfile1-rw-r----- 1 root root 12582912 Jul 29 23:32 ibtmp1drwxr-x--- 2 root root 20 Jul 29 23:32 kimdrwxr-x--- 2 root root 4096 Jul 29 23:32 mysqldrwxr-x--- 2 root root 4096 Jul 29 23:32 performance_schemadrwxr-x--- 2 root root 20 Jul 29 23:32 reppppdrwxr-x--- 2 root root 4096 Jul 29 23:32 wordpress-rw-r----- 1 root root 482 Jul 29 23:32 xtrabackup_info[root@slave ~]# chown -R mysql.mysql /usr/local/mysql/data/ #修改属主属组[root@slave ~]# /etc/init.d/mysqld start #启动mysqlStarting MySQL. SUCCESS! [root@slave ~]# mysql -uroot -p -e \"show databases;\" #查看数据，是否恢复Enter password: +--------------------+| Database |+--------------------+| information_schema || kim || mysql || performance_schema || repppp || wordpress |+--------------------+ 总结全库备份与恢复三步曲： innobackupex全量备份，并指定备份目录路径； 在恢复前，需要使用–apply-log参数先进行合并数据文件，确保数据的一致性要求； 恢复时，直接使用–copy-back参数进行恢复，需要注意的是，在my.cnf中要指定数据文件目录的路径。 三、xtrabackup增量备份与恢复 使用innobackupex进行增量备份，每个InnoDB的页面都会包含一个LSN信息，每当相关的数据发生改变，相关的页面的LSN就会自动增长。这正是InnoDB表可以进行增量备份的基础，即innobackupex通过备份上次完全备份之后发生改变的页面来实现。在进行增量备份时，首先要进行一次全量备份，第一次增量备份是基于全备的，之后的增量备份都是基于上一次的增量备份的，以此类推。 要实现第一次增量备份，可以使用下面的命令进行： 12345678910基于全量备份的增量备份与恢复做一次增量备份（基于当前最新的全量备份）innobackupex --user&#x3D;root --password&#x3D;root --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --incremental &#x2F;backups&#x2F; --incremental-basedir&#x3D;&#x2F;backups&#x2F;2018-07-30_11-01-371. 准备基于全量innobackupex --user&#x3D;root --password&#x3D;root --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --apply-log --redo-only &#x2F;backups&#x2F;2018-07-30_11-01-372. 准备基于增量innobackupex --user&#x3D;root --password&#x3D;root --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --apply-log --redo-only &#x2F;backups&#x2F;2018-07-30_11-01-37 --incremental-dir&#x3D;&#x2F;backups&#x2F;2018-07-30_13-51-47&#x2F;3. 恢复innobackupex --copy-back --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf &#x2F;opt&#x2F;2017-01-05_11-04-55&#x2F;解释：1. 2018-07-30_11-01-37指的是完全备份所在的目录。2. 2018-07-30_13-51-47指定是第一次基于2018-07-30_11-01-37增量备份的目录，其他类似以此类推，即如果有多次增量备份。每一次都要执行如上操作。 需要注意的是，增量备份仅能应用于InnoDB或XtraDB表，对于MyISAM表而言，执行增量备份时其实进行的是完全备份。 &quot;准备&quot;(prepare)增量备份与整理完全备份有着一些不同，尤其要注意的是： 需要在每个备份 (包括完全和各个增量备份)上，将已经提交的事务进行&quot;重放&quot;。&quot;重放&quot;之后，所有的备份数据将合并到完全备份上。 基于所有的备份将未提交的事务进行&quot;回滚&quot; 1、增量备份演示 12345678910111213141516171819202122232425[root@master backups]# innobackupex --user=root --password=123456 --host=127.0.0.1 /backups/ #全备数据[root@master ~]# mysql -uroot -p #在master上创建student库并创建testtb表插入若干数据Enter password: mysql&gt; create database student;Query OK, 1 row affected (0.03 sec)mysql&gt; use student;Database changedmysql&gt; create table testtb(id int);Query OK, 0 rows affected (0.07 sec)mysql&gt; insert into testtb values(1),(10),(99);Query OK, 3 rows affected (0.04 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from testtb;+------+| id |+------+| 1 || 10 || 99 |+------+3 rows in set (0.00 sec)mysql&gt; quit;Bye 2、使用innobackupex进行增量备份 1234567891011121314151617181920212223242526272829303132[root@master backups]# innobackupex --user=root --password=123456 --host=127.0.0.1 --incremental /backups/ --incremental-basedir=/backups/2018-07-30_11-01-37/......180730 13:51:50 Executing UNLOCK TABLES180730 13:51:50 All tables unlocked180730 13:51:50 Backup created in directory '/backups/2018-07-30_13-51-47/'MySQL binlog position: filename 'mysql-bin.000005', position '664'180730 13:51:50 [00] Writing /backups/2018-07-30_13-51-47/backup-my.cnf180730 13:51:50 [00] ...done180730 13:51:50 [00] Writing /backups/2018-07-30_13-51-47/xtrabackup_info180730 13:51:50 [00] ...donextrabackup: Transaction log of lsn (3158741) to (3158741) was copied.180730 13:51:50 completed OK![root@master backups]# ll #查看备份数据total 0drwxr-x--- 7 root root 232 Jul 30 11:01 2018-07-30_11-01-37 #全量备份数据目录drwxr-x--- 8 root root 273 Jul 30 13:51 2018-07-30_13-51-47 #增量备份数据目录[root@master 2018-07-30_11-01-37]# cat xtrabackup_checkpoints #查看全量备份的xtrabackup_checkpointsbackup_type = full-backuped #备份类型为全量备份from_lsn = 0 #lsn从0开始to_lsn = 3127097 #lsn到3127097结束last_lsn = 3127097compact = 0recover_binlog_info = 0[root@master 2018-07-30_13-51-47]# cat xtrabackup_checkpoints #查看增量备份的xtrabackup_checkpointsbackup_type = incremental #备份类型为增量备份from_lsn = 3127097 #lsn从3127097开始to_lsn = 3158741 #lsn到啊3158741结束last_lsn = 3158741 compact = 0recover_binlog_info = 0 3、增量备份后数据恢复演示 （1）模拟mysql故障，删除数据目录所有数据 123[root@master ~]# /etc/init.d/mysqld stop #模拟mysql故障，停止mysqlShutting down MySQL.. SUCCESS! [root@master ~]# rm -rf /usr/local/mysql/data/* #删除数据目录中的所有数据 （2）合并全备数据目录，确保数据的一致性 12345678910111213141516[root@master ~]# innobackupex --apply-log --redo-only /backups/2018-07-30_11-01-37/180730 14:05:27 innobackupex: Starting the apply-log operationIMPORTANT: Please check that the apply-log run completes successfully. At the end of a successful apply-log run innobackupex prints \"completed OK!\".innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4)xtrabackup: cd to /backups/2018-07-30_11-01-37/............xtrabackup: starting shutdown with innodb_fast_shutdown = 1InnoDB: Starting shutdown...InnoDB: Shutdown completed; log sequence number 3127106InnoDB: Number of pools: 1180730 14:05:29 completed OK! （3）将增量备份数据合并到全备数据目录当中 1234567891011121314151617[root@master ~]# innobackupex --apply-log --redo-only /backups/2018-07-30_11-01-37/ --incremental-dir=/backups/2018-07-30_13-51-47/180730 14:06:42 innobackupex: Starting the apply-log operationIMPORTANT: Please check that the apply-log run completes successfully. At the end of a successful apply-log run innobackupex prints \"completed OK!\".............180730 14:06:44 [00] ...done180730 14:06:44 completed OK![root@master ~]# cat /backups/2018-07-30_11-01-37/xtrabackup_checkpoints backup_type = log-applied #查看到数据备份类型是增加from_lsn = 0 #lsn从0开始to_lsn = 3158741 #lsn结束号为最新的lsnlast_lsn = 3158741compact = 0recover_binlog_info = 0 （4）恢复数据 1234567891011121314151617181920212223242526272829303132333435363738[root@master ~]# innobackupex --copy-back /backups/2018-07-30_11-01-37/180730 14:07:51 innobackupex: Starting the copy-back operationIMPORTANT: Please check that the copy-back run completes successfully. At the end of a successful copy-back run innobackupex prints \"completed OK!\"...............180730 14:08:17 [01] ...done180730 14:08:17 completed OK![root@master ~]# ll /usr/local/mysql/data/total 77844-rw-r----- 1 root root 79691776 Jul 30 14:08 ibdata1drwxr-x--- 2 root root 20 Jul 30 14:08 kimdrwxr-x--- 2 root root 4096 Jul 30 14:08 mysqldrwxr-x--- 2 root root 4096 Jul 30 14:08 performance_schemadrwxr-x--- 2 root root 20 Jul 30 14:08 reppppdrwxr-x--- 2 root root 56 Jul 30 14:08 studentdrwxr-x--- 2 root root 4096 Jul 30 14:08 wordpress-rw-r----- 1 root root 21 Jul 30 14:08 xtrabackup_binlog_pos_innodb-rw-r----- 1 root root 554 Jul 30 14:08 xtrabackup_info[root@master ~]# chown -R mysql.mysql /usr/local/mysql/data #更改数据的属主属组[root@master ~]# /etc/init.d/mysqld start #启动mysqlStarting MySQL.Logging to '/usr/local/mysql/data/master.err'... SUCCESS! [root@master ~]# mysql -uroot -p -e \"show databases;\" #查看数据是否恢复Enter password: +--------------------+| Database |+--------------------+| information_schema || kim || mysql || performance_schema || repppp || student || wordpress |+--------------------+ 总结： 增量备份需要使用参数–incremental指定需要备份到哪个目录，使用incremental-dir指定全备目录； 进行数据备份时，需要使用参数–apply-log redo-only先合并全备数据目录数据，确保全备数据目录数据的一致性； 再将增量备份数据使用参数–incremental-dir合并到全备数据当中； 最后通过最后的全备数据进行恢复数据，注意，如果有多个增量备份，需要逐一合并到全备数据当中，再进行恢复。 方案一：xtrabackup完全备份+binlog增量备份 1、备份 创建备份目录 1mkdir -p /opt/mysqlbackup/&#123;full,inc&#125; **full：全备存放的目录；inc：增量备份存放的目录 ** （1）完全备份 需要开启和设置二进制日志 基本语法： 1innobackupex --user=DBUSER --password=DBUSERPASS /path/to/BACKUP-DIR/ 执行下面的命令进行完全备份： 1# innobackupex --user=root --password=123 /opt/mysqlbackup/full 注： --defaults-file=/etc/my.cnf 指定mysql的配置文件my.cfg，如果指定则必须是第一个参数。 /path/to/BACKUP-DIR/指定备份所存放的目标目录，备份过程会创建一个以当时备份时间命名的目录存放备份文件。 出现如下提示。表示成功 12345678200113 09:49:37 Backup created in directory '/opt/mysqlbackup/full/2020-01-13_09-49-22'200113 09:49:37 [00] Writing backup-my.cnf200113 09:49:37 [00] ...done200113 09:49:37 [00] Writing xtrabackup_info200113 09:49:37 [00] ...donextrabackup: Transaction log of lsn (67343410) to (67343419) was copied.200113 09:49:37 completed OK! 备份后的文件： 在备份的同时，备份数据会在备份目录下创建一个以当前日期时间为名字的目录存放备份文件： 1234567891011[root@localhost ~]# cd /opt/mysqlbackup/full/[root@localhost full]#[root@localhost full]# lltotal 4drwxr-x---. 12 root root 4096 Jan 13 09:49 2020-01-13_09-49-22[root@localhost full]# ll 2020-01-13_09-49-22/total 77892-rw-r-----. 1 root root 425 Jan 13 09:49 backup-my.cnf-rw-r-----. 1 root root 115 Jan 13 09:49 xtrabackup_checkpoints-rw-r-----. 1 root root 431 Jan 13 09:49 xtrabackup_info-rw-r-----. 1 root root 2560 Jan 13 09:49 xtrabackup_logfile 各文件说明： xtrabackup_checkpoints ——备份类型（如完全或增量）、备份状态（如是否已经为prepared状态）和LSN(日志序列号)范围信息； 每个InnoDB页(通常为16k大小)都会包含一个日志序列号，即LSN。LSN是整个数据库系统的系统版本号，每个页面相关的LSN能够表明此页面最近是如何发生改变的。 xtrabackup_binlog_info —— mysql服务器当前正在使用的二进制日志文件及至备份这一刻为止二进制日志事件的位置。 xtrabackup_binlog_pos_innodb ——二进制日志文件及用于InnoDB或XtraDB表的二进制日志文件的当前position。 xtrabackup_binary ——备份中用到的xtrabackup的可执行文件； backup-my.cnf ——备份命令用到的配置选项信息； 在使用innobackupex进行备份时，还可以使用–no-timestamp选项来阻止命令自动创建一个以时间命名的目录；如此一来，innobackupex命令将会创建一个BACKUP-DIR目录来存储备份数据 注意：相关选项说明： 其中， –user指定连接数据库的用户名， –password指定连接数据库的密码， –defaults-file指定数据库的配置文件，innobackupex要从其中获取datadir等信息； –database指定要备份的数据库，这里指定的数据库只对MyISAM表有效，对于InnoDB 数据来说都是全备（所有数据库中的InnoDB数据都进行了备份，不是只备份指定的数据库，恢复时也一样）； /opt/mysqlbackup/full是备份文件的存放位置。 注意：备份数据库的用户需要具有相应权限，如果要使用一个最小权限的用户进行备份，则可基于如下命令创建此类用户： 1234mysql&gt; CREATE USER &#39;bkpuser&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123456&#39;; #创建用户mysql&gt; REVOKE ALL PRIVILEGES ON *.* FROM &#39;bkpuser&#39;@&#39;localhost&#39;; #回收此用户所有权限mysql&gt; GRANT RELOAD,LOCK TABLES,RELICATION CLIENT ON *.* TO &#39;bkpuser&#39;@&#39;localhost&#39;; #授权刷新、锁定表、用户查看服务器状态mysql&gt; FLUSH PRIVILEGES; #刷新授权表 至此全备完全成功，然后向mysql某个库插入几条数据，然后进行增量备份 对完全备份的后数据库更改进行二进制日志增量备份： 模拟数据库修改： 1234567891011121314151617mysql&gt; create database tb1;Query OK, 1 row affected (0.00 sec)mysql&gt; use tb1;Database changedmysql&gt; create table tom1(qq int(10));Query OK, 0 rows affected (0.01 sec)mysql&gt; create table tom2(qq int(10));Query OK, 0 rows affected (0.01 sec)mysql&gt; insert into tb1.tom1 values (3);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into tb1.tom2 values (4);Query OK, 1 row affected (0.00 sec) （2）增量备份二进制文件： 1[root@mysql ~]# mysqlbinlog --start-position=2378 /usr/local/mysql/data/mysql_bin_log.000001 &gt; /opt/mysqlbackup/inc/`date +%F`.sql 2、还原数据库： 模拟数据库损坏： 我这里直接使用删除数据目录文件来模拟损坏 1[root@mysql ~]# rm -fr /usr/local/mysql/data/* 还原完全备份： （1）准备(prepare)一个完全备份 一般情况下，在备份完成后，数据尚且不能用于恢复操作， 因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。“准备”的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。 在准备（prepare）过程结束后，InnoDB表数据已经前滚到整个备份结束的点，而不是回滚到xtrabackup刚开始时的点。 innobakupex命令的–apply-log选项可用于实现上述功能。 如下面的命令： --apply-log指明是将日志应用到数据文件上，完成之后将备份文件中的数据恢复到数据库中： 1[root@mysql ~]# innobackupex --apply-log /opt/mysqlbackup/full/2020-06-28_17-55-31/ 注：/opt/mysqlbackup/full/2020-06-28_17-55-31/备份文件所在目录名称 如果执行正确，其最后输出的几行信息通常如下： 1234InnoDB: FTS optimize thread exiting.InnoDB: Starting shutdown...InnoDB: Shutdown completed; log sequence number 2598952200628 18:01:23 completed OK! 在实现“准备”的过程中，innobackupex通常还可以使用–use-memory选项来指定其可以使用的内存的大小，默认通常为100M。如果有足够的内存可用，可以多划分一些内存给prepare的过程，以提高其完成速度。 innobackupex命令的–copy-back选项用于执行恢复操作，其通过复制所有数据相关的文件至mysql服务器DATADIR目录中来执行恢复过程。innobackupex通过backup-my.cnf来获取DATADIR目录的相关信息。 （2）还原数据库语法： 1# innobackupex --copy-back /opt/mysqlbackup/full/2020-06-28_17-55-31/ 这里的–copy-back指明是进行数据恢复。数据恢复完成之后，需要修改相关文件的权限mysql数据库才能正常启动。 如果执行正确，其输出信息的最后几行通常如下： 123200628 18:04:29 [01] Copying ./ibtmp1 to /usr/local/mysql/data/ibtmp1200628 18:04:29 [01] ...done200628 18:04:29 completed OK! 请确保如上信息的最行一行出现“completed OK!”。 修改还原后的数据目录权限: 12345678910111213141516[root@mysql ~]# ll /usr/local/mysql/data/总用量 122916-rw-r----- 1 root root 258 Jun 28 18:04 ib_buffer_pool-rw-r----- 1 root root 12582912 Jun 28 18:04 ibdata1-rw-r----- 1 root root 50331648 Jun 28 18:04 ib_logfile0-rw-r----- 1 root root 50331648 Jun 28 18:04 ib_logfile1-rw-r----- 1 root root 12582912 Jun 28 18:04 ibtmp1drwxr-x--- 2 root root 4096 Jun 28 18:04 mysqldrwxr-x--- 2 root root 8192 Jun 28 18:04 performance_schemadrwxr-x--- 2 root root 8192 Jun 28 18:04 sysdrwxr-x--- 2 root root 84 Jun 28 18:04 tb1drwxr-x--- 2 root root 20 Jun 28 18:04 test2drwxr-x--- 2 root root 248 Jun 28 18:04 testdbdrwxr-x--- 2 root root 20 Jun 28 18:04 testqqdrwxr-x--- 2 root root 20 Jun 28 18:04 xgp-rw-r----- 1 root root 481 Jun 28 18:04 xtrabackup_info 当数据恢复至DATADIR目录以后，还需要确保所有数据文件的属主和属组均为正确的用户，如mysql，否则，在启动mysqld之前还需要事先修改数据文件的属主和属组。如： 1[root@mysql ~]# chown -R mysql:mysql /usr/local/mysql/data/ 必须重启MySQL： 1[root@mysql ~]# systemctl restart mysqld 验证还原后的数据 1234567891011mysql&gt; use tb1Database changedmysql&gt; show tables;+---------------+| Tables_in_tb1 |+---------------+| tom1 || tom2 |+---------------+2 rows in set (0.00 sec) （3）还原增量备份： 为了防止还原时产生大量的二进制日志，在还原时可临时关闭二进制日志后再还原： 12mysql&gt; set sql_log_bin&#x3D;0;mysql&gt; source &#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;2020-06-28.sql 或者在命令行： 12mysql –uroot –p &lt; &#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;2016-09-12.sqlmysqlbinlog &#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;2016-09-12.sql | mysql –uroot -p 重新启动二进制日志并验证还原数据： 1mysql&gt; set sql_log_bin=1; 验证数据是否恢复回来 方案二、xtrabackup完全备份+xtrabacup增量备份 前面我们进行增量备份时，使用的还是老方法：备份二进制日志。其实xtrabackup还支持进行增量备份。 先介绍下xtrabackup的备份原理 在InnoDB内部会维护一个redo日志文件，我们也可以叫做事务日志文件（transaction log，事务日志）。事务日志会存储每一个InnoDB表数据的记录修改。当InnoDB启动时，InnoDB会检查数据文件和事务日志，并执行两个步骤：它应用已经提交的事务日志到数据文件，并将修改过但没有提交的数据进行回滚操作。 xtrabackup在启动时会记住log sequence number（LSN），并且复制所有的数据文件。复制过程需要一些时间，所以这期间如果数据文件有改动，那么将会使数据库处于一个不同的时间点。这时，xtrabackup会运行一个后台进程，用于监视事务日志，并从事务日志复制最新的修改。xtrabackup必须持续的做这个操作，是因为事务日志是会轮转重复的写入，并且事务日志可以被重用。所以xtrabackup自启动开始，就不停的将事务日志中每个数据文件的修改都记录下来。这就是xtrabackup的备份过程 所以每个InnoDB的页面都会包含一个LSN信息，每当相关的数据发生改变，相关的页面的LSN就会自动增长。这正是InnoDB表可以进行增量备份的基础。 xtraBackup基于InnoDB的crash-recovery功能。它会复制innodb的data file，由于不锁表，复制出来的数据是不一致的，在恢复的时候使用crash-recovery，使得数据恢复一致。当InnoDB启动的时候，它会先去检查data file和transaction log，并且会做二步操作： 1.It applies committed transaction logentries to the data files 2.it performs an undo operation on anytransactions that modified data but did not commit. 所以在prepare过程中，XtraBackup使用复制到的transactions log对备份出来的innodb data file进行crash recovery。 测试环境准备 创建一个测试数据库，并创建一张表输入几行数据 12345mysql&gt; create database test;mysql&gt; use test;mysql&gt; create table xx(id int,name varchar(20));mysql&gt; insert into xx values(1,&#39;tom1&#39;);mysql&gt; insert into xx values(2,&#39;tom2&#39;); 1、 xtrabacup进行备份 执行完全备份： 备份命令： 1# xtrabackup --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;&quot;123456&quot; --port&#x3D;3306 --backup --target-dir&#x3D;&#x2F;opt&#x2F;mysqlbackup&#x2F;full&#x2F;full_incre_$(date+%Y%m%d_%H%M%S) 部分显示信息如下所示： –defaults-file指定数据库的配置文件，如果使用该参数必须做为第一个参数； –user指定连接数据库的用户名； –password指定连接数据库的密码； –port指定连接数据库的端口号； –backup 实施备份到target-dir; –target-dir=name 备份文件的存放目录路径。innobackupex要从其中获取datadir等信息； –database指定要备份的数据库，这里指定的数据库只对MyISAM表和InnoDB表的表结构有效，对于InnoDB 数据来说都是全备（所有数据库中的InnoDB数据都进行了备份，不是只备份指定的数据库，恢复时也一样）； /opt/mysqlbackup/full/是备份文件的存放位置。 查看完全备份文件 12[root@localhost ~]# ls /opt/mysqlbackup/full/ -ldrwxr-x---. 8 root root 4096 Sep 12 22:11 full_incre_20160912_221111 xtrabackup进行增量备份 先录入些数据，实现第一次增量数据： 12345mysql&gt; use test;mysql&gt; insert into xx values(3,&#39;tom3&#39;);再进行增量备份1备份命令：# xtrabackup --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;&quot;123456&quot; --port&#x3D;3306 --backup --target-dir&#x3D;&#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;incre_$(date +%Y%m%d_%H%M%S) --incremental-basedir&#x3D;&#x2F;opt&#x2F;mysqlbackup&#x2F;full&#x2F;full_incre_20160912_221111&#x2F; 其中，–incremental-basedir指定上次完整备份或者增量备份文件的位置(即如果是第一次增量备份则指向完全备份所在目录，在执行过增量备份之后再一次进行增量备份时，其–incremental-basedir应该指向上一次的增量备份所在的目录)。 查看增量备份文件： 12345678910111213[root@localhost ~]# ls -l &#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;drwxr-x---. 8 root root 4096 Sep 12 22:15 incre_20160912_221510注：这里的增量备份其实只针对的是InnoDB，对于MyISAM来说，还是完整备份。向表中再插入几行数据，继续第二次增量备份mysql&gt; use test;mysql&gt; insert into xx values(4,&#39;tom4&#39;);mysql&gt; commit;进行第二次增量备份备份命令：# xtrabackup --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;&quot;123456&quot; --port&#x3D;3306 --backup --target-dir&#x3D;&#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;incre_$(date +%Y%m%d_%H%M%S)--incremental-basedir&#x3D;&#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;incre_20160912_221510&#x2F; 注：第二次增量备份–incremental-basedir指向上一次增量备份文件的位置。 查看增量备份文件 123[root@localhost ~]# ls -l &#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;drwxr-x---. 8 root root 4096 Sep 12 22:15 incre_20160912_221510drwxr-x---. 8 root root 4096 Sep 12 22:19 incre_20160912_221916 2、 xtrabacup进行增量恢复 为了验证比对，先删除两个增量备份前表里面的数据 12mysql&gt; use test;mysql&gt; delete from xx where id&#x3D;3; **完整备份恢复： ** 在进行恢复前，如果完整备份在远程主机上，首先将完整备份复制到本地主机上，如果是tar包，则需要先解包，解包命令为：tar –izxf xxx.tar，这里必须使用-i参数（忽略存档中的 0 字节块（通常意味着文件结束））。 开始全备份恢复 命令如下： 1# xtrabackup --defaults-file=/etc/my.cnf --prepare --user=root --password=\"123456\" --apply-log-only --target-dir=/opt/mysqlbackup/full/full_incre_20160912_221111/ **恢复到第一次增量的时刻 ** **增量备份恢复的步骤和完整备份恢复的步骤基本一致，只是应用日志的过程稍有不同。增量备份恢复时，是先将所有的增量备份挨个应用到完整备份的数据文件中，然后再将完整备份中的数据恢复到数据库中。 恢复命令： ** 1# xtrabackup --defaults-file=/etc/my.cnf --prepare --user=root --password=\"123456\" --apply-log-only --target-dir=/opt/mysqlbackup/full/full_incre_20160912_221111/ --incremental-dir=/opt/mysqlbackup/inc/incre_20160912_221510/ 恢复到第二次增量备份前面： 恢复命令 1# xtrabackup --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --prepare --user&#x3D;root --password&#x3D;&quot;123456&quot; --apply-log-only --target-dir&#x3D;&#x2F;opt&#x2F;mysqlbackup&#x2F;full&#x2F;full_incre_20160912_221111&#x2F; --incremental-dir&#x3D;&#x2F;opt&#x2F;mysqlbackup&#x2F;inc&#x2F;incre_20160912_221916&#x2F; 恢复整个库 恢复命令： 1# xtrabackup --defaults-file=/etc/my.cnf --prepare --user=root --password=\"123456\" --target-dir=/opt/mysqlbackup/full/full_incre_20160912_221111/ 然后停止mysql数据库： 1[root@localhost ~]# systemctl stop mysqld 开始rsync数据文件： 12# cd &#x2F;opt&#x2F;mysqlbackup&#x2F;full&#x2F;full_incre_20160912_221111&#x2F;#rsync -rvt --exclude &#39;xtrabackup_checkpoints&#39; --exclude &#39;xtrabackup_logfile&#39; .&#x2F; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F; 当数据恢复至DATADIR目录以后，还需要确保所有数据文件的属主和属组均为正确的用户，如mysql，否则，在启动mysqld之前还需要事先修改数据文件的属主和属组。 授予mysql访问权限： 1# chown -R mysql:mysql /usr/local/mysql/data/ 启动mysql服务： 1# systemctl start mysqld 验证 登录mysql，看到以前在备份之后删除的数据已经通过2次增量备份恢复过来了，如下所示： 123456789[root@localhost ~]# mysql -uroot -p123456 -e \"select * from test.xx\"+------+------+| id | name |+------+------+| 1 | tom1 || 2 | tom2 || 3 | tom3 || 4 | tom4 |+------+------+ 123456#备份：innobackupex --user&#x3D;DBUSER --password&#x3D;DBUSERPASS --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf &#x2F;path&#x2F;to&#x2F;BACKUP-DIR&#x2F;#恢复：innobackupex --apply-log &#x2F;backups&#x2F;2018-07-30_11-04-55&#x2F;innobackupex --copy-back --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf &#x2F;backups&#x2F;2018-07-30_11-04-55&#x2F; 123456# 预处理全量备份innobackupex --apply-log --redo-only &#x2F;backups&#x2F;2020-06-28_17-24-29&#x2F;# 把增量备份合并到全量备份innobackupex --apply-log --redo-only &#x2F;backups&#x2F;2020-06-28_17-24-29&#x2F; --incremental-dir&#x3D;&#x2F;backups&#x2F;2020-06-28_17-29-29&#x2F;# 用全量备份恢复innobackupex --user&#x3D;root --password&#x3D;1234 --copyback &#x2F;backups&#x2F;2020-06-28_17-24-29&#x2F;","path":"posts/49lt.html","date":"06-25","excerpt":"","tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"}]},{"title":"mysqldump备份还原","text":"mysqldump备份结合binlog日志恢复 MySQL备份一般采取全库备份加日志备份的方式，例如每天执行一次全备份，每小时执行一次二进制日志备份。这样在MySQL故障后可以使用全备份和日志备份将数据恢复到最后一个二进制日志备份前的任意位置或时间。 一、binlog介绍 mysql的二进制日志记录着该数据库的所有增删改的操作日志(前提是要在自己的服务器上开启binlog)，还包括了这些操作的执行时间。为了显示这些二进制内容，我们可以使用mysqlbinlog命令来查看。 Binlog的用途 主从同步 恢复数据库 开启binary log功能 通过编辑my.cnf中的log-bin选项可以开启二进制日志；形式如下： 1log-bin[=DIR/[filename]] **（配置文件中只写log_bin不写后面的文件名和路径时，默认存放在/usr/local/mysql/data目录下，文件名为主机名-bin.000001…命名）其中，DIR参数指定二进制文件的存储路径；filename参数指定二级制文件的文件名，其形式为filename.number，number的形式为000001、000002等。每次重启mysql服务或运行mysql&gt; flush logs;都会生成一个新的二进制日志文件，这些日志文件的number会不断地递增。除了生成上述的文件外还会生成一个名为filename.index的文件。这个文件中存储所有二进制日志文件的清单又称为二进制文件的索引 配置保存以后重启mysql的服务器，用mysql&gt; show variables like ‘log_bin’;查看bin-log是否开启，如图： ** 查看产生的binary log 注：查看binlog内容是为了恢复数据 bin-log因为是二进制文件，不能通过文件内容查看命令直接打开查看，mysql提供两种方式查看方式，在介绍之前，我们先对数据库进行一下增删改的操作，否则log里边数据有点空。 123456#mysql -uroot -p -e &quot;reset master&quot;&#x2F;&#x2F; 清空所有的二进制文件，从00001开始#mysql -uroot -p -e &quot;create database test&quot;#mysql -uroot -p -e &quot;use test;create table tb1(id int primary keyauto_increment,name varchar(20))&quot;#mysql -uroot -p -e &quot;insert into test.tb1(name) values(&#39;lisi&#39;)&quot;#mysql -uroot -p -e &quot;insert into test.tb1(name) values(&#39;zhangsan&#39;)&quot; 重新开始一个新的日志文件 1234567891011#mysql -uroot -p -e &quot;flush logs&quot;#mysql -uroot -p -e &quot;delete from test.tb1 where id&#x3D;2&quot;#mysql -uroot -p -e &quot;insert into test.tb1(name) values(&#39;tom&#39;)&quot;# mysql -uroot -p -e &quot;select * from test.tb1&quot;Enter password:+----+------+| id | name |+----+------+| 1 | lisi || 3 | tom |+----+------+ 查看MySQL Server上的二进制日志 1234567mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 1087 || mysql-bin.000002 | 673 |+------------------+-----------+ 查看二进制日志信息的命令： 语法格式： 1SHOW BINLOG EVENTS[IN &#39;log_name&#39;] [FROM pos] [LIMIT [offset,] row_count] 查看二进制日志中的事件 1mysql&gt; show binlog events; 默认显示可找到的第一个二进制日志文件中的事件，包含了日志文件名、事件的开始位置、事件类型、结束位置、信息等内容 具体操作请查看该网址 二、mysqldump介绍 mysqldump是mysql用于备份和数据转移的一个工具。它主要产生一系列的SQL语句，可以封装到文件，该文件包含有所有重建你的数据库所需要的 SQL命令如CREATE DATABASE，CREATE TABLE，INSERT等等。可以用来实现轻量级的快速迁移或恢复数据库。 mysqldump 是将数据表导成 SQL 脚本文件，在不同的 MySQL 版本之间升级时相对比较合适，这也是最常用的备份方法。 mysqldump一般在数据量很小的时候（几个G）可以用于备份。当数据量比较大的情况下，就不建议用mysqldump工具进行备份了。 数据库的导出 导出对象说明：mysqldump可以针对单个表、多个表、单个数据库、多个数据库、所有数据库进行导出的操作 123456789# mysqldump [options] db_name [tbl_name ...] &#x2F;&#x2F;导出指定数据库或单个表 # mysqldump [options] --databases db_name ... &#x2F;&#x2F;导出多个数据库 #mysqldump [options] --all-databases &#x2F;&#x2F;导出所有 导出数据库test # mysqldump -uroot -p --flush-logs test &gt; &#x2F;opt&#x2F;test.sql &#x2F;&#x2F;--flush-logs这个选项就会完整备份的时候重新开启一个新binlog 实例一 12345678910111213141516171819202122232425----------------------------------------------------------------truetrueMySQL数据库备份----------------------------------------------------------------# 备份指定数据库[root@192 ~]# mysqldump -uroot -p --databases ttt &gt;&#x2F;opt&#x2F;ttt_all.sql# 备份数据库并且压缩[root@192 ~]# mysqldump -uroot -p --databases ttt|gzip &gt;&#x2F;opt&#x2F;ttt_all.sql.gz# 备份同个库多个表[root@192 ~]# mysqldump -uroot -p ttt demo student &gt;&#x2F;opt&#x2F;ttt_demo_student.sql# 同时备份多个库[root@192 ~]# mysqldump -uroot -p --databases ttt myschool &gt;&#x2F;opt&#x2F;db_ttt_myschool.sql# 备份实例上所有的数据库[root@192 ~]# mysqldump -uroot -p --opt --all-databases &gt;&#x2F;opt&#x2F;db_all.sql# 备份数据库结构，不备份数据[root@192 ~]# mysqldump --no-data -uroot -p --databases ttt &gt;&#x2F;opt&#x2F;no_data_ttt.sql----------------------------------------------------------------truetrueMySQL数据库还原----------------------------------------------------------------# 恢复到指定数据库(数据库必须事先存在)[root@192 ~]# mysql -uroot -p ttt &lt;&#x2F;opt&#x2F;ttt_all.sql# 还原压缩的MySQL数据备份文件[root@192 ~]# gunzip &lt;&#x2F;opt&#x2F;new_ttt_all.sql |mysql -uroot -p ttt# 使用source导入sql文件source &#x2F;data&#x2F;cmdb_backup.sql 实例二 在前面我们介绍了mysql的binlog和mysqldump工具，下面我们来学习如何实现mysqldump全库备份+binlog的数据恢复 环境准备与备份还原：检查开启binlog 先创建一些原始数据 1234567891011121314mysql&gt; reset master;mysql&gt; create database test_db;mysql&gt; use test_db;mysql&gt; create table tb1(id int primary key auto_increment,name varchar(20));mysql&gt; insert into tb1(name) values(&#39;tom1&#39;);mysql&gt; insert into tb1(name) values(&#39;tom2&#39;);mysql&gt; commit;mysql&gt; select * from tb1;+----+------+| id | name |+----+------+| 1 | tom1 || 2 | tom2 |+----+------+ 方案：mysqldump全库备份+binlog还原 1、mysqldump备份方案： 每周一凌晨1点全库备份 2、备份步骤 （1） 创建备份目录 12# mkdir &#x2F;opt&#x2F;mysqlbackup# mkdir &#x2F;opt&#x2F;mysqlbackup&#x2F;daily （2）全库备份 这里我们模拟周一的完整备份数据库任务 123#mysqldump -uroot -p --flush-logs test_db &gt; &#x2F;opt&#x2F;mysqlbackup&#x2F;test_db_2016_09_12.sql（test_db_&#96;date +%Y%m%d_%H%M%S&#96;）[root@localhost data]# ls -l &#x2F;opt&#x2F;mysqlbackup&#x2F;-rw-r--r--. 1 root root 1871 Sep 13 21:06 test_db_2016_09_12.sql 备份mysqldump全库备份之前的binlog日志文（注：生产环境中可能不只一个binlog文件） 12# cp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql-bin.000001 &#x2F;opt&#x2F;mysqlbackup&#x2F;daily&#x2F;# mysql -uroot -p -e &quot;purge binary logs to &#39;mysql-bin.000002&#39;&quot; 3、模拟下操作失误,将数据修改错误了。 12345mysql&gt; use test_db;mysql&gt; delete from tb1 where id&#x3D;1;mysql&gt; commit;mysql&gt; insert into tb1(name) values(&#39;tom3&#39;);mysql&gt; commit; 备份自mysqldump之后的binlog日志文件 1cp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql-bin.000002 &#x2F;opt&#x2F;mysqlbackup&#x2F;daily&#x2F; 上面的模拟的误操作是删除了id=1的记录 4、现在我们使用mysqldump的全库备份和binlog来恢复数据。 使用mysqldump的备份进行全库恢复 1# mysql -uroot -p test_db &lt; &#x2F;opt&#x2F;mysqlbackup&#x2F;test_db_2016_09_12.sql 查询一下数据 12345678[root@localhost ~]# mysql -uroot -p -e &quot;select * from test_db.tb1&quot;Enter password:+----+------+| id | name |+----+------+| 1 | tom1 || 2 | tom2 |+----+------+ 从显示结果可以看到使用mysqldump备份将数据还原到了备份时的状态，刚才删除的数据（id=2）恢复回来了，但备份后产生的数据却丢失了所以还得利用binlog进一步还原 因为删除是在全库备份后发生的，而mysqldump全库备份时使用–flush-logs选项，所以只需要分析全库备份后的binlog即mysql-bin.000002。 123456mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000002 | 1853 |+------------------+-----------+ 查看mysql-bin.000002中的事件，可以看到有删除事件 1234567891011mysql&gt; show binlog events in &#39;mysql-bin.000002&#39;;| mysql-bin.000002 | 219 | Query | 1 | 294 | BEGIN|| mysql-bin.000002 | 294 | Table_map | 1 | 346 | table_id:118 (test_db.tb1)|| mysql-bin.000002 | 346 | Delete_rows | 1 | 391 | table_id:118 flags: STMT_END_F|| mysql-bin.000002 | 391 | Xid | 1 | 422 | COMMIT &#x2F;*xid&#x3D;2739 *&#x2F; 使用mysqlbinlog 命令可以查看备份的binlog文件的详细事件。 恢复流程：我们直接用bin-log日志将数据库恢复到删除位置前,然后跳过故障点,再进行恢复删除后的所有操作。 1# mysqlbinlog -v &#x2F;opt&#x2F;mysqlbackup&#x2F;daily&#x2F;mysql-bin.000002 我们先用mysqlbinlog命令找到delete那条语句的位置 1234567891011# at 219#160911 17:19:55 server id 1 end_log_pos 294 CRC32 0x84590493 Querythread_id&#x3D;66 exec_time&#x3D;0 error_code&#x3D;0SET TIMESTAMP&#x3D;1473585595&#x2F;*!*&#x2F;;SET @@session.pseudo_thread_id&#x3D;66&#x2F;*!*&#x2F;;SET @@session.foreign_key_checks&#x3D;1, @@session.sql_auto_is_null&#x3D;0,@@session.unique_checks&#x3D;1, @@session.autocommit&#x3D;1&#x2F;*!*&#x2F;;SET @@session.sql_mode&#x3D;1075838976&#x2F;*!*&#x2F;;SET @@session.auto_increment_increment&#x3D;1, @@session.auto_increment_offset&#x3D;1&#x2F;*!*&#x2F;;&#x2F;*!\\C utf8 *&#x2F;&#x2F;*!*&#x2F;;。。。 。。。 。。。 通过mysqlbinlog命令所显示的结果可以看到误操作delete的开始postion为219，结束position是422。 从二进制日志中读取指定position=219事件位置作为截至，即把数据恢复到delete删除前 1#mysqlbinlog --start-position&#x3D;422 &#x2F;opt&#x2F;mysqlbackup&#x2F;daily&#x2F;mysql-bin.000002 | mysql -u root -p 查看恢复结果： 123456789# mysql -uroot -p -e &quot;select * from test_db.tb1&quot;Enter password:+----+------+| id | name |+----+------+| 1 | tom1 || 2 | tom2 || 3 | tom3 |+----+------+ 从上面显示可以看出数据恢复到正常状态 生产环境中Mysql数据库的备份是周期性重复的操作，所以通常是要编写脚本实现，通过crond计划任务周期性执行备份脚本 mysqldump备份方案： 周日凌晨1点全库备份 周一到周六凌晨每隔4个小时增量备份一次 设置crontab任务，每天执行备份脚本 12345# crontab –e#每个星期日凌晨1:00执行完全备份脚本0 1 * * 0 &#x2F;root&#x2F;mysqlfullbackup.sh &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1#周一到周六每隔4个小时增量备份一次0 *&#x2F;4 * * 1-6 &#x2F;root&#x2F;mysqldailybackup.sh &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 mysqlfullbackup.sh脚本内容： 123456789101112131415161718192021222324252627282930313233343536373839404142[root@localhost ~]# cat mysqlfullbackup.sh#!/bin/sh# Name:mysqlFullBackup.sh# 定义数据库目录mysqlDir=/usr/local/mysql# 定义用于备份数据库的用户名和密码user=rootuserpwd=123456dbname=test_db# 定义备份目录databackupdir=/opt/mysqlbackup[ ! -d $databackupdir ] &amp;&amp; mkdir $databackupdir# 定义邮件正文文件emailfile=$databackupdir/email.txt# 定义邮件地址email=root@localhost.localdomain# 定义备份日志文件logfile=$databackupdir/mysqlbackup.logDATE=`date -I`echo \"\" &gt; $emailfileecho $(date +\"%y-%m-%d %H:%M:%S\") &gt;&gt; $emailfilecd $databackupdir# 定义备份文件名dumpfile=mysql_$DATE.sqlgzdumpfile=mysql_$DATE.sql.tar.gz# 使用mysqldump备份数据库，请根据具体情况设置参数$mysqlDir/bin/mysqldump -u$user -p$userpwd --flush-logs -x $dbname &gt; $dumpfile//-x--lock-all-tables# 压缩备份文件if [ $? -eq 0 ]; thentruetar czf $gzdumpfile $dumpfile &gt;&gt; $emailfile 2&gt;&amp;1trueecho \"BackupFileName:$gzdumpfile\" &gt;&gt; $emailfiletrueecho \"DataBase Backup Success!\" &gt;&gt; $emailfiletruerm -f $dumpfileelsetrueecho \"DataBase Backup Fail!\" &gt;&gt; $emailfilefi# 写日志文件echo \"--------------------------------------------------------\" &gt;&gt; $logfilecat $emailfile &gt;&gt; $logfile# 发送邮件通知cat $emailfile | mail -s \"MySQL Backup\" $email mysqldailybackup.sh脚本内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[root@localhost ~]# cat mysqldailybackup.sh#!/bin/sh# Name:mysqlDailyBackup.sh# 定义数据库目录和数据目录mysqldir=/usr/local/mysqldatadir=$mysqldir/data# 定义用于备份数据库的用户名和密码user=rootuserpwd=123456# 定义备份目录，每日备份文件备份到$dataBackupDir/dailydatabackupdir=/opt/mysqlbackupdailybackupdir=$databackupdir/daily[ ! -d $dailybackupdir ] &amp;&amp; mkdir -p $databackupdir/daily# 定义邮件正文文件emailfile=$databackupdir/email.txt# 定义邮件地址email=root@localhost.localdomain# 定义日志文件logfile=$databackupdir/mysqlbackup.logecho \"\" &gt; $emailfileecho $(date +\"%y-%m-%d %H:%M:%S\") &gt;&gt; $emailfile## 刷新日志，使数据库使用新的二进制日志文件$mysqldir/bin/mysqladmin -u$user -p$userpwd flush-logscd $datadir# 得到二进制日志列表filelist=`cat mysql-bin.index`icounter=0for file in $filelistdotrueicounter=`expr $icounter + 1` // = let icounter++donenextnum=0ifile=0for file in $filelistdotruebinlogname=`basename $file`truenextnum=`expr $nextnum + 1`# 跳过最后一个二进制日志（数据库当前使用的二进制日志文件）trueif [ $nextnum -eq $icounter ]; thentruetrueecho \"Skip lastest!\" &gt; /dev/nulltrueelsetruetruedest=$dailybackupdir/$binlogname# 跳过已经备份的二进制日志文件truetrueif [ -e $dest ]; thentruetruetrueecho \"Skip exist $binlogname!\" &gt; /dev/nulltruetrueelse# 备份日志文件到备份目录truetruetruecp $binlogname $dailybackupdirtruetruetrueif [ $? -eq 0 ]; thentruetruetruetrueifile=`expr $ifile + 1`truetruetruetrueecho \"$binlogname backup success!\" &gt;&gt; $emailfiletruetruetruefitruetruefitruefidoneif [ $ifile -eq 0 ];thentrueecho \"No Binlog Backup!\" &gt;&gt; $emailfileelsetrueecho \"Backup $ifile File(s).\" &gt;&gt; $emailfiletrueecho \"Backup MySQL Binlog OK!\" &gt;&gt; $emailfilefi# 发送邮件通知cat $emailfile | mail -s \"MySQL Backup\" $email# 写日志文件echo \"--------------------------------------------------------\" &gt;&gt; $logfilecat $emailfile &gt;&gt; $logfile","path":"posts/49et.html","date":"06-24","excerpt":"","tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"}]},{"title":"MySQL配置参数优化","text":"为什么要分表和分区？ 我们的数据库数据越来越大，随之而来的是单个表中数据太多。以至于查询速度变慢，而且由于表的锁机制导致应用操作也搜到严重影响，出现了数据库性能瓶颈。 mysql中有一种机制是表锁定和行锁定，是为了保证数据的完整性。表锁定表示你们都不能对这张表进行操作，必须等我对表操作完才行。行锁定也一样，别的sql必须等我对这条数据操作完了，才能对这条数据进行操作。当出现这种情况时，我们可以考虑分表或分区。 一、分表 什么是分表？ 分表是将一个大表按照一定的规则分解成多张具有独立存储空间的实体表，每个表都对应三个文件，MYD数据文件，.MYI索引文件，.frm表结构文件。这些表可以分布在同一块磁盘上，也可以在不同的机器上。app读写的时候根据事先定义好的规则得到对应的表名，然后去操作它。 将单个数据库表进行拆分，拆分成多个数据表，然后用户访问的时候，根据一定的算法（如用hash的方式，也可以用求余（取模）的方式），让用户访问不同的表，这样数据分散到多个数据表中，减少了单个数据表的访问压力。提升了数据库访问性能。分表的目的就在于此，减小数据库的负担，缩短查询时间。 Mysql分表分为垂直切分和水平切分 垂直切分是指数据表列的拆分，把一张列比较多的表拆分为多张表 通常我们按以下原则进行垂直拆分: 把不常用的字段单独放在一张表; 把text，blob（binary large object，二进制大对象）等大字段拆分出来放在附表中; 经常组合查询的列放在一张表中; 垂直拆分更多时候就应该在数据表设计之初就执行的步骤，然后查询的时候用join关键起来即可。 水平拆分是指数据表行的拆分，把一张的表的数据拆成多张表来存放。 水平拆分原则 通常情况下，我们使用hash、取模等方式来进行表的拆分 比如一张有400W的用户表users，为提高其查询效率我们把其分成4张表users1，users2，users3，users4 通过用ID取模的方法把数据分散到四张表内Id%4= [0,1,2,3] 然后查询,更新,删除也是通过取模的方法来查询 部分业务逻辑也可以通过地区，年份等字段来进行归档拆分; 进行拆分后的表，这时我们就要约束用户查询行为。比如我们是按年来进行拆分的,这个时候在页面设计上就约束用户必须要先选择年,然后才能进行查询。 1、分表的几种方式： 1）mysql集群 它并不是分表，但起到了和分表相同的作用。集群可分担数据库的操作次数，将任务分担到多台数据库上。集群可以读写分离，减少读写压力。从而提升数据库性能。 2）预先估计会出现大数据量并且访问频繁的表，将其分为若干个表 根据一定的算法（如用hash的方式，也可以用求余（取模）的方式）让用户访问不同的表。 例如论坛里面发表帖子的表，时间长了这张表肯定很大，几十万，几百万都有可能。聊天室里面信息表，几十个人在一起一聊一个晚上，时间长了，这张表的数据肯定很大。像这样的情况很多。所以这种能预估出来的大数据量表，我们就事先分出个N个表，这个N是多少，根据实际情况而定。以聊天信息表为例：我们事先建100个这样的表，message_00,message_01,message_02…message_98,message_99.然后根据用户的ID来判断这个用户的聊天信息放到哪张表里面，可以用hash的方式来获得，也可以用求余的方式来获得，方法很多。 或者可以设计每张表容纳的数据量是N条，那么如何判断某张表的数据是否容量已满呢？可以在程序段对于要新增数据的表，在插入前先做统计表记录数量的操作，当&lt;N条数据，就直接插入，当已经到达阀值，可以在程序段新创建数据库表（或者已经事先创建好），再执行插入操作）。 3）利用merge存储引擎来实现分表 如果要把已有的大数据量表分开比较痛苦，最痛苦的事就是改代码，因为程序里面的sql语句已经写好了，用merge存储引擎来实现分表, 这种方法比较适合。 merge分表，分为主表和子表，主表类似于一个壳子，逻辑上封装了子表，实际上数据都是存储在子表中的。 我们可以通过主表插入和查询数据，如果清楚分表规律，也可以直接操作子表。 下面我们来实现一个简单的利用merge存储引擎来实现分表的演示： 创建一个完整表存储着所有的成员信息（表名为member) 12345678910# 创建库drop database IF EXISTS testdb;create database testdb;use testdb;create table member(id bigint auto_increment primary key,name varchar(20),sex tinyint not null default &#39;0&#39;)engine&#x3D;myisam default charset&#x3D;utf8 auto_increment&#x3D;1; 加入点数据： 12insert into member(name,sex) values(&#39;tom1&#39;,1);insert into member(name,sex) select name,sex from member; 第二条语句多执行几次就有了很多数据 123456789101112131415161718192021mysql&gt; select * from member;+----+------+-----+| id | name | sex |+----+------+-----+| 1 | tom1 | 1 || 2 | tom1 | 1 || 3 | tom1 | 1 || 4 | tom1 | 1 || 5 | tom1 | 1 || 6 | tom1 | 1 || 7 | tom1 | 1 || 8 | tom1 | 1 || 9 | tom1 | 1 || 10 | tom1 | 1 || 11 | tom1 | 1 || 12 | tom1 | 1 || 13 | tom1 | 1 || 14 | tom1 | 1 || 15 | tom1 | 1 || 16 | tom1 | 1 |+----+------+-----+ 下面我们进行分表，这里我们把member分两个表tb_member1,tb_member2 123456789101112131415# 创建两个分表use testdb;DROP table IF EXISTS tb_member1;create table tb_member1(id bigint primary key ,name varchar(20),sex tinyint not null default &#39;0&#39;)ENGINE&#x3D;MyISAM DEFAULT CHARSET&#x3D;utf8 ;DROP table IF EXISTS tb_member2;create table tb_member2(id bigint primary key,name varchar(20),sex tinyint not null default &#39;0&#39;)ENGINE&#x3D;MyISAM DEFAULT CHARSET&#x3D;utf8; 创建主表tb_member 1234567# 创建主表tb_memberDROP table IF EXISTS tb_member;create table tb_member(id bigint primary key ,name varchar(20),sex tinyint not null default &#39;0&#39;) ENGINE&#x3D;MERGE UNION&#x3D;(tb_member1,tb_member2) INSERT_METHOD&#x3D;LAST CHARSET&#x3D;utf8 ; 12345678insert into member(name,sex) values(&#39;tom2&#39;,2);insert into member(name,sex) select name,sex from member;insert into member(name,sex) values(&#39;tom3&#39;,3);insert into member(name,sex) select name,sex from member;insert into member(name,sex) values(&#39;tom4&#39;,4);insert into member(name,sex) select name,sex from member; **注：INSERT_METHOD,此参数INSERT_METHOD = NO 表示该表不能做任何写入操作只作为查询使用,INSERT_METHOD = LAST表示插入到最后的一张表里面。INSERT_METHOD = first表示插入到第一张表里面。 ** 查看一下tb_member表的结构: 12345678910111213mysql&gt; desc tb_member;mysql&gt; desc tb_member;+-------+-------------+------+-----+---------+-----------------------------------------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-----------------------------------------+| id | bigint(20) | NO | PRI | NULL | auto_increment || name | varchar(20) | YES | | NULL | || sex | tinyint(4) | NO | | 0 | |+-------+-------------+------+-----+---------+------------------------------------------+3 rows in set (0.00 sec) 接下来，我们把数据分到两个分表中去： 12345# 按照已经有行插入insert into tb_member1(id,name,sex) select id,name,sex from member whereid%2&#x3D;0;insert into tb_member2(id,name,sex) select id,name,sex from member whereid%2&#x3D;1; 查看两个子表的数据： 12345678910111213141516171819202122232425262728mysql&gt; select * from tb_member1;+----+------+-----+| id | name | sex |+----+------+-----+| 16 | tom1 | 1 || 14 | tom1 | 1 || 12 | tom1 | 1 || 10 | tom1 | 1 || 8 | tom1 | 1 || 6 | tom1 | 1 || 4 | tom1 | 1 || 2 | tom1 | 1 |+----+------+-----+8 rows in set (0.00 sec)mysql&gt; select * from tb_member2;+----+------+-----+| id | name | sex |+----+------+-----+| 3 | tom1 | 1 || 1 | tom1 | 1 || 5 | tom1 | 1 || 7 | tom1 | 1 || 9 | tom1 | 1 || 11 | tom1 | 1 || 13 | tom1 | 1 || 15 | tom1 | 1 |+----+------+-----+8 rows in set (0.00 sec) 查看一下主表的数据： 1234567891011121314151617181920212223242526272829mysql&gt; select * from tb_member;+----+------+-----+| id | name | sex |+----+------+-----+| 16 | tom1 | 1 || 14 | tom1 | 1 || 12 | tom1 | 1 || 10 | tom1 | 1 || 8 | tom1 | 1 || 6 | tom1 | 1 || 4 | tom1 | 1 || 2 | tom1 | 1 || 15 | tom1 | 1 || 13 | tom1 | 1 || 11 | tom1 | 1 || 9 | tom1 | 1 || 7 | tom1 | 1 || 5 | tom1 | 1 || 3 | tom1 | 1 || 1 | tom1 | 1 |+----+------+-----+16 rows in set (0.00 sec)mysql&gt; select * from tb_member where id&#x3D;3;+----+------+-----+| id | name | sex |+----+------+-----+| 3 | tom1 | 1 |+----+------+-----+1 row in set (0.00 sec) 注意：总表只是一个外壳，存取数据发生在一个一个的子表里面。 注意：每个子表都有自已独立的相关表文件，而主表只是一个壳，并没有完整的相关表文件 123456789[root@localhost ~]# ls -l &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;test&#x2F;tb_member*-rw-r-----. 1 mysql mysql 8614 Sep 15 21:49&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;test&#x2F;tb_member1.frm-rw-r-----. 1 mysql mysql 320 Sep 16 00:02&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;test&#x2F;tb_member1.MYD-rw-r-----. 1 mysql mysql 2048 Sep 16 00:43&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;test&#x2F;tb_member1.MYI-rw-r-----. 1 mysql mysql 8614 Sep 15 21:50&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;test&#x2F;tb_member.MRG 二、分区 什么是分区？ 分区和分表相似，都是按照规则分解表。不同在于分表将大表分解为若干个独立的实体表，而分区是将数据分段划分在多个位置存放，分区后，表还是一张表，但数据散列到多个位置了。app读写的时候操作的还是表名字，db自动去组织分区的数据。 分区主要有两种形式： 水平分区（Horizontal Partitioning）这种形式分区是对表的行进行分区，所有在表中定义的列在每个数据集中 都能找到，所以表的特性依然得以保持。 举个简单例子：一个包含十年发票记录的表可以被分区为十个不同的分区，每个分区包含的是其中一年的记录。 垂直分区（Vertical Partitioning）这种分区方式一般来说是通过对表的垂直划分来减少目标表的宽度，使某些特定的列被划分到特定的分区，每个分区都包含了其中的列所对应的行。 举个简单例子：一个包含了大text和BLOB列的表，这些text和BLOB列又不经常被访问，这时候就要把这些不经常使用的text和BLOB了划分到另一个分区，在保证它们数据相关性的同时还能提高访问速度。 1、mysql怎么查看是否支持分区 mysql从5.1开始支持分区功能 查询命令如下： 12mysql&gt; show variables like &#39;%partition%&#39;;Empty set (0.00 sec) 如果查询结果显示Empty，表示不支持分区。 但是上面的查询方法只是针对mysql5.6以下版本。 如果mysql5.6以及以上版本，需要使用下面的查询命令： 1mysql&gt; show plugins; 编写代码 1234567891011121314151617drop database IF EXISTS testdb;create database testdb;use testdb;create table if not exists user ( id int not null auto_increment, name varchar(30) not null default &#39;&#39;, sex int(1) not null default &#39;0&#39;, primary key(id))default charset&#x3D;utf8 auto_increment&#x3D;1partition by range(id) ( partition p0 values less than (3), partition p1 values less than (6), partition p2 values less than (9), partition p3 values less than (12), partition p4 values less than maxvalue); 插入些数据 1234567891011121314insert into testdb.user(name,sex)values (&#39;tom1&#39;,&#39;0&#39;);insert into testdb.user(name,sex)values (&#39;tom2&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom3&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom4&#39;,&#39;0&#39;);insert into testdb.user(name,sex)values (&#39;tom5&#39;,&#39;0&#39;);insert into testdb.user(name,sex)values (&#39;tom6&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom7&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom8&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom9&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom10&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom11&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom12&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom13&#39;,&#39;1&#39;);insert into testdb.user(name,sex)values (&#39;tom14&#39;,&#39;1&#39;); 到存放数据库表文件的地方看一下 1select * from testdb.user partition(p4); 从information_schema系统库中的partitions表中查看分区信息 1mysql&gt; select * from information_schema.partitions where table_schema&#x3D;&#39;test2&#39; and table_name&#x3D;&#39;user&#39;\\G; 测试在创建表之后分区是否可以 2、新增分区 12mysql&gt; alter table test2.user add partition (partition partionname values lessthan (n)); （1）删除分区 当删除了一个分区，也同时删除了该分区中所有的数据。 1234567alter table testdb.user drop partition p4;alter table testdb.user add partition( partition m5 values less than (13));select * from testdb.user partition(m5); 查看分区 1select * from information_schema.&#96;PARTITIONS&#96;; 1234select PARTITION_NAME,PARTITION_METHOD,PARTITION_DESCRIPTION,TABLE_ROWSfrom information_schema.&#96;PARTITIONS&#96;where TABLE_SCHEMA&#x3D;&#39;testdb&#39;and table_name&#x3D; &#39;user&#39;; 3、分区的合并 下面的SQL，将p1 – p3合并为2个分区p01– p02 12345alter table testdb.userreorganize partition p1,p2,p3 into(truepartition t1 values less than (8),truepartition t2 values less than (12)); 4、未分区表和分区表性能测试 创建一个未分区的表 12345678910mysql&gt; create table test2.tab1(c1 int,c2 varchar(30),c3 date);创建分区表,按日期的年份拆分mysql&gt; CREATE TABLE test2.tab2 ( c1 int, c2 varchar(30) , c3 date )PARTITION BY RANGE (year(c3)) (PARTITION p0 VALUES LESS THAN (1995),PARTITION p1 VALUES LESS THAN (1996) , PARTITION p2 VALUES LESS THAN (1997) ,PARTITION p3 VALUES LESS THAN (1998) , PARTITION p4 VALUES LESS THAN (1999) ,PARTITION p5 VALUES LESS THAN (2000) , PARTITION p6 VALUES LESS THAN (2001) ,PARTITION p7 VALUES LESS THAN (2002) , PARTITION p8 VALUES LESS THAN (2003) ,PARTITION p9 VALUES LESS THAN (2004) , PARTITION p10 VALUES LESS THAN (2010),PARTITION p11 VALUES LESS THAN MAXVALUE ); 注意:最后一行，考虑到可能的最大值 通过存储过程插入100万条测试数据 创建存储过程： 12345678910111213mysql&gt; delimiter $$&#x2F;&#x2F;指定存储过程结束符mysql&gt;CREATE PROCEDURE load_part_tab()truetruebegintruedeclare v int default 0;truewhile v &lt; 2000000truedotruetrueinsert into test2.tab1truetruevalues (v,&#39;testing partitions&#39;,adddate(&#39;1995-01-01&#39;,(rand(v)*36520) mod 3652));trueset v &#x3D; v + 1;trueend while;trueendtrue$$ 注：RAND()函数在0和1之间产生一个随机数，如果一个整数参数N被指定，它被用作种子值。每个种子产生的随机数序列是不同的。 执行存储过程load_part_tab向test2.tab1表插入数据 12345678910111213141516171819mysql&gt; delimiter ; &#x2F;&#x2F; 注意有空格mysql&gt; call load_part_tab();向test2.tab2表中插入数据mysql&gt; insert into test2.tab2 select * from test2.tab1;测试SQL性能mysql&gt; select count(*) from test2.tab1 where c3 &gt; &#39;1995-01-01&#39; and c3 &lt; &#39;1995-12-31&#39;;+----------+| count(*) |+----------+| 219642 |+----------+1 row in set (0.84 sec)mysql&gt; select count(*) from test2.tab2 where c3 &gt; &#39;1995-01-01&#39; and c3 &lt; &#39;1995-12-31&#39;;+----------+| count(*) |+----------+| 219642 |+----------+1 row in set (0.09 sec) 结果表明分区表比未分区表的执行时间少很多。 通过explain语句来分析执行情况 123456789101112131415161718192021222324252627282930313233mysql&gt; flush tables;mysql&gt; explain select count(*) from test2.tab1 where c3 &gt; &#39;1995-01-01&#39; and c3 &lt;&#39;1995-12-31&#39;\\G;*************************** 1. row ***************************id: 1select_type: SIMPLEtable: tab1partitions: NULLtype: ALLpossible_keys: NULLkey: NULLkey_len: NULLref: NULLrows: 2001552filtered: 11.11Extra: Using where1 row in set, 1 warning (0.00 sec)mysql&gt; explain select count(*) from test2.tab2 where c3 &gt; &#39;1995-01-01&#39; and c3 &lt;&#39;1995-12-31&#39;\\G;*************************** 1. row ***************************id: 1select_type: SIMPLEtable: tab2partitions: p1type: ALLpossible_keys: NULLkey: NULLkey_len: NULLref: NULLrows: 220206filtered: 11.11Extra: Using where1 row in set, 1 warning (0.00 sec) explain语句显示了SQL查询要处理的记录数目可以看出分区表比未分区表的明显扫描的记录要少很多。 创建索引后情况测试 1234567891011121314mysql&gt; create index idx_of_c3 on test2.tab1(c3);Query OK, 0 rows affected (5.07 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; create index idx_of_c3 on test2.tab2(c3);Query OK, 0 rows affected (4.87 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; flush tables;mysql&gt; select count(*) from test2.tab1 where c3 &gt; &#39;1996-01-01&#39; and c3 &lt; &#39;1996-12-31&#39;;+----------+| count(*) |+----------+| 220264 |+----------+1 row in set (0.12 sec) 重启mysqld服务 12345678mysql&gt; select count(*) from test2.tab2 where c3 &gt; &#39;1996-01-01&#39; and c3 &lt; &#39;1996-12-31&#39;;+----------+| count(*) |+----------+| 220264 |+----------+1 row in set (0.11 sec) 创建索引后分区表比未分区表相差不大（数据量越大差别会明显些） 5、分区时，将不同分区放到不同存储位置 （1）建表时，提前创建好存储目录，并授权给mysql: 1234567[root@mysql ~]# cd /opt/[root@mysql opt]# mkdir -p data/ares&#123;1..3&#125;[root@mysql opt]# ll data/总用量 0drwxr-xr-x 2 root root 6 Jun 23 17:27 ares1drwxr-xr-x 2 root root 6 Jun 23 17:27 ares2drwxr-xr-x 2 root root 6 Jun 23 17:27 ares3 （2）创建表格。 注：使用mysql默认的存储引擎inodb时候，只需要指定data directory 就可以，因为inodb的数据和索引在一个文件中。但是创建表格时指定engine=myisam时，修改分区的存储位置，需要同时指定data directory和index directory。 123456789create table user( id int not null auto_increment, name varchar(30) not null default &#39;&#39;, primary key(id)) engine&#x3D;innodb default charset&#x3D;utf8 auto_increment&#x3D;1 partition by range(id)( partition p1 values less than (3) data directory &#39;&#x2F;opt&#x2F;data&#x2F;area1&#39;, partition p2 values less than (6) data directory &#39;&#x2F;opt&#x2F;data&#x2F;area2&#39;, partition p3 values less than (9) data directory &#39;&#x2F;opt&#x2F;data&#x2F;area3&#39;); （3）查看分区情况 123456789101112131415[root@mysql ~]# ls -R &#x2F;data&#x2F;&#x2F;data&#x2F;:area1 area2 area3&#x2F;data&#x2F;area1:test&#x2F;data&#x2F;area1&#x2F;test:user#P#p1.ibd&#x2F;data&#x2F;area2:test&#x2F;data&#x2F;area2&#x2F;test:user#P#p2.ibd&#x2F;data&#x2F;area3:test&#x2F;data&#x2F;area3&#x2F;test:user#P#p3.ibd 查看默认数据存储位置的文件： 12345[root@mysql ~]# cd &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;test[root@mysql test]# ls –l-rw-r----- 1 mysql mysql 30 9月 22 17:55 user#P#p1.isl-rw-r----- 1 mysql mysql 30 9月 22 17:55 user#P#p2.isl-rw-r----- 1 mysql mysql 30 9月 22 17:55 user#P#p3.isl 6、mysql分区的类型 （1）RANGE分区 基于属于一个给定连续区间的列值，把多行分配给分区。这些区间要连续且不能相互重叠，使用VALUES LESS THAN操作符来进行定义。以下是实例。 123456789101112131415CREATE TABLE employees (id INT NOT NULL,fname VARCHAR(30),lname VARCHAR(30),hired DATE NOT NULL DEFAULT &#39;1970-01-01&#39;,separated DATE NOT NULL DEFAULT &#39;9999-12-31&#39;,job_code INT NOT NULL,store_id INT NOT NULL)partition BY RANGE (store_id) (partition p0 VALUES LESS THAN (6),partition p1 VALUES LESS THAN (11),partition p2 VALUES LESS THAN (16),partition p3 VALUES LESS THAN (21)); 按照这种分区方案，在商店1到5工作的雇员相对应的所有行被保存在分区P0中，商店6到10的雇员保存在P1中，依次类推。注意，每个分区都是按顺序进行定义，从最低到最高。 对于包含数据(72, ‘Michael’, ‘Widenius’,‘1998-06-25’, NULL, 13)的一个新行，可以很容易地确定它将插入到p2分区中，但是如果增加了一个编号为第21的商店，将会发生什么呢？在这种方案下，由于没有规则把store_id大于20的商店包含在内，服务器将不知道把该行保存在何处，将会导致错误。要避免这种错误，可以创建maxvalue分区，所有不在指定范围内的记录都会被存储到maxvalue所在的分区中。 1mysql&gt; alter table test2.user add partition (partition p4 values less than maxvalue); （2）LIST分区 类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择。LIST分区通过使用“PARTITION BY LIST(expr)”来实现，其中“expr” 是某列值或一个基于某个列值、并返回一个整数值的表达式，然后通过“VALUES IN (value_list)”的方式来定义每个分区，其中“value_list”是一个通过逗号分隔的整数列表。 要按照属于同一个地区商店的行保存在同一个分区中的方式来分割表，可以使用下面的“CREATE TABLE”语句： 123456789101112131415CREATE TABLE employees (id INT NOT NULL,fname VARCHAR(30),lname VARCHAR(30),hired DATE NOT NULL DEFAULT &#39;1970-01-01&#39;,separated DATE NOT NULL DEFAULT &#39;9999-12-31&#39;,job_code INT,store_id INT)PARTITION BY LIST(store_id)(PARTITION pNorth VALUES IN (3,5,6,9,17),PARTITION pEast VALUES IN (1,2,10,11,19,20),PARTITION pWest VALUES IN (4,12,13,14,18),PARTITION pCentral VALUES IN (7,8,15,16)); 这使得在表中增加或删除指定地区的雇员记录变得容易起来。例如，假定西区的所有音像店都卖给了其他公司。那么与在西区音像店工作雇员相关的所有记录（行）可以使用查询“ALTER TABLE employees DROP PARTITION pWest; ”来进行删除，它与具有同样作用的DELETE （删除）查询“DELETE query DELETE FROM employees WHERE store_id IN (4,12,13,14,18); ”比起来，要有效得多。 要点：如果试图插入列值不在分区值列表中的一行时，那么“INSERT”查询将失败并报错。例如，假定LIST分区的采用上面的方案，下面的插入将失败： 1INSERT INTO employees VALUES(224, &#39;Linus&#39;, &#39;Torvalds&#39;, &#39;2002-05-01&#39;, &#39;2004-10-12&#39;, 42, 21); 这是因为“store_id”列值21不能在用于定义分区pNorth, pEast, pWest,或pCentral的值列表中找到。要重点注意的是，LIST分区没有类似如“VALUES LESS THAN MAXVALUE”这样的包含其他值在内的定义。将要匹配的任何值都必须在值列表中找到。 3.HASH分区 这种模式允许DBA通过对表的一个或多个列的Hash Key进行计算，最后通过这个Hash码不同数值对应的数据区域进行分区。 hash分区的目的是将数据均匀的分布到预先定义的各个分区中，保证各分区的数据量大致一致。在RANGE和LIST分区中，必须明确指定一个给定的列值或列值集合应该保存在哪个分区中；而在HASH分区中，MYSQL自动完成这些工作，用户所要定一个列值或者表达式，以及指定被分区的表将要被分割成的分区数量。 1mysql&gt; create table t_hash( a int(11), b datetime) partition by hash(year(b)) partitions 4; hash的分区函数页需要返回一个整数值。partitions子句中的值是一个非负整数，不加的partitions子句的话，默认为分区数为1。 1234567create table t_hash( a int(11), b datetime) partition by hash(year(b)) partitions 4;insert into t_hash values(1,&#39;2010-04-01&#39;);select PARTITION_NAME,PARTITION_METHOD,PARTITION_DESCRIPTION,TABLE_ROWSfrom information_schema.&#96;PARTITIONS&#96;where TABLE_SCHEMA&#x3D;&#39;testdb&#39;and table_name&#x3D; &#39;t_hash&#39;; 该记录会被放入分区p2中。因为插入2010-04-01进入表t_hash,那么 1234567891011121314151617181920212223242526272829MOD(YEAR('2010-04-01'),4)=2mysql&gt; select * from information_schema.partitions where table_schema='test2' andtable_name='t_hash'\\G;*************************** 1. row *************************** TABLE_CATALOG: def TABLE_SCHEMA: testdb TABLE_NAME: t_hash PARTITION_NAME: p0 SUBPARTITION_NAME: NULL PARTITION_ORDINAL_POSITION: 1 SUBPARTITION_ORDINAL_POSITION: NULL PARTITION_METHOD: HASH SUBPARTITION_METHOD: NULL PARTITION_EXPRESSION: year(b) SUBPARTITION_EXPRESSION: NULL PARTITION_DESCRIPTION: NULL TABLE_ROWS: 0 AVG_ROW_LENGTH: 0 DATA_LENGTH: 16384 MAX_DATA_LENGTH: NULL INDEX_LENGTH: 0 DATA_FREE: 0 CREATE_TIME: 2016-09-16 22:48:59 UPDATE_TIME: 2016-09-17 23:36:22 CHECK_TIME: NULL CHECKSUM: NULL PARTITION_COMMENT: NODEGROUP: default TABLESPACE_NAME: NULL 可以看到P2分区有一条记录。当前这个例子并不能把数据均匀的分布到各个分区，因为按照YEAR函数进行的，该值本身是离散的。如果对连续的值进行HASH分区，如自增长的主键，则可以较好地将数据平均分布。 请思考： 1mysql&gt; insert into t_hash values(1,&#39;2012-04-01&#39;) 记录会插入哪个分区？ 7、key分区 key分区和hash分区相似，不同在于hash分区是用户自定义函数进行分区，key分区使用mysql数据库提供的函数进行分区，NDB cluster使用MD5函数来分区，对于其他存储引擎mysql使用内部的hash函数。 12mysql&gt; create table t_key( a int(11), b datetime) partition by key(b) partitions4; 上面的RANGE、LIST、HASH、KEY四种分区中，分区的条件必须是整形，如果不是整形需要通过函数将其转换为整形。 8、columns分区 mysql-5.5开始支持COLUMNS分区，可视为RANGE和LIST分区的进化，COLUMNS分区可以直接使用非整形数据进行分区。 COLUMNS分区支持以下数据类型： 所有整形，如INT SMALLINT TINYINT BIGINT。FLOAT和DECIMAL则不支持。 日期类型，如DATE和DATETIME。其余日期类型不支持。 字符串类型，如CHAR、VARCHAR、BINARY和VARBINARY。 BLOB和TEXT类型不支持。 COLUMNS可以使用多个列进行分区。 mysql分表和分区有什么区别呢 实现方式上 a）mysql的分表是真正的分表，一张表分成很多表后，每一个小表都是完整的一张表，都对 应三个文件，一个.MYD数据文件，.MYI索引文件，.frm表结构文件。 b）分区不一样，一张大表进行分区后，他还是一张表，不会变成二张表，但是他存放数据的区块变多了 数据处理上 a）分表后，数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面。 b）分区呢，不存在分表的概念，分区只不过把存放数据的文件分成了许多小块，分区后的表呢，还是一张表，数据处理还是由自己来完成。 提高性能上 a）分表后，单表的并发能力提高了，磁盘I/O性能也提高了。并发能力为什么提高了呢，因为查寻一次所花的时间变短了，如果出现高并发的话，总表可以根据不同的查询，将并发压力分到不同的小表里面。 b）mysql提出了分区的概念，主要是想突破磁盘I/O瓶颈，想提高磁盘的读写能力，来增加mysql性能。在这一点上，分区和分表的测重点不同，分表重点是存取数据时，如何提高mysql并发能力上；而分区呢，如何突破磁盘的读写能力，从而达到提高mysql性能的目的。 实现的难易度上 a）分表的方法有很多，用merge来分表，是最简单的一种方式。这种方式跟分区难易度差不多，并且对 程序代码来说可以做到透明的。如果是用其他分表方式就比分区麻烦了。 b）分区实现是比较简单的，建立分区表，根建平常的表没什么区别，并且对开代码端来说是透明的。 mysql分表和分区有什么联系？ 都能提高mysql的性高，在高并发状态下都有一个良好的表现。 分表和分区不矛盾，可以相互配合的，对于那些大访问量，并且表数据比较多的表，我们可以采取分表和分区结合的方式，访问量不大，但是表数据很多的表，我们可以采取分区的方式等。 分表技术是比较麻烦的，需要手动去创建子表，app服务端读写时候需要计算子表名。采用merge好一些，但也要创建子表和配置子表间的union关系。 表分区相对于分表，操作方便，不需要创建子表。","path":"posts/49wn.html","date":"06-23","excerpt":"","tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"}]},{"title":"MySQL配置参数优化","text":"前言 很多人都将&lt;数据库设计范式&gt;作为数据库表结构设计“圣经”，认为只要按照这个范式需求设计，就能让设计出来的表结构足够优化，既能保证性能优异同时还能满足扩展性要求。殊不知，在N年前被奉为“圣经”的数据库设计3范式早就已经不完全适用了。这里我整理了一些比较常见的数据库表结构设计方面的优化技巧，希望对大家有用。 由于MySQL数据库是基于行(Row)存储的数据库，而数据库操作 IO 的时候是以 page(block)的方式，也就是说，如果我们每条记录所占用的空间量减小，就会使每个page中可存放的数据行数增大，那么每次 IO 可访问的行数也就增多了。反过来说，处理相同行数的数据，需要访问的 page 就会减少，也就是 IO 操作次数降低，直接提升性能。此外，由于我们的内存是有限的，增加每个page中存放的数据行数，就等于增加每个内存块的缓存数据量，同时还会提升内存换中数据命中的几率，也就是缓存命中率。 1、数据类型选择 数据库操作中最为耗时的操作就是 IO 处理，大部分数据库操作 90% 以上的时间都花在了 IO 读写上面。所以尽可能减少 IO 读写量，可以在很大程度上提高数据库操作的性能。 使用可以存下你的数据的最小的数据类型 使用简单的数据类型。int要比varchar类型在MySQL处理上简单 极可能的使用not null定义字段 尽量少用text类型，非用不可时最好考虑分表 我们无法改变数据库中需要存储的数据，但是我们可以在这些数据的存储方式方面花一些心思。下面的这些关于字段类型的优化建议主要适用于记录条数较多，数据量较大的场景，因为精细化的数据类型设置可能带来维护成本的提高，过度优化也可能会带来其他的问题： 数字类型：非万不得已不要使用DOUBLE，不仅仅只是存储长度的问题，同时还会存在精确性的问题。同样，固定精度的小数，也不建议使用DECIMAL，建议乘以固定倍数转换成整数存储，可以大大节省存储空间，且不会带来任何附加维护成本。对于整数的存储，在数据量较大的情况下，建议区分开 TINYINT / INT / BIGINT 的选择，因为三者所占用的存储空间也有很大的差别，能确定不会使用负数的字段，建议添加unsigned定义。当然，如果数据量较小的数据库，也可以不用严格区分三个整数类型。 字符类型：非万不得已不要使用 TEXT 数据类型，其处理方式决定了他的性能要低于char或者是varchar类型的处理。定长字段，建议使用 CHAR 类型，不定长字段尽量使用 VARCHAR，且仅仅设定适当的最大长度，而不是非常随意的给一个很大的最大长度限定，因为不同的长度范围，MySQL也会有不一样的存储处理。 时间类型：尽量使用TIMESTAMP类型，因为其存储空间只需要 DATETIME 类型的一半。对于只需要精确到某一天的数据类型，建议使用DATE类型，因为他的存储空间只需要3个字节，比TIMESTAMP还少。不建议通过INT类型类存储一个unix timestamp 的值，因为这太不直观，会给维护带来不必要的麻烦，同时还不会带来任何好处。 ENUM &amp; SET：对于状态字段，可以尝试使用 ENUM 来存放，因为可以极大的降低存储空间，而且即使需要增加新的类型，只要增加于末尾，修改结构也不需要重建表数据。如果是存放可预先定义的属性数据呢?可以尝试使用SET类型，即使存在多种属性，同样可以游刃有余，同时还可以节省不小的存储空间。 LOB类型：强烈反对在数据库中存放 LOB 类型数据，虽然数据库提供了这样的功能，但这不是他所擅长的，我们更应该让合适的工具做他擅长的事情，才能将其发挥到极致。在数据库中存储 LOB 数据就像让一个多年前在学校学过一点Java的营销专业人员来写 Java 代码一样。 2、字符编码 字符集直接决定了数据在MySQL中的存储编码方式，由于同样的内容使用不同字符集表示所占用的空间大小会有较大的差异，所以通过使用合适的字符集，可以帮助我们尽可能减少数据量，进而减少IO操作次数。 纯拉丁字符能表示的内容，没必要选择 latin1 之外的其他字符编码，因为这会节省大量的存储空间。 如果我们可以确定不需要存放多种语言，就没必要非得使用UTF8或者其他UNICODE字符类型，这回造成大量的存储空间浪费。 MySQL的数据类型可以精确到字段，所以当我们需要大型数据库中存放多字节数据的时候，可以通过对不同表不同字段使用不同的数据类型来较大程度减小数据存储量，进而降低 IO 操作次数并提高缓存命中率。 3、适当拆分 有些时候，我们可能会希望将一个完整的对象对应于一张数据库表，这对于应用程序开发来说是很有好的，但是有些时候可能会在性能上带来较大的问题。 当我们的表中存在类似于 TEXT 或者是很大的 VARCHAR类型的大字段的时候，如果我们大部分访问这张表的时候都不需要这个字段，我们就该义无反顾的将其拆分到另外的独立表中，以减少常用数据所占用的存储空间。这样做的一个明显好处就是每个数据块中可以存储的数据条数可以大大增加，既减少物理 IO 次数，也能大大提高内存中的缓存命中率。 上面几点的优化都是为了减少每条记录的存储空间大小，让每个数据库中能够存储更多的记录条数，以达到减少 IO 操作次数，提高缓存命中率。下面这个优化建议可能很多开发人员都会觉得不太理解，因为这是典型的反范式设计，而且也和上面的几点优化建议的目标相违背。 4、适度冗余 为什么我们要冗余?这不是增加了每条数据的大小，减少了每个数据块可存放记录条数吗? 确实，这样做是会增大每条记录的大小，降低每条记录中可存放数据的条数，但是在有些场景下我们仍然还是不得不这样做： 被频繁引用且只能通过 Join 2张(或者更多)大表的方式才能得到的独立小字段。 这样的场景由于每次Join仅仅只是为了取得某个小字段的值，Join到的记录又大，会造成大量不必要的 IO，完全可以通过空间换取时间的方式来优化。不过，冗余的同时需要确保数据的一致性不会遭到破坏，确保更新的同时冗余字段也被更新。 5、表的范式化和反范式化 范式化是指数据库设计的规范，目前说到的范式化一般是指第三设计范式，也就是要求数据表中不存在非关键字段对任意候选关键字段的传递函数依赖则符合第三范式。 反范式化是指为了查询效率的考虑把原本符合第三范式的表适当的增加冗余，以达到优化查询效率的目的，反范式化是一种空间来换取时间的操作。 6、规范的对象名称 数据库和表名尽可能和所服务的业务模块名一致 服务于同意子模块的一类表尽量以子模块为前缀或者后缀 字段名称尽量保持和实际数据响应 索引名称尽量包含所有的检索字段名或者缩写 约束其他对象也应该尽可能包含所属表或者其他对象，以表名各自关系 7、表的垂直拆分 所谓的垂直拆分，就是把原来一个有很多列的表拆分成多个表，这解决了表的宽度问题。通常垂直拆分可以按依稀原则进行： 把不常用的字段单独存放到一个表中 把大字段独立存放到一个表中 把经常一起使用的字段放到一起 8、表的水平拆分 表的水平拆分是为了解决单表的数据量过大的问题（单表达到上亿条），水平拆分的表每个表的结构都是一致的。 常用的水平拆分方法为： 对customer_id进行hash运算，如果要拆分成5个表则使用mode(customer_id, 5)取出0-4个值 针对不同的hashID把数据存到不同的表中 9、尽量使用 NOT NULL NULL 类型比较特殊，SQL 难优化。虽然 MySQL NULL类型和 Oracle 的NULL 有差异，会进入索引中，但如果是一个组合索引，那么这个NULL 类型的字段会极大影响整个索引的效率。此外，NULL 在索引中的处理也是特殊的，也会占用额外的存放空间。 很多人觉得 NULL 会节省一些空间，所以尽量让NULL来达到节省IO的目的，但是大部分时候这会适得其反，虽然空间上可能确实有一定节省，倒是带来了很多其他的优化问题，不但没有将IO量省下来，反而加大了SQL的IO量。所以尽量确保 DEFAULT 值不是 NULL，也是一个很好的表结构设计优化习惯。 10、优化数据库表结构 将字段很多的表分解成多个表 查看表的表结构 优化表结构 1 将字段很多的表分解成多个表 2 增加中间表 3 合理增加冗余字段 4 优化插入记录的速度 禁用索引(在插入数据之前禁用索引，会让创建索引不会生效，命令：alter table 表名 disable keys ，注意表的创建表后加引擎 engine=myisam，可以禁用成功) ![image-20200627201918154](E:\\软件\\博客\\Blog\\blog\\source_posts\\119 mysql优化表结构.assets\\image-20200627201918154.png)","path":"posts/49an.html","date":"06-22","excerpt":"","tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"}]},{"title":"MySQL软件优化","text":"一、软件优化 **MySQL瓶颈优化（业务从小到大的转变） 假设一个网站从最开始访问量很小做到日PV千万，我们来推测一下它的mysql服务器架构演变过程。 ** **第一阶段： 网站访问量日pv量级在1w以下。单台机器跑web和db，不需要做架构层调优（比如，不需要增加memcached缓存）。此时，数据往往都是每日冷备份的，但是有时候如果考虑数据安全性，会搭建一个mysql主从。 ** **第二阶段： 网站访问量日pv达到几万。此时单台机器已经有点负载，需要我们把web和db分开，需要搭建memcached服务作为缓存。也就是说，在这个阶段，我们还可以使用单台机器跑mysql去承担整个网站的数据存储和查询。如果做mysql主从目的也是为了数据安全性。 ** **第三阶段： 网站访问量日pv达到几十万。单台机器虽然也可以支撑，但是需要的机器配置要比之前的机器多好多。如果经费允许，可以购买配置很高的机器来跑mysql服务，但是并不是说，配置翻倍，到了一定阶段配置增加已经不能带来性能的增加。所以，此阶段，我们会想到做mysql服务的集群，也就是说我们可以拿多台机器跑mysql。但mysql的集群和web集群是不一样的，我们需要考虑数据的一致性，所以不能简单套用做web集群的方式。可以做的架构是，mysql主从，一主多从。为了保证架构的强壮和数据完整，主只能是一个，从可以是多个。还有一个问题，我们需要想到，就是在前端web层，我们程序里面指定了mysql机器的ip，那么当mysql机器有多台时，程序里面如何去配置？我们可以拿多台机器跑mysql，其中一台写，其他多台是读，我们只需要把读写的ip分别配置到程序中，程序自动会去区分机器。 ** 第四阶段： 网站访问量日pv到几百万。之前的一主多从模式已经遇到瓶颈，因为当网站访问量变大，读数据库的量也会越来越大，我们需要多加一些从进来，但是从的数量增加到数十台时，由于主需要把bin-log全部分到所以从上，那么这个过程本身就是一件很繁琐读取，势必会造成从上同步过来的数据有很大延迟。所以，我们可以做一个优化，把mysql原来的一主多从为一主一从，然后作为其他从的主，而前面的主，只负责网站业务的写入，而后面的从不负责网站任何业务，只负责给其他从同步bin-log。这样还可以继续多叠加几个从库。 第五阶段： 网站访问量日pv到1千万的时候，我们发现，网站的写入量非常大，我们之前架构中只有一个主，这里的主已经成为瓶颈了。所以，需要再进一步作出调整 解决瓶颈：做索引 查询一些MySQL数据库的性能参数用show status 1234567mysql&gt; SHOW STATUS LIKE &#39;Connections&#39;; &#x2F;&#x2F;连接mysql服务器的次数+---------------+-------+| Variable_name | Value |+---------------+-------+| Connections | 4 |+---------------+-------+1 row in set (0.00 sec) Uptime：mysql服务器的上线时间 1234567mysql&gt; SHOW STATUS LIKE &#39;uptime&#39;;+---------------+----------+| Variable_name | Value |+---------------+----------+| Uptime | 14159453 |+---------------+----------+1 row in set (0.00 sec) Com_select:查询操作的次数 1234567mysql&gt; SHOW STATUS LIKE &#39;com_select&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_select | 7 |+---------------+-------+1 row in set (0.00 sec) Com_insert：插入操作的次数 1234567mysql&gt; SHOW STATUS LIKE &#39;com_insert&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_insert | 3 |+---------------+-------+1 row in set (0.00 sec) Com_update：更新操作的次数 1234567mysql&gt; SHOW STATUS LIKE &#39;com_update&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_update | 0 |+---------------+-------+1 row in set (0.00 sec) Com_delete：删除操作的次数 1234567mysql&gt; SHOW STATUS LIKE &#39;com_delete&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_delete | 0 |+---------------+-------+1 row in set (0.00 sec) Slow_queries：查询mysql服务器的慢查询次数 1234567mysql&gt; SHOW STATUS LIKE &#39;slow_queries&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Slow_queries | 0 |+---------------+-------+1 row in set (0.00 sec) 1、分析查询语句 1Explain [extended] select select_option; 123456789101112131415mysql&gt; explain select * from student\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: student partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL &#x2F;&#x2F;使用哪个列或常数与索引一起使用来查询记录 rows: 13 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) Select_type:表示select语句的类型 其中simple 是简单查询(不包括连接查询和子查询) Primary 主查询 Union 连接查询 Type:表的连接类型 System仅有系统表一行 Const 数据表中最多只有一行匹配，将在查询开始时被读取，并在余下的查询优化中，作为常量 Eq_ref 用于使用 = 操作符比较带索引的列 ref 对于来自前面的表的任意行的组合，从该表中读取所有匹配的行 ref_or_null 同上，添加可以专门搜索包含null值的行 index_merge 将连接类型表示使用了索引并优化方法 range 只检索给定范围的行 index 与all的连接类型相同，除了只扫描索引树 all 前面的表的任意行的组合，进行完整的表的扫描 possible_keys: NULL //指出mysql使用哪个索引在表中找到行 NULL表示没有创建索引 describe select 语句和分析查询语句 123456789101112131415mysql&gt; DESC select * from student\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: student partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 13 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 索引提高了查询效率 Create index 索引名 on 表名(字段) 12345678910111213141516171819202122232425#创建索引，在一定程度.上能够提升sQL的执行效率create index index_student on student (studentNo);mysql&gt; create index index_student on student (studentNo);Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; select * from student;+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+| 10000 | 123 | 郭靖 | 男 | 1 | 13645667783 | 天津市河西区 | 1990-09-08 00:00:00 | NULL | NULL || 10001 | 123 | 李文才 | 男 | 1 | 13645667890 | 地址不详 | 1994-04-12 00:00:00 | NULL | NULL || 10002 | 123 | 李斯文 | 男 | 1 | 13645556793 | 河南洛阳 | 1993-07-23 00:00:00 | NULL | NULL || 10003 | 123 | 张萍 | 女 | 1 | 13642345112 | 地址不详 | 1995-06-10 00:00:00 | NULL | NULL || 10004 | 123 | 韩秋洁 | 女 | 1 | 13812344566 | 北京市海淀区 | 1995-07-15 00:00:00 | NULL | NULL || 10005 | 123 | 张秋丽 | 女 | 1 | 13567893246 | 北京市东城区 | 1994-01-17 00:00:00 | NULL | NULL || 10006 | 123 | 肖梅 | 女 | 1 | 13563456721 | 河北省石家庄市 | 1991-02-17 00:00:00 | NULL | NULL || 10007 | 123 | 秦洋 | 男 | 1 | 13056434411 | 上海市卢湾区 | 1992-04-18 00:00:00 | NULL | NULL || 10008 | 123 | 何睛睛 | 女 | 1 | 13053445221 | 广州市天河区 | 1997-07-23 00:00:00 | NULL | NULL || 20000 | 123 | 王宝宝 | 男 | 2 | 15076552323 | 地址不详 | 1996-06-05 00:00:00 | NULL | NULL || 20010 | 123 | 何小华 | 女 | 2 | 13318877954 | 地址不详 | 1995-09-10 00:00:00 | NULL | NULL || 30011 | 123 | 陈志强 | 男 | 3 | 13689965430 | 地址不详 | 1994-09-27 00:00:00 | NULL | NULL || 30012 | 123 | 李露露 | 女 | 3 | 13685678854 | 地址不详 | 1992-09-27 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+13 rows in set (0.00 sec) 优化查询速度 注意： 1做索引了之后，用 like ‘xx%’ %不在第一位查询效率最高 1234select * from student where studentName&#x3D;&#39;李文才&#39;;select * from student where studentName like &#39;%文&#39;;select * from student where studentName like &#39;文%&#39;;select * from student where studentName like &#39;%文%&#39;; 2、多字段索引，除了第一字段查询最快，其余不按索引来，索引不生效 12345678910111213141516171819mysql&gt; CREATE INDEX index_id_price ON student(sex);Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; explain select * from student where sex&#x3D;&#39;2&#39;\\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: student partitions: NULL type: refpossible_keys: index_id_price key: index_id_price key_len: 6 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 3、若创建索引所设置的字段，查询索引组合 or 左右边的值都是属于索引设置字段下的值 123456789101112131415mysql&gt; EXPLAIN SELECT * FROM student where studentName&#x3D;&#39;何小华&#39; or sex&#x3D;2\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: student partitions: NULL type: ALLpossible_keys: index_id_price key: NULL key_len: NULL ref: NULL rows: 13 filtered: 19.00 Extra: Using where1 row in set, 2 warnings (0.00 sec) profiling分析查询 通过慢日志查询可以知道哪些SQL语句执行效率低下，通过explain我们可以得知SQL语句的具体执行情况，索引使用等，还可以结合show命令查看执行状态。如果觉得explain的信息不够详细，可以同通过profiling命令得到更准确的SQL执行消耗系统资源的信息。 profiling默认是关闭的。可以通过以下语句查看 12345678910111213141516mysql&gt; show variables like &#39;%profiling%&#39;; &#x2F;&#x2F;off表示未开启+------------------------+-------+| Variable_name | Value |+------------------------+-------+| have_profiling | YES || profiling | OFF || profiling_history_size | 15 |+------------------------+-------+3 rows in set, 1 warning (0.00 sec)mysql&gt; select @@profiling; &#x2F;&#x2F;0表示未开启+-------------+| @@profiling |+-------------+| 0 |+-------------+1 row in set, 1 warning (0.00 sec) 打开profiling功能： mysql&gt;set profiling=1; 执行需要测试的sql 语句： 12345678910mysql&gt; set profiling&#x3D;1;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; select @@profiling;+-------------+| @@profiling |+-------------+| 1 |+-------------+1 row in set, 1 warning (0.00 sec) 执行要测试的sql语句 1234567891011121314151617181920212223242526272829303132333435mysql&gt; select * from student where studentName&#x3D;&#39;郭靖&#39;;+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+| 10000 | 123 | 郭靖 | 男 | 1 | 13645667783 | 天津市河西区 | 1990-09-08 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+1 row in set (0.00 sec)mysql&gt; show profiles;+----------+------------+--------------------------------------------------+| Query_ID | Duration | Query |+----------+------------+--------------------------------------------------+| 1 | 0.00011150 | select @@profiling || 2 | 0.00015925 | select * from student where f_name&#x3D;&#39;studentName&#39; || 3 | 0.00013125 | select * from student where f_name&#x3D;&#39;studentName&#39; || 4 | 0.00033975 | select * from student where studentName&#x3D;&#39;&#39; || 5 | 0.00027950 | select * from student where studentName&#x3D;&#39;????&#39; |+----------+------------+--------------------------------------------------+5 rows in set, 1 warning (0.00 sec)mysql&gt; show profile for query 2;+----------------------+----------+| Status | Duration |+----------------------+----------+| starting | 0.000050 || checking permissions | 0.000005 || Opening tables | 0.000011 || init | 0.000034 || end | 0.000003 || query end | 0.000003 || closing tables | 0.000005 || freeing items | 0.000037 || cleaning up | 0.000012 |+----------------------+----------+9 rows in set, 1 warning (0.00 sec) status:是profile里的状态，duration：是status状态下的耗时。因此我们关注的就是那个状态最耗时，这些状态中那些可以优化。 当然也可以查看更多的信息如CPU等等 12345678SHOW PROFILE [type [, type] ... ][FOR QUERY n] type: ALL:显示所有的开销信息 BLOCK IO:显示块IO相关开销 CPU:显示用户CPU时间、系统CPU时间 IPC:显示发送和接收相关开销信息PAGE FAULTS:显示页面错误相关开销信息 SWAPS:显示交换次数相关开销的信息 测试完成之以后，记得要关闭调试功能，以免影响数据库的正常使用： 1mysql&gt; set profiling&#x3D;0; 优化数据库表结构 将字段很多的表分解成多个表 查看表的表结构 **优化表结构 1 将字段很多的表分解成多个表 2 增加中间表 3 合理增加冗余字段 4 优化插入记录的速度 ** （1），禁用索引(在插入数据之前禁用索引，会让创建索引不会生效，命令：alter table 表名 disable keys ，注意表的创建表后加引擎 engine=myisam，可以禁用成功) 12mysql&gt; ALTER TABLE fruits DISABLE KEYS;Query OK, 0 rows affected, 1 warning (0.05 sec) (2)，禁用唯一性检查(插入记录之前禁用唯一性检查，命令：set unique_checks=0 关闭set unique_checks=1) 12mysql&gt; set unique_checks&#x3D;0;Query OK, 0 rows affected (0.00 sec) （3）使用批量插入(多条插入命令整合成一条命令) 1234567891011121314151617mysql&gt; INSERT INTO fruits values(&#39;x1&#39;,&#39;101&#39;,&#39;mongo2&#39;,&#39;5.5&#39;);Query OK, 1 row affected (0.00 sec)mysql&gt; INSERT INTO fruits values(&#39;x2&#39;,&#39;101&#39;,&#39;mongo2&#39;,&#39;5.5&#39;);Query OK, 1 row affected (0.08 sec)mysql&gt; INSERT INTO fruits values(&#39;x3&#39;,&#39;101&#39;,&#39;mongo2&#39;,&#39;5.5&#39;);Query OK, 1 row affected (0.01 sec)mysql&gt; INSERT INTO fruits values(&#39;x4&#39;,&#39;101&#39;,&#39;mongo2&#39;,&#39;5.5&#39;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into fruits values (&#39;x8&#39;,&#39;101&#39;,&#39;mongo2&#39;,&#39;5.5&#39;),(&#39;x7&#39;,&#39;101&#39;,&#39;mongo2&#39;,&#39;5.5&#39;), (&#39;x6&#39;,&#39;101&#39;,&#39;mongo2&#39;,&#39;5.5&#39;),(&#39;x5&#39;,&#39;101&#39;,&#39;mongo2&#39;,&#39;5.5&#39;);Query OK, 4 rows affected (0.07 sec)Records: 4 Duplicates: 0 Warnings: 0 (4)使用load data infile批量插入 对于innnodb表来说 (1) 禁用唯一性检查 12mysql&gt; SET unique_checks&#x3D;0;Query OK, 0 rows affected (0.00 sec) (5) 禁用外键检查(命令: set foreign_key_checks=0，开启=1) 12mysql&gt; SET foreign_key_checks&#x3D;0;Query OK, 0 rows affected (0.00 sec) (6) 禁用自动提交(命令: set autocommit=0，开启=1) 12mysql&gt; set autocommit&#x3D;0;Query OK, 0 rows affected (0.00 sec) 4、分析表，检查表和优化表 分析表：分析关键字的分布 检查表：检查是否存在错误 优化表：消除删除或更新造成的空间浪费 分析表语句：analyze [local |no_wirte_to_binlog] table tb1_name[tb2_name]….. Local的关键字不写入二进制日志 后跟1个表或多个表 在分析期间只能读，不能进行插入和更新的操作。 1234567mysql&gt; ANALYZE TABLE fruits;+-------------+---------+----------+----------+| Table | Op | Msg_type | Msg_text |+-------------+---------+----------+----------+| test.fruits | analyze | status | OK |+-------------+---------+----------+----------+1 row in set (0.07 sec) Table是表名 op执行的操作是什么 msg_type 信息级别（status是正常状态，info是信息，note注意，warning警告，error错误） msg_text 是显示信息 检查表：检查是否存在错误,关键字统计，检查视图是否有错误 Check table 表名 option ={quick |fast | medium|extended |changed} Quick 不扫描行，不检查错误连接 Fast 只检查没有被正确关闭的表 Medium 扫描行验证被删除的连接是有效的，也可以计算各行的关键字校验和。 Extended 对每行所有关键字进行全面的关键字查找Changed 只检查上次检查后被更改的表和没有被正确关闭的表 Option只对myisam 有效 对innodb表无效 在执行时会给表加上只读锁 1234567mysql&gt; CHECK TABLE fruits ;+-------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+-------------+-------+----------+----------+| test.fruits | check | status | OK |+-------------+-------+----------+----------+1 row in set (0.00 sec) 优化表：消除删除或更新造成的空间浪费 Optimize [local |no_write_to_binlog] table tb1_name …. 只能优化myisam的表和innodb的表都有效 但是只能优化表中的varchar\\text\\blob 执行过程中上只读锁 123456789101112mysql&gt; optimize table fruits\\G*************************** 1. row ***************************Table: test.fruitsOp: optimizeMsg_type: noteMsg_text: Table does not support optimize, doing recreate + analyze instead*************************** 2. row ***************************Table: test.fruitsOp: optimizeMsg_type: statusMsg_text: OK2 rows in set (0.12 sec)","path":"posts/49c6.html","date":"06-21","excerpt":"","tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"}]},{"title":"MySQL之my.cnf配置文件优化","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198[client]port &#x3D; 3306socket &#x3D; &#x2F;tmp&#x2F;mysql.sockdefault-character-set &#x3D; utf8[mysql]no-auto-rehash #仅允许使用键值的updates和deletes[mysqld]port &#x3D; 3306 #msyql服务器端口号basedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql #mysql安装目录datadir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data #mysql数据存放目录#datadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;data #同上socket &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql.sock #sock文件 #字符集与校对规则character-set-server &#x3D; utf8 #默认字符集collation-server &#x3D; utf8_general_ci #设置校对规则 external-locking &#x3D; FALSE #避免外部锁定(减少出错几率，增加稳定性)skip-name-resolv #禁止外部连接进行DNS解析skip-slave-start # 复制进程就不会随着数据库的启动而启动 http:&#x2F;&#x2F;blog.csdn.net&#x2F;aeolus_pu&#x2F;article&#x2F;details&#x2F;9419965 #master库binlog参数相关server-id &#x3D; 1 #主从复制时，ID不能相同#binlog_format &#x3D; mixed #二进制日志格式（mixed、row、statement）binlog-cache-size &#x3D; 32M #设置二进制日志缓存大小sync-binlog &#x3D; 1 #每隔N秒将缓存中的二进制日志记录写回硬盘max_binlog_cache_size &#x3D; 8M #最大的二进制Cache日志缓冲尺寸max_binlog_size &#x3D; 1G #单个二进制日志文件的最大值，默认1G，最大1Glog-bin-index &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql-bin.index #binlog索引文件位置log-bin &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql-bin #binlog日志存放目录expire_logs_days &#x3D; 90 #二进制日志文件过期时间#slave数据库binlog参数server-id &#x3D; 10 #各数据库id不能相同log_slave_updates &#x3D; 1 #级联也使用relay-log &#x3D; &#x2F;usr&#x2F;lcoal&#x2F;mysql&#x2F;data&#x2F;relay-bin #relady目录relay-log-info-file &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;relay-log.info #info目录slave-skip-errors &#x3D; 1007,1008,1032,1062 #跳过主从复制时的错误read-only &#x3D; 1 #从服务器只读,SQL线程不影响，具有super，root用户不限制master-connect-retry &#x3D; 60 #主从复制丢失，重连间隔时间，默认60s#replicate-ignore-db &#x3D; mysql #忽略mysql库不同步replicate-wild-do-table&#x3D;testdb1.%replicate-wild-do-table&#x3D;testdb2.%replicate-wild-do-table&#x3D;testdb3.%#master半同步开启参数rpl_semi_sync_master_enabled &#x3D; ONrpl_semi_sync_master_timeout &#x3D; 10000#rpl_semi_sync_master_wait_no_slave &#x3D; ON#rpl_semi_sync_master_trace_level &#x3D; 32#slave半同步开启参数rpl_semi_sync_slave_enabled &#x3D; ON#rpl_semi_sync_slave_trace_level &#x3D; 32 back_log &#x3D; 1000 #指出在MySQL暂时停止响应新请求之前，短时间内的多少个请求open_files_limit &#x3D; 1024 #打开文件的最大个数，如果出现too mantopen files之类的就需要调整该值了 #连接相关max_connections &#x3D; 2000 #指定MySQL允许的最大连接进程数，show global variables like &#39;%connections%&#39;; http:&#x2F;&#x2F;elf8848.iteye.com&#x2F;blog&#x2F;1847445 max_user_connections &#x3D; 2000 #单用户最大的连接数，max_user_connections &lt; 实例 max_user_connections &lt; max_connectionsmax_connect_errors &#x3D; 100000 #默认为10，设置每个主机的连接请求异常中断的最大次数，超过后会blocked，连接成功后初始0，出现错误后需要flush hosts max_allowed_packet &#x3D; 8M #服务器一次能处理的最大的查询包的值wait_timeout &#x3D; 360 #指定一个请求的最大连接时间interactive_timeout &#x3D; 360 #连接保持活动的时间#访问日志#general_log &#x3D; on#general_log_file &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql_access.log #错误日志log_error &#x3D; &#x2F;data&#x2F;mysql&#x2F;data&#x2F;mysql_error.log#慢查询相关参数slow_query_log &#x3D; on #开启慢查询log-queries-not-using-indexes #记录所有没有使用到索引的查询语句long_query_time &#x3D; 2 #指定多少秒未返回结果的查询属于慢查询min_examined_row_limit &#x3D; 5 #记录那些由于查找了多余5次而引发的慢查询log-slow-admin-statements #记录那些慢的OPTIMIZE TABLE,ANALYZE TABLE和ALTER TABLE语句log-slow-slave-statements #记录由slave所产生的慢查询slow_query_log_file &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;slow.log #指定慢查询日志文件路径table_cache &#x3D; 614 #表分配的内存，物理内存越大，设置就越大table_open_cache &#x3D; 512 #设置高速缓存表的数目thread_cache_size &#x3D; 64 #服务器线程缓存数，与内存大小有关(建议大于3G设置为64)thread_concurrency &#x3D; 32 #CPU核数的两倍query_cache_size &#x3D; 32M #指定MySQL查询缓冲区的大小query_cache_limit &#x3D; 2M #只有小于此设置值的结果才会被缓存query_cache_min_res_unit &#x3D; 2k #设置查询缓存分配内存的最小单位key_buffer_size &#x3D; 512M #指定用于索引的缓冲区大小，增加它可得到更好的索引处理性能sort_buffer_size &#x3D; 2M #设置查询排序时所能使用的缓冲区大小，系统默认大小为2MBjoin_buffer_size &#x3D; 1M #联合查询操作所能使用的缓冲区大小read_buffer_size &#x3D; 4M #读查询操作所能使用的缓冲区大小read_rnd_buffer_size &#x3D; 16M #设置进行随机读的时候所使用的缓冲区thread_stack &#x3D; 192K #设置Mysql每个线程的堆栈大小，默认值足够大，可满足普通操作bulk_insert_buffer_size &#x3D; 8M #可以适当调整参数至16MB~32MB，建议8MB#myisam参数引擎相关myisam_sort_buffer_size &#x3D; 128Mmyisam_max_sort_file_size &#x3D; 10Gmyisam_repair_threads &#x3D; 1myisam_recover #自动检查和修复没有适当关闭的MyISAM表key_buffer_size &#x3D; 16M #myisam索引buffer，只有key没有data transaction_isolation &#x3D; READ-COMMITTED #事务隔离级别tmp_table_size &#x3D; 64M #设置内存临时表最大值max_heap_table_size &#x3D; 64M #独立的内存表所允许的最大容量#innodb引擎参数相关default-storage-engine&#x3D;InnoDB #默认表的类型为InnoDBinnodb_old_blocks_time &#x3D;1000 #减小单次的大批量数据查询,默认为0，调整后性能提升80% http:&#x2F;&#x2F;www.cnblogs.com&#x2F;cenalulu&#x2F;archive&#x2F;2012&#x2F;10&#x2F;10&#x2F;2718585.html innodb_flush_method &#x3D; O_DIRECT #从innode刷新到磁盘，不经过系统write,fdatasync(默认)，O_DSYNC，O_DIRECT http:&#x2F;&#x2F;blog.csdn.net&#x2F;jiao_fuyou&#x2F;article&#x2F;details&#x2F;16113403 innodb_additional_mem_pool_size &#x3D; 16M #设置InnoDB存储的数据目录信息和其他内部数据结构的内存池大小innodb_buffer_pool_size &#x3D; 51G #InnoDB使用一个缓冲池来保存索引和原始数据，官方建议物理内存的80%innodb_data_file_path &#x3D; ibdata1:128M:autoextend #表空间innodb_file_io_threads &#x3D; 4 #InnoDB中的文件I&#x2F;O线程，通常设置为4，innodb除master线程外，还有insert buffer, log, read, write这4种线程，默认各有一个innodb_read_io_threads &#x3D; 8innodb_write_io_threads &#x3D; 8innodb_thread_concurrency &#x3D; 8 #服务器有几个CPU就设置为几，建议用默认设置，一般设为8innodb_flush_log_at_trx_commit &#x3D; 2 #设置为0就等于innodb_log_buffer_size队列满后再统一存储，默认为1innodb_log_buffer_size &#x3D; 16M #默认为1MB，通常设置为6-8MB就足够innodb_log_file_size &#x3D; 512M #确定日志文件的大小，更大的设置可以提高性能，但也会增加恢复数据库的时间innodb_log_files_in_group &#x3D; 3 #为提高性能，MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3innodb_max_dirty_pages_pct &#x3D; 90 #InnoDB主线程刷新缓存池中的数据innodb_lock_wait_timeout &#x3D; 120 #InnoDB事务被回滚之前可以等待一个锁定的超时秒数innodb_file_per_table &#x3D; 1 #InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间,0关闭,1开启innodb_autoextend_increment &#x3D; 256 #这个参数的作用是控制innodb 共享表空间文件自动扩展的大小[mysqldump]quickmax_allowed_packet &#x3D; 64M[mysqld_safe]log-error &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql.errpid-file &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysqld.pid 查询innodb分配资源mysql&gt; show engine innodb status;----------------------BUFFER POOL AND MEMORY----------------------Total memory allocated 137363456; in additional pool allocated 0Dictionary memory allocated 59957Buffer pool size 8191Free buffers 8028Database pages 163Old database pages 0Modified db pages 0Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages made young 0, not young 00.00 youngs&#x2F;s, 0.00 non-youngs&#x2F;sPages read 163, created 0, written 10.00 reads&#x2F;s, 0.00 creates&#x2F;s, 0.00 writes&#x2F;sNo buffer pool page gets since the last printoutPages read ahead 0.00&#x2F;s, evicted without access 0.00&#x2F;s, Random read ahead 0.00&#x2F;sLRU len: 163, unzip_LRU len: 0I&#x2F;O sum[0]:cur[0], unzip sum[0]:cur[0] 我们使用的是专用于MySQL的（5.5 Percona的）上运行CentOS的（不同口味），主要128GB的服务器。我们innodb_buffer_pool_size设置为104GB这些和他们也有&#x2F; tmp目录8GB的内存磁盘。他们被大量使用，但从未使用过任何的交换。当然vm.swappiness设置为1，下面就是我们用较低层的服务器（包括128GB为简洁起见），他们又从来没有使用过任何掉期和运行大型数据库（2-3TB）：128GB RAM：innodb_buffer_pool_size &#x3D; 104GB64GB RAM：innodb_buffer_pool_size &#x3D; 56G32GB RAM：innodb_buffer_pool_size &#x3D; 28G 在大多数情况下，我们分配（N - 7G）* 0.9。所以对于一个64G的节点，我们最终分配给缓冲池内存〜51G64GB RAM：innodb_buffer_pool_size &#x3D; 51G https:&#x2F;&#x2F;www.percona.com&#x2F;blog&#x2F;2015&#x2F;06&#x2F;02&#x2F;80-ram-tune-innodb_buffer_pool_size&#x2F; http:&#x2F;&#x2F;osxr.org:8080&#x2F;mysql&#x2F;ident?_i&#x3D;back_log&amp;_remember&#x3D;1 王导DBA MySQL优化log_error &#x3D; localhost3306.errsync_binlog&#x3D;1innodb_old_blocks_time &#x3D;1000innodb_flush_method &#x3D; O_DIRECTback_log&#x3D;1000max_connections &#x3D; 2000max_user_connections&#x3D;2000min_examined_row_limit &#x3D;5skip-slave-startskip-name-resolvemax_connect_errors &#x3D; 100000character-set-server&#x3D;utf8collation-server&#x3D;utf8_binbinlog_cache_size&#x3D;32Mquery_cache_limit &#x3D; 2Mtmp_table_size&#x3D;256Mmax_heap_table_size&#x3D;256Minteractive_timeout&#x3D;360wait_timeout&#x3D;360log_slave_updates&#x3D;1expire_logs_days&#x3D;60binlog_format&#x3D;mixedtmpdir&#x3D;&#x2F;dev&#x2F;shminnodb_autoextend_increment &#x3D; 256innodb_buffer_pool_instances&#x3D;8innodb_additional_mem_pool_size&#x3D;128Minnodb_max_dirty_pages_pct&#x3D;80innodb_read_io_threads &#x3D; 8innodb_write_io_threads &#x3D; 8innodb_log_file_size &#x3D; 1Ginnodb_log_files_in_group &#x3D; 2innodb_flush_log_at_trx_commit &#x3D; 2innodb_file_per_table&#x3D;1","path":"posts/49ca.html","date":"06-20","excerpt":"","tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"}]},{"title":"MySQL配置参数优化","text":"一、配置参数优化 MySQL参数优化对于不同的网站，与其在线量、访问量、帖子数量、网络情况,以及机器硬件配置都有关系,优化不可能一-次性完成， 需要不断的观察以及调试，才有可能得到最佳效果。下面列出了 对性能优化影响较大的主要变量，主要分为连接请求的变星和缓冲区变星。 1、连接请求的变量 （1）max_connections MySQL的最大连接数，如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当 然这建立在机器能支撑的情况下，因为如果连接数越多，MySQL会 为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。数值过 小会经常出现ERROR 1040: Too many connections错误，可以通过mysql&gt; show status like 'connections';通配符查看当前状态的连接数量(试图连接到MySQL(不管是否连接成功)的连接数)，以定夺该值的大小。 123456789101112131415mysql&gt;show variables like &#39;max_connections&#39;; #最大连接数+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 151 |+-----------------+-------+1 row in set (0.00 sec)mysql&gt;show status like &#39;max_used_connections&#39;; #响应的连接数+----------------------+-------+| Variable_name | Value |+----------------------+-------+| Max_used_connections | 1 |+----------------------+-------+1 row in set (0.00 sec) rnax_used_connections / max_connections * 100% (理想值≈85%)如果max_used_connections跟max_connections相同那么就是max_connections设 置过低或者超过服务器负载上限了，低于10%则设置过大。如何设置max_connections? 修改/etc/my.cnf文件，在[mysqld]下面添加如下内容， 如设置最大连接数为1024 1max_connections &#x3D; 1024 重启mysq|服务 2、back _log MySQL能暂存的连接数量。 当主要MySQL线程在一个很短时间内得到非常多的连接请求，它就会起作用。如果MySQL的连接数据达到max. connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back Jlog, 如果等待连接的数量超过back _log,将不被授予连接资源。back_log值指出在MySQL暂时停止回答新请求之前的短时间内有多少个请求可以被存在堆栈中。只有如果期望在一个短时间内有很多连接，你需要增加它。当观察你主机进程列表(mysql&gt; show full processlist)，发现大量xxxxx | unauthenticated user | x | xxx.xxx.xxx.xxx I NULL I Connect | NULL I login | NULL的待连接进程时，就要加大back. log的值了或加大max_connections的值。通过 123456789101112131415mysql&gt; show full processlist;+----+------+-----------+------+---------+------+----------+----| Id | User | Host | db | Command | Time | State | Inf+----+------+-----------+------+---------+------+----------+----| 2 | root | localhost | NULL | Query | 0 | starting | sho+----+------+-----------+------+---------+------+----------+----1 row in set (0.00 sec)mysql&gt; show variables like &#39;back_log&#39;; #查看back_log的设置+---------------+-------+| Variable_name | Value |+---------------+-------+| back_log | 80 |+---------------+-------+1 row in set (0.00 sec) 如何设置back_log? 修改/etc/my.cnf文件，在[mysqld]下面添加如下内容，如设置最大连接数为1024 1back_log &#x3D; 数值 重启mysql服务，查看一下 1234567mysql&gt; show variables like &#39;back_log&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| back_log | 1024 |+---------------+-------+1 row in set (0.00 sec) 3、wait_timeout和interactive_timeout wait_ftimeout wait_timeout和interactive_timeout wait_ftimeout – 指的是MySQL在关闭一个非交互的连接之前所要等待的秒数interactive. time – 指的是mysq|在关闭一个交互的连接之前所要等待的秒数，比如我们在终端上进入mysq|管理，使用的即使交互的连接，这时候，如果没有操作的时间超过了interactive_timne设置的时间就会自动断开。默认数值是28800，可调优为7200。对性能的影响: wait_timeout: (1) 如果设置大小，那么连接关闭的很快，从而使一些持久的连接不起作用 (2) 如果设置太大，容易造成连接打开时间过长，在show processlist时，能看到太多的sleep状态的连接，从而造成too many connections错误 (3)一般希望wait_timeout尽可能地低interactive_timeout的设置将要对你的web application没有多大 的影响查看wait_timeout和interactive_timeout 12345678910111213141516171819mysql&gt; show variables like &#39;%wait_timeout%&#39;;+--------------------------+----------+| Variable_name | Value |+--------------------------+----------+| innodb_lock_wait_timeout | 50 || lock_wait_timeout | 31536000 || wait_timeout | 28800 |+--------------------------+----------+3 rows in set (0.01 sec)mysql&gt; show variables like &#39;%interactive_timeout%&#39;;+---------------------+-------+| Variable_name | Value |+---------------------+-------+| interactive_timeout | 28800 |+---------------------+-------+1 row in set (0.01 sec)set global interactive_timeout&#x3D;7200; 如何设置wait_timeout和linteractive_timeout?修改/etc/my.cnf文件，在[mysqld]下 面添加如下内容 12wait_timeout&#x3D;100interactive_timeout&#x3D;100 重启一下mysql，查看一下 1234567891011121314151617mysql&gt; show variables like &#39;%wait_timeout%&#39;;+--------------------------+----------+| Variable_name | Value |+--------------------------+----------+| innodb_lock_wait_timeout | 50 || lock_wait_timeout | 31536000 || wait_timeout | 100 |+--------------------------+----------+3 rows in set (0.00 sec)mysql&gt; show variables like &#39;%interactive_timeout%&#39;;+---------------------+-------+| Variable_name | Value |+---------------------+-------+| interactive_timeout | 100 |+---------------------+-------+1 row in set (0.00 sec) （2）缓冲区变量 全局缓冲： 4、key_buffer_size key_buffer_size指定索引缓冲区的大小，它决定索引处理的速度，尤其是索引读的速度。通过检查状态值Key_read_requests和Key_reads，可以知道key_buffer_size设置是否合理。比例key_reads/ key_read_requests应该尽可能的低，至少是1:100，1:1000更好（上述状态值可以使用SHOW STATUS LIKE ‘key_read%’获得）。 一共有6个索引读取请求，有3个请求在内存中没有找到直接从硬盘读取索引，计算索引未命中缓存的概率： key_cache_miss_rate ＝ Key_reads / Key_read_requests * 100% =50% key_buffer_size只对MyISAM表起作用。即使你不使用MyISAM表，但是内部的临时磁盘表是MyISAM表，也要使用该值。可以使用检查状态值created_tmp_disk_tables得知详情。 如何调整key_buffer_size 默认配置数值是8388608(8M)，主机有4GB内存，可以调优值为268435456(256MB) 修改/etc/my.cnf文件，在[mysqld]下面添加如下内容 1key_buffer_size&#x3D;268435456或key_buffer_size&#x3D;256M 重启MySQL Server进入后，查看设置已经生效。 5、query_cache_size(查询缓存简称QC) query_cache_size(查询缓存简称QC) 使用查询缓冲，MySQL将查询结果存放在缓冲区中，今后对于同样的SELECT语句（区分大小写），将直接从缓冲区中读取结果。 一个SQL查询如果以select开头，那么MySQL服务器将尝试对其使用查询缓存。 注：两个SQL语句，只要相差哪怕是一个字符（例如大小写不一样；多一个空格等），那么这两个SQL 将使用不同的一个CACHE。 通过检查状态值’Qcache%’，可以知道query_cache_size设置是否合理（上述状态值可以使用SHOW STATUS LIKE ‘Qcache%’获得）。 **Qcache_free_blocks：缓存中相邻内存块的个数。如果该值显示较大，则说明Query Cache 中的内存碎片较多了，FLUSH QUERY CACHE会对缓存中的碎片进行整理，从而得到一个空闲块。 ** **注：当一个表被更新之后，和它相关的cache blocks将被free。但是这个block依然可能存在队列中，除非是在队列的尾部。可以用FLUSH QUERY CACHE语句来清空free blocks Qcache_free_memory：Query Cache 中目前剩余的内存大小。通过这个参数我们可以较为准确的观察出当前系统中的Query Cache 内存大小是否足够，是需要增加还是过多了。 ** **Qcache_hits：表示有多少次命中缓存。我们主要可以通过该值来验证我们的查询缓存的效果。数字越大， 缓存效果越理想。 ** Qcache_inserts：表示多少次未命中然后插入，意思是新来的SQL请求在缓存中未找到，不 得不执行查询处理，执行查询处理后把结果insert到查询缓存中。这样的情况的次数越多，表示查询缓存应用到的比较少，效果也就不理想。当然系统刚启动后，查询缓存是空的，这很正常。 **Qcache_lowmem_prunes：多少条Query 因为内存不足而被清除出Query Cache过“Qcache_lowmem_prunes”和“Qcache_free_memory”相互结合，能够更清楚的了解到我们系统中Query Cache 的内存大小是否真的足够，是否非常频繁的出现因为内存不足而有Query 被换出。这个数字最好长时间来看；如果这个数字在不断增长，就表示可能碎片非常严重，或者内存很少。（上面的free_blocks和free_memory可以告诉您属于哪种情况） ** Qcache_not_cached：不适合进行缓存的查询的数量，通常是由于这些查询不是 SELECT 语句或者用了now()之类的函数。 Qcache_queries_in_cache：当前Query Cache 中cache 的Query 数量； Qcache_total_blocks：当前QueryCache 中的block 数量；我们再查询一下服务器关于query_cache的配置： 123456789101112131415161718192021222324252627mysql&gt; show status like &#39;%Qcache%&#39;;+-------------------------+---------+| Variable_name | Value |+-------------------------+---------+| Qcache_free_blocks | 1 || Qcache_free_memory | 1031832 || Qcache_hits | 0 || Qcache_inserts | 0 || Qcache_lowmem_prunes | 0 || Qcache_not_cached | 0 || Qcache_queries_in_cache | 0 || Qcache_total_blocks | 1 |+-------------------------+---------+8 rows in set (0.00 sec)mysql&gt; show variables like &#39;%query_cache%&#39;;+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| have_query_cache | YES || query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 || query_cache_type | OFF || query_cache_wlock_invalidate | OFF |+------------------------------+---------+6 rows in set (0.00 sec) 上图可以看出query_cache_type为off表示不缓存任何查询 各字段的解释： query_cache_limit：超过此大小的查询将不缓存 **query_cache_min_res_unit：缓存块的最小大小 ，query_cache_min_res_unit的配置是一柄”双刃剑”，默认是4KB，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费。 ** **query_cache_size：查询缓存大小 (注：QC存储的最小单位是1024 byte，所以如果你设定了一个不是1024的倍数的值，这个值会被四舍五入到最接近当前值的等于1024的倍数的值。) ** query_cache_type：缓存类型，决定缓存什么样的查询，注意这个值不能随便设置，必须设置为数字，可选项目以及说明如下： query_cache_type三个参数的含义: query_cache_type=0（OFF）关闭 query_cache_type=1（ON）缓存所有结果，除非select语句使用SQL_NO_CACHE禁用查询缓存 query_cache_type=2(DEMAND)，只缓存select语句中通过SQL_CACHE指定需要缓存的查询 如果设置为0，那么可以说，你的缓存根本就没有用，相当于禁用了。 如果设置为1，将会缓存所有的结果，除非你的select语句使用SQL_NO_CACHE禁用了查询缓存。 如果设置为2，则只缓存在select语句中通过 SQL_CACHE指定需要缓存的查询。 query_cache_wlock_invalidate：当有其他客户端正在对MyISAM表进行写操作时，如果查询在query cache中，是否返回cache结果还是等写操作完成再读表获取结果。 修改/etc/my.cnf,配置完后的部分文件如下： query_cache_size=256M query_cache_type=1 保存文件，重新启动MYSQL服务，然后通过如下查询来验证是否真正开启了： 查询缓存碎片率 = Qcache_free_blocks / Qcache_total_blocks * 100% 如果查询缓存碎片率超过20%，可以用FLUSH QUERY CACHE整理缓存碎片，或者试试减小query_cache_min_res_unit，如果你的查询都是小数据量的话。 查询缓存利用率 = (query_cache_size – Qcache_free_memory) / query_cache_size * 100% 查询缓存利用率在25%以下的话说明query_cache_size设置的过大，可适当减小；查询缓存利用率在80％以上而且 Qcache_lowmem_prunes &gt; 50的话说明query_cache_size可能有点小，要不就是碎片太多。 查询缓存命中率 =Qcache_hits/(Qcache_hits +Qcache_inserts) * 100% Query Cache 的限制 a) 所有子查询中的外部查询SQL 不能被Cache； b) 在Procedure，Function 以及Trigger 中的Query 不能被Cache； c) 包含其他很多每次执行可能得到不一样结果的函数的Query不能被Cache。 鉴于上面的这些限制，在使用Query Cache 的过程中，建议通过精确设置的方式来使用，仅仅让合适的表的数据可以进入Query Cache，仅仅让某些Query的查询结果被Cache。 如何设置query_cache_size？ 修改/etc/my.cnf文件，在[mysqld]下面添加如下内容 12query_cache_size&#x3D;256Mquery_cache_type&#x3D;1 重启MySQL Server进入后，查看设置已经生效。 6、max_connect_errors max_connect_errors是一个MySQL中与安全有关的计数器值，它负责阻止过多尝试失败的客户端以防止暴力破解密码的情况,当超过指定次数，MYSQL服务器将禁止host的连接请求，直到mysql服务器重启或 通过flush hosts命令清空此host的相关信息。max_connect_errors的值与性能并无太大关系。 修改/etc/my.cnf文件，在[mysqld]下面添加如下内容 max_connect_errors=20 重启MySQL Server进入后，查看设置已经生效。 7、sort_buffer_size **sort_buffer_size 每个需要进行排序的线程分配该大小的一个缓冲区。增加这值加速ORDER BY或GROUPBY操作。 Sort_Buffer_Size 是一个connection级参数，在每个connection（session）第一次需要使用这个buffer的时候，一次性分配设置的内存。 Sort_Buffer_Size 并不是越大越好，由于是connection级的参数，过大的设置+高并发可能会耗尽系统内存资源。例如：500个连接将会消 耗 500*sort_buffer_size(2M)=1G内存 例如设置sort_buffer_size 修改/etc/my.cnf文件，在[mysqld]下面添加如下内容 sort_buffer_size = 2M 重启MySQL Server进入后，查看设置已经生效。 ** 8、max_allowed_packet = 32M max_allowed_packet = 32M MySQL根据配置文件会限制Server接受的数据包大小。有时候大的插入和更新会受 max_allowed_packet 参数限制，导致写入或者更新失败。最大值是1GB，必须设置1024的倍数。 9、join_buffer_size = 2M join_buffer_size = 2M 用于表间关联缓存的大小，和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。 10、thread_cache_size = 300 thread_cache_size = 300服务器线程缓存，这个值表示可以重新利用保存在缓存中线程的数量,当断开连接时,那么客户端的线程将被放到缓存中以响应下一个客户而不是销毁(前提是缓存数未达上限),如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，那么这个线程将被重新创建,如果有很多新的线程，增加这个值可以改善系统性能.通过比较 Connections 和 Threads_created 状态的变量，可以看到这个变量的作用。设置规则如下：1GB 内存配置为8，2GB配置为16，3GB配置为32，4GB或更高内存，可配置更大。服务器处理此客户的线程将会缓存起来以响应下一个客户而不是销毁(前提是缓存数未达上限) 试图连接到MySQL(不管是否连接成功)的连接数 Threads_cached :代表当前此时此刻线程缓存中有多少空闲线程。 Threads_connected :代表当前已建立连接的数量，因为一个连接就需要一个线程，所以也可以看成当前被使用的线程数。 Threads_created :代表从最近一次服务启动，已创建线程的数量，如果发现Threads_created值过大的话，表明MySQL服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中thread_cache_size值。 Threads_running :代表当前激活的（非睡眠状态）线程数。并不是代表正在使用的线程数，有时候连接已建立，但是连接处于sleep状态。 3）配置InnoDB的几个变量 （1）innodb_buffer_pool_size 对于InnoDB表来说，innodb_buffer_pool_size的作用就相当于key_buffer_size对于MyISAM表的作用一样。InnoDB使用该参数指定大小的内存来缓冲数据和索引。对于单独的MySQL数据库服务器，最大可以把该值设置成物理内存的80%。根据MySQL手册，对于2G内存的机器，推荐值是1G（50%）。 如果你的数据量不大，并且不会暴增，那么无需把 innodb_buffer_pool_size 设置的太大了。 mysql&gt; show variables like ‘innodb_buffer_pool_size’; 设置innodb_buffer_pool_size 修 改/etc/my.cnf文件，在[mysqld]下面添加如下内容 innodb_buffer_pool_size = 2048M 重启MySQL Server进入后，查看设置已经生效。 2、innodb_flush_log_at_trx_commit innodb_flush_log_at_trx_commit 主要控制了innodb将log buffer中的数据写入日志文件并flush磁盘的时间点，取值分别为0、1、2三个。0，表示当事务提交时，不做日志写入操作，而是每秒钟将log buffer中的数据写入日志文件并flush磁盘一次；1，则在每秒钟或是每次事物的提交都会引起日志文件写入、flush磁盘的操作，确保了事务的ACID；设置为2，每次事务提交引起写入日志文件的动作，但每秒钟完成一次flush磁盘操作。 实际测试发现，该值对插入数据的速度影响非常大，设置为2时插入10000条记录只需要2秒，设置为0时只需要1秒，而设置为1时则需要229秒。因此，MySQL手册也建议尽量将插入操作合并成一个事务，这样可以大幅提高速度。 根据MySQL手册，在允许丢失最近部分事务的危险的前提下，可以把该值设为0或2。 3、innodb_thread_concurrency = 0 innodb_thread_concurrency = 0 此参数用来设置innodb线程的并发数量，默认值为0表示不限制，若要设置则与服务器的CPU核数相同或是cpu的核数的2倍，建议用默认设置，一般为8. 4、innodb_log_buffer_size innodb_log_buffer_size 此参数确定些日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，对于较大的事务，可以增大缓存大小。 innodb_log_buffer_size=32M 5、innodb_log_file_size = 50M innodb_log_file_size = 50M此参数确定数据日志文件的大小，以M为单位，更大的设置可以提高性能. 6、innodb_log_files_in_group = 3 innodb_log_files_in_group = 3为提高性能，MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3第十四章.md 1/6/20206 / 7 7、read_buffer_size = 1M read_buffer_size = 1M MySql 读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，并且你认为频繁扫描进行得太慢，可以通过增加该变量值以及内存缓冲区大小提高其性能。和 sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。 8、read_rnd_buffer_size = 16M read_rnd_buffer_size = 16M MySql 的随机读（查询操作）缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。 注：顺序读是指根据索引的叶节点数据就能顺序地读取所需要的行数据。随机读是指一般需要根据辅助索引叶节点中的主键寻找实际行数据，而辅助索引和主键所在的数据段不同，因此访问方式是随机的。 9、bulk_insert_buffer_size = 64M bulk_insert_buffer_size = 64M 批量插入数据缓存大小，可以有效提高插入效率，默认为8M 10、binary log log-bin=/usr/local/mysql/data/mysql-bin binlog_cache_size = 2M binary log log-bin=/usr/local/mysql/data/mysql-bin binlog_cache_size = 2M //为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存,提高记录bin-log的效率。没有什么大事务，dml也不是很频繁的情况下可以设置小一点，如果事务大而且多，dml操作也频繁，则可以适当的调大一点。前者建议是–1M，后者建议是：即 2–4M max_binlog_cache_size = 8M //表示的是binlog 能够使用的最大cache内存大小 max_binlog_size = 512M //指定binlog日志文件的大小，如果当前的日志大小达到max_binlog_size，还会自动创建新的二进制日志。你不能将该变量设置为大于1GB或小于4096字节。默认值是1GB。在导入大容量的sql文件时，建议关闭sql_log_bin，否则硬盘扛不住，而且建议定期做删除。 expire_logs_days = 7 //定义了mysql清除过期日志的时间。 二进制日志自动删除的天数。默认值为0,表示“没有自动删除”。 mysqladmin flush-logs 也可以重新开始新的binary log 11、log_queries_not_using_indexes log_queries_not_using_indexes 开启这个选项真实地记录了返回所有行的查询。 在优化之前执行mysqlslap工具进行测试 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@localhost ~]#mysqlslap --defaults-file=/etc/my.cnf --concurrency=10 --iterations=1 --create-schema='test1' --query='select * from test1.tb1' --engine=innodb --number-of-queries=2000 -uroot -p123456 –verbose显示结果：BenchmarkRunning for engine innodbAverage number of seconds to run all queries: 13.837 secondsMinimum number of seconds to run all queries: 13.837 secondsMaximum number of seconds to run all queries: 13.837 secondsNumber of clients running queries: 10Average number of queries per client: 200优化之后执行mysqlslap工具进行测试[root@localhost ~]#mysqlslap --defaults-file=/etc/my.cnf --concurrency=10 --iterations=1 --create-schema='test1' --query='select * from test1.tb1' --engine=innodb --number-of-queries=2000 -uroot -p123456 –verbose显示结果：BenchmarkRunning for engine innodbAverage number of seconds to run all queries: 4.199 secondsMinimum number of seconds to run all queries: 4.199 secondsMaximum number of seconds to run all queries: 4.199 secondsNumber of clients running queries: 10Average number of queries per client: 200相关优化参数总结：[mysqld]slow_query_log = 1slow_query_log_file = /usr/local/mysql/data/slow-query.loglong_query_time = 1log-queries-not-using-indexesmax_connections = 1024back_log = 128wait_timeout = 60interactive_timeout = 7200key_buffer_size=256Mquery_cache_size = 256Mquery_cache_type=1query_cache_limit=50Mmax_connect_errors=20sort_buffer_size = 2Mmax_allowed_packet=32Mjoin_buffer_size=2Mthread_cache_size=200innodb_buffer_pool_size = 2048Minnodb_flush_log_at_trx_commit = 1innodb_log_buffer_size=32Minnodb_log_file_size=128Minnodb_log_files_in_group=3log-bin=mysql-binbinlog_cache_size=2Mmax_binlog_cache_size=8Mmax_binlog_size=512Mexpire_logs_days=7read_buffer_size=1Mread_rnd_buffer_size=16Mbulk_insert_buffer_size=64Mlog-error = /usr/local/mysql/data/mysqld.err","path":"posts/49c4.html","date":"06-20","excerpt":"","tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"}]},{"title":"MySQL自带工具使用介绍","text":"一、MySQL自带工具使用介绍 MySQL数据库不仅提供了数据库的服务器端应用程序，同时还提供了大量的客户端工具程序，如mysql，mysqladmin，mysqldump等等 。 语法格式： Usage: mysql [OPTIONS] [database] 例如： 1# mysql -e &quot;select user,host from user&quot; mysql 大家只要运行一下“mysql --help”就会得到如下相应的基本使用帮助信息： 这里主要介绍一些在运维过程中会用到的相关选项： 首先看看“-e, --execute=name”参数，这个参数是告诉 mysql，我要执行“-e”后面的某个命令，而不是要通过mysql连接登录到MySQL Server 上面。此参数在我们写一些基本的MySQL 检查和监控的脚本中非常有用，运维mysql时经常在脚本中使用到它。 #mysql -hhostname -Pport -uusername -ppassword -e 相关mysql的sql语句 1、mysql命令 Mysql命令是用的最多的一个命令工具了，为用户提供一个命令行接口来操作管理MySQL 服务器。可以通过mysql --help来查看其详细使用方法。 mysql命令选项 作用 说明 -u 指定连接数据库时使用的用户 -p 指定用户的密码 可以-p后面直接写密码，也可以不写，进行交互式输入密码，推荐后者 -h 指定要登录的主机 可选，如果为空，则登录本机 -P 指定要连接的端口 可选，默认是3306 -e 可以通过-e命令直接执行SQL语句，而不用进入数据库 免交互登录数据库执行SQL语句，通常在脚本中使用 -D 指定要登录到哪个库 默认不会登录到库，可以省略此选项，直接写库名 -E 查询到的结果以行来显示 类似于每条SQL语句后面加“\\G” -f 即使出现SQL错误，也强制继续 比如在不登陆数据库执行删除库的操作会有一个交互式的确认操作，可以使用此选项来避免交互式 -X 将查询到的数据导出位xml文件 导出的文件在windows系统中可以使用excel表格打开 -H 将查询到的数据导出位html文件 导出的文件在windows系统中可以使用浏览器打开 –prompt 定制自己的MySQL提示符显示的内容 默认登登录到MySQL后的提示符是“mysql &gt;”，可以使用该选项定制提示符 –tee 将操作数据库所有输入和输出的内容都记录进文件中 在一些较大维护变更的时候，为了方便被查，可以将整个操作过程中的输出信息保存到某个文件中 这里主要介绍一些在运维过程中会用到的相关选项。 1）-e、-u、-p、-h、-P、 等选项的使用语法 首先看看“-e, --execute=name”参数，这个参数是告诉mysql，我要执行“-e”后面的某个命令，而不是要通过mysql连接登录到MySQL Server 上面。此参数在我们写一些基本的MySQL 检查和监控的脚本中非常有用，运维mysql时经常在脚本中使用到它。 语法格式： 1[root@mysql ~]# mysql -hhostname -Pport -uusername -ppassword -e 相关mysql的sql语句 示例1：免登录执行sql语句 123456789101112[root@mysql ~]# mysql -hlocalhost -P3306 -uroot -p mysql -e &quot;select user,host from user;&quot;Enter password: +---------------+-----------+| user | host |+---------------+-----------+| bankMaster | % || bankMaster | 127.0.0.1 || epetadmin | localhost || mysql.session | localhost || mysql.sys | localhost || root | localhost |+---------------+-----------+ 示例2： 通过binlog_cache_use 以及 binlog_cache_disk_use来分析设置的binlog_cache_size是否足够 12345678[root@mysql ~]# mysql -uroot -p -e &quot;show status like &#39;binlog_cache%&#39;&quot;Enter password: +-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| Binlog_cache_disk_use | 0 || Binlog_cache_use | 0 |+-----------------------+-------+ 示例3： 通过脚本创建数据库、表及对表进行增、改、删、查操作.脚本内容如下： 1234567891011121314151617181920212223242526272829303132333435# cat mysql1.sh#!&#x2F;bin&#x2F;bashHOSTNAME&#x3D;&quot;localhost&quot;PORT&#x3D;&quot;3306&quot;USERNAME&#x3D;&quot;root&quot;PASSWORD&#x3D;&quot;123&quot;DBNAME&#x3D;&quot;test_db&quot;TABLENAME&#x3D;&quot;tb1&quot;#create databasecreate_db_sql&#x3D;&quot;create database if not exists $&#123;DBNAME&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e &quot;$&#123;create_db_sql&#125;&quot;#create tablecreate_table_sql&#x3D;&quot;create table if not exists $&#123;TABLENAME&#125; (name varchar(20),id int default 0)&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;create_table_sql&#125;&quot;#insert data to tableinsert_sql&#x3D;&quot;insert into $&#123;TABLENAME&#125; values (&#39;tom&#39;,1)&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;insert_sql&#125;&quot;#select dataselect_sql&#x3D;&quot;select * from $&#123;TABLENAME&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;select_sql&#125;&quot;#update dataupdate_sql&#x3D;&quot;update $&#123;TABLENAME&#125; set id&#x3D;3&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;update_sql&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;select_sql&#125;&quot;#delete datadelete_sql&#x3D;&quot;delete from $&#123;TABLENAME&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;delete_sql&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;select_sql&#125;&quot; 执行一下 12345678910111213141516171819[root@mysql ~]# sh mysql1.sh mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure.+------+------+| name | id |+------+------+| tom | 1 |+------+------+mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure.+------+------+| name | id |+------+------+| tom | 3 |+------+------+mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure. 2、-E 如果在连接时候使用了“-E, --vertical”参数，登入之后的所有查询结果都将以纵列显示，效果和我们在一条query 之后以“\\G”结尾一样。 123456789101112131415161718# mysql -uroot -p123 -Emysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 27Server version: 5.7.22 Source distributionCopyright (c) 2000, 2018, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.mysql&gt; show databases;*************************** 1. row ***************************Database: information_schema*************************** 2. row ***************************Database: mysql*************************** 3. row ***************************Database: test_db10 rows in set (0.00 sec) “-H, --html”与“-X, --xml”，在启用这两个参数之后，select出来的所有结果都会按照“Html”与“Xml”格式来输出，在有些场合之下，比如希望Xml或者Html 文件格式导出某些报表文件的时候，是非常方便的。 123456789101112131415161718192021222324252627282930313233343536373839[root@192 ~]# mysql -utest -p -XEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 40Server version: 5.7.30 MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.mysql&gt; use test_db;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from tb1;&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;&lt;resultset statement&#x3D;&quot;select * from tb1;&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;&gt; &lt;row&gt; &lt;field name&#x3D;&quot;name&quot;&gt;tom&lt;&#x2F;field&gt; &lt;field name&#x3D;&quot;id&quot;&gt;1&lt;&#x2F;field&gt; &lt;&#x2F;row&gt; &lt;row&gt; &lt;field name&#x3D;&quot;name&quot;&gt;tom&lt;&#x2F;field&gt; &lt;field name&#x3D;&quot;id&quot;&gt;2&lt;&#x2F;field&gt; &lt;&#x2F;row&gt; &lt;row&gt; &lt;field name&#x3D;&quot;name&quot;&gt;tom&lt;&#x2F;field&gt; &lt;field name&#x3D;&quot;id&quot;&gt;3&lt;&#x2F;field&gt; &lt;&#x2F;row&gt;&lt;&#x2F;resultset&gt;3 rows in set (0.01 sec) 3、-H选项的使用方式 123[root@mysql ~]# mysql -H -uroot -p123.com -e \"select * from mysql.user\" &gt; a.html#将查询的结果重定向输出到a.html文件中[root@mysql ~]# sz a.html #下载这个文件到本地windows系统 4、创建授予test用户可以在指定的源登录 123# mysql -uroot -p -e &quot;grant all on test_db.* to root@&#39;192.168.1.10&#39; identified by&#39;123&#39;&quot;Enter password: 测试test用户连接mysql服务器 1234567891011121314151617[root@mysql ~]# mysql -u root -p -e &quot;grant all on test_db.* to test@&#39;192.168.1.%&#39; identified by &#39;123&#39;&quot;Enter password: [root@mysql ~]# mysql -utest -p123 -h 192.168.1.10mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 18Server version: 5.7.22 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.mysql&gt; 二、–prompt使用方法 “–prompt=name”参数对于做运维的人来说是一个非常重要的参数选项，其主要功能是定制自己的mysql提示符的显示内容。 在默认情况下，我们通过mysql登入到数据库之后，mysql的提示符只是一个很简单的内容”mysql&gt;“，没有其他任何附加信息。非常幸运的是mysql通过“--prompt=name”参数给我们提供了自定义提示信息的办法，可以通过配置显示登入的主机地址，登录用户名，当前时间，当前数据库schema，MySQL Server 的一些信息等等。 个人强烈建议将登录主机名，登录用户名和所在的schema 这三项加入提示内容，因为当大家手边管理的MySQL 越来越多，操作越来越频繁的时候，非常容易因为操作的时候没有太在意自己当前所处的环境而造成在错误的环境执行了错误的命令并造成严重后果的情况。如果我们在提示内容中加入了这几项之后，至少可以更方便的提醒自己当前所处环境，以尽量减少犯错误的概率. 个人强烈建议提示符定义： 1&quot;\\\\u@\\\\h : \\\\d \\\\r:\\\\m:\\\\s&gt; &quot; 提示符解释： \\u ：表示用户名, \\h ：表示主机名， \\d ：表示当前数据库， \\r小时：（12小时制）， \\R小时（24小时制）， \\m：分种， \\s秒， 显示效果 1234567891011121314151617181920[root@mysql ~]# mysql -uroot -p --prompt&#x3D;&quot;\\\\u@\\\\h: \\\\d \\\\r:\\\\m:\\\\s&quot;Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 26Server version: 5.7.22 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.root@localhost: (none) 04:54:56&gt; use test_dbReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedroot@localhost: (none) 04:54:56&gt; 三、–tee的使用方法 “–tee=name”参数也是对运维人员非常有用的参数选项，用来告诉mysql，将所有输入和输出内容都记录进文件。在我们一些较大维护变更的时候，为了方便被查，最好是将整个操作过程的所有输入和输出内容都保存下来.假如mysql命令行状态下，要进行大量的交互操作，其实可以把这些操作记录在log中进行审计，很简单 mysql -u root -p --tee=/path/xxxx.log 也可以在服务器上的/etc/my.cnf中的[client]加入 tee =/tmp/client_mysql.log即可. 注：若没有[client]就添加即可 或者在mysql&gt;提示符下执行下面的命令 12345678910111213mysql&gt; tee &#x2F;opt&#x2F;xgp.logLogging to file &#39;&#x2F;opt&#x2F;xgp.log&#39;mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || test_db |+--------------------+5 rows in set (0.00 sec) 查看一下 1234567891011121314[root@mysql ~]# cat &#x2F;opt&#x2F;xgp.log mysql&gt; tee &#x2F;opt&#x2F;xgp.logLogging to file &#39;&#x2F;opt&#x2F;xgp.log&#39;mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || test_db |+--------------------+5 rows in set (0.00 sec) 同样，“–tee”这个配置项也可以写入my.cnf这个主配置文件中的client字段下，如下： 1234567891011[root@mysql ~]# vim /etc/my.cnf [client]socket=/usr/local/mysql/mysql.sock[mysqld]basedir=/usr/local/mysqldatadir=/usr/local/mysql/datapid-file=/usr/local/mysql/data/mysql.pidsocket=/usr/local/mysql/mysql.socklog-error=/usr/local/mysql/data/mysql.errtee=/opt/xgp.log 四、mysqladmin命令 mysqladmin,顾名思义,提供的功能都是与MySQL管理相关的各种功能。如MySQL Server状态检查,各种统计信息的flush,创建/删除数据库，关闭MySQL Server等等。mysqladmin所能做的事情，虽然大部分都可以通过mysql连接登录上MySQL Server之后来完成，但是大部分通过mysqladmin来完成操作会更简单更方便。 mysqladmin后面可以接选项，也可以接命令,这里就不说选项了，主要说一下命令 命令字 作用 create databasename 创建一个库 drop databasename 删除一个库 status 查询MySQL的基本状态（显示的信息有限 ） extended-status 查询服务器的详细状态信息（类似于在数据库中执行show status;） flush-hosts 刷新服务器缓存 flush-logs 刷新二进制日志文件（如果二进制日志功能开启，那么执行这个操作会生成新的二进制日志文件） flush-status 刷新状态变量 flush-tables 刷新所有表 flush-threads 刷新所有线程缓存 flush-privileges 重新加载授权表 processlist 查看当前连接数据库的所有ID详细信息 kill id 杀掉某个或多个连接ID（一般需要先使用processlist查看出ID列表，然后根据ID将其kill掉 ） ping 检测某个MySQL服务是否处于启动状态 password 修改用户密码 shutdown 关闭MySQL服务 start-slave 开启主从复制 stop-slave 关闭主从复制 variables 查询MySQL服务中的所有变量 version 查询MySQL的版本详细信息 （1）ping 监测服务是否正常 123[root@mysql ~]# mysqladmin -uroot -p pingEnter password: mysqld is alive （2）status 获取mysql当前状态值 123[root@mysql ~]# mysqladmin -uroot -p statusEnter password: Uptime: 3413 Threads: 2 Questions: 102 Slow queries: 0 Opens: 118 Flush tables: 1 Open tables: 111 Queries per second avg: 0.029 状态值： **mysqladmin status命令结果有下述列 ** Uptime:是mysql服务器运行的秒数. Threads:活跃线程的数量即开启的会话数. Questions： 服务器启动以来客户的问题(查询)数目 （只要跟mysql作交互，不管查询表，还是查询服务器状态都记一次）. Slow queries：是慢查询的数量. **Opens：mysql已经打开的数据库表的数量 ** **Flush tables: mysql已经执行的flush tables，refresh和reload命令的数量.注：flush tables //刷新表（清除缓存）reload 重载授权表 refresh 洗掉所有表并关闭和打开日志文件 ** open：打开数据库的表的数量，以服务器启动开始. Queries per second avg：select语句平均查询时间 Memory in use分配的内存(只有在MySQL用–withdebug编译时可用) Max memory used分配的最大内存(只有在MySQL用–with-debug编译时可用) （3）processlist 获取数据库当前连接信息 12345678[root@mysql ~]# mysqladmin -uroot -p processlistEnter password: +----+------+-----------+---------+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+---------+---------+------+----------+------------------+| 32 | root | localhost | test_db | Sleep | 877 | | || 40 | root | localhost | | Query | 0 | starting | show processlist |+----+------+-----------+---------+---------+------+----------+------------------+ （4）获取数据库当前的连接数 123[root@mysql ~]# mysql -uroot -p -BNe \"select host,count(host) from processlist group by host\" information_schemaEnter password: localhost 2 （5）显示mysql的启动时长 1234[root@mysql ~]# mysql -uroot -p123 -e \"SHOW STATUS LIKE '%uptime%'\" | awk '/ptime/&#123; calc = $NF/3600;print $(NF-1), calc\"Hour\"&#125;'Uptime 1.005HourUptime_since_flush_status 1.005Hour （6）查看数据库所有库大小 1234567891011[root@mysql ~]# mysql -uroot -p123 -e 'select table_schema,round(sum(data_length+index_length)/1024/1024,4) from information_schema.tables group by table_schema'+--------------------+--------------------------------------------------+| table_schema | round(sum(data_length+index_length)/1024/1024,4) |+--------------------+--------------------------------------------------+| information_schema | 0.1563 || mysql | 2.4425 || performance_schema | 0.0000 || sys | 0.0156 || test_db | 0.0156 |+--------------------+--------------------------------------------------+ （7）processlist获取当前数据库的连接线程信息： 监控mysql进程运行状态： 上面的这三个功能在一些简单监控脚本中经常使用到的.mysqladmin其他参数选项可以通过执行“mysqladmin–help”或man mysqladmin得到帮助信息.编写一个简单的mysql监控脚本，内容如下： 12345678910111213#!/bin/bash#监测服务是否正常mysqladmin -uroot -p123 -h localhost ping#获取mysql当前状态值mysqladmin -uroot -p123 -h localhost status#获取数据库当前连接信息mysqladmin -uroot -p123 -h localhost processlist#获取数据库当前的连接数mysql -uroot -p123 -BNe \"select host,count(host) from processlist group by host\" information_schema#显示mysql的启动时长mysql -uroot -p123 -e \"SHOW STATUS LIKE '%uptime%'\" | awk '/ptime/&#123; calc = $NF/3600;print $(NF-1), calc\"Hour\"&#125;'#查看数据库所有库大小mysql -uroot -p123 -e 'select table_schema,round(sum(data_length+index_length)/1024/1024,4) from information_schema.tables group by table_schema' 五、mysqldump 这个工具其功能就是将MySQL Server中的数据以SQL 语句的形式从数据库中dump 成文本文件。mysqldump是做为MySQL 的一种逻辑备份工具，在我之前的博文中有这个工具的使用方法：MySQL的备份与恢复详解 六、mysqlbinlog mysqlbinlog程序的主要功能就是分析MySQL Server 所产生的二进制日志（也就是binlog）。 通过mysqlbinlog，我们可以解析出binlog中指定时间段或者指定日志起始和结束位置的内容解析成SQL 语句。 七、Mysqlslap性能测试 MySQL二种存储引擎 mysqlslap是mysql自带的基准测试工具,优点:查询数据,语法简单,灵活容易使用.该工具可以模拟多个客户端同时并发的向服务器发出查询更新,给出了性能测试数据而且提供了多种引擎的性能比较.mysqlslap为mysql性能优化前后提供了直观的验证依据,建议系统运维和DBA人员应该掌握一些常见的压力测试工具,才能准确的掌握线上数据库支撑的用户流量上限及其抗压性等问题.现在看一下这个压力测试工具mysqlslap，关于他的选项手册上以及–help介绍的很详细。 这里解释一下一些常用的选项 –concurrency代表并发数量，多个可以用逗号隔开。例如：concurrency=50,100,200 --engines代表要测试的引 擎，可以有多个，用分隔符隔开。 –iterations代表要运行这些测试多少次，即运行多少次后，得到结果。 –auto-generate-sql 代表用系统自己生成的SQL脚本来测试。 –auto-generate-sql-load-type 代表要测试的是读 还是写还是两者混合的（read,write,update,mixed） –number-of-queries 代表总共要运行多少次查询。每个客户运行的查询数量可以用查询总数/并发数来计算。比如倒数第二个结果2=200/100。 –debug-info 代表要额外输出CPU以及内存的相关信息（注：只有在MySQL用–with-debug编译时可）。 –number-int-cols 代表测试表中的INTEGER类型的属性有几个。 –number-char-cols代表测试表的char类型字段的数量。 –create-schema 代表自己定义的模式（在MySQL中也就是库即创建测试的数据库）。 –query 代表自己的SQL脚本。 –only-print如果只想打印看看SQL语句是什么，可以用这个选项。 –csv=name 生产CSV格式数据文件 查看Mysql数据库默认最大连接数 （1）查看Mysql数据库默认最大连接数 可以看到mysql5.7.13默认是151。注：不同版本默认最大连接数不差别。一般生产环境是不够的。 1234567mysql&gt; show variables like &#39;%max_connections%&#39;;+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 151 |+-----------------+-------+1 row in set (0.00 sec) 注：不同版本默认最大连接数不差别。一般生产环境是不够的 2、修改MySQL数据库默认最大连接数 方法一 123456789mysql&gt; set GLOBAL max_connections &#x3D; 1024;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like &#39;%max_connections%&#39;;+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 1024 |+-----------------+-------+1 row in set (0.00 sec) 方法二 12345在my.cnf[mysqld]下添加 max_connections&#x3D;1024 #增加到1024重启Mysql.总结：修改my.cnf文件并重启mysqld服务 3、查看Mysql默认使用存储引擎， 如下查看： mysql&gt; show engines; 123456789101112131415mysql&gt; show engines;+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || CSV | YES | CSV storage engine | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || BLACKHOLE | YES | &#x2F;dev&#x2F;null storage engine (anything you write to it disappears) | NO | NO | NO || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || ARCHIVE | YES | Archive storage engine | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+9 rows in set (0.00 sec) 4、测试 现在我们来看一下具体测试的例子。 1）用自带的SQL脚本来测试 123456789101112131415161718192021222324252627282930313233[root@mysql ~]# mysqlslap --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --concurrency&#x3D;100,200 --iterations&#x3D;1 --number-int-cols&#x3D;20 --number-char-cols&#x3D;30 --auto-generate-sql --auto-generate-sql-add-autoincrement --auto-generate-sql-load-type&#x3D;mixed --engine&#x3D;myisam,innodb --number-of-queries&#x3D;2000 -uroot -p123 --verboseBenchmarktrueRunning for engine myisamtrueAverage number of seconds to run all queries: 0.330 secondstrueMinimum number of seconds to run all queries: 0.330 secondstrueMaximum number of seconds to run all queries: 0.330 secondstrueNumber of clients running queries: 100trueAverage number of queries per client: 20BenchmarktrueRunning for engine myisamtrueAverage number of seconds to run all queries: 0.341 secondstrueMinimum number of seconds to run all queries: 0.341 secondstrueMaximum number of seconds to run all queries: 0.341 secondstrueNumber of clients running queries: 200trueAverage number of queries per client: 10BenchmarktrueRunning for engine innodbtrueAverage number of seconds to run all queries: 0.610 secondstrueMinimum number of seconds to run all queries: 0.610 secondstrueMaximum number of seconds to run all queries: 0.610 secondstrueNumber of clients running queries: 100trueAverage number of queries per client: 20BenchmarktrueRunning for engine innodbtrueAverage number of seconds to run all queries: 0.457 secondstrueMinimum number of seconds to run all queries: 0.457 secondstrueMaximum number of seconds to run all queries: 0.457 secondstrueNumber of clients running queries: 200trueAverage number of queries per client: 10 测试说明 1模拟测试两次读写并发，第一次100，第二次200，自动生成SQL脚本，测试表包含20个init字段，30个char字段，每次执行2000查询请求。测试引擎分别是myisam，innodb。 测试结果说明 12Myisam第一次100客户端同时发起增查用1.459/s,第二次200客户端同时发起增查用1.420/sInnodb第一次100客户端同时发起增查用1.352/s,第二次200客户端同时发起增查用2.330/s 测试结论 12由此可见MyISAM存储引擎处理性能是最好的，也是最常用的，但不支持事务。InonDB存储引擎提供了事务型数据引擎（ACID），在事务型引擎里使用最多的。具有事务回滚，系统修复等特点。 2）测试结果保存为csv文件 Mysqlslap测试工具生产CSV格式数据文件并转换成图表形式： 1[root@mysql ~]# mysqlslap --defaults-file=/etc/my.cnf --concurrency=100,200 --iterations=1 --number-int-cols=20 --number-char-cols=30 --auto-generate-sql --auto-generate-sql-add-autoincrement --auto-generate-sql-load-type=mixed --engine=myisam,innodb --number-of-queries=2000 -uroot -p123 --csv=/root/a.csv 将/root/a.csv拷贝到windows主机上，打开并生成图表 3）使用自定义sql脚本测试 用我们自己定义的SQL 脚本或语句来测试 首先准备好要测试的数据库表，这里我们编写一个生成表的脚本去完成 脚本内容如下： 12345678910111213141516171819202122232425[root@mysql ~]# cat /root/mysql3.sh#!/bin/bashHOSTNAME=\"localhost\"PORT=\"3306\"USERNAME=\"root\"PASSWORD=\"123\"DBNAME=\"test1\"TABLENAME=\"tb1\"#create databasemysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e \"drop database if exists $&#123;DBNAME&#125;\" create_db_sql=\"create database if not exists $&#123;DBNAME&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e \"$&#123;create_db_sql&#125;\"#create tablecreate_table_sql=\"create table if not exists $&#123;TABLENAME&#125;(stuid int not null primary key,stuname varchar(20) not null,stusex char(1) not null,cardid varchar(20) not null,birthday datetime,entertime datetime,address varchar(100) default null)\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;create_table_sql&#125;\"#insert data to tablei=1while [ $i -le 20000 ]doinsert_sql=\"insert into $&#123;TABLENAME&#125; values($i,'zhangsan','1','1234567890123456','1999-10-10','2016-9-3','zhongguo beijingshi changpinqu')\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;insert_sql&#125;\"let i++done#select dataselect_sql=\"select count(*) from $&#123;TABLENAME&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;select_sql&#125;\" 授权脚本x执行权限 1[root@192 opt]# chmod +x mysql_test.sh 执行脚本mysql3.sh生成mysqlslap工具需要的测试表 1234[root@mysql ~]# /root/mysql3.sh执行mysqlslap工具进行测试[root@mysql ~]# mysqlslap --defaults-file=/etc/my.cnf --concurrency=10,20 --iterations=1 --create-schema='test1' --query='select * from test1.tb1' --engine=myisam,innodb --number-of-queries=2000 -uroot -p123 –verbose 显示结果： 123456789101112131415161718192021222324252627282930313233[root@192 opt]# mysqlslap --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --concurrency&#x3D;10,20 --iterations&#x3D;1 --create-schema&#x3D;&#39;test1&#39; --query&#x3D;&#39;select * from test1.tb1&#39; --engine&#x3D;myisam,innodb --number-of-queries&#x3D;2000 -uroot -p1234 –verbosemysqlslap: [Warning] Using a password on the command line interface can be insecure.Benchmark Running for engine myisam Average number of seconds to run all queries: 3.261 seconds Minimum number of seconds to run all queries: 3.261 seconds Maximum number of seconds to run all queries: 3.261 seconds Number of clients running queries: 10 Average number of queries per client: 200Benchmark Running for engine myisam Average number of seconds to run all queries: 3.010 seconds Minimum number of seconds to run all queries: 3.010 seconds Maximum number of seconds to run all queries: 3.010 seconds Number of clients running queries: 20 Average number of queries per client: 100Benchmark Running for engine innodb Average number of seconds to run all queries: 3.421 seconds Minimum number of seconds to run all queries: 3.421 seconds Maximum number of seconds to run all queries: 3.421 seconds Number of clients running queries: 10 Average number of queries per client: 200Benchmark Running for engine innodb Average number of seconds to run all queries: 3.252 seconds Minimum number of seconds to run all queries: 3.252 seconds Maximum number of seconds to run all queries: 3.252 seconds Number of clients running queries: 20 Average number of queries per client: 100 注：通过mysqlslap工具对mysql server进行压力测试，可以通过–concurrency、–number-of-queries等选项的值查看每次测试的结果，通过反复测试、优化得出mysql server的最大并发数.如果mysqlslap工具输出结果为Segmentation fault (core dumped)基本表示走超出mysql server的负载。","path":"posts/f96f.html","date":"06-18","excerpt":"","tags":[{"name":"mysqladmin","slug":"mysqladmin","permalink":"https://wsdlxgp.top/tags/mysqladmin/"},{"name":"--tee","slug":"tee","permalink":"https://wsdlxgp.top/tags/tee/"},{"name":"--prompt","slug":"prompt","permalink":"https://wsdlxgp.top/tags/prompt/"},{"name":"mysqldump","slug":"mysqldump","permalink":"https://wsdlxgp.top/tags/mysqldump/"},{"name":"mysqlslap","slug":"mysqlslap","permalink":"https://wsdlxgp.top/tags/mysqlslap/"}]},{"title":"MySQL数据文件介绍及存放位置","text":"一、MySQL数据库文件介绍 MySQL的每个数据库都对应存放在一个与数据库同名的文件夹中，MySQL数据库文件包括MySQL所建数据库文件和MySQL所用存储引擎创建的数据库文件。 1、MySQL创建并管理的数据库文件： .frm文件：存储数据表的框架结构，文件名与表名相同，每个表对应一个同名frm文件，与操作系统和存储引擎无关，即不管MySQL运行在何种操作系统上，使用何种存储引擎，都有这个文件。 除了必有的.frm文件，根据MySQL所使用的存储引擎的不同（MySQL常用的两个存储引擎是MyISAM和InnoDB），存储引擎会创建各自不同的数据库文件。 2、MyISAM数据库表文件： .MYD文件：即MY Data，表数据文件 .MYI文件：即MY Index，索引文件 .log文件：日志文件 3、InnoDB采用表空间（tablespace）来管理数据，存储表数据和索引， InnoDB数据库文件（即InnoDB文件集，ib-file set）： ibdata1、ibdata2等：系统表空间文件，存储InnoDB系统信息和用户数据库表数据和索引，所有表共用 .ibd文件：单表表空间文件，每个表使用一个表空间文件（file per table），存放用户数据库表数据和索引 日志文件： ib_logfile1、ib_logfile2 二、MySQL数据库存放位置： 1、MySQL如果使用MyISAM存储引擎，数据库文件类型就包括.frm、.MYD、.MYI，默认存放位置是C:\\Documentsand Settings\\All Users\\Application Data\\MySQL\\MySQL Server 5.1\\data 2、MySQL如果使用InnoDB存储引擎，数据库文件类型就包括.frm、ibdata1、.ibd，存放位置有两个， .frm文件默认存放位置是C:\\Documents and Settings\\All Users\\ApplicationData\\MySQL\\MySQL Server 5.1\\data，ibdata1、.ibd文件默认存放位置是MySQL安装目录下的data文件夹 三、操作 看看我的数据库文件的存放位置 12345678910111213141516[root@pacteralinux ~]# cd /mnt/resource/mysqldate/[root@pacteralinux mysqldate]# ll -htotal 173M-rw-rw----. 1 mysql mysql 56 Nov 25 17:17 auto.cnf-rw-rw----. 1 mysql mysql 76M Dec 24 17:02 ibdata1-rw-rw----. 1 mysql mysql 48M Dec 24 17:02 ib_logfile0-rw-rw----. 1 mysql mysql 48M Nov 26 13:39 ib_logfile1drwx------. 2 mysql mysql 4.0K Nov 26 13:41 mysqldrwx------. 2 mysql mysql 20K Nov 26 17:00 mysqldbsrwxrwxrwx. 1 mysql mysql 0 Dec 24 17:02 mysql.sock-rw-rw----. 1 mysql root 499K Dec 25 14:42 pacteralinux.err-rw-rw----. 1 mysql mysql 6 Dec 24 17:02 pacteralinux.piddrwx------. 2 mysql mysql 4.0K Nov 26 13:41 performance_schemadrwx------. 2 mysql mysql 4.0K Nov 26 13:41 testdrwx------. 2 mysql mysql 4.0K Dec 9 16:49 weixindemo[root@pacteralinux mysqldate]# 其中这三个文件我一直很迷惑 123-rw-rw----. 1 mysql mysql 76M Dec 24 17:02 ibdata1-rw-rw----. 1 mysql mysql 48M Dec 24 17:02 ib_logfile0-rw-rw----. 1 mysql mysql 48M Nov 26 13:39 ib_logfile1 再看这些文件（部分） 1234567891011121314[root@pacteralinux mysqldb]# ll -htotal 3.6G-rw-rw----. 1 mysql mysql 11K Nov 26 16:47 chen_fundnetvalue_bak.frm-rw-rw----. 1 mysql mysql 62K Nov 26 16:47 chen_fundnetvalue_bak.MYD-rw-rw----. 1 mysql mysql 4.0K Nov 26 16:47 chen_fundnetvalue_bak.MYI-rw-rw----. 1 mysql mysql 11K Nov 26 16:47 chen_fundnetvalue.frm-rw-rw----. 1 mysql mysql 834K Nov 26 16:47 chen_fundnetvalue.MYD-rw-rw----. 1 mysql mysql 18K Nov 26 16:47 chen_fundnetvalue.MYI-rw-rw----. 1 mysql mysql 8.4K Nov 26 16:47 codelist_bak.frm-rw-rw----. 1 mysql mysql 162 Nov 26 16:47 codelist_bak.MYD-rw-rw----. 1 mysql mysql 1.0K Nov 26 16:47 codelist_bak.MYI-rw-rw----. 1 mysql mysql 8.4K Nov 26 16:47 codelist.frm-rw-rw----. 1 mysql mysql 162 Nov 26 16:47 codelist.MYD-rw-rw----. 1 mysql mysql 1.0K Nov 26 16:47 codelist.MYI . 前面是表名，每个表由frm MYD MYI三个后缀名组成，所有表都是！ 在MySQL 中每一个数据库都会在定义好（或者默认）的数据目录下存在一个以数据库名字命名的文件夹，用来存放该数据库中各种表数据文件。不同的MySQL 存储引擎有各自不同的数据文件，存放位置也有区别。 多数存储引擎的数据文件都存放在和MyISAM 数据文件位置相同的目录下，但是每个数据文件的扩展名却各不一样。如MyISAM 用“.MYD”作为扩展名，Innodb 用“.ibd”，Archive 用“.arc”，CSV 用“.csv”，等等。 1、下面就来详细分析一下这些是什么文件！！！！！ （1）“.frm”文件 与表相关的元数据（meta）信息都存放在“.frm”文件中，包括表结构的定义信息等。不论是什么存储引擎，每一个表都会有一个以表名命名的“.frm”文件。所有的“.frm”文件都存放在所属数据库的文件夹下面。（innodb，myisam） （2）“.MYD”文件 “.MYD”文件是MyISAM 存储引擎专用，存放MyISAM 表的数据。每一个MyISAM 表都会有一个“.MYD”文件与之对应，同样存放于所属数据库的文件夹下，和“.frm”文件在一起。 （3）“.MYI”文件 “.MYI”文件也是专属于MyISAM存储引擎的，主要存放MyISAM表的索引相关信息。对于MyISAM存储来说，可以被cache 的内容主要就是来源于“.MYI”文件中。每一个MyISAM表对应一个“.MYI”文件，存放于位置和“.frm”以及“.MYD”一样。 （4）小结一下： MyISAM 存储引擎的表在数据库中，每一个表都被存放为三个以表名命名的物理文件（frm,myd,myi）。 每个表都有且仅有这样三个文件做为MyISAM 存储类型的表的存储，也就是说不管这个表有多少个索引，都是存放在同一个.MYI 文件中。 这个在开始里看的比较清楚。 2、“.ibd”文件和ibdata 文件 这两种文件都是存放Innodb 数据的文件，之所以有两种文件来存放Innodb 的数据（包括索引），是因为Innodb 的数据存储方式能够通过配置来决定是使用共享表空间存放存储数据，还是独享表空间存放存储数据。独享表空间存储方式使用“.ibd”文件来存放数据，且每个表一个“.ibd”文件，文件存放在和MyISAM数据相同的位置。 如果选用共享存储表空间来存放数据，则会使用ibdata 文件来存放，所有表共同使用一个（或者多个，可自行配置）ibdata 文件。ibdata 文件可以通过innodb_data_home_dir 和innodb_data_file_path两个参数共同配置组成， innodb_data_home_dir 配置数据存放的总目录， 而innodb_data_file_path 配置每一个文件的名称。当然，也可以不配innodb_data_home_dir而直接在innodb_data_file_path参数配置的时候使用绝对路径来完成配置。 123456789mysql&gt; showvariables like 'innodb_data%';+-----------------------+------------------------+|Variable_name | Value |+-----------------------+------------------------+|innodb_data_file_path | ibdata1:10M:autoextend || innodb_data_home_dir | |+-----------------------+------------------------+2 rows in set(0.01 sec) innodb_data_file_path中可以一次配置多个ibdata文件。文件可以是指定大小，也可以是自动扩展的，但是Innodb 限制了仅仅只有最后一个ibdata 文件能够配置成自动扩展类型。当我们需要添加新的ibdata 文件的时候，只能添加在innodb_data_file_path配置的最后，而且必须重启MySQL 才能完成ibdata 的添加工作。 3、ibdata文件瘦身法 MySql innodb如果是共享表空间，ibdata1文件越来越大，达到了30多个G，对一些没用的表进行清空： truncate table xxx; 然后optimize table xxx; 没有效果 因为对共享表空间不起作用。 mysql ibdata1存放数据，索引等，是MYSQL的最主要的数据。 如果不把数据分开存放的话，这个文件的大小很容易就上了G，甚至几十G。对于某些应用来说，并不是太合适。因此要把此文件缩小。 无法自动收缩，必须数据导出，删除ibdata1，然后数据导入，比较麻烦，因此需要改为每个表单独的文件。 解决方法：数据文件单独存放(共享表空间如何改为每个表独立的表空间文件)。 步骤如下： 1）备份数据库 从命令行进入MySQL Server 5.0\\bin 备份全部数据库，执行命令 1D:\\&gt;mysqldump -q -umysql -ppassword --add-drop-table --all-databases &gt; c:/all.sql 做完此步后，停止数据库服务。 2）找到my.ini或my.cnf文件 linux下执行 ./mysqld --verbose --help | grep -A 1 'Default options' 会有类似显示： Default options are read from the following files in the given order: /etc/my.cnf ~/.my.cnf /usr/local/service/mysql3306/etc/my.cnf windows环境下可以： mysqld --verbose --help &gt; mysqlhelp.txt notepad mysqlhelp.txt 在里面查找Default options，可以看到查找my.ini的顺序，以找到真实目录 3）修改mysql配置文件 打开my.ini或my.cnf文件 [mysqld]下增加下面配置 innodb_file_per_table=1 验证配置是否生效，可以重启mysql后,执行 show variables like '%per_table%' 看看innodb_file_per_table变量是否为ON 4）删除原数据文件 删除原来的ibdata1文件及日志文件ib_logfile*，删除data目录下的应用数据库文件夹(mysql文件夹不要删) 5）还原数据库 启动数据库服务 从命令行进入MySQL Server 5.0\\bin 还原全部数据库，执行命令mysql -uusername -pyourpassword &lt; c:/all.sql 经过以上几步后，可以看到新的ibdata1文件就只有几十M了，数据及索引都变成了针对单个表的小ibd文件了，它们在相应数据库的文件夹下面。 四、mysql data文件夹下的ibdata1 文件作用 这个文件超级大， 查了一下， 大概的作用如下 是储存的格式 INNODB类型数据状态下， ibdata用来储存文件的数据 而库名的文件夹里面的那些表文件只是结构而已 由于mysql4.1默认试innodb，所以这个文件默认就存在了https://wsdlxgp.top/ 这个链接试innodb的中文参考， innodb的东西可以在my.ini中设置 使用过MySQL的同学，刚开始接触最多的莫过于MyISAM表引擎了，这种引擎的数据库会分别创建三个文件：表结构、表索引、表数据空间。我们可以将某个数据库目录直接迁移到其他数据库也可以正常工作。 然而当你使用InnoDB的时候，一切都变了。InnoDB 默认会将所有的数据库InnoDB引擎的表数据存储在一个共享空间中：ibdata1，这样就感觉不爽，增删数据库的时候，ibdata1文件不会自动收缩，单个数据库的备份也将成为问题。通常只能将数据使用mysqldump 导出，然后再导入解决这个问题。 在MySQL的配置文件[mysqld]部分，增加innodb_file_per_table参数，可以修改InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。 独立表空间 优点： 1.每个表都有自已独立的表空间。 2.每个表的数据和索引都会存在自已的表空间中。 3.可以实现单表在不同的数据库中移动。 4.空间可以回收（drop/truncate table方式操作表空间不能自动回收） 5.对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。 缺点： 单表增加比共享空间方式更大。 结论： 共享表空间在Insert操作上有一些优势，但在其它都没独立表空间表现好。 当启用独立表空间时，请合理调整一下 innodb_open_files 参数。 两个重要参数： 12innodb_data_file_pathinnodb_data_home_dir 这两个参数看参考文献的时候一直没有理解，先说明如下 我的my.cnf 12#innodb_data_home_dir = /var/lib/mysql/#innodb_data_file_path = ibdata1:10M:autoextend 为了在 MySQL-Max-3.23 中使用 InnoDB 表，你必须在配置文件‘my.cnf’中的 [mysqld] 区中详细指定配置参数。 作为最小设置，在 3.23 中你必须在 innodb_data_file_path 上指定数据文件名能及大小。 如果在‘my.cnf’中没有指定innodb_data_home_dir，系统将在 MySQL 的 datadir 目录下创建数据文件。 如果将 innodb_data_home_dir 设为一个空串，那可以在 innodb_data_file_path 中给定一个绝对路径。 在 MySQL-4.0 中可以不设定 innodb_data_file_path ：MySQL-4.0 将默认地在 datadir 目录下建立一个 10 MB 大小自扩充(auto-extending)的文件‘ibdata1’(在MySQL-4.0.0 与 4.0.1 中数据文件的大小为 64 MB 并且是非自扩充的(not auto-extending))。 为了得到更好的性能你必须所示的例子明确地设定 InnoDB 启动参数。 从 3.23.50 版和 4.0.2 版开始，InnoDB 允许在 innodb_data_file_path 中设置的最一个数据文件描述为 auto-extending。 innodb_data_file_path 语法如下所示： 12pathtodatafile:sizespecification;pathtodatafile:sizespec;... ...;pathtodatafile:sizespec[:autoextend[:max:sizespecification]] 如果用 autoextend 选项描述最后一个数据文件，当 InnoDB 用尽所有表自由空间后将会自动扩充最后一个数据文件，每次增量为 8 MB。示例： 12innodb_data_home_dir &#x3D;innodb_data_file_path &#x3D; &#x2F;ibdata&#x2F;ibdata1:100M:autoextend 指定 InnoDB 只建立一个最初大小为 100 MB 并且当表空间被用尽时以 8MB 每块增加的数据文件。如果硬盘空间不足，可以再添加一个数据文件并将其放在其它的硬盘中。 举例来说：先检查硬盘空间的大小，设定ibdata1文件使它接近于硬盘空余空间大小并为 1024 * 1024 bytes (= 1 MB)的倍数， 将 ibdata1 明确地指定在 innodb_data_file_path 中。在此之后可以添加另一个数据文件： 12innodb_data_home_dir =innodb_data_file_path = /ibdata/ibdata1:988M;/disk2/ibdata2:50M:autoextend 注意：设定文件大小时一定要注意你的OS是否有最大文件尺寸为2GB的限制！InnoDB是不会注意你的OS文件尺寸限制的， 在一些文件系统中你可能要设定最大容量限制： 12innodb_data_home_dir &#x3D;innodb_data_file_path &#x3D; &#x2F;ibdata&#x2F;ibdata1:100M:autoextend:max:2000M","path":"posts/80a7.html","date":"06-18","excerpt":"","tags":[{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"},{"name":"sql结构化查询语句s","slug":"sql结构化查询语句s","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5s/"}]},{"title":"MySQL事务日志","text":"事务日志(或称redo日志) 事务日志（InnoDB特有的日志）可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。事务日志采用追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。事务日志持久以后，内存中被修改的数据在后台可以慢慢的刷回到磁盘。目前大多数的存储引擎都是这样实现的。 如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。具有的恢复方式则视存储引擎而定。 查看事务日志的定义： 1show global variables like &#39;%log%&#39;; 显示结果 123456789101112131415161718| innodb_flush_log_at_timeout | 1 || innodb_flush_log_at_trx_commit | 1 #在事务提交时innodb是否同步日志从缓冲区到文件中，当这个值为1（默认值）之时，在每个事务提交时，日志缓冲被写到日志文件，对日志文件做到磁盘操作的刷新，性能会很差造成大量的磁盘I&#x2F;O但这种方式最安全；如果设为2,每次提交事务都会写日志，但并不会执行刷的操作。每秒定时会刷到日志文件。要注意的是，并不能保证100%每秒一定都会刷到磁盘，这要取决于进程的调度。每次事务提交的时候将数据写入事务日志，而这里的写入仅是调用了文件系统的写入操作，而文件系统是有 缓存的，所以这个写入并不能保证数据已经写入到物理磁盘。设置为0，日志缓冲每秒一次地被写到日志文件，并且对日志文件做到磁盘操作的刷新，但是在一个事务提交不做任何操作。注：刷写的概念刷写其实是两个操作，刷（flush）和写（write），区分这两个概念是很重要的。在大多数的操作系统中，把Innodb的log buffer（内存）写入日志（调用系统调用write），只是简单的把数据移到操作系统缓存中，操作系统缓存同样指的是内存。并没有实际的持久化数据。所以，通常设为0和2的时候，在崩溃或断电的时候会丢失最后一秒的数据，因为这个时候数据只是存在于操作系统缓存。之所以说“通常”，可能会有丢失不只1秒的数据的情况，比如说执行flush操作的时候阻塞了。总结设为1当然是最安全的，但性能页是最差的（相对其他两个参数而言，但不是不能接受）。如果对数据一致性和完整性要求不高，完全可以设为2,如果只最求性能，例如高并发写的日志服务器，设为0来获得更高性能|| innodb_locks_unsafe_for_binlog | OFF || innodb_log_buffer_size | 16777216 || innodb_log_checksums | ON|| innodb_log_compressed_pages | ON || innodb_log_file_size | 50331648 #日志文件大小 || innodb_log_files_in_group | 2 # DB中设置几组事务日志，默认是2|| innodb_log_group_home_dir | .&#x2F; #定义innodb事务日志组的位置,此位置设置默认为MySQL的datadir | 每个事务日志都是大小为50兆的文件（不同版本的mysql有差异）： 在mysql中默认以ib_logfile0,ib_logfile1名称存在 慢查询日志：slow query log 顾名思义，慢查询日志中记录的是执行时间较长的query，也就是我们常说的slow query。 慢查询日志采用的是简单的文本格式，可以通过各种文本编辑器查看其中的内容。其中 记录了语句执行的时刻，执行所消耗的时间，执行用户，连接主机等相关信息。 慢查询日志的作用： 慢查询日志是用来记录执行时间超过指定时间的查询语句。通过慢查询日志，可以查找出哪些查询语句的执行效率很低，以便进行优化。一般建议开启，它对服务器性能的影响微乎其微，但是可以记录mysql服务器上执行了很长时间的查询语句。可以帮助我们定位性能问题的。MySQL 还提供了专门用来分析满查询日志的工具程序mysqldumpslow，用来帮助数据库管理人员解决可能存在的性能问题。 查看慢查询日志的定义： 1234567891011121314151617181920mysql&gt; show global variables like &#39;%slow_query_log%&#39;;+---------------------+------------------------------------+| Variable_name | Value |+---------------------+------------------------------------+| slow_query_log | OFF || slow_query_log_file | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;192-slow.log |+---------------------+------------------------------------+2 rows in set (0.00 sec)mysql&gt; show global variables like &#39;%long%&#39;;+----------------------------------------------------------+-----------+| Variable_name | Value |+----------------------------------------------------------+-----------+| long_query_time | 10.000000 || performance_schema_events_stages_history_long_size | 10000 || performance_schema_events_statements_history_long_size | 10000 || performance_schema_events_transactions_history_long_size | 10000 || performance_schema_events_waits_history_long_size | 10000 |+----------------------------------------------------------+-----------+5 rows in set (0.00 sec) **启动和设置慢查询日志： ** 方法1：通过配置文件my.cnf开启慢查询日志： 注：在不同的mysql版本中，开启慢查询日志参数不太一样，不过都可以通过 show variables like “%slow%” 和show variables like &quot;%long%&quot;查看出来。 1234567891011mysql&gt; show global variables like &#39;%slow%&#39;;+---------------------------+------------------------------------------+| Variable_name | Value |+---------------------------+------------------------------------------+| log_slow_admin_statements | OFF || log_slow_slave_statements | OFF || slow_launch_time | 2 || slow_query_log | OFF || slow_query_log_file | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;localhost-slow.log |+---------------------------+------------------------------------------+5 rows in set (0.00 sec) 其中： slow_query_log： off关闭状态 on开启状态 slow_query_log_file 慢查询日志存放地点 long_query_time选项来设置一个时间值，时间以秒为单位，可以精确到微秒。如果查询时间超过了这个时间值（默认为10秒），这个查询语句将被记录到慢查询日志中, 设置为0的话表示记录所有的查询。 slow_launch_time 表示如果建立线程花费了比这个值更长的时间,slow_launch_threads 计数器将增加 注：如果不指定存储路径，慢查询日志默认存储到mysql数据库的数据文件下，如果不指定文件名，默认文件名为hostname-slow.log 修改my.cnf文件： 12345[mysqld]slow_query_log=1slow_query_log_file=/usr/local/mysql/data/mysql-slow.loglong_query_time=1slow_launch_time=1 重启mysqld服务 再次查询慢查询日志定义 方法2：通过登录mysql服务器直接定义，方式如下： 123456mysql&gt;set global slow_query_log&#x3D;1; #开启慢查询日志Query OK, 0 rowsaffected (0.35 sec)mysql&gt;set session long_query_time&#x3D;0.0001; #更改时间（当前session中，退出则重置）Query OK, 0 rowsaffected (0.00 sec)mysql&gt;set global long_query_time&#x3D;0.0001; #更改时间（全局中，重启服务则重置）mysql&gt; SHOW VARIABLES LIKE &#39;long%&#39;; #查询定义时间 查看慢查询日志 12345678mysql&gt; use mysqlmysql&gt; select user,host from user where user&#x3D;&quot;root&quot;; +------+-----------+| user | host |+------+-----------+| root | localhost |+------+-----------+1 row in set (0.02 sec) 或用系统查看文件内容命令如cat直接查看慢日志文件 第一行表示记录日志时的时间。其格式是 YYYY-MM-DD HH:MM:SS。我们可以看出上面的查询记录于 2016 年 8 月 29 日下午 15:47：24 - 注意：这个是服务器时间. MySql 用户、服务器以及主机名第三行表示总的查询时间、锁定时间、&quot;发送&quot;或者返回的行数 Query_time: 0.000304 表示用了0.000304秒 Lock_time: 0.000128 表示锁了0.000128秒 Rows_sent: 4 表示返回4行 Rows_examined: 4 表示一共查了4行 SETtimestamp=UNIXTIME; 这是查询实际发生的时间 何将其变成一个有用的时间，将 Unix 时间转成一个可读的时间，可以使用 date –d@日志中的时间戳可以看到查询进行的同时记录了该日志 ，但是对于一台超负载的服务器常常并非如此。因此记住：SETtimestamp= value 才是实际的查询的执行时间。 慢查询分析mysqldumpslow 们可以通过打开log文件查看得知哪些SQL执行效率低下。从日志中，可以发现查询时间超过long_query_time时间的query为慢查询，而小于long_query_time时间的没有出现在此日志中。 如果慢查询日志中记录内容很多，可以使用mysqldumpslow工具（MySQL客户端安装自带）来对慢查询日志进行分类汇总。mysqldumpslow对日志文件进行了分类汇总，显示汇总后摘要结果 进入log的存放目录，运行 1[root@localhost data]# mysqldumpslow mysqld-slow.log 123456注： mysqldumpslow -s c -t 10 &#x2F;database&#x2F;mysql&#x2F;slow-query.log 这会输出记录次数最多的10条SQL语句，其中： -s, 是表示按照何种方式排序，c、t、l、r分别是按照记录次数、时间、查询时间、返回的记录数来排序，ac、at、al、ar，表示相应的倒序； -t, 是top n的意思，即为返回前面多少条的数据； -g, 后边可以写一个正则匹配模式，大小写不敏感的； 例如： &#x2F;path&#x2F;mysqldumpslow -s r -t 10&#x2F;database&#x2F;mysql&#x2F;slow-log 得到返回记录集最多的10个查询。&#x2F;path&#x2F;mysqldumpslow -s t -t 10 -g “left join” &#x2F;database&#x2F;mysql&#x2F;slow-log 得到按照时间排序的前10条里面含有左连接的查询语句。","path":"posts/4c37.html","date":"06-17","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"mysql二进制日志","text":"一、什么是二进制日志 MySQL的二进制日志（binary log）是一个二进制文件，主要用于记录修改数据或有可能引起数据变更的MySQL语句。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作，并且记录了语句发生时间、执行时长、操作数据等其它额外信息，但是它不记录SELECT、SHOW等那些不修改数据的SQL语句。二进制日志（binary log）主要用于数据库恢复和主从复制，以及审计（audit）操作。 开启二进制日志对性能的开销很小，带来的好处远大于坏处。 二、开启和设置二进制日志 1、查看二进制日志状态 默认情况下二进制日志是关闭的。 系统变量log_bin的值为OFF表示没有开启二进制日志，ON表示开启了二进制日志，如下所示： 1234567mysql&gt; show variables like &#39;log_bin&#39;;+---------------------------------+------------------------------------+| Variable_name | Value |+---------------------------------+------------------------------------+| log_bin | OFF |+---------------------------------+------------------------------------+1 rows in set (0.00 sec) 2、开启二进制日志 （1）修改配置文件并重启mysql服务 如果需要开启二进制日志，则必须在配置文件中[mysqld]下面添加log-bin [=DIR[filename]] 。 1234DIR参数指定二进制文件的存储路径；filename参数指定二级制文件的文件名。 其中filename可以任意指定，但最好有一定规范。系统变量log_bin是静态参数，不能动态修改的（因为它不是Dynamic Variable）。 内容如下所示： 1234server-id = 1 # mysql5.7必须加，否则mysql服务启动报错log-bin = mysql_bin_log # 路径及命名，默认在data下expire_logs_days = 10 # 过期时间,二进制文件自动删除的天数,0代表不删除max_binlog_size = 100M # 单个日志文件的大小限制，超出会新建一个 操作步骤： Linux下的配置文件为/etc/my.cnf，Windows下的配置文件为my.ini。 12345678910111213141516171819202122232425[root@192 ~]# vim /etc/my.cnf[mysqld]# 省略部分内容server-id = 1 # mysql5.7必须加，否则mysql服务启动报错log-bin = mysql_bin_log # 路径及命名，默认在data下expire_logs_days = 10 # 过期时间,二进制文件自动删除的天数,0代表不删除max_binlog_size = 100M # 单个日志文件大小[root@192 ~]# systemctl restart mysqld.service[root@192 ~]# systemctl status mysqld.service● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 二 2020-06-16 17:47:34 CST; 35s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 78724 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 78701 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 78726 (mysqld) Tasks: 27 CGroup: /system.slice/mysqld.service └─78726 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid6月 16 17:47:25 my_oracle systemd[1]: Starting MySQL Server...6月 16 17:47:34 my_oracle systemd[1]: Started MySQL Server. （2）查看二进制日志状态 重启MySQL后，你就会发现log_bin变为了ON，二进制日志（binary log）默认放在数据目录下（系统变量datadir下）。 show variables like ‘log_bin%’; 1234567891011mysql&gt; show variables like &#39;log_bin%&#39;;+---------------------------------+------------------------------------+| Variable_name | Value |+---------------------------------+------------------------------------+| log_bin | ON || log_bin_basename | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql_bin_log || log_bin_index | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql_bin_log.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF |+---------------------------------+------------------------------------+5 rows in set (0.00 sec) （3）查看当前服务器所有的二进制日志文件 show binary logs; MySQL二进制日志存储了所有的变更信息，MySQL二进制日志经常使用。当MySQL创建二进制日志文件时，首先创建一个以’filename’为名称，以’.index’为后缀的文件；在创建一个以’filename’为名称，以’.000001’为后缀的文件。当MySQL服务重启一次，以’.000001’为后缀的文件会增加一个，并且后缀名加1递增。如果日志长度超过max_binlog_size的上限，也会创建一个新的日志。 Show binary logs;可以查看当前的*二进制日志文件个数及其文件名。二进制日志并不能直接查看，如果想要查看日志内容，可以通过mysqlbinlog命令查看。 1234567mysql&gt; show binary logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000001 | 120 |+----------------------+-----------+1 rows in set (0.00 sec) 或者： show master logs; 1234567mysql&gt; show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000001 | 120 |+----------------------+-----------+1 rows in set (0.00 sec) （4）查看当前二进制日志文件状态 show master status; 1234567mysql&gt; show master status;+----------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+----------------------+----------+--------------+------------------+-------------------+| mysql_bin_log.000001 | 120 | | | |+----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 三、切换二进制日志 执行 flush logs 可以刷新切换二进制文件。 每次重启MySQL服务也会生成一个新的二进制日志文件，相当于二进制日志切换。 1、重启MySQL服务切换日志 （1）重启MySQL服务器前 查看二进制日志状态，如下所示： 1234567mysql&gt; show master status;+----------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+----------------------+----------+--------------+------------------+-------------------+| mysql_bin_log.000001 | 120 | | | |+----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) （2）重启MySQL服务 service mysql restart 1234[root@192 ~]# service mysql restartShutting down MySQL.... SUCCESS! Starting MySQL.. SUCCESS! [root@192 ~]# （3）查看日志 1234567mysql&gt; show master status;+----------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+----------------------+----------+--------------+------------------+-------------------+| mysql_bin_log.000002 | 120 | | | |+----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 2、切换二进制日志并查看 执行flush logs刷新，切换二进制文件，并查看二进制日志状态。如下所示： flush logs; show master status; 12345678910mysql&gt; flush logs;Query OK, 0 rows affected (0.06 sec)mysql&gt; show master status;+----------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+----------------------+----------+--------------+------------------+-------------------+| mysql_bin_log.000003 | 120 | | | |+----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 切换二进制日志时，你会看到这些number会不断递增。另外，除了这些二进制日志文件外，你会看到还生成了一个mysql-bin.index的文件，这个文件中存储所有二进制日志文件的清单又称为二进制文件的索引。 1234567891011[root@192 ~]# ll /var/lib/mysql/#源码安装路径是：/usr/local/mysql/data/-rw-rw----. 1 mysql mysql 171 4月 10 11:25 mysql_bin_log.000001-rw-rw----. 1 mysql mysql 143 4月 10 11:25 mysql_bin_log.000002-rw-rw----. 1 mysql mysql 143 4月 10 11:25 mysql_bin_log.000003-rw-rw----. 1 mysql mysql 92 4月 10 11:25 mysql_bin_log.index[root@192 ~]# cat /var/lib/mysql/mysql_bin_log.index ./mysql_bin_log.000001./mysql_bin_log.000002./mysql_bin_log.000003 四、查看二进制日志 1、查看当前日志 show binlog events; 12345678mysql&gt; show binlog events;+----------------------+-----+-------------+-----------+-------------+---------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+-------------+-----------+-------------+---------------------------------------+| mysql_bin_log.000001 | 4 | Format_desc | 1 | 120 | Server ver: 5.6.42-log, Binlog ver: 4 || mysql_bin_log.000001 | 120 | Rotate | 1 | 171 | mysql_bin_log.000002;pos&#x3D;4 |+----------------------+-----+-------------+-----------+-------------+---------------------------------------+2 rows in set (0.00 sec) 2、查看指定日志 （1）模拟产生二进制日志 建库、建表、插入数据 1234567891011mysql&gt; create database demo;Query OK, 1 row affected (0.00 sec)mysql&gt; use demo;Database changedmysql&gt; create table student(stuNo int, stuName varchar(25));Query OK, 0 rows affected (0.01 sec)mysql&gt; insert into student values(1001,&#39;John&#39;);Query OK, 1 row affected (0.00 sec) （2）查看日志 show binlog events in ‘mysql_bin_log.000002’; 123456789101112mysql&gt; show binlog events in &#39;mysql_bin_log.000002&#39;;+----------------------+-----+-------------+-----------+-------------+------------------------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+-------------+-----------+-------------+------------------------------------------------------------------+| mysql_bin_log.000002 | 4 | Format_desc | 1 | 120 | Server ver: 5.6.42-log, Binlog ver: 4 || mysql_bin_log.000002 | 120 | Query | 1 | 214 | create database demo || mysql_bin_log.000002 | 214 | Query | 1 | 340 | use &#96;demo&#96;; create table student(stuNo int, stuName varchar(25)) || mysql_bin_log.000002 | 340 | Query | 1 | 419 | BEGIN || mysql_bin_log.000002 | 419 | Query | 1 | 532 | use &#96;demo&#96;; insert into student values(1001,&#39;John&#39;) || mysql_bin_log.000002 | 532 | Xid | 1 | 563 | COMMIT &#x2F;* xid&#x3D;15 *&#x2F; |+----------------------+-----+-------------+-----------+-------------+------------------------------------------------------------------+6 rows in set (0.00 sec) show binlog events in ‘mysql_bin_log.000002’ from 419; 查看某个节点 12345678mysql&gt; show binlog events in &#39;mysql_bin_log.000002&#39; from 419;+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| mysql_bin_log.000002 | 419 | Query | 1 | 532 | use &#96;demo&#96;; insert into student values(1001,&#39;John&#39;) || mysql_bin_log.000002 | 532 | Xid | 1 | 563 | COMMIT &#x2F;* xid&#x3D;15 *&#x2F; |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+2 rows in set (0.00 sec) show binlog events in ‘mysql_bin_log.000002’ from 419 limit 1; 查看从419开始的一条数据 12345678910111213141516mysql&gt; show binlog events in &#39;mysql_bin_log.000002&#39; from 419 limit 1;+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| mysql_bin_log.000002 | 419 | Query | 1 | 532 | use &#96;demo&#96;; insert into student values(1001,&#39;John&#39;) |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+1 row in set (0.00 sec)mysql&gt; show binlog events in &#39;mysql_bin_log.000002&#39; from 419 limit 2;+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| mysql_bin_log.000002 | 419 | Query | 1 | 532 | use &#96;demo&#96;; insert into student values(1001,&#39;John&#39;) || mysql_bin_log.000002 | 532 | Xid | 1 | 563 | COMMIT &#x2F;* xid&#x3D;15 *&#x2F; |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+2 rows in set (0.00 sec) 五、使用二进制日志恢复数据库 如果开启了二进制日志，出现了数据丢失，可以通过二进制日志恢复数据库，语法如下： 1mysqlbinlog [option] filename | mysql -u user -p passwd option的参数主要有两个 --start-datetime --stop-datetime 和 start-position --stop-position ,前者指定恢复的时间点，后者指定恢复的位置（位置指的是二进制文件中 # at 580 580就是位置），原理就是把记录的语句重新执行了一次。如果恢复了两次。会产生重复数据。 1、按时间点恢复数据 （1）从日志开头截止到某个时间点的恢复 1mysqlbinlog [--no-defaults] --stop-datetime&#x3D;’年-月-日 小时:分钟:秒’ 二进制日志 | mysql -u 用户名 -p 例如： 1mysqlbinlog [--no-defaults] --stop-datetime=’2020-03-18 10:30:26’ /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -p （2）从某个时间点到日志结尾的恢复 1mysqlbinlog [--no-defaults] --start-datetime&#x3D;’年-月-日 小时:分钟:秒’ 二进制日志 | mysql -u 用户名 -p 例如： 1mysqlbinlog [--no-defaults] --start-datetime=’2020-01-10 8:20:20’ /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -p （3）从某个时间点到某个时间点的恢复 1mysqlbinlog [--no-defaults] --start-datetime&#x3D;’年-月-日 小时:分钟:秒’ --stop-datetime&#x3D;’年-月-日小时:分钟:秒’ 二进制日志 | mysql -u 用户名 -p 例如： 1mysqlbinlog [--no-defaults] --start-datetime=’2010-11-10 8:20:20’ --stop-datetime=’2020-03-18 10:30:26’ /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -p 2、按位置恢复数据 （1）从某个位置到日志结尾的恢复 123/usr/local/mysql/bin/mysqlbinlog --start-position='275' /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -pEnter password: [root@bogon ~]# （2）从日志开头位置到日志结尾的恢复 123/usr/local/mysql/bin/mysqlbinlog --stop-position='465' /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -pEnter password: [root@bogon ~]# （3）从某个位置到某个位置的恢复 123/usr/local/mysql/bin/mysqlbinlog --start-position='4' --stop-position='120' /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -pEnter password: [root@bogon ~]# 例子 123456789101112131415161718192021222324252627mysql&gt; drop database demo;Query OK, 1 row affected (0.00 sec)mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec)[root@192 ~]# &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqlbinlog --start-position&#x3D;&#39;4&#39; --stop-position&#x3D;&#39;313&#39; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql_bin_log.000002 | mysql -uroot -pmysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || demo || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec) 六、删除二进制日志 1、删除某个日志之前的所有二进制日志文件 purge binary logs to xxx; 表示删除某个日志之前的所有二进制日志文件，这个命令会修改index中相关数据。 如下所示： 12345678910111213141516171819202122232425mysql&gt; show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000001 | 143 || mysql_bin_log.000002 | 586 || mysql_bin_log.000003 | 171 || mysql_bin_log.000004 | 171 || mysql_bin_log.000005 | 120 |+----------------------+-----------+5 rows in set (0.00 sec)mysql&gt; purge binary logs to &#39;mysql_bin_log.000002&#39;;Query OK, 0 rows affected (0.03 sec)mysql&gt; show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000002 | 586 || mysql_bin_log.000003 | 171 || mysql_bin_log.000004 | 171 || mysql_bin_log.000005 | 120 |+----------------------+-----------+4 rows in set (0.00 sec) 查看日志清单： 12345[root@192 ~]# cat /var/lib/mysql/mysql_bin_log.index ./mysql_bin_log.000002./mysql_bin_log.000003./mysql_bin_log.000004./mysql_bin_log.000005 2、清除某个时间点以前的二进制日志文件 12mysql&gt; purge binary logs before &#39;2020-03-10 10:10:00&#39;;Query OK, 0 rows affected (0.00 sec) 3、清除7天前的二进制日志文件 12mysql&gt; purge master logs before date_sub( now( ), interval 7 day);Query OK, 0 rows affected (0.00 sec) 4、清除所有的二进制日志文件（当前不存在主从复制关系） reset之后，从000001开始生成全新空日志。 123456789101112131415161718192021mysql&gt; show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000002 | 586 || mysql_bin_log.000003 | 171 || mysql_bin_log.000004 | 171 || mysql_bin_log.000005 | 120 |+----------------------+-----------+4 rows in set (0.00 sec)mysql&gt; reset master;Query OK, 0 rows affected (0.01 sec)mysql&gt; show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000001 | 120 |+----------------------+-----------+1 row in set (0.00 sec) 5、自动清理二进制日志文件 另外，我们也可以设置expire_logs_days参数，设置自动清理，其默认值为0,表示不启用过期自动删除功能，如果启用了自动清理功能，表示超出此天数的二进制日志文件将被自动删除，自动删除工作通常发生在MySQL启动时或flush日志时。 1234567mysql&gt; show variables like &#39;expire_logs_days&#39;;+------------------+-------+| Variable_name | Value |+------------------+-------+| expire_logs_days | 10 |+------------------+-------+1 row in set (0.00 sec) 七、停止二进制日志 可以通过修改配置文件停止二进制日志功能，但是需要重启数据库，mysql提供了语句可以在线停止二进制功能。 12set sql_log_bin &#x3D; 0 # 停止二进制日志功能set sql_log_bin &#x3D; 1 # 开启二进制日志功能","path":"posts/af18.html","date":"06-17","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"mysql日志","text":"mysql日志 MySQL日志记录了MySQL数据库日常操作和错误信息。MySQL有不同类型的日志文件（各自存储了不同类型的日志），从日志当中可以查询到MySQL数据库的运行情况、用户的操作、错误的信息等。 A：MySQL日志分为4大类 错误日志：记录mysql服务的启动，运行或停止mysql服务时出现的问题 查询日志：记录建立的客户端的连接和执行的语句 二进制日志：记录所有更改数据的语句，可以用于数据的复制 慢查询日志：记录所有执行的时间超过long_query_time的所有查询或不使用索引的查询 默认情况下，所有日志创建与MySQL数据目录中，通过刷新日志，可以强制MySQL关闭和重新打开日志文件，Flush logs刷新日志或者执行mysqladmin flush-logs 如果正使用MySQL复制功能，在复制服务器上可以维护更多日志文件，这种日志我们称为接替日志。启动日志功能会降低MySQL数据库的性能。 B：错误日志：Error Log 在mysql数据库中，错误日志功能是默认开启的。默认情况下，错误日志存储在mysql数据库的数据目录中。错误日志文件通常的名称为hostname.err。其中，hostname表示服务器主机名。 错误日志信息可以自己进行配置的，错误日志所记录的信息是可以通过log-error和log-warnings来定义的，其中log-error是定义是否启用错误日志的功能和错误日志的存储位置，log-warnings是定义是否将警告信息也定义至错误日志中。默认情况下错误日志大概记录以下几个方面的信息：服务器启动和关闭过程中的信息（未必是错误信息，如mysql如何启动InnoDB的表空间文件的、如何初始化自己的存储引擎的等等）、服务器运行过程中的错误信息、事件调度器运行一个事件时产生的信息、在从服务器上启动服务器进程时产生的信息 注1：MySQL有很多系统变量可以设置，系统变量设置不同，会导致系统运行状态的不同。因此mysql提供两组命令，分别查看系统设置和运行状态。 C：MySQL日志缓存 一个高速、稳定、可靠的系统，缓存在其中必定起着至关重要的作用。MySQL日志处理也使用了缓存机制。MySQL日志最初存放在MySQL服务器的内存中，若超过指定的存储容量，内存中的日志则写（或者刷新flush）到外存中，以数据库表或者以文件的方式永远的保存在硬盘中。 1、查看系统设置： 1SHOW [GLOBAL | SESSION] VARIABLES [like_or_where] SHOW VARIABLES： shows the values of MySQL system variables. 2、运行状态： 1SHOW [GLOBAL | SESSION] STATUS [like_or_where] SHOW STATUS： provides server status information. D：如何修改系统配置 方法1：配置文件设置my.cnf 如：binlog_cache_size = 1M 方法2：set global binlog_cache_size = 1048576; 注 2：查看mysql的版本 12[root@localhost ~]# mysql -Vmysql Ver 14.14 Distrib 5.7.28, for Linux (x86_64) using EditLine wrapper 或 12345678910111213141516171819202122mysql&gt; status;--------------mysql Ver 14.14 Distrib 5.7.28, for Linux (x86_64) using EditLine wrapperConnection id: 5Current database:Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: &#39;&#39;Using delimiter: ;Server version: 5.7.28 Source distributionProtocol version: 10Connection: Localhost via UNIX socketServer characterset: utf8Db characterset: utf8Client characterset: utf8Conn. characterset: utf8UNIX socket: &#x2F;tmp&#x2F;mysql.sockUptime: 1 hour 12 min 8 secThreads: 1 Questions: 10 Slow queries: 0 Opens: 106 Flush tables: 1 Opentables: 99 Queries per second avg: 0.002-------------- 或 1234567mysql&gt; select version();+-----------+| version() |+-----------+| 5.7.28 |+-----------+1 row in set (0.00 sec) E: 一般而言，日志级别的定义没有会话变量都只是在全局级别下进行定义 错误日志的状态： 123456789mysql&gt; show global variables like &#39;%log_error%&#39;;+---------------------+---------------------------------+| Variable_name | Value |+---------------------+---------------------------------+| binlog_error_action | ABORT_SERVER || log_error | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql.err || log_error_verbosity | 3 |+---------------------+---------------------------------+3 rows in set (0.00 sec) 其中 log_error定义为错误日志文件路径 log_error_verbosity: 更改错误日志位置可以使用log-error来设置形式如下 12\\#vi /etc/my.cnflog-error = /usr/local/mysql/data/mysqld.err 查看mysql错误日志： 1#tail /usr/local/mysql/data/mysqld.err 为了方便维护需要，有时候会希望将错误日志中的内容做备份并重新开始记录，这时候就可以利用MySQL 的FLUSH LOGS 命令来告诉MySQL 备份旧日志文件并生成新的日志文件。备份文件名以“.old”结尾。 删除错误日志： 在mysql5.5.7之前：数据库管理员可以删除很长时间之前的错误日志，以保证mysql服务器上的硬盘空间。mysql数据库中，可以使用mysqladmin命令开启新的错误日志。mysqladmin命令的语法如下：mysqladmin –u root –p flush-logs也可以登录mysql数据库中使用FLUSH LOGS语句来开启新的错误日志。 在mysql5.5.7之后：服务器将关闭此项功能。只能使用重命名原来的错误日志文件，手动冲洗日志创建一个新的：方式如下： 123\\# mv mysql.err mysql.old\\# mysqladmin -uroot -p flush-logsEnter password: F： 二进制日志 主要记录MySQL数据库的变化，二进制日志以一种有效的格式，并且是事务安全的方式包含更新日志中可用的信息。二进制日志包含了所有更新了数据或者已经潜在更新了数据。二进制日志还包含关于每个更新数据库的语句的执行时间，它不包含没有修改任何数据的语句。使用二进制日志的主要目的是最大可能地恢复数据库。 启动二进制日志，默认情况下二进制日志是关闭的 编辑配置文件My.ini 或my.cnf 1234567891011[root@localhost ~]# vim &#x2F;etc&#x2F;my.cnf【格式】：[mysqld]log-binexpire_logs_days &#x3D; 10max_binlog_size &#x3D; 100Mlog-bin [&#x3D;path&#x2F;[filename]] &#x2F;&#x2F;二进制日志[路径[指定日志文件的名字Expire_logs_days &#x3D; 10 &#x2F;&#x2F;清除日志的天数Max_binlog_size &#x3D; 100M &#x2F;&#x2F;单个日志文件的大小限制，超出会新建一个默认为1GB【重启mysql】 Show variables 或show variables like 'log_%'; 语句来查询日志设置 123456789101112131415161718192021222324252627mysql&gt; show variables like &#39;log_%&#39;;+---------------------------------+-------------------------------------------------+| Variable_name | Value|+---------------------------------+-------------------------------------------------+| log_bin | ON|| log_bin_trust_function_creators | OFF|| log_error |&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;localhost.localdomain.err || log_output | FILE|| log_queries_not_using_indexes | OFF|| log_slave_updates | OFF|| log_slow_queries | OFF|| log_warnings | 1|+---------------------------------+-------------------------------------------------+8 rows in set (0.00 sec) 【查看二进制日志】 MySQL二进制日志存储了所有的变更信息，MySQL二进制日志经常使用。当MySQL创建二进制日志文件时，首先创建一个以’filename’为名称，以’.index’为后缀的文件；在创建一个以’filename’为名称，以’.000001’为后缀的文件。当MySQL服务重启一次，以’.000001’为后缀的文件会增加一个，并且后缀名加1递增。如果日志长度超过max_binlog_size的上限，也会创建一个新的日志。 Show binary logs;可以查看当前的二进制日志文件个数及其文件名。二进制日志并不能直接查看，如果想要查看日志内容，可以通过mysqlbinlog命令查看 12345678mysql&gt; SHOW BINARY LOGS;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 2189 || mysql-bin.000002 | 107 |+------------------+-----------+2 rows in set (0.06 sec) 【查看二进制日志的内容】 退出mysql在命令行 12345678910[root@localhost data]# mysqlbinlog mysql-bin.000001&#x2F;*!40019 SET @@session.max_insert_delayed_threads&#x3D;0*&#x2F;;&#x2F;*!50003 SET @OLD_COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;0*&#x2F;;DELIMITER &#x2F;*!*&#x2F;;# at 4#170826 11:40:02 server id 1 end_log_pos 107 Start: binlog v 4, server v5.5.22-log created 170826 11:40:02 at startupROLLBACK&#x2F;*!*&#x2F;;BINLOG &#39;... ... 省略 【删除二进制日志】 MySQL的二进制文件可以配置自动删除，同时MySQL提供了手动删除二进制文件的方法RESET MASTER 删除所有的二进制日志文件；PURGE MASTER LOGS只删除部分二进制日志文件。 Reset master; 删除所有二进制日志 Purge master logs to ‘二进制名’ 删除单个二进制日志之前的 12345mysql&gt; PURGE MASTER LOGS TO &quot;mysql-bin.000012&quot;;Query OK, 0 rows affected (0.02 sec)Purge binary logs before ‘date’ 删除指定日期之前的日志mysql&gt; PURGE MASTER LOGS BEFORE &#39;20170101&#39;;Query OK, 0 rows affected (0.07 sec)","path":"posts/b6d.html","date":"06-17","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL创建触发器","text":"一、MySQL创建触发器（CREATE TRIGGER） 基本语法 在 MySQL 5.7 中，可以使用 CREATE TRIGGER 语句创建触发器。 语法格式如下： 123CREATE &lt;触发器名&gt; &lt; BEFORE | AFTER &gt;&lt;INSERT | UPDATE | DELETE &gt;ON &lt;表名&gt; FOR EACH Row&lt;触发器主体&gt; 语法说明如下。 1) 触发器名 触发器的名称，触发器在当前数据库中必须具有唯一的名称。如果要在某个特定数据库中创建，名称前面应该加上数据库的名称。 2) INSERT | UPDATE | DELETE 触发事件，用于指定激活触发器的语句的种类。 注意：三种触发器的执行时间如下。 INSERT：将新行插入表时激活触发器。例如，INSERT 的 BEFORE 触发器不仅能被 MySQL 的 INSERT 语句激活，也能被 LOAD DATA 语句激活。 DELETE： 从表中删除某一行数据时激活触发器，例如 DELETE 和 REPLACE 语句。 UPDATE：更改表中某一行数据时激活触发器，例如 UPDATE 语句。 3) BEFORE | AFTER BEFORE 和 AFTER，触发器被触发的时刻，表示触发器是在激活它的语句之前或之后触发。若希望验证新数据是否满足条件，则使用 BEFORE 选项；若希望在激活触发器的语句执行之后完成几个或更多的改变，则通常使用 AFTER 选项。 4) 表名 与触发器相关联的表名，此表必须是永久性表，不能将触发器与临时表或视图关联起来。在该表上触发事件发生时才会激活触发器。同一个表不能拥有两个具有相同触发时刻和事件的触发器。例如，对于一张数据表，不能同时有两个 BEFORE UPDATE 触发器，但可以有一个 BEFORE UPDATE 触发器和一个 BEFORE INSERT 触发器，或一个 BEFORE UPDATE 触发器和一个 AFTER UPDATE 触发器。 5) 触发器主体 触发器动作主体，包含触发器激活时将要执行的 MySQL 语句。如果要执行多个语句，可使用 BEGIN…END 复合语句结构。 6) FOR EACH ROW 一般是指行级触发，对于受触发事件影响的每一行都要激活触发器的动作。例如，使用 INSERT 语句向某个表中插入多行数据时，触发器会对每一行数据的插入都执行相应的触发器动作。 注意：每个表都支持 INSERT、UPDATE 和 DELETE 的 BEFORE 与 AFTER，因此每个表最多支持 6 个触发器。每个表的每个事件每次只允许有一个触发器。单一触发器不能与多个事件或多个表关联。 另外，在 MySQL 中，若需要查看数据库中已有的触发器，则可以使用 SHOW TRIGGERS 语句。 二、创建 BEFORE 类型触发器 在 test_db 数据库中，数据表 tb_emp8 为员工信息表，包含 id、name、deptId 和 salary 字段，数据表 tb_emp8 的表结构如下所示。 1234567891011121314151617181920mysql&gt; create table tb_emp8( -&gt; id int(11) not null PRIMARY KEY, -&gt; name VARCHAR(22) UNIQUE, -&gt; deptId int(11) not null, -&gt; salary FLOAT DEFAULT 0 -&gt; )charset &#x3D; &#39;utf8mb4&#39;;Query OK, 0 rows affected (0.01 sec)mysql&gt; SELECT * FROM tb_emp8;Empty set (0.07 sec)mysql&gt; DESC tb_emp8;+--------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(22) | YES | UNI | NULL | || deptId | int(11) | NO | MUL | NULL | || salary | float | YES | | 0 | |+--------+-------------+------+-----+---------+-------+4 rows in set (0.05 sec) 【实例 1】 创建一个名为 SumOfSalary 的触发器，触发的条件是向数据表 tb_emp8 中插入数据之前，对新插入的 salary 字段值进行求和计算。输入的 SQL 语句和执行过程如下所示。 12345# 创建触发器create TRIGGER SumOfSalarybefore insert on tb_emp8for each ROWset @sum&#x3D;@sum+NEW.salary; 触发器 SumOfSalary 创建完成之后，向表 tb_emp8 中插入记录时，定义的 sum 值由 0 变成了 1500，即插入值 1000 和 500 的和，如下所示。 123456789101112131415SET @sum&#x3D;0;Query OK, 0 rows affected (0.05 sec)#插入数据，会自动调用触发器会自动调用触发器mysql&gt; INSERT INTO tb_emp8 -&gt; VALUES(1,&#39;A&#39;,1,1000),(2,&#39;B&#39;,1,500);Query OK, 2 rows affected (0.09 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; SELECT @sum;+------+| @sum |+------+| 1500 |+------+1 row in set (0.03 sec) 三、创建 AFTER 类型触发器 在 test_db 数据库中，数据表 tb_emp6 和 tb_emp7 都为员工信息表，包含 id、name、deptId 和 salary 字段，数据表 tb_emp6 和 tb_emp7 的表结构如下所示。 123456789101112131415161718192021222324mysql&gt; SELECT * FROM tb_emp6;Empty set (0.07 sec)mysql&gt; SELECT * FROM tb_emp7;Empty set (0.03 sec)mysql&gt; DESC tb_emp6;+--------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(25) | YES | | NULL | || deptId | int(11) | YES | MUL | NULL | || salary | float | YES | | NULL | |+--------+-------------+------+-----+---------+-------+4 rows in set (0.00 sec)mysql&gt; DESC tb_emp7;+--------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(25) | YES | | NULL | || deptId | int(11) | YES | | NULL | || salary | float | YES | | 0 | |+--------+-------------+------+-----+---------+-------+4 rows in set (0.04 sec) 【实例 2】 创建一个名为 double_salary 的触发器，触发的条件是向数据表 tb_emp6 中插入数据之后，再向数据表 tb_emp7 中插入相同的数据，并且 salary 为 tb_emp6 中新插入的 salary 字段值的 2 倍。输入的 SQL 语句和执行过程如下所示。 123456mysql&gt; CREATE TRIGGER double_salary -&gt; AFTER INSERT ON tb_emp6 -&gt; FOR EACH ROW -&gt; INSERT INTO tb_emp7 -&gt; VALUES (NEW.id,NEW.name,deptId,2*NEW.salary);Query OK, 0 rows affected (0.25 sec) 触发器 double_salary 创建完成之后，向表 tb_emp6 中插入记录时，同时向表 tb_emp7 中插入相同的记录，并且 salary 字段为 tb_emp6 中 salary 字段值的 2 倍，如下所示。 1234567891011121314151617181920212223242526# 插入后触发mysql&gt; INSERT INTO tb_emp6 -&gt; VALUES (1,&#39;A&#39;,1,1000),(2,&#39;B&#39;,1,500);Query OK, 2 rows affected (0.09 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; SELECT * FROM tb_emp6;+----+------+--------+--------+| id | name | deptId | salary |+----+------+--------+--------+| 1 | A | 1 | 1000 || 2 | B | 1 | 500 |+----+------+--------+--------+3 rows in set (0.04 sec)mysql&gt; SELECT * FROM tb_emp7;+----+------+--------+--------+| id | name | deptId | salary |+----+------+--------+--------+| 1 | A | 1 | 2000 || 2 | B | 1 | 1000 |+----+------+--------+--------+2 rows in set (0.06 sec)#删除触发器drop trigger double_salary;","path":"posts/184.html","date":"06-16","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL触发器","text":"A：MySQL触发器到底是什么？ MySQL 的触发器和存储过程一样，都是嵌入到 MySQL 中的一段程序，是 MySQL 中管理数据的有力工具。不同的是执行存储过程要使用 CALL 语句来调用，而触发器的执行不需要使用 CALL 语句来调用，也不需要手工启动，而是通过对数据表的相关操作来触发、激活从而实现执行。比如当对 student 表进行操作（INSERT，DELETE 或 UPDATE）时就会激活它执行。 触发器与数据表关系密切，主要用于保护表中的数据。特别是当有多个表具有一定的相互联系的时候，触发器能够让不同的表保持数据的一致性。 在 MySQL 中，只有执行 INSERT、UPDATE 和 DELETE 操作时才能激活触发器，其它 SQL 语句则不会激活触发器。 那么为什么要使用触发器呢？比如，在实际开发项目时，我们经常会遇到以下情况： 在学生表中添加一条关于学生的记录时，学生的总数就必须同时改变。 增加一条学生记录时，需要检查年龄是否符合范围要求。 删除一条学生信息时，需要删除其成绩表上的对应记录。 删除一条数据时，需要在数据库存档表中保留一个备份副本。 虽然上述情况实现的业务逻辑不同，但是它们都需要在数据表发生更改时，自动进行一些处理。这时就可以使用触发器处理。例如，对于第一种情况，可以创建一个触发器对象，每当添加一条学生记录时，就执行一次计算学生总数的操作，这样就可以保证每次添加一条学生记录后，学生总数和学生记录数是一致的。 B: 触发器的优缺点 触发器的优点如下： 触发器的执行是自动的，当对触发器相关表的数据做出相应的修改后立即执行。 触发器可以实施比 FOREIGN KEY 约束、CHECK 约束更为复杂的检查和操作。 触发器可以实现表数据的级联更改，在一定程度上保证了数据的完整性。 触发器的缺点如下： 使用触发器实现的业务逻辑在出现问题时很难进行定位，特别是涉及到多个触发器的情况下，会使后期维护变得困难。 大量使用触发器容易导致代码结构被打乱，增加了程序的复杂性， 如果需要变动的数据量较大时，触发器的执行效率会非常低。 C：MySQL 支持的触发器 在实际使用中，MySQL 所支持的触发器有三种：INSERT 触发器、UPDATE 触发器和 DELETE 触发器。 1) INSERT 触发器 在 INSERT 语句执行之前或之后响应的触发器。 使用 INSERT 触发器需要注意以下几点： 在 INSERT 触发器代码内，可引用一个名为 NEW（不区分大小写）的虚拟表来访问被插入的行。 在 BEFORE INSERT 触发器中，NEW 中的值也可以被更新，即允许更改被插入的值（只要具有对应的操作权限）。 对于 AUTO_INCREMENT 列，NEW 在 INSERT 执行之前包含的值是 0，在 INSERT 执行之后将包含新的自动生成值。 2) UPDATE 触发器 在 UPDATE 语句执行之前或之后响应的触发器。 使用 UPDATE 触发器需要注意以下几点： 在 UPDATE 触发器代码内，可引用一个名为 NEW（不区分大小写）的虚拟表来访问更新的值。 在 UPDATE 触发器代码内，可引用一个名为 OLD（不区分大小写）的虚拟表来访问 UPDATE 语句执行前的值。 在 BEFORE UPDATE 触发器中，NEW 中的值可能也被更新，即允许更改将要用于 UPDATE 语句中的值（只要具有对应的操作权限）。 OLD 中的值全部是只读的，不能被更新。 注意：当触发器设计对触发表自身的更新操作时，只能使用 BEFORE 类型的触发器，AFTER 类型的触发器将不被允许。 3) DELETE 触发器 在 DELETE 语句执行之前或之后响应的触发器。 使用 DELETE 触发器需要注意以下几点： 在 DELETE 触发器代码内，可以引用一个名为 OLD（不区分大小写）的虚拟表来访问被删除的行。 OLD 中的值全部是只读的，不能被更新。 总体来说，触发器使用的过程中，MySQL 会按照以下方式来处理错误。 对于事务性表，如果触发程序失败，以及由此导致的整个语句失败，那么该语句所执行的所有更改将回滚；对于非事务性表，则不能执行此类回滚，即使语句失败，失败之前所做的任何更改依然有效。 若 BEFORE 触发程序失败，则 MySQL 将不执行相应行上的操作。 若在 BEFORE 或 AFTER 触发程序的执行过程中出现错误，则将导致调用触发程序的整个语句失败。 仅当 BEFORE 触发程序和行操作均已被成功执行，MySQL 才会执行 AFTER 触发程序。","path":"posts/f9da.html","date":"06-15","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL创建存储过程","text":"一、MySQL创建存储过程 1、基本语法 可以使用 CREATE PROCEDURE 语句创建存储过程。 语法格式如下： 123CREATE PROCEDURE &lt;过程名&gt; ( [过程参数[,…] ] ) &lt;过程体&gt;[过程参数[,…] ] 格式[ IN | OUT | INOUT ] &lt;参数名&gt; &lt;类型&gt; 2、语法说明如下： 1) 过程名 存储过程的名称，默认在当前数据库中创建。若需要在特定数据库中创建存储过程，则要在名称前面加上数据库的名称，即 db_name.sp_name。需要注意的是，名称应当尽量避免选取与 MySQL 内置函数相同的名称，否则会发生错误。 2) 过程参数 存储过程的参数列表。其中，&lt;参数名&gt;为参数名，&lt;类型&gt;为参数的类型（可以是任何有效的 MySQL 数据类型）。当有多个参数时，参数列表中彼此间用逗号分隔。存储过程可以没有参数（此时存储过程的名称后仍需加上一对括号），也可以有 1 个或多个参数。 MySQL 存储过程支持三种类型的参数，即输入参数、输出参数和输入/输出参数，分别用 IN、OUT 和 INOUT 三个关键字标识。其中，输入参数可以传递给一个存储过程，输出参数用于存储过程需要返回一个操作结果的情形，而输入/输出参数既可以充当输入参数也可以充当输出参数。 需要注意的是，参数的取名不要与数据表的列名相同，否则尽管不会返回出错信息，但是存储过程的 SQL 语句会将参数名看作列名，从而引发不可预知的结果。 3) 过程体 存储过程的主体部分，也称为存储过程体，包含在过程调用的时候必须执行的 SQL 语句。这个部分以关键字 BEGIN 开始，以关键字 END 结束。若存储过程体中只有一条 SQL 语句，则可以省略 BEGIN-END 标志。 在存储过程的创建中，经常会用到一个十分重要的 MySQL 命令，即 DELIMITER 命令，特别是对于通过命令行的方式来操作 MySQL 数据库的使用者，更是要学会使用该命令。 在 MySQL 中，服务器处理 SQL 语句默认是以分号作为语句结束标志的。然而，在创建存储过程时，存储过程体可能包含有多条 SQL 语句，这些 SQL 语句如果仍以分号作为语句结束符，那么 MySQL 服务器在处理时会以遇到的第一条 SQL 语句结尾处的分号作为整个程序的结束符，而不再去处理存储过程体中后面的 SQL 语句，这样显然不行。 为解决以上问题，通常使用 DELIMITER 命令将结束命令修改为其他字符。语法格式如下： 1DELIMITER $$ 语法说明如下： $$ 是用户定义的结束符，通常这个符号可以是一些特殊的符号，如两个“?”或两个“￥”等。 当使用 DELIMITER 命令时，应该避免使用反斜杠“\\”字符，因为它是 MySQL 的转义字符。 在 MySQL 命令行客户端输入如下 SQL 语句。 1mysql &gt; DELIMITER ?? 成功执行这条 SQL 语句后，任何命令、语句或程序的结束标志就换为两个问号“??”了。 若希望换回默认的分号“;”作为结束标志，则在 MySQL 命令行客户端输入下列语句即可： 1mysql &gt; DELIMITER ; 注意：DELIMITER 和分号“;”之间一定要有一个空格。在创建存储过程时，必须具有 CREATE ROUTINE 权限。可以使用 SHOW PROCEDURE STATUS 命令查看数据库中存在哪些存储过程，若要查看某个存储过程的具体信息，则可以使用 SHOW CREATE PROCEDURE &lt;存储过程名&gt;。 3、创建不带参数的存储过程 例 1 创建名称为 ShowStuScore 的存储过程，存储过程的作用是从学生成绩信息表中查询学生的成绩信息，输入的 SQL 语句和执行过程如下所示。 123456mysql&gt; DELIMITER //mysql&gt; CREATE PROCEDURE ShowStuScore() -&gt; BEGIN -&gt; SELECT * FROM tb_students_score; -&gt; END //Query OK， 0 rows affected (0.09 sec) 创建存储过程 ShowStuScore 后，通过 CALL 语句调用该存储过程的 SQL 语句和执行结果如下所示。 123456789101112131415161718mysql&gt; DELIMITER ;mysql&gt; CALL ShowStuScore();+--------------+---------------+| student_name | student_score |+--------------+---------------+| Dany | 90 || Green | 99 || Henry | 95 || Jane | 98 || Jim | 88 || John | 94 || Lily | 100 || Susan | 96 || Thomas | 93 || Tom | 89 |+--------------+---------------+10 rows in set (0.00 sec)Query OK, 0 rows affected (0.02 sec) 例 2 12345678910# 创建存储过程delimiter $$create PROCEDURE test_bank()BEGINselect * from bank;END$$# 调用存储过程delimiter ;call test_bank(); 4、创建带参数的存储过程 例 3 创建名称为 GetScoreByStu 的存储过程，输入参数是学生姓名。存储过程的作用是通过输入的学生姓名从学生成绩信息表中查询指定学生的成绩信息，输入的 SQL 语句和执行过程如下所示。 12345678mysql&gt; DELIMITER &#x2F;&#x2F;mysql&gt; CREATE PROCEDURE GetScoreByStu -&gt; (IN name VARCHAR(30)) -&gt; BEGIN -&gt; SELECT student_score FROM tb_students_score -&gt; WHERE student_name&#x3D;name; -&gt; END &#x2F;&#x2F;Query OK, 0 rows affected (0.01 sec) 创建存储过程 GetScoreByStu 后，通过 CALL 语句调用该存储过程，SQL 语句和执行结果如下所示。 123456789mysql&gt; DELIMITER ;mysql&gt; CALL GetScoreByStu(&#39;Green&#39;);+---------------+| student_score |+---------------+| 99 |+---------------+1 row in set (0.03 sec)Query OK, 0 rows affected (0.03 sec) 例 4 12345678910# 创建带参数的存储过程delimiter $$create PROCEDURE show_customer(in name VARCHAR(20))BEGINselect * from bank where cusName&#x3D;name;END $$#调用带参数的存储过程delimiter ;call show_customer(&#39;zs&#39;); 二、存储过程的参数 MySQL存储过程的参数用在存储过程的定义，共有三种参数类型,IN,OUT,INOUT,形式如： 1CREATEPROCEDURE 存储过程名([[IN |OUT |INOUT ] 参数名 数据类形...]) IN 输入参数：表示调用者向过程传入值（传入值可以是字面量或变量） OUT 输出参数：表示过程向调用者传出值(可以返回多个值)（传出值只能是变量） INOUT 输入输出参数：既表示调用者向过程传入值，又表示过程向调用者传出值（值只能是变量） 1、in 输入参数 123456789101112# 存储过程的参数delimiter $$create PROCEDURE test(in p_in int)BEGIN SELECT p_in; set p_in &#x3D; 2; select p_in;END $$ delimiter ; set @p_in&#x3D;1;call in_param(@p_in); 1select @p_in; 以上可以看出，p_in 在存储过程中被修改，但并不影响 @p_id 的值，因为前者为局部变量、后者为全局变量。 2、out输出参数 1234567891011121314151617181920212223242526272829303132mysql&gt; delimiter &#x2F;&#x2F;mysql&gt; create procedure out_param(out p_out int) -&gt; begin -&gt; select p_out; -&gt; set p_out&#x3D;2; -&gt; select p_out; -&gt; end -&gt; &#x2F;&#x2F;mysql&gt; delimiter ; mysql&gt; set @p_out&#x3D;1; mysql&gt; call out_param(@p_out);+-------+| p_out |+-------+| NULL |+-------+ #因为out是向调用者输出参数，不接收输入的参数，所以存储过程里的p_out为null+-------+| p_out |+-------+| 2 |+-------+ mysql&gt; select @p_out;+--------+| @p_out |+--------+| 2 |+--------+ #调用了out_param存储过程，输出参数，改变了p_out变量的值 3、inout输入参数 1234567891011121314151617181920212223242526272829303132mysql&gt; delimiter $$mysql&gt; create procedure inout_param(inout p_inout int) -&gt; begin -&gt; select p_inout; -&gt; set p_inout&#x3D;2; -&gt; select p_inout; -&gt; end -&gt; $$mysql&gt; delimiter ; mysql&gt; set @p_inout&#x3D;1; mysql&gt; call inout_param(@p_inout);+---------+| p_inout |+---------+| 1 |+---------+ +---------+| p_inout |+---------+| 2 |+---------+ mysql&gt; select @p_inout;+----------+| @p_inout |+----------+| 2 |+----------+#调用了inout_param存储过程，接受了输入的参数，也输出参数，改变了变量 注意： 1、如果过程没有参数，也必须在过程名后面写上小括号例： 1CREATE PROCEDURE sp_name ([proc_parameter[,...]]) …… 2、确保参数的名字不等于列的名字，否则在过程体中，参数名被当做列名来处理 建议： 输入值使用in参数。 返回值使用out参数。 inout参数就尽量的少用。 三、MySQL删除存储过程（DROP PROCEDURE） 存储过程被创建后，就会一直保存在数据库服务器上，直至被删除。当 MySQL 数据库中存在废弃的存储过程时，我们需要将它从数据库中删除。 MySQL 中使用 DROP PROCEDURE 语句来删除数据库中已经存在的存储过程。语法格式如下： 1DROP &#123; PROCEDURE | FUNCTION &#125; [ IF EXISTS ] &lt;过程名&gt; 语法说明如下： 过程名：指定要删除的存储过程的名称。 IF EXISTS：指定这个关键字，用于防止因删除不存在的存储过程而引发的错误。 注意：存储过程名称后面没有参数列表，也没有括号，在删除之前，必须确认该存储过程没有任何依赖关系，否则会导致其他与之关联的存储过程无法运行。 实例 1 下面删除存储过程 showstuscore，SQL 语句和运行结果如下： 12mysql&gt; DROP PROCEDURE test;Query OK, 0 rows affected (0.08 sec) 删除后，可以通过查询 information_schema 数据库下的 routines 表来确认上面的删除是否成功。SQL 语句和运行结果如下： 12mysql&gt; SELECT * FROM information_schema.routines WHERE routine_name='showstuscore';Empty set (0.03 sec) 结果显示，没有查询出任何记录，说明存储过程 showstuscore 已经被删除了。","path":"posts/bc0b.html","date":"06-14","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL存储过程","text":"A：MySQL存储过程简介 我们前面所学习的 MySQL 语句都是针对一个表或几个表的单条 SQL 语句，但是在数据库的实际操作中，经常会有需要多条 SQL 语句处理多个表才能完成的操作。 例如，为了确认学生能否毕业，需要同时查询学生档案表、成绩表和综合表，此时就需要使用多条 SQL 语句来针对这几个数据表完成处理要求。 存储过程是一组为了完成特定功能的 SQL 语句集合。使用存储过程的目的是将常用或复杂的工作预先用 SQL 语句写好并用一个指定名称存储起来，这个过程经编译和优化后存储在数据库服务器中，因此称为存储过程。当以后需要数据库提供与已定义好的存储过程的功能相同的服务时，只需调用“CALL存储过程名字”即可自动完成。 常用操作数据库的 SQL 语句在执行的时候需要先编译，然后执行。存储过程则采用另一种方式来执行 SQL 语句。 一个存储过程是一个可编程的函数，它在数据库中创建并保存，一般由 SQL 语句和一些特殊的控制结构组成。当希望在不同的应用程序或平台上执行相同的特定功能时，存储过程尤为合适。 MySQL 5.0 版本以前并不支持存储过程，这使 MySQL 在应用上大打折扣。MySQL 从 5.0 版本开始支持存储过程，既提高了数据库的处理速度，同时也提高了数据库编程的灵活性 存储过程是数据库中的一个重要功能，存储过程可以用来转换数据、数据迁移、制作报表，它类似于编程语言，一次执行成功，就可以随时被调用，完成指定的功能操作。 使用存储过程不仅可以提高数据库的访问效率，同时也可以提高数据库使用的安全性。 对于调用者来说，存储过程封装了 SQL 语句，调用者无需考虑逻辑功能的具体实现过程。只是简单调用即可，它可以被 Java 和 C# 等编程语言调用。 B：存储过程有如下优点： 1) 封装性 通常完成一个逻辑功能需要多条 SQL 语句，而且各个语句之间很可能传递参数，所以，编写逻辑功能相对来说稍微复杂些，而存储过程可以把这些 SQL 语句包含到一个独立的单元中，使外界看不到复杂的 SQL 语句，只需要简单调用即可达到目的。并且数据库专业人员可以随时对存储过程进行修改，而不会影响到调用它的应用程序源代码。 2) 可增强 SQL 语句的功能和灵活性 存储过程可以用流程控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。 3) 可减少网络流量 由于存储过程是在服务器端运行的，且执行速度快，因此当客户计算机上调用该存储过程时，网络中传送的只是该调用语句，从而可降低网络负载。 4) 高性能 当存储过程被成功编译后，就存储在数据库服务器里了，以后客户端可以直接调用，这样所有的 SQL 语句将从服务器执行，从而提高性能。但需要说明的是，存储过程不是越多越好，过多的使用存储过程反而影响系统性能。 5) 提高数据库的安全性和数据的完整性 存储过程提高安全性的一个方案就是把它作为中间组件，存储过程里可以对某些表做相关操作，然后存储过程作为接口提供给外部程序。这样，外部程序无法直接操作数据库表，只能通过存储过程来操作对应的表，因此在一定程度上，安全性是可以得到提高的。 6) 使数据独立 数据的独立可以达到解耦的效果，也就是说，程序可以调用存储过程，来替代执行多条的 SQL 语句。这种情况下，存储过程把数据同用户隔离开来，优点就是当数据表的结构改变时，调用表不用修改程序，只需要数据库管理者重新编写存储过程即可。 C：MySQL存储过程的优点 通常存储过程有助于提高应用程序的性能。当创建，存储过程被编译之后，就存储在数据库中。 但是，MySQL实现的存储过程略有不同。 MySQL存储过程按需编译。 在编译存储过程之后，MySQL将其放入缓存中。 MySQL为每个连接维护自己的存储过程高速缓存。 如果应用程序在单个连接中多次使用存储过程，则使用编译版本，否则存储过程的工作方式类似于查询。 存储过程有助于减少应用程序和数据库服务器之间的流量，因为应用程序不必发送多个冗长的SQL语句，而只能发送存储过程的名称和参数。 存储的程序对任何应用程序都是可重用的和透明的。 存储过程将数据库接口暴露给所有应用程序，以便开发人员不必开发存储过程中已支持的功能。 存储的程序是安全的。 数据库管理员可以向访问数据库中存储过程的应用程序授予适当的权限，而不向基础数据库表提供任何权限。 D：MySQL存储过程的缺点 如果使用大量存储过程，那么使用这些存储过程的每个连接的内存使用量将会大大增加。 此外，如果您在存储过程中过度使用大量逻辑操作，则CPU使用率也会增加，因为数据库服务器的设计不当于逻辑运算。 存储过程的构造使得开发具有复杂业务逻辑的存储过程变得更加困难。 很难调试存储过程。只有少数数据库管理系统允许您调试存储过程。不幸的是，MySQL不提供调试存储过程的功能。 开发和维护存储过程并不容易。开发和维护存储过程通常需要一个不是所有应用程序开发人员拥有的专业技能。这可能会导致应用程序开发和维护阶段的问题。","path":"posts/ae29.html","date":"06-13","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL用户管理（2）","text":"一、MySQL root修改普通用户密码 1、使用SET语句修改普通用户的密码 在 MySQL 中，只有 root 用户可以通过更新 MySQL 数据库来更改密码。使用 root 用户登录到 MySQL 服务器后，可以使用 SET 语句来修改普通用户密码。语法格式如下： 1SET PASSWORD FOR &#39;username&#39;@&#39;hostname&#39; &#x3D; PASSWORD (&#39;newpwd&#39;); 其中，username 参数是普通用户的用户名，hostname 参数是普通用户的主机名，newpwd 是要更改的新密码。 注意：新密码必须使用 PASSWORD() 函数来加密，如果不使用 PASSWORD() 加密，也会执行成功，但是用户会无法登录。 如果是普通用户修改密码，可省略 FOR 子句来更改自己的密码。语法格式如下： 1SET PASSWORD &#x3D; PASSWORD(&#39;newpwd&#39;); 示例 1 首先创建一个没有密码的 testuser 用户，SQL 语句和运行结果如下： 12mysql&gt; CREATE USER &#39;testuser&#39;@&#39;localhost&#39;;Query OK, 0 rows affected (0.14 sec) root 用户登录 MySQL 服务器后，再使用 SET 语句将 testuser 用户的密码修改为“newpwd”，SQL 语句和运行结果如下： 12mysql&gt; SET PASSWORD FOR &#39;testuser&#39;@&#39;localhost&#39; &#x3D; PASSWORD(&quot;newpwd&quot;);Query OK, 0 rows affected, 1 warning (0.01 sec) 由运行结果可以看出，SET 语句执行成功，testuser 用户的密码被成功设置为“newpwd”。 下面验证 testuser 用户密码是否修改成功。退出 MySQL 服务器，使用 testuser 用户登录，输入密码“newpwd”，SQL 语句和运行结果如下： 12345678910111213C:\\Users\\leovo&gt;mysql -utestuser -pEnter password: ******Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 15Server version: 5.7.29-log MySQL Community Server (GPL) Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners. Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement. 由运行结果可以看出，testuser 用户登录成功，修改密码成功。 示例 2 使用 testuser 用户登录 MySQL 服务器，再使用 SET 语句将密码更改为“newpwd1”，SQL 语句和运行结果如下所示： 12mysql&gt; SET PASSWORD &#x3D; PASSWORD(&#39;newpwd1&#39;);Query OK, 0 rows affected, 1 warning (0.00 sec) 由运行结果可以看出，修改密码成功。 2、使用UPDATE语句修改普通用户的密码 使用 root 用户登录 MySQL 服务器后，可以使用 UPDATE 语句修改 MySQL 数据库的 user 表的 authentication_string 字段，从而修改普通用户的密码。UPDATA 语句的语法如下： 1UPDATE MySQL.user SET authentication_string &#x3D; PASSWORD(&quot;newpwd&quot;) WHERE User &#x3D; &quot;username&quot; AND Host &#x3D; &quot;hostname&quot;; 其中，username 参数是普通用户的用户名，hostname 参数是普通用户的主机名，newpwd 是要更改的新密码。 注意，执行 UPDATE 语句后，需要执行 FLUSH PRIVILEGES 语句重新加载用户权限。 示例 3 使用 root 用户登录 MySQL 服务器，再使用 UPDATE 语句将 testuser 用户的密码修改为“newpwd2”的 SQL 语句和运行结果如下： 123456mysql&gt; UPDATE MySQL.user SET authentication_string &#x3D; PASSWORD (&quot;newpwd2&quot;) -&gt; WHERE User &#x3D; &quot;testuser&quot; AND Host &#x3D; &quot;localhost&quot;;Query OK, 1 row affected, 1 warning (0.07 sec)Rows matched: 1 Changed: 1 Warnings: 1mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.03 sec) 由运行结果可以看出，密码修改成功。testuser 的密码被修改成了 newpwd2。使用 FLUSH PRIVILEGES 重新加载权限后，就可以使用新的密码登录 testuser 用户了。 3、使用 GRANT 语句修改普通用户密码 除了前面介绍的方法，还可以在全局级别使用 GRANT USAGE 语句指定某个账户的密码而不影响账户当前的权限。需要注意的是，使用 GRANT 语句修改密码，必须拥有 GRANT 权限。一般情况下最好使用该方法来指定或修改密码。语法格式如下： 1GRANT USAGE ON *.* TO &#39;user&#39;@’hostname’ IDENTIFIED BY &#39;newpwd&#39;; 其中，username 参数是普通用户的用户名，hostname 参数是普通用户的主机名，newpwd 是要更改的新密码。 示例 4 使用 root 用户登录 MySQL 服务器，再使用 GRANT 语句将 testuser 用户的密码修改为“newpwd3”，SQL 语句和运行结果如下： 12mysql&gt; GRANT USAGE ON *.* TO &#39;testuser&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;newpwd3&#39;;Query OK, 0 rows affected, 1 warning (0.05 sec) 由运行结果可以看出，密码修改成功。 二、MySQL修改root密码 1、使用mysqladmin命令在命令行指定新密码 root 用户可以使用 mysqladmin 命令来修改密码，mysqladmin 的语法格式如下： 1mysqladmin -u username -h hostname -p password &quot;newpwd&quot; 语法参数说明如下： usermame 指需要修改密码的用户名称，在这里指定为 root 用户； hostname 指需要修改密码的用户主机名，该参数可以不写，默认是 localhost； password 为关键字，而不是指旧密码； newpwd 为新设置的密码，必须用双引号括起来。如果使用单引号会引发错误，可能会造成修改后的密码不是你想要的。 执行完上面的语句，root 用户的密码将被修改为“newpwd”。 示例 1 下面使用 mysqladmin 将 root 用户的密码修改为“rootpwd”，在 Windows 命令行窗口（cmd）中执行命令和运行结果如下： 1234C:\\Users\\leovo&gt;mysqladmin -u root -p password &quot;rootpwd&quot;Enter password: ****mysqladmin: [Warning] Using a password on the command line interface can be insecure.Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety. 输入 mysqladmin 命令后，按回车键，然后输入 root 用户原来的密码。执行完毕后，密码修改成功，root 用户登录时将使用新的密码。 运行结果中，输入密码后会提示在命令行界面上使用密码可能不安全的警告信息，因为在命令行输入密码时，MySQL 服务器就会提示这些安全警告信息。 下面使用修改后的“rootpwd”密码登录 root 用户，SQL 语句和运行结果如下： 12345678910111213C:\\Users\\leovo&gt;mysql -uroot -pEnter password: *******Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 23Server version: 5.7.29-log MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement. 结果显示，root 用户登录成功，所以使用 mysqladmin 命令修改 root 用户密码成功。 2、修改MySQL数据库的user表 因为所有账户信息都保存在 user 表中，因此可以直接通过修改 user 表来改变 root 用户的密码。 root 用户登录到 MySQL 服务器后，可以使用 UPDATE 语句修改 MySQL 数据库的 user 表的 authentication_string 字段，从而修改用户的密码。 使用 UPDATA 语句修改 root 用户密码的语法格式如下： 1UPDATE mysql.user set authentication_string &#x3D; PASSWORD (&quot;rootpwd) WHERE User &#x3D; &quot;root&quot; and Host&#x3D;&quot;localhost&quot;; 新密码必须使用 PASSWORD() 函数来加密。执行UPDATE语句后，需要执行FLUSH PRIVILEGES语句重新加载用户权限。 示例 2 下面使用 UPDATE 语句将 root用户的密码修改为“rootpwd2”。 使用 root 用户登录到 MySQL 服务器后，SQL 语句和运行结果如下所示： 123456mysql&gt; UPDATE mysql.user set authentication_string &#x3D; password (&quot;rootpwd2&quot;) -&gt; WHERE User &#x3D; &quot;root&quot; and Host &#x3D; &quot;localhost&quot;;Query OK, 1 row affected, 0 warning (0.00 sec)Rows matched: 1 Changed: 1 Warnings:0mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.06 sec) 结果显示，密码修改成功。而且使用了FLUSH PRIVILEGES;语句加载权限。退出后就必须使用新密码来登录了。 3、使用SET语句修改root用户的密码 SET PASSWORD 语句可以用来重新设置其他用户的登录密码或者自己使用的账户的密码。使用 SET 语句修改密码的语法结构如下： 1SET PASSWORD &#x3D; PASSWORD (&quot;rootpwd&quot;); 示例 3 下面使用 SET 语句将 root 用户的密码修改为“rootpwd3”。 使用 root 用户登录到 MySQL 服务器后，SQL 语句和运行结果如下所示： 12MySQL&gt; SET PASSWORD &#x3D; password (&quot;rootpwd3&quot;);Query OK, 0 rows affected (0.00 sec) 结果显示，SET 语句执行成功，root 用户的密码被成功设置为“rootpwd3”。 三、MySQL忘记root密码解决方案 在忘记 MySQL 密码的情况下，可以通过 --skip-grant-tables 关闭服务器的认证，然后重置 root 的密码，具体操作步骤如下。 步骤 1)：关闭正在运行的 MySQL 服务。打开 cmd 进入 MySQL 的 bin 目录。 步骤 2)：输入mysqld --console --skip-grant-tables --shared-memory 命令。–skip-grant-tables 会让 MySQL 服务器跳过验证步骤，允许所有用户以匿名的方式，无需做密码验证就可以直接登录 MySQL 服务器，并且拥有所有的操作权限。 步骤 3)：上一个 DOS 窗口不要关闭，打开一个新的 DOS 窗口，此时仅输入 mysql 命令，不需要用户名和密码，即可连接到 MySQL。 步骤 4)：输入命令 update mysql.user set authentication_string=password('root') where user='root' and Host ='localhost'; 设置新密码。 注意：MySQL 5.7 版本中的 user 表里已经去掉了 password 字段，改为了 authentication_string。 步骤 5)：刷新权限（必须步骤），输入flush privileges;命令。 步骤 6)：因为之前使用 --skip-grant-tables 启动，所以需要重启 MySQL 服务器去掉 --skip-grant-tables。输入无误后输入quit;命令退出 MySQL 服务。 步骤 7)：重启 MySQL 服务，使用用户名 root 和刚才设置的新密码 root 登录就可以了。 四、MySQL修改密码的3种方式 1. 使用 SET PASSWORD 命令 步骤 1)：输入命令mysql -u root -p指定 root 用户登录 MySQL，输入后按回车键输入密码。如果没有配置环境变量，请在 MySQL 的 bin 目录下登录操作。 步骤 2)：使用 SET PASSWORD 修改密码命令格式为 set password for username @localhost = password(newpwd);，其中 username 为要修改密码的用户名，newpwd 为要修改的新密码。如图所示。 步骤 3)：输入quit;命令退出 MySQL 重新登录，输入新密码“root”登录就可以了； 2. 使用mysqladmin修改密码 使用 mysqladmin 命令修改 MySQL 的 root 用户密码格式为 mysqladmin -u用户名 -p旧密码 password 新密码。 注意：下图修改密码的命令中 -uroot 和 -proot 是整体，不要写成 -u root -p root，-u 和 root 间可以加空格，但是会有警告出现，所以就不要加空格了。 3. UPDATE直接编辑user表 步骤 1)：输入命令mysql -u root -p指定 root 用户登录 MySQL，输入后按回车键输入密码。如果没有配置环境变量，请在 MySQL 的 bin 目录下登录操作。 步骤 2)：输入use mysql;命令连接权限数据库。 步骤 3)：输入命令update mysql.user set authentication_string=password('新密码') where user='用户名' and Host ='localhost';设置新密码。 步骤 4)：输入 flush privileges; 命令刷新权限。 步骤 5)：输入quit;命令退出 MySQL 重新登录，此时密码已经修改为刚才输入的新密码了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#创建数据库DROP DATABASE IF EXISTS &#96;bankDB&#96;;CREATE DATABASE &#96;bankDB&#96;;USE &#96;bankDB&#96;;DROP TABLE IF EXISTS &#96;userInfo&#96;;CREATE TABLE &#96;userInfo&#96; #用户信息表( &#96;customerID&#96; INT(4) PRIMARY KEY AUTO_INCREMENT COMMENT &#39;用户编号&#39;, &#96;customerName&#96; CHAR(8) NOT NULL COMMENT &#39;用户编号&#39;, &#96;PID&#96; CHAR(18) UNIQUE NOT NULL COMMENT &#39;身份证号&#39;, &#96;telephone&#96; CHAR(20) NOT NULL COMMENT &#39;手机号码&#39;, &#96;address&#96; VARCHAR(50) COMMENT &#39;居住地址&#39;)ENGINE &#x3D; INNODB,CHARSET&#x3D;UTF8,COMMENT&#x3D;&#39;用户表&#39;;DROP TABLE IF EXISTS &#96;cardInfo&#96;;CREATE TABLE &#96;cardInfo&#96; #银行卡信息表( &#96;cardID&#96; CHAR(19) NOT NULL PRIMARY KEY COMMENT &#39;卡号&#39;, &#96;password&#96; CHAR(6) NOT NULL DEFAULT &#39;888888&#39; COMMENT &#39;密码&#39;, &#96;curID&#96; VARCHAR(10) NOT NULL DEFAULT &#39;RMB&#39; COMMENT &#39;币种&#39;, &#96;savingID&#96; INT NOT NULL COMMENT &#39;存款类型&#39;, &#96;openDate&#96; TIMESTAMP NOT NULL COMMENT &#39;开户日期&#39; , &#96;openMoney&#96; DECIMAL(20,2) NOT NULL DEFAULT 1 COMMENT &#39;开户金额&#39; , &#96;balance&#96; DECIMAL(20,2) NOT NULL DEFAULT 1 COMMENT &#39;余额&#39;, &#96;IsReportLoss&#96; BIT NOT NULL DEFAULT 0 COMMENT &#39;是否挂失&#39;, &#96;customerID&#96; INT NOT NULL) ENGINE &#x3D; INNODB,CHARSET&#x3D;UTF8,COMMENT&#x3D;&#39;银行卡信息表&#39;;DROP TABLE IF EXISTS &#96;tradeInfo&#96;;CREATE TABLE &#96;tradeInfo&#96; #交易信息表( cardID CHAR(16) NOT NULL COMMENT &#39;卡号&#39;, tradeDate TIMESTAMP NOT NULL COMMENT &#39;交易日期&#39;, tradeMoney DECIMAL(20,2) NOT NULL COMMENT &#39;实际交易金额&#39;, tradeType CHAR(4) NOT NULL COMMENT &#39;交易类型&#39;, remark TEXT COMMENT &#39;备注&#39; )ENGINE &#x3D; INNODB,CHARSET&#x3D;UTF8,COMMENT&#x3D;&#39;交易信息表&#39;;DROP TABLE IF EXISTS &#96;deposit&#96;;CREATE TABLE &#96;deposit&#96; #存款类型表( savingID INT(4) AUTO_INCREMENT PRIMARY KEY, savingName VARCHAR(20) NOT NULL, descrip VARCHAR(50))ENGINE &#x3D; INNODB,CHARSET&#x3D;UTF8,COMMENT&#x3D;&#39;存款类型表&#39;;&#x2F;*--加约束--$*&#x2F;ALTER TABLE cardInfo ADD CONSTRAINT FK_customerID FOREIGN KEY(customerID) REFERENCES userInfo(customerID), ADD CONSTRAINT FK_savingID FOREIGN KEY(savingID) REFERENCES deposit(savingID);ALTER TABLE tradeInfo ADD CONSTRAINT FK_cardID FOREIGN KEY(cardID) REFERENCES cardInfo(cardID);","path":"posts/66c1.html","date":"06-12","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL用户管理（1）","text":"A：补充技能点 MySQL用户管理 创建普通用户 执行GRANT语句创建用户并授权 使用mysqladmin命令修改root账户密码 使用SET命令修改用户密码 删除普通用户 MySQL 在安装时会自动创建一个名为 mysql 的数据库，mysql 数据库中存储的都是用户权限表。用户登录以后，MySQL 会根据这些权限表的内容为每个用户赋予相应的权限。 user 表是 MySQL 中最重要的一个权限表，用来记录允许连接到服务器的账号信息。需要注意的是，在 user 表里启用的所有权限都是全局级的，适用于所有数据库。 user 表中的字段大致可以分为 4 类，分别是用户列、权限列、安全列和资源控制列。 B：为什么需要用户管理 root是超级管理员用户，很容易引发由于误操作所导致的数据不安全问题，怎么办? 针对不同用户进行合理的用户角色权限分配，即用户管理 一、MySQL创建用户（3种方式） MySQL 提供了以下 3 种方法创建用户。 使用 CREATE USER 语句创建用户 在 mysql.user 表中添加用户 使用 GRANT 语句创建用户 1. 使用CREATE USER语句创建用户 可以使用 CREATE USER 语句来创建 MySQL 用户，并设置相应的密码。其基本语法格式如下： 1CREATE USER &lt;用户&gt; [ IDENTIFIED BY [ PASSWORD ] &#39;password&#39; ] [ ,用户 [ IDENTIFIED BY [ PASSWORD ] &#39;password&#39; ]] 例1 1234567# 创建普通用户create user &#96;teacher&#96;@&#96;localhost&#96; IDENTIFIED BY &#39;123456&#39;;create user &#96;student&#96;@&#96;localhost&#96;# 查看用户use mysql;select host,user from user; 例2 在 MySQL 中，可以使用 password() 函数获取密码的哈希值，查看 test1 哈希值的 SQL 语句和执行过程如下： 1234567mysql&gt; SELECT password(&#39;teacher&#39;);+-------------------------------------------+| password(&#39;teacher&#39;) |+-------------------------------------------+| *977F15BF49C046DA76BC81A80146AAB943F679F1 |+-------------------------------------------+1 row in set, 1 warning (0.00 sec) *“977F15BF49C046DA76BC81A80146AAB943F679F1”就是 test1 的哈希值。下面创建用户 test1，SQL 语句和执行过程如下： 12mysql&gt; CREATE USER &#39;text1&#39;@&#39;localhost&#39;IDENTIFIED BY PASSWORD &#39;*977F15BF49C046DA76BC81A80146AAB943F679F1&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec) 执行成功后就可以使用密码“test1”登录了。 2. 使用 INSERT 语句新建用户 可以使用 INSERT 语句将用户的信息添加到 mysql.user 表中，但必须拥有对 mysql.user 表的 INSERT 权限。通常 INSERT 语句只添加 Host、User 和 authentication_string 这 3 个字段的值。 MySQL 5.7 的 user 表中的密码字段从 Password 变成了 authentication_string，如果你使用的是 MySQL 5.7 之前的版本，将 authentication_string 字段替换成 Password 即可。 使用 INSERT 语句创建用户的代码如下： 1INSERT INTO mysql.user(Host, User, authentication_string, ssl_cipher, x509_issuer, x509_subject) VALUES (&#39;hostname&#39;, &#39;username&#39;, PASSWORD(&#39;password&#39;), &#39;&#39;, &#39;&#39;, &#39;&#39;); 由于 mysql 数据库的 user 表中，ssl_cipher、x509_issuer 和 x509_subject 这 3 个字段没有默认值，所以向 user 表插入新记录时，一定要设置这 3 个字段的值，否则 INSERT 语句将不能执行。 例 3 下面使用 INSERT 语句创建名为 test2 的用户，主机名是 localhost，密码也是 test2。SQL 语句和执行过程如下： 12mysql&gt; INSERT INTO mysql.user(Host, User, authentication_string, ssl_cipher, x509_issuer, x509_subject) VALUES (&#39;localhost&#39;, &#39;test2&#39;, PASSWORD(&#39;test2&#39;), &#39;&#39;, &#39;&#39;, &#39;&#39;);Query OK, 1 row affected, 1 warning (0.02 sec) 结果显示，新建用户成功。但是这时如果通过该账户登录 MySQL 服务器，不会登录成功，因为 test2 用户还没有生效。 可以使用 FLUSH 命令让用户生效，命令如下： 1FLUSH PRIVILEGES; 使用以上命令可以让 MySQL 刷新系统权限相关表。执行 FLUSH 命令需要 RELOAD 权限。 注意：user 表中的 User 和 Host 字段区分大小写，创建用户时要指定正确的用户名称或主机名。 3. 使用GRANT语句新建用户 虽然 CREATE USER 和 INSERT INTO 语句都可以创建普通用户，但是这两种方式不便授予用户权限。于是 MySQL 提供了 GRANT 语句。 使用 GRANT 语句创建用户的基本语法形式如下: 1GRANT priv_type ON database.table TO user [IDENTIFIED BY [PASSWORD] &#39;password&#39;] 其中： priv_type 参数表示新用户的权限； database.table 参数表示新用户的权限范围，即只能在指定的数据库和表上使用自己的权限； user 参数指定新用户的账号，由用户名和主机名构成； IDENTIFIED BY 关键字用来设置密码； password 参数表示新用户的密码。 例 4 下面使用 GRANT 语句创建名为 test3 的用户，主机名为 localhost，密码为 test3。该用户对所有数据库的所有表都有 SELECT 权限。SQL 语句和执行过程如下： 12mysql&gt; GRANT SELECT ON*.* TO &#39;test3&#39;@localhost IDENTIFIED BY &#39;test3&#39;;Query OK, 0 rows affected, 1 warning (0.01 sec) 其中，“.” 表示所有数据库下的所有表。结果显示创建用户成功，且 test3 用户对所有表都有查询（SELECT）权限。 技巧：GRANT 语句是 MySQL 中一个非常重要的语句，它可以用来创建用户、修改用户密码和设置用户权限。教程后面会详细介绍如何使用 GRANT 语句修改密码、更改权限。 二、MySQL修改用户（RENAME USER） 在 MySQL中，我们可以使用 RENAME USER 语句修改一个或多个已经存在的用户账号。 语法格式如下： 1RENAME USER &lt;旧用户&gt; TO &lt;新用户&gt; 其中： &lt;旧用户&gt;：系统中已经存在的 MySQL 用户账号。 &lt;新用户&gt;：新的 MySQL 用户账号。 使用 RENAME USER 语句时应注意以下几点： RENAME USER 语句用于对原有的 MySQL 用户进行重命名。 若系统中旧账户不存在或者新账户已存在，该语句执行时会出现错误。 使用 RENAME USER 语句，必须拥有 mysql 数据库的 UPDATE 权限或全局 CREATE USER 权限。 例 1 使用 RENAME USER 语句将用户名 test1 修改为 testUser1，主机是 localhost。SQL 语句和执行过程如下。 123mysql&gt; RENAME USER &#39;test1&#39;@&#39;localhost&#39; -&gt; TO &#39;testUser1&#39;@&#39;localhost&#39;;Query OK, 0 rows affected (0.03 sec) 在 cmd 命令行工具中，使用 testUser1 用户登录数据库服务器，如下所示。 12345678910C:\\Users\\USER&gt;mysql -h localhost -u testUser1 -pEnter password: *****Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 7Server version: 5.7.20-log MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement. 三、MySQL删除用户（DROP/DELETE USER） 在 MySQL 数据库中，可以使用 DROP USER 语句删除用户，也可以直接在 mysql.user 表中删除用户以及相关权限。 1. 使用 DROP USER 语句删除普通用户 使用 DROP USER 语句删除用户的语法格式如下： 1DROP USER &lt;用户1&gt; [ , &lt;用户2&gt; ]… 其中，用户用来指定需要删除的用户账号。 使用 DROP USER 语句应注意以下几点： DROP USER 语句可用于删除一个或多个用户，并撤销其权限。 使用 DROP USER 语句必须拥有 mysql 数据库的 DELETE 权限或全局 CREATE USER 权限。 在 DROP USER 语句的使用中，若没有明确地给出账户的主机名，则该主机名默认为“%”。 注意：用户的删除不会影响他们之前所创建的表、索引或其他数据库对象，因为 MySQL 并不会记录是谁创建了这些对象。 例 1 下面使用 DROP USER 语句删除用户’test1@‘localhost’。SQL 语句和执行过程如下。 12mysql&gt; DROP USER &#39;test1&#39;@&#39;localhost&#39;;Query OK, 0 rows affected (0.00 sec) 在 cmd 命令行工具中，使用 test1 用户登录数据库服务器，发现登录失败，说明用户已经删除，如下所示。 123C:\\Users\\USER&gt;mysql -h localhost -u test1 -pEnter password: ****ERROR 1045 (28000): Access denied for user &#39;test&#39;@&#39;localhost&#39; (using password: YES) 2. 使用DELETE语句删除普通用户 可以使用 DELETE 语句直接删除 mysql.user 表中相应的用户信息，但必须拥有 mysql.user 表的 DELETE 权限。其基本语法格式如下： 1DELETE FROM mysql.user WHERE Host&#x3D;&#39;hostname&#39; AND User&#x3D;&#39;username&#39;; Host 和 User 这两个字段都是 mysql.user 表的主键。因此，需要两个字段的值才能确定一条记录。 例 2 下面使用 DELETE 语句删除用户’test2’@‘localhost’。SQL 语句和执行过程如下所示。 12DELETE FROM mysql.user WHERE Host&#x3D;&#39;localhost&#39;AND User&#x3D;&#39;test2&#39;;Query OK, 1 rows affected (0.00 sec) 结果显示删除成功。可以使用 SELETE 语句查询 mysql.user 表，以确定该用户是否已经成功删除。 四、MySQL查看用户权限 在 MySQL 中，可以通过查看 mysql.user 表中的数据记录来查看相应的用户权限，也可以使用 SHOW GRANTS 语句查询用户的权限。 mysql 数据库下的 user 表中存储着用户的基本权限，可以使用 SELECT 语句来查看。SELECT 语句的代码如下： 1SELECT * FROM mysql.user; 要执行该语句，必须拥有对 user 表的查询权限。 注意：新创建的用户只有登录 MySQL 服务器的权限，没有任何其它权限，不能查询 user 表。 除了使用 SELECT 语句之外，还可以使用 SHOW GRANTS FOR 语句查看权限。其语法格式如下： 1SHOW GRANTS FOR &#39;username&#39;@&#39;hostname&#39;; 其中，username 表示用户名，hostname 表示主机名或主机 IP。 例 1 下面创建 testuser1 用户并查询权限，SQL 语句和执行过程如下： 12345678910mysql&gt; CREATE USER &#39;testuser1&#39;@&#39;localhost&#39;;Query OK, 0 rows affected (0.00 sec)mysql&gt; SHOW GRANTS FOR &#39;testuser1&#39;@&#39;localhost&#39;;+-----------------------------------------------+| Grants for testuser1@localhost |+-----------------------------------------------+| GRANT USAGE ON *.* TO &#39;testuser1&#39;@&#39;localhost&#39; |+-----------------------------------------------+1 row in set (0.00 sec) 其中，USAGE ON *.*表示该用户对任何数据库和任何表都没有权限。 例 2 下面查询 root 用户的权限，代码如下： 12345678mysql&gt; SHOW GRANTS FOR &#39;root&#39;@&#39;localhost&#39;;+---------------------------------------------------------------------+| Grants for root@localhost |+---------------------------------------------------------------------+| GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;localhost&#39; WITH GRANT OPTION || GRANT PROXY ON &#39;&#39;@&#39;&#39; TO &#39;root&#39;@&#39;localhost&#39; WITH GRANT OPTION |+---------------------------------------------------------------------+2 rows in set (0.00 sec) 五、MySQL GRANT：用户授权 授权就是为某个用户赋予某些权限。例如，可以为新建的用户赋予查询所有数据库和表的权限。MySQL 提供了 GRANT 语句来为用户设置权限。 在 MySQL 中，拥有 GRANT 权限的用户才可以执行 GRANT 语句，其语法格式如下： 1234GRANT priv_type [(column_list)] ON database.tableTO user [IDENTIFIED BY [PASSWORD] &#39;password&#39;][, user[IDENTIFIED BY [PASSWORD] &#39;password&#39;]] ...[WITH with_option [with_option]...] 1、权限类型说明 1）授予数据库权限时，&lt;权限类型&gt;可以指定为以下值： ![image-20200614164858090](G:\\四期\\数据库\\mysql文档\\11 MySQL 事务（2）.assets\\image-20200614164858090.png) 2) 授予表权限时，&lt;权限类型&gt;可以指定为以下值： ![image-20200614164921901](G:\\四期\\数据库\\mysql文档\\11 MySQL 事务（2）.assets\\image-20200614164921901.png) 3) 授予列权限时，&lt;权限类型&gt;的值只能指定为 SELECT、INSERT 和 UPDATE，同时权限的后面需要加上列名列表 column-list。 4) 最有效率的权限是用户权限。 授予用户权限时，&lt;权限类型&gt;除了可以指定为授予数据库权限时的所有值之外，还可以是下面这些值： CREATE USER：表示授予用户可以创建和删除新用户的权限。 SHOW DATABASES：表示授予用户可以使用 SHOW DATABASES 语句查看所有已有的数据库的定义的权限。 例 1 使用 GRANT 语句创建一个新的用户 testUser，密码为 testPwd。用户 testUser 对所有的数据有查询、插入权限，并授予 GRANT 权限。SQL 语句和执行过程如下。 12345mysql&gt; GRANT SELECT,INSERT ON *.* -&gt; TO &#39;testUser&#39;@&#39;localhost&#39; -&gt; IDENTIFIED BY &#39;testPwd&#39; -&gt; WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.05 sec) 使用 SHOW GRANTS 语句查询用户 testUser 的权限，如下所示。 1234567mysql&gt; SHOW GRANTS FOR &#39;testUser&#39;@&#39;localhost&#39;;+-------------------------------------------------------------------------+| Grants for testUser@localhost |+-------------------------------------------------------------------------+| GRANT SELECT, INSERT ON *.* TO &#39;testUser&#39;@&#39;localhost&#39; WITH GRANT OPTION |+-------------------------------------------------------------------------+1 row in set (0.00 sec) 结果显示，testUser 对所有数据库的所有表有查询、插入权限，并可以将这些权限赋予给别的用户。 六、MySQL REVOKE：删除用户权限 在 MySQL 中，可以使用 REVOKE 语句删除某个用户的某些权限（此用户不会被删除），在一定程度上可以保证系统的安全性。例如，如果数据库管理员觉得某个用户不应该拥有 DELETE 权限，那么就可以删除 DELETE 权限。 使用 REVOKE 语句删除权限的语法格式有两种形式，如下所示： 1）第一种 删除用户某些特定的权限，语法格式如下： 123REVOKE priv_type [(column_list)]...ON database.tableFROM user [, user]... REVOKE 语句中的参数与 GRANT 语句的参数意思相同。其中： priv_type 参数表示权限的类型； column_list 参数表示权限作用于哪些列上，没有该参数时作用于整个表上； user 参数由用户名和主机名构成，格式为“username’@‘hostname’”。 2）第二种 删除特定用户的所有权限，语法格式如下： 1REVOKE ALL PRIVILEGES, GRANT OPTION FROM user [, user] ... 删除用户权限需要注意以下几点： REVOKE 语法和 GRANT 语句的语法格式相似，但具有相反的效果。 要使用 REVOKE 语句，必须拥有 MySQL 数据库的全局 CREATE USER 权限或 UPDATE 权限。 例 1 使用 REVOKE 语句取消用户 testUser 的插入权限，SQL 语句和执行过程如下。 1234567891011mysql&gt; REVOKE INSERT ON *.* -&gt; FROM &#39;testUser&#39;@&#39;localhost&#39;;Query OK, 0 rows affected (0.01 sec)mysql&gt; SHOW GRANTS FOR &#39;testUser&#39;@&#39;localhost&#39;;+-----------------------------------------------------------------+| Grants for testUser@localhost |+-----------------------------------------------------------------+| GRANT SELECT ON *.* TO &#39;testUser&#39;@&#39;localhost&#39; WITH GRANT OPTION |+-----------------------------------------------------------------+1 row in set (0.00 sec) 结果显示，删除 testUser 用户的 INSERT 权限成功。 创建用户并授权 GRANT语句可实现创建用户同时授权或为已存在的用户授权 ![image-20200612151755831](G:\\四期\\数据库\\mysql文档\\11 MySQL用户管理（1）.assets\\image-20200612151755831.png) 12345# 给用户授权grant insert,select on myschool.studentto &#96;xgp&#96;@&#96;localhost&#96; IDENTIFIED by &#39;123456&#39;;grant select on myschool.student to &#96;student&#96;@&#96;localhost&#96;; 12use myschool;delete from student; 1234C:\\WINDOWS\\system32&gt;mysqladmin -u xgp -p password \"1111\"Enter password: ******mysqladmin: [Warning] Using a password on the command line interface can be insecure.Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety. ![image-20200612153552461](G:\\四期\\数据库\\mysql文档\\11 MySQL用户管理（1）.assets\\image-20200612153552461.png) 1set password &#x3D; password(&quot; 8888 ) 1SET PASSWORD FOR &#96;teacher&#96;@localhost&#96; &#x3D; PASSWORD(&quot;8888&quot;); 12drop user xgp@localhost;select * from user; ![image-20200612154416018](G:\\四期\\数据库\\mysql文档\\11 MySQL用户管理（1）.assets\\image-20200612154416018.png)","path":"posts/22c1.html","date":"06-11","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL 事务(2)","text":"一、MySQL设置事务自动提交（开启和关闭） MySQL 默认开启事务自动提交模式，即除非显式的开启事务（BEGIN 或 START TRANSACTION），否则每条 SOL 语句都会被当做一个单独的事务自动执行。但有些情况下，我们需要关闭事务自动提交来保证数据的一致性。下面主要介绍如何设置事务自动提交模式。 在 MySQL 中，可以通过 SHOW VARIABLES 语句查看当前事务自动提交模式，如下所示： 1234567mysql&gt; SHOW VARIABLES LIKE &#39;autocommit&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| autocommit | ON |+---------------+-------+1 row in set, 1 warning (0.04 sec) 结果显示，autocommit 的值是 ON，表示系统开启自动提交模式。 在 MySQL 中，可以使用 SET autocommit 语句设置事务的自动提交模式，语法格式如下： 1SET autocommit &#x3D; 0|1|ON|OFF; 对取值的说明： 值为 0 和值为 OFF：关闭事务自动提交。如果关闭自动提交，用户将会一直处于某个事务中，只有提交或回滚后才会结束当前事务，重新开始一个新事务。 值为 1 和值为 ON：开启事务自动提交。如果开启自动提交，则每执行一条 SQL 语句，事务都会提交一次。 示例 下面我们关闭事务自动提交，模拟银行转账。 使用 SET autocommit 语句关闭事务自动提交，且张三转给李四 500 元，SQL 语句和运行结果如下： 12345678910111213141516mysql&gt; SET autocommit &#x3D; 0; ;Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 1000.00 || 李四 | 1.00 |+--------------+--------------+2 rows in set (0.00 sec)mysql&gt; UPDATE bank SET cusMoney &#x3D; cusMoney-500 WHERE cusName&#x3D;&#39;张三&#39; ;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; UPDATE bank SET cusMoney &#x3D; cusMoney+500 WHERE cusName&#x3D;&#39;李四&#39;;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 这时重新打开一个 cmd 窗口，查看 bank 数据表中张三和李四的余额，SQL 语句和运行结果如下所示： 12345678mysql&gt; SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 1000.00 || 李四 | 1.00 |+--------------+--------------+2 rows in set (0.00 sec) 结果显示，张三和李四的余额是事务执行前的数据。 下面在之前的窗口中使用 COMMIT 语句提交事务，并查询 bank 数据表的数据，如下所示： 12345678910mysql&gt; COMMIT;Query OK, 0 rows affected (0.07 sec)mysql&gt; SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 500.00 || 李四 | 501.00 |+--------------+--------------+2 rows in set (0.00 sec) 结果显示，bank 数据表的数据更新成功。 在本例中，关闭自动提交后，该位置会作为一个事务起点，直到执行 COMMIT 语句和 ROLLBACK 语句后，该事务才结束。结束之后，这就是下一个事务的起点。 关闭自动提交功能后，只用当执行 COMMIT 命令后，MySQL 才将数据表中的资料提交到数据库中。如果执行 ROLLBACK 命令，数据将会被回滚。如果不提交事务，而终止 MySQL 会话，数据库将会自动执行回滚操作。 使用 BEGIN 或 START TRANSACTION 开启一个事务之后，自动提交将保持禁用状态，直到使用 COMMIT 或 ROLLBACK 结束事务。之后，自动提交模式会恢复到之前的状态，即如果 BEGIN 前 autocommit = 1，则完成本次事务后 autocommit 还是 1。如果 BEGIN 前 autocommit = 0，则完成本次事务后 autocommit 还是 0。 二、MySQL事务隔离级别详解 在《数据库事务》一节中介绍了 MySQL 事务的四大特性，其中事务的隔离性就是指当多个事务同时运行时，各事务之间相互隔离，不可互相干扰。 如果事务没有隔离性，就容易出现脏读、不可重复读和幻读等情况。 1) 脏读 脏读是指一个事务正在访问数据，并且对数据进行了修改，但是这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 2) 不可重复读 不可重复读是指在一个事务内，多次读取同一个数据。 在这个事务还没有结束时，另外一个事务也访问了该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 3) 幻读 幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 为了解决以上这些问题，标准 SQL 定义了 4 类事务隔离级别，用来指定事务中的哪些数据改变是可见的，哪些数据改变是不可见的。 MySQL 包括的事务隔离级别如下： 读未提交（READ UNCOMITTED） 读提交（READ COMMITTED） 可重复读（REPEATABLE READ） 串行化（SERIALIZABLE） MySQL 事务隔离级别可能产生的问题如下表所示： 隔离级别 脏读 不可重复读 幻读 READ UNCOMITTED √ √ √ READ COMMITTED × √ √ REPEATABLE READ × × √ SERIALIZABLE × × × MySQL 的事务的隔离级别由低到高分别为 READ UNCOMITTED、READ COMMITTED、REPEATABLE READ、SERIALIZABLE。低级别的隔离级别可以支持更高的并发处理，同时占用的系统资源更少。 下面根据实例来一一阐述它们的概念和联系。 1. 读未提交（READ UNCOMITTED，RU） 顾名思义，读未提交就是可以读到未提交的内容。 如果一个事务读取到了另一个未提交事务修改过的数据，那么这种隔离级别就称之为读未提交。 在该隔离级别下，所有事务都可以看到其它未提交事务的执行结果。因为它的性能与其他隔离级别相比没有高多少，所以一般情况下，该隔离级别在实际应用中很少使用。 例 1 主要演示了在读未提交隔离级别中产生的脏读现象。 示例 1 1) 先在 test 数据库中创建 testnum 数据表，并插入数据。SQL 语句和执行结果如下： 12345mysql&gt; CREATE TABLE testnum( -&gt; num INT(4));Query OK, 0 rows affected (0.57 sec)mysql&gt; INSERT INTO test.testnum (num) VALUES(1),(2),(3),(4),(5);Query OK, 5 rows affected (0.09 sec) 2) 下面的语句需要在两个命令行窗口中执行。为了方便理解，我们分别称之为 A 窗口和 B 窗口。 在 A 窗口中修改事务隔离级别，因为 A 窗口和 B 窗口的事务隔离级别需要保持一致，所以我们使用 SET GLOBAL TRANSACTION 修改全局变量。SQL 语句如下： 1234mysql&gt; SET GLOBAL TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;Query OK, 0 rows affected (0.04 sec)flush privileges;Query OK, 0 rows affected (0.04 sec) 查询事务隔离级别，SQL 语句和运行结果如下： 12345mysql&gt; show variables like &#39;%tx_isolation%&#39;\\G*************************** 1. row ***************************Variable_name: tx_isolation Value: READ-UNCOMMITTED1 row in set, 1 warning (0.00 sec) 结果显示，现在 MySQL 的事务隔离级别为 READ-UNCOMMITTED。 3) 在 A 窗口中开启一个事务，并查询 testnum 数据表，SQL 语句和运行结果如下： 12345678910111213mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM testnum;+------+| num |+------+| 1 || 2 || 3 || 4 || 5 |+------+5 rows in set (0.00 sec) 4) 打开 B 窗口，查看当前 MySQL 的事务隔离级别，SQL 语句如下： 12345mysql&gt; show variables like &#39;%tx_isolation%&#39;\\G*************************** 1. row ***************************Variable_name: tx_isolation Value: READ-UNCOMMITTED1 row in set, 1 warning (0.00 sec) 确定事务隔离级别是 READ-UNCOMMITTED 后，开启一个事务，并使用 UPDATE 语句更新 testnum 数据表，SQL 语句和运行结果如下： 12345mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE test.testnum SET num&#x3D;num*2 WHERE num&#x3D;2;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0 5) 现在返回 A 窗口，再次查询 testnum 数据表，SQL 语句和运行结果如下： 1234567891011mysql&gt; SELECT * FROM testnum;+------+| num |+------+| 1 || 4 || 3 || 4 || 5 |+------+5 rows in set (0.02 sec) 由结果可以看出，A 窗口中的事务读取到了更新后的数据。 6) 下面在 B 窗口中回滚事务，SQL 语句和运行结果如下： 12mysql&gt; ROLLBACK;Query OK, 0 rows affected (0.09 sec) 7) 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下： 1234567891011mysql&gt; SELECT * FROM testnum;+------+| num |+------+| 1 || 2 || 3 || 4 || 5 |+------+5 rows in set (0.00 sec) 当 MySQL 的事务隔离级别为 READ UNCOMITTED 时，首先分别在 A 窗口和 B 窗口中开启事务，在 B 窗口中的事务更新但未提交之前， A 窗口中的事务就已经读取到了更新后的数据。但由于 B 窗口中的事务回滚了，所以 A 事务出现了脏读现象。 使用读提交隔离级别可以解决实例中产生的脏读问题。 2. 读提交（READ COMMITTED，RC） 顾名思义，读提交就是只能读到已经提交了的内容。 如果一个事务只能读取到另一个已提交事务修改过的数据，并且其它事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值，那么这种隔离级别就称之为读提交。 该隔离级别满足了隔离的简单定义：一个事务从开始到提交前所做的任何改变都是不可见的，事务只能读取到已经提交的事务所做的改变。 这是大多数数据库系统的默认事务隔离级别（例如 Oracle、SQL Server），但不是 MySQL 默认的。 例 2 演示了在读提交隔离级别中产生的不可重复读问题。 示例 2 1) 使用 SET 语句将 MySQL 事务隔离级别修改为 READ COMMITTED，并查看。SQL 语句和运行结果如下： 1234567mysql&gt; SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like &#39;%tx_isolation%&#39;\\G*************************** 1. row ***************************Variable_name: tx_isolation Value: READ-COMMITTED1 row in set, 1 warning (0.00 sec) 2) 确定当前事务隔离级别为 READ COMMITTED 后，开启一个事务，SQL 语句和运行结果如下： 12mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec) 3) 在 B 窗口中开启事务，并使用 UPDATE 语句更新 testnum 数据表，SQL 语句和运行结果如下： 123456mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE test.testnum SET num&#x3D;num*2 WHERE num&#x3D;2;Query OK, 1 row affected (0.07 sec)Rows matched: 1 Changed: 1 Warnings: 0 4) 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下： 1234567891011mysql&gt; SELECT * from test.testnum;+------+| num |+------+| 1 || 2 || 3 || 4 || 5 |+------+5 rows in set (0.00 sec) 5) 提交 B 窗口中的事务，SQL 语句和运行结果如下： 12mysql&gt; COMMIT;Query OK, 0 rows affected (0.07 sec) 6) 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下： 1234567891011mysql&gt; SELECT * from test.testnum;+------+| num |+------+| 1 || 4 || 3 || 4 || 5 |+------+5 rows in set (0.00 sec) 当 MySQL 的事务隔离级别为 READ COMMITTED 时，首先分别在 A 窗口和 B 窗口中开启事务，在 B 窗口中的事务更新并提交后，A 窗口中的事务读取到了更新后的数据。在该过程中，A 窗口中的事务必须要等待 B 窗口中的事务提交后才能读取到更新后的数据，这样就解决了脏读问题。而处于 A 窗口中的事务出现了不同的查询结果，即不可重复读现象。 使用可重复读隔离级别可以解决实例中产生的不可重复读问题。 3. 可重复读（REPEATABLE READ，RR） 顾名思义，可重复读是专门针对不可重复读这种情况而制定的隔离级别，可以有效的避免不可重复读。 在一些场景中，一个事务只能读取到另一个已提交事务修改过的数据，但是第一次读过某条记录后，即使其它事务修改了该记录的值并且提交，之后该事务再读该条记录时，读到的仍是第一次读到的值，而不是每次都读到不同的数据。那么这种隔离级别就称之为可重复读。 可重复读是 MySQL 的默认事务隔离级别，它能确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。在该隔离级别下，如果有事务正在读取数据，就不允许有其它事务进行修改操作，这样就解决了可重复读问题。 例 3 演示了在可重复读隔离级别中产生的幻读问题。 示例 3 1) 在 test 数据库中创建 testuser 数据表，SQL 语句和执行结果如下： 1234mysql&gt; CREATE TABLE testuser( -&gt; id INT (4) PRIMARY KEY, -&gt; name VARCHAR(20));Query OK, 0 rows affected (0.29 sec) 2) 使用 SET 语句修改事务隔离级别，SQL 语句如下： 12mysql&gt; SET GLOBAL TRANSACTION ISOLATION LEVEL REPEATABLE READ;Query OK, 0 rows affected (0.00 sec) 3) 在 A 窗口中开启事务，并查询 testuser 数据表，SQL 语句和运行结果如下： 12345mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM test.testuser where id&#x3D;1;Empty set (0.04 sec) 4) 在 B 窗口中开启一个事务，并向 testuser 表中插入一条数据，SQL 语句和运行结果如下： 123456mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO test.testuser VALUES(1,&#39;zhangsan&#39;);Query OK, 1 row affected (0.04 sec)mysql&gt; COMMIT;Query OK, 0 rows affected (0.06 sec) 5) 现在返回 A 窗口，向 testnum 数据表中插入数据，SQL 语句和运行结果如下： 1234mysql&gt; INSERT INTO test.testuser VALUES(1,&#39;lisi&#39;);ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;PRIMARY&#39;mysql&gt; SELECT * FROM test.testuser where id&#x3D;1;Empty set (0.00 sec) 使用串行化隔离级别可以解决实例中产生的幻读问题。 4. 串行化（SERIALIZABLE） 如果一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。那么这种隔离级别就称之为串行化。 SERIALIZABLE 是最高的事务隔离级别，主要通过强制事务排序来解决幻读问题。简单来说，就是在每个读取的数据行上加上共享锁实现，这样就避免了脏读、不可重复读和幻读等问题。但是该事务隔离级别执行效率低下，且性能开销也最大，所以一般情况下不推荐使用。 三、MySQL查看和修改事务隔离级别 在《MySQL事务隔离级别》一节中我们了解了 MySQL 的事务隔离级别，本节主要介绍查看和修改事务隔离级别的几种方法。 查看事务隔离级别 在 MySQL 中，可以通过show variables like '%tx_isolation%'或select @@tx_isolation;语句来查看当前事务隔离级别。 查看当前事务隔离级别的 SQL 语句和运行结果如下： 1234567891011121314mysql&gt; show variables like &#39;%tx_isolation%&#39;;+---------------+-----------------+| Variable_name | Value |+---------------+-----------------+| tx_isolation | REPEATABLE-READ |+---------------+-----------------+1 row in set, 1 warning (0.17 sec）mysql&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set, 1 warning (0.00 sec) 结果显示，目前 MySQL 的事务隔离级别是 REPEATABLE-READ。 另外，还可以使用下列语句分别查询全局和会话的事务隔离级别： 12SELECT @@global.tx_isolation;SELECT @@session.tx_isolation; 提示：在MySQL 8.0.3 中，tx_isolation 变量被 transaction_isolation 变量替换了。在 MySQL 8.0.3 版本中查询事务隔离级别，只要把上述查询语句中的 tx_isolation 变量替换成 transaction_isolation 变量即可。 修改事务隔离级别 MySQL 提供了 SET TRANSACTION 语句，该语句可以改变单个会话或全局的事务隔离级别。语法格式如下： SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE} 其中，SESSION 和 GLOBAL 关键字用来指定修改的事务隔离级别的范围： SESSION：表示修改的事务隔离级别将应用于当前 session（当前 cmd 窗口）内的所有事务； GLOBAL：表示修改的事务隔离级别将应用于所有 session（全局）中的所有事务，且当前已经存在的 session 不受影响； 如果省略 SESSION 和 GLOBAL，表示修改的事务隔离级别将应用于当前 session 内的下一个还未开始的事务。 任何用户都能改变会话的事务隔离级别，但是只有拥有 SUPER 权限的用户才能改变全局的事务隔离级别。 如果使用普通用户修改全局事务隔离级别，就会提示需要超级权限才能执行此操作的错误信息，SQL 语句和运行结果如下： 123456789101112131415161718C:\\Users\\leovo&gt;mysql -utestuser -pEnter password: ******Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 41Server version: 5.7.29-log MySQL Community Server (GPL) Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners. Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement. mysql&gt; SET GLOBAL TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;ERROR 1227 (42000): Access denied; you need (at least one of) the SUPER privilege(s) for this operationmysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;Query OK, 0 rows affected (0.00 sec) 示例 1 使用 SET TRANSACTION 语句分别修改 session 和全局的事务隔离级别SQL 语句和运行结果如下： 123456789101112131415161718mysql&gt; select @@session.tx_isolation;+------------------------+| @@session.tx_isolation |+------------------------+| SERIALIZABLE |+------------------------+1 row in set, 1 warning (0.00 sec)mysql&gt; SET GLOBAL TRANSACTION ISOLATION LEVEL REPEATABLE READ;Query OK, 0 rows affected (0.00 sec)mysql&gt; select @@global.tx_isolation;+-----------------------+| @@global.tx_isolation |+-----------------------+| REPEATABLE-READ |+-----------------------+1 row in set, 1 warning (0.00 sec) 还可以使用 set tx_isolation 命令直接修改当前 session 的事务隔离级别，SQL 语句和运行结果如下： 12345678910mysql&gt; set tx_isolation&#x3D;&#39;READ-COMMITTED&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; select @@session.tx_isolation;+------------------------+| @@session.tx_isolation |+------------------------+| READ-COMMITTED |+------------------------+1 row in set, 1 warning (0.00 sec)","path":"posts/40d5.html","date":"06-10","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL 事务(1)","text":"A: MySQL 事务 MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你既需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 一般来说，事务是必须满足4个条件（ACID）: :原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。 原子性:一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性:在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性:数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性:事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。 B: 关于事务的一些术语 开启事务：Start Transaction 事务结束：End Transaction 提交事务：Commit Transaction 回滚事务：Rollback Transaction C: MYSQL 事务处理主要有两种方法： 1、用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 2、直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=0 禁止自动提交 SET AUTOCOMMIT=1 开启自动提交 12345678910111213141516171819202122232425262728293031323334353637383940414243444546mysql&gt; use RUNOOB;Database changedmysql&gt; CREATE TABLE runoob_transaction_test( id int(5)) engine&#x3D;innodb; # 创建数据表Query OK, 0 rows affected (0.04 sec) mysql&gt; select * from runoob_transaction_test;Empty set (0.01 sec) mysql&gt; begin; # 开始事务Query OK, 0 rows affected (0.00 sec) mysql&gt; insert into runoob_transaction_test value(5);Query OK, 1 rows affected (0.01 sec) mysql&gt; insert into runoob_transaction_test value(6);Query OK, 1 rows affected (0.00 sec) mysql&gt; commit; # 提交事务Query OK, 0 rows affected (0.01 sec) mysql&gt; select * from runoob_transaction_test;+------+| id |+------+| 5 || 6 |+------+2 rows in set (0.01 sec) mysql&gt; begin; # 开始事务Query OK, 0 rows affected (0.00 sec) mysql&gt; insert into runoob_transaction_test values(7);Query OK, 1 rows affected (0.00 sec) mysql&gt; rollback; # 回滚Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from runoob_transaction_test; # 因为回滚所以数据没有插入+------+| id |+------+| 5 || 6 |+------+2 rows in set (0.01 sec) D: 什么是事务 事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作 多个操作作为一个整体向系统提交，要么都执行、要么都不执行 事务是一个不可分割的工作逻辑单元 转账过程就是一个整体 它需要两条UPDATE语句来完成，这两条语句是一个整体 如果其中任一条出现错误， 则整个转账业务也应取消，两个账户中的余额应恢复 到原来的数据，从而确保转账前和转账后的余额不变，即都是1001元 E: 为什么需要事务 了解事务之前，先来看看数据库为什么需要有事务，假设没有事务会有什么影响？ 举一个转账的例子，假设你朋友向你借10000元，你打开APP，乐呵呵的把钱转了，你的卡里已经少了10000元，但是你打电话给朋友时，你朋友说没有收到啊，你这时候肯定卖银行怎么不靠谱，没到账怎么把我卡里的钱给扣了。 我们来捋一捋上述银行发生的过程，简单的分三步： A发起转账10000给B -&gt; A银行卡减10000元 -&gt; B银行卡增加10000元。 上述案例是第三步出现了问题，如果有事务，则不会发生案例中的事情，可以理解为事务就是这三个步骤是一根绳子上的蚂蚱，要么都成功，要么都失败。 所以数据库引入事务的主要目的是事务会把数据库会从一种一致状态转换到另一种一致状态，数据库提交工作时可以确保要么所有修改都保存，要么所有修改都不保存。 了解事务，还需要了解事务的理论依据ACID，也可以说事务的几个特性。 一、银行转账问题 假定资金从账户A转到账户B，至少需要两步 账户A的资金减少 然后账户B的资金相应增加 123456789101112131415161718192021222324drop database if EXISTS &#96;bankdb&#96;;create database &#96;bankdb&#96;;use &#96;bankdb&#96;;drop table IF EXISTS &#96;bank&#96;;create table &#96;bank&#96;( &#96;cusName&#96; VARCHAR(20), #用户名 &#96;cusMoney&#96; DECIMAL(10,2) #用户名)CHARSET &#x3D; &#39;utf8mb4&#39;;insert into bankVALUES(&#39;张三&#39;,1000),(&#39;李四&#39;,1);# 模拟转账UPDATE bankset cusMoney&#x3D;cusMoney-500where cusName&#x3D;&#39;张三&#39;;UPDATE bankset cusMoney&#x3D;cusMoney+500where cusName&#x3D;&#39;李四&#39;;# 查看账户select * from bank; 下面开始模拟实现转账功能。从张三的账户直接转账 500 元到李四的账户，可以使用 UPDATE 语句分别修改张三的账户和李四的账户。张三的账户减少 500 元，李四的账户增加 500 元， SQL 语句如下所示： 12345678910111213# 模拟转账BEGIN; #开始UPDATE bankset cusMoney&#x3D;cusMoney-500where cusName&#x3D;&#39;张三&#39;;UPDATE bankset cusMoney&#x3D;cusMoney+500where cusName&#x3D;&#39;李四&#39;;COMMIT; # 结束# 查看一下select * from bank; ![image-20200614160258903](G:\\四期\\数据库\\mysql文档\\09 MySQL 事务+用户权限.assets\\image-20200614160258903.png) 正常情况下，执行以上的转账操作后，余额总和应保持不变，仍为 1001 元。但是，如果在这个过程的其中一个环节出现差错，如在张三的账户减少 500 元之后，这时发生了服务器故障，李四的账户没有立即增加 500 元，此时，第三方读取到两个账户的余额总和变为 500+1=501 元，即账户总额间少了 500 元。 MySQL 为了解决此类问题，提供了事务。事务可以将一系列的数据操作捆绑成一个整体进行统一管理，如果某一事务执行成功，则在该事务中进行的所有数据更改均会提交，成为数据库中的永久组成部分。如果事务执行时遇到错误，则就必须取消或回滚。取消或回滚后，数据将全部恢复到操作前的状态，所有数据的更改均被清除。 MySQL 通过事务保证了数据的一致性。上述提到的转账过程就是一个事务，它需要两条 UPDATE 语句来完成。这两条语句是一个整体，如果其中任何一个环节出现问题，则整个转账业务也应取消，两个账户中的余额应恢复为原来的数据，从而确保转账前和转账后的余额总和不变，即都是 1001 元。 二、执行事务的语法和流程 SQL 使用下列语句来管理事务。 1) 开始事务 1BEGIN; 或 1START TRANSACTION; 这个语句显式地标记一个事务的起始点。 2) 提交事务 MySQL 使用下面的语句来提交事务： 1COMMIT; COMMIT 表示提交事务，即提交事务的所有操作，具体地说，就是将事务中所有对数据库的更新都写到磁盘上的物理数据库中，事务正常结束。 提交事务，意味着将事务开始以来所执行的所有数据都修改成为数据库的永久部分，因此也标志着一个事务的结束。一旦执行了该命令，将不能回滚事务。只有在所有修改都准备好提交给数据库时，才执行这一操作。 3) 回滚（撤销）事务 MySQL 使用以下语句回滚事务： 1ROLLBACK; ROLLBACK 表示撤销事务，即在事务运行的过程中发生了某种故障，事务不能继续执行，系统将事务中对数据库的所有已完成的操作全部撤销，回滚到事务开始时的状态。这里的操作指对数据库的更新操作。 当事务执行过程中遇到错误时，使用 ROLLBACK 语句使事务回滚到起点或指定的保持点处。同时，系统将清除自事务起点或到某个保存点所做的所有的数据修改，并且释放由事务控制的资源。因此，这条语句也标志着事务的结束。 总结 BEGIN 或 START TRANSACTION 语句后面的 SQL 语句对数据库数据的更新操作都将记录在事务日志中，直至遇到 ROLLBACK 语句或 COMMIT 语句。如果事务中某一操作失败且执行了 ROLLBACK 语句，那么在开启事务语句之后所有更新的数据都能回滚到事务开始前的状态。如果事务中的所有操作都全部正确完成，并且使用了 COMMIT 语句向数据库提交更新数据，则此时的数据又处在新的一致状态。 1、实例演示 下面通过两个例子来演示一下 MySQL 事务的具体用法。 示例 1 下面模拟在张三的账户减少 500 元后，李四的账户还未增加 500 时，有其他会话访问数据表的场景。由于代码需要在两个窗口中执行，为了方便阅读，这里我们称为 A 窗口和 B 窗口。 1) 在 A 窗口中开启一个事务，并更新 mybank 数据库中 bank 表的数据，SQL 语句和运行结果如下： 12345678mysql&gt; USE mybank;Database changedmysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE bank SET cusMoney &#x3D; cusMoney-500 -&gt; WHERE cusName&#x3D;&#39;张三&#39;;Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0 2) 在 B 窗口中查询 bank 数据表中的数据，SQL 语句和运行结果如下： 12345678mysql&gt; SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 1000.00 || 李四 | 1.00 |+--------------+--------------+2 rows in set (0.00 sec) 从结果可以看出，虽然 A 窗口中的事务已经更改了 bank 表中的数据，但没有立即更新数据，这时其他会话读取到的仍然是更新前的数据。 3) 在 A 窗口中继续执行事务并提交事务，SQL 语句和运行结果如下： 123456mysql&gt; UPDATE bank SET cusMoney &#x3D; cusMoney+500 -&gt; WHERE cusName&#x3D;&#39;李四&#39;;Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; COMMIT;Query OK, 0 rows affected (0.07 sec) 4) 在 B 窗口中再次查询 bank 数据表的数据，SQL 语句和运行结果如下： 12345678mysql&gt; SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 500.00 || 李四 | 501.00 |+--------------+--------------+2 rows in set (0.00 sec) 在 A 窗口中执行 COMMIT 提交事务后，对数据所做的更新将一起提交，其他会话读取到的是更新后的数据。从结果可以看出张三和李四的总账户余额和转账前保持一致，这样数据从一个一致性状态更新到另一个一致性状态。 前面提到，当事务在执行中出现问题，也就是不能按正常的流程执行一个完整的事务时，可以使用 ROLLBACK 语句进行回滚，使用数据恢复到初始状态。 在例 1 中，张三的账户余额已经减少到 500 元，如果再转出 1000 元，将会出现余额为负数，因此需要回滚到原始状态。如例 2 所示。 示例 2 将张三的账户余额减少 1000 元，并让事务回滚，SQL 语句和运行结果如下所示： 123456789101112131415161718mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec) mysql&gt; UPDATE bank SET cusMoney &#x3D; cusMoney-1000 WHERE cusName&#x3D;&#39;张三&#39;;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0 mysql&gt; ROLLBACK;Query OK, 0 rows affected (0.07 sec) mysql&gt; SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 500.00 || 李四 | 501.00 |+--------------+--------------+2 rows in set (0.00 sec) 从结果可以看出，执行事务回滚后，账户数据恢复到初始状态，即该事务执行之前的状态。 拓展 在数据库操作中，为了有效保证并发读取数据的正确性，提出了事务的隔离级别。在例 1 和例 2 的演示中，事务的隔离级别为默认隔离级别。在 MySQL 中，事务的默认隔离级别是 REPEATABLE-READ （可重读）隔离级别，即事务未结束时（未执行 COMMIT 或 ROLLBACK），其它会话只能读取到未提交数据。 请猛击《MySQL事务隔离级别》了解更多内容。 2、注意事项 MySQL 事务是一项非常消耗资源的功能，大家在使用过程中要注意以下几点。 1) 事务尽可能简短 事务的开启到结束会在数据库管理系统中保留大量资源，以保证事务的原子性、一致性、隔离性和持久性。如果在多用户系统中，较大的事务将会占用系统的大量资源，使得系统不堪重负，会影响软件的运行性能，甚至导致系统崩溃。 2) 事务中访问的数据量尽量最少 当并发执行事务处理时，事务操作的数据量越少，事务之间对相同数据的操作就越少。 3) 查询数据时尽量不要使用事务 对数据进行浏览查询操作并不会更新数据库的数据，因此应尽量不使用事务查询数据，避免占用过量的系统资源。 4) 在事务处理过程中尽量不要出现等待用户输入的操作 在处理事务的过程中，如果需要等待用户输入数据，那么事务会长时间地占用资源，有可能造成系统阻塞。 回滚 1234567BEGIN;UPDATE bankset cusMoney&#x3D;cusMoney+500where cusName&#x3D;&#39;张三&#39;;ROLLBACK;select * from bank; 1234567BEGIN;UPDATE bankset cusMoney&#x3D;cusMoney+500where cusName&#x3D;&#39;张三&#39;;COMMIT;select * from bank; 1查看事务状态:SHOW VARIABLES LIKE &#39;AUTOCOMMIT&#39;;","path":"posts/b0d5.html","date":"06-09","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL索引","text":"A: 为什么要使用索引 索引是 MySQL 中一种十分重要的数据库对象。它是数据库性能调优技术的基础，常用于实现数据的快速检索。 索引就是根据表中的一列或若干列按照一定顺序建立的列值与记录行之间的对应关系表，实质上是一张描述索引列的列值与原表中记录行之间一一对应关系的有序表。 在 MySQL 中，通常有以下两种方式访问数据库表的行数据： 1) 顺序访问 顺序访问是在表中实行全表扫描，从头到尾逐行遍历，直到在无序的行数据中找到符合条件的目标数据。这种方式实现比较简单，但是当表中有大量数据的时候，效率非常低下。例如，在几千万条数据中查找少量的数据时，使用顺序访问方式将会遍历所有的数据，花费大量的时间，显然会影响数据库的处理性能。 2) 索引访问 索引访问是通过遍历索引来直接访问表中记录行的方式。使用这种方式的前提是对表建立一个索引，在列上创建了索引之后，查找数据时可以直接根据该列上的索引找到对应记录行的位置，从而快捷地查找到数据。索引存储了指定列数据值的指针，根据指定的排序顺序对这些指针排序。 例如，在学生基本信息表 students 中，如果基于 student_id 建立了索引，系统就建立了一张索引列到实际记录的映射表，当用户需要查找 student_id 为 12022 的数据的时候，系统先在 student_id 索引上找到该记录，然后通过映射表直接找到数据行，并且返回该行数据。因为扫描索引的速度一般远远大于扫描实际数据行的速度，所以采用索引的方式可以大大提高数据库的工作效率。 B: 索引的分类 索引的类型和存储引擎有关，每种存储引擎所支持的索引类型不一定完全相同。根据存储方式的不同，MySQL 中常用的索引在物理上分为以下两类。 1) B-树索引 B-树索引又称为 BTREE 索引，目前大部分的索引都是采用 B-树索引来存储的。B-树索引是一个典型的数据结构，其包含的组件主要有以下几个： 叶子节点：包含的条目直接指向表里的数据行。叶子节点之间彼此相连，一个叶子节点有一个指向下一个叶子节点的指针。 分支节点：包含的条目指向索引里其他的分支节点或者叶子节点。 根节点：一个 B-树索引只有一个根节点，实际上就是位于树的最顶端的分支节点。 2) 哈希索引 哈希（Hash）一般翻译为“散列”，也有直接音译成“哈希”的，就是把任意长度的输入（又叫作预映射，pre-image）通过散列算法变换成固定长度的输出，该输出就是散列值。 哈希索引也称为散列索引或 HASH 索引。MySQL 目前仅有 MEMORY 存储引擎和 HEAP 存储引擎支持这类索引。其中，MEMORY 存储引擎可以支持 B- 树索引和 HASH 索引，且将 HASH 当成默认索引。 C: 常用索引类型 普通索引 ●基本索引类型●允许在定义索引的列中插入重复值和空值 唯一索引 ●索引列数据不重复●允许有空值 主键索引 ●主键列中的每个值是非空、唯一的 复合索引 ●一个主键将自动创建主键索引●将多个列组合作为索引 全文索引 ●支持值的全文查找 空间索引 ●允许重复值和空值●对空间数据类型的列建立的索引 D: 索引的使用原则和注意事项 虽然索引可以加快查询速度，提高 MySQL 的处理性能，但是过多地使用索引也会造成以下弊端： 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 除了数据表占数据空间之外，每一个索引还要占一定的物理空间。如果要建立聚簇索引，那么需要的空间就会更大。 当对表中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。 注意：索引可以在一些情况下加速查询，但是在某些情况下，会降低效率。 索引只是提高效率的一个因素，因此在建立索引的时候应该遵循以下原则： 在经常需要搜索的列上建立索引，可以加快搜索的速度。 在作为主键的列上创建索引，强制该列的唯一性，并组织表中数据的排列结构。 在经常使用表连接的列上创建索引，这些列主要是一些外键，可以加快表连接的速度。 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，所以其指定的范围是连续的。 在经常需要排序的列上创建索引，因为索引已经排序，所以查询时可以利用索引的排序，加快排序查询。 在经常使用 WHERE 子句的列上创建索引，加快条件的判断速度。 与此对应，在某些应用场合下建立索引不能提高 MySQL 的工作效率，甚至在一定程度上还带来负面效应，降低了数据库的工作效率，一般来说不适合创建索引的环境如下： 对于那些在查询中很少使用或参考的列不应该创建索引。因为这些列很少使用到，所以有索引或者无索引并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度，并增大了空间要求。 对于那些只有很少数据值的列也不应该创建索引。因为这些列的取值很少，例如人事表的性别列。查询结果集的数据行占了表中数据行的很大比例，增加索引并不能明显加快检索速度。 对于那些定义为 TEXT、IMAGE 和 BIT 数据类型的列不应该创建索引。因为这些列的数据量要么相当大，要么取值很少。 当修改性能远远大于检索性能时，不应该创建索引。因为修改性能和检索性能是互相矛盾的。当创建索引时，会提高检索性能，降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 一、MySQL创建索引 1、MySQL 提供了三种创建索引的方法： 1) 使用 CREATE INDEX 语句 可以使用专门用于创建索引的 CREATE INDEX 语句在一个已有的表上创建索引，但该语句不能创建主键。 语法格式： 1CREATE &lt;索引名&gt; ON &lt;表名&gt; (&lt;列名&gt; [&lt;长度&gt;] [ ASC | DESC]) 2) 使用 CREATE TABLE 语句 索引也可以在创建表（CREATE TABLE）的同时创建。在 CREATE TABLE 语句中添加以下语句。语法格式： 1CONSTRAINT PRIMARY KEY [索引类型] (&lt;列名&gt;,…) 语法格式： 1KEY | INDEX [&lt;索引名&gt;] [&lt;索引类型&gt;] (&lt;列名&gt;,…) 在 CREATE TABLE 语句中添加此语句，表示在创建新表的同时创建该表的索引。 语法格式： 1UNIQUE [ INDEX | KEY] [&lt;索引名&gt;] [&lt;索引类型&gt;] (&lt;列名&gt;,…) 在 CREATE TABLE 语句中添加此语句，表示在创建新表的同时创建该表的唯一性索引。 语法格式： 1FOREIGN KEY &lt;索引名&gt; &lt;列名&gt; 在 CREATE TABLE 语句中添加此语句，表示在创建新表的同时创建该表的外键。 在使用 CREATE TABLE 语句定义列选项的时候，可以通过直接在某个列定义后面添加 PRIMARY KEY 的方式创建主键。而当主键是由多个列组成的多列索引时，则不能使用这种方法，只能用在语句的最后加上一个 PRIMARY KRY(&lt;列名&gt;，…) 子句的方式来实现。 3) 使用 ALTER TABLE 语句 CREATE INDEX 语句可以在一个已有的表上创建索引，ALTER TABLE 语句也可以在一个已有的表上创建索引。在使用 ALTER TABLE 语句修改表的同时，可以向已有的表添加索引。具体的做法是在 ALTER TABLE 语句中添加以下语法成分的某一项或几项。 语法格式： 1ADD INDEX [&lt;索引名&gt;] [&lt;索引类型&gt;] (&lt;列名&gt;,…) 在 ALTER TABLE 语句中添加此语法成分，表示在修改表的同时为该表添加索引。 语法格式： 1ADD PRIMARY KEY [&lt;索引类型&gt;] (&lt;列名&gt;,…) 在 ALTER TABLE 语句中添加此语法成分，表示在修改表的同时为该表添加主键。 语法格式： 1ADD UNIQUE [ INDEX | KEY] [&lt;索引名&gt;] [&lt;索引类型&gt;] (&lt;列名&gt;,…) 在 ALTER TABLE 语句中添加此语法成分，表示在修改表的同时为该表添加唯一性索引。 语法格式： 1ADD FOREIGN KEY [&lt;索引名&gt;] (&lt;列名&gt;,…) 在 ALTER TABLE 语句中添加此语法成分，表示在修改表的同时为该表添加外键。 2、创建一般索引 创建一个表 tb_stu_info，在该表的 height 字段创建一般索引。输入的 SQL 语句和执行过程如下所示。 12345678910111213141516171819202122mysql&gt; CREATE TABLE tb_stu_info -&gt; ( -&gt; id INT NOT NULL, -&gt; name CHAR(45) DEFAULT NULL, -&gt; dept_id INT DEFAULT NULL, -&gt; age INT DEFAULT NULL, -&gt; height INT DEFAULT NULL, -&gt; INDEX(height) -&gt; );Query OK，0 rows affected (0.40 sec)mysql&gt; SHOW CREATE TABLE tb_stu_info\\G*************************** 1. row *************************** Table: tb_stu_infoCreate Table: CREATE TABLE &#96;tb_stu_info&#96; ( &#96;id&#96; int(11) NOT NULL, &#96;name&#96; char(45) DEFAULT NULL, &#96;dept_id&#96; int(11) DEFAULT NULL, &#96;age&#96; int(11) DEFAULT NULL, &#96;height&#96; int(11) DEFAULT NULL, KEY &#96;height&#96; (&#96;height&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;gb23121 row in set (0.01 sec) 3、创建唯一索引 创建一个表 tb_stu_info2，在该表的 id 字段上使用 UNIQUE 关键字创建唯一索引。输入的 SQL 语句和执行过程如下所示。 1234567891011121314151617181920212223mysql&gt; CREATE TABLE tb_stu_info2 -&gt; ( -&gt; id INT NOT NULL, -&gt; name CHAR(45) DEFAULT NULL, -&gt; dept_id INT DEFAULT NULL, -&gt; age INT DEFAULT NULL, -&gt; height INT DEFAULT NULL, -&gt; UNIQUE INDEX(height) -&gt; );Query OK，0 rows affected (0.40 sec)mysql&gt; SHOW CREATE TABLE tb_stu_info2\\G*************************** 1. row *************************** Table: tb_stu_info2Create Table: CREATE TABLE &#96;tb_stu_info2&#96; ( &#96;id&#96; int(11) NOT NULL, &#96;name&#96; char(45) DEFAULT NULL, &#96;dept_id&#96; int(11) DEFAULT NULL, &#96;age&#96; int(11) DEFAULT NULL, &#96;height&#96; int(11) DEFAULT NULL, UNIQUE KEY &#96;height&#96; (&#96;height&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;gb23121 row in set (0.00 sec) 二、查看索引 在 MySQL 中，如果要查看已创建的索引的情况，可以使用 SHOW INDEX 语句查看表中创建的索引。 语法格式： 1SHOW INDEX FROM &lt;表名&gt; [ FROM &lt;数据库名&gt;] 语法说明如下： &lt;表名&gt;：要显示索引的表。 &lt;数据库名&gt;：要显示的表所在的数据库。 显示数据库 mytest 的表 course 的索引情况。 1mysql&gt; SHOW INDEX FROM course FROM mytest; 该语句会返回一张结果表，该表有如下几个字段，每个字段所显示的内容说明如下。 参数 说明 Table 表示创建索引的数据表名，这里是 tb_stu_info2 数据表。 Non_unique 表示该索引是否是唯一索引。若不是唯一索引，则该列的值为 1；若是唯一索引，则该列的值为 0。 Key_name 表示索引的名称。 Seq_in_index 表示该列在索引中的位置，如果索引是单列的，则该列的值为 1；如果索引是组合索引，则该列的值为每列在索引定义中的顺序。 Column_name 表示定义索引的列字段。 Collation 表示列以何种顺序存储在索引中。在 MySQL 中，升序显示值“A”（升序），若显示为 NULL，则表示无分类。 Cardinality 索引中唯一值数目的估计值。基数根据被存储为整数的统计数据计数，所以即使对于小型表，该值也没有必要是精确的。基数越大，当进行联合时，MySQL 使用该索引的机会就越大。 Sub_part 表示列中被编入索引的字符的数量。若列只是部分被编入索引，则该列的值为被编入索引的字符的数目；若整列被编入索引，则该列的值为 NULL。 Packed 指示关键字如何被压缩。若没有被压缩，值为 NULL。 Null 用于显示索引列中是否包含 NULL。若列含有 NULL，该列的值为 YES。若没有，则该列的值为 NO。 Index_type 显示索引使用的类型和方法（BTREE、FULLTEXT、HASH、RTREE）。 Comment 显示评注。 【实例 】 使用 SHOW INDEX 语句查看表 tb_stu_info2 的索引信息，输入的 SQL 语句和执行结果如下所示。 12345678910111213141516mysql&gt; SHOW INDEX FROM tb_stu_info2\\G*************************** 1. row *************************** Table: tb_stu_info2 Non_unique: 0 Key_name: heightSeq_in_index: 1 Column_name: height Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE Comment:Index_comment:1 row in set (0.03 sec) 三、MySQL修改和删除索引 基本语法 当不再需要索引时，可以使用 DROP INDEX 语句或 ALTER TABLE 语句来对索引进行删除。 1) 使用 DROP INDEX 语句 语法格式： 1DROP INDEX &lt;索引名&gt; ON &lt;表名&gt; 语法说明如下： &lt;索引名&gt;：要删除的索引名。 &lt;表名&gt;：指定该索引所在的表名。 2) 使用 ALTER TABLE 语句 根据 ALTER TABLE 语句的语法可知，该语句也可以用于删除索引。具体使用方法是将 ALTER TABLE 语句的语法中部分指定为以下子句中的某一项。 DROP PRIMARY KEY：表示删除表中的主键。一个表只有一个主键，主键也是一个索引。 DROP INDEX index_name：表示删除名称为 index_name 的索引。 DROP FOREIGN KEY fk_symbol：表示删除外键。 注意：如果删除的列是索引的组成部分，那么在删除该列时，也会将该列从索引中删除；如果组成索引的所有列都被删除，那么整个索引将被删除。 删除索引 【实例 1】 删除表 tb_stu_info 中的索引，输入的 SQL 语句和执行结果如下所示。 123456789101112131415mysql&gt; DROP INDEX height -&gt; ON tb_stu_info;Query OK, 0 rows affected (0.27 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; SHOW CREATE TABLE tb_stu_info\\G*************************** 1. row *************************** Table: tb_stu_infoCreate Table: CREATE TABLE `tb_stu_info` ( `id` int(11) NOT NULL, `name` char(45) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, `age` int(11) DEFAULT NULL, `height` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=gb23121 row in set (0.00 sec) 【实例 2】 删除表 tb_stu_info2 中名称为 id 的索引，输入的 SQL 语句和执行结果如下所示。 123456789101112131415mysql&gt; ALTER TABLE tb_stu_info2 -&gt; DROP INDEX height;Query OK, 0 rows affected (0.13 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; SHOW CREATE TABLE tb_stu_info2\\G*************************** 1. row *************************** Table: tb_stu_info2Create Table: CREATE TABLE `tb_stu_info2` ( `id` int(11) NOT NULL, `name` char(45) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, `age` int(11) DEFAULT NULL, `height` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=gb23121 row in set (0.00 sec) 四、MySQL索引的设计原则 索引的设计可以遵循一些已有的原则，创建索引的时候应尽量考虑符合这些原则，便于提升索引的使用效率，更高效的使用索引。本节将介绍一些索引的设计原则。 1. 选择唯一性索引 唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。如果使用姓名的话，可能存在同名现象，从而降低查询速度。 2. 为经常需要排序、分组和联合操作的字段建立索引 经常需要 ORDER BY、GROUP BY、DISTINCT 和 UNION 等操作的字段，排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。 3. 为常作为查询条件的字段建立索引 如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。 注意：常查询条件的字段不一定是所要选择的列，换句话说，最适合索引的列是出现在 WHERE 子句中的列，或连接子句中指定的列，而不是出现在 SELECT 关键字后的选择列表中的列。 4. 限制索引的数目 索引的数目不是“越多越好”。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。在修改表的内容时，索引必须进行更新，有时还可能需要重构。因此，索引越多，更新表的时间就越长。 如果有一个索引很少利用或从不使用，那么会不必要地减缓表的修改速度。此外，MySQL 在生成一个执行计划时，要考虑各个索引，这也要花费时间。创建多余的索引给查询优化带来了更多的工作。索引太多，也可能会使 MySQL 选择不到所要使用的最佳索引。 **5. **尽量使用数据量少的索引 如果索引的值很长，那么查询的速度会受到影响。例如，对一个 CHAR(100) 类型的字段进行全文检索需要的时间肯定要比对 CHAR(10) 类型的字段需要的时间要多。 6. 数据量小的表最好不要使用索引 由于数据较小，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果。 7. 尽量使用前缀来索引 如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT 和 BLOG 类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。 **8. **删除不再使用或者很少使用的索引 表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。应该定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。 总结 选择索引的最终目的是为了使查询的速度变快，上面给出的原则是最基本的准则，但不能只拘泥于上面的准则。应该在学习和工作中不断的实践，根据应用的实际情况进行分析和判断，选择最合适的索引方式。 小练习 1234create index index_fruiton fruit(sid);show index from fruit; 12drop index index_fruit on fruit;show index from fruit; 创建索引的指导原则 按照下列标准选择建立索引的列 ◆频繁搜索的列 ◆经常用作查询选择的列 ◆经常排序、分组的列 ◆经常用作连接的列(主键/外键) 请不要使用下面的列创建索引 ◆仅包含几个不同值的列 ◆表中仅包含几行 使用索引时注意事项 查询时减少使用*返回全部列，不要返回不需要的列 索引应该尽量小，在字节数小的列上建立索引 WHERE子句中有多个条件表达式时，包含索引列的表达式应置3 F其他条件表达式之前 避免在ORDER BY子句中使用表达式","path":"posts/8338.html","date":"06-08","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL视图","text":"A：什么是视图？视图是干什么用的？ 视图（view）是一种虚拟存在的表，是一个逻辑表，本身并不包含数据。作为一个select语句保存在数据字典中的。 通过视图，可以展现基表的部分数据；视图数据来自定义视图的查询中使用的表，使用视图动态生成。 基表：用来创建视图的表叫做基表base table 数据库视图的创建是基于SQL SELECT query和JOIN的。视图和表很相似，它也包含行和列，所以可以直接对它进行查询操作。另外大多数的数据库同样允许进行UPADTE操作，但必须满足一定的条件。视图的数据结构如图： 我们需要理解，数据库并没有存储视图所关联的数据，存储的只是视图的定义也就是相应的SQL SELECT and JOIN。 B：为什么要使用视图？ （a）因为视图的诸多优点，如下 视图可以简化你的复杂查询：视图的定义是基于一个查询声明，这个查询声明可能关联了很多底层表。我们可以使用视图向数据库的使用者或者外部程序隐藏复杂的底层表关系。 视图可以限制特定用户的数据访问权：有时我们希望隐藏某些表的一些数据对一些特定用户，这时视图可以很好的帮助我们实现这个功能。 视图可以使用可计算的列：我们知道表的列一般都不支持动态计算，但是视图的列是支持的。假设在有一张order_details表，其中包含product_nums和price_each两列，当我们需要查询order总价时我们就需要查询出结果后在代码中进行计算，如果我们使用视图的话可以在视图中添加一列total_price(product_nums*price_each)。这样就可以直接查询出order的总价。 视图可以帮助我们兼容旧的系统：假设我们拥有一个数据中心，这个数据中心被很多的程序在使用。如果有一天我们决定重新设计这个数据中心以适应一些新的业务需求，可能需要删除一些旧的表，并且创建一些新的表，但是我们并不希望这些变动影响到那些老的程序。那么我们可以创建一些视图用来适配那些老的程序。 简单：使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。 安全：使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现。 数据独立：一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。 总而言之，使用视图的大部分情况是为了保障数据安全性，提高查询效率。 C：视图简易分析 百度百科定义了什么是视图，但是对缺乏相关知识的人可能还是难以理解或者只有一个比较抽象的概念，笔者举个例子来解释下什么是视图。 朕想要了解皇宫的国库的相关情况，想知道酒窖有什么酒，剩多少，窖藏多少年，于是派最信任的高公公去清点，高公公去国库清点后报给了朕；朕又想知道藏书情况，于是又派高公公去清点并回来报告给朕，又想知道金银珠宝如何，又派高公公清点。。。过一段时间又想知道藏书情况，高公公还得重新再去清点，皇上问一次，高公公就得跑一次路。 后来皇上觉得高公公不容易，就成立了国库管理部门，小邓子负责酒窖，小卓子负责藏书，而小六子负责金库的清点。。。后来皇上每次想了解国库就直接问话负责人，负责人就按照职责要求进行汇报。 安排专人管理后，每次皇上想要了解国库情况，就不必让高公公每次都跑一趟，而是指定的人员按照指定的任务完成指定的汇报工作就可以了。 和数据库相对应，每次进行查询工作，都需要编写查询代码进行查询；而视图的作用就是不必每次都重新编写查询的SQL代码，而是通过视图直接查询即可。因此： 视图是虚拟表，本身不存储数据，而是按照指定的方式进行查询。 D：使用场合 权限控制的时候，不希望用户访问表中某些含敏感信息的列，比如salary… 关键信息来源于多个复杂关联表，可以创建视图提取我们需要的信息，简化操作； E：视图相关的MySQL指令 操作指令 代码 创建视图 CREATE VIEW 视图名(列1，列2…) AS SELECT (列1，列2…) FROM …; 使用视图 当成表使用就好 修改视图 CREATE OR REPLACE VIEW 视图名 AS SELECT […] FROM […]; 查看数据库已有视图 &gt;SHOW TABLES [like...];（可以使用模糊查找） 查看视图详情 DESC 视图名或者SHOW FIELDS FROM 视图名 视图条件限制 [WITH CHECK OPTION] F：使用视图注意事项： 视图中可以使用多个表 一个视图可以嵌套另一个视图 对视图数据进行添加、更新和删除操作直接影响所引用表中的数据 当视图数据来自多个表时，不允许添加和删除数据 创建视图需要足够的访问权限。 创建视图的数目没有限制。 视图不能索引，也不能有关联的触发器、默认值或规则。 视图可以和表一起使用。 视图不包含数据，所以每次使用视图时，都必须执行查询中所需的任何一个检索操作。如果用多个连接和过滤条件创建了复杂的视图或嵌套了视图，可能会发现系统运行性能下降得十分严重。因此，在部署大量视图应用时，应该进行系统测试。 提示：ORDER BY 子句可以用在视图中，但若该视图检索数据的 SELECT 语句中也含有 ORDER BY 子句，则该视图中的 ORDER BY 子句将被覆盖。 一、MySql创建视图 创建视图与创建表语法类似，不同的是创建视图是从一条查询语句创建的。视图创建后，可以像一张表一样使用，但只能用于数据查询，如：可以在一个查询中使用、可以在存储过程中、可以在另一个视图中使用。MySql创建视图语法如下： 1CREATE VIEW 视图名 AS SELECT 查询语句; 创建表 1234567891011create table tb_students_info(true&#96;id&#96; int(4) not null comment &#39;id&#39; primary key auto_increment,true&#96;name&#96; varchar(50) not null comment &#39;name&#39;,true&#96;dept_id&#96; varchar(20) not null comment &#39;dept_id&#39;,true&#96;age&#96; int(4) unsigned comment &#39;age&#39;,true&#96;sex&#96; varchar(50) comment &#39;sex&#39;,true&#96;height&#96; int(4) unsigned comment &#39;height&#39;,true&#96;login_date&#96; datetime comment &#39;login_date&#39;)charset&#x3D;&#39;utf8&#39; comment&#x3D;&#39;tb_students_info&#39;;select * from tb_students_info; 插入数据 1234567891011insert into tb_students_info(id,name,dept_id,age,sex,height,login_date)values(1,&#39;Dany&#39;,&#39;1&#39;,&#39;25&#39;,&#39;F&#39;,&#39;160&#39;,&#39;2015-09-10&#39;),(2,&#39;Green&#39;,&#39;3&#39;,&#39;23&#39;,&#39;F&#39;,&#39;158&#39;,&#39;2016-10-22&#39;),(3,&#39;Henry&#39;,&#39;2&#39;,&#39;23&#39;,&#39;M&#39;,&#39;185&#39;,&#39;2015-05-31&#39;),(4,&#39;Jane&#39;,&#39;1&#39;,&#39;22&#39;,&#39;F&#39;,&#39;162&#39;,&#39;2016-12-20&#39;),(5,&#39;Jim&#39;,&#39;1&#39;,&#39;24&#39;,&#39;M&#39;,&#39;175&#39;,&#39;2016-01-15&#39;),(6,&#39;John&#39;,&#39;2&#39;,&#39;21&#39;,&#39;M&#39;,&#39;172&#39;,&#39;2015-11-11&#39;),(7,&#39;Lily&#39;,&#39;6&#39;,&#39;22&#39;,&#39;F&#39;,&#39;165&#39;,&#39;2016-02-26&#39;),(8,&#39;Susan&#39;,&#39;4&#39;,&#39;23&#39;,&#39;F&#39;,&#39;170&#39;,&#39;2015-10-01&#39;),(9,&#39;Thomas&#39;,&#39;3&#39;,&#39;22&#39;,&#39;M&#39;,&#39;178&#39;,&#39;2016-06-07&#39;),(10,&#39;Tom&#39;,&#39;4&#39;,&#39;23&#39;,&#39;M&#39;,&#39;165&#39;,&#39;2016-08-05&#39;); 查看一下 1select * from tb_students_info; 1、创建基于单表的视图 MySQL 可以在单个数据表上创建视图。 查看 test_db 数据库中的 tb_students_info 表的数据，如下所示。 12345678910111213141516mysql&gt; SELECT * FROM tb_students_info;+----+--------+---------+------+------+--------+---------------------+| id | name | dept_id | age | sex | height | login_date |+----+--------+---------+------+------+--------+---------------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 00:00:00 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 00:00:00 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 00:00:00 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 00:00:00 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 00:00:00 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 00:00:00 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 00:00:00 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 00:00:00 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 00:00:00 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 00:00:00 |+----+--------+---------+------+------+--------+---------------------+10 rows in set (0.00 sec) 【实例 1】 在 tb_students_info 表上创建一个名为 view_students_info 的视图，输入的 SQL 语句和执行结果如下所示。 1234567891011121314151617181920mysql&gt; CREATE VIEW view_students_info -&gt; AS SELECT * FROM tb_students_info;Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM view_students_info;+----+--------+---------+------+------+--------+---------------------+| id | name | dept_id | age | sex | height | login_date |+----+--------+---------+------+------+--------+---------------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 00:00:00 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 00:00:00 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 00:00:00 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 00:00:00 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 00:00:00 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 00:00:00 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 00:00:00 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 00:00:00 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 00:00:00 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 00:00:00 |+----+--------+---------+------+------+--------+---------------------+10 rows in set (0.00 sec) 默认情况下，创建的视图和基本表的字段是一样的，也可以通过指定视图字段的名称来创建视图。 【实例 2】 在 tb_students_info 表上创建一个名为 v_students_info 的视图，输入的 SQL 语句和执行结果如下所示。 12345678910111213141516171819202122mysql&gt; CREATE VIEW v_students_info -&gt; (s_id,s_name,d_id,s_age,s_sex,s_height,s_date) -&gt; AS SELECT id,name,dept_id,age,sex,height,login_date -&gt; FROM tb_students_info;Query OK, 0 rows affected (0.06 sec)mysql&gt; SELECT * FROM v_students_info;+------+--------+------+-------+-------+----------+---------------------+| s_id | s_name | d_id | s_age | s_sex | s_height | s_date |+------+--------+------+-------+-------+----------+---------------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 00:00:00 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 00:00:00 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 00:00:00 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 00:00:00 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 00:00:00 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 00:00:00 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 00:00:00 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 00:00:00 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 00:00:00 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 00:00:00 |+------+--------+------+-------+-------+----------+---------------------+10 rows in set (0.00 sec) 可以看到，view_students_info 和 v_students_info 两个视图中的字段名称不同，但是数据却相同。因此，在使用视图时，可能用户不需要了解基本表的结构，更接触不到实际表中的数据，从而保证了数据库的安全。 2、创建基于多表的视图 MySQL 中也可以在两个以上的表中创建视图，使用 CREATE VIEW 语句创建。 【实例 3】 在表 tb_student_info 和表 tb_departments 上创建视图 v_students_info，输入的 SQL 语句和执行结果如下所示。 123456789101112131415161718192021mysql&gt; CREATE VIEW v_students_info -&gt; (s_id,s_name,d_id,s_age,s_sex,s_height,s_date) -&gt; AS SELECT id,name,dept_id,age,sex,height,login_date -&gt; FROM tb_students_info;Query OK, 0 rows affected (0.06 sec)mysql&gt; SELECT * FROM v_students_info;+------+--------+------+-------+-------+----------+------------+| s_id | s_name | d_id | s_age | s_sex | s_height | s_date |+------+--------+------+-------+-------+----------+------------+| 1 | Dany | 1 | 24 | F | 160 | 2015-09-10 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 |+------+--------+------+-------+-------+----------+------------+10 rows in set (0.01 sec) 通过这个视图可以很好地保护基本表中的数据。视图中包含 s_id、s_name 和 dept_name，s_id 字段对应 tb_students_info 表中的 id 字段，s_name 字段对应 tb_students_info 表中的 name 字段，dept_name 字段对应 tb_departments 表中的 dept_name 字段。 二、查询视图 视图一经定义之后，就可以如同查询数据表一样，使用 SELECT 语句查询视图中的数据，语法和查询基础表的数据一样。 视图用于查询主要应用在以下几个方面： 使用视图重新格式化检索出的数据。 使用视图简化复杂的表连接。 使用视图过滤数据。 DESCRIBE 可以用来查看视图，语法如下： 1DESCRIBE 视图名； 【实例 4】 通过 DESCRIBE 语句查看视图 v_students_info 的定义，输入的 SQL 语句和执行结果如下所示。 12345678910111213mysql&gt; DESCRIBE v_students_info;+----------+---------------+------+-----+------------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+------------+-------+| s_id | int(11) | NO | | 0 | || s_name | varchar(45) | YES | | NULL | || d_id | int(11) | YES | | NULL | || s_age | int(11) | YES | | NULL | || s_sex | enum(&#39;M&#39;,&#39;F&#39;) | YES | | NULL | || s_height | int(11) | YES | | NULL | || s_date | date | YES | | 2016-10-22 | |+----------+---------------+------+-----+------------+-------+7 rows in set (0.04 sec) 1注意：DESCRIBE 一般情况下可以简写成 DESC，输入这个命令的执行结果和输入 DESCRIBE 是一样的。 1、查看视图的字段信息 查看视图的字段信息与查看数据表的字段信息一样，都是使用 DESCRIBE 关键字来查看的。具体语法如下： 1DESCRIBE 视图名; 或简写成： 1DESC 视图名; 示例 1 下面创建学生信息表 studentinfo 的一个视图，用于查询学生姓名和考试分数。 创建学生信息表 studentinfo 的 SQL 语句和运行结果如下： 1234567mysql&gt; CREATE TABLE studentinfo( -&gt; ID INT(11) PRIMARY KEY, -&gt; NAME VARCHAR(20), -&gt; SCORE DECIMAL(4,2), -&gt; SUBJECT VARCHAR(20), -&gt; TEACHER VARCHAR(20));Query OK, 0 rows affected (0.10 sec) 创建查询学生姓名和分数的视图语句如下： 12mysql&gt; CREATE VIEW v_studentinfo AS SELECT name,score FROM studentinfo;Query OK, 0 rows affected (0.04 sec) 通过 DESCRIBE 语句查看视图 v_studentsinfo 中的字段信息，SQL 语句和运行结果如下所示。 12345678mysql&gt; DESCRIBE v_studentinfo;+-------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || score | decimal(4,2) | YES | | NULL | |+-------+--------------+------+-----+---------+-------+2 rows in set (0.01 sec) 注意：使用 DESC 的执行结果和使用 DESCRIBE 是一样的。 由运行结果可以看出，查看视图的字段内容与查看表的字段内容显示的格式是相同的。因此，更能说明视图实际上也是一张数据表了，不同的是，视图中的数据都来自于数据库中已经存在的表。 查看视图的详细信息 在 MySQL 中，SHOW CREATE VIEW 语句可以查看视图的详细定义。其语法如下所示： 1SHOW CREATE VIEW 视图名; 通过上面的语句，还可以查看创建视图的语句。创建视图的语句可以作为修改或者重新创建视图的参考，方便用户操作。 示例 2 使用 SHOW CREATE VIEW 查看视图，SQL 语句和运行结果如下所示： 1234567mysql&gt; SHOW CREATE VIEW v_studentinfo \\G*************************** 1. row *************************** View: v_studentinfo Create View: CREATE ALGORITHM&#x3D;UNDEFINED DEFINER&#x3D;&#96;root&#96;@&#96;localhost&#96; SQL SECURITY DEFINER VIEW &#96;v_studentinfo&#96; AS select &#96;studentinfo&#96;.&#96;NAME&#96; AS &#96;name&#96;,&#96;studentinfo&#96;.&#96;SCORE&#96; AS &#96;score&#96; from &#96;studentinfo&#96;character_set_client: gbkcollation_connection: gbk_chinese_ci1 row in set (0.00 sec) 上述 SQL 语句以\\G结尾，这样能使显示结果格式化。如果不使用\\G，显示的结果会比较混乱，如下所示： 12345678910111213141516mysql&gt; DESCRIBE v_studentinfo;+-------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || score | decimal(4,2) | YES | | NULL | |+-------+--------------+------+-----+---------+-------+2 rows in set (0.01 sec)mysql&gt; SHOW CREATE VIEW v_studentinfo;+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+| View | Create View | character_set_client | collation_connection |+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+| v_studentinfo | CREATE ALGORITHM&#x3D;UNDEFINED DEFINER&#x3D;&#96;root&#96;@&#96;localhost&#96; SQL SECURITY DEFINER VIEW &#96;v_studentinfo&#96; AS select &#96;studentinfo&#96;.&#96;NAME&#96; AS &#96;name&#96;,&#96;studentinfo&#96;.&#96;SCORE&#96; AS &#96;score&#96; from &#96;studentinfo&#96; | gbk | gbk_chinese_ci |+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+1 row in set (0.01 sec) 二、 MySql视图修改 1、基本语法 可以使用 ALTER VIEW 语句来对已有的视图进行修改。 语法格式如下： 1ALTER VIEW 视图名 AS SELECT 查询语句; 语法说明如下： &lt;视图名&gt;：指定视图的名称。该名称在数据库中必须是唯一的，不能与其他表或视图同名。 &lt;SELECT 语句&gt;：指定创建视图的 SELECT 语句，可用于查询多个基础表或源视图。 需要注意的是，对于 ALTER VIEW 语句的使用，需要用户具有针对视图的 CREATE VIEW 和 DROP 权限，以及由 SELECT 语句选择的每一列上的某些权限。 修改视图的定义，除了可以通过 ALTER VIEW 外，也可以使用 DROP VIEW 语句先删除视图，再使用 CREATE VIEW 语句来实现。 2、修改视图内容 视图是一个虚拟表，实际的数据来自于基本表，所以通过插入、修改和删除操作更新视图中的数据，实质上是在更新视图所引用的基本表的数据。 注意：对视图的修改就是对基本表的修改，因此在修改时，要满足基本表的数据定义。 某些视图是可更新的。也就是说，可以使用 UPDATE、DELETE 或 INSERT 等语句更新基本表的内容。对于可更新的视图，视图中的行和基本表的行之间必须具有一对一的关系。 还有一些特定的其他结构，这些结构会使得视图不可更新。更具体地讲，如果视图包含以下结构中的任何一种，它就是不可更新的： 聚合函数 SUM()、MIN()、MAX()、COUNT() 等。 DISTINCT 关键字。 GROUP BY 子句。 HAVING 子句。 UNION 或 UNION ALL 运算符。 位于选择列表中的子查询。 FROM 子句中的不可更新视图或包含多个表。 WHERE 子句中的子查询，引用 FROM 子句中的表。 ALGORITHM 选项为 TEMPTABLE（使用临时表总会使视图成为不可更新的）的时候。 【实例 1】 使用 ALTER 语句修改视图 view_students_info，输入的 SQL 语句和执行结果如下所示。 12345678910111213mysql&gt; ALTER VIEW view_students_info -&gt; AS SELECT id,name,age -&gt; FROM tb_students_info;Query OK, 0 rows affected (0.07 sec)mysql&gt; DESC view_students_info;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | NO | | 0 | || name | varchar(45) | YES | | NULL | || age | int(11) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+3 rows in set (0.03 sec) 用户可以通过视图来插入、更新、删除表中的数据，因为视图是一个虚拟的表，没有数据。通过视图更新时转到基本表上进行更新，如果对视图增加或删除记录，实际上是对基本表增加或删除记录。 查看视图 view_students_info 的数据内容，如下所示。 12345678910111213141516mysql&gt; SELECT * FROM view_students_info;+----+--------+------+| id | name | age |+----+--------+------+| 1 | Dany | 24 || 2 | Green | 23 || 3 | Henry | 23 || 4 | Jane | 22 || 5 | Jim | 24 || 6 | John | 21 || 7 | Lily | 22 || 8 | Susan | 23 || 9 | Thomas | 22 || 10 | Tom | 23 |+----+--------+------+10 rows in set (0.00 sec) 【实例 2】 使用 UPDATE 语句更新视图 view_students_info，输入的 SQL 语句和执行结果如下所示。 1234567891011121314151617181920mysql&gt; UPDATE view_students_info -&gt; SET age&#x3D;25 WHERE id&#x3D;1;Query OK, 0 rows affected (0.24 sec)Rows matched: 1 Changed: 0 Warnings: 0mysql&gt; SELECT * FROM view_students_info;+----+--------+------+| id | name | age |+----+--------+------+| 1 | Dany | 25 || 2 | Green | 23 || 3 | Henry | 23 || 4 | Jane | 22 || 5 | Jim | 24 || 6 | John | 21 || 7 | Lily | 22 || 8 | Susan | 23 || 9 | Thomas | 22 || 10 | Tom | 23 |+----+--------+------+10 rows in set (0.00 sec) 查看基本表 tb_students_info 和视图 v_students_info 的内容，如下所示。 123456789101112131415161718192021222324252627282930313233mysql&gt; SELECT * FROM tb_students_info;+----+--------+---------+------+------+--------+------------+| id | name | dept_id | age | sex | height | login_date |+----+--------+---------+------+------+--------+------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 |+----+--------+---------+------+------+--------+------------+10 rows in set (0.00 sec)mysql&gt; SELECT * FROM v_students_info;+------+--------+------+-------+-------+----------+------------+| s_id | s_name | d_id | s_age | s_sex | s_height | s_date |+------+--------+------+-------+-------+----------+------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 |+------+--------+------+-------+-------+----------+------------+10 rows in set (0.00 sec) 3、修改视图名称 修改视图的名称可以先将视图删除，然后按照相同的定义语句进行视图的创建，并命名为新的视图名称。 三、MySql视图删除 1、基本语法 可以使用 DROP VIEW 语句来删除视图。 语法格式如下： 1DROP VIEW &lt;视图名1&gt; [ , &lt;视图名2&gt; …] 其中：&lt;视图名&gt;指定要删除的视图名。DROP VIEW 语句可以一次删除多个视图，但是必须在每个视图上拥有 DROP 权限。 2、删除视图 【实例】删除 v_students_info 视图，输入的 SQL 语句和执行过程如下所示。 1234mysql&gt; DROP VIEW IF EXISTS v_students_info;Query OK, 0 rows affected (0.00 sec)mysql&gt; SHOW CREATE VIEW v_students_info;ERROR 1146 (42S02): Table &#39;test_db.v_students_info&#39; doesn&#39;t exist 可以看到，v_students_info 视图已不存在，将其成功删除。 小练习 123456789101112#删除视图drop view if EXISTS view_student_for_teacher;#创建视图create view view_student_for_teacher asselect studentNo,studentName,sex,gradeName,phonefrom student sjoin grade gon s.gradeId &#x3D; g.gradeID;#查看视图select * from view_student_for_teacher; ![image-20200611173158789](G:\\四期\\数据库\\mysql文档\\06 视图.assets\\image-20200611173158789.png) 1234#查看数据库的视图use information_schema;SELECT * from views\\G;select * from views where table_schema ='myschool'\\G; 视图实例1-创建视图及查询数据操作 现有三张表：用户(user)、课程(course)、用户课程中间表(user_course)，表结构及数据如下： 表定义： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859-- ------------------------------ Table structure for &#96;course&#96;-- ----------------------------DROP TABLE IF EXISTS &#96;course&#96;;CREATE TABLE &#96;course&#96; ( &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT, &#96;name&#96; varchar(200) NOT NULL, &#96;description&#96; varchar(500) NOT NULL, PRIMARY KEY (&#96;id&#96;)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;4 DEFAULT CHARSET&#x3D;utf8;-- ------------------------------ Records of course-- ----------------------------INSERT INTO &#96;course&#96; VALUES (&#39;1&#39;, &#39;JAVA&#39;, &#39;JAVA课程&#39;);INSERT INTO &#96;course&#96; VALUES (&#39;2&#39;, &#39;C++&#39;, &#39;C++课程&#39;);INSERT INTO &#96;course&#96; VALUES (&#39;3&#39;, &#39;C语言&#39;, &#39;C语言课程&#39;);-- ------------------------------ Table structure for &#96;user&#96;-- ----------------------------DROP TABLE IF EXISTS &#96;user&#96;;CREATE TABLE &#96;user&#96; ( &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT, &#96;account&#96; varchar(255) NOT NULL, &#96;name&#96; varchar(255) NOT NULL, &#96;address&#96; varchar(255) DEFAULT NULL, &#96;others&#96; varchar(200) DEFAULT NULL, &#96;others2&#96; varchar(200) DEFAULT NULL, PRIMARY KEY (&#96;id&#96;)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;4 DEFAULT CHARSET&#x3D;utf8;-- ------------------------------ Records of user-- ----------------------------INSERT INTO &#96;user&#96; VALUES (&#39;1&#39;, &#39;user1&#39;, &#39;小陈&#39;, &#39;美国&#39;, &#39;1&#39;, &#39;1&#39;);INSERT INTO &#96;user&#96; VALUES (&#39;2&#39;, &#39;user2&#39;, &#39;小张&#39;, &#39;日本&#39;, &#39;2&#39;, &#39;2&#39;);INSERT INTO &#96;user&#96; VALUES (&#39;3&#39;, &#39;user3&#39;, &#39;小王&#39;, &#39;中国&#39;, &#39;3&#39;, &#39;3&#39;);-- ------------------------------ Table structure for &#96;user_course&#96;-- ----------------------------DROP TABLE IF EXISTS &#96;user_course&#96;;CREATE TABLE &#96;user_course&#96; ( &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT, &#96;userid&#96; bigint(20) NOT NULL, &#96;courseid&#96; bigint(20) NOT NULL, PRIMARY KEY (&#96;id&#96;)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;7 DEFAULT CHARSET&#x3D;utf8;-- ------------------------------ Records of user_course-- ----------------------------INSERT INTO &#96;user_course&#96; VALUES (&#39;1&#39;, &#39;1&#39;, &#39;2&#39;);INSERT INTO &#96;user_course&#96; VALUES (&#39;2&#39;, &#39;1&#39;, &#39;3&#39;);INSERT INTO &#96;user_course&#96; VALUES (&#39;3&#39;, &#39;2&#39;, &#39;1&#39;);INSERT INTO &#96;user_course&#96; VALUES (&#39;4&#39;, &#39;2&#39;, &#39;2&#39;);INSERT INTO &#96;user_course&#96; VALUES (&#39;5&#39;, &#39;2&#39;, &#39;3&#39;);INSERT INTO &#96;user_course&#96; VALUES (&#39;6&#39;, &#39;3&#39;, &#39;2&#39;); 这时，当我们想要查询小张上的所以课程相关信息的时候，需要这样写一条长长的SQL语句，如下： 12345678910SELECT &#96;uc&#96;.&#96;id&#96; AS &#96;id&#96;, &#96;u&#96;.&#96;name&#96; AS &#96;username&#96;, &#96;c&#96;.&#96;name&#96; AS &#96;coursename&#96;FROM &#96;user&#96; &#96;u&#96;LEFT JOIN &#96;user_course&#96; &#96;uc&#96; ON ((&#96;u&#96;.&#96;id&#96; &#x3D; &#96;uc&#96;.&#96;userid&#96;))LEFT JOIN &#96;course&#96; &#96;c&#96; ON ((&#96;uc&#96;.&#96;courseid&#96; &#x3D; &#96;c&#96;.&#96;id&#96;))WHERE u.&#96;name&#96; &#x3D; &#39;小张&#39; 但是我们可以通过视图简化操作，例如我们创建视图view_user_course如下： 12345678910111213141516171819202122-- ------------------------------ View structure for &#96;view_user_course&#96;-- ----------------------------DROP VIEWIF EXISTS &#96;view_user_course&#96;;CREATE ALGORITHM &#x3D; UNDEFINED DEFINER &#x3D; &#96;root&#96;@&#96;localhost&#96; SQL SECURITY DEFINER VIEW &#96;view_user_course&#96; AS ( SELECT &#96;uc&#96;.&#96;id&#96; AS &#96;id&#96;, &#96;u&#96;.&#96;name&#96; AS &#96;username&#96;, &#96;c&#96;.&#96;name&#96; AS &#96;coursename&#96; FROM ( ( &#96;user&#96; &#96;u&#96; LEFT JOIN &#96;user_course&#96; &#96;uc&#96; ON ((&#96;u&#96;.&#96;id&#96; &#x3D; &#96;uc&#96;.&#96;userid&#96;)) ) LEFT JOIN &#96;course&#96; &#96;c&#96; ON ((&#96;uc&#96;.&#96;courseid&#96; &#x3D; &#96;c&#96;.&#96;id&#96;)) )); 几点说明（MySQL中的视图在标准SQL的基础之上做了扩展）： ALGORITHM=UNDEFINED：指定视图的处理算法； DEFINER=root@localhost：指定视图创建者； SQL SECURITY DEFINER：指定视图查询数据时的安全验证方式； 创建好视图之后，我们可以直接用以下SQL语句在视图上查询小张上的所以课程相关信息，同样可以得到所需结果： 1234567SELECT vuc.username, vuc.coursenameFROM view_user_course vucWHERE vuc.username &#x3D; &#39;小张&#39; 视图实例2-增删改数据操作 继续，我们可以尝试在视图view_user_course上做增删改数据操作，如下： 1update view_user_course set username&#x3D;&#39;test&#39;,coursename&#x3D;&#39;JAVASCRIPT&#39; where id&#x3D;3 遗憾的是操作失败，提示错误信息如下： 123[SQL] update view_user_course set username&#x3D;&#39;test&#39;,coursename&#x3D;&#39;JAVASCRIPT&#39; where id&#x3D;3[Err] 1393 - Can not modify more than one base table through a join view &#39;demo.view_user_course&#39; 因为不能在一张由多张关联表连接而成的视图上做同时修改两张表的操作； 那么哪些操作可以在视图上进行呢？ 视图与表是一对一关系情况：如果没有其它约束（如视图中没有的字段，在基本表中是必填字段情况），是可以进行增删改数据操作； 如我们创建用户关键信息视图view_user_keyinfo，如下： 123456789101112-- ------------------------------ View structure for &#96;view_user_keyinfo&#96;-- ----------------------------DROP VIEWIF EXISTS &#96;view_user_keyinfo&#96;;CREATE ALGORITHM &#x3D; UNDEFINED DEFINER &#x3D; &#96;root&#96;@&#96;localhost&#96; SQL SECURITY DEFINER VIEW &#96;view_user_keyinfo&#96; AS SELECT &#96;u&#96;.&#96;id&#96; AS &#96;id&#96;, &#96;u&#96;.&#96;account&#96; AS &#96;account&#96;, &#96;u&#96;.&#96;name&#96; AS &#96;username&#96;FROM &#96;user&#96; &#96;u&#96;; 进行增删改操作如下，操作成功（注意user表中的其它字段要允许为空，否则操作失败）： 1234567891011121314INSERT INTO view_user_keyinfo (account, username)VALUES (&#39;test1&#39;, &#39;test1&#39;);DELETEFROM view_user_keyinfoWHERE username &#x3D; &#39;test1&#39;;UPDATE view_user_keyinfoSET username &#x3D; &#39;updateuser&#39;WHERE id &#x3D; 1 视图与表是一对多关系情况：如果只修改一张表的数据，且没有其它约束（如视图中没有的字段，在基本表中是必填字段情况），是可以进行改数据操作，如以下语句，操作成功； 123update view_user_course set coursename&#x3D;&#39;JAVA&#39; where id&#x3D;1;update view_user_course set username&#x3D;&#39;test2&#39; where id&#x3D;3; 以下操作失败： 123delete from view_user_course where id&#x3D;3;insert into view_user_course(username, coursename) VALUES(&#39;2&#39;,&#39;3&#39;);","path":"posts/a0ec.html","date":"06-07","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL子查询","text":"子查询 子查询指一个查询语句嵌套在另一个查询语句内部的查询，这个特性从mysql4.1开始引入。在select子句中先计算子查询，子查询结果作为外层另一个查询的过滤条件，查询可以基于一个表或者多个表。子查询中常用的操作符有any（some）、all、in、exists。子查询可以添加到select、update和delete语句中，而且可以进行多层嵌套。子查询中也可以使用比较运算符，如“&lt;”,“&lt;=”,“&gt;”,“&gt;=”和“!=”等。 示例1 12SELECT * from studentWHERE studentName &#x3D; &#39;李文才&#39;; 示例2 12345SELECT * from studentWHERE studentName &#x3D; true(select studentName from studenttruetruewhere studentNo&#x3D;10001true); 示例3 12345# 请查找出年龄大于15岁的学生# select * from student# where 年龄 &gt; 15;select DATEDIFF(NOW(),&#39;2005-01-01&#39;) &#x2F;365 （1）带any、some关键字的子查询 any和some关键字是同义词，表示满足其中任一条件，它们允许创建一个表达式对子查询的返回值列进行比较，只要满足内层子查询中的任何一个比较条件，就返回一个结果作为外层查询的条件。 12345create table tb1(truenum1 int not null);insert into tb1 values(1),(5),(13),(27);select * from tb1; 12345create table tb2(truenum2 int not null);insert into tb2 values(6),(14),(11),(20);select * from tb2; 1234# 查询tb1比tb2大的数select num1 from tb1where num1 &gt; any(select num2 from tb2); （2）带all关键字的子查询 all关键字与any和some不同，使用all时需要同时满足所有内层查询的条件 1234# tb1中大于tb2所有数字select num1 from tb1where num1 &gt; all(select num2 from tb2); （3）带exists关键字的子查询 exists关键字后面的参数是一个任意的子查询，系统对子查询进行运算以判断它是否返回行，如果至少返回一行，那么exists的结果为true，此时外层查询语句将进行查询；如果子查询没有返回任何行，那么exists返回的结果是false，此时外层语句将不进行查询。 12345678910111213141516171819create table suppliers( s_id int not null auto_increment, s_name char(50) not null, s_city char(50) null, s_zip char(10) null, s_call char(50) not null, primary key(s_id));insert into suppliers(s_id,s_name,s_city,s_zip,s_call)values(101,&#39;FastFruit Inc.&#39;,&#39;tianjin&#39;,&#39;300000&#39;,&#39;48075&#39;),(102,&#39;LT Supplies&#39;,&#39;chongqing&#39;,&#39;400000&#39;,&#39;44333&#39;),(103,&#39;acme&#39;,&#39;shanghai&#39;,&#39;200000&#39;,&#39;90046&#39;),(104,&#39;fnk inc.&#39;,&#39;zhongshan&#39;,&#39;528437&#39;,&#39;11111&#39;),(105,&#39;good set&#39;,&#39;taiyuang&#39;,&#39;030000&#39;,&#39;22222&#39;),(106,&#39;just eat ours&#39;,&#39;beijing&#39;,&#39;010&#39;,&#39;45678&#39;),(107,&#39;dk inc.&#39;,&#39;zhengzhou&#39;,&#39;450000&#39;,&#39;33332&#39;);select * from suppliers; 123select * from fruit where EXISTS(trueSELECT * from suppliers where s_id&#x3D;107); （4）带in关键字的子查询 in关键字进行子查询时，内层查询语句仅仅返回一个数据列，这个数据列里的值将提供给外层查询语句进行比较操作。 123456789mysql&gt; select c_id from orders where o_num in-&gt; (select o_num from orderitems where f_id &#x3D; &#39;c0&#39;);+-------+| c_id |+-------+| 10004 || 10001 |+-------+2 rows in set (0.00 sec) （5）带比较运算符的子查询 1234567891011mysql&gt; select s_id,f_name from fruits-&gt; where s_id &#x3D;-&gt; (select s1.s_id from suppliers as s1 where s1.s_city&#x3D;&#39;tianjin&#39;);+------+------------+| s_id | f_name |+------+------------+| 101 | apple || 101 | blackberry || 101 | cherry |+------+------------+3 rows in set (0.00 sec) 5、合并查询结果 利用union关键字，可以给出多条select语句，并将它们的结果组合成单个结果集。合并时，两个表对应的列数和数据类型必须相同。各个select语句之间使用union或union all关键字分隔。union不使用关键字all，执行的时候删除重复的记录，所有返回的行都是唯一的；使用关键字all的作用是不删除重复行也不对结果进行自动排序。 123456# 合并select sid,sname,sprice from fruitlwhere sprice &gt; 6UNION all select * from fruitwhere sid in (101,104); 123456# 合并select sid,sname,sprice from fruitwhere sprice &gt; 6UNIONselect * from fruitwhere sid in (101,104); union和union all的区别：使用union all的功能是不删除重复行，加上all关键字语句执行时所需要的资源少，所以尽可能地使用它，因此知道有重复行但是想保留这些行，确定查询结果中不会有重复数据或者不需要去掉重复数据的时候，应当使用union all以提高查询效率。 6、为表和字段取别名 前面介绍了分组查询、聚合函数查询和嵌套子查询，取别名使用关键字as为查询结果中的某一列指定一个特别的名字。可以为字段或者表分别取别名，在查询时，使用别名替代指定的内容。 （1）为表取别名 12345678mysql&gt; select * from orders as o-&gt; where o.o_num &#x3D; 30001;+-------+---------------------+-------+| o_num | o_date | c_id |+-------+---------------------+-------+| 30001 | 2008-09-01 00:00:00 | 10001 |+-------+---------------------+-------+1 row in set (0.00 sec) （2）为字段取别名 1234567891011121314151617mysql&gt; select f1.f_name as fruits_name ,f1.f_price as fruits_price-&gt; from fruits as f1-&gt; where f1.f_price &lt; 8;+-------------+--------------+| fruits_name | fruits_price |+-------------+--------------+| apple | 5.20 || apricot | 2.20 || berry | 7.60 || xxxx | 3.60 || cherry | 3.20 || lemon | 6.40 || xbabay | 2.60 || grape | 5.30 || xbababa | 3.60 |+-------------+--------------+9 rows in set (0.01 sec) 7、使用正则表达式查询 正则表达式通常被用来检索或替换那些符合某个模式的文本内容，根据指定的匹配模式匹配文本中符合要求的特殊字符串。例如从一个文本文件中提取电话号码，查找一篇文章中重复的单词或者替换用户输入的某些敏感词语等等，这些地方都可以使用正则表达式。正则表达式强大且灵活，可以应用于非常复杂的查询。mysql中使用regexp关键字指定正则表达式的字符匹配模式。 （1）查询以特定字符或字符串开头的记录 1select * from fruit where sname regexp &#39;^苹&#39;; （2）查询以特定字符或字符串结尾的记录 1select * from fruit where sname regexp &#39;果$&#39;; （3）用符合‘.’来代替字符串中的任意一个字符 1select * from fruit where sname regexp &#39;.果&#39;; （4）匹配指定字符中的任意一个 1select * from student where sex regexp &#39;[男]&#39;; （5）使用“*”和“+”来匹配多个字符 1select studentName from student where studentName regexp &#39;^李*露&#39;; 1select studentName from student where studentName regexp &#39;^李+露&#39;; （6）匹配指定字符以外的字符 1select * from student where sex regexp &#39;[^男]&#39;; （7）使用{n,}或者{n,m}来指定字符串连续出现的次数 1select studentName from student where studentName regexp &#39;李&#123;0,&#125;&#39;;","path":"posts/b19d.html","date":"06-06","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL高级查询","text":"回想 123456select studentNo, studentName, sex, gradeNamefrom student s,grade gwhere s.gradeId &#x3D; g.gradeID;select studentNo,studentName,sex,gradeNamefrom student s join grade gon s.gradeId &#x3D; g.gradeID; ![image-20200610140605161](G:\\四期\\数据库\\mysql文档\\05 mysql通算符.assets\\image-20200610140605161.png) 123select count(1), sex from studentgroup by sexHAVING sex &#x3D;&#39;男&#39;; ![image-20200610140916671](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610140916671.png) 123# 排序select * from studentLIMIT 4,5; ![image-20200610141016816](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610141016816.png) 12SELECT * from studentwhere studentNo in (&#39;10005&#39;,&#39;10001&#39;); ![image-20200610141245878](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610141245878.png) 12SELECT * from studentwhere studentNo BETWEEN 10001 and 10005; ![image-20200610141437404](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610141437404.png) 123select * from studentwhere email is nulland identityCard is null; ![image-20200610141528016](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610141528016.png) 查询数据 数据库管理系统的一个最重要的功能就是数据查询，数据查询不应只是简单查询数据库中存储的数据，还应该根据需要对数据进行筛选，以及确定数据以什么样的格式显示。MySQL提供了功能强大、灵活的语句来实现这些操作。 1、基本查询语句 mysql从数据表中查询数据的基本语句为select语句。select语句的基本格式是： 12SELECT &#123;* | &lt;字段列表&gt;&#125; [ FROM &lt;表1&gt;, &lt;表2&gt;.... [ where &lt;表达式&gt; ] [ group by ] [ having ] [ order by&lt;..&gt; ] [ limit &lt;...&gt; ] {*|&lt;字段列表&gt;}包含星号通配符选择字段列表，表示查询的字段，其中字段列至少包含一个字段名称，如果要查询多个字段，多个字段之间用逗号隔开，最后一个字段后不要加逗号。 FROM&lt;表1&gt;,&lt;表2&gt;…：表1和表2表示查询数据的来源，可以是单个或多个。 WHERE子句是可选项，如果选择该项，将限定查询必须满足的查询条件。 GROUP BY&lt;字段&gt;，该子句告诉MySQL按什么样的顺序显示查询出来的数据，可以进行的排序有：升序（asc）、降序（desc）。 [limit]，该子句告诉mysql每次显示查询出来的数据条款。 12345678910111213141516171819202122232425262728mysql&gt; create table fruits-&gt; (-&gt; f_id char(10) not null,-&gt; s_id int not null,-&gt; f_name char(255) not null,-&gt; f_price decimal(8,2) not null,-&gt; primary key(f_id)-&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into fruits(f_id,s_id,f_name,f_price)-&gt; values(&#39;a1&#39;,101,&#39;apple&#39;,&#39;5.2&#39;),-&gt; (&#39;b1&#39;,101,&#39;blackberry&#39;,&#39;10.2&#39;),-&gt; (&#39;bs1&#39;,102,&#39;orange&#39;,&#39;11.2&#39;),-&gt; (&#39;bs2&#39;,105,&#39;melon&#39;,&#39;8.2&#39;),-&gt; (&#39;t1&#39;,102,&#39;banana&#39;,&#39;10.3&#39;),-&gt; (&#39;t2&#39;,102,&#39;grape&#39;,&#39;5.3&#39;),-&gt; (&#39;o2&#39;,103,&#39;coconut&#39;,&#39;9.2&#39;),-&gt; (&#39;c0&#39;,101,&#39;cherry&#39;,&#39;3.2&#39;),-&gt; (&#39;a2&#39;,103,&#39;apricot&#39;,&#39;2.2&#39;),-&gt; (&#39;l2&#39;,104,&#39;lemon&#39;,&#39;6.4&#39;),-&gt; (&#39;b2&#39;,104,&#39;berry&#39;,&#39;7.6&#39;),-&gt; (&#39;m1&#39;,106,&#39;mango&#39;,&#39;15.7&#39;),-&gt; (&#39;m2&#39;,105,&#39;xbabay&#39;,&#39;2.6&#39;),-&gt; (&#39;t4&#39;,107,&#39;xbababa&#39;,&#39;3.6&#39;),-&gt; (&#39;m3&#39;,105,&#39;xxtt&#39;,&#39;11.6&#39;),-&gt; (&#39;b5&#39;,107,&#39;xxxx&#39;,&#39;3.6&#39;);Query OK, 16 rows affected (0.02 sec)Records: 16 Duplicates: 0 Warnings: 0 2、单表查询 单表查询是指从一张表数据中查询所需的数据。主要有：查询所有字段、查询指定字段、查询指定记录、查询空值、多条件的查询、对查询结果进行排序等方式。 &lt;1&gt;查询所有字段 在select语句中使用星号（）通配符查询所有字段。 select查询记录最简单的形式是从一个表中检索所有记录，实现的方法是使用星号（）通配符指定查找所有列的名称。 1mysql&gt; select * from fruits; &lt;2&gt;在select语句中指定所有字段 根据前面select语句的格式，select关键字后面的字段名为将要查询的数据，因此可以将表中所有字段的名称跟在select子句后面，如果忘记了字段名称，可以使用DESC命令查看表的结构。有时候，由于表中的字段多，不一定能记住所有的字段名称。因此很不方便，不建议使用。 1Select f_id,s_id,f_name,f_price from fruit （1）查询指定字段 1select 字段名 from 表名； 12345678910111213141516171819202122mysql&gt; select f_name from fruits;+------------+| f_name |+------------+| apple || apricot || blackberry || berry || xxxx || orange || melon || cherry || lemon || mango || xbabay || xxtt || coconut || banana || grape || xbababa |+------------+16 rows in set (0.00 sec) （2）查询多个字段 使用select声明，可以获取多个字段下的数据，只需要在关键字select后面指定要查询的字段的名称，不同字段名称之间用逗号分隔，最后一个字段后面不需要加逗号 1select 字段1，字段2，字段3 ....，字段n from 表名； 12345678910111213141516171819202122mysql&gt; select f_name,f_price from fruits;+------------+---------+| f_name | f_price |+------------+---------+| apple | 5.20 || apricot | 2.20 || blackberry | 10.20 || berry | 7.60 || xxxx | 3.60 || orange | 11.20 || melon | 8.20 || cherry | 3.20 || lemon | 6.40 || mango | 15.70 || xbabay | 2.60 || xxtt | 11.60 || coconut | 9.20 || banana | 10.30 || grape | 5.30 || xbababa | 3.60 |+------------+---------+16 rows in set (0.01 sec) （3）查询指定记录 数据库中包含大量的数据，根据特殊要求可能只需要查询表中的指定数据，相当于对数据的过滤。在select语句中，通过where子句可以对数据进行过滤。 1select 字段1，字段2....字段n from 表名 where 查询条件； ![image-20200613131557954](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613131557954.png) 123456789mysql&gt; select f_name,f_price-&gt; from fruits-&gt; where f_price &#x3D; 10.2;+------------+---------+| f_name | f_price |+------------+---------+| blackberry | 10.20 |+------------+---------+1 row in set (0.01 sec) （4）带in关键字的查询 in操作符用来查询满足指定范围内的条件的记录，使用IN操作符，将所有检索条件用括号括起来，检索条件之间用逗号分隔开，只要满足条件范围内的一个值即为匹配项。 123456789101112131415mysql&gt; select s_id,f_name,f_price-&gt; from fruits-&gt; where s_id in (101,102)-&gt; order by f_name;+------+------------+---------+| s_id | f_name | f_price |+------+------------+---------+| 101 | apple | 5.20 || 102 | banana | 10.30 || 101 | blackberry | 10.20 || 101 | cherry | 3.20 || 102 | grape | 5.30 || 102 | orange | 11.20 |+------+------------+---------+6 rows in set (0.00 sec) （5）带between and的范围查询 Between and用来查询某个范围内的值，该操作符需要两个参数，即范围的开始值和结束值，如果字段值满足指定的范围查询条件，则这些记录被返回。 1234567891011121314151617181920mysql&gt; select f_name,f_price-&gt; from fruits-&gt; where f_price between 2.00 and 10.20;+------------+---------+| f_name | f_price |+------------+---------+| apple | 5.20 || apricot | 2.20 || blackberry | 10.20 || berry | 7.60 || xxxx | 3.60 || melon | 8.20 || cherry | 3.20 || lemon | 6.40 || xbabay | 2.60 || coconut | 9.20 || grape | 5.30 || xbababa | 3.60 |+------------+---------+12 rows in set (0.00 sec) （7）带like的字符匹配查询 通配符是一种在SQL的where条件子句中拥有特殊意思的字符，SQL语句中支持多种通配符，可以和like一起使用的通配符有‘%’和‘_’。 &lt;1&gt;百分号（%）通配符，匹配任意长度的字符，甚至包括零字符 1234567891011mysql&gt; select f_id,f_name-&gt; from fruits-&gt; where f_name like &#39;b%&#39;;+------+------------+| f_id | f_name |+------+------------+| b1 | blackberry || b2 | berry || t1 | banana |+------+------------+3 rows in set (0.00 sec) &lt;2&gt;下划线（__)通配符，一次只能匹配任意一个字符 123456789mysql&gt; select f_id,f_name-&gt; from fruits-&gt; where f_name like &#39;____y&#39;;+------+--------+| f_id | f_name |+------+--------+| b2 | berry |+------+--------+1 row in set (0.00 sec) （8）查询空值 数据表创建的时候，设计者可以指定某列中是否可以包含空值（NULL)。空值不同于0，也不同于空字符串。空值一般表示数据未知、不适用或将在以后添加数据。在select语句中使用IS NULL子句，可以查询某字段内容为空的记录。 1234567891011121314151617181920212223242526272829mysql&gt; create table customers-&gt; (-&gt; c_id int not null auto_increment,-&gt; c_name char(50) not null,-&gt; c_address char(50) null,-&gt; c_city char(50) null,-&gt; c_zip char(50) null,-&gt; c_contact char(50) null,-&gt; c_email char(50) null,-&gt; primary key(c_id)-&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into customers(c_id,c_name,c_address,c_city,c_zip,c_contact,c_email)-&gt; values(10001,&#39;RedHook&#39;,&#39;200Street&#39;,&#39;Tianjin&#39;,&#39;300000&#39;,&#39;LiMing&#39;,&#39;LMing@163.com&#39;),-&gt; (10002,&#39;Stars&#39;,&#39;333 FromageLane&#39;,&#39;Dalian&#39;,&#39;116000&#39;,&#39;Zhangbo&#39;,&#39;Jerry@hotmail.com&#39;),-&gt; (10003,&#39;Netbhood&#39;,&#39;1 Sunny Place&#39;,&#39;Qingdao&#39;,&#39;266000&#39;,&#39;LuoCong&#39;,NULL),-&gt;(10004,&#39;JOTO&#39;,&#39;829 Riverside Drive&#39;, &#39;Haikou&#39;,&#39;570000&#39;,&#39;YangShan&#39;,&#39;sam@hotmail.com&#39;);Query OK, 4 rows affected (0.02 sec)Records: 4 Duplicates: 0 Warnings: 0mysql&gt; select c_id,c_name,c_email from customers where c_email IS NULL;+-------+----------+---------+| c_id | c_name | c_email |+-------+----------+---------+| 10003 | Netbhood | NULL |+-------+----------+---------+1 row in set (0.01 sec) （9）带and的多条件查询 使用select查询时，可以增加查询的限制条件，这样可以使查询的结果更加精确。MySQL在where子句中使用and操作符限定只有满足所有查询条件的记录才会被返回。可以使用and连接两个甚至多个查询条件，多个条件表达式之间用and分开。 12345678910mysql&gt; select f_id,f_price,f_name-&gt; from fruits-&gt; where s_id &#x3D; &#39;101&#39; and f_price &gt;&#x3D;5;+------+---------+------------+| f_id | f_price | f_name |+------+---------+------------+| a1 | 5.20 | apple || b1 | 10.20 | blackberry |+------+---------+------------+2 rows in set (0.00 sec) （10）带or的多条件查询 与and相反，在where声明中使用or操作符，表示只需要满足其中一个条件的记录即可返回。or也可以连接两个甚至多个查询条件，多个条件表达式之间用or分开。 1234567891011121314mysql&gt; select s_id,f_name,f_price-&gt; from fruits-&gt; where s_id &#x3D; 101 or s_id &#x3D; 102;+------+------------+---------+| s_id | f_name | f_price |+------+------------+---------+| 101 | apple | 5.20 || 101 | blackberry | 10.20 || 102 | orange | 11.20 || 101 | cherry | 3.20 || 102 | banana | 10.30 || 102 | grape | 5.30 |+------+------------+---------+6 rows in set (0.00 sec) （11）查询结果不重复 12345678910111213141516171819# 查询不重复# 创建表create table &#96;fruit&#96;(true&#96;sid&#96; int(3) PRIMARY KEY not null,true&#96;sname&#96; VARCHAR(20) not NULL,true&#96;sprice&#96; FLOAT not null)CHARSET &#39;utf8mb4&#39;;# 表中添加数据insert into &#96;fruit&#96;(sid,sname,sprice)values(100,&#39;芒果&#39;,5.00),(101,&#39;苹果&#39;,5.00),(102,&#39;香蕉&#39;,7.00),(103,&#39;梨&#39;,6.00),(104,&#39;火龙果&#39;,10.00),(105,&#39;榴莲&#39;,15.00);# 查看一下select * from fruit; ![image-20200613132514405](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613132514405.png) 12345#去掉重复数据select DISTINCT sprice from fruit;select DISTINCT sex from student S join grade gon s.gradeId &#x3D; g.gradeID； ![image-20200613132441783](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613132441783.png) 123#聚合函数select max(sprice) 最高价,min(sprice),sum(sprice),avg(sprice) from fruit; ![](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613132535375.png) 3、对查询结果排序 （1）单列排序 123456789mysql&gt; select f_name from fruits;+------------+| f_name |+------------+| apple || apricot || blackberry || berry || xxxx | （2）多列排序 12345678910111213141516171819202122mysql&gt; select f_name,f_price from fruits order by f_name,f_price;+------------+---------+| f_name | f_price |+------------+---------+| apple | 5.20 || apricot | 2.20 || banana | 10.30 || berry | 7.60 || blackberry | 10.20 || cherry | 3.20 || coconut | 9.20 || grape | 5.30 || lemon | 6.40 || mango | 15.70 || melon | 8.20 || orange | 11.20 || xbababa | 3.60 || xbabay | 2.60 || xxtt | 11.60 || xxxx | 3.60 |+------------+---------+16 rows in set (0.00 sec) 在多列进行排序的时候，首先排序的第一列必须有相同的列值，才会对第二列进行排序。如果第一列数据中所有值都是唯一的，将不再对第二列进行排序。 （3）指定排序方向 默认情况下，查询数据按字母升序进行排序（从A~Z)，但数据的排序并不仅限于此，还可以使用order by对查询结果进行降序排序（从Z~A)，这可以通过关键字DESC实现。 12345678910111213141516171819202122mysql&gt; select f_name,f_price from fruits order by f_name,f_price DESC;+------------+---------+| f_name | f_price |+------------+---------+| apple | 5.20 || apricot | 2.20 || banana | 10.30 || berry | 7.60 || blackberry | 10.20 || cherry | 3.20 || coconut | 9.20 || grape | 5.30 || lemon | 6.40 || mango | 15.70 || melon | 8.20 || orange | 11.20 || xbababa | 3.60 || xbabay | 2.60 || xxtt | 11.60 || xxxx | 3.60 |+------------+---------+16 rows in set (0.01 sec) 与DESC相反ASC是升序 4、分组查询 分组插叙是对数据按照某个或多个字段进行分组，MySQL中使用group by关键字对数据进行分组，基本语法形式为：group by 字段 1、创建分组 Group by 关键字通常和集合函数一起使用，例如：MAX()、MIN()、COUNT()、SUM()、AVG()。 根据s_id对fruits表中的数据进行分组 12345678910111213mysql&gt; select s_id,count(*) as total from fruits group by s_id;+------+-------+| s_id | total |+------+-------+| 101 | 3 || 102 | 3 || 103 | 2 || 104 | 2 || 105 | 3 || 106 | 1 || 107 | 2 |+------+-------+7 rows in set (0.00 sec) （1）根据s_id对fruits表中的数据进行分组，将每个供应商的水果名称显示出来 12345678910111213mysql&gt; select s_id,group_concat(f_name) as name from fruits group by s_id;+------+-------------------------+| s_id | name |+------+-------------------------+| 101 | apple,blackberry,cherry || 102 | orange,banana,grape || 103 | apricot,coconut || 104 | berry,lemon || 105 | melon,xbabay,xxtt || 106 | mango || 107 | xxxx,xbababa |+------+-------------------------+7 rows in set (0.00 sec) （2）使用having过滤分组 根据s_id对fruits表中的数据进行分组，并显示水果种类大于1的分组信息 12345678910111213mysql&gt; select s_id,group_concat(f_name) as name from fruits group by s_id havingcount(f_name) &gt; 1;+------+-------------------------+| s_id | name |+------+-------------------------+| 101 | apple,blackberry,cherry || 102 | orange,banana,grape || 103 | apricot,coconut || 104 | berry,lemon || 105 | melon,xbabay,xxtt || 107 | xxxx,xbababa |+------+-------------------------+6 rows in set (0.00 sec) （3）在group by 子句中使用with rollup 使用with rollup关键字之后，在所有查询出的分组记录之后增加一条记录，该记录计算查询出的所有记录的总和，即统计记录数量。 12345678910111213141516mysql&gt; select s_id,count(*) as total-&gt; from fruits-&gt; group by s_id with rollup;+------+-------+| s_id | total |+------+-------+| 101 | 3 || 102 | 3 || 103 | 2 || 104 | 2 || 105 | 3 || 106 | 1 || 107 | 2 || NULL | 16 |+------+-------+8 rows in set (0.00 sec) （4）多字段分组 使用group by可以对多个字段进行分组，group by关键字后面跟需要分组的字段，MySQL根据多字段的值来进行层次分组，分组层次从左到右，即先按第1个字段分组，然后在第1个字段值相同的记录中，再根据第2个字段的值进行分组，以此类推 12345678910111213141516171819202122mysql&gt; select * from fruits group by s_id,f_name;+------+------+------------+---------+| f_id | s_id | f_name | f_price |+------+------+------------+---------+| a1 | 101 | apple | 5.20 || b1 | 101 | blackberry | 10.20 || c0 | 101 | cherry | 3.20 || t1 | 102 | banana | 10.30 || t2 | 102 | grape | 5.30 || bs1 | 102 | orange | 11.20 || a2 | 103 | apricot | 2.20 || o2 | 103 | coconut | 9.20 || b2 | 104 | berry | 7.60 || l2 | 104 | lemon | 6.40 || bs2 | 105 | melon | 8.20 || m2 | 105 | xbabay | 2.60 || m3 | 105 | xxtt | 11.60 || m1 | 106 | mango | 15.70 || t4 | 107 | xbababa | 3.60 || b5 | 107 | xxxx | 3.60 |+------+------+------------+---------+16 rows in set (0.00 sec) （5）group by和order by一起使用 某些情况下需要对分组进行排序 12345678910111213141516171819202122232425mysql&gt; create table orderitems-&gt; (-&gt; o_num int not null,-&gt; o_item int not null,-&gt; f_id char(10) not null,-&gt; quantity int not null,-&gt; item_price decimal(8,2) not null,-&gt; primary key(o_num,o_item)-&gt; );Query OK, 0 rows affected (0.03 sec)mysql&gt; insert into orderitems(o_num,o_item,f_id,quantity,item_price)-&gt; values(30001,1,&#39;a1&#39;,10,&#39;5.2&#39;),-&gt; (30001,2,&#39;b2&#39;,3,&#39;7.6&#39;),-&gt; (30001,3,&#39;bs1&#39;,5,&#39;11.2&#39;),-&gt; (30001,4,&#39;bs2&#39;,15,&#39;9.2&#39;),-&gt; (30002,1,&#39;b3&#39;,2,&#39;20.0&#39;),-&gt; (30003,1,&#39;c0&#39;,100,10),-&gt; (30004,1,&#39;o2&#39;,50,&#39;2.50&#39;),-&gt; (30005,1,&#39;c0&#39;,5,&#39;10&#39;),-&gt; (30005,2,&#39;b1&#39;,10,&#39;8.99&#39;),-&gt; (30005,3,&#39;a2&#39;,10,&#39;2.2&#39;),-&gt; (30005,4,&#39;m1&#39;,5,&#39;14.99&#39;);Query OK, 11 rows affected (0.00 sec)Records: 11 Duplicates: 0 Warnings: 0 查询价格大于100的订单号和总价订单价格 12345678910111213mysql&gt; select o_num,sum(quantity*item_price) as ordertotal-&gt; from orderitems-&gt; group by o_num-&gt; having sum(quantity*item_price) &gt;&#x3D; 100;+-------+------------+| o_num | ordertotal |+-------+------------+| 30001 | 268.80 || 30003 | 1000.00 || 30004 | 125.00 || 30005 | 236.85 |+-------+------------+4 rows in set (0.00 sec) 5、使用limit限制查询结果的数量 select返回所有匹配的行，有可能是表中所有的行，如仅仅需要返回第一行或者前几行，使用limit关键字，语法格式如下：limit [位置偏移量] 行数 12345678910111213141516171819mysql&gt; select * from fruits limit 4;+------+------+------------+---------+| f_id | s_id | f_name | f_price |+------+------+------------+---------+| a1 | 101 | apple | 5.20 || a2 | 103 | apricot | 2.20 || b1 | 101 | blackberry | 10.20 || b2 | 104 | berry | 7.60 |+------+------+------------+---------+4 rows in set (0.02 sec)mysql&gt; select * from fruits limit 4,3;+------+------+--------+---------+| f_id | s_id | f_name | f_price |+------+------+--------+---------+| b5 | 107 | xxxx | 3.60 || bs1 | 102 | orange | 11.20 || bs2 | 105 | melon | 8.20 |+------+------+--------+---------+3 rows in set (0.00 sec) 6、使用聚合函数查询 ![image-20200613133729764](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613133729764.png) （1）count()函数 Count()函数统计数据表中包含的记录行的总数，或者根据查询结果返回列中包含的数据行数。 Count(*)计算表中总的函数，不管某列有数列或者为空值 Count(字段名)计算指定列下总的行数，计算时将忽略空值的行 1234567891011121314151617181920212223242526272829mysql&gt; select count(*) as cust_num-&gt; from customers;+----------+| cust_num |+----------+| 4 |+----------+1 row in set (0.00 sec)mysql&gt; select count(c_email) as email_num-&gt; from customers;+-----------+| email_num |+-----------+| 3 |+-----------+1 row in set (0.00 sec)mysql&gt; select o_num,count(f_id)-&gt; from orderitems-&gt; group by o_num;+-------+-------------+| o_num | count(f_id) |+-------+-------------+| 30001 | 4 || 30002 | 1 || 30003 | 1 || 30004 | 1 || 30005 | 4 |+-------+-------------+5 rows in set (0.00 sec) （2）sum()函数 sum()是一个求总和的函数，返回指定列值得总和。 12345678910111213141516171819202122mysql&gt; select sum(quantity) as items_total-&gt; from orderitems-&gt; where o_num &#x3D; 30005;+-------------+| items_total |+-------------+| 30 |+-------------+1 row in set (0.01 sec)mysql&gt; select o_num,sum(quantity) as items_total-&gt; from orderitems-&gt; group by o_num;+-------+-------------+| o_num | items_total |+-------+-------------+| 30001 | 33 || 30002 | 2 || 30003 | 100 || 30004 | 50 || 30005 | 30 |+-------+-------------+5 rows in set (0.00 sec) 注意：sum()函数在计算时，忽略列值为NULL的行。 （3）avg()函数 avg()函数通过计算返回的行数和每一行数据的和，求得指定列数据的平均值。 123456789101112131415161718mysql&gt; select avg(f_price) as avg_price-&gt; from fruits-&gt; where s_id&#x3D;103;+-----------+| avg_price |+-----------+| 5.700000 |+-----------+1 row in set (0.00 sec)mysql&gt; select avg(f_price) as avg_price-&gt; from fruits-&gt; where s_id&#x3D;103;+-----------+| avg_price |+-----------+| 5.700000 |+-----------+1 row in set (0.00 sec) （4）max()函数 12345678910111213141516171819202122mysql&gt; select max(f_price) as max_price from fruits;+-----------+| max_price |+-----------+| 15.70 |+-----------+1 row in set (0.00 sec)mysql&gt; select s_id,max(f_price) as max_price-&gt; from fruits-&gt; group by s_id;+------+-----------+| s_id | max_price |+------+-----------+| 101 | 10.20 || 102 | 11.20 || 103 | 9.20 || 104 | 7.60 || 105 | 11.60 || 106 | 15.70 || 107 | 3.60 |+------+-----------+7 rows in set (0.00 sec) （5）min()函数 min()返回查询列中的最小值 1234567891011121314151617181920mysql&gt; select min(f_price) as min_price from fruits;+-----------+| min_price |+-----------+| 2.20 |+-----------+1 row in set (0.00 sec)mysql&gt; select s_id,min(f_price) as max_price from fruits group by s_id;+------+-----------+| s_id | max_price |+------+-----------+| 101 | 3.20 || 102 | 5.30 || 103 | 2.20 || 104 | 6.40 || 105 | 2.60 || 106 | 15.70 || 107 | 3.60 |+------+-----------+7 rows in set (0.00 sec) 连接查询 连接是关系数据库模型的主要特点。连接查询是关系数据库中最主要的查询，主要包括内连接、外连接。通过连接运算符可以实现多个表查询。在关系数据库管理系统中，表建立时各数据之间的关系不必确定，常把一个实体的所有信息存放在一个表中。当查询数据时，通过连接操作查询出存放在多个表中的不同实体的信息。当两个或多个表现中存在相同意义的字段时，便可以通过这些字段对不同的表进行连接查询。 1、内连接查询 内连接（inner join）使用比较运算符进行表间某些列数据的比较操作，并列出这些表中与连接条件相匹配的数据行，组合成新纪录，也就是说，在内连接查询中，只有满足条件的记录才能出现在结果关系中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344mysql&gt; create table suppliers-&gt; (-&gt; s_id int not null auto_increment,-&gt; s_name char(50) not null,-&gt; s_city char(50) null,-&gt; s_zip char(10) null,-&gt; s_call char(50) not null,-&gt; primary key(s_id)-&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into suppliers(s_id,s_name,s_city,s_zip,s_call)-&gt; values(101,&#39;FastFruit Inc.&#39;,&#39;tianjin&#39;,&#39;300000&#39;,&#39;48075&#39;),-&gt; (102,&#39;LT Supplies&#39;,&#39;chongqing&#39;,&#39;400000&#39;,&#39;44333&#39;),-&gt; (103,&#39;acme&#39;,&#39;shanghai&#39;,&#39;200000&#39;,&#39;90046&#39;),-&gt; (104,&#39;fnk inc.&#39;,&#39;zhongshan&#39;,&#39;528437&#39;,&#39;11111&#39;),-&gt; (105,&#39;good set&#39;,&#39;taiyuang&#39;,&#39;030000&#39;,&#39;22222&#39;),-&gt; (106,&#39;just eat ours&#39;,&#39;beijing&#39;,&#39;010&#39;,&#39;45678&#39;),-&gt; (107,&#39;dk inc.&#39;,&#39;zhengzhou&#39;,&#39;450000&#39;,&#39;33332&#39;);Query OK, 7 rows affected (0.01 sec)Records: 7 Duplicates: 0 Warnings: 0mysql&gt; select suppliers.s_id,s_name,f_name,f_price-&gt; from fruits ,suppliers-&gt; where fruits.s_id &#x3D; suppliers.s_id;+------+----------------+------------+---------+| s_id | s_name | f_name | f_price |+------+----------------+------------+---------+| 101 | FastFruit Inc. | apple | 5.20 || 103 | acme | apricot | 2.20 || 101 | FastFruit Inc. | blackberry | 10.20 || 104 | fnk inc. | berry | 7.60 || 107 | dk inc. | xxxx | 3.60 || 102 | LT Supplies | orange | 11.20 || 105 | good set | melon | 8.20 || 101 | FastFruit Inc. | cherry | 3.20 || 104 | fnk inc. | lemon | 6.40 || 106 | just eat ours | mango | 15.70 || 105 | good set | xbabay | 2.60 || 105 | good set | xxtt | 11.60 || 103 | acme | coconut | 9.20 || 102 | LT Supplies | banana | 10.30 || 102 | LT Supplies | grape | 5.30 || 107 | dk inc. | xbababa | 3.60 |+------+----------------+------------+---------+16 rows in set (0.00 sec) 如果在一个连接查询中，涉及的两个表都是同一个表，这种查询称为自连接查询。自连接是一种特殊的内连接，它是指相互连接的表在物理上为同一张表，但可以在逻辑上分为两张表 。 1234567891011mysql&gt; select f1.f_id,f1.f_name-&gt; from fruits as f1, fruits as f2-&gt; where f1.s_id &#x3D; f2.s_id and f2.f_id &#x3D; &#39;a1&#39;;+------+------------+| f_id | f_name |+------+------------+| a1 | apple || b1 | blackberry || c0 | cherry |+------+------------+3 rows in set (0.00 sec) 2、外连接查询 外连接查询将将查询多个表中相关联的行，内连接时，返回查询结果集合中的仅是符合查询条件和连接条件的行。但有时候需要包含没有关联的行中数据，即返回查询结果集合中的不仅包含符合连接条件的行，而且还包含左表（左外连接或左连接）、右表（右外连接或右连接）或两个连接表（全外连接）中的所有数据行。外连接分为左外连接或左连接和右外连接或右连接。 Left join（左连接）：返回包括左表中的所有记录和右表中连接字段相等的记录。 Right join（右连接）：返回包括右表中的所有记录和左表中连接字段相等的记录。 123456789# 左连接select * from student sLEFT JOIN grade gon s.gradeId &#x3D; g.gradeID;# 右连接select * from student sRIGHT JOIN grade gon s.gradeId &#x3D; g.gradeID; ![image-20200613134628052](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613134628052.png) 创建表 123456789101112131415161718192021222324create table orders( o_num int not null auto_increment, o_date datetime not null, c_id int not null, primary key(o_num));insert into orders(o_num,o_date,c_id)values(30001,&#39;2008-09-01&#39;,10001),(30002,&#39;2008-09-12&#39;,10003),(30003,&#39;2008-09-30&#39;,10004),(30004,&#39;2008-10-03&#39;,10005),(30005,&#39;2008-10-08&#39;,10001);create table customers( c_id int not null auto_increment, c_name char(50) not null, c_address char(50) null, c_city char(50) null, c_zip char(50) null, c_contact char(50) null, c_email char(50) null, primary key(c_id)); 插入数据 123456789insert into customers(c_id,c_name,c_address,c_city,c_zip,c_contact,c_email)values(10001,&#39;RedHook&#39;,&#39;200Street&#39;,&#39;Tianjin&#39;,&#39;300000&#39;,&#39;LiMing&#39;,&#39;LMing@163.com&#39;),(10002,&#39;Stars&#39;,&#39;333 Fromage Lane&#39;,&#39;Dalian&#39;,&#39;116000&#39;,&#39;Zhangbo&#39;,&#39;Jerry@hotmail.com&#39;),(10003,&#39;Netbhood&#39;,&#39;1 Sunny Place&#39;,&#39;Qingdao&#39;,&#39;266000&#39;,&#39;LuoCong&#39;,NULL),(10004,&#39;JOTO&#39;,&#39;829 Riverside Drive&#39;, &#39;Haikou&#39;,&#39;570000&#39;,&#39;YangShan&#39;,&#39;sam@hotmail.com&#39;);select * from customers;select * from orders; ![image-20200613135037758](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613135037758.png) ![image-20200613135042714](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613135042714.png) （1）左连接 1234# 左外连接select c.c_id,o.o_num from customers cLEFT OUTER JOIN orders oon c.c_id &#x3D; o.c_id; ![image-20200610151134872](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610151134872.png) （2）右连接 1234# 右外连接select c.c_id,o.o_num from customers cRIGHT OUTER JOIN orders oon c.c_id &#x3D; o.c_id; ![image-20200610151240505](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610151240505.png) 3、复合条件连接查询 复合条件连接查询是在连接查询的过程中，通过添加过滤条件，限制查询的结果，使查询的结果更加准确。 1234select c.c_id,o.o_num from customers cLEFT OUTER JOIN orders oon c.c_id &#x3D; o.c_idand c.c_id&#x3D;10001; ![image-20200610152148735](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610152148735.png) 4、编写SQL语句，查看年龄比“李斯文”小的学生，要求显示这些学生的信息 ![image-20200610162453310](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610162453310.png) 第一步:查询得到“李斯文”的出生日期 第二步:利用WHERE语句，筛选出生日期比“李斯文”大的学生 123# 请查找出年龄比李斯文小的学生select bornDate from studentwhere studentName &#x3D; &#39;李斯文&#39;; ![image-20200610163928028](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610163928028.png) 12select studentName,bornDate from studentwhere bornDate&gt;&#39;1993-07-23&#39;; ![image-20200610163937508](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610163937508.png) 12345select studentName,bornDate from studentwhere bornDate&gt;( select bornDate from student where studentName &#x3D; &#39;李斯文&#39;); ![image-20200610163937508](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610163937508.png) 1234567891011DROP TABLE IF EXISTS 666;create database &#96;666&#96;;use &#96;666&#96;drop table if exists &#96;t&#96;;CREATE TABLE &#96;ttt&#96;(true&#96;sid&#96; int (4) not null PRIMARY KEY, &#96;sname&#96; VARCHAR(20) not null)CHARSET &#x3D; &#39;utf8mb4&#39;;select * from ttt ![image-20200610165549705](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610165549705.png) 12345create table tb1(truenum1 int not null);insert into tb1 values(1),(5),(13),(27);select * from tb1; ![image-20200611161645057](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200611161645057.png) 12345create table tb2(truenum2 int not null);insert into tb2 values(6),(14),(11),(20);select * from tb2; ![image-20200611161650169](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200611161650169.png)","path":"posts/98ba.html","date":"06-05","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL数据插入和复制","text":"一、DML语句(增删改) 插入数据的个数和类型要与表结构保持一致 1、插入单条数据记录 语法： 1INSERT INTO 表名 [(字段名列表)] VALUES (值列表); 注意： 1234字段名是可选的，如省略则依次插入所有字段多个列表和多个值之间使用逗号分隔值列表和字段名列表一一对应如插入的是表中部分数据，字段名列表必填 示例： 123456789# 插入单条数据insert into student(sid,sname,gradeID)VALUES(1002,&#39;徐淑丽&#39;,2);insert into studentVALUES(1003,&#39;孙子涵&#39;,1);insert into grade(gradeID,graedName)values(4,&#39;云计算&#39;); 查看一下 2、插入多条数据记录 语法： 12INSERT INTO 新表（字段名列表）VALUES(值列表1),(值列表2),……,(值列表n); 示例： 123# 插入多条数据insert into student(sid,sname,gradeID)VALUES(1005,&#39;王永义&#39;,3),(1006,&#39;包晓艺&#39;,2),(1007,&#39;黑瓜子&#39;,1); 经验： 1为避免表结构发生变化引发的错误，建议插入数据时写明具体字段名！ 3、将查询结果插入新表 （1）事先创建新表且与插入数据字段相符 123INSERT INTO 新表（字段1,字段2……） SELECT字段1，字段2……FROM 原表; （2）无需事先创建新表 123CREATE TABLE 新表（SELECT 字段1，字段2……FROM 原表）; （3）练习 编写SQL语句实现从学生表提取姓名、手机号两列数据存储到通讯录表中。 &lt;1&gt;不需要事先创建表 123create table copy_grade(trueselect * from grade); &lt;2&gt;事先创建表 1234567create TABLE c_grade(true&#96;id&#96; int(4) not null,true&#96;name&#96; VARCHAR(20) not null);insert into c_grade(id,name)SELECT * from grade; 查看一下 4、更新数据记录 语法： 123UPDATE 表名 SET 字段1&#x3D;值1,字段2&#x3D;值2,…,字段n&#x3D;值n [WHERE 条件]; 示例1 1234567# 更新数据update c_gradeset name &#x3D; &#39;高级运维&#39;where id &#x3D; 4# where条件一 定要设置，否则会修改所有的列SELECT * from c_grade 查看一下 示例2 12345UPDATE studentset gradeID&#x3D;2,sex&#x3D;&#39;女&#39;where sid&#x3D;1002;SELECT * from student 查看一下 分析一下 5、删除数据记录 语法： 12DELETE FROM 表名 [WHERE条件];TRUNCATE TABLE 表名; 注意： 1TRUNCATE语句删除后将重置自增列，表结构及其字段、约束、索引保持不变，执行速度比DELETE语句快 示例 1234567# DELETE不能 重置自增列DELETE from c_grade WHERE id&#x3D;1;SELECT * from c_grade;# truncate能够 重置自增列truncate table c_grade;SELECT * from c_grade; 小结 MySQL中如何使用一条INSERT语句插入多条数据? 12INSERT INTO 表名(字段一,字段二,)VALUES(数据一,&#39;数据二&#39;); MySQL中将查询结果集插入新表的两种方式是什么?两者的区别是什么? 1234567不需要实现创建表,将查询结果插入新表create table 新表名称( select * from 需要查询的表); 需要提前创建表 INSERT into 提前创建好的表名称() select * from 需要查询的表； 删除数据时使用DEL ETE和TRUNCATE的区别是什么? 12删除表内数据，不会重置自增列删除表内出局，也会重置自增列 二、DQL语句（查询） 1、通用查询 语法： 123456SELECT &lt;字段名列表&gt;FROM &lt;表名或视图&gt;[WHERE &lt;查询条件&gt;][GROUP BY &lt;分组的字段名&gt;][HAVING &lt;条件&gt;][ORDER BY &lt;排序的字段名&gt; [ASC 或 DESC]] 示例： 1234SELECT &#96;studentNo&#96;,&#96;studentName&#96;,&#96;phone&#96;,&#96;address&#96;,&#96;bornDate&#96; FROM &#96;student&#96;WHERE &#96;gradeId&#96; &#x3D; 1ORDER BY studentNo; （1）把student中男和女的个数分别显示出来 1234SELECT count(1) from student#where sname&#x3D;&#39;黑瓜子&#39;;GROUP BY sex#HAVING sex&#x3D;&#39;男&#39; ; （2）排序 123SELECT * from student-- order by sid asc;order by sid desc; 2、LIMIT子句 MySQL查询语句中使用LIMIT子句限制结果集。 语法： 123456SELECT &lt;字段名列表&gt;FROM &lt;表名或视图&gt;[WHERE &lt;查询条件&gt;][GROUP BY &lt;分组的字段名&gt;][ORDER BY &lt;排序的列名&gt; [ASC 或 DESC]][LIMIT [位置偏移量, ]行数]; 示例： 12SELECT * from studentlimit 4,3; 注意： 1使用LIMIT子句时，注意第1条记录的位置是0！ 3、常用函数 （1）聚合函数 函数名 作用 count() 返回某字段的行数 avg() 返回某字段的平均值 max() 返回某字段的最大值 min() 返回某字段的最小值 sum() 返回某字段的和 （2）字符串函数 函数名 作用 示例 LENGTH(str) 计算字符串长度 SELECT LENGTH(‘date’); CONCAT(str1,str2,…) 字符串合并 select CONCAT(‘a’,‘b’,‘c’) INSERT(str,pos,len,newstr) 字符串替换 select INSERT(‘old string’,1,3,‘letter’) LOWER(str) 将字符串转换为小写 select LOWER(‘A’) UPPER(str) 将字符串转换为大写 select UPPER(‘a’) LEFT(s,n) 返回字符串 s 开始的最左边 n 个字符 SELECT LEFT(‘hello’,2); RIGHT(s,n) 返回字符串 s 开始的最右边 n 个字符 SELECT RIGHT(‘hello word!’,5); LPAD(s1,len,s2) 返回字符串 s1 ，其左边由字符串 s2填充到 len 字符长度，如果 s1 的长度大于 len ，则返回值被缩短至 len 长度 SELECT RPAD(‘hello’,4,’?’); RPAD(s1,len,s2) 返回字符串 s1 ，其右边由字符串 s2 填充到 len 字符长度，如果 s1 的长度大于 len ，则返回值被缩短至 len 长度 SELECT RPAD(‘hello’,10,’?’); LTRIM(s) 用于删除字符串 s 左侧的空格 SELECT LTRIM(’ book '); RTRIM(s) 用于删除字符串 s 右侧的空格 SELECT RTRIM(’ book '); TRIM(s) 用于删除字符串 s 两侧的空格 SELECT TRIM(’ book '); TRIM(s1 FROM s) 删除指定字符串的函数 SELECT TRIM(‘xy’ FROM ‘xyxyabcxy’); REPEAT(s,n) 用于重复字符串 s ，n 表示重复多少次 SELECT REPEAT(‘mysql’,3); SPACE(n) 用于返回 n 个空格 SELECT SPACE(20); REPLACE(s,s1,s2) 使用字符串 s2 替换字符串 s 中所有的字符串 s1 SELECT REPLACE(‘xxx.mysql.com’, ‘x’, ‘w’); STRCMP(s1,s2) 用于比较字符串 s1 和 s2 的大小，若所有字符串相同则返回 0 ，若第一个字符串大于第二个字符串则返回 1 ，若第一个字符串小于第二个字符串则返回 -1 SELECT STRCMP(‘txt’, ‘txt2’), STRCMP(‘txt’, ‘txt’); SUBSTRING(str,num,len) 获取指定位置的子字符串 select SUBSTRING(‘JavaMysqlOracle’,5,5); MID(s,n,len) 用于获取指定位置的子字符串 SELECT MID(‘breakfast’,5); LOCATE(str1,str) 返回字符串 str1 在字符串 str 中的开始位置 SELECT LOCATE(‘ball’, ‘football’); POSITION(str1 IN str) 返回字符串 str1 在字符串 str 中的开始位置 SELECT POSITION(‘ball’ IN ‘football’); INSTR(str, str1) 返回子字符串 str1 在字符串 str 中的开始位置 SELECT INSTR(‘football’, ‘ball’); REVERSE(s) 将字符串 s 反转 SELECT REVERSE(‘abcd’); ELT(n, s1, s2, s3, …) 返回第 n 个字符串，如果 n超出范围则返回 NULL SELECT ELT(3, ‘a’, ‘b’, ‘c’, ‘d’); FIELD(s, s1, s2, …) 返回字符串 s 在列表 s1, s2, … 中的位置，如果不存在字符串 s 则返回 0 ，如果字符串 s 是 NULL 也返回 0 SELECT FIELD(‘hi’, ‘hihi’, ‘hey’, ‘hi’, ‘bas’); FIND_IN_SET(s1, s2) 返回字符串 s1 在字符串列表 s2中的位置 SELECT FIND_IN_SET(‘hi’, ‘hihi,hey,hi,bas’); 12# 字符串连接select CONCAT(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;) ![image-20200608142620041](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142620041.png) 12# 字符串替换select INSERT(&#39;old string&#39;,1,3,&#39;letter&#39;) ![image-20200608142655908](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142655908.png) 12# 字符串转小写select LOWER(&#39;A&#39;) ![image-20200608142815767](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142815767.png) 12# 字符串转大写select LOWER(&#39;a&#39;) ![image-20200608142830810](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142830810.png) 12# 字符串截取select SUBSTRING(&#39;JavaMysqlOracle&#39;,5,5) ![image-20200608142956979](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142956979.png) （3）时间日期函数 函数名 作用 示例 CURDATE() 获取当前日期 select CURDATE(); CURTIME() 获取当前时间 select CURTIME(); CURRENT_TIMESTAMP() 、.LOCALTIME() 、NOW() 、SYSDATE()CURRENT_TIMESTAMP() 获取当前日期和时间 select NOW(); UNIX_TIMESTAMP() 获取 UNIX 格式的时间戳 SELECT UNIX_TIMESTAMP(); FROM_UNIXTIME() 将 UNIX 格式的时间戳转换为普通格式的时间 SELECT FROM_UNIXTIME(‘1495542689’); UTC_DATE() UTC_DATE() 获取当前 UTC (世界标准时间) 日期值 SELECT UTC_DATE(); UTC_TIME() UTC_TIME() 获取当前 UTC (世界标准时间) 时间值 SELECT UTC_TIME(); YEAR(date) 返回日期date的年份 select YEAR(NOW()); QUARTER(date) 返回日期date为一年中第几季度 select QUARTER(NOW()); MONTH(date) 返回日期date的月份 select MONTH(NOW()); WEEK(date) 返回日期date为一年中第几周 select WEEK(NOW()); DAY(date) 返回日期date的日期 select DAY(NOW()); DAYOFYEAR(date) 返回 date 是一年中的第几天，一年有 365 天 SELECT DAYOFYEAR(‘2017-05-23’); DAYOFMONTH(date) 计算 date 是一个月中的第几天 SELECT DAYOFMONTH(‘2017-05-23’); HOUR(time) 返回日期date的小时 select HOUR(NOW()); MINUTE(time) 返回日期date的分钟 select MINUTE(NOW()); SECOND(time) 返回日期date的秒 select SECOND(NOW()); TIME_TO_SEC(time) 将 time 转换为秒钟，公式为 &quot; 小时3600 + 分钟60 + 秒 &quot; SELECT TIME_TO_SEC(‘23:23:00’); SEC_TO_TIME(time) 将秒值转换为时间格式 SELECT SEC_TO_TIME(‘84180’); DATEDIFF(date1,date2) 返回日期date的date1和date2间隔的天数 select DATEDIFF(NOW(),‘2020-06-07’); ADDDATE(date,n) 计算日期date加上n天以后在日期 select ADDDATE(NOW(),3); DATE_FORMAT(date, format) 格式化日期，即根据 format 指定的格式显示 date 值 SELECT DATE_FORMAT(‘1997-10-04 22:23:00’, ‘%W %M %Y’); TIME_FORMAT(time, format) 格式化时间，即根据 format 指定的格式显示 time 值 SELECT TIME_FORMAT(‘16:00:00’, ‘%H %k %I’); GET_FORMAT() 指定值类型和格式化类型，然后会显示成格式字符串 SELECT DATE_FORMAT(‘2000-10-05 22:23:00’, GET_FORMAT(DATE,‘USA’)); 参考内容： 12345678910111213141516171819202122232425262728# 当前的日期select CURDATE();# 当前的时间select CURTIME();# 当前的日期和时间select NOW();# 年select YEAR(NOW());# 月select MONTH(NOW());# 日select DAY(NOW());# 星期select WEEK(NOW());# 时select HOUR(NOW());# 分select MINUTE(NOW());# 秒select SECOND(NOW());# 计算从2020&#x2F;1&#x2F;&#x2F;1 到 2020&#x2F;6&#x2F;8 有多少天select DATEDIFF(now(),&#39;2020-01-01&#39;)# 三天后的现在select adddate(now(),3) （4）数学函数 函数名 作用 示例 ABS(x) 绝对值函数 SELECT ABS(-2); PI() 返回圆周率的函数 SELECT PI(); SQRT(x) 平方根函数，返回非负数二次方根 SELECT SQRT(9); CEIL(x) 向上取整 SELECT CEIL(2.1); FLOOR(x) 向下取整 SELECT FLOOR(2.5); RAND(x) 返回一个随机浮点值，范围在 0 ~ 1 之间 SELECT RAND(); ROUND(x) 对x进行四舍五入 SELECT ROUND(-1.34); ROUND(x,y) 对x进行四舍五入，并且保留小数点后y位 SELECT ROUND(1.37,1); TRUNCATE(x,y) 对x进行截取，结果保留小数点后y位 SELECT TRUNCATE(1.31,1); POW(x,y) 返回 x 的 y 次方的结果 SELECT POW(2,4); 12345678# 只要有小数就往整数进一位select ceil(3.01)# 只要整数部位select FLOOR(3.91);# 随机数select rand(); （5）系统信息函数 函数名 作用 示例 VERSION() 获取 MySQL 版本号 SELECT VERSION(); CHARSET(str) 查看字符串 str 的字符集 SELECT CHARSET(‘abc’); COLLATION(str) 查看字符串 str 的字符排列方式 SELECT COLLATION(‘abc’); LAST_INSERT_ID() 获取最后一个自动生成的ID 值 SELECT LAST_INSERT_ID(); USER() 、CURRENT_USER() 、SYSTEM_USER() 返回当前登录的用户及主机名 SELECT USER();SELECT CURRENT_USER();SELECT SYSTEM_USER(); CONNECTION_ID() 查看当前用户的连接数的ID SELECT CONNECTION_ID(); DATABASE()、SCHEMA() 查看当前使用的数据库 SELECT DATABASE();SELECT SCHEMA(); SHOW PROCESSLIST 查看当前用户的连接信息 SHOW PROCESSLIST; CONNECTION_ID()函数的参数 123456781. Id ：用户登录 MySQL 时，系统分配的连接 id2. User ：当前连接的用户3. Host ：显示这个语句是从哪个 IP 的哪个端口上发出的，可以用来追踪出现问题语句的用户4. db ：显示这个进程目前连接的是哪个数据库5. Command ：显示当前连接执行的命令，一般取值为休眠(Sleep)、查询(Query)、连接(Connect)6. Time ：显示这个状态持续的时间，单位是秒7. State ：显示使用当前连接的 SQL 语句的状态8. Info ：显示这个 SQL 语句 示例1： 1234567891011121314151617181920# 查看MySQL版本select VERSION();# 查看数据库连接的ID# 查看MySQL connection id连接id# 对于已经建立的连接的客户端，都有一个唯一的连接ID。select CONNECTION_ID();# 查看MySQL接口SHOW PROCESSLIST;use mysql;# 查看当前数据库select database();SELECT SCHEMA();# 查看当前用户select user();# 查看当前日期select CURRENT_DATE();# 查看当前用户select SYSTEM_USER(); 示例2： 12345678create table worker(trueid int auto_increment PRIMARY key,truename VARCHAR(30))CHARSET&#x3D;utf8mb4;insert into worker(name) VALUES(&#39;xxx&#39;);insert into worker(name) VALUES(&#39;yyy&#39;);select LAST_INSERT_ID(); （6）条件判断函数 函数 作用 示例 IF() IF(expr, v1, v2) 如果表达式 expr 为 TRUE ，则返回值为 v1 ，否则返回 v2 SELECT IF(1&gt;2, 2, 3); IFNULL() IFNULL(v1, v2) 如果 v1 不为 NULL ，则返回值为 v1 ；如果 v1 为 NULL ，则返回值为 v2 SELECT IFNULL(1,2), IFNULL(NULL,10); CASE expr WHEN v1 THEN r1 [WHEN v2 THEN r2] [ELSE rn] END 如果 expr 等于某个 vn，则返回对应位置 THEN 后面的结果，如果与所有值都不相等，则返回 ELSE 后面的 rn SELECT CASE 2 WHEN 1 THEN ‘one’ WHEN 2 THEN ‘two’ ELSE ‘more’ END; （7）加密/解密函数 函数 作用 示例 PASSWORD(str) 从明文密码 str 计算并返回加密后的密码字符串，当参数为 NULL 时，返回 NULL SELECT PASSWORD(‘newpwd’); MD5(str) 为字符串 str 算出一个 MD5 128 比特校验值 SELECT MD5(‘newpwd’); ENCODE(str, pswd_str) 使用 pswd_str 作为密码，加密 str SELECT ENCODE(‘secret’, ‘newpwd’); DECODE(crypt_str, pswd_str) 使用 pswd_str 作为密码，解密加密字符串 crypt_str SELECT DECODE(ENCODE(‘secret’,‘cry’), ‘cry’); 加密 123select PASSWORD(&#39;123456&#39;);select MD5(&#39;123456&#39;);select ENCODE(&#39;123456&#39;,&#39;abc&#39;) 解密 1select DECODE(ENCODE(&#39;123456&#39;,&#39;abc&#39;),&#39;abc&#39;); 示例 12select PASSWORD(&#39;123456&#39;);select BENCHMARK(500000，PASSWORD(&#39;123456&#39;)); （8）其它函数 函数 作用 示例 FORMAT(x, n) 将数字 x 格式化，并以四舍五入的方式保留小数点后 n 位，结果以字符串的形式返回 SELECT FORMAT(1.23456, 4); CONV() 不同进制数之间的转换 SELECT CONV(‘a’,16,2), # 将16进制的a转换为2进制SELECT CONV(15,10,2), # 将10进制的15转换为2进制SELECT CONV(15,10,8), # 将10进制的15转换为8进制SELECT CONV(15,10,16); # 将10进制的15转换为16进制 INET_ATON(expr) 将网络地址转换为一个代表该地址数值的整数 SELECT INET_ATON(‘192.168.1.1’); GET_LOCK(str, timeout) 使用字符串 str 来得到一个锁，持续时间 timeout 秒1. 若成功得到锁，则返回 12. 若操作超时，则返回 03. 若发生错误，则返回 NULL SELECT GET_LOCK(‘lock1’, 10); RELEASE_LOCAK(str) 用于解开被 GET_LOCK() 获取的，用字符串 str 所命名的锁1. 若锁被解开，则返回 12. 若该线程尚未创建锁，则返回 03. 若命名的锁不存在，则返回 NULL4. 若该锁从未被 GET_LOCK() 的调用获取，或锁已经被提前解开，则该锁不存在 SELECT RELEASE_LOCK(‘lock1’); IS_FREE_LOCK(str) 检查名为 str 的锁是否可以使用1. 若锁可以使用，则返回 12. 若锁正在被使用，则返回 03. 若出现错误，则返回 NULL SELECT IS_FREE_LOCK(‘lock1’); IS_USED_LOCK(str) 检查名为 str 的锁是否正在被使用，若被封锁，则返回使用该锁的客户端的连接标识符，否则返回 NULL SELECT IS_USED_LOCK(‘lock1’); BENCHMARK(count, expr) 用于重复 count 次执行表达式 expr1. 可以用于计算 MySQL 处理表达式的速度2. 可以在 MySQL 客户端内部报告语句执行的时间 SELECT PASSWORD(‘newpwd’);SELECT BENCHMARK( 500000, PASSWORD(‘newpwd’) ); CONVERT(… USING …) 用于改变字符串的默认字符集默认是utf8字符集 SELECT CHARSET(‘abc’);SELECT CHARSET(CONVERT(‘abc’ USING latin1)); CONVERT(x, type) 将一个数据类型的值转换为另一个数据类型的值 SELECT CONVERT(100, CHAR(2)); 示例1： 123select format(3.1415926,2);select format(3.14,4);select format(3.14,0); 示例2： 1234select CONV(&#39;a&#39;,16,2);select CONV(15,10,2);select CONV(15,10,8);select CONV(15,10,16); 示例3： 1select INET_ATON(&#39;192.168.79.160&#39;); （7）数据类型转换百数 12345678910select if(1&gt;2,&#39;true&#39;,&#39;false&#39;);select IFNULL(null,2);select IFNULL(1,2);select case 2 when 1 then &#39;one&#39; when 2 then &#39;two&#39;else &#39;more&#39;end; ![image-20200613115249566](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613115249566.png) 4、运算符 （1）算术运算符 运算符 作用 示例 + 加法 select 1+2; - 减法 select 1-2; * 乘法 select 2*5; /或DIV 除法 select 9/3; 或 select 9 DIV 3; %或MOD 取余 select 9%2; 或 select 9 MOD 2; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 算数运算符mysql&gt; select 1+2;+-----+| 1+2 |+-----+| 3 |+-----+1 row in set (0.00 sec)mysql&gt; select 3-5;+-----+| 3-5 |+-----+| -2 |+-----+1 row in set (0.00 sec)mysql&gt; select 4*5;+-----+| 4*5 |+-----+| 20 |+-----+1 row in set (0.00 sec)mysql&gt; select 5&#x2F;3;+--------+| 5&#x2F;3 |+--------+| 1.6667 |+--------+1 row in set (0.00 sec)mysql&gt; select 5 DIV 3;+---------+| 5 DIV 3 |+---------+| 1 |+---------+1 row in set (0.00 sec)mysql&gt; select 6%8;+------+| 6%8 |+------+| 6 |+------+1 row in set (0.00 sec) （2）比较运算符 SELECT 语句中的条件语句经常要使用比较运算符。 通过这些比较运算符，可以判断表中的哪些记录是符合条件的。比较结果为真，则返回 1，为假则返回 0，比较结果不确定则返回 NULL。 符号 描述 备注 = 等于 &lt;&gt;, != 不等于 &gt; 大于 &lt; 小于 &lt;= 小于等于 &gt;= 大于等于 BETWEEN 在两值之间 &gt;=min&amp;&amp;&lt;=max NOT BETWEEN 不在两值之间 IN 在集合中 NOT IN 不在集合中 &lt;=&gt; 严格比较两个NULL值是否相等 两个操作码均为NULL时，其所得值为1；而当一个操作码为NULL时，其所得值为0 LIKE 模糊匹配 REGEXP 或 RLIKE 正则式匹配 IS NULL 为空 IS NOT NULL 不为空 1）等于 1234567891011121314mysql&gt; select 2&#x3D;3;+-----+| 2&#x3D;3 |+-----+| 0 |+-----+mysql&gt; select NULL &#x3D; NULL;+-------------+| NULL &#x3D; NULL |+-------------+| NULL |+-------------+ 2）不等于 123456mysql&gt; select 2&lt;&gt;3;+------+| 2&lt;&gt;3 |+------+| 1 |+------+ 3）安全等于 与 = 的区别在于当两个操作码均为 NULL 时，其所得值为 1 而不为 NULL，而当一个操作码为 NULL 时，其所得值为 0而不为 NULL。 12345678910111213141516171819202122mysql&gt; select 2&lt;&#x3D;&gt;3;+-------+| 2&lt;&#x3D;&gt;3 |+-------+| 0 |+-------+mysql&gt; select null&#x3D;null;+-----------+| null&#x3D;null |+-----------+| NULL |+-----------+ mysql&gt; select null&lt;&#x3D;&gt;null;+-------------+| null&lt;&#x3D;&gt;null |+-------------+| 1 |+-------------+ 4）小于 123456mysql&gt; select 2&lt;3;+-----+| 2&lt;3 |+-----+| 1 |+-----+ 5）小于等于 123456mysql&gt; select 2&lt;&#x3D;3;+------+| 2&lt;&#x3D;3 |+------+| 1 |+------+ 6）大于 123456mysql&gt; select 2&gt;3;+-----+| 2&gt;3 |+-----+| 0 |+-----+ 7）大于等于 123456mysql&gt; select 2&gt;&#x3D;3;+------+| 2&gt;&#x3D;3 |+------+| 0 |+------+ 8）BETWEEN 123456mysql&gt; select 5 between 1 and 10;+--------------------+| 5 between 1 and 10 |+--------------------+| 1 |+--------------------+ 9）IN 123456mysql&gt; select 5 in (1,2,3,4,5);+------------------+| 5 in (1,2,3,4,5) |+------------------+| 1 |+------------------+ 10）NOT IN 123456mysql&gt; select 5 not in (1,2,3,4,5);+----------------------+| 5 not in (1,2,3,4,5) |+----------------------+| 0 |+----------------------+ 11）IS NULL 12345678910111213mysql&gt; select null is NULL;+--------------+| null is NULL |+--------------+| 1 |+--------------+mysql&gt; select &#39;a&#39; is NULL;+-------------+| &#39;a&#39; is NULL |+-------------+| 0 |+-------------+ 12）IS NOT NULL 1234567891011121314mysql&gt; select null IS NOT NULL;+------------------+| null IS NOT NULL |+------------------+| 0 |+------------------+ mysql&gt; select &#39;a&#39; IS NOT NULL;+-----------------+| &#39;a&#39; IS NOT NULL |+-----------------+| 1 |+-----------------+ 13、LIKE 12345678910111213mysql&gt; select &#39;12345&#39; like &#39;12%&#39;;+--------------------+| &#39;12345&#39; like &#39;12%&#39; |+--------------------+| 1 |+--------------------+mysql&gt; select &#39;12345&#39; like &#39;12_&#39;;+--------------------+| &#39;12345&#39; like &#39;12_&#39; |+--------------------+| 0 |+--------------------+ 14、REGEXP 12345678910111213mysql&gt; select &#39;beijing&#39; REGEXP &#39;jing&#39;;+-------------------------+| &#39;beijing&#39; REGEXP &#39;jing&#39; |+-------------------------+| 1 |+-------------------------+mysql&gt; select &#39;beijing&#39; REGEXP &#39;xi&#39;;+-----------------------+| &#39;beijing&#39; REGEXP &#39;xi&#39; |+-----------------------+| 0 |+-----------------------+ （3）逻辑运算符 逻辑运算符用来判断表达式的真假。如果表达式是真，结果返回 1。如果表达式是假，结果返回 0。 运算符号 作用 NOT 或 ! 逻辑非 AND 逻辑与 OR 逻辑或 XOR 逻辑异或 1）与 1234567891011121314mysql&gt; select 2 and 0;+---------+| 2 and 0 |+---------+| 0 |+---------+ mysql&gt; select 2 and 1; +---------+ | 2 and 1 | +---------+ | 1 | +---------+ 2）或 123456789101112131415161718192021222324252627mysql&gt; select 2 or 0;+--------+| 2 or 0 |+--------+| 1 |+--------+mysql&gt; select 2 or 1;+--------+| 2 or 1 |+--------+| 1 |+--------+mysql&gt; select 0 or 0;+--------+| 0 or 0 |+--------+| 0 |+--------+mysql&gt; select 1 || 0;+--------+| 1 || 0 |+--------+| 1 |+--------+ 3）非 12345678910111213mysql&gt; select not 1;+-------+| not 1 |+-------+| 0 |+-------+mysql&gt; select !0;+----+| !0 |+----+| 1 |+----+ 4）异或（其他数字只能与0比较） 当任意一个操作数为NULL时,返回值为NULL，对于非NULL的操作数,如果两个的逻辑真假值相异，则返回结果为1，否则为0。 12345678910111213141516171819202122232425262728293031323334mysql&gt; select 1 xor 1;+---------+| 1 xor 1 |+---------+| 0 |+---------+mysql&gt; select 0 xor 0;+---------+| 0 xor 0 |+---------+| 0 |+---------+mysql&gt; select 1 xor 0;+---------+| 1 xor 0 |+---------+| 1 |+---------+mysql&gt; select null or 1;+-----------+| null or 1 |+-----------+| 1 |+-----------+mysql&gt; select 1 ^ 0;+-------+| 1 ^ 0 |+-------+| 1 |+-------+ （4）位运算符 位运算符是在二进制数上进行计算的运算符。位运算会先将操作数变成二进制数，进行位运算。然后再将计算结果从二进制数变回十进制数。 运算符号 作用 &amp; 按位与 | 按位或 ^ 按位异或 ! 取反 &lt;&lt; 左移 &gt;&gt; 右移 1）按位与 对应的二进制位都为 1 ，则该位的运算结果为 1 ，否则为 0。 123456mysql&gt; select 3&amp;5;+-----+| 3&amp;5 |+-----+| 1 |+-----+ 2）按位或 对应的二进制位有一个或两个为 1 ，则该位的运算结果为 1 ，否则为 0。 12345678mysql&gt; SELECT 10 | 15 , 9 | 4 | 2 ;+---------+-----------+| 10 | 15 | 9 | 4 | 2 | # 10的二进制为1010,15的二进制为1111，按位或运算之后结果为1111，即15+---------+-----------+ # 9的二进制为1001,4为0100,2的二进制为0010，按位或运算之后1111| 15 | 15 |+---------+-----------+ 3）按位异或 对应的二进制位不相同时，结果为 1，否则为 0。 123456mysql&gt; select 3^5;+-----+| 3^5 |+-----+| 6 |+-----+ 4）按位取反 将对应的二进制数逐位反转，即 1 取反后变 0 ，0 取反后变 1。 123456mysql&gt; select ~18446744073709551612;+-----------------------+| ~18446744073709551612 |+-----------------------+| 3 |+-----------------------+ 5）按位右移 使指定的二进制位都右移指定的位数，右移指定位之后，右边低位的数值将被移出并丢弃，左边高位空出的职位用 0 补齐。 123456mysql&gt; select 3&gt;&gt;1;+------+| 3&gt;&gt;1 |+------+| 1 |+------+ 6）按位左移 使指定的二进制位都左移指定的位数，左移指定位之后，左边高位的数值将被移出并丢弃，右边低位空出的位置用 0 补齐。 123456mysql&gt; select 3&lt;&lt;1;+------+| 3&lt;&lt;1 |+------+| 6 |+------+ （5）运算符优先级 最低优先级为： :=。 ![image-20200613115948741](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613115948741.png) 最高优先级为： !、BINARY、 COLLATE。 三、小练习 1、导入数据库 ![image-20200609171913909](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609171913909.png) ![image-20200609171943656](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609171943656.png) ![image-20200609172002895](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172002895.png) 2、grade添加数据 ![image-20200609172219791](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172219791.png) 1234select * from student;select studentNo as 学号,studentName as 姓名,sex as 性别,gradeId as 年级编号,bornDate as 出生日期from student; ![image-20200609172714342](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172714342.png) ![image-20200609172657559](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172657559.png) ![image-20200609172730224](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172730224.png) 3、两表联查 12345# 两表联查select * from grade;select * from student,grade;select * from student,grade where grade.gradeID &#x3D; student.gradeId; ![image-20200613123717083](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613123717083.png) 示例1： 123456789# 逗号+WHEREselect studentNo as 学号,studentName as 姓名,sex as 性别,gradeName as 年级,bornDate as 出生日期from student as s,grade as gwhere g.gradeID &#x3D; s.gradeId; ![image-20200609173647871](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609173647871.png) 示例2： 12345678910# join+onselect studentNo as 学号,studentName as 姓名,sex as 性别,gradeName as 年级,bornDate as 出生日期from student as sjoin grade as gon g.gradeID &#x3D; s.gradeId; ![image-20200613123857349](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613123857349.png) 4、模糊查询某学生的信息 12345# 查询某学生的信息select * from student where studentName &#x3D; &#39;郭靖&#39;;select * from student where studentName like &#39;%郭%&#39;;select * from student where studentName like &#39;%靖&#39;;select * from student where studentName like &#39;郭%&#39;; ![image-20200613124019868](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124019868.png) 5、排序 降序 12# 降序select * from student ORDER BY studentNo desc; ![image-20200613124251255](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124251255.png) 升序 12# 升序select * from student ORDER BY studentNo asc; ![image-20200613124257120](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124257120.png) 6、分组 12# 分组: 只有聚会的数和参与了分组的字段能够出现在select语句后面select sex,count(1) from student GROUP BY sex; ![image-20200613124341995](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124341995.png) 12345# 分组后再筛选数据select count(1),sexfrom studentGROUP BY sexhaving sex&#x3D;&#39;男&#39;; ![image-20200613124412250](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124412250.png) 123456789101112131415161718192021222324252627282930313233343536373839404142434445# ANDselect * from student where sex&#x3D;&#39;男&#39; and studentName&#x3D;&#39;李文才&#39;;+-----------+----------+-------------+-----+---------+-------------+----------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+----------+---------------------+-------+--------------+| 10001 | 123 | 李文才 | 男 | 1 | 13645667890 | 地址不详 | 1994-04-12 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+----------+---------------------+-------+--------------+1 row in set (0.00 sec)# ORselect * from student where sex&#x3D;&#39;男&#39; or studentName&#x3D;&#39;李文才&#39;;+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+| 10000 | 123 | 郭靖 | 男 | 1 | 13645667783 | 天津市河西区 | 1990-09-08 00:00:00 | NULL | NULL || 10001 | 123 | 李文才 | 男 | 1 | 13645667890 | 地址不详 | 1994-04-12 00:00:00 | NULL | NULL || 10002 | 123 | 李斯文 | 男 | 1 | 13645556793 | 河南洛阳 | 1993-07-23 00:00:00 | NULL | NULL || 10007 | 123 | 秦洋 | 男 | 1 | 13056434411 | 上海市卢湾区 | 1992-04-18 00:00:00 | NULL | NULL || 20000 | 123 | 王宝宝 | 男 | 2 | 15076552323 | 地址不详 | 1996-06-05 00:00:00 | NULL | NULL || 30011 | 123 | 陈志强 | 男 | 3 | 13689965430 | 地址不详 | 1994-09-27 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+# &#x3D;select * from student where sex&lt;&gt;&#39;男&#39;;+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+| 10003 | 123 | 张萍 | 女 | 1 | 13642345112 | 地址不详 | 1995-06-10 00:00:00 | NULL | NULL || 10004 | 123 | 韩秋洁 | 女 | 1 | 13812344566 | 北京市海淀区 | 1995-07-15 00:00:00 | NULL | NULL || 10005 | 123 | 张秋丽 | 女 | 1 | 13567893246 | 北京市东城区 | 1994-01-17 00:00:00 | NULL | NULL || 10006 | 123 | 肖梅 | 女 | 1 | 13563456721 | 河北省石家庄市 | 1991-02-17 00:00:00 | NULL | NULL || 10008 | 123 | 何睛睛 | 女 | 1 | 13053445221 | 广州市天河区 | 1997-07-23 00:00:00 | NULL | NULL || 20010 | 123 | 何小华 | 女 | 2 | 13318877954 | 地址不详 | 1995-09-10 00:00:00 | NULL | NULL || 30012 | 123 | 李露露 | 女 | 3 | 13685678854 | 地址不详 | 1992-09-27 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+7 rows in set (0.00 sec)# &lt;&gt;select * from student where bornDate&lt;&#39;1991&#39;;+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+| 10000 | 123 | 郭靖 | 男 | 1 | 13645667783 | 天津市河西区 | 1990-09-08 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+1 row in set, 1 warning (0.00 sec)select * from student;where select DATEDIFF(NOW(),&#39;1991-1-1&#39;)&#x2F;365;","path":"posts/e5cc.html","date":"06-04","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"mysql的增删改查","text":"MySQL高级查询 学习目的 使用SQL语句为成绩表添加主、外键 使用SQL语句实现数据添加、修改、查询 查询指定学生考试成绩 查询某学期开设的课程 查询某课程最近一次考试缺考的学生名单 一、RDBMS 术语 数据库: 数据库是一些关联表的集合。 数据表: 表是数据的矩阵。在一个数据库中的表看起来像一个简单的电子表格。 列: 一列(数据元素) 包含了相同的数据, 例如邮政编码的数据。 行：一行（=元组，或记录）是一组相关的数据，例如一条用户订阅的数据。 冗余：存储两倍数据，冗余可以使系统速度更快。 主键：主键是唯一的。一个数据表中只能包含一个主键。你可以使用主键来查询数据。 外键：外键用于关联两个表。 复合键：复合键（组合键）将多个列作为一个索引键，一般用于复合索引。 索引：使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或多列的值进行排序的一种结构。类似于书籍的目录。 参照完整性: 参照的完整性要求关系中不允许引用不存在的实体。与实体完整性是关系模型必须满足的完整性约束条件，目的是保证数据的一致性。 数据库的主键代表了唯一标示一条数据，所以主键是唯一的，比如学号，卡号之类的； 数据库的外键是为了保证数据库的一致性，假设表1中的一个外键是表2的主键，此时要在表2中插入一条数据时就必须查看（这条数据，也就是表2的那个主键的信息在表1中是否存在，如果不存在则无法插入），而当你需要在表1中删除一条信息是，如果在表2中还存在这个数据的话也是无法直接删除的。 二、增删改查操作 1、创建一个操作表 1234567891011#创建数据库cerate database test_mysql;#进入数据库use test_mysql;#创建表CREATE TABLE &#96;ttt&#96;(true&#96;sid&#96; int(4) not null key auto_increment,true&#96;sname&#96; varchar(20) default&#39;姓名不详&#39; not null) 查看一下 1desc ttt; 2、修改表名 语法： 1alter table 旧表名 rename 新表名; 操作 12# 修改表名alter table ttt rename teacher; 查看一下 12#查看表show tables; 3、添加列 语法 12# 添加字段alter table 表名 add 字段名 数据类型[属性]; 操作 12#添加列alter table teacher add &#96;sex&#96; char(2); 查看一下 1desc teacher; 4、修改列 语法 12# 修改字段alter table 表名 CHANGE 原字段名 新字段名 数据类型[属性]; 操作 12#修改列中 sex修改为gender 类型改为char(2)alter table teacher CHANGE &#96;sex&#96; &#96;gender&#96; char(2); 查看一下 12#查看表内容desc teacher; 4、删除字段 语法 12# 删除字段alter table 表名 drop 字段名; 操作 1alter table teacher drop gender; 查看一下 12#查看表内容desc teacher; 三、主键和外键 1、SQL 的主键和外键的作用： 12345外键取值规则：空值或参照的主键值(1)插入非空值时，如果主键值中没有这个值，则不能插入。(2)更新时，不能改为主键表中没有的值。(3)删除主键表记录时，可以在建外键时选定外键记录一起联删除还是拒绝删除。(4)更新主键记录时，同样有级联更新和拒绝执行的选择。 2、创建一个表 1234create table grade(true&#96;gradeID&#96; int(4) not null,true&#96;gredName&#96; varchar(20) not null); 查看一下 1desc grade; 3、创建主键 （1）语法 12ALTER TABLE 表名 ADD CONSTRAINT主键名PRIMARY KEY 表名(主键字段); （2）创建 12alter table grade add CONSTRAINT pk_gradePRIMARY key grage(&#96;gradeID&#96;); 查看一下 1desc grade; 4、添加外键 外键（从表）：可以增加数据的完整性与准确性 （1）语法 123ALTER TABLE 表名 ADD CONSTRAINT 外键名FOREIGN KEY (外键字段)REFERENCES 关联表名 (关联字段) ; （2）创建一个表 123456create table student(true&#96;sid&#96; int(4) not null PRIMARY KEY,true&#96;sname&#96; VARCHAR(50) not null,true&#96;gradeID&#96; int(4) not null, &#96;sex&#96; char(2) comment &#39;性别&#39;,); 查看一下 1desc student; （3）创建外键 123alter table student add CONSTRAINT fk_student_gradeFOREIGN KEY (&#96;gradeID&#96;)REFERENCES &#96;grade&#96;(&#96;gradeID&#96;); 查看一下 5、测试 （1）grade表添加内容 （2）student表添加内容 所以我们添加数值不要超过主表设置的默认值。 四、练习 1、需求说明 在test数据库中创建person表 字段名称 字段说明 数据类型 长度 属性 number 序号 INT 4 自增列 name 姓名 VARCHAR 50 非空 sex 性别 CHAR 2 bornDate 出生日期 DATETIME 将表名修改为tb_person 删除出生日期字段 添加出生日期字段, 数据类型为DATE类型 修改序号字段名(number) 为id,类型为BIGINT类型 123456789101112131415161718create table person(true&#96;number&#96; int(4) comment &#39;序号&#39; key auto_increment, &#96;name&#96; varchar(50) comment &#39;姓名&#39; not null, &#96;sex&#96; char(2) comment &#39;性别&#39;, &#96;bornDarte&#96; datetime(0) comment &#39;出生日期&#39;);# 修改表名alter table person rename tb_person;# 删除字段alter table tb_person drop &#96;bornDarte&#96;;# 添加列alter table tb_person add &#96;bornDarte&#96; date;# 修改表中字段名alter table tb_person change number id bigint;# 查看表结构desc tb_person; 2、需求说明 result表需要添加的内容 主键约束:学号、课程编号和日期构成组合主键. 外键约束:主表student和从表result通过studentNo字段建立主外键关联 1234567891011121314151617181920212223# 主键create table result(true&#96;studentNo&#96; int(4) comment &#39;学号&#39;,true&#96;subjedctNo&#96; int(4) comment &#39;课程编号&#39;,true&#96;examDate&#96; datetime comment &#39; 日期&#39;)charset&#x3D;&#39;utf8&#39;;alter table result add CONSTRAINT PK_resultPRIMARY key result(&#96;studentNo&#96;,&#96;subjedctNo&#96;,&#96;examDate&#96;);desc result;# 外键create table student(true&#96;sid&#96; int(4) not null PRIMARY KEY,true&#96;sname&#96; VARCHAR(50) not null,true&#96;studentNo&#96; int(4) not null);alter table student add CONSTRAINT fk_student_resultFOREIGN key (&#96;studentNo&#96;)REFERENCES &#96;result&#96;(&#96;studentNo&#96;);desc student; 查看一下外键","path":"posts/edab.html","date":"06-03","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL的建库、建表、建约束与存储引擎","text":"一、MySQL建库、建表 1、创建数据库 创建数据库是在系统磁盘上划分⼀块区域用于数据的存储和管理，如果管理员在设置权限的时候为用户创建了数据库，则可以直接使用，否则，需要自己创建数据库。 语法格式： 1CREATE DATABASE [IF NOT EXISTS] 数据库名 示例： IF NOT EXISTS：在创建数据库之前进行判断，只有该数据库目前尚不存在时才能执行操作。 此选项可以用来避免数据库已经存在而重复创建的错误。 12# 创建myschool数据库create database myschool; IF NOT EXISTS：在创建数据库之前进行判断，只有该数据库目前尚不存在时才能执行操作。 此选项可以用来避免数据库已经存在而重复创建的错误。 2、创建表 语法格式： 12345CREATE TABLE [IF NOT EXISTS] 表名 (字段1 数据类型 [字段属性|约束][索引][注释],……字段n 数据类型 [字段属性|约束][索引][注释])[表类型][表字符集][注释]; 示例： 12345#创建学生表CREATE TABLE &#96;student&#96;（&#96;studentNo&#96; INT(4) PRIMARY KEY,&#96; name&#96; CHAR(10),……）; 注意： 1234多字段使用逗号分隔保留字用撇号括起来单行注释：#……多行注释：&#x2F;*……*&#x2F; （1）字段的约束及属性 主键 123CREATE TABLE student（&#96;studentNo&#96; INT(4) PRIMARY KEY,……）; 注释 123CREATE TABLE test (&#96;id&#96; int(11) UNSIGNED COMMENT ‘编号’)COMMENT&#x3D;&#39;测试表’ ; 设置字符集编码 123CREATE TABLE [IF NOT EXISTS] 表名（#省略代码）CHARSET &#x3D; 字符集名; （2）在myschool数据库中创建学生表 所需执行的命令 1234567891011121314create databases myschool;use myschool;create table student(true&#96;studentNo&#96; int(4) not null comment &#39;学号&#39; primary key,true&#96;loginPwd&#96; varchar(20) not null comment &#39;密码&#39;,true&#96;studentName&#96; varchar(50) not null comment &#39;姓名&#39;,true&#96;sex&#96; char(2) not null default &#39;男&#39; comment &#39;性别&#39;,true&#96;gradeID&#96; int(4) unsigned comment &#39;年级编号&#39;,true&#96;phone&#96; varchar(50) comment &#39;电话&#39;,true&#96;address&#96; varchar(255) default &#39;地址不详&#39; comment &#39;地址&#39;,true&#96;bornDate&#96; datetime comment &#39;出生日期&#39;,true&#96;email&#96; varchar(50) comment &#39;邮件账号&#39;,true&#96;identityCard&#96; varchar(18) comment &#39;身份证号&#39; unique key)charset&#x3D;&#39;utf8&#39; comment&#x3D;&#39;学生表&#39;; 查看一下表结构 12345678910111213141516mysql&gt; desc student;+--------------+-----------------+------+-----+----------+-------+| Field | Type | Null | Key | Default | Extra |+--------------+-----------------+------+-----+----------+-------+| studentNo | int(4) | NO | PRI | NULL | || loginPwd | varchar(20) | NO | | NULL | || studentName | varchar(50) | NO | | NULL | || sex | char(2) | NO | | 男 | || gradeID | int(4) unsigned | YES | | NULL | || phone | varchar(50) | YES | | NULL | || address | varchar(255) | YES | | 地址不详 | || bornDate | datetime | YES | | NULL | || email | varchar(50) | YES | | NULL | || identityCard | varchar(18) | YES | UNI | NULL | |+--------------+-----------------+------+-----+----------+-------+10 rows in set (0.00 sec) 3、查看表 （1）查看表是否存在 12use myschool;show tables; （2）查看表定义 语法格式： 12use myschool;desc &#96;student&#96;; 示例： 12use myschool;desc &#96;student&#96;; 4、删除表 语法格式： 1drop table [if exists] 表名; 示例： 12use myschool;drop table if exists &#96;student&#96;; 在删除表之前，先使用 if exists 语句验证表是否存在 5、删除数据库 删除数据库是将已经存在的数据库从磁盘空间上清除，清除之后，数据库中的所有数据也将除。 删除数据库语句和创建数据库的命令相似，MySQL中删除数据库的基本语法格式为： 1drop database if exists 数据库名; 示例： 1drop database if exists myschool; 6、上机练习 （1）myschool数据库中创建科目表(subject) 123456create table subject( &#96;subjectNo&#96; int(4) comment &#39;课程编号&#39; primary key auto_increment, &#96;subjectName&#96; varchar(50) comment &#39;课程名称&#39;, &#96;classHour&#96; int(4) comment &#39;学时&#39;, &#96;gradeID&#96; int(4) comment &#39;年级编号&#39;); 查看一下表结构 12345678910mysql&gt; desc subject;+-------------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------------+-------------+------+-----+---------+----------------+| subjectNo | int(4) | NO | PRI | NULL | auto_increment || subjectName | varchar(50) | YES | | NULL | || classHour | int(4) | YES | | NULL | || gradeID | int(4) | YES | | NULL | |+-------------+-------------+------+-----+---------+----------------+4 rows in set (0.00 sec) （2）myschool数据库中创建成绩表（result） 123456create table result( &#96;studentNo&#96; int(4) comment &#39;学号&#39; not null, &#96;subjectNo&#96; int(4) comment &#39;课程编号&#39; not null, &#96;examDate&#96; datetime(0) comment &#39;考试日期&#39; not null, &#96;studentResult&#96; int(4) comment &#39;考试成绩&#39; not null); 查看一下表结构 12345678910mysql&gt; desc result;+---------------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------------+----------+------+-----+---------+-------+| studentNo | int(4) | NO | | NULL | || subjectNo | int(4) | NO | | NULL | || examDate | datetime | NO | | NULL | || studentResult | int(4) | NO | | NULL | |+---------------+----------+------+-----+---------+-------+4 rows in set (0.00 sec) 二、MySQL的存储引擎 1、存储引擎简介 数据库存储引擎是数据库底层软件组件，数据库管理系统（DBMS）使用数据引擎进行创建、查询、更 新和删除数据操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能。使用不同的存 储引擎，还可以获得特定的功能。 现在许多不同的数据库管理系统都支持多种不同的数据引擎。MySQL的核心就是存储引擎。 2、存储引擎的类型 mysql有多种存储引擎，它们分别为： 123456789MyISAMInnoDBMERGEMEMORYEXAMPLEFEDERATEDARCHIVECSVBLACKHOLE 3、存储引擎的主要区别 （1）MyISAM 存储引擎特点 MySQL 5.5 之前使用 MyISAM 引擎，MySQL 5.5 之后使用 InnoDB 引擎 MyISAM 引擎读取速度较快，占用资源相对较少，不支持事务，不支持外键约束，但支持全文索引 读写互相阻塞，也就是说读数据的时候你就不能写数据，写数据的时候你就不能读数据 MyISAM 引擎只能缓存索引，而不能缓存数据 （2）InnoDB 存储引擎特点 事务型数据库的首选引擎，支持事务安全表，支持行锁定和外键，MySQL5.5.5 版本之后，InnoDB作为默认存储引擎 具有提交、回滚和崩溃恢复能力的事务安全存储引擎，能处理巨大数据量，性能及效率高，完全支持外键完整性约束 具有非常高效的缓存特性，能缓存索引也能缓存数据，对硬件要求比较高 使用InnoDB时，将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据⽂文件，以及两个名为 ib_logfile0 和 ib_logfile1 的 5MB ⼤大⼩小的日志⽂文件 （3）Memory 存储引擎特点 Memory存储引擎将表中的数据存储到内存中，为查询和引用其他表数据提供快速访问 Memory存储引擎执行 HASH 和 BTREE 索引，不支持 BLOB 和 TEXT 列，支持AUTO_INCREMENT列和对可包含 NULL 值得列的索引 当不再需要 Memory 表的内容时，要释放被 Memory 表使用的内存，应该执行DELETE FROM 或 TRUNCATE TABLE ，或者删除整个表 4、存储引擎适用场合 （1）MyISAM 适⽤用场景 不需要事务支持的业务，例如：转账就不行 适用于读数据比较多的业务，不适用于读写频繁的业务 并发相对较低、数据修改相对较少的业务 硬件资源比较差的机器可以考虑使用 MyISAM 引擎 （2）InnoDB 适⽤用场景 需要事务⽀持的业务、⾼并发的业务 数据更新较为频繁的场景，⽐如：BBS、SNS、微博等 数据⼀致性要求较⾼的业务，⽐如：充值转账、银⾏卡转账 （3）总结 使用MyISAM: 不需事务，空间小，以查询访问为主 使用InnoDB: 多删除、更新操作，安全性高，事务处理及并发控制 5、查看当前默认存储引擎 123456789mysql&gt; show variables like '%storage_engine';+----------------------------------+--------+| Variable_name | Value |+----------------------------------+--------+| default_storage_engine | InnoDB || default_tmp_storage_engine | InnoDB || internal_tmp_disk_storage_engine | InnoDB |+----------------------------------+--------+3 rows in set, 1 warning (0.02 sec) 6、修改默认存储引擎 （1）MySQL 5.5 修改my.ini配置文件 1default_storage_engine=InnoDB （2）MySQL 5.7 最简单的方法，就是通过命令直接修改表的存储引擎，如下所示： 1alter table 表名 ENGINE = 引擎名; 示例： 1ALTER TABLE student ENGINE = InnoDB; 7、设置表的存储引擎 语法格式： 123CREATE TABLE 表名(#省略代码)ENGINE=存储引擎; 示例： 123CREATE TABLE `myisam` (id INT(4))ENGINE=MyISAM; 三、MySQL补充知识 在mysql中，每个数据库最多可创建20亿个表，一个表允许定义1024列，每行的最大长度为8092字节（不包括⽂本和图像类型的长度）。 当表中定义有varchar、nvarchar或varbinary类型列时，如果向表中插入的数据行超过8092字节时，将导致语句失败，并产生错误信息。 SQL Server对每个表中行的数量没有直接限制，但它受数据库存储空间的限制。每个数据库的最大空间1048516TB，所以一个表可用的最大空间为1048516TB减去数据库类系统表和其它数据库对象所占用的空间。理论上无限大，就看你硬盘够不够大，大多数情况先是你的硬盘不够。","path":"posts/1d95.html","date":"06-02","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"mysql数据库基础","text":"一、数据库基础知识 1、什么是数据库 数据库的概念诞生生于60年前，随看信息技术和市场的快速发展，数据库技术层出不穷，随着应用的扩展和深入，数据库的数量和规模越来越大，其诞生和发展给计算机信息管理带来了一场巨大的革命。 数据库的发展大致划分为以下几个阶段:人工管理阶段、文件系统阶段、数据库系统阶段、高级数据库阶段。其种类大概有3种:层次式数据库、网络式数据库和关系式数据库。不同种类的数据库按不同的数据结构来联系和组织。 对于数据库的概念，没有一个完全固定的定义。 随着数据库历史的发展，定义的内容也有很大的差异，其中一种比较普遍的观点认为，数据库(DataBase, DB)是一个长期存储在计算机内的、有组织的、有共享的，统一管理的数据集合。它是一个按数据结构来存储和管理数据的计算机软件系统。即数据库包含两层含义:保管数据的“仓库&quot;，以及数据管理的方法和技术。 数据库的特点包括:实现数据共享，减少数据冗余;采用特定的数据类型:具有较高的数据独立性:具有统一的数据控制功能。 2、为何需要数据库 存储数据的方法 第一种方法:用大脑来记住数据 第二种方法:写在纸上 第三种方法:写在计算机的内存中 第四种方法:写成磁盘文件 3、数据库能够做什么 存储大量数据，方便检索和访问 保持数据信息的一致、完整 共享和安全 通过组合分析，产生新的有用信息 4、数据库和应用程序 应用程序 数据库 作用 响应操作并显示结果、向数据库请求数据 存储数据、检索数据、生成新的数据 要求 美观、操作简单方便 统一安全、性能等 5、时下流行的数据库 Oracle SqIServer MySQL Oracle公司的产品 针对不同用户群体的多个版本 开放源代码 产品免费、服务收费 易用性好 网站应用广泛 6、数据库的基本概念 在关系数据库中，数据库的表是一系列二维数组的集合,用来存储数据和操作数据的逻辑结构。它是由纵向的列和横向的行组成，行被称为记录，也叫作实体,是组织数据的单位;列被称为字段，每一列表示记录的一个属性，都有相应的描述信息，如数据类型、数据宽度等。例如一个有关作者信息的名为authors的表中，每个列包含所有作者的某个特定类型的信息。 （1）实体 这些客观存在的、可以被描述的事物都是“实体”。 二、MySQL数据库 MySQL是一个开放源代码的数据库管理系统(DBMS) ，它是由MySQL AB公司开发、发布并支持的。MySQL是一个跨平台的开源关系数据库管理系统，广泛地应用在Internet上的中小型网站公司开发中。 1、MySQL的优势 运行速度快。 使用成本低: MySQL对多数个人用户来说是免费的。 容易使用:与其他大型数据库的设置和管理相比，其复杂程度较低，易于学习。 可移植性强:能够工作在众多不同的系统平台上，例如: Windows. Linux、Unix等。 支持丰富的接口;提供了用于C、C++、Java、per1、PHP、Ruby、Python等语言的API 支持查询语言; MySQL可以利用标准SQL语法和支持ODBC (开放式数据库连接)的应用程序 安全性和连续性:十分灵活和安全的权限和密码系统，允许基于主机的验证。连接到服务器器时，所有的密码传输均采用加密形式，从而保证了密码安全。并且由于Mysq1是网络化的，因此可以在因特网上的任何地方访问，提高数据共享的效率。， 2、MySQL版本 MySQL分为2个不同的版本: 社区版(Community Server) 企业版(Enterprise Server) 免费、开源 收费，不可自由下载 适合普通用户 适合对功能和安全要求高的企业用户 功能和服务更完善它能够以很高的性价比为企业提供数据仓库应用，支持ACID事务处理,提供完整的提交、回滚、崩溃恢复和行级锁定功能。 3、MySQL的命名 MySQL的命名机制由3个数字和1个后缀组成，例如mysql-5.5.13. 第1个数字(5)是主版本号，描述了文件格式，所有版本5的发行版都有相同的文件格式。 第2个数字(5)是发行级别，主版本号和发行级别组合在一-起便构成了发行序列号。 第3个数字(13)是在此发行系列的版本号，随每次新发布版本递增，通常选择已经发行的最新版本。 4、MySQL的运行机制 (1)讲解思路 就一个SQL语句，如select * from tablename ，从支持接口进来后，进入连接池后做权限。验证等环节，然后判断是否有缓存，有则直接放回结果，否则进入SQL接口，在查询之前查询优化器进行优化，最后进行解析，查询。并通过存储引擎与文件交互。然后再介绍MySQL的企业管理服务和工具。 (2)名词解释 支持接口: 不同的编程语言与SQL的交互 连接池: 管理缓冲用户连接，线程处理等需要缓存的需求 SQL接口: 接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL接口 解析器: SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。 主要功能: 将SQL语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的;例如将select 自from tablename where 1=1; 分解为select.中、from、 tablename、where 、1=1,并去解析。 如果在分解构成中遇到错误，那么就说明这个SQL语句是不合理的。 查询优化器: SQL语句在查询之前会使用查询优化器对查询进行优化，使用的是”选取-投影-联接’ &quot;策略进行查询。 例: select uid,name from user where gender = 1; a.先根据where语句进行选取，而不是先将表全部查询出来以后再进行gender过滤 b.先根据uid和name进行属性投影，而不是将属性全部陬出以后再进行过滤 将这两个查询条件联接起来生成最终查询结果。 缓存: 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。 这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。 存储引擎: 存储引擎是MySq|中具体的与文件打交道的子系统。也是Mysq|最具有特色的一个地方。 Mysql的存储引擎是插件式的。它根据MySql AB公司提供的文件访问层的一个抽象接口来定制-种文件访问机制(这种访问机制就叫存储引擎)。 现在有很多种存储引擎,各个存储引擎的优势各不一样，最常用的9MyISAM. InnoDB. BDB。 MyISAM引擎.它查询速度快。有较好的索引优化和数据压缩技术，但是它不支持事务。 InnoDB支持事务，并且提供行级的锁定，应用也相当厂泛。 Mysq也支持自己定制存储引擎，甚至一个库中不同的表使用不同的存储引擎，这些都是允许的。 MySQL5.7默认使用InnoDB存储引擎。 5、MySQL安装与配置 (1)安装步骤(略) (2)基本配置 123端口号: 3306默认字符集: utf-8root密码设置 (3)安装目录介绍 1234bin:include:1ib:share: (4)命令行连接MySQL(cmd窗口) 1)检查MySQL服务是否启动 方式1: Windows服务 右击此电脑——管理——服务和应用程序——服务——查找MYSQL57服务（我的mysql名称是mysqlxgp888） 如果关闭该服务，登陆mysql会出错 12C:\\WINDOWS\\system32&gt;mysql -u root -pERROR 2003 (HY000): Can't connect to MySQL server on 'localhost' (10061) 方式2: dos命令启动mysql 123C:\\WINDOWS\\system32&gt;net start mysqlxgp888MYSQLxgp888 服务正在启动 .MYSQLxgp888 服务已经启动成功。 关闭mysql服务 123C:\\WINDOWS\\system32&gt;net stop mysqlxgp888MYSQLxgp888 服务正在停止.MYSQLxgp888 服务已成功停止。 修改了配置文件，必须重启MySQL服务才能生效。 2)连接MySQL 语法格式: 1mysq1 -h服务器主机地址-u用户名-p密码 示例: 1mysq1 -u root -p 方式1: dos命令启动 方式2: MySQL Command Line Client 默认root登录，仅输入密码。 三、MySQL数据库类型 1、系统数据库 安装完MySQL服务器后，MySQL会附带系统数据库，包括: information_ schema:主要存储系统中的一些数据库对象信息，如用户表信息、字段信息、权限信息、字符集信息和分区信息等。 performance_ schema: 主要存储数据库服务器性能参数 mysql:主要存储系统的用户权限信息 test :MySQL数据库管理系统自动创建的测试数据库，任何用户都可以使用 2、用户数据库 用户数据库是用户根据实际需求创建的数据库。本章后面的讲解主要针对用户数据库。 四、数据库基本操作（cmd） 1、登陆数据库 1C:\\WINDOWS\\system32&gt;mysql -u root -p123456 查看一下 123456789101112mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || userinfo |+--------------------+7 rows in set (0.00 sec) 2、创建数据库（test） 基本语法： create database 数据库名称 ； 创建应该名称为itcast的数据库。sql语法如下： 1create database itcast; 需要主要的是，为了避免用户自定义的名称与系统命令冲突，最好使用反引号（``）包括数据库名称/字段名称和数据表名称 如果创建数据库存在，则程序会报错，为了防止此情况发生，再创建数据库可以使用“if not exists”，语法如下： 12mysql&gt; create database test;Query OK, 1 row affected (0.00 sec) 3、查看数据库 查看MySql数据库服务器已经存在的数据库 12345678910111213mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || test || userinfo |+--------------------+7 rows in set (0.00 sec) 4、选择数据库 数据库服务器可能存在多个数据，选择数据库的命令语法： 1use 数据库名称 操作 12mysql&gt; use test;Database changed 5、删除数据库 数据库的删除操作不仅会删除里面的数据，还会回收原来分配的存储空间 1drop database 数据库名称 在使用“drop database” 命令删除数据库时，若删除数据库不存在，MySql服务器会报错，因此，可以再删除数据库时，使用“if existe” 12mysql&gt; drop database test;Query OK, 0 rows affected (0.00 sec) //若删除MySql数据库服务器中存在数据库itcase,则删除该数据库，否则不执行删除 数据库itcasse的操作。 查看一下 123456789101112mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || userinfo |+--------------------+6 rows in set (0.00 sec) 五、图形化MySQL管理工具 1、连接数据库 2、查看数据库 3、选择数据库 六、结构化查询语言 1、SQL 对数据库进行查询和修改操作的语言叫SQL. SQL的含义是结构化查询语句(Structured Query Languate)，是对数据库进行查询和修改操作的语言。 2、T-SQL T-SQL: Transact-SQL T-SQL是SQL的增强版，对功能进行了扩充：如变量说明、流程控制、功能函数。 3、SQL的组成 名称 解释 命令举例 DML (数据操作语言) 用来操作数据库中所包含的数据 INSERT- 将数据插入表中DELETE-更新表中的现有数据UPDATE-删除数据库表中的所有记录等 DDL (数据定义语言) 用于创建和删除数据库对象等操作 CREATE-创建数据库及其对象（表，索引，视图，存储过程，函数和触发器）DROP-改变现有数据库的结构ALTER-从数据库中删除对象TRUNCATE-删除表中的所有记录，包括为记录分配的所有空格COMMENT-为数据字典添加注释RENAME-重命名对象 DQL (数据查询语言) 用来对数据库中的数据进行查询 SELECT-从数据库中检索数据 DCL (数据控制语言) 用来控制数据库组件的存取许可、存取权限等 GRANT-允许用户访问数据库的权限COMMIT-提交事务ROLLBACK-在发生任何错误的情况下回滚事务 结构化查询语言是高级的非过程化编程语言，允许用户在高层数据结构上工作。它不要求用户指定对数据的存放方法，也不需要用户了zhi解具体的数据存放方式，所以具有完全不同底层结构的不同数据库系统, 可以使用相同的结构化dao查询语言作为数据内输入与管理的接口。结构化查询语言语句可以嵌套，这使它具有极大的灵活性和强大的功能。 扩展资料： SQL可以独立完成数据容库生命周期中的全部活动，包括定义关系模式、录入数据、建立数据库、査询、更新、维护、数据库重构、数据库安全性控制等一系列操作，这就为数据库应用系统开发提供了良好的环境，在数据库投入运行后，还可根据需要随时逐步修改模式，且不影响数据库的运行，从而使系统具有良好的可扩充性。 七、MySQL常用数据类型 MySql提供了很多数值类型，大体分为整数类型和浮点类型 整数类型根据取值范围分为int，smallint等， 浮点类型又分为float，declmal等。 1、数值类型 2、数值类型的属性: UNSIGNED 标识为无符号数 ZEROFILL 宽度(位数)不足，以0填充 3、实施一下 （1）ZEROFILL：没有数值的位置用0填充 12345678910111213create database `school`;#创建数据库use `school`;#切换数据库create table `student` (true`sid` INT(4) ZEROFILL);#创建表desc student;#查看表结构 插入数据 在上面的部分添加如下内容，选中并执行 12insert into `student` VALUES(12),(123),(1234);#插入数据 查看一下 命令行—查看一下 1234567891011mysql&gt; use school;Database changedmysql&gt; select * from student;+------+| sid |+------+| 0012 || 0123 || 1234 |+------+ （2）UNSIGNED不用0填充空值 把上面的ZEROFILL改为UNSIGNED 12345678910111213141516create database `school`;#创建数据库use `school`;#切换数据库create table `student` (true`sid` INT(4) UNSIGNED);#创建表desc student;#查看表结构insert into `student` VALUES(12),(123),(1234)#插入数据 命令行—查看一下 4、字符串类型 BLOB和TEXT都是用于存储大量数据的，但二者的区别在于，对于存储的数据进行排序和比较时，BLOB是区分大小写的，而TEXT是不区分大小写的 注意： char(n) 和 varchar(n) 中括号中 n 代表字符的个数，并不代表字节个数，比如 CHAR(30) 就可以存储 30 个字符。 CHAR 和 VARCHAR 类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。 BINARY 和 VARBINARY 类似于 CHAR 和 VARCHAR，不同的是它们包含二进制字符串而不要非二进制字符串。也就是说，它们包含字节字符串而不是字符字符串。这说明它们没有字符集，并且排序和比较基于列值字节的数值值。 BLOB 是一个二进制大对象，可以容纳可变数量的数据。有 4 种 BLOB 类型：TINYBLOB、BLOB、MEDIUMBLOB 和 LONGBLOB。它们区别在于可容纳存储范围不同。 有 4 种 TEXT 类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。对应的这 4 种 BLOB 类型，可存储的最大长度不同，可根据实际情况选择。 5、日期类型 表示时间值的日期和时间类型为DATETIME、DATE、TIMESTAMP、TIME和YEAR。 每个时间类型有一个有效值范围和一个&quot;零&quot;值，当指定不合法的MySQL不能表示的值时使用&quot;零&quot;值。 TIMESTAMP类型有专有的自动更新特性，将在后面描述。","path":"posts/ba11.html","date":"06-01","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"小案例","text":"编写一个案例代码 1、name_function.py 文件内容 1234567891011121314# coding=utf-8'''编写函数或者类的时候，可以给他们编写测试。通过测试，可确定代码面对各种各样输入都能够按照既定的要求正常工作对于程序员来说，编写测试，可以在用户发现问题前预先找出错误。Python中的测试模块：'''def get_format_name(first,last): '''创建一个姓名''' full_name = first + ' ' + last return full_name.title() 2、names.py 文件内容 12345678910111213# coding=utf-8from exam.name_function import get_format_nameprint('请输入q在指定时间内退出。')while True: fist = input('请输入你的姓：') if fist == 'q': break last = input('请输入你的名：') if last == 'q': break formatted_name = get_format_name(fist,last) print(formatted_name) 输出结果 1234请输入q在指定时间内退出。请输入你的姓：x请输入你的名：gpX Gp 3、编写测试案例代码 test_name_function.py 文件内容 1234567891011121314151617# coding=utf-8import unittestfrom exam.name_function import get_format_nameclass NameTestCase(unittest.TestCase): '''测试name_function.py''' def test_firt_last_name(self): '''能够正确处理某种格式的姓名''' formatted_name = get_format_name('janis','joplin') #断言：期待的结果 self.assertEqual(formatted_name,'janis Joplin')if __name__ == '__main__': unittest.main() 输出结果","path":"posts/a1c5.html","date":"11-03","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python并发线程","text":"开始学习Python线程 Python中使用线程有两种方式：函数或者用类来包装线程对象。 函数式：调用thread模块中的start_new_thread()函数来产生新线程。语法如下: 1thread.start_new_thread ( function, args[, kwargs] ) 参数说明: function - 线程函数。 args - 传递给线程函数的参数,他必须是个tuple类型。 kwargs - 可选参数。python 简单的执行线程次数 123456789101112131415161718192021# coding:utf-8import threadingimport timedef say_hi(): # time.sleep(1) #延迟几秒 print('hello world!')def main(): for i in range(5): # 创建线程 thread = threading.Thread(target=say_hi) # 启动线程 thread.start()if __name__ == '__main__': main() 输出结果 12345hello world!hello world!hello world!hello world!hello world! 1、单线程 在好些年前的MS-DOS时代，操作系统处理问题都是单任务的，我想做听音乐和看电影两件事儿，那么一定要先排一下顺序。 12345678910111213141516from time import ctime,sleepdef music(): for i in range(2): print(\"I was listening to music. %s\" %ctime()) sleep(1)def move(): for i in range(2): print(\"I was at the movies! %s\" %ctime()) sleep(5)if __name__ == '__main__': music() move() print(\"all over %s\" %ctime()) 我们先听了一首音乐，通过for循环来控制音乐的播放了两次，每首音乐播放需要1秒钟，sleep()来控制音乐播放的时长。接着我们又看了一场电影，每一场电影需要5秒钟，因为太好看了，所以我也通过for循环看两遍。在整个休闲娱乐活动结束后，我通过print(&quot;all over %s&quot; %ctime())看了一下当前时间，差不多该睡觉了 输出结果 12345I was listening to music. Wed Jun 17 23:19:18 2020I was listening to music. Wed Jun 17 23:19:19 2020I was at the movies! Wed Jun 17 23:19:20 2020I was at the movies! Wed Jun 17 23:19:25 2020all over Wed Jun 17 23:19:30 2020 其实，music()和move()更应该被看作是音乐和视频播放器，至于要播放什么歌曲和视频应该由我们使用时决定。所以，我们对上面代码做了改造： 12345678910111213141516171819import threadingfrom time import ctime,sleepdef music(func): for i in range(2): print (\"I was listening to %s. %s\" %(func,ctime())) sleep(1)def move(func): for i in range(2): print (\"I was at the %s! %s\" %(func,ctime())) sleep(5)if __name__ == '__main__': music(u'爱情买卖') move(u'阿凡达') print (\"all over %s\" %ctime()) 输出结果 12345I was listening to 爱情买卖. Thu Apr 17 11:48:59 2014I was listening to 爱情买卖. Thu Apr 17 11:49:00 2014I was at the 阿凡达! Thu Apr 17 11:49:01 2014I was at the 阿凡达! Thu Apr 17 11:49:06 2014all over Thu Apr 17 11:49:11 2014 2、多线程 Python3 通过两个标准库 _thread (python2中是thread模块）和 threading 提供对线程的支持。 _thread 提供了低级别的、原始的线程以及一个简单的锁，它相比于 threading 模块的功能还是比较有限的。 （1）使用_thread模块 调用_thread模块中的start_new_thread()函数来产生新线程。 先用一个实例感受一下： 123456789101112131415161718192021222324import _threadimport time# 为线程定义一个函数def print_time(threadName, delay): count = 0 while count &lt; 5: time.sleep(delay) count += 1 print(\"%s: %s\" % (threadName, time.ctime(time.time())))# 创建两个线程try: _thread.start_new_thread(print_time, (\"Thread-1\", 2,)) _thread.start_new_thread(print_time, (\"Thread-2\", 4,))except: print(\"Error: unable to start thread\")while 1: passprint(\"Main Finished\") 输出结果 123456789Thread-1: Thu Aug 10 16:35:47 2017Thread-2: Thu Aug 10 16:35:49 2017Thread-1: Thu Aug 10 16:35:49 2017Thread-1: Thu Aug 10 16:35:51 2017Thread-2: Thu Aug 10 16:35:53 2017Thread-1: Thu Aug 10 16:35:53 2017Thread-1: Thu Aug 10 16:35:55 2017Thread-2: Thu Aug 10 16:35:57 2017Thread-2: Thu Aug 10 16:36:01 2017 注意到，在主线程写了: 12while 1: pass 这是让主线程一直在等待. 如果去掉上面两行，那就直接输出并结束程序执行: 1\"Main Finished\" 线程模块 Python通过两个标准库thread和threading提供对线程的支持。thread提供了低级别的、原始的线程以及一个简单的锁。 threading 模块提供的其他方法： threading.currentThread(): 返回当前的线程变量。 threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 除了使用方法外，线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法: run(): 用以表示线程活动的方法。 start(): 启动线程活动。 join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。 isAlive(): 返回线程是否活动的。 getName(): 返回线程名。 setName(): 设置线程名。 1、直接创建线程 接上面的听音乐和看电影的例子，我们可以直接使用threading.Thread 创建线程，并指定执行的方法以及传递的参数： 12345678910111213141516171819202122232425import threadingfrom time import ctime,sleepdef music(func): for i in range(2): print (\"I was listening to %s. %s\" %(func,ctime())) sleep(1)def move(func): for i in range(2): print (\"I was at the %s! %s\" %(func,ctime())) sleep(5)threads = []t1 = threading.Thread(target=music,args=(u'爱情买卖',))threads.append(t1)t2 = threading.Thread(target=move,args=(u'阿凡达',))threads.append(t2)if __name__ == '__main__': for t in threads: t.start() print (\"all over %s\" %ctime()) 输出结果 12345I was listening to 爱情买卖. Thu Aug 10 16:57:12 2017I was at the 阿凡达! Thu Aug 10 16:57:12 2017all over Thu Aug 10 16:57:12 2017I was listening to 爱情买卖. Thu Aug 10 16:57:13 2017I was at the 阿凡达! Thu Aug 10 16:57:17 2017 2、使用Threading模块创建线程（构造线程类） 我们也可以通过直接从 threading.Thread 继承创建一个新的子类，并实例化后调用 start() 方法启动新线程，即它调用了线程的 run() 方法 使用Threading模块创建线程，直接从threading.Thread继承，然后重写init方法和run方法： 12345678910111213141516171819202122232425262728293031323334#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()print (\"退出主线程\") 输出结果 123456789101112131415开始线程：Thread-1开始线程：Thread-2退出主线程Thread-1: Thu Aug 10 16:48:41 2017Thread-2: Thu Aug 10 16:48:42 2017Thread-1: Thu Aug 10 16:48:42 2017Thread-1: Thu Aug 10 16:48:43 2017Thread-2: Thu Aug 10 16:48:44 2017Thread-1: Thu Aug 10 16:48:44 2017Thread-1: Thu Aug 10 16:48:45 2017退出线程：Thread-1Thread-2: Thu Aug 10 16:48:46 2017Thread-2: Thu Aug 10 16:48:48 2017Thread-2: Thu Aug 10 16:48:50 2017退出线程：Thread-2 从结果可以看到，为什么我们开启了两个线程之后，主线程立即退出了？因为我们没有使用join方法，对于主线程来说，thread1和thread2是子线程，使用join方法，会让主线程等待子线程执行解说再继续执行。 join()方法 我们修改一下代码： 123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()thread1.join()thread2.join()print (\"退出主线程\") 123456789101112131415开始线程：Thread-1开始线程：Thread-2Thread-1: Thu Aug 10 16:52:07 2017Thread-2: Thu Aug 10 16:52:08 2017Thread-1: Thu Aug 10 16:52:08 2017Thread-1: Thu Aug 10 16:52:09 2017Thread-2: Thu Aug 10 16:52:10 2017Thread-1: Thu Aug 10 16:52:10 2017Thread-1: Thu Aug 10 16:52:11 2017退出线程：Thread-1Thread-2: Thu Aug 10 16:52:12 2017Thread-2: Thu Aug 10 16:52:14 2017Thread-2: Thu Aug 10 16:52:16 2017退出线程：Thread-2退出主线程 可以看到 退出主线程 在最后才被打印出来。 setDaemon()方法 有一个方法常常拿来与join方法做比较，那就是setDaemon()方法。我们首先来看一下setDaemon()方法的使用效果： 12345678910111213141516171819202122232425262728293031323334353637#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.setDaemon(True)thread2.setDaemon(True)thread1.start()thread2.start()print (\"退出主线程\") 输出结果 123开始线程：Thread-1开始线程：Thread-2退出主线程 可以看到，在主线程结束之后，程序就终止了，也就是说两个子线程也被终止了，这就是setDaemon方法的作用。主线程A中，创建了子线程B，并且在主线程A中调用了B.setDaemon(),这个的意思是，把主线程A设置为守护线程，这时候，要是主线程A执行结束了，就不管子线程B是否完成,一并和主线程A退出.这就是setDaemon方法的含义，这基本和join是相反的。此外，还有个要特别注意的：必须在start() 方法调用之前设置，如果不设置为守护线程，程序会被无限挂起。 3、两个疑问 我们刚才介绍了两种使用多线程的方式，一种是直接调用threading.Thread 创建线程，另一种是从 threading.Thread 继承创建一个新的子类，并实例化后调用 start() 方法启动进程。学到这里，我就抛出了两个疑问，为什么第一种方法中我们可以为不同的线程指定运行的方法，而第二种我们都运行的是同一个方法，那么它内部的实现机制是什么呢？第二个疑问是，第二种方法中，我们没有实例化start()方法，那么run和start这两个方法的联系是什么呢？ 首先，start方法和run方法的关系如下：用start方法来启动线程，真正实现了多线程运行，这时无需等待run方法体代码执行完毕而直接继续执行下面的代码。通过调用Thread类的start()方法来启动一个线程，这时此线程处于就绪（可运行）状态，并没有运行，一旦得到cpu时间片，就开始执行run()方法，这里方法 run()称为线程体，它包含了要执行的这个线程的内容，Run方法运行结束，此线程随即终止。 而run()方法的源码如下，可以看到，如果我们指定了target即线程执行的函数的话，run方法可以转而调用那个函数，如果没有的话，将不执行，而我们在自定义的Thread类里面重写了这个run 方法，所以程序会执行这一段。 12345678910111213141516def run(self): \"\"\"Method representing the thread's activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object's constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. \"\"\" try: if self._target: self._target(*self._args, **self._kwargs) finally: # Avoid a refcycle if the thread is running a function with # an argument that has a member that points to the thread. del self._target, self._args, self._kwargs 4、按时间为批次执行线程 线程有不确定性 1234567891011121314151617181920# coding:utf-8import threadingdef say_hi(count, name): while count &gt; 0: print('hello', name) count -= 1def main(): username = ['Alan', 'Bob', 'Cendy', 'Kily','Heny'] for i in range(5): thread = threading.Thread(target=say_hi,args=(50,username[i])) thread.start()if __name__ == '__main__': main() 输出结果 12345678910111213hello Alanhello Alanhello Alanhello Alanhello hello Bobhello Bobhello Bobhello Bobhello BobAlanhello Cendyhello Cendyhello Bobhellohello Alanhello Cendy 5、继承的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding:utf-8import threadingimport timedef say_hi(count,name): # time.sleep(1) #延迟几秒 # print('hello world!') while count &gt; 0: print('hello', name) count -= 1def main(): username = ['Alan','Bob','Cendy','Kily','Heny'] for i in range(5): # thread = threading.Thread(target=say_hi,args=(10,username[i])) thread = MyThread(10,username[i]) thread.start() # for i in range(5): # # 创建线程 # thread = threading.Thread(target=say_hi) # # 启动线程 # thread.start()class MyThread(threading.Thread): def __init__(self, count, name): super().__init__() self.count = count self.name = name def run(self): while self.count &gt; 0: print('hello', self.name) self.count -= 1def run_main(): username = ['Alan', 'Bob', 'Cendy', 'Kily', 'Heny'] for i in range(5): # thread = threading.Thread(target=say_hi, args=(10, username[i])) thread = MyThread(10,username[i]) thread.start()if __name__ == '__main__': run_main() 输出结果 12345678910hello Alanhello Alanhello Bobhello Bobhello Cendyhello Cendyhello Kilyhello Kilyhello Henyhello Heny 线程同步 如果多个线程共同对某个数据修改，则可能出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。 使用Thread对象的Lock和Rlock可以实现简单的线程同步，这两个对象都有acquire方法和release方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到acquire和release方法之间。如下： 多线程的优势在于可以同时运行多个任务（至少感觉起来是这样）。但是当线程需要共享数据时，可能存在数据不同步的问题。 考虑这样一种情况：一个列表里所有元素都是0，线程&quot;set&quot;从后向前把所有元素改成1，而线程&quot;print&quot;负责从前往后读取列表并打印。 那么，可能线程&quot;set&quot;开始改的时候，线程&quot;print&quot;便来打印列表了，输出就成了一半0一半1，这就是数据的不同步。为了避免这种情况，引入了锁的概念。 锁有两种状态——锁定和未锁定。每当一个线程比如&quot;set&quot;要访问共享数据时，必须先获得锁定；如果已经有别的线程比如&quot;print&quot;获得锁定了，那么就让线程&quot;set&quot;暂停，也就是同步阻塞；等到线程&quot;print&quot;访问完毕，释放锁以后，再让线程&quot;set&quot;继续。 经过这样的处理，打印列表时要么全部输出0，要么全部输出1，不会再出现一半0一半1的尴尬场面。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/python3import threadingimport timeclass myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开启线程： \" + self.name) # 获取锁，用于线程同步 threadLock.acquire() print_time(self.name, self.counter, 3) # 释放锁，开启下一个线程 threadLock.release()def print_time(threadName, delay, counter): while counter: time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1threadLock = threading.Lock()threads = []# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()# 添加线程到线程列表threads.append(thread1)threads.append(thread2)# 等待所有线程完成for t in threads: t.join()print (\"退出主线程\") 输出结果 123456789开启线程： Thread-1开启线程： Thread-2Thread-1: Thu Aug 10 20:45:59 2017Thread-1: Thu Aug 10 20:46:00 2017Thread-1: Thu Aug 10 20:46:01 2017Thread-2: Thu Aug 10 20:46:03 2017Thread-2: Thu Aug 10 20:46:05 2017Thread-2: Thu Aug 10 20:46:07 2017退出主线程 线程优先级队列（ Queue） Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步。 Queue模块中的常用方法: Queue.qsize() 返回队列的大小 Queue.empty() 如果队列为空，返回True,反之False Queue.full() 如果队列满了，返回True,反之False Queue.full 与 maxsize 大小对应 Queue.get([block[, timeout]])获取队列，timeout等待时间 Queue.get_nowait() 相当Queue.get(False) Queue.put(item) 写入队列，timeout等待时间 Queue.put_nowait(item) 相当Queue.put(item, False) Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号 Queue.join() 实际上意味着等到队列为空，再执行别的操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/usr/bin/python3import queueimport threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, q): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.q = q def run(self): print (\"开启线程：\" + self.name) process_data(self.name, self.q) print (\"退出线程：\" + self.name)def process_data(threadName, q): while not exitFlag: queueLock.acquire() if not workQueue.empty(): data = q.get() queueLock.release() print (\"%s processing %s\" % (threadName, data)) else: queueLock.release() time.sleep(1)threadList = [\"Thread-1\", \"Thread-2\", \"Thread-3\"]nameList = [\"One\", \"Two\", \"Three\", \"Four\", \"Five\"]queueLock = threading.Lock()workQueue = queue.Queue(10)threads = []threadID = 1# 创建新线程for tName in threadList: thread = myThread(threadID, tName, workQueue) thread.start() threads.append(thread) threadID += 1# 填充队列queueLock.acquire()for word in nameList: workQueue.put(word)queueLock.release()# 等待队列清空while not workQueue.empty(): pass# 通知线程是时候退出exitFlag = 1# 等待所有线程完成for t in threads: t.join()print (\"退出主线程\") 上面的代码每次执行的结果是不一样的，取决于哪个进程先获得锁，一次运行的输出如下： 123456789101112开启线程：Thread-1开启线程：Thread-2开启线程：Thread-3Thread-2 processing OneThread-3 processing TwoThread-1 processing ThreeThread-3 processing FourThread-1 processing Five退出线程：Thread-3退出线程：Thread-2退出线程：Thread-1退出主线程 总结 如果你的代码是IO密集型的，线程和多进程可以帮到你。多进程比线程更易用，但是消耗更多的内存。如果你的代码是CPU密集型的，多进程就明显是更好的选择——特别是所使用的机器是多核或多CPU的。对于网络应用，在你需要扩展到多台机器上执行任务，RQ是更好的选择。 注：关于并发、并行区别与联系 并发是指，程序在运行的过程中存在多于一个的执行上下文。这些执行上下文一般对应着不同的调用栈。 在单处理器上，并发程序虽然有多个上下文运行环境，但某一个时刻只有一个任务在运行。 但在多处理器上，因为有了多个执行单元，就可以同时有数个任务在跑。 这种物理上同一时刻有多个任务同时运行的方式就是并行。 和并发相比，并行更加强调多个任务同时在运行。 而且并行还有一个层次问题，比如是指令间的并行还是任务间的并行。","path":"posts/2b38.html","date":"11-02","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python并发线程介绍","text":"Python 多线程 多线程类似于同时执行多个不同程序，多线程运行有如下优点： 使用线程可以把占据长时间的程序中的任务放到后台去处理。 用户界面可以更加吸引人，这样比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度 程序的运行速度可能加快 在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下我们可以释放一些珍贵的资源如内存占用等等。 线程在执行过程中与进程还是有区别的。每个独立的进程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 每个线程都有他自己的一组CPU寄存器，称为线程的上下文，该上下文反映了线程上次运行该线程的CPU寄存器的状态。 指令指针和堆栈指针寄存器是线程上下文中两个最重要的寄存器，线程总是在进程得到上下文中运行的，这些地址都用于标志拥有线程的进程地址空间中的内存。 线程可以被抢占（中断）。 在其他线程正在运行时，线程可以暂时搁置（也称为睡眠） – 这就是线程的退让。 线程和进程 计算机，用于计算的机器。计算机的核心是CPU，在现在多核心的电脑很常见了。为了充分利用cpu核心做计算任务，程序实现了多线程模型。通过多线程实现多任务的并行执行。 现在的操作系统多是多任务操作系统。每个应用程序都有一个自己的进程。操作系统会为这些进程分配一些执行资源，例如内存空间等。在进程中，又可以创建一些线程，他们共享这些内存空间，并由操作系统调用，以便并行计算。 线程状态 创建线程之后，线程并不是始终保持一个状态。其状态大概如下： New 创建。 Runnable 就绪。等待调度 Running 运行。 Blocked 阻塞。阻塞可能在 Wait Locked Sleeping Dead 消亡 这些状态之间是可以相互转换的，一图胜千颜色： 线程中执行到阻塞，可能有3种情况： 同步：线程中获取同步锁，但是资源已经被其他线程锁定时，进入Locked状态，直到该资源可获取（获取的顺序由Lock队列控制） 睡眠：线程运行sleep()或join()方法后，线程进入Sleeping状态。区别在于sleep等待固定的时间，而join是等待子线程执行完。当然join也可以指定一个“超时时间”。从语义上来说，如果两个线程a,b, 在a中调用b.join()，相当于合并(join)成一个线程。最常见的情况是在主线程中join所有的子线程。 等待：线程中执行wait()方法后，线程进入Waiting状态，等待其他线程的通知(notify）。 线程类型 线程有着不同的状态，也有不同的类型。大致可分为： 主线程 子线程 守护线程（后台线程） 前台线程 Python线程与GIL 相比进程，线程更加轻量，可以实现并发。可是在python的世界里，对于线程，就不得不说一句GIL(全局解释器锁)。GIL的存在让python的多线程多少有点鸡肋了。Cpython的线程是操作系统原生的线程在解释器解释执行任何Python代码时，都需要先获得这把锁才行，在遇到 I/O 操作时会释放这把锁。因为python的进程做为一个整体，解释器进程内只有一个线程在执行，其它的线程都处于等待状态等着GIL的释放。 关于GIL可以有更多的趣事，一时半会都说不完。总之python想用多线程并发，效果可能还不如单线程（线程切换耗时间）。想要利用多核，可以考虑使用多进程。 线程和进程 计算机的核心是CPU，它承担了所有的计算任务。它就像一座工厂，时刻在运行。 假定工厂的电力有限，一次只能供给一个车间使用。也就是说，一个车间开工的时候，其他车间都必须停工。背后的含义就是，单个CPU一次只能运行一个任务。 进程就好比工厂的车间，它代表CPU所能处理的单个任务。任一时刻，CPU总是运行一个进程，其他进程处于非运行状态。 一个车间里，可以有很多工人。他们协同完成一个任务。 线程就好比车间里的工人。一个进程可以包括多个线程。 车间的空间是工人们共享的，比如许多房间是每个工人都可以进出的。这象征一个进程的内存空间是共享的，每个线程都可以使用这些共享内存。 可是，每间房间的大小不同，有些房间最多只能容纳一个人，比如厕所。里面有人的时候，其他人就不能进去了。这代表一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。 一个防止他人进入的简单方法，就是门口加一把锁。先到的人锁上门，后到的人看到上锁，就在门口排队，等锁打开再进去。这就叫&quot;互斥锁&quot;（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域。 还有些房间，可以同时容纳n个人，比如厨房。也就是说，如果人数大于n，多出来的人只能在外面等着。这好比某些内存区域，只能供给固定数目的线程使用。 这时的解决方法，就是在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了。这种做法叫做&quot;信号量&quot;（Semaphore），用来保证多个线程不会互相冲突。 不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计。 多线程与多进程 从上面关于线程和进程的的通俗解释来看，多线程和多进程的含义如下： 多进程：允许多个任务同时进行 多线程：允许单个任务分成不同的部分运行","path":"posts/f802.html","date":"11-01","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python 操作 MySQL 写入读出 CSV 文件","text":"一.Python 操作 MySQL 写入读出 CSV 文件 有一个数据文件，是 csv 格式，大约 1T 数据，要导入到 MySQL，要求正确高效。 csv 数据格式这个样子的 12345678[root@python ~]# cat data.csvSymbol,Price,DateAA, 39.48, 6/11/2007AIG, 71.38, 6/11/2007AXP, 62.58, 6/11/2007BA, 98.31, 6/11/2007C, 53.08, 6/11/2007CAT, 78.29, 6/11/2007 正好最近要写再测试数据库的脚本，虽然两者不搭边，总归都是操作数据库的，正好测试的时候就用 python 连了 首先 Python 数据库接口支持很多数据库，什么关系型的像 mysql 啊、PG（PostgreSQL） 啊、SQL Server、Oracle，非关系型的像 MongoDB 啊，Redis 啊， Hbase 等等， 这里就以 MySQL 数据库为例，毕竟我要用的 MySQL 嘛，而且面试题也是，当然操作其他数据库道理也都一样，从一个 csv 文件中读入数据，插入到数据库中，再将数据库中的数据读出，保存到另一个 csv 文件。 介绍 主要定义两个对象，一个用于管理连接的 Connection（count） 了，另一个是用于执行查询的 Cursor （cur）对象。 Python 操作数据库的大致思路 导入模块 连接数据库 执行查询返回结果 步骤： 导入数据库模块 import MySQLdb 连接数据库 connect ，返回一个 conn 对象 通过该对象的 cursor() 成员函数返回一个 cur 对象 通过 cur 对象的 execute() 方法执行 SQL 语句 关闭 cur 和 conn对象 1、读文件 如何用Python像操作Excel一样提取其中的一列，即一个字段，利用Python自带的csv模块，有两种方法可以实现： 第一种方法使用reader函数，接收一个可迭代的对象（比如csv文件），能返回一个生成器，就可以从其中解析出csv的内容：比如下面的代码可以读取csv的全部内容，以行为单位： 1234567891011121314# coding=utf-8import csvfrom collections import namedtuple'''读取csv文件'''with open('data.csv') as f: f_csv = csv.reader(f) # 取出csv文件头：表头 headers = next(f_csv) # 遍历表头以外的所有行 d = namedtuple('Row', 'headers') for r in f_csv: row = d(r) print(row) 输出结果 123456Row(headers=['AA', ' 39.48', ' 6/11/2007'])Row(headers=['AIG', ' 71.38', ' 6/11/2007'])Row(headers=['AXP', ' 62.58', ' 6/11/2007'])Row(headers=['BA', ' 98.31', ' 6/11/2007'])Row(headers=['C', ' 53.08', ' 6/11/2007'])Row(headers=['CAT', ' 78.29', ' 6/11/2007']) 或 123456789101112#!/usr/bin/python3# -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.reader(f) rows = [row for row in reader]print(rows) 输出结果 1234567[['Symbol', 'Price', 'Date'], ['AA', ' 39.48', ' 6/11/2007'], ['AIG', ' 71.38', ' 6/11/2007'], ['AXP', ' 62.58', ' 6/11/2007'], ['BA', ' 98.31', ' 6/11/2007'], ['C', ' 53.08', ' 6/11/2007'], ['CAT', ' 78.29', ' 6/11/2007']] 要提取其中某一列，可以用下面的代码： 123456789101112#!/usr/bin/python3# -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读取第二列的内容with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.reader(f) column = [row[1] for row in reader]print(column) 输出结果 1['Price', ' 39.48', ' 71.38', ' 62.58', ' 98.31', ' 53.08', ' 78.29'] 注意从csv读出的都是str类型。这种方法要事先知道列的序号，比如Name在第2列，而不能根据’Name’这个标题查询。这时可以采用第二种方法： 2、第二种方法 是使用DictReader，和reader函数类似，接收一个可迭代的对象，能返回一个生成器，但是返回的每一个单元格都放在一个字典的值内，而这个字典的键则是这个单元格的标题（即列头）。用下面的代码可以看到DictReader的结构： 1234567891011# -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.DictReader(f) column = [row for row in reader]print(column) 输出结果 123456[&#123;'Symbol': 'AA', 'Price': ' 39.48', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'AIG', 'Price': ' 71.38', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'AXP', 'Price': ' 62.58', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'BA', 'Price': ' 98.31', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'C', 'Price': ' 53.08', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'CAT', 'Price': ' 78.29', 'Date': ' 6/11/2007'&#125;] 3、把 csv 中的数据读出来放到插入到 mysql 表 对于 mysql 数据库，需要安装第三方模块 Mysql-python 。安装完以后，在程序中导入模块即可。 库名：student_info 表名：data_csv 首先要导入 MySQLdb 模块先安装 MySQLdb 1pip install MySQLdb 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# coding=utf-8import pymysql as dbimport csvfrom collections import namedtuplefrom contextlib import contextmanager@contextmanagerdef get_conn(**kwargs): '''获取mysql数据库连接''' conn = db.connect( host=kwargs.get('host'), user=kwargs.get('user'), passwd=kwargs.get('passwd'), port=kwargs.get('port', 3306), db=kwargs.get('db')) try: yield conn finally: if conn: conn.close()def get_data(filename): '''读取csv文件''' with open(filename) as f: f_csv = csv.reader(f) # 取出csv文件头：表头 headers = next(f_csv) # 遍历表头以外的所有行 Row = namedtuple(\"Row\", ['Symbol', 'Price', 'Date']) for r in f_csv: yield Row(*r)def execute_sql(conn, sql): '''执行SQL的函数''' with conn as cur: cur.execute(sql)def create_table(conn): '''创建新表''' sql_drop_table = 'drop table if exists data_csv' sql_create_table = '''create table `data_csv`( `Symbol` varchar (20) not null, `Price` decimal not null, `Date` varchar (20) default null) engine=innodb default charset=utf8mb4 ''' for sql in [sql_drop_table, sql_create_table]: execute_sql(conn, sql)def insert_data(conn, symbol, price, date): insert_format = \"insert into data_csv values('&#123;0&#125;','&#123;1&#125;','&#123;2&#125;')\" sql = insert_format.format(symbol, price, date) execute_sql(conn, sql)def main(): conn_args = dict(host='127.0.0.1', user='root', passwd='123456', port=3306, db='student_info') with get_conn(**conn_args) as conn: with conn as cur: create_table(conn) for t in get_data('data.csv'): insert_data(conn, t.Symbol, t.Price, t.Date)if __name__ == '__main__': main()","path":"posts/5bf9.html","date":"10-30","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python 操作 MySQL 数据库","text":"Python 操作 MySQL 数据库 Python 标准数据库接口为 Python DB-API，Python DB-API为开发人员提供了数据库应用编程接口。 Python 数据库接口支持非常多的数据库，你可以选择适合你项目的数据库： GadFly mSQL MySQL PostgreSQL Microsoft SQL Server 2000 Informix Interbase Oracle Sybase 你可以访问Python数据库接口及API查看详细的支持数据库列表。 不同的数据库你需要下载不同的DB API模块，例如你需要访问Oracle数据库和Mysql数据，你需要下载Oracle和MySQL数据库模块。 DB-API 是一个规范. 它定义了一系列必须的对象和数据库存取方式, 以便为各种各样的底层数据库系统和多种多样的数据库接口程序提供一致的访问接口 。 Python的DB-API，为大多数的数据库实现了接口，使用它连接各数据库后，就可以用相同的方式操作各数据库。 Python DB-API使用流程： 引入 API 模块。 获取与数据库的连接。 执行SQL语句和存储过程。 关闭数据库连接。 1、什么是MySQLdb? MySQLdb 是用于Python链接Mysql数据库的接口，它实现了 Python 数据库 API 规范 V2.0，基于 MySQL C API 上建立的。 2、如何安装MySQLdb? 为了用DB-API编写MySQL脚本，必须确保已经安装了MySQL。复制以下代码，并执行： 1234#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb 如果执行后的输出结果如下所示，意味着你没有安装 MySQLdb 模块： 1234Traceback (most recent call last): File \"test.py\", line 3, in &lt;module&gt; import MySQLdbImportError: No module named MySQLdb 安装MySQLdb，请访问 http://sourceforge.net/projects/mysql-python ，(Linux平台可以访问：https://pypi.python.org/pypi/MySQL-python)从这里可选择适合您的平台的安装包，分为预编译的二进制文件和源代码安装包。 如果您选择二进制文件发行版本的话，安装过程基本安装提示即可完成。如果从源代码进行安装的话，则需要切换到MySQLdb发行版本的顶级目录，并键入下列命令: 12345$ gunzip MySQL-python-1.2.2.tar.gz$ tar -xvf MySQL-python-1.2.2.tar$ cd MySQL-python-1.2.2$ python setup.py build$ python setup.py install **注意：**请确保您有root权限来安装上述模块。 3、数据库连接 连接数据库前，请先确认以下事项： 您已经创建了数据库 TESTDB. 在TESTDB数据库中您已经创建了表 EMPLOYEE EMPLOYEE表字段为 FIRST_NAME, LAST_NAME, AGE, SEX 和 INCOME。 连接数据库TESTDB使用的用户名为 “testuser” ，密码为 “test123”,你可以可以自己设定或者直接使用root用户名及其密码，Mysql数据库用户授权请使用Grant命令。 在你的机子上已经安装了 Python MySQLdb 模块。 如果您对sql语句不熟悉，可以访问我们的 SQL基础教程 实例1： 以下实例链接Mysql的student_info数据库： 12345678910111213141516171819202122#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标cursor = db.cursor()# 使用execute方法执行SQL语句cursor.execute(\"SELECT VERSION()\")# 使用 fetchone() 方法获取一条数据data = cursor.fetchone()print(\"Database version : %s\" % data)# 关闭数据库连接db.close() 执行以上脚本输出结果如下： 1Database version : 5.7.14-log 实例2： 以下实例链接Mysql的student_info数据库并查看user表 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# encoding=utf-8import pymysql as dbfrom contextlib import contextmanager@contextmanagerdef get_conn(**kwargs): '''获取mysql数据库连接''' conn = db.connect( host=kwargs.get('host'), user=kwargs.get('user'), passwd=kwargs.get('passwd'), port=kwargs.get('port', 3306), db=kwargs.get('db')) try: yield conn finally: if conn: conn.close()def execute_sql(conn, sql): '''执行SQL的函数''' # cur = conn.cursor() with conn as cur: cur.execute(sql)def create_table(conn): '''创建新表''' sql_drop_table = 'drop table if exists student' sql_create_table = '''create table `student`( `sno` int(11) not null, `sname` varchar(25) default null, `sage` int(11) default null, primary key (`sno`)) engine=innodb default charset=utf8mb4 ''' for sql in [sql_drop_table, sql_create_table]: execute_sql(conn, sql)def insert_data(conn, sno, sname, sage): insert_format = \"insert into student values(&#123;0&#125;,'&#123;1&#125;',&#123;2&#125;)\" sql = insert_format.format(sno, sname, sage) execute_sql(conn, sql)def main(): conn_args = dict(host='127.0.0.1', user='root', passwd='123456', port=3306, db='student_info') with get_conn(**conn_args) as conn: with conn as cur: cur.execute('select * from user') rows = cur.fetchall() for row in rows: print(row)if __name__ == '__main__': main() 执行以上脚本输出结果如下： 1(111,) 4、创建数据库表 如果数据库连接存在我们可以使用execute()方法来为数据库创建表，如下所示创建表EMPLOYEE： 123456789101112131415161718192021222324252627#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# 如果数据表已经存在使用 execute() 方法删除表。cursor.execute(\"DROP TABLE IF EXISTS EMPLOYEE\")# 创建数据表SQL语句sql = \"\"\"CREATE TABLE EMPLOYEE ( FIRST_NAME CHAR(20) NOT NULL, LAST_NAME CHAR(20), AGE INT, SEX CHAR(1), INCOME FLOAT )\"\"\"cursor.execute(sql)# 关闭数据库连接db.close() 5、数据库插入操作 以下实例使用执行 SQL INSERT 语句向表 EMPLOYEE 插入记录 123456789101112131415161718192021222324252627#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 插入语句sql = \"\"\"INSERT INTO EMPLOYEE(FIRST_NAME, LAST_NAME, AGE, SEX, INCOME) VALUES ('Mac', 'Mohan', 20, 'M', 2000)\"\"\"try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # Rollback in case there is any error db.rollback()# 关闭数据库连接db.close() 以上例子也可以写成如下形式： 12345678910111213141516171819202122232425262728#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 插入语句sql = \"INSERT INTO EMPLOYEE(FIRST_NAME, \\ LAST_NAME, AGE, SEX, INCOME) \\ VALUES (%s, %s, %s, %s, %s )\" % \\ ('Mac', 'Mohan', 20, 'M', 2000)try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # 发生错误时回滚 db.rollback()# 关闭数据库连接db.close() 6、数据库查询操作 Python查询Mysql使用 fetchone() 方法获取单条数据, 使用fetchall() 方法获取多条数据。 fetchone(): 该方法获取下一个查询结果集。结果集是一个对象 fetchall():接收全部的返回结果行. rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。 实例： 查询EMPLOYEE表中salary（工资）字段大于1000的所有数据： 12345678910111213141516171819202122232425262728293031323334#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标cursor = db.cursor()# SQL 查询语句sql = \"SELECT * FROM EMPLOYEE \\ WHERE INCOME &gt; %s\" % (1000)try: # 执行SQL语句 cursor.execute(sql) # 获取所有记录列表 results = cursor.fetchall() for row in results: fname = row[0] lname = row[1] age = row[2] sex = row[3] income = row[4] # 打印结果 print(\"fname=%s,lname=%s,age=%s,sex=%s,income=%s\" % \\ (fname, lname, age, sex, income ))except: print(\"Error: unable to fecth data\")# 关闭数据库连接db.close() 以上脚本执行结果如下： 1fname=Mac,lname=Mohan,age=20,sex=M,income=2000.0 7、数据库更新操作 更新操作用于更新数据表的的数据，以下实例将 EMPLOYEE 表中的 SEX 字段为 ‘M’ 的 AGE 字段递增 1： 12345678910111213141516171819202122232425#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 更新语句sql = \"UPDATE EMPLOYEE SET AGE = AGE + 1 WHERE SEX = '%c'\" % ('M')try: # 执行SQL语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # 发生错误时回滚 db.rollback()# 关闭数据库连接db.close() 8、删除操作 删除操作用于删除数据表中的数据，以下实例演示了删除数据表 EMPLOYEE 中 AGE 大于 20 的所有数据： 12345678910111213141516171819202122232425#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 删除语句sql = \"DELETE FROM EMPLOYEE WHERE AGE &gt; %s\" % (20)try: # 执行SQL语句 cursor.execute(sql) # 提交修改 db.commit()except: # 发生错误时回滚 db.rollback()# 关闭连接db.close() 9、执行事务 事务机制可以确保数据一致性。 事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。 原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。 一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。 Python DB API 2.0 的事务提供了两个方法 commit 或 rollback。 实例： 12345678910# SQL删除记录语句sql = \"DELETE FROM EMPLOYEE WHERE AGE &gt; %s\" % (20)try: # 执行SQL语句 cursor.execute(sql) # 向数据库提交 db.commit()except: # 发生错误时回滚 db.rollback() 对于支持事务的数据库， 在Python数据库编程中，当游标建立之时，就自动开始了一个隐形的数据库事务。 commit()方法游标的所有更新操作，rollback（）方法回滚当前游标的所有操作。每一个方法都开始了一个新的事务。 10、错误处理 DB API中定义了一些数据库操作的错误及异常，下表列出了这些错误和异常: 异常 描述 Warning 当有严重警告时触发，例如插入数据是被截断等等。必须是 StandardError 的子类。 Error 警告以外所有其他错误类。必须是 StandardError 的子类。 InterfaceError 当有数据库接口模块本身的错误（而不是数据库的错误）发生时触发。 必须是Error的子类。 DatabaseError 和数据库有关的错误发生时触发。 必须是Error的子类。 DataError 当有数据处理时的错误发生时触发，例如：除零错误，数据超范围等等。 必须是DatabaseError的子类。 OperationalError 指非用户控制的，而是操作数据库时发生的错误。例如：连接意外断开、 数据库名未找到、事务处理失败、内存分配错误等等操作数据库是发生的错误。 必须是DatabaseError的子类。 IntegrityError 完整性相关的错误，例如外键检查失败等。必须是DatabaseError子类。 InternalError 数据库的内部错误，例如游标（cursor）失效了、事务同步失败等等。 必须是DatabaseError子类。 ProgrammingError 程序错误，例如数据表（table）没找到或已存在、SQL语句语法错误、 参数数量错误等等。必须是DatabaseError的子类。 NotSupportedError 不支持错误，指使用了数据库不支持的函数或API等。例如在连接对象上 使用.rollback()函数，然而数据库并不支持事务或者事务已关闭。 必须是DatabaseError的子类。","path":"posts/26aa.html","date":"10-29","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python中的上下文管理器","text":"python with语句上下文管理的两种实现方法 在编程中会经常碰到这种情况：有一个特殊的语句块，在执行这个语句块之前需要先执行一些准备动作；当语句块执行完成后，需要继续执行一些收尾动作。例如，文件读写后需要关闭，数据库读写完毕需要关闭连接，资源的加锁和解锁等情况。 对于这种情况python提供了上下文管理器（Context Manager）的概念，可以通过上下文管理器来定义/控制代码块执行前的准备动作，以及执行后的收尾动作。 上下文管理器 with语句:可以确保某些事情(如关闭资源、释放锁)一定会发生。 先创建一个t.txt文件，里面随便写点东西 然后编写代码 12345678try: f = open('t.txt') print(f.read())finally: f.close()with open('t.txt') as f: print(f.read()) 输出结果 12fewfwefweweffewfwefwewef 一、为何使用上下文管理器 在我看来，这和 Python 崇尚的优雅风格有关。 可以以一种更加优雅的方式，操作（创建/获取/释放）资源，如文件操作、数据库连接； 可以以一种更加优雅的方式，处理异常； 第一种，我们上面已经以资源的连接为例讲过了。 而第二种，会被大多数人所忽略。这里会重点讲一下。 大家都知道，处理异常，通常都是使用 try...execept.. 来捕获处理的。这样做一个不好的地方是，在代码的主逻辑里，会有大量的异常处理代理，这会很大的影响我们的可读性。 好一点的做法呢，可以使用 with 将异常的处理隐藏起来。 1、不使用上下文管理器的情况 通过try…finally语句执行异常处理和关闭句柄的动作。 12345678logger = open(\"t.txt\", \"w\")try: logger.write('Hello ') logger.write('World')finally: logger.close()print(logger.closed) 2、使用上下文管理器 默认文件Python的内置file类型是支持上下文管理协议的。 使用上下文管理器with使得依据精简了很多。 12345with open(\"t.txt\", \"w\") as logger: logger.write('Hello ') logger.write('World')print(logger.closed) 或 1234567891011121314151617# coding=utf-8import codecsclass Open(object): def __init__(self, filename, mode, encoding='utf-8'): self.fp = codecs.open(filename, mode, encoding) def __enter__(self): return self.fp def __exit__(self, exc_type, exc_val, exc_tb): self.fp.close()data = u'Hello World'with Open('t.txt','w') as f: f.write(data) 以上三种方法都会在t.txt中写入Hello World数据。 二、实现上下文管理器 实现上下文管理器有两种方式实现。 方法一：类实现enter和exit方法。 方法二：contextlib模块装饰器和生成器实现。 下面我们通过两种方法分别实现一个自定义的上下文管理器。 1、方法一：通过类实现__enter__和__exit__方法 12345678910class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, type, value, traceback): self.file_obj.close()with File('t.txt', 'w') as opened_file: opened_file.write('Hola!') 以上这种方法会在t.txt中写入Hola!数据。 实现__enter__和__exit__方法后，就能通过with语句进行上下文管理。 a、底层都发生了什么？ 1231、with语句先暂存了File类的__exit__方法，然后它调用File类的__enter__方法。2、__enter__方法打开文件并返回给with语句，打开的文件句柄被传递给opened_file参数。3、with语句调用之前暂存的__exit__方法，__exit__方法关闭了文件。 b、异常处理 12345关于异常处理，with语句会采取哪些步骤。1. 它把异常的type,value和traceback传递给__exit__方法2. 它让__exit__方法来处理异常 3. 如果__exit__返回的是True，那么这个异常就被忽略。4. 如果__exit__返回的是True以外的任何东西，那么这个异常将被with语句抛出。 （1）异常抛出 123456789101112131415#异常抛出，_exit__返回的是True以外的任何东西，那么这个异常将被with语句抛出class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, type, value, traceback): self.file_obj.close() print(\"type:\",type) print(\"value:\",value) print(\"traceback:\",traceback)with File('t.txt', 'w') as opened_file: opened_file.undefined_function('Hola!') 输出结果 1234567type: &lt;class 'AttributeError'&gt;value: '_io.TextIOWrapper' object has no attribute 'undefined_function'traceback: &lt;traceback object at 0x000001BEB1AD7F00&gt;Traceback (most recent call last): File \"G:/四期/python/Pytghon_MySQL/上下文管理器/666.py\", line 15, in &lt;module&gt; opened_file.undefined_function('Hola!')AttributeError: '_io.TextIOWrapper' object has no attribute 'undefined_function' （2）异常忽略： 12345678910111213141516# 异常忽略，__exit__返回的是True，那么这个异常就被忽略。class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, exception_type, exception_value, traceback): print(\"Exception has been handled\") self.file_obj.close() return Truewith File('t.txt', 'w') as opened_file: opened_file.undefined_function('Hola!') 输出结果 1Exception has been handled 2、方法二：contextlib模块装饰器和生成器实现 这种方式实现更优雅，我个人更喜欢这种方式。 yield之前的代码由__enter__方法执行，yield之后的代码由__exit__方法执行。本质上还是__enter__和__exit__方法。 1234567891011121314# coding=utf-8import codecsfrom contextlib import contextmanager@contextmanagerdef Open(filename,mode,encoding='utf-8'): fp = codecs.open(filename,mode,encoding) try: yield fp finally: fp.close()data = u'上下文--管理器'with Open('t.txt','w') as f: f.write(data) 以上这种方法会在t.txt中写入上下文--管理器数据。 或 12345678910111213141516171819202122from contextlib import closingclass OpenMyFile(object): def __init__(self, path): print(\"opening the txt\") self.f = open(path, \"w\") def write(self, string): self.f.write(string) def close(self): print(\"closing the txt\") self.f.close()with closing(OpenMyFile(\"t.txt\")) as file: file.write(\"this is demo4\")# 输出：print(\"opening the txt\")print(\"closing the txt\") 以上这种方法会在t.txt中写入this is demo4数据。 输出结果 1234opening the txtclosing the txtopening the txtclosing the txt 3、方法三（@contextmanager） 利用contextlib中的contextmanager装饰器。 123456789101112131415161718from contextlib import contextmanager@contextmanagerdef open_my_file(path): print(\"opening the txt\") f = open(\"t.txt\", \"w\") yield f print(\"closing the txt\") f.close()with open_my_file(\"t.txt\") as file: file.write(\"this is demo3\")# 输出：print(\"opening the txt\")print(\"closing the txt\") 以上这种方法会在t.txt中写入this is demo3数据。 输出结果 1234opening the txtclosing the txtopening the txtclosing the txt 4、with语句上多个下文关联 直接通过一个with语句打开多个上下文，即可同时使用多个上下文变量，而不必需嵌套使用with语句。 1234567891011121314class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, exception_type, exception_value, traceback): self.file_obj.close() return Truewith File('t.txt', 'w') as f1, File('t.txt', 'w') as f2: print(f1, f2) 输出结果 1&lt;_io.TextIOWrapper name='t.txt' mode='w' encoding='cp936'&gt; &lt;_io.TextIOWrapper name='t.txt' mode='w' encoding='cp936'&gt; 总结 本文介绍了Python中的上下文管理器，以及如何结合with语句来使用上下文管理器。 总结一下with 语句的执行流程： 执行context_expr 以获取上下文管理器对象 调用上下文管理器的 enter() 方法 如果有 as var 从句，则将 enter() 方法的返回值赋给 var 执行代码块 with_suite 调用上下文管理器的 exit() 方法，如果 with_suite 产生异常，那么该异常的 type、value 和 traceback 会作为参数传给 exit()，否则传三个 None 如果 with_suite 产生异常，并且 exit() 的返回值等于 False，那么这个异常将被重新抛出到上层 如果 with_suite 产生异常，兵器 exit() 的返回值等于 True，那么这个异常就被忽略，继续执行后面的代码 在很多情况下，with语句可以简化代码，并增加代码的健壮性。 使用上下文管理器有三个好处： 提高代码的复用率； 提高代码的优雅度； 提高代码的可读性； With 语句的实际执行流程是这样的： 执行 context_exp 以获取上下文管理器 加载上下文管理器的 __exit__() 方法以备稍后调用 调用上下文管理器的 __enter__() 方法 如果有 as var 从句，则将 __enter__() 方法的返回值赋给 var 执行子代码块 with_suit 调用上下文管理器的 __exit__() 方法，如果 with_suit 的退出是由异常引发的，那么该异常的 type、value 和 traceback 会作为参数传给 __exit__()，否则传三个 None 如果 with_suit 的退出由异常引发，并且 __exit__() 的返回值等于 False，那么这个异常将被重新引发一次；如果 __exit__() 的返回值等于 True，那么这个异常就被无视掉，继续执行后面的代码","path":"posts/7aea.html","date":"10-28","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python装饰器的应用场景","text":"装饰器用于身份认证 首先是最常见的身份认证的应用。这个很容易理解，举个最常见的例子，大家登录微信，需要输入用户名密码，然后点击确认，这样服务器端便会查询你的用户名是否存在、是否和密码匹配等等。如果认证通过，就可以顺利登录；反之，则提示你登录失败。 再比如一些网站，你不登录也可以浏览内容，但如果你想要发布文章或留言，在点击发布时，服务器端便会查询你是否登录。如果没有登录，就不允许这项操作等等。 如下是一个实现身份认证的简单示例： 12345678910111213141516import functoolsdef authenticate(func): @functools.wraps(func) def wrapper(*args, **kwargs): request = args[0] # 如果用户处于登录状态 if check_user_logged_in(request): # 执行函数 post_comment() return func(*args, **kwargs) else: raise Exception('Authentication failed') return wrapper @authenticatedef post_comment(request, ...) ... 注意，对于函数来说，它也有自己的一些属性，例如 name 属性，代码中 @functools.wraps(func) 也是一个装饰器，如果不使用它，则 post_comment.name 的值为 wrapper。而使用它之后，则 post_comment.name 的值依然为 post_comment。 上面这段代码中，定义了装饰器 authenticate，函数 post_comment() 则表示发表用户对某篇文章的评论，每次调用这个函数前，都会先检查用户是否处于登录状态，如果是登录状态，则允许这项操作；如果没有登录，则不允许。 装饰器用于日志记录 日志记录同样是很常见的一个案例。在实际工作中，如果你怀疑某些函数的耗时过长，导致整个系统的延迟增加，想在线上测试某些函数的执行时间，那么，装饰器就是一种很常用的手段。 我们通常用下面的方法来表示： 123456789101112131415import timeimport functoolsdef log_execution_time(func): @functools.wraps(func) def wrapper(*args, **kwargs): start = time.perf_counter() res = func(*args, **kwargs) end = time.perf_counter() print('&#123;&#125; took &#123;&#125; ms'.format(func.__name__, (end - start) * 1000)) return res return wrapper @log_execution_timedef calculate_similarity(items): ... 这里，装饰器 log_execution_time 记录某个函数的运行时间，并返回其执行结果。如果你想计算任何函数的执行时间，在这个函数上方加上@log_execution_time即可。 装饰器用于输入合理性检查 在大型公司的机器学习框架中，调用机器集群进行模型训练前，往往会用装饰器对其输入（往往是很长的 json 文件）进行合理性检查。这样就可以大大避免输入不正确对机器造成的巨大开销。 它的写法往往是下面的格式： 123456789import functoolsdef validation_check(input): @functools.wraps(func) def wrapper(*args, **kwargs): ... # 检查输入是否合法 @validation_checkdef neural_network_training(param1, param2, ...): ... 其实在工作中，很多情况下都会出现输入不合理的现象。因为我们调用的训练模型往往很复杂，输入的文件有成千上万行，很多时候确实也很难发现。 试想一下，如果没有输入的合理性检查，很容易出现“模型训练了好几个小时后，系统却报错说输入的一个参数不对，成果付之一炬”的现象。这样的“惨案”，大大减缓了开发效率，也对机器资源造成了巨大浪费。 缓存装饰器 关于缓存装饰器的用法，其实十分常见，这里以 Python 内置的 LRU cache 为例来说明。 LRU cache，在 Python 中的表示形式是 @lru_cache。@lru_cache 会缓存进程中的函数参数和结果，当缓存满了以后，会删除最近最久未使用的数据。 正确使用缓存装饰器，往往能极大地提高程序运行效率。举个例子，大型公司服务器端的代码中往往存在很多关于设备的检查，比如使用的设备是安卓还是 iPhone，版本号是多少。这其中的一个原因，就是一些新的功能，往往只在某些特定的手机系统或版本上才有（比如 Android v200+）。 这样一来，我们通常使用缓存装饰器来包裹这些检查函数，避免其被反复调用，进而提高程序运行效率，比如写成下面这样： 123@lru_cachedef check(param1, param2, ...) # 检查用户设备类型，版本号等等 ...","path":"posts/1351.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python的装饰器（3）","text":"Python @函数装饰器及用法（超级详细） 前面章节中，我们已经讲解了 Python 内置的 3 种函数装饰器，分别是 ＠staticmethod、＠classmethod 和 @property，其中 staticmethod()、classmethod() 和 property() 都是 Python 的内置函数。 那么，函数装饰器的工作原理是怎样的呢？假设用 funA() 函数装饰器去装饰 funB() 函数，如下所示： 123456789#funA 作为装饰器函数def funA(fn): #... fn() # 执行传入的fn参数 #... return '...'@funAdef funB(): #... 实际上，上面程序完全等价于下面的程序： 12345678def funA(fn): #... fn() # 执行传入的fn参数 #... return '...'def funB(): #...funB = funA(funB) 通过比对以上 2 段程序不难发现，使用函数装饰器 A() 去装饰另一个函数 B()，其底层执行了如下 2 步操作： 将 B 作为参数传给 A() 函数； 将 A() 函数执行完成的返回值反馈回 B。 举个实例： 123456789#funA 作为装饰器函数def funA(fn): print(\"xgp的博客\") fn() # 执行传入的fn参数 print(\"https://wsdlxgp.top/\") return \"装饰器函数的返回值\"@funAdef funB(): print(\"学习 Python\") 程序执行流程为： 123xgp的博客学习 Pythonhttps://wsdlxgp.top/ 在此基础上，如果在程序末尾添加如下语句： 1print(funB) 其输出结果为： 1装饰器函数的返回值 显然，被“＠函数”修饰的函数不再是原来的函数，而是被替换成一个新的东西（取决于装饰器的返回值），即如果装饰器函数的返回值为普通变量，那么被修饰的函数名就变成了变量名；同样，如果装饰器返回的是一个函数的名称，怎么被修饰的函数名依然表示一个函数。 实际上，所谓函数装饰器，就是通过装饰器函数，在不修改原函数的前提下，来对函数的功能进行合理的扩充。 1、带参数的函数装饰器 在分析 funA() 函数装饰器和 funB() 函数的关系时，细心的读者可能会发现一个问题，即当 funB() 函数无参数时，可以直接将 funB 作为 funA() 的参数传入。但是，如果被修饰的函数本身带有参数，那应该如何传值呢？ 比较简单的解决方法就是在函数装饰器中嵌套一个函数，该函数带有的参数个数和被装饰器修饰的函数相同。例如： 123456789def funA(fn): # 定义一个嵌套函数 def say(arc): print(\"kubernetes教程:\",arc) return say@funAdef funB(arc): print(\"funB():\", a)funB(\"https://wsdlxgp.top/categories/Kubernetes/\") 程序执行结果为： 1kubernetes教程: https://wsdlxgp.top/categories/Kubernetes/ 这里有必要给读者分析一下这个程序，其实，它和如下程序是等价的： 12345678910def funA(fn): # 定义一个嵌套函数 def say(arc): print(\"kubernetes教程:\",arc) return saydef funB(arc): print(\"funB():\", a) funB = funA(funB)funB(\"https://wsdlxgp.top/categories/Kubernetes/\") 如果运行此程序会发现，它的输出结果和上面程序相同。 显然，通过 funB() 函数被装饰器 funA() 修饰，funB 就被赋值为 say。这意味着，虽然我们在程序显式调用的是 funB() 函数，但其实执行的是装饰器嵌套的 say() 函数。 但还有一个问题需要解决，即如果当前程序中，有多个（≥ 2）函数被同一个装饰器函数修饰，这些函数带有的参数个数并不相等，怎么办呢？ 最简单的解决方式是用*args 和 **kwargs 作为装饰器内部嵌套函数的参数，*args 和 **kwargs 表示接受任意数量和类型的参数。举个例子： 12345678910111213def funA(fn): # 定义一个嵌套函数 def say(*args,**kwargs): fn(*args,**kwargs) return say@funAdef funB(arc): print(\"xgp的博客：\",arc)@funAdef other_funB(name,arc): print(name,arc)funB(\"https://wsdlxgp.top/\")other_funB(\"kubernetes教程：\",\"https://wsdlxgp.top/categories/Kubernetes/\") 运行结果为： 12xgp的博客： https://wsdlxgp.top/kubernetes教程： https://wsdlxgp.top/categories/Kubernetes/ 2、函数装饰器可以嵌套 上面示例中，都是使用一个装饰器的情况，但实际上，Python 也支持多个装饰器，比如： 12345@funA@funB@funCdef fun(): #... 上面程序的执行顺序是里到外，所以它等效于下面这行代码： 1fun = funA( funB ( funC (fun) ) ) 这里不再给出具体实例，有兴趣的读者可自行编写程序进行测试。","path":"posts/1341.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python的装饰器（2）","text":"Python 函数装饰器 装饰器(Decorators)是 Python 的一个重要部分。简单地说：他们是修改其他函数的功能的函数。他们有助于让我们的代码更简短，也更Pythonic（Python范儿）。大多数初学者不知道在哪儿使用它们，所以我将要分享下，哪些区域里装饰器可以让你的代码更简洁。 首先，让我们讨论下如何写你自己的装饰器。 这可能是最难掌握的概念之一。我们会每次只讨论一个步骤，这样你能完全理解它。 1、一切皆对象 首先我们来理解下 Python 中的函数: 123456789101112131415161718192021def hi(name=\"yasoob\"): return \"hi \" + name print(hi())# output: 'hi yasoob' # 我们甚至可以将一个函数赋值给一个变量，比如greet = hi# 我们这里没有在使用小括号，因为我们并不是在调用hi函数# 而是在将它放在greet变量里头。我们尝试运行下这个 print(greet())# output: 'hi yasoob' # 如果我们删掉旧的hi函数，看看会发生什么！del hiprint(hi())#outputs: NameError print(greet())#outputs: 'hi yasoob' 2、在函数中定义函数 刚才那些就是函数的基本知识了。我们来让你的知识更进一步。在 Python 中我们可以在一个函数中定义另一个函数： 123456789101112131415161718192021222324def hi(name=\"yasoob\"): print(\"now you are inside the hi() function\") def greet(): return \"now you are in the greet() function\" def welcome(): return \"now you are in the welcome() function\" print(greet()) print(welcome()) print(\"now you are back in the hi() function\") hi()#output:now you are inside the hi() function# now you are in the greet() function# now you are in the welcome() function# now you are back in the hi() function # 上面展示了无论何时你调用hi(), greet()和welcome()将会同时被调用。# 然后greet()和welcome()函数在hi()函数之外是不能访问的，比如： greet()#outputs: NameError: name 'greet' is not defined 那现在我们知道了可以在函数中定义另外的函数。也就是说：我们可以创建嵌套的函数。现在你需要再多学一点，就是函数也能返回函数。 3、从函数中返回函数 其实并不需要在一个函数里去执行另一个函数，我们也可以将其作为输出返回出来： 123456789101112131415161718192021def hi(name=\"yasoob\"): def greet(): return \"now you are in the greet() function\" def welcome(): return \"now you are in the welcome() function\" if name == \"yasoob\": return greet else: return welcome a = hi()print(a)#outputs: &lt;function greet at 0x7f2143c01500&gt; #上面清晰地展示了`a`现在指向到hi()函数中的greet()函数#现在试试这个 print(a())#outputs: now you are in the greet() function 再次看看这个代码。在 if/else 语句中我们返回 greet 和 welcome，而不是 greet() 和 welcome()。为什么那样？这是因为当你把一对小括号放在后面，这个函数就会执行；然而如果你不放括号在它后面，那它可以被到处传递，并且可以赋值给别的变量而不去执行它。 你明白了吗？让我再稍微多解释点细节。 当我们写下 a = hi()，hi() 会被执行，而由于 name 参数默认是 yasoob，所以函数 greet 被返回了。如果我们把语句改为 a = hi(name = &quot;ali&quot;)，那么 welcome 函数将被返回。我们还可以打印出 hi()()，这会输出 now you are in the greet() function。 4、将函数作为参数传给另一个函数 12345678910def hi(): return \"hi yasoob!\" def doSomethingBeforeHi(func): print(\"I am doing some boring work before executing hi()\") print(func()) doSomethingBeforeHi(hi)#outputs:I am doing some boring work before executing hi()# hi yasoob! 现在你已经具备所有必需知识，来进一步学习装饰器真正是什么了。装饰器让你在一个函数的前后去执行代码。 5、你的第一个装饰器 在上一个例子里，其实我们已经创建了一个装饰器！现在我们修改下上一个装饰器，并编写一个稍微更有用点的程序： 123456789101112131415161718192021222324def a_new_decorator(a_func): def wrapTheFunction(): print(\"I am doing some boring work before executing a_func()\") a_func() print(\"I am doing some boring work after executing a_func()\") return wrapTheFunction def a_function_requiring_decoration(): print(\"I am the function which needs some decoration to remove my foul smell\") a_function_requiring_decoration()#outputs: \"I am the function which needs some decoration to remove my foul smell\" a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration)#now a_function_requiring_decoration is wrapped by wrapTheFunction() a_function_requiring_decoration()#outputs:I am doing some boring work before executing a_func()# I am the function which needs some decoration to remove my foul smell# I am doing some boring work after executing a_func() 你看明白了吗？我们刚刚应用了之前学习到的原理。这正是 python 中装饰器做的事情！它们封装一个函数，并且用这样或者那样的方式来修改它的行为。现在你也许疑惑，我们在代码里并没有使用 @ 符号？那只是一个简短的方式来生成一个被装饰的函数。这里是我们如何使用 @ 来运行之前的代码： 12345678910111213@a_new_decoratordef a_function_requiring_decoration(): \"\"\"Hey you! Decorate me!\"\"\" print(\"I am the function which needs some decoration to \" \"remove my foul smell\") a_function_requiring_decoration()#outputs: I am doing some boring work before executing a_func()# I am the function which needs some decoration to remove my foul smell# I am doing some boring work after executing a_func() #the @a_new_decorator is just a short way of saying:a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration) 希望你现在对 Python 装饰器的工作原理有一个基本的理解。如果我们运行如下代码会存在一个问题： 12print(a_function_requiring_decoration.__name__)# Output: wrapTheFunction 这并不是我们想要的！Ouput输出应该是&quot;a_function_requiring_decoration&quot;。这里的函数被warpTheFunction替代了。它重写了我们函数的名字和注释文档(docstring)。幸运的是Python提供给我们一个简单的函数来解决这个问题，那就是functools.wraps。我们修改上一个例子来使用functools.wraps： 123456789101112131415161718from functools import wraps def a_new_decorator(a_func): @wraps(a_func) def wrapTheFunction(): print(\"I am doing some boring work before executing a_func()\") a_func() print(\"I am doing some boring work after executing a_func()\") return wrapTheFunction @a_new_decoratordef a_function_requiring_decoration(): \"\"\"Hey yo! Decorate me!\"\"\" print(\"I am the function which needs some decoration to \" \"remove my foul smell\") print(a_function_requiring_decoration.__name__)# Output: a_function_requiring_decoration 现在好多了。我们接下来学习装饰器的一些常用场景。 蓝本规范: 1234567891011121314151617181920from functools import wrapsdef decorator_name(f): @wraps(f) def decorated(*args, **kwargs): if not can_run: return \"Function will not run\" return f(*args, **kwargs) return decorated @decorator_namedef func(): return(\"Function is running\") can_run = Trueprint(func())# Output: Function is running can_run = Falseprint(func())# Output: Function will not run 注意：@wraps接受一个函数来进行装饰，并加入了复制函数名称、注释文档、参数列表等等的功能。这可以让我们在装饰器里面访问在装饰之前的函数的属性。 使用场景 现在我们来看一下装饰器在哪些地方特别耀眼，以及使用它可以让一些事情管理起来变得更简单。 1、授权(Authorization) 装饰器能有助于检查某个人是否被授权去使用一个web应用的端点(endpoint)。它们被大量使用于Flask和Django web框架中。这里是一个例子来使用基于装饰器的授权： 12345678910from functools import wraps def requires_auth(f): @wraps(f) def decorated(*args, **kwargs): auth = request.authorization if not auth or not check_auth(auth.username, auth.password): authenticate() return f(*args, **kwargs) return decorated 2日志(Logging) 日志是装饰器运用的另一个亮点。这是个例子： 1234567891011121314151617from functools import wraps def logit(func): @wraps(func) def with_logging(*args, **kwargs): print(func.__name__ + \" was called\") return func(*args, **kwargs) return with_logging @logitdef addition_func(x): \"\"\"Do some math.\"\"\" return x + x result = addition_func(4)# Output: addition_func was called 我敢肯定你已经在思考装饰器的一个其他聪明用法了。 带参数的装饰器 来想想这个问题，难道@wraps不也是个装饰器吗？但是，它接收一个参数，就像任何普通的函数能做的那样。那么，为什么我们不也那样做呢？ 这是因为，当你使用@my_decorator语法时，你是在应用一个以单个函数作为参数的一个包裹函数。记住，Python里每个东西都是一个对象，而且这包括函数！记住了这些，我们可以编写一下能返回一个包裹函数的函数。 1、在函数中嵌入装饰器 我们回到日志的例子，并创建一个包裹函数，能让我们指定一个用于输出的日志文件。 12345678910111213141516171819202122232425262728293031from functools import wraps def logit(logfile='out.log'): def logging_decorator(func): @wraps(func) def wrapped_function(*args, **kwargs): log_string = func.__name__ + \" was called\" print(log_string) # 打开logfile，并写入内容 with open(logfile, 'a') as opened_file: # 现在将日志打到指定的logfile opened_file.write(log_string + '\\n') return func(*args, **kwargs) return wrapped_function return logging_decorator @logit()def myfunc1(): pass myfunc1()# Output: myfunc1 was called# 现在一个叫做 out.log 的文件出现了，里面的内容就是上面的字符串 @logit(logfile='func2.log')def myfunc2(): pass myfunc2()# Output: myfunc2 was called# 现在一个叫做 func2.log 的文件出现了，里面的内容就是上面的字符串 装饰器类 现在我们有了能用于正式环境的logit装饰器，但当我们的应用的某些部分还比较脆弱时，异常也许是需要更紧急关注的事情。比方说有时你只想打日志到一个文件。而有时你想把引起你注意的问题发送到一个email，同时也保留日志，留个记录。这是一个使用继承的场景，但目前为止我们只看到过用来构建装饰器的函数。 幸运的是，类也可以用来构建装饰器。那我们现在以一个类而不是一个函数的方式，来重新构建logit。 1234567891011121314151617181920212223from functools import wraps class logit(object): def __init__(self, logfile='out.log'): self.logfile = logfile def __call__(self, func): @wraps(func) def wrapped_function(*args, **kwargs): log_string = func.__name__ + \" was called\" print(log_string) # 打开logfile并写入 with open(self.logfile, 'a') as opened_file: # 现在将日志打到指定的文件 opened_file.write(log_string + '\\n') # 现在，发送一个通知 self.notify() return func(*args, **kwargs) return wrapped_function def notify(self): # logit只打日志，不做别的 pass 这个实现有一个附加优势，在于比嵌套函数的方式更加整洁，而且包裹一个函数还是使用跟以前一样的语法： 123@logit()def myfunc1(): pass 现在，我们给 logit 创建子类，来添加 email 的功能(虽然 email 这个话题不会在这里展开)。 123456789101112class email_logit(logit): ''' 一个logit的实现版本，可以在函数调用时发送email给管理员 ''' def __init__(self, email='admin@myproject.com', *args, **kwargs): self.email = email super(email_logit, self).__init__(*args, **kwargs) def notify(self): # 发送一封email到self.email # 这里就不做实现了 pass 从现在起，@email_logit 将会和 @logit 产生同样的效果，但是在打日志的基础上，还会多发送一封邮件给管理员。 1原文地址：https://eastlakeside.gitbooks.io/interpy-zh/content/decorators/","path":"posts/1339.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python的装饰器（1）","text":"一、Python 函数装饰器 是修改函数的一种快捷方式 是代码的编写更加便利和灵活 能够提高代码的可读性和可维护性 本质上是一个函数， 这个函数接受其他函数作为参数， 并将其以一个新的修改后的函数进行替换 12345def say_hi(): print('Hi')hello = say_hihello() 输出结果 1Hi 实例一 12345678910111213#coding=utf-8import randomn = random.randint(1,5)if n % 2 == 0: def display(n): print('&#123;0&#125;是一个偶数。'.format(n))else: def display(n): print('&#123;0&#125;是一个奇数。'.format(n))display(n) 多次执行才可见如下效果 123451是一个奇数。3是一个奇数。5是一个奇数。2是一个偶数。4是一个偶数。 实例二 函数里面嵌套函数 12345678#coding=utf-8def outer(x, y): def inner(): return x + y return innerf = outer(1,2)print(f()) 输出结果 13 1、装饰器底层原理 （1）简单的 12345678910111213141516#coding=utf-8def greeting(f): f()def say_hi(): print('Hi')def say_hello(): print('Hello')greeting(say_hi)greeting(say_hello) 输出结果 12HiHello （2）复杂的 12345678910111213141516171819# coding=utf-8def say_hi(): print('Hi')def bread(f): def wrapper(*args, **kwargs): print('开始调用&#123;0&#125;。'.format(f.__name__)) f() print('完成&#123;0&#125;的调用。'.format(f.__name__)) return wrapper@breaddef say_hi(): print('Hi')say_hi_copy = bread(say_hi)say_hi_copy() 输出结果 12345开始调用wrapper。开始调用say_hi。Hi完成say_hi的调用。完成wrapper的调用。 第二种方法 12345678910111213141516#coding=utf-8def bread(f): def wrapper(*args, **kwargs): print('开始调用&#123;0&#125;。'.format(f.__name__)) f() print('完成&#123;0&#125;的调用。'.format(f.__name__)) return wrapper@breaddef say_hi(): print('Hi')say_hi() 输出结果 123开始调用say_hi。Hi完成say_hi的调用。 小练习（授权） 假定我们现在有一个特殊栈 这个栈不但实现了先进后出的数据结构， 还会检查操作栈的用户是否具有相应的授权 只有管理员才能够进行栈的操作 方法一 1234567891011121314151617181920212223242526272829303132# coding=utf-8def check_is_admin(f): def wrapper(*args, **kwargs): if kwargs.get('username') != 'admin': raise Exception('你没有权限进行此项操作。') return f(*args, **kwargs) return wrapperclass Stack: def __init__(self): self.storage = [] @check_is_admin def put(self, username, elem): # check_is_admin(username=username) self.storage.append(elem) @check_is_admin def get(self, username): # check_is_admin(username=username) if not self.storage: raise Exception('栈里没有数据。') return self.storage.pop()stack = Stack()stack.put(username='admin', elem=3)print(stack.get(username='admin')) 输出结果 13 方法二 123456789101112131415161718# coding=utf-8import timedef benchmark(func): def wrapper(*args,**kwargs): # 获取当前时间 t = time.time() res = func(*args,**kwargs) print(func.__name__,time.time() - t) return res return wrapper@benchmarkdef add(a,b): time.sleep(1) return a + bprint(add(1,2)) 输出结果 12add 1.00126099586486823","path":"posts/1338.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python中生成器和迭代器的区别","text":"Python中生成器和迭代器的区别(代码在Python3.5下测试)： 1、Num01–&gt;迭代器 定义： 对于list、string、tuple、dict等这些容器对象,使用for循环遍历是很方便的。在后台for语句对容器对象调用iter()函数。iter()是python内置函数。 iter()函数会返回一个定义了next()方法的迭代器对象，它在容器中逐个访问容器内的元素。next()也是python内置函数。在没有后续元素时，next()会抛出一个StopIteration异常，通知for语句循环结束。 迭代器是用来帮助我们记录每次迭代访问到的位置，当我们对迭代器使用next()函数的时候，迭代器会向我们返回它所记录位置的下一个位置的数据。实际上，在使用next()函数的时候，调用的就是迭代器对象的_next_方法（Python3中是对象的_next_方法，Python2中是对象的next()方法）。所以，我们要想构造一个迭代器，就要实现它的_next_方法。但这还不够，python要求迭代器本身也是可迭代的，所以我们还要为迭代器实现_iter_方法，而_iter_方法要返回一个迭代器，迭代器自身正是一个迭代器，所以迭代器的_iter_方法返回自身self即可。 一些术语的解释： 1，迭代器协议：对象需要提供next()方法，它要么返回迭代中的下一项，要么就引起一个StopIteration异常，以终止迭代。 2，可迭代对象：实现了迭代器协议对象。list、tuple、dict都是Iterable（可迭代对象），但不是Iterator（迭代器对象）。但可以使用内建函数iter()，把这些都变成Iterable（可迭代器对象）。 3，for item in Iterable 循环的本质就是先通过iter()函数获取可迭代对象Iterable的迭代器，然后对获取到的迭代器不断调用next()方法来获取下一个值并将其赋值给item，当遇到StopIteration的异常后循环结束 Python自带容器对象案例： 123456789101112131415161718# 随便定义一个listlistArray=[1,2,3]# 使用iter()函数iterName=iter(listArray)print(iterName)# 结果如下：是一个列表list的迭代器# &lt;list_iterator object at 0x0000017B0D984278&gt;print(next(iterName))print(next(iterName))print(next(iterName))print(next(iterName))#没有迭代到下一个元素，直接抛出异常# 1# 2# 3# Traceback (most recent call last):# File \"Test07.py\", line 32, in &lt;module&gt;# StopIteration Python中一个实现了**_iter_方法和_next_**方法的类对象，就是迭代器，如下案例是计算菲波那切数列的案例 123456789101112131415161718192021222324252627class Fib(object): def __init__(self, max): super(Fib, self).__init__() self.max = max def __iter__(self): self.a = 0 self.b = 1 return self def __next__(self): fib = self.a if fib &gt; self.max: raise StopIteration self.a, self.b = self.b, self.a + self.b return fib# 定义一个main函数，循环遍历每一个菲波那切数def main(): # 20以内的数 fib = Fib(20) for i in fib: print(i)# 测试if __name__ == '__main__': main() 解释说明： 在本类的实现中，定义了一个_iter_(self)方法，这个方法是在for循环遍历时被iter()调用，返回一个迭代器。因为在遍历的时候，是直接调用的python内置函数iter()，由iter()通过调用_iter_(self)获得对象的迭代器。有了迭代器，就可以逐个遍历元素了。而逐个遍历的时候，也是使用内置的next(）函数通过调用对象的_next_(self)方法对迭代器对象进行遍历。所以要实现_iter_(self)和_next_(self)这两个方法。 而且因为实现了_next_(self)方法，所以在实现_iter_(self)的时候，直接返回self就可以。 总结一句话就是： 在循环遍历自定义容器对象时,会使用python内置函数iter()调用遍历对象的_iter_(self)获得一个迭代器,之后再循环对这个迭代器使用next()调用迭代器对象的_next_(self)。 注意点：iter(self)只会被调用一次,而_next_(self)会被调用 n 次，直到出现StopIteration异常。 2、Num02–&gt;生成器 作用： 12&gt;延迟操作。也就是在需要的时候才产生结果，不是立即产生结果。1 注意事项： 12&gt;生成器是只能遍历一次的。&gt;生成器是一类特殊的迭代器。 分类： 第一类： 生成器函数：还是使用 def 定义函数，但是，使用yield而不是return语句返回结果。yield语句一次返回一个结果，在每个结果中间，挂起函数的状态，以便下次从它离开的地方继续执行。 如下案例加以说明： 123456789101112131415161718# 菲波那切数列def Fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1 return '亲！没有数据了...'# 调用方法，生成出10个数来f=Fib(10)# 使用一个循环捕获最后return 返回的值，保存在异常StopIteration的value中while True: try: x=next(f) print(\"f:\",x) except StopIteration as e: print(\"生成器最后的返回值是：\",e.value) break 第二类： 生成器表达式：类似于列表推导，只不过是把一对大括号[]变换为一对小括号()。但是，生成器表达式是按需产生一个生成器结果对象，要想拿到每一个元素，就需要循环遍历。 如下案例加以说明： 1234567891011121314151617181920212223242526272829# 一个列表xiaoke=[2,3,4,5]# 生成器generator，类似于list，但是是把[]改为()gen=(a for a in xiaoke)for i in gen: print(i)#结果是：2345# 为什么要使用生成器？因为效率。# 使用生成器表达式取代列表推导式可以同时节省 cpu 和 内存(RAM)。# 如果你构造一个列表(list)的目的仅仅是传递给别的函数,# 比如 传递给tuple()或者set(), 那就用生成器表达式替代吧!# 本案例是直接把列表转化为元组kk=tuple(a for a in xiaoke)print(kk)#结果是：(2, 3, 4, 5)# python内置的一些函数，可以识别这是生成器表达式，外面有一对小括号，就是生成器result1=sum(a for a in range(3))print(result1)# 列表推导式result2=sum([a for a in range(3)])print(result2)","path":"posts/1337.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python生成器（send，close，throw）方法详解","text":"一、Python生成器send()方法 我们知道，通过调用 next() 或者 __next()__ 方法，可以实现从外界控制生成器的执行。除此之外，通过 send() 方法，还可以向生成器中传值。 值得一提的是，send() 方法可带一个参数，也可以不带任何参数（用 None 表示）。其中，当使用不带参数的 send() 方法时，它和 next() 函数的功能完全相同。例如： 12345678def intNum(): print(\"开始执行\") for i in range(5): yield i print(\"继续执行\")num = intNum()print(num.send(None))print(num.send(None)) 输出结果 1234开始执行0继续执行1 注意，虽然 send(None) 的功能是 next() 完全相同，但更推荐使用 next()，不推荐使用 send(None)。 这里重点讲解一些带参数的 send(value) 的用法，其具备 next() 函数的部分功能，即将暂停在 yield 语句出的程序继续执行，但与此同时，该函数还会将 value 值作为 yield 语句返回值赋值给接收者。 注意，带参数的 send(value) 无法启动执行生成器函数。也就是说，程序中第一次使用生成器调用 next() 或者 send() 函数时，不能使用带参数的 send() 函数。 举个例子： 123456789def foo(): bar_a = yield \"hello\" bar_b = yield bar_a yield bar_bf = foo()print(f.send(None))print(f.send(\"xgp\"))print(f.send(\"https://wsdlxgp.top/\")) 分析一下此程序的执行流程： 1) 首先，构建生成器函数，并利用器创建生成器（对象）f 。 2) 使用生成器 f 调用无参的 send() 函数，其功能和 next() 函数完全相同，因此开始执行生成器函数，即执行到第一个 yield “hello” 语句，该语句会返回 “hello” 字符串，然后程序停止到此处（注意，此时还未执行对 bar_a 的赋值操作）。 3) 下面开始使用生成器 f 调用有参的 send() 函数，首先它会将暂停的程序开启，同时还会将其参数“xgp”赋值给当前 yield 语句的接收者，也就是 bar_a 变量。程序一直执行完 yield bar_a 再次暂停，因此会输出“xgp”。 4） 最后依旧是调用有参的 send() 函数，同样它会启动餐厅的程序，同时将参数“https://wsdlxgp.top/”传给 bar_b，然后执行完 yield bar_b 后（输出 https://wsdlxgp.top/），程序执行再次暂停。 因此，该程序的执行结果为： 123helloxgphttps://wsdlxgp.top/ 二、Python生成器close()方法 当程序在生成器函数中遇到 yield 语句暂停运行时，此时如果调用 close() 方法，会阻止生成器函数继续执行，该函数会在程序停止运行的位置抛出 GeneratorExit 异常。 举个例子： 12345678def foo(): try: yield 1 except GeneratorExit: print('捕获到 GeneratorExit')f = foo()print(next(f))f.close() 输出结果 121捕获到 GeneratorExit 注意，虽然通过捕获 GeneratorExit 异常，可以继续执行生成器函数中剩余的代码，带这部分代码中不能再包含 yield 语句，否则程序会抛出 RuntimeError 异常。例如： 123456789def foo(): try: yield 1 except GeneratorExit: print('捕获到 GeneratorExit') yield 2 # 抛出 RuntimeError 异常f = foo()print(next(f))f.close() 输出结果 1234561捕获到 GeneratorExitTraceback (most recent call last): File \"G:/四期/python/Pytghon_MySQL/生成器/xxx.py\", line 9, in &lt;module&gt; f.close()RuntimeError: generator ignored GeneratorExit 另外，生成器函数一旦使用 close() 函数停止运行，后续将无法再调用 next() 函数或者 __next()__方法启动执行，否则会抛出 StopIteration 异常。例如： 1234567def foo(): yield \"c.biancheng.net\"print(\"生成器停止执行\")f = foo()print(next(f)) # 输出 \"c.biancheng.net\"f.close()next(f) # 原本应输出\"生成器停止执行\" 输出结果 123456Traceback (most recent call last): File \"G:/四期/python/Pytghon_MySQL/生成器/xxx.py\", line 10, in &lt;module&gt; next(f) # 原本应输出\"生成器停止执行\"StopIteration生成器停止执行c.biancheng.net 三、Python生成器throw()方法 生成器 throw() 方法的功能是，在生成器函数执行暂停处，抛出一个指定的异常，之后程序会继续执行生成器函数中后续的代码，直到遇到下一个 yield 语句。需要注意的是，如果到剩余代码执行完毕没有遇到下一个 yield 语句，则程序会抛出 StopIteration 异常。 举个例子： 12345678def foo(): try: yield 1 except ValueError: print('捕获到 ValueError')f = foo()print(next(f))f.throw(ValueError) 输出结果 123456Traceback (most recent call last): File \"G:/四期/python/Pytghon_MySQL/生成器/xxx.py\", line 8, in &lt;module&gt; f.throw(ValueError)StopIteration1捕获到 ValueError 显然，一开始生成器函数在 yield 1 处暂停执行，当执行 throw() 方法时，它会先抛出 ValueError 异常，然后继续执行后续代码找到下一个 yield 语句，该程序中由于后续不再有 yield 语句，因此程序执行到最后，会抛出一个 StopIteration 异常。","path":"posts/1336.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python的生成器（2）","text":"A：Python迭代器，生成器详解 本质上，生成器也是一种迭代器。但生成器只能迭代一次，因为值是在迭代过程生成，而所有的值没有保存在内存。这里先介绍下迭代器的概念，迭代器分为3部分： 可迭代对象： python中的任意对象，只要它定义了可以返回一个迭代器iter方法，或者支持下标索引的getitem方法，那它就是一个可迭代对象。简单来说可迭代对象就是可以提供迭代器的任意对象。 迭代器： python中的任意对象有next方法就是一个迭代器。 迭代： 简单来说就是从某个地方取出一个元素的过程，像使用循环遍历一个列表这个过程就叫迭代。 了解迭代器的概念，我们再来细究生成器的原理：生成器是只能迭代一次的迭代器。大多数时候生成器都是通过函数来实现的。使用生成器“生成”一个值可以通过for循环，或者将它们传递给可以进行迭代的函数和结构。 （注：这个过程并不是return返回一个值，而是“生成”一个值，且所有值不保存在内存里面） A：生成器协议 在 Python 中，使用了 yield 的函数被称为生成器（generator）。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 调用一个生成器函数，返回的是一个迭代器对象。 1、生成器实现的协议:迭代器协议 （1）迭代器协议: 对象需要提供next的方法, 它要么返回迭代中的-项, 要么就引起一个StopIteration异常，来终止迭代 （2）使用了迭代器进行访问数据的工具 for循环:sum()、max()、min()、len()等函数 （3）以下实例使用 yield 实现斐波那契数列： 12345678910111213141516171819#!/usr/bin/python3 import sys def fibonacci(n): # 生成器函数 - 斐波那契 a, b, counter = 0, 1, 0 while True: if (counter &gt; n): return yield a a, b = b, a + b counter += 1f = fibonacci(10) # f 是一个迭代器，由生成器返回生成 while True: try: print (next(f), end=\" \") except StopIteration: sys.exit() 执行以上程序，输出结果如下： 10 1 1 2 3 5 8 13 21 34 55 2、生成器的创建方式也比迭代器简单很多，大体分为以下 2 步： 定义一个以 yield 关键字标识返回值的函数； 调用刚刚创建的函数，即可创建一个生成器 举个例子： 123456def intNum(): print(\"开始执行\") for i in range(5): yield i print(\"继续执行\")num = intNum() 由此，我们就成功创建了一个 num 生成器对象。显然，和普通函数不同，number() 函数的返回值用的是 yield 关键字，而不是 return 关键字，此类函数又成为生成器函数。 和 return 相比，yield 除了可以返回相应的值，还有一个更重要的功能，即每当程序执行完该语句时，程序就会暂停执行。不仅如此，即便调用生成器函数，Python解释器也不会执行函数中的代码，它只会返回一个生成器（对象）。 3、要想使生成器函数得以执行，或者想使执行完 yield 语句立即暂停的程序得以继续执行，有以下 2 种方式： 通过生成器（上面程序中的 num）调用 next() 内置函数或者 next() 方法； 通过 for 循环遍历生成器。 例如，在上面程序的基础上，添加如下语句： 1234567#调用 next() 内置函数print(next(num))#调用 __next__() 方法print(num.__next__())#通过for循环遍历生成器for i in num: print(i) 程序执行结果为： 1234567891011开始执行0继续执行1继续执行2继续执行3继续执行4继续执行 这里有必要给读者分析一个程序的执行流程： 1) 首先，在创建有 num 生成器的前提下，通过其调用 next() 内置函数，会使 Python 解释器开始执行 intNum() 生成器函数中的代码，因此会输出“开始执行”，程序会一直执行到yield i，而此时的 i==0，因此 Python 解释器输出“0”。由于受到 yield 的影响，程序会在此处暂停。 2) 然后，我们使用 num 生成器调用 next() 方法，该方法的作用和 next() 函数完全相同（事实上，next() 函数的底层执行的也是 next() 方法），它会是程序继续执行，即输出“继续执行”，程序又会执行到yield i，此时 i==1，因此输出“1”，然后程序暂停。 3) 最后，我们使用 for 循环遍历 num 生成器，之所以能这么做，是因为 for 循环底层会不断地调用 next() 函数，使暂停的程序继续执行，因此会输出后续的结果。 注意，在 Python 2.x 版本中不能使用 next() 方法，可以使用 next() 内置函数，另外生成器还有 next() 方法（即以 num.next() 的方式调用）。 4、除此之外，还可以使用 list() 函数和 tuple() 函数，直接将生成器能生成的所有值存储成列表或者元组的形式。 例如： 1234num = intNum()print(list(num))num = intNum()print(tuple(num)) 程序执行结果为： 1234567891011121314开始执行继续执行继续执行继续执行继续执行继续执行[0, 1, 2, 3, 4]开始执行继续执行继续执行继续执行继续执行继续执行(0, 1, 2, 3, 4) 通过输出结果可以判断出，list() 和 tuple() 底层实现和 for 循环的遍历过程是类似的。 相比迭代器，生成器最明显的优势就是节省内存空间，即它不会一次性生成所有的数据，而是什么时候需要，什么时候生成。 小练习 假设现在有一个列表， 列表中包含多个整数， 我们对列表进行过滤， 在过滤的结果中，只保留列表中的偶数的数字。 方法一 1234567891011121314#conding=utf-8def get_even_num(list): res = [] for item in list: res.append(item) return resdef main(): list = range(5) for i in get_even_num(list): print(i,end=' ')if __name__ == '__main__': main() 输出结果 10 1 2 3 4 方法二 1234567891011121314151617#conding=utf-8def get_even_num(list): # res = [] # for item in list: # res.append(item) # return res for item in list: if item % 2 == 0: yield itemdef main(): list = range(5) for i in get_even_num(list): print(i,end=' ')if __name__ == '__main__': main() 输出结果 10 2 4 或者 1234567891011#conding=utf-8def get_even_num(list): return [item for item in list if item % 2 == 0]def main(): list = range(5) for i in get_even_num(list): print(i,end=' ')if __name__ == '__main__': main() 输出结果 10 2 4","path":"posts/1335.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python的生成器（1）","text":"A：概述 可迭代对象、迭代器和生成器这三个概念很容易混淆，前两者通常不会区分的很明显，只是用法上有区别。生成器在某种概念下可以看做是特殊的迭代器，它比迭代实现上更加简洁。三者关系如图： B：可迭代对象 先说下上面三者的基础：可迭代对象（Iterable Object），简单的来理解就是可以使用 for 来循环遍历的对象。比如常见的 list、set和dict。可以用以下方法来测试对象是否是可迭代 1234567&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance('abc', Iterable) # str是否可迭代True&gt;&gt;&gt; isinstance([1,2,3], Iterable) # list是否可迭代True&gt;&gt;&gt; isinstance(123, Iterable) # 整数是否可迭代False C：Python迭代器概念 迭代是Python最强大的功能之一，是访问集合元素的一种方式。 迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 迭代器有两个基本的方法：iter() 和 next()。 操作一 （1）字符串，列表或元组对象都可用于创建迭代器： 1234567&gt;&gt;&gt; list=[1,2,3,4]&gt;&gt;&gt; it = iter(list) # 创建迭代器对象&gt;&gt;&gt; print (next(it)) # 输出迭代器的下一个元素1&gt;&gt;&gt; print (next(it))2&gt;&gt;&gt; （2）迭代器对象可以使用常规for语句进行遍历： 123456#!/usr/bin/python3 list=[1,2,3,4]it = iter(list) # 创建迭代器对象for x in it: print (x, end=\" \") （3）执行以上程序，输出结果如下： 11 2 3 4 （4）也可以使用 next() 函数： 123456789101112#!/usr/bin/python3 import sys # 引入 sys 模块 list=[1,2,3,4]it = iter(list) # 创建迭代器对象 while True: try: print (next(it)) except StopIteration: sys.exit() 执行以上程序，输出结果如下： 12341234 操作二 其实你对所有的可迭代对象调用 dir() 方法时，会发现他们都实现了 __iter__ 方法。这样就可以通过 iter(object) 来返回一个迭代器。 123456&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; y = iter(x)&gt;&gt;&gt; type(x)&lt;class 'list'&gt;&gt;&gt;&gt; type(y)&lt;class 'list_iterator'&gt; 可以看到调用 iter() 之后，变成了一个 list_iterator 的对象。会发现增加了 __next__ 方法。所有实现了 __iter__ 和 __next__ 两个方法的对象，都是迭代器。 迭代器是带状态的对象，它会记录当前迭代所在的位置，以方便下次迭代的时候获取正确的元素。__iter__返回迭代器自身，__next__返回容器中的下一个值，如果容器中没有更多元素了，则抛出StopIteration异常。 操作三 123456789101112&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; y = iter(x)&gt;&gt;&gt; next(y)1&gt;&gt;&gt; next(y)2&gt;&gt;&gt; next(y)3&gt;&gt;&gt; next(y)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;StopIteration 具体的实现我没有深入研究。但是我大胆的猜测一下…联系操作系统中 printf(fmt,...) 的实现方式，其中是定义一个 va_list 来用于保存需要打印的 ... 信息的。然后实现了va_start() va_end() va_arg() 三个方法来不停地迭代式的打印信息。感兴趣可以自己了解。 那回到Iterator ，如何判断对象是否是迭代器，和判断是否是可迭代对象的方法差不多，只要把 Iterable 换成 Iterator。 Python的for循环本质上就是通过不断调用next()函数实现的，举个栗子，下面的代码 123x = [1, 2, 3]for elem in x: ... 实际上执行时是 也就是先将可迭代对象转化为Iterator，再去迭代。应该是处于对内存的节省考虑。因为迭代器只有在你调用 next() 才会实际计算下一个值。 （2）itertools 库提供了很多常见迭代器的使用 123456&gt;&gt;&gt; from itertools import count # 计数器&gt;&gt;&gt; counter = count(start=13)&gt;&gt;&gt; next(counter)13&gt;&gt;&gt; next(counter)14 （3）无限循环序列： 12345678910&gt;&gt;&gt; from itertools import cycle&gt;&gt;&gt; colors = cycle(['red', 'white', 'blue'])&gt;&gt;&gt; next(colors)'red'&gt;&gt;&gt; next(colors)'white'&gt;&gt;&gt; next(colors)'blue'&gt;&gt;&gt; next(colors)'red' E：创建一个迭代器 把一个类作为一个迭代器使用需要在类中实现两个方法 iter() 与 next() 。 如果你已经了解的面向对象编程，就知道类都有一个构造函数，Python 的构造函数为 init(), 它会在对象初始化的时候执行。 更多内容查阅：Python3 面向对象 iter() 方法返回一个特殊的迭代器对象， 这个迭代器对象实现了 next() 方法并通过 StopIteration 异常标识迭代的完成。 next() 方法（Python 2 里是 next()）会返回下一个迭代器对象。 创建一个返回数字的迭代器，初始值为 1，逐步递增 1： 123456789101112131415161718class MyNumbers: def __iter__(self): self.a = 1 return self def __next__(self): x = self.a self.a += 1 return x myclass = MyNumbers()myiter = iter(myclass) print(next(myiter))print(next(myiter))print(next(myiter))print(next(myiter))print(next(myiter)) 执行输出结果为： 1234512345 StopIteration StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 next() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。 在 20 次迭代后停止执行： 123456789101112131415161718class MyNumbers: def __iter__(self): self.a = 1 return self def __next__(self): if self.a &lt;= 20: x = self.a self.a += 1 return x else: raise StopIteration myclass = MyNumbers()myiter = iter(myclass) for x in myiter: print(x) 执行输出结果为： 12345678910111213141516171819201234567891011121314151617181920","path":"posts/1334.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python的迭代器","text":"A：概述 可迭代对象、迭代器和生成器这三个概念很容易混淆，前两者通常不会区分的很明显，只是用法上有区别。生成器在某种概念下可以看做是特殊的迭代器，它比迭代实现上更加简洁。三者关系如图： B：可迭代对象 先说下上面三者的基础：可迭代对象（Iterable Object），简单的来理解就是可以使用 for 来循环遍历的对象。比如常见的 list、set和dict。可以用以下方法来测试对象是否是可迭代 1234567&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance('abc', Iterable) # str是否可迭代True&gt;&gt;&gt; isinstance([1,2,3], Iterable) # list是否可迭代True&gt;&gt;&gt; isinstance(123, Iterable) # 整数是否可迭代False C：Python迭代器概念 迭代是Python最强大的功能之一，是访问集合元素的一种方式。 迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 迭代器有两个基本的方法：iter() 和 next()。 操作一 （1）字符串，列表或元组对象都可用于创建迭代器： 1234567&gt;&gt;&gt; list=[1,2,3,4]&gt;&gt;&gt; it = iter(list) # 创建迭代器对象&gt;&gt;&gt; print (next(it)) # 输出迭代器的下一个元素1&gt;&gt;&gt; print (next(it))2&gt;&gt;&gt; （2）迭代器对象可以使用常规for语句进行遍历： 123456#!/usr/bin/python3 list=[1,2,3,4]it = iter(list) # 创建迭代器对象for x in it: print (x, end=\" \") （3）执行以上程序，输出结果如下： 11 2 3 4 （4）也可以使用 next() 函数： 123456789101112#!/usr/bin/python3 import sys # 引入 sys 模块 list=[1,2,3,4]it = iter(list) # 创建迭代器对象 while True: try: print (next(it)) except StopIteration: sys.exit() 执行以上程序，输出结果如下： 12341234 操作二 其实你对所有的可迭代对象调用 dir() 方法时，会发现他们都实现了 __iter__ 方法。这样就可以通过 iter(object) 来返回一个迭代器。 123456&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; y = iter(x)&gt;&gt;&gt; type(x)&lt;class 'list'&gt;&gt;&gt;&gt; type(y)&lt;class 'list_iterator'&gt; 可以看到调用 iter() 之后，变成了一个 list_iterator 的对象。会发现增加了 __next__ 方法。所有实现了 __iter__ 和 __next__ 两个方法的对象，都是迭代器。 迭代器是带状态的对象，它会记录当前迭代所在的位置，以方便下次迭代的时候获取正确的元素。__iter__返回迭代器自身，__next__返回容器中的下一个值，如果容器中没有更多元素了，则抛出StopIteration异常。 操作三 123456789101112&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; y = iter(x)&gt;&gt;&gt; next(y)1&gt;&gt;&gt; next(y)2&gt;&gt;&gt; next(y)3&gt;&gt;&gt; next(y)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;StopIteration 具体的实现我没有深入研究。但是我大胆的猜测一下…联系操作系统中 printf(fmt,...) 的实现方式，其中是定义一个 va_list 来用于保存需要打印的 ... 信息的。然后实现了va_start() va_end() va_arg() 三个方法来不停地迭代式的打印信息。感兴趣可以自己了解。 那回到Iterator ，如何判断对象是否是迭代器，和判断是否是可迭代对象的方法差不多，只要把 Iterable 换成 Iterator。 Python的for循环本质上就是通过不断调用next()函数实现的，举个栗子，下面的代码 123x = [1, 2, 3]for elem in x: ... 实际上执行时是 也就是先将可迭代对象转化为Iterator，再去迭代。应该是处于对内存的节省考虑。因为迭代器只有在你调用 next() 才会实际计算下一个值。 操作四 先新建test.txt文件，里面瞎写点东西 123with open('test.txt') as f: for line in f: print(line.rstrip()) 输出结果 1234testdfasdasdfasdfasdgfdg 1、itertools 库提供了很多常见迭代器的使用 123456&gt;&gt;&gt; from itertools import count # 计数器&gt;&gt;&gt; counter = count(start=13)&gt;&gt;&gt; next(counter)13&gt;&gt;&gt; next(counter)14 2、无限循环序列： 12345678910&gt;&gt;&gt; from itertools import cycle&gt;&gt;&gt; colors = cycle(['red', 'white', 'blue'])&gt;&gt;&gt; next(colors)'red'&gt;&gt;&gt; next(colors)'white'&gt;&gt;&gt; next(colors)'blue'&gt;&gt;&gt; next(colors)'red' 3、dir方法 dir() 函数不带参数时，返回当前范围内的变量、方法和定义的类型列表；带参数时，返回参数的属性、方法列表。如果参数包含方法__dir__()，该方法将被调用。如果参数不包含__dir__()，该方法将最大限度地收集参数信息 。 12f = open('test.txt')print(dir(f)) 输出结果 1['_CHUNK_SIZE', '__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_checkClosed', '_checkReadable', '_checkSeekable', '_checkWritable', '_finalizing', 'buffer', 'close', 'closed', 'detach', 'encoding', 'errors', 'fileno', 'flush', 'isatty', 'line_buffering', 'mode', 'name', 'newlines', 'read', 'readable', 'readline', 'readlines', 'reconfigure', 'seek', 'seekable', 'tell', 'truncate', 'writable', 'write', 'write_through', 'writelines'] 迭代器本身是一个底层的特性和概念，在程序中并不常用，但它为生成器这一更有趣的特性提供了基础。","path":"posts/1333.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python的SaltStack","text":"SaltStack Ansible和SaltStack的区别 Ansible安装部署简单。默认情况下，SaltStack需要安装客户端接收服务器发送过来的命令。Ansible不需要在被控服务器上部署任何的客户端，直接使用ssh通道进行远程命令的执行或者下发配置。 SaltStack响应速度快。默认情况下，Ansible使用的是标准的SSH协议，而SaltStack使用ZeroMQ进行通信和传输。因此，仅仅从响应速度来讲，SaltStack比Ansible快很多，甚至快十几倍。在一般运维场景下，Ansible的响应速度完全可以满足需求。 Ansible更安全。Ansible使用标准的SSH连接传输数据，不需要在远程主机上启动守护进程。此外，标准的SSH数据传输本身就是加密传输，远程主机不易被攻击。 对Windows的支持。SaltStack对Windows的支持比较友好，Ansible从1.7版本开始加入了对Windows的支持。由于Windows默认没有SSH，而Ansible有依赖SSH进行通信，所以在Windows下Ansible需要依赖PowerShell来实现远程管理。Ansible必须使用Linux系统运行控制端。 Ansible自身运维比较简单。SaltStack需要在Master和Minion主机启动一个守护进程，自身需要检测守护进程的运行状态，增加了运维成本。Ansible和服务器之间用SSH进行通信，服务器上值需要运行SSH进程就可以进行运维操作。因此，从工具本身的运维角度来说，Ansible要比SaltStack简单很多。 一、安装SaltStack 1、实验环境： 角色 主机名 id(minion id) IP Master python SN-2020-03-01 192.168.1.80 minion 192.168.1.40 SN-2020-03-11 192.168.1.40 2、安装EPEL(都要) 123yum install epel或yum install epel-release -y 3、安装SaltStack （1）主服务器安装（主控端） 123yum -y install salt-masterchkconfig salt-master onservice salt-master start （2）从服务器安装（被控端） 123yum -y install salt-minionchkconfig salt-minion onservice salt-minion start 4、SaltStack防火墙配置(master) 在主控端添加TCP 4505、TCP 4506的规则，而在被控端无须配置防火墙，原理是被控端直接与主控端的zeromq建立长链接，接收广播到的任务信息并执行，具体操作是添加两条iptables规则: 12[root@python ~]# iptables -I INPUT -m state --state new -m tcp -p tcp --dport 4505 -j ACCEPT[root@python ~]# iptables -I INPUT -m state --state new -m tcp -p tcp --dport 4506 -j ACCEPT 5、更新Saltstack配置及安装校验 Saltstack分两种角色，一种为master（主控端），另一种为minion（被控端），安装完毕后需要对两种角色的配置文件进行修改。下面具体说明： （1）master主控端配置 1）更新主控端关键项配置 /etc/salt/master 123456789[root@python ~]# vim test.ping# 绑定Master通信IPinterface: 192.168.79.143 # 15行# 自动认证，避免手动运行salt-key来确认证书信任auto_accept: True #215# 指定saltstack文件根目录的位置file_roots: #406 base: - /srv/salt 当/etc/salt/master没有配置auto_accept: True时，需要通过salt-key命令来进行证书认证操作，具体操作如下： 12345salt-key -L:显示已经或未认证的被控端id,Accepted Keys为已认证清单，Unaccepted Kys为未认证的清单salt-key -D:删除所有认证主机id证书salt-key -d id:删除单个id证书salt-key -A:接受所有id证书请求salt-key -a id:接受单个id证书请求 2）重启saltstack salt-master服务，使新配置生效 1service salt-master restart （2）minion被控制端配置 1）更新被控端关键项配置 /etc/salt/minion 12345[root@192 ~]# vim test.ping# 指定master主机IP地址master: 192.168.79.143 # 15行# 修改被控制端主机识别ID，建议使用操作系统主机名来配置id: XGP 2）重启saltstack salt-minion服务，使新配置生效 1service salt-minion restart （3）校验安装结果 通过test模块的ping方法，可以确认指定被控端设备与主控端是否建立信任关系，及连通性是否正常，探测所有被控端采用“*”来代替“SN-2020-03-20”即可。如下所示： 123[root@192 ~]# salt 'XGP' test.pingXGP: True 二、使用saltstack远程执行命令 saltstack的一个比较突出的优势是，具备执行远程命令的功能，可以帮助运维人员完成集中化的操作平台。 1、salt命令格式 1salt '&lt;操作目标&gt;' &lt;方法&gt;[参数] 示例：查看被控主机的内存使用情况 12345[root@python ~]# salt 'XGP' cmd.run 'free -m'XGP: total used free shared buff/cache available Mem: 976 500 94 2 381 260 Swap: 2047 267 1780 2、常用的具体参数 针对&lt;操作目标&gt;，saltstack提供了多种方法对被控端主机（id）进行过滤。 （1）-E,–pcre 通过正则表达式进行匹配。示例：监控SN-2020字符开头的主机id名是否连通，如下所示： 123[root@python ~]# salt -E '^XG*' test.pingXGP: True （2）-L,–list 以主机名id列表的形式进行过滤，格式与Python的列表相似，即不同的主机id名称使用逗号进行分隔。示例：获取主机id名为XGP；获取完整操作系统发行版本名称。如下所示： 12345[root@python ~]# salt -L 'XGP' grains.item osfullnameXGP: ---------- osfullname: CentOS Linux （3）-G,–grain 根据被控主机的grain信息进行匹配过滤，格式为’:’，例如：过滤内核为Linux的主机可以写成‘kernel:Linux’，如果同时需要正则表达式的支持，可切换成–grain-pcre参数来执行。示例：获取主机发行版本号为7.5的Python版本号。 1234[root@python ~]# salt -G 'osrelease:6.5' cmd.run 'python -V'saltstack_web1group_1: Python 2.6.6saltstack_web1group_2: Python 2.6.6 （4）-I,–pillar 12345[root@python ~]# salt -I 'httpd:root:/data' test.pingsaltstack_web1group_1: Truesaltstack_web1group_2: True#其中pillar属性配置文件如下：httpd:root: /data （5）-N,–nodegroup 根据主控端master配置文件中的分组名称进行过滤。如下所示： /etc/salt/master 1234567891011121314[root@python ~]# vim /etc/salt/master nodegroups: #710 group1: 'L@XGP，WSD' #如果有多个可用逗号隔开 group2: 'L@XGP' [root@python ~]# service salt-master restartRedirecting to /bin/systemctl restart salt-master.service[root@python ~]# salt -N group1 test.pingXGP: True[root@python ~]# salt -N group2 test.pingXGP: True （6）-C,–compound 根据条件运算符not、and、or去匹配不同规则的主机信息。示例：探测SN-2020开头，并且操作系统版本为CentOS的主机连通性。 123[root@python ~]# salt -C 'E@XG* and G@os:CentOS' test.pingXGP: True 其中，not语句不能作为第一个条件执行，不过可以通过以下方式来规避。示例：探测非SN-2023开头的主机连通性。 123[root@192 ~]# salt -C '* and not E@^SN-2023*' test.pingSN-2020-03-20: True （7）-S,–ipcidr 根据被控主机的IP地址或IP子网进行匹配，示例如下： 12[root@192 ~]# salt -S 192.168.0.0/16 test.ping[root@192 ~]# salt -S 192.168.79.164 test.ping 三、saltstack常用模块及API saltstack提供了非常丰富的功能模块，设计操作系统的基础功能、常用工具支持等。使用sys模块可以列出当前版本支持的模块。 12345678[root@192 ~]# salt '*' sys.list_modulesSN-2020-03-20: - acl - aliases - alternatives - archive - artifactory &lt;!--省略部分输出--&gt; APId的原理是通过调用master client模块，实例化一个LocalClient对象，再调用cmd()方法实现的。以下是API实现test.ping的示例： 12345import salt.clientclinet = salt.client.LocalClient()result = client.cmd('*', 'test.ping')print(result) 结果以一个标准的Python字典形式的字符串返回，可以通过eval()函数转换成Python的字典类型，方便后续的业务u逻辑处理。程序运行结果如下： 1&#123;'SN-2020-03-20':True&#125; 1、Archive模块 功能：实现系统层面的压缩包调用，支持gunzip、gzip、rar、tar、unrar、unzip等。 示例： 123456789# 采用gzip解压 /tmp/data.txt文件[root@192 ~]# salt 'SN-2020-03-20' archive.gzip /tmp/data.txtSN-2020-03-20:# 采用tar压缩 /tmp/data.txt文件[root@192 ~]# salt 'SN-2020-03-20' archive.tar cvf /tmp/data.txt.tar /tmp/data.txtSN-2020-03-20: - tar: Removing leading `/' from member names - /tmp/data.txt 调用API： 1client.cmd('SN-2020-03-20','archive.gzip',['/tmp/data.txt']) 2、cmd模块 实现远程的命令行调用执行（默认具备root操作权限，慎用！） 示例： 12345678910111213# 获取所有被控主机的内存情况salt '*' cmd.run \"free -m\"# 在SN-2020-03-20主机运行test.sh脚本，salt 'SN-2020-03-20' cmd.script salt://script/test.sh # 其中script/test.sh脚本存放在file_roots指定的目录:/srv/saltmkdir -p /srv/salt/scriptvim /srv/salt/script/test.sh# 该命令会做2个动作：# 1.首先同步test.sh到minion的cache目录（如：同步到# /var/cache/salt/minion/files/base/script/test.sh）；# 2.其次运行该脚本。 调用API： 1client.cmd('SN-2020-03-20','cmd.run',['free -m']) 3、cp模块 实现远程文件、目录的复制，以及下载URL文件等操作。 示例： 12345678910111213141516171819# 将指定被控主机的/etc/hosts文件复制到被控主机本地的salt的cache目录（/var/cache/salt/minion/localfiles/）[root@192 ~]# salt '*' cp.cache_local_file /etc/hostsSN-2020-03-20: /var/cache/salt/minion/localfiles/etc/hosts# 将主服务器file_roots指定位置下的目录复制到被控主机，空目录不复制[root@192 ~]# salt \"SN-2020-03-20\" cp.get_dir salt://ccc /tmpSN-2020-03-20: - /tmp/ccc/ccc.txt# 将主服务器file_roots指定位置下的文件复制到被控主机[root@192 ~]# salt \"SN-2020-03-20\" cp.get_file salt://test.sh /tmp/test.shSN-2020-03-20: /tmp/test.sh# 下载URL内容到被控主机指定位置[root@192 ~]# salt \"SN-2020-03-20\" cp.get_url https://slashdot.org/ /tmp/index.htmlSN-2020-03-20: /tmp/index.html 调用API： 1client.cmd('SN-2020-03-20', 'cp.get_file, ['salt://path/to/file' ,'/minion/dest']) 4、cron模块 实现被控主机的crontab操作。 示例： 123456789101112131415# 查看指定被控主机、root用户的crontab清单[root@192 ~]# salt \"SN-2020-03-20\" cron.raw_cron rootSN-2020-03-20: # Lines below here are managed by Salt, do not edit * * * * * /usr/bin/date# 为指定的被控主机、root用户添加/usr/bin/date任务作业 [root@192 ~]# salt \"SN-2020-03-20\" cron.set_job root '*' '*' '*' '*' '*' /usr/bin/dateSN-2020-03-20: new# 删除指定的被控主机、root用户crontab的/usr/bin/date任务作业[root@192 ~]# salt \"SN-2020-03-20\" cron.rm_job root /usr/bin/dateSN-2020-03-20: removed 调用API： 1client.cmd('SN-03-2020-20', 'cron.set_job', ['root','*','*','*','*','*','/usr/bin/date']) 5、dnsutil模块 实现被控主机通用DNS相关操作。 示例： 12345# 添加指定被控主机hosts的主机配置项salt '*' dnsutil.hosts_append /etc/hosts 127.0.0.1 ad1.yk.com,ad2,yk.com# 删除指定被控主机hosts的主机配置项salt '*' dnsutil.hosts_remove /etc/hosts ad1.yk.com 调用API： 1client.cmd('*', 'dnsutil.hosts_append', ['/etc/hosts','127.0.0.1','ad1.yk.com']) 6、file模块 被控主机文件常见的操作，包括文件读写、权限、查找、校验等。 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# 校验所有被控主机/etc/fstab文件的MD5，一致则返回True# 修改所有别空主机文件的属组、用户权限，等价于chown test:root /tmp/test.sh[root@192 ~]# salt \"SN-2020-03-20\" file.chown /tmp/test.sh test rootSN-2020-03-20: None# 复制被控主机本地文件到本地的文件[root@192 ~]# salt \"SN-2020-03-20\" file.copy /tmp/ccc/ccc.txt /tmp/c.txtSN-2020-03-20: True# 检查所有被控主机/etc目录是否存在，存在则返回True，检查文件是否存在使用file.file_exists方法[root@192 ~]# salt \"SN-2020-03-20\" file.directory_exists /etcSN-2020-03-20: True[root@192 ~]# salt \"SN-2020-03-20\" file.file_exists /etc/passwdSN-2020-03-20: True[root@192 ~]# # 获取所有被控主机/etc/passwd的stats信息[root@192 ~]# salt \"SN-2020-03-20\" file.stats /etc/passwdSN-2020-03-20: ---------- atime: 1585115927.94 ctime: 1572940727.67 gid: 0 group: root inode: 19172097 mode: 0644 mtime: 1572940727.67 size: 2349 target: /etc/passwd type: file uid: 0 user: root# 获取所有被控主机/etc/passwd的权限mode，如：755,644[root@192 ~]# salt \"SN-2020-03-20\" file.get_mode /etc/passwdSN-2020-03-20: 0644# 修改所有被控主机/etc/passwd的权限mode为644[root@192 ~]# salt \"SN-2020-03-20\" file.set_mode /etc/passwd 644SN-2020-03-20: 0644# 在所有被控主机创建目录[root@192 ~]# salt \"SN-2020-03-20\" file.mkdir /opt/testSN-2020-03-20: None# 将所有被控主机/etc/httpd/httpd.conf文件的LogLevel参数warn值修改为info[root@192 ~]# salt \"SN-2020-03-20\" file.sed /tmp/date.log \"内容\" \"content\"SN-2020-03-20: ---------- pid: 15581 retcode: 0 stderr: stdout:# 给所有被控主机的/tmp/test/test.conf文件追加内容“maxclient 100”[root@192 ~]# salt \"SN-2020-03-20\" file.append /tmp/date.log \"追加内容\"SN-2020-03-20: Wrote 1 lines to \"/tmp/date.log\"# 删除所有被控主机的/tmp/foo文件[root@192 ~]# salt \"SN-2020-03-20\" file.remove /tmp/c.txtSN-2020-03-20: True 调用API： 1client.cmd('*', 'file.remove', ['/tmp/foo']) 7、iptables模块 被控主机ilptables支持。 示例： 1234567891011# 在所有被控主机追加、插入iptables规则，其中INPUT为输入链salt '*' iptables.append filter INPUT rule='-m state --state RELATED,ESTABLISHED -j ACCEPT'salt '*' iptables.insert filter INPUT position=3 rule='-m state --state RELATED,ESTABLISHED -j ACCEPT'# 在所有被控主机删除指定链编号为3（position=3）或者指定存在的规则salt '*' iptables.delete filter INPUT position=3salt '*' iptables.delete filter INPUT rule='-m state --state RELATED,ESTABLISHED -j ACCEPT'# 保存所有被控主机规则到本地硬盘（/etc/sysconfig/iptables）salt '*' iptables.save /etc/sysconfig/iptables 调用API： 1client.cmd('SN-2020-03-20', 'iptables.append', ['filter', 'INPUT', 'rule=\\'-p tcp--sport 80 -j ACCEPT\\'']) 8、network模块 返回被控主机网络信息。 示例： 12345678910111213141516171819# 在指定被控主机“SN-2020-03-20”获取dig、ping、traceroute目录域名信息salt 'SN-2020-03-20' network.dig www.qq.comsalt 'SN-2020-03-20' network.ping www.qq.comsalt 'SN-2020-03-20' network.traceroute www.qq.com# 获取指定被控主机“SN-2020-03-20”的MAC地址salt 'SN-2020-03-20' network.hwaddr ens33# 检测指定被控主机“SN-2020-03-20”是否属于10.0.0.0/16子网范围，属于则返回Truesalt 'SN-2020-03-20' network.in_subnet 10.0.0.0/16# 获取指定被控主机“SN-2020-03-20”的网卡配置信息salt 'SN-2020-03-20' network.interfaces# 获取指定被控主机“SN-2020-03-20”的IP地址配置信息salt 'SN-2020-03-20' network.ip_addrs# 获取指定被控主机“SN-2020-03-20”的子网信息salt 'SN-2020-03-20' network.subnets 调用API： 1client.cmd('SN-2020-03-20','network.subnets') 9、pkg包管理模块 被控主机程序包管理，如yum、apt-get等。 示例： 12345678# 为所有被控主机安装PHP环境，根据不同系统发行版调用不同的安装工具进行部署，如Redhat平台的yum，等价于yum -y install phpsalt '*' pkg.install php# 卸载所有被控主机的PHP环境salt '*' pkg.remove php# 升级所有被控主机的软件包salt '*' pkg.upgrade 调用API： 1client.cm(&#39;SN-2020-03-20&#39;,&#39;pgk.remove&#39;, [&#39;php&#39;]) 10、Service服务模块 被控主机程序包的服务管理。 示例： 12345678910# 开启（enable）、禁用（disable）nginx开机自启动服务salt '*' service.enable nginxsalt '*' service.disable nginx# 针对nginx服务的reload、restart、start、stop、status操作salt '*' service.reload nginxsalt '*' service.restart nginxsalt '*' service.start nginxsalt '*' service.stop nginxsalt '*' service.staus nginx API调用： 1client.cmd('SN-2020-03-20', 'service.stop', ['nginx']) 11、其他模块 通过上面介绍的10个常用的模块，基本上已经覆盖了日常的运维操作。saltstack还提供了其他模块，如下所示： 123456789user：系统用户模块group：系统组模块partition：系统分区模块puppet：puppet管理模块system：系统重启、关机模块timezone：时区管理模块nginx：NGINX管理模块mount：文件系统挂载模块…… 更多的模块介绍请查阅官网。 四、grains组件 grains是saltstack最重要的组件之一，grains的作用是手机被控主机的基本信息，这些信息通常都是一些静态类的数据，包括CPU、内核、操作系统、虚拟化等，在服务器端可以根据这些信息进行灵活定制，管理员可以利用这些信息对不同业务进行个性化配置。官网提供的用来区分不同操作系统的示例如下（采用jinja模板）： 12345&#123;% if grains['os'] == 'Ubuntu' %&#125;host: &#123;&#123; grains['host'] &#125;&#125;&#123;% elif grains['os'] == 'CentOSu' %&#125;host: &#123;&#123; grains['fqdn'] &#125;&#125;&#123;% endif %&#125; 示例中CentOS发行版主机将被“host: {{ grains['fqdn'] }}”匹配，同时，命令行的匹配操作系统发行版本为CentOS的被控端可以通过-G参数来过滤，如salt -G ‘os:CentOS’ test.ping。 1、grains常用操作命令 匹配内核版本为3.10.0-957.el7.x86_64的主机： 123[root@192 ~]# salt -G 'kernelrelease:3.10.0-957.el7.x86_64' cmd.run 'uname -a'SN-2020-03-20: Linux 192.168.79.146 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 获取所有主机的grains项信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960[root@192 ~]# salt 'SN-2020-03-20' grains.lsSN-2020-03-20: - SSDs - biosreleasedate - biosversion - cpu_flags - cpu_model - cpuarch - domain - fqdn - fqdn_ip4 - fqdn_ip6 - gpus - host - hwaddr_interfaces - id - init - ip4_interfaces - ip6_interfaces - ip_interfaces - ipv4 - ipv6 - kernel - kernelrelease - locale_info - localhost - lsb_distrib_id - machine_id - manufacturer - master - mdadm - mem_total - nodename - num_cpus - num_gpus - os - os_family - osarch - oscodename - osfinger - osfullname - osmajorrelease - osrelease - osrelease_info - path - productname - ps - pythonexecutable - pythonpath - pythonversion - saltpath - saltversion - saltversioninfo - selinux - serialnumber - server_id - shell - systemd - virtual - zmqversion 当然，也可以获取主机单项grains数据，如获取操作系统发行版本，执行命令：salt 'SN-2020-03-20' grains.item os，结果如下所示： 12345[root@192 ~]# salt 'SN-2020-03-20' grains.item osSN-2020-03-20: ---------- os: CentOS 如果要获取主机id为“SN-2020-03-20”的所有grains键及值信息，执行以下命令： 1salt 'SN-2020-03-20' grains.items 2、定义grains数据 定义grains数据的方法有两种，其中一种为在被控主机定制配置文件，另一种是通过主 控端扩展模块API实现，区别是模块更灵活。可以通过Python编程动态定义，而配置文件 只适合相对固定的键与值，下面分别举例说明。 （1）被控端主机定制grains数据 SSH登录一台被控机，如：SN-2020-03-20，配置文件定制的路径为/etc/salt/minion.d/hostinfo.conf，具体操作如下： 12345678[root@192 ~]# vim /etc/salt/minion.d/hostinfo.confgrains: roles: - webserver - redis deployment: datacenter4 cabinet: 13[root@192 ~]# service salt-minion restart 重启被控主机salt-minion服务，使配置生效。验证结果在主控机运行：salt 'SN-2020-03-20' grains.item roles deployment cabinet，观察配置的键和值，如下所示： 12345678910[root@192 ~]# salt 'SN-2020-03-20' grains.item roles deployment cabinetSN-2020-03-20: ---------- cabinet: 13 deployment: datacenter4 roles: - webserver - redis （2）主控端主机定制grains数据 实现步骤： 1231. 首先在主控端编写Python代码，2. 然后将Python文件同步到被控主机，3. 最后刷新生效。 在主控端base目录（默认的base配置在/srv/salt）下生成_grains目录，编写Python代码，事项获取主控机系统允许最大打开文件数的grains数据。 /srv/salt/_grains/sysprocess.py 123456789101112131415161718import os,sys,commandsdef grains_openfile(): grains = &#123;&#125; _open_file = 65536 getulimit = 0 try: getulimit = commands.getstatusoutout('source /etc/profile;ulimit -n')trueif getulimit[0] == 0: _open_file = int(getulimit[1]) except Exception as e: pass grains['max_open_file'] = _open_file return grains 上面代码说明： 1231. grains_open_file()：定义一个获取最大打开文件数的函数，函数名称没有要求，符合Python的函数命名规则即可；2. grains&#123;&#125;：初始化一个grains字典，变量名一定要用grains，以便SaltStack识别；3. grains['max_open_file']=_open_file：将获取的“ulimit -n”的结果赋值给grains['max_open_file']，其中“max_open_file”就是grains的项，“_open_file”就是grains的值。 最后同步模块到指定被控端主机，并刷新生效。因为grains比较适合采集静态类数据，比如：硬件、内核信息等。当有动态类的功能需求是，需要执行刷新，具体操作如下： 1） 同步模块 12345678910111213[root@192 ~]# salt 'SN-2020-03-20' saltutil.sync_allSN-2020-03-20: ---------- beacons: grains: - grains.sysprocess modules: output: renderers: returners: sdb: states: utils: 文件被同步到控端主机的minion cache目录下，如下所示： /var/cache/salt/minion/extmods/grains/为扩展模块文件最终存放位置，刷新模块后将在同路径下生成字节码pyc； /var/cache/salt/minion/files/base/_grains/为临时存放位置。 1234567[root@192 ~]# ll /var/cache/salt/minion/extmods/grains/总用量 8-rw-------. 1 root root 362 3月 27 14:22 sysprocess.py [root@192 ~]# ll /var/cache/salt/minion/files/base/_grains/总用量 4-rw-------. 1 root root 362 3月 27 14:22 sysprocess.py 2）刷新模块 123[root@192 ~]# salt 'SN-2020-03-20' sys.reload_modulesSN-2020-03-20: True 在被控端主机的/var/cache/salt/minion/extmods/grains/位置多了一个编译后的字节码文件sysprocess.pyc。 12345678[root@192 ~]# ll /var/cache/salt/minion/extmods/grains/总用量 8-rw-------. 1 root root 362 3月 27 14:22 sysprocess.py-rw-------. 1 root root 646 3月 27 14:22 sysprocess.pyc [root@192 ~]# ll /var/cache/salt/minion/files/base/_grains/总用量 4-rw-------. 1 root root 362 3月 27 14:22 sysprocess.py 3）校验数据 12345[root@192 ~]# salt 'SN-2020-03-20' grains.item max_open_fileSN-2020-03-20: ---------- max_open_file: 65536 五、pillar组件 pillar也是Saltstack最重要的组件之一其作用是定义与被控主机相关的任何数据，定义好的数据可以被其他组件使用，如模板、state,、API等。在pillar中定义的数据与不同业务特性的被控主机相关联，这样不同被控主机只能看到自己匹配的数据，因此pillar安全性很高，适用于一些比较敏感的数据，这也是区别于grains最关键的一点。如定义不同业务组主机的用户id、组id、读写权限、程序包等信息。定义的规范是采用Python字典形式，即键/值。最上层的键一般为主机的id或组名称。下面详细描述如何进行pillar的定义和使用。 1、pillar的定义 1）主配置文件定义 Saltstack默认将主控端配置文件中的所有数据都定义到pillar中，而且对所有被控主机开放，可通过修改/etc/salt/master配置中的pillar opts: Ture或False来定义是否开启或禁用这项功能，修改后执行salt '*' pillar.data来观察效果。以主机“SN2013-08-022”为例，执行salt ‘SN2013-08-022’ pillar.data。 1234567891011[root@192 ~]# salt 'SN-2020-03-20' pillar.dataSN-2020-03-20: ---------- appname: website flow: ---------- maxconn: 30000 maxmem: 6G 2）SLS文件定义 pillar支持在sls文件中定义数据，格式须符合YAM L规范，与Saltstack的state组件十分相似，新人容易将两者混淆，两者文件的配置格式、入口文件top.sls都是一致的。下面详细介绍pillar使用sls定义的配置过程。 1. 定义pillar的主目录 修改主配置文件/etc/salt/master的pillar_roots参数，定义pillar的主目录，格式如下： 123pillar_roots: base: - /srv/pillar 同时创建pillar目录，执行命令：install -d /srv/pillar。 2. 定义入口文件top.sls 入口文件的作用一般是定义pillar的数据覆盖被控主机的有效范围，“*”代表任意主机，其中包括了一个data.sls文件，具体内容如下： /srv/pillar/top.sls 123base: '*': - data /srv/pillar/data.sls 1234appname: websiteflow: maxconn: 30000 maxmem: 6G 3. 校验pillar 通过查看&quot; SN2020-03-20”主机的pillar数据，可以看到多出了data.sls数据项，原因是我们定义top.sls时使用‘*’覆盖了所有主机，这样当查看’‘ SN2020-03-20”的pillar数据时可以看到我们定义的数据。 如果结果不符合预期，可以尝试刷新被控主机pillar数据，运行salt ’*’ saltutil.refresh_pillar即可。 123456789101112131415[root@192 ~]# salt '*' saltutil.refresh_pillarSN-2020-03-20: True[root@192 ~]# salt 'SN-2020-03-20' pillar.data appname flowSN-2020-03-20: ---------- appname: website flow: ---------- maxconn: 30000 maxmem: 6G 2、pillar的使用 完成pillar配置后，接下来介绍使用方法。 我们可以在state、模块文件中引用，模块格式为“”，例如： 12&#123;&#123; pillar['appname'] &#125;&#125; #一级字典&#123;&#123; pillar['flow']['maxconn'] &#125;&#125; #二级字典 PythonAPI格式如下： 12pillar[&#39;flow&#39;][&#39;maxconn&#39;]pillar.get(&#39;flow:appname&#39;, &#123;&#125;) 1、操作主机 123[root@192 ~]# salt -I 'appname:website' test.pingSN-2020-03-20: True 2、结合grains处理数据的差异性 首先通过结合grains的id信息来区分不同id的maxcpu的值，其次进行引用观察匹配的信息，将data.sls修改成如下形式.其中，“if … else…endfi”为jinja2的模板语法，更多信息请访问Jinja2官网语法介绍，网址为http://jinja.pocoo. org/docs/templates/。 123456789appname: websiteflow: maxconn: 30000 maxmem: 6G &#123;% if grains['id'] == 'SN-2020-03-20' %&#125; maxcpu: 8 &#123;% else %&#125; maxcpu: 4 &#123;% endif %&#125; 通过查看被控主机的pillar数据，可以看到maxcpu的差异，如下所示： 1234567891011121314151617181920212223[root@192 ~]# salt 'SN-2020-03-20' pillar.data flowSN-2020-03-20: ---------- flow: ---------- maxconn: 30000 maxcpu: 8 maxmem: 6G [root@192 ~]# salt 'SN-2020-03-21' pillar.data flowSN-2020-03-20: ---------- flow: ---------- maxconn: 30000 maxcpu: 4 maxmem: 6G 六、state介绍 state是Saltstack最核心的功能。通过预先定制好的sls (salt state file)文件对被控主机进行状态管理，支持包括程序包(pkg)、文件(file)、网络配置(network)、系统服务(service)，系统用户(user)等，更多状态对象见http://docs.sai tstack.com/ref/states/all/index.html。 1、state的定义 state的定义是通过sls文件进行描述的，支持YAML语法，定义的规则如下： 123$ID: $State: - $state: states 其中： 123$ID：定义state的名称，通常采用与描述的对象保持一致的方法，如apache, nginx等;$State：须管理对象的类型$state:states：定制对象的状态。 官网提供的示例如下： 1234567apache: pkg: - installed service: - running - require - pkg: apache 上述代码检查apache软件包是否已安装状态，如果未安装，将通过yum或apt进行安装；检查服务apache进程是否处于运行状态。下面详细进行说明: 1234567第1行用于定义state的名称，此示例为apache，当然也可以取其他相关的名称。第2行和第4行表示state声明开始，使用了pkg和service这两个状态对象。pkg使用系统本地的软件包管理器(yum或apt)管理将要安装的软件，service管理系统守护进程。第3行和第5行是要执行的方法。这些方法定义了pache软件包和服务目标状态，此示例要求软件包应当处于已安装状态，服务必须运行，如未安装将会被安装并启动。第6行是关键字require，它确保了apache服务只有在成功安装软件包后才会启动。 2、state的使用 state的入口文件与pillar一样，文件名称都是top.sls，但state要求sls文件必须存放在saltstack base定义的目录下，默认为/srv/salt。state描述配置.sls支持jinjia模板、grains、pillar引用等。在state的逻辑层次定义完成后，再通过salt ‘*’ state.highstate执行生效。 下面结合grains与pillar，实现一个根据不同操作系统类型部署apache环境的任务。 （1）定义pillar /srv/pillar/top.sls 123base: '*': - apache 在top.sls中引用二级配置有两种方式：一种是直接引用，如直接引用apache.sls；另一种是创建apache目录，再引用目录中的init.sls文件，两者的效果是一样的。为了规范起见，我们采用二级配置形式。同理，state的top.sls也采用如此方式。 1）创建apache目录： 1mkdir /srv/pillar/apache 2）在apache目录创建init.sls 内容如下： 12345678pkgs: &#123;% if grains['os_family'] == 'Debian' %&#125;trueapache: apache2 &#123;% elif grains['os_family'] == 'RedHat' %&#125;trueapache: httpd &#123;% elif grains['os'] == 'Arch' %&#125;trueapache: apache &#123;% endif %&#125; 3）测试pillar数据 1234567[root@192 ~]# salt 'SN-2020-03-20' pillar.data pkgsSN-2020-03-20: ---------- pkgs: ---------- apache: httpd （2）定义state /srv/salt/top.sls 123base: '*': - apache /srv/salt/apache/init.sls 123456789apache: pkg: - installed - name: &#123;&#123; pillar['pkgs']['apache'] &#125;&#125; service： - running - name: &#123;&#123; pillar['pkgs']['apache'] &#125;&#125; - require: - pgk: &#123;&#123; pillar['pkgs']['apache'] &#125;&#125; 在配置中，{{ pillar\\['pkgs']['apache'] }}将引用匹配到操作系统发行版对应的pillar数据，我的环境为CentOS，故将匹配为httpd，检查目标主机是否已经安装，没有则进行安装( yum -y install httpd)。同时检查apache服务是否已经启动，没有则启动(/etc/init.d/httpd start)。 （3）执行state 执行state及返回信息如下所示： 1234567891011121314151617181920212223242526272829303132333435[root@192 ~]# salt 'SN-2020-03-20' state.highstateSN-2020-03-20:---------- ID: apache Function: pkg.installed Name: httpd Result: True Comment: The following packages were installed/updated: httpd Started: 17:24:45.296375 Duration: 38108.261 ms Changes: ---------- httpd: ---------- new: 2.4.6-90.el7.centos old:---------- ID: apache Function: service.running Name: httpd Result: False Comment: The following requisites were not found: require: pgk: httpd Started: Duration: Changes: Summary------------Succeeded: 1 (changed=1)Failed: 1------------Total states run: 2 可以看出，结果返回两种对象类型结果，分别为pkg与service，执行的结果是自动部署apache 2.4.6-90环境，但是启动apache服务失败，因为“/etc/init.d/httpd start”无法执行，只能手动启动了。","path":"posts/1332.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python中Ansible模块的Playbook理解","text":"Playbook 在上一节中，我们详细介绍了Ansible提供的一些常用模块。可以看到，Ansible中的每个模块专注于某一方面的功能。虽然每个模块实现的功能都比较简单，但是，将各个模块组合起来就可以实现比较复杂的功能。在Ansible中，将各个模块组合起来的文件是一个YAML格式的配置文件。这个配置文件，在Ansible中称为Playbook。 在这一节中，我们将循序渐进地介绍Ansible中的Playbook，我们将首先介绍Playbook的定义，然后介绍如何使用Playbook完成远程服务器部署，之后详细介绍Playbook的基本语法，使用Playbook的基本讲法就能够完成大部分的部署任务。 在这一节中，找们将介绍如何使用Playbook的基本语法完成nginx与MongoDB的部署，最后，我们介绍了部分Playbook的高级语法。 1、Playbook的定义 Playbook不同于其他使用单个模块操作远程服务器，Playbook的功能更加强大。如果只使用Playbook的基本功能，那么，Playbook是一个非常简单的配、管理和部署系统。此外，Playbook也可以实现各种高级功能，如指定任务的执行顺序，委派其他主机来执行某一个任务，与监控服务器和负载均衡组件进行交互等。 有一个非常恰当的比喻,，Ansible中的模块类似于Linux下的命令，Ansible中的Playbook类似于Linux下的Shell脚本文件。Shell脚本文件将各个Linux命令组合起来，以此实现复杂的功能，Playbook将各个模块组合起来也可以实现复杂的部署功能。在shell脚本中，除了调用Linux命令以外，还有一些基本的语法，如变量定义、if语句、for循环等。在Playbook中，一方面通过YAML格式进行定义提高Playbook的可读性、可维护性，降低工程师的学习负担；另一方面，Ansible提供了若干可以应用在Playbook中的选项，以便工程师实现更加高级的功能。 一个Playbook可以包含一到多个Play，每一个Play是一个完整的部署任务。在Play中，我们需要指定对哪些远程服务器执行操作，以及对这些远程服务器执行哪些操作。 下面是一个名为first_playbook.yml的Playbook。在这个Playbook中，我们定义了两个Play，前者用来在数据库服务器上部署MongoDB，后者用来在web服务器上部署“应用”。这里只是为了对Playbook进行演示，并没有真的部署应用。 1234567891011121314151617[root@python ~]# vim first_playbook.yml---- hosts: dbservers become: yes become_method: sudo tasks: - name: install mongodb yum: name=mongodb-server state=present- hosts: webservers tasks: - name: copy file copy: src=/tmp/data.txt dest=/tmp/data.txt - name: change mode file: dest=/tmp/data.txt mode=655 owner=root group=root 这个Playbook中包含了两个Play。一个Playbook可以包含一到多个Play，所以即使Playbook中值包含一个Play，也需要使用列表的形式进行定义。在YAML语法中，“- hosts”前面的“-”表示定义列表。 在Ansible中，一个Play必须包含以下两项： 121. hosts：需要对哪些远程服务器执行操作2. tasks：需要在这些服务器上执行的任务列表 例如，对web服务器进行部署时，我们仅仅使用了hosts和tasks两个选项。前者表示对哪些服务器执行操作，后者表示对服务器执行哪些操作。在部署数据库服务器时需要安装软件，因此使用了become与become_method两个选项，用来表示使用管理员的身份去安装MongoDB数据库。 一个Play可以包含一到多个task，因此task也必须以YAML的列表形式进行定义。可以看到，在这个例子中，对数据库服务器进行操作时仅包含了一个task，对web服务器进行部署时包含了两个task。 在Ansible中，task有两种定义形式： 121. action：module options2. module：options 前一种形式是Ansible的旧版本语法，第2种形式是新版本的语法，直接使用模块的名称作为键，使用模块的参数作为值。如下所示： 12- name: install httpd yum: name=httpd update_cache=yes state=present 在安装Apache的例子中，“name=httpd update_cache=yes state=present”是一个完整的字符串，而不是一个字典。只是字符串的值是一个“key=value”形式的参数。 在参数较多时，为了增加Playbook的可读性，我们也可以像下面这样定义一个task： 12345- name: install httpd yum: &gt; name=httpd update_cache=yes state=present 在Ansible中，当参数较长时，除了使用“&gt;”进行折叠换行以外，也可以使用缩进字块的形式： 12345- name: install httpd yum: name: httpd update_cache: yes state: present 虽然从字面来看，这两种指定参数的方式相差不大。但是，从YAML的语法来说，这是完全不同的两个方法。前者是一个比较长的字符串，后者是一个字典。 task的定义中，name是可选的。所以，像下面这样定义task也是完全合法的： 1- yum: name=httpd update_cache=yes state=present name的作用在于，执行Playbook时作为注释进行显示，以便使用者知道当前执行到哪一步。因此，在定义task时，一般都会定义name字段。 在实际工作中，虽然一个Playbook可以包含多个Play，但是为了Playbook的可读性和可维护性，我们一般只会在Playbook中编写一个Play。例如，对于这里的例子，我们可以将first_playbook.yml这个Playbook拆分成两个Playbook，分别名为db.yml与web.yml。其中，db.yml文件包含了与数据库服务器相关的部署任务，web.yml文件包含了与web服务器相关的部署任务。 当我们需要部署数据库服务器和web服务器时，可以先执行db.yml文件，再执行web.yml文件。除此之外，Ansible还提供了一种便捷方式来处理这种情况。例如，我们可以编写一个名为all.yml的Playbook，它的内容如下： 123---- include: db.yml- include: web.yml include选项是Ansible提供的，用于在一个Playbook中导入其他Playbook。在Ansible中，只需要使用include选项导入其他Playbook文件，执行这个Playbook时，被导入的Playbook便会依次执行。 上面详细介绍了Ansible的Playbook定义，这个Playbook定义虽然比较简单，但是，是一个比较完整的Playbook例子。在实际工作中使用的Playbook也不会比这个Playbook复杂很多。 我们接下来将介绍如何使用ansible-playbook命令执行Playbook，然后再介绍Playbook的其他语法。 2、ansible拆分playbook.yml 查看一下所需文件是否正确 1234567891011121314[root@python ~]# cat hosts 127.0.0.1[webservers]192.168.1.60[dbservers]192.168.1.80[common:children]dbserverswebservers[root@python ~]# cat /etc/ansible/ansible.cfg [defaults]remote_user = rootremote_port = 22inventory = /root/hosts 拆分playbook.yml 12345678910111213141516171819202122[root@python ~]# cat db.yml ---- hosts: dbservers become: yes become_method: sudo tasks: - name: install mongodb yum: name=mongodb-server state=present #mongodb-server 可欢成其他服务如（git）[root@python ~]# cat web.yml ---- hosts: webservers tasks: - name: copy file copy: src=/tmp/data.txt dest=/opt/data.txt - name: change mode file: dest=/opt/data.txt mode=655 owner=root group=root[root@python ~]# cat all.yml ---- include: db.yml- include: web.yml[root@python ~]# touch /tmp/data.txt[root@python ~]# touch /opt/data.txt 3、使用Ansible-playbook执行Playbook 上一小节中，我们简单地介绍了Playbook的定义。那么，当我们有了一个Playbook文件以后，如何执行这个文件完成应用部署呢？我们知道，Ansible安装完成以后存在多个可执行的命令行工具，其中，ansible-playbook便是用于执行Playbook的命令行工具。 ansible-playbook的执行方式如下: 1ansible-playbook first_playbook.yml ansible-playbook命令也有若干命令行选项，其中,有部分选项与ansible命令相同。Ansible中也存在一些ansible-playbook特有的命令行选项。 ansible-playbook命令与ansible命令相同的命令行选项: 12345-T --timeout：建立SSH连接的超时时间--key-file --private-key：建立SSH连接的私钥文件-i --inventory-file：指定Inventory文件，默认是/etc/ansible/hosts-f --forks：并发执行的进程数，默认为5--list-hosts：playbooks匹配的服务器列表。 ansible-playbook也有一个名为–list-hosts的选项，该选项的作用是列出匹配的服务器列表。例如，在我们这个 Playbook的例子中，hosts文件的内容如下： 12345678127.0.0.1[webservers]192.168.1.60[dbservers]192.168.1.80[common:children]dbserverswebservers 我们知道，Ansible中的Play定义了需要对哪些服务器执行哪些操作，也就是说，每一个Play都可以指定匹配的远程服务器。在我们这个Playbook的例子中，对数据库服务器安装MongoDB，对web服务器部署“应用“。因此，ansible-playbook命令与ansible命令的–list-hosts选项输出的结果将会大不相同。ansible-playbook命令的–list-hosts选项输出的结果如下： 1[root@python ~]# ansible-playbook all.yml --list-hosts ansible-playbook命令有一些特有的选项，如下所示： 1234--list-tasks：列出任务列表--step：每执行一个任务后停止，等待用户确认--syntax-check：检查Playbook语法-C --check：检查当前这个Playbook是否会修改远程服务器，相当于预测Playbook的执行结果。 这里的几个选项，除了–step以外，其他几个选项都不会执行Playbook中的任务。这些选项存在主要是为了便于调试Playbook。例如，–list-tasks选项，该选项用来显示当前Playbook中的任务列表。当Playbook比较大时，可以通过这个方式快速查看任务列表。如下所示： 1234567891011[root@python ~]# ansible-playbook all.yml --list-tasksplaybook: all.yml play #1 (dbservers): dbservers TAGS: [] tasks: install mongodb TAGS: [] play #2 (webservers): webservers TAGS: [] tasks: copy file TAGS: [] change mode TAGS: [] 当我们查看任务列表时，任务的名称就是task的name字段。因此，name的定义需要具有较好的描述性，让使用者通过名字就能知道该任务需要做什么事情。 –step选项类似于编程语言中的单步调试。当我们使–step选项执行Playbook时，ansible-playbook在每一个任务之前都会停住，等侍用户输入yes,、no或continue。如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@python ~]# ansible-playbook all.yml --step[DEPRECATION WARNING]: 'include' for playbook includes. You should use 'import_playbook' instead. This feature will be removed in version 2.12. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.PLAY [dbservers] ***************************************************************Perform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: yPerform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: *********************TASK [Gathering Facts] *********************************************************ok: [192.168.1.80]Perform task: TASK: install mongodb (N)o/(y)es/(c)ontinue: yPerform task: TASK: install mongodb (N)o/(y)es/(c)ontinue: *********************TASK [install mongodb] *********************************************************changed: [192.168.1.80]PLAY [webservers] **************************************************************Perform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: yPerform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: *********************TASK [Gathering Facts] *********************************************************ok: [192.168.1.60]Perform task: TASK: copy file (N)o/(y)es/(c)ontinue: yPerform task: TASK: copy file (N)o/(y)es/(c)ontinue: ***************************TASK [copy file] ***************************************************************changed: [192.168.1.60]Perform task: TASK: change mode (N)o/(y)es/(c)ontinue: yPerform task: TASK: change mode (N)o/(y)es/(c)ontinue: *************************TASK [change mode] *************************************************************changed: [192.168.1.60]PLAY RECAP *********************************************************************192.168.1.60 : ok=3 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 192.168.1.80 : ok=2 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 输入yes以后，任务将会继续执行，并在下一个任务时停止，等待用户继续输入。当我们输入continue时，Ansible会执行完当前这个Play，当执行到下一个Play时再停止，并等待用户输入。 二、Playbook的详细语法 到目前为止，我们已经学习了如何编写Playbook以及如何运行Playbook。但是，我们仅仅介绍了最简单的Playbook。在这一节中，我们将会介绍Playbook是如何通过不同的选项提供丰富多样的功能。灵活使用这些选项，能够编写出形式各异的Playbook，以此应对自动部署中的各种情况。 在定义Play时，只有hosts与tasks是必选选项，其他选项都是根据需要添加的。在这一小节中。我们将介绍Playbook提供的不同功能，以Playbook的功能为线索，介绍Play与task中可以使用的选项。 （1）权限 在Ansible中，默认使用当前用户连接远程服务器执行操作。我们也可以在anaible.cfg文件中配置连接远程服务器的默认用户。此外，如果是不同的用户使用不同类型的远程服务器，那么也可以在Playbook的Play定义中指定连接远程服务器的用户。例如，我们可以指定执行Play的用户： 123---- hosts: webservers remote_user: root 用户可以细分每一个task，如下所示： 1234567---- hosts: werbservers remote_user: root tasks: - name: test connection ping: remote_user: yourname 很多时候，我们需要的不是以某个特定用户连接远程服务器，而是在需要更高级别的权限时，使用管理员身份去执行操作。在ansible中，可以通过become与become_ method选项实现： 1234---- hosts: werbservers remote_user: root become: yes 与remote_user选项类似，我们也可以为单个任务使用管理员权限，如下所示： 12345678---- hosts: werbservers remote_user: yourname tasks: - name: installed nginx service: name=nginx state=started become: yes become_method: sudo 实例 先修改远程服务器中test的权限为（0:0） 123456789101112131415161718192021222324[root@192 ~]# vim /etc/passwdtest:x:0:0::/home/test:/bin/bash[root@python ~]# chown test:root /etc/ansible/*[root@python ~]# su test[test@python root]$ cd [test@python ~]$ vim hosts[db]192.168.1.60[test@python ~]$ vim db.yml---- hosts: db remote_user: root #远程服务器登陆的用户 tasks: - name: installed nginx become: yes become_method: sudo ping: remote_user: root #远程服务器登陆的用户[test@python ~]$ vim /etc/ansible/ansible.cfg [defaults]inventory = /home/test/hosts 执行一下 12345678910111213141516171819202122232425[test@python ~]$ sudo ansible-playbook db.yml --stepWe trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility.[sudo] password for test: PLAY [db] **********************************************************************Perform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: yPerform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: *********************TASK [Gathering Facts] *********************************************************Enter passphrase for key '/root/.ssh/id_rsa': ok: [192.168.1.60]Perform task: TASK: installed nginx (N)o/(y)es/(c)ontinue: Perform task: TASK: installed nginx (N)o/(y)es/(c)ontinue: *********************PLAY RECAP *********************************************************************192.168.1.60 : ok=1 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 （2）通知 在Ansible中，模块是幂等的。例如，我们要在远程服务器上创建一个用户，如果该用户已经存在，那么Ansible不会将该用户删除以后重新创建，而是直接返回成功，并通过changed字段表示是否对远程服务器进行了修改。 考虑这样一种需求：我们要通过Ansible修改Apache的配置文件，并重启Apache服务，使得新的配置文件生效。由于Ansible的模块是幂等的，当我们修改Apache的配置文件时，如果配置文件的内容已经与我们想要修改成的内容一样（例如，不小心将Ansible执行了两次的情况），那么，Ansible就什么也不做。既然Apache的配置文件并没有真的被修改，那么我们也不应该去重启Apache的服务器。在Ansible中，通过notify与handler机制来实现这里的功能。 在下面的例子中，我们首先尝试安装Apache，然后修改Apache的配置文件。如果配置文件被修改，则通过notify选项通知handler进行后续处理。 handler是Ansible提供的条件机制，与tasks比较类似，都是去执行某些操作。但是，handler只有在被notify触发以后才会执行，如果没有被触发则不会执行。在Playbook中，如果task后面存在notify选项，那么，当Ansible识别到task改变了系统的状态，就会通过notify去触发handler。 Ansibie是通过什么条件判断notify触发的是哪一个handler呢？很简单，在Ansible中，task使用handler的名字作为参数，以此来触发特定的handler。例如，在我们这里的例子中，notify触发的是“restart apache&quot;这个handler, handlers中也存在一个名为&quot; restart apache“的handler。 1234567891011121314151617---- hosts: webservers tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 需要注意的是，handler只会在所有task执行完后执行。并且，即便一个handler被触发多次，它也只会执行一次。handler并不是在被触发时立即执行，而是按照Play中定义的顺序执行。一般情况下，handler都位于Play的最后，即在所有任务执行完成以后再执行。 Ansible官方文档提到handler的唯一用途，就是重启服务与服务器，正如找们这个例子所演示的。 在这个例子中，我们还用到T了template模块。template模块用以渲染Jinja模板。 （3）变量 在Inventory管理章节，我们已经介绍了如何定义变量。在Ansible中，还有其他几种定义变量的方式。对于简单的Playbook，最直接的方式是将变量定义在Playbook的vars选项中。如下所示： 123- hosts: dbservers vars: mysql_port: 3307 在Playbook中定义变量，可以在模板渲染时使用。例如：Ansible官方给出的例子中，MySQL配置文件的部分模板如下： 12345[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockuser=mysqlport=&#123;&#123; mysql_port &#125;&#125; 当变量较少的时候，定义在vars选项中完全没有问题。当变量较多时，可以将变量保存在一个独立的文件中，并通过vars_files选项引用该文件。如下所示： 12345678910---- hosts: all vars: favcolor: blue vars_files: - /vars/external_vars.yml tasks: - name: this is just a placeholer command: /bin/echo foo 保存变量的文件是一个简单的YAML格式的字典，如下所示： 1234---# in th above example, this would be vars/external_vars.ymlsomevar: somevaluepassword: magic 在shell脚本中，我们可以通过获取上一条命令的返回码判断命令是否执行成功。在Ansible中，我们也可以获取任务的执行结果，将任务的执行结果保存在一个变最中，并在之后引用这个变量。这样的变量在Ansible中使用register选项获取，也称为注册变量。 例如，在下面这个例子中，我们首先执行/usr/bin/foo命令，并通过register选项获取命令的执行结果，将结果保存在foo_result中。在之后的task中，使用这个变量名引用/usr/bin/foo命令的执行结果。 12345678- hosts: web_servers tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True - shell: /usr/bin/bar when: foo_result == 5 这个例子还涉及了两个新的选项，分别是ignore_errors与when。前者表示忽略当前task中的错误，后者是一个条件语句，只有条件为真时才会执行这个task。 （4）Facts变量 在Ansible中，还有一些特殊的变量，这些变量不需要我们进行任何设置就可以直接使用，这样的变量称为Facts变量。Facts变量是Ansible执行远程部署之前从远程服务器中获取的系统信息，包括服务器的名称、IP地址、操作系统、分区信息、硬件信息等。Facts变量可以配合Playbook实现更加个性化的功能需求。例如，将MongoDB数据库的数据保存在/var/mongo-&lt;hostname&gt;/目录下。 我们可以通过setup模块查看Facts变量的列表，如下所示： 1ansible all -m setup 有了Facts变量以后，如何在Ansible中使用它们呢？答案是直接使用。我们可以在Playbook中直接通过变量的名字引用变量，也可以在Jinja2模板中通过变量的名字引用变量。下面是一个名为test_facts.yml的Playbook。在这个Playbook中，我们输出了操作系统的类型，并且只有在操作系统为“RedHat&quot;类操作系统时才会执行安装操作。 1234567891011---- hosts: dbservers tasks: - shell: echo &#123;&#123; ansible_os_family &#125;&#125; register: myecho - debug: var=myecho.stdout_lines - name: install git on Red Hat Linux yum: name=git state=installed when: ansible_os_family == \"RedHat\" setup模块为了输出结果的可读性，对模块的输出进行了归类和整理。因此，当我们要访问复杂变量的子属性时，需要使用嵌套结构。例如，我们可以通过下面两种方式访问Ansible中的ipv4地址： 12ansible_ens33['ipv4']['address']ansible_ens33.ipv4.address 访问复杂的变量的Playbook： 12345678910111213---- hosts: dbservers gather_facts: yes tasks: - shell: echo &#123;&#123; ansible_ens33['ipv4']['address'] &#125;&#125; register: myecho - debug: var=myecho.stdout_lines - shell: echo &#123;&#123; ansible_ens33.ipv4.address &#125;&#125; register: myecho - debug: var=myecho.stdout_lines 在实际工作中，我们一般会在Jinja2模板中引用Facts变量。使用方式与这里的例子一样，为了节省篇幅就不再赘述了。 在Playbook中，可以通过gather_ facts选项控制是否收集远程服务器的信息。该选项默认取值为yes，如果确定不需要用到远程服务器的信息，可以将该选项设置为no，以此提高Ansible部署的效率。如下所示： 1234---- hosts: dbservers gather_factes: no tasks: （5）循环 1234567- name: Install Mysql package yum: name=&#123;&#123; item &#125;&#125; state=installed with_items: - mysql-server - MySQL-python - libselinux-python - libsemanage-python （6）条件 有时候，一个任务是否执行取决于一个变量的取值，或者上一个任务的执行结果，这个时候找们就需要条件语句。再或者说，在循环的时候想要跳过一些特定的元素，在服务器部署时只对某些特定的操作系统进行操作。所有这些行为都可以使用条件语句解决。Ansible的Playbook不是一门编程语言，因此没有相应的条件语句，不过Ansible提供了一个类似的选项。 在Playbook中可以通过when选项执行条件语句，when就类似于编程语言中的if语句。 下面是一个简单的when选项使用示例： 12345# 查看Linux系统版本：cat /etc/redhat-releasetasks: - name: \"系统关机\" command: /sbin/shutdown -t now when: ansible_os_family == \"RedHat\" when选项也支持多个条件语句，下面是一个YAML格式的多条件： 123456tasks: - name: \"shutdown CentOS 7 systems\" command: /sbin/shutdown -t now when: - ansible_distribution == \"CentOS\" - ansible_distribution_major_version == \"7\" 对于更复杂的条件可以使用and、or与括号进行定义： 1234tasks: - name: \"shutdown CentOS 7 and Debian 6 systems\" command: /sbin/shutdown -t now when: (ansible_distribution == \"CentOS\" and ansible_distribution_major_version == \"7\") or (ansible_distribution == \"Debian\" and ansible_distribution_major_version == \"6\") 在when选项中可以读取变量的取值，例如： 123456vars: epic: truetasks: - shell: echo \"This certainly is epic!\" when: epic when选项可以与循环一起使用，以实现过滤的功能： 1234tasks: - command: echo &#123;&#123; item &#125;&#125; with_items: [0, 2, 4, 6, 8, 10] when: item &gt; 5 （7）任务执行策略 在Ansible中，Playbook的执行是以task为单位进行的。Ansible默认使用5个进程对远程服务器执行任务。在默认情况的任务执行策略( linear)中，Ansible首先执行task1，并且等到所有服务器执行完task1以后再开始执行task2，以此类推。从Ansible 2.0开始，Ansible支持名为free的任务执行策略，允许执行较快的远程服务器提前完成Play的部署，不用等待其他远程服务器一起执行task。如下所示： 1234- hosts: all strategy: free tasks: …… 在这一节中，我们比较详细地介绍了Ansible中的Playbook选项。在Ansible中，Play与task都有很多选项，每个选项可以实现不同的功能。Ansibie官方并没有通过功能的形式介绍不同的选项给出一个完整的选项列表。我们也可以参考https://github.com/lorin/ansible-quickref快速了解Play与task中的选项，以及各个选项的含义。 4、案例：使用Playbook部署nginx 12wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo//下载源 在这个例子中，我们使用Ansible配置一台服务器运行nginx进程。部署nginx的Playbook如下： 12345678910111213141516171819202122232425---- hosts: webservers become: yes become_method: sudo vars: worker_prosess: 4 worker_connections: 768 max_open_files: 65506 tasks: - name: install nginx yum: name=nginx update_cache=yes state=present - name: copy nginx config file template: src=/root/test_ansible/nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: restart nginx - name: copy index.html template: src: /root/test_ansible/index.html.j2 dest: /usr/share/nginx/www/index.html mode: 0644 notify: restart nginx handlers: - name: restart nginx service: name=nginx state=restarted 在这个Playbook中，我们首先通过hosts选项指定了要对哪些远程服务器执行操作。随后，我们通过become与become_method选项声明了部署时使用sudo权限。接下来，我们在vars字段中定义了三个变量，这三个变量将用在nginx的配置文件中。我们在tasks选项下定义了部署nginx服务的任务列表，包括软件安装、模板渲染、定制s首页和重启nginx进程。 为了避免配置文件在没有任何修改的情况下重启了nginx进程，这里使用了Ansible的handler机制。在这个Playbook中，存在两个notify选项，以及一个handler选项。无论是nginx的配置文件，还是定制首页发生了修改，我们都会重启nginx进程。由于我们使用了Ansible的handlers机制，因此，在没有任何修改的情况下，Ansible并不会重启nginx进程。使用handler机制还有一个好处，notify多次，handler也只会执行一次，避免了反复多次重启nginx进程。 在这个部署nginx服务的Playbook中，我们用到了nginx.conf.j2这个配置模板。这个模板使用的是Jinja2的语法，所以后缀名为j2。模板的内容如下： 12345678910111213141516171819202122232425[root@python ~]# mkdir test_ansible[root@python ~]# vim /root/test_ansible/nginx.conf.j2worker_processes &#123;&#123; worker_prosess &#125;&#125;;worker_rlimit_nofile &#123;&#123; max_open_files &#125;&#125;;events &#123; worker_connections &#123;&#123; worker_connections &#125;&#125;;&#125;http &#123;trueserver &#123; listen 80;truetruetruetruelisten 443 ssl;truetrue server_name localhost;truetrue location / &#123; root /usr/share/nginx/www; index index.html index.htm;truetruetruetruetruetruetr_files $uri $uri/ =404; &#125; &#125;&#125; Ansible会使用我们在Playbook的vars字段中定义的变量，将Jinja2模板渲染成真实的配置文件。 我们的Playbook还用到了一个名为index.html.j2的模板，该模板用于渲染网站首页。index.html.j2的内容如下： 12345678910111213[root@python ~]# vim /root/test_ansible/index.html.j2&lt;html&gt; &lt;meta charset=\"utf-8\"&gt;true&lt;head&gt;truetrue&lt;title&gt;wellcome to ansible&lt;/title&gt;true&lt;/head&gt;true&lt;body&gt;truetrue&lt;h1&gt;nginx, configured by ansible&lt;/h1&gt;truetrue&lt;p&gt;如果你能看到这个页面，说明ansible自动部署nginx成功了！&lt;/p&gt;truetruetruetrue&lt;p&gt;&#123;&#123; ansible_hostname &#125;&#125;&lt;p&gt;true&lt;/body&gt;&lt;/html&gt; 在index.html.j2中，我们用到了一个名为ansible_hostname的变量。这个变量是Facts变量，是Ansible在执行Playbook之前从远程服务器获取到的信息。因此，我们不需要定义，直接使用即可。 有了Playbook以后，使用ansible-playbook命令进行部署。如下所示： 1234567891011121314151617181920212223242526[root@python ~]# pip install Jinja2[root@python ~]# vim /etc/ansible/ansible.cfg [defaults]inventory = /root/hosts[root@bogon ~]# ansible-playbook nginx.ymlPLAY [webservers] **********************************************************************************************************TASK [Gathering Facts] *****************************************************************************************************ok: [127.0.0.1]TASK [install nginx] *******************************************************************************************************ok: [127.0.0.1]TASK [copy nginx config file] **********************************************************************************************ok: [127.0.0.1]TASK [copy index.html] *****************************************************************************************************ok: [127.0.0.1]PLAY RECAP *****************************************************************************************************************127.0.0.1 : ok=4 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 [root@bogon ~]# 如果安装失败，可能是端口被占用，可以停止使用该端口的服务，或者更改nginx端口。 1234567891011121314151617181920[root@bogon ~]# netstat -ntlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1/systemd tcp 0 0 0.0.0.0:6000 0.0.0.0:* LISTEN 7470/X tcp 0 0 192.168.122.1:53 0.0.0.0:* LISTEN 7654/dnsmasq tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 7337/sshd tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN 7340/cupsd tcp 0 0 127.0.0.1:6010 0.0.0.0:* LISTEN 31653/sshd: root@pt tcp 0 0 127.0.0.1:6011 0.0.0.0:* LISTEN 31653/sshd: root@pt tcp 0 0 127.0.0.1:6012 0.0.0.0:* LISTEN 31653/sshd: root@pt tcp6 0 0 :::111 :::* LISTEN 1/systemd tcp6 0 0 :::80 :::* LISTEN 17867/httpd tcp6 0 0 :::6000 :::* LISTEN 7470/X tcp6 0 0 :::22 :::* LISTEN 7337/sshd tcp6 0 0 ::1:631 :::* LISTEN 7340/cupsd tcp6 0 0 ::1:6010 :::* LISTEN 31653/sshd: root@pt tcp6 0 0 ::1:6011 :::* LISTEN 31653/sshd: root@pt tcp6 0 0 ::1:6012 :::* LISTEN 31653/sshd: root@pt [root@bogon ~]# systemctl stop httpd.service 第二台服务器启动一下nginx 12345678910[root@192 ~]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful[root@192 ~]# nginxnginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] still could not bind() 浏览器访问一下","path":"posts/1331.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python自动化管理Ansible","text":"一、Ansible介绍 Ansible是一个简单的自动化运维工具，可完成配置管理、应用部署、服务编排以及其他各种IT需求。Ansible也是一款基于Python语言实现的开源软件，其依赖Jinja2、paramiko和PYYAML这几个Python库。 1Ansible的作者是Michael Dehaan，Michael Dehaan同时也是知名软件Cobber的作者和Func的共同作者。Michael Dehaan与2012年创建了AnsibleWorks公司，之后改名为Ansible公司。Ansible公司与2015年10月被红帽公司（Red Hat）收购。 在这一小节，我们将首先介绍Ansible的优点，然后比较Ansible与Fabric之间的差异。 1、Ansible的优点 Ansible作为配置工具，通常与Puppet、Chef、Saltstack进行比较，如下所示： 工具 发布时间 语言 架构 协议 Puppet 2005年 Ruby C/S http Chef 2008年 Ruby C/S http Saltstack 2012年 Python C/S（可无Client） ssh/zmq/raet Ansible 2013年 Python 无Client ssh 从发布时间来看，Ansible完全没有优势，那么，是什么特性让Ansible进入了工程师的视野，并且逐步获得青睐呢？我们需要了解一下Ansible有哪些优点。 Ansible具有以下几个优点： （1）部署简单 1只需要在主控端部署Ansible环境，被控端无须做任何操作。换句话说，在安装Ansible时，远程服务器无烦安装任何依赖。因此，相对于其他配置管理器，Ansible安装部署非常简单，省去了客户端的安装。在数千台规模的大型数据中心意味着少了一些路由和安全策略的配置，省去了很多不必要的麻烦。 （2）基于ssh进行配置管理，充分利用现成的机制 1Ansible不依赖与客户端，直接使用ssh进行配置管理，在Ansible早期版本中，默认使用paramiko进行配置管理，从Ansible1.3版本开始，Ansible默认使用OpenSSH实现个服务器间通信。 （3）Ansible不需要守护进程 1因为Ansible依赖OpenSSH进行通信，不需要安装客户端，因此服务端也不需要像其他配置管理一样使用一个守护进程。Ansible的安装和维护都变得更加简单，系统更加安全可靠。 （4）日志集中存储 1所有操作日志都存储在Ansible发起服务器，可以采用自定义的格式，这样可以很方便地知晓哪些服务器操作有问题，哪些已经成功，也便于日后追溯。 （5）Ansible简单易用 1Ansible和其他配置管理工具一样，运行一个部署命令就可以完成应用部署，使用非常简单。此外，Ansible使用YAML语法管理配置，YAML本身是一种可读性非常强的标记语言，工程师几乎像阅读英文一样阅读YAML的配置文件。因为Ansible使用YAML管理配置，所以使用Ansible不需要使用者具有任何编程背景。运维自动化工具本身是用来简化运维工作的，如果本身比较复杂（如Puppet），甚至需要一定的程序开发能力，那么就会增加使用者的使用难度和犯错的概率。 （6）Ansible功能强大 1Ansible通过模块来实现各种功能，目前，Ansible已经有了950多个模块，工程师也可以使用任何语言编写自定义的Ansible模块。 （7）Ansible设计优秀，便于分享 1Ansible使用role组织Playbook，并提供了分享role的平台（galaxy.ansible.com），便于大家分享和复用。充分使用role，可以编写可读性更强的配置文件。使用开源的role，能够有效节省编写Playbook的时间。 （8）Ansible对云计算和大数据平台都有很好的支持 1从Ansible的模块列表可以看到，Ansible包含了大量与云服务、AWS、OpenStack、Docker等相关的模块。并且，Ansible便于扩展，当出现新事务时可以根据需要编写自定义的模块。 Ansible作为自动化系统运维的一大利器，在构建整个体系过程中有着举足轻重的地位。其简单易用、易于安装、功能强大、便于分享、内含大量模板等都是它的魅力所在，再加上易封装、接口调用方便，Ansible正在被越来越多的大公司采用。 2、Ansible与Fabric之间的比较 简单来说，Fabric像是一个工具箱，提供了很多好用的工具，用于在远程服务器执行命令。而Ansible则提供了一套简单的流程，只需要按照它的流程来做就能轻松完成任务。这就像是库和框架的关系一样，其中，Fabric是库，Ansible是框架。 （1）Fabric与Ansible之间的共同点 121.都是基于paramiko开发；2.都使用ssh和远程服务器通讯，不需要在远程服务器上安装客户端。 （2）Fabric与Ansible之间的主要区别 123451. Fabric简单，Ansible复杂。因此，Fabric学习成本低，Ansible的学习成本高；2. Fabric通过ssh执行简单的命令，Ansible将模块拷贝到远程服务器后执行，执行完成以后删除模块；3. 使用Fabric需要具有Python编程背景，使用Ansible则不需要；4. Fabric对常用的管理操作和ssh连接操作进行了封装，工程师通过编写简单的代码就能完成要做的事情。Ansible不需要工程师编写任何代码，直接编写YAML格式的配置文件来描述要做的事情；5. Fabric提供了基本的接口，业务逻辑需要用户自己实现；Ansible提供了大量的模块，用户只需要学习模块的用法即可完成复杂的任务。 二、Ansible使用入门 在这一小节我们介绍Ansible的安装与基本使用，然后在接下来的章节中介绍Ansible的高级用法。 ansible使用原则： 确定要操作哪些服务器（服务器列表） 确定对这些服务器进行什么样的操作（命令） 关于hosts文件： 默认读取/etc/ansible/hosts文件 通过命令行参数-i指定hosts文件 通过/etc/ansible/ansible.cfg里面的inventory选项指定hosts文件 1、安装Ansible Ansible不需要安装客户端，因此，相对于其他配置管理工具，Ansible的安装简单得多，只需要在控制端安装Ansible即可。Ansible使用Python语言开发，我们可以直接使用pip进行安装，也可以使用Linux下的包管理工具(如yumI、apt-get)进行安装。如下所示: 1[root@python ~]# pip3 install ansible 检查Ansible是否安装成功，如下所示： 1234567[root@python ~]# ansible --versionansible 2.9.9 config file = /etc/ansible/ansible.cfg configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Aug 7 2019, 00:51:29) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] Ansible依赖Python与SSH，因此服务器需要安装SSH和Python 2.5或2.5以上版本的Python。SSH和Python是大多数操作系统中默认安装的软件，这进一步降低了Ansible安装部署的难度。除了SSH和Python以外，服务器端不需要再预装任何软件。在控制端（Ansible命令运行的那台机器）需要安装Python 2.6或更高版本的Python程序，且Ansible的控制端只能运行在Linux下。 与其他库和工具不同的是，Ansible包含了多个工具。安装完Ansible以后，控制端会增加以下几个可执行程序： 1234567ansibleansible-docansible-playbookansible-vaultansible-consoleansible-galaxyansible-pull 这些可执行程序将在之后使用时进行详细介绍。 2、Ansible的架构 为了更好的理解Ansible，在介绍Ansible的使用之前，我们先看一下Ansible的架构图，如下所示： 在Ansible中，用户通过编排引擎操作主机。其中，主机可以通过配置文件配置，调用云计算的接口获取，或者访问CMDB中的数据库。Ansible的编排引擎有Inventory、API、Modules（模块）和Plugins组成。Ansible的典型用法是：工程师将需要远程服务器执行的操作写在Ansible Playbook中，然后使用Ansible执行Playbook中的操作。 3、Ansible的运行环境 使用Ansible操作远程服务器时，首先需要确定的是操作哪些服务器，然后再确定对这些服务器执行哪些操作。 Ansible会默认读取/etc/ansible/hosts文件中配置的远程服务器列表。在我们这一小节，/etc/ansible/hosts文件内容如下： 123456[root@python ~]# mkdir /etc/ansible[root@python ~]# vim /etc/ansible/hosts[test]127.0.0.1192.168.1.80 Ansible中存在一个名为ping的模块，该模块并不是测试服务器的网络是否连接，而是尝试建立SSH连接，以便验证用户的SSH是否已经正确配置。如下所示： 1[root@python ~]# ansible test -m ping 修改test的权限 12345678[root@python ~]# chmod 755 /etc/sudoers[root@python ~]# vim /etc/sudoerstest ALL=(ALL) ALL #92行左右添加[root@python ~]# vim /etc/ansible/hosts[test]127.0.0.1 ansible_user=root ansible_port=22192.168.1.80 再次测试一下 1root@python ~]# ansible test -m ping 常见错误解决方案如下： （1）ansible管理节点生成ssh-key 1[root@192 ~]# ssh-keygen 执行成功后，将会在~/.ssh目录下生成2个文件：id_rsa和id_rsa.pub （2）添加目标节点的ssh认证信息 12[root@192 ~]# ssh-copy-id root@47.100.98.242[root@192 ~]# ssh-copy-id root@192.168.79.133 （3）测试 123456789101112131415[root@192 ~]# ansible test -m ping192.168.79.133 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125;47.100.98.242 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125; Ansible默认使用当前用户和默认的22端口号与远程服务器建立SSH连接。如果需要使用其他用户，或者使用非默认的SSH端口号，可以在host之后增加用户名和端口号的配置。如下所示： 1234[root@192 ~]# cat &#x2F;etc&#x2F;ansible&#x2F;hosts[test]192.168.79.133 ansible_user&#x3D;test ansible_port&#x3D;2247.100.98.242 ansible_user&#x3D;laoyu ansible_port&#x3D;80 一般情况下，工作环境的服务器ssh用户名和ssh端口号都是相同的。如果我们有很多的远程服务器，每一台服务器都需要配置ansible_user或ansible_port参数，如果依然使用前面的配置方式进行配置，会显得非常冗余。对于这种情况，可以在Ansible配置文件中修改相应的配置。 Ansible默认使用/etc/ansible/ansible.cfg文件，我们可以在ansible.cfg中设定一些默认值，这样就需要对同样的内容输入多次。如下所示： 1234[root@192 ~]# cat /etc/ansible/ansible.cfg[defaults]remote_port = 2090remote_user = test 4、Ansible的ad-hoc模式 ping模块是Ansible中最简单的模块，而command模块则是工程师最熟悉的模块。command模块的作用非常简单，就是在服务器中执行shell命令。在Ansible中，通过-m参数指定模块名称，通过-a参数指定模块的参数。因此，使用command模块在远程服务器执行shell命令的语句如下： 12345678910[root@python ~]# ansible test -m command -a \"hostname\"127.0.0.1 | CHANGED | rc=0 &gt;&gt;python192.168.1.80 | CHANGED | rc=0 &gt;&gt;python[root@python ~]# ansible test -m command -a \"whoami\"192.168.1.80 | CHANGED | rc=0 &gt;&gt;root127.0.0.1 | CHANGED | rc=0 &gt;&gt;root command是Ansible中的默认模块，当我们省略-m参数时，默认使用command模块。如下所示： 12345[root@python ~]# ansible test -m command -a \"whoami\"192.168.1.80 | CHANGED | rc=0 &gt;&gt;root127.0.0.1 | CHANGED | rc=0 &gt;&gt;root 大部分情况下，Ansible的模块包含多个参数，参数使用“key=value”的形式表示，各个参数之间使用空格分隔。如下所示： （1）创建ansible.cfg文件 1234[root@python ~]# vim /etc/ansible/ansible.cfg[defaults]remote_port = 22remote_user = root 再次测试一下 1[root@python ~]# ansible test -m ping 1[root@python ~]# ansible test -m command -a \"hostname\" （2）将本地文件拷贝到服务器 12345[root@python ~]# cd /tmp/[root@python tmp]# mkdir abc[root@python tmp]# cd abc/[root@python abc]# lsnginx.conf restart.sh #要拷贝的文件 进行拷贝 1[root@python abc]# ansible test -m copy -a \"src=/tmp/abc/nginx.conf dest=/opt/nginx.conf\" 查看一下是否有拷贝的文件 12[root@python abc]# ls /opt/ | grep nginx.confnginx.conf &lt;1&gt;创建剧本（拷贝） 1234567891011121314[root@python abc]# vim test_playbook.yml---- hosts: test become: yes #是否支持root权限 become_method: sudo tasks: #任务 - name: copy file #描叙 copy: src=/opt/nginx.conf dest=/tmp/abc/nginx.conf #拷贝的 - name: package install #描叙 yum: name=&#123;&#123;item&#125;&#125; state=present #安装的 with_items: - tmux 执行一下 1[root@python abc]# ansible-playbook test_playbook.yml 查看是否有拷贝的文件 12[root@python abc]# ls | grep nginx.conf nginx.conf （3）在远程服务器中安装软件 1[root@python abc]# ansible test -m yum -a \"name=tmux state=present\" -become 5、使用playbook控制服务器 前面通过Ansible命令执行操作的方式，称为ad-hoc。我们可以使用ad-hoc来执行非常简单的操作，也可以使用ad-hoc的方式来学习模块的使用方式。但是，在实际的生产环境中，我们一般将远程服务器需要做的事情写在一个YAML配置文件中。 例如，将本地文件拷贝到远程服务器并修改文件所有者，然后安装软件的功能，写在YAML的配置文件中以后，其内容如下： 1234567891011121314151617[root@192 ~]# cat test_playbook.yml---- hosts: test become: yes become_method: sudo tasks:true- name: copy file copy: src=~/s.txt dest=/opt/s.txttruetrue- name: change mode file: dest=/opt/s.txt mode=500 owner=root group=roottruetrue- name: ensure packages installed yum: name=&#123;&#123;item&#125;&#125; state=presenttrue with_items:true - gittrue - tmux 这个YAML文件称为Ansible Playbook。Playbook中首先包含了一些声明信息，如hosts关键字声明该Playbook应用的服务器列表，become和become_method表示在远程服务器通过sudo执行操作。Playbook最后包含了若干个task，每一个task对应于前面的一条ad-hoc命令。具体执行时，多个task按序执行。如果你不能完全理解YAML文件，现在只需要对Ansible的执行方式有一个认识即可。后续小节将会详细讲解如何编写Ansible Playbook。 有了Playbook以后，通过ansible-playbook命令执行，如下所示： 1234567891011121314151617181920212223242526272829303132[root@192 ~]# ansible-playbook test_palybook.ymlPLAY [test] ****************************************************************************************************************TASK [Gathering Facts] *****************************************************************************************************ok: [47.100.98.242]ok: [127.0.0.1]TASK [copy file] ***********************************************************************************************************ok: [127.0.0.1]ok: [47.100.98.242]TASK [change mode] *********************************************************************************************************ok: [127.0.0.1]ok: [47.100.98.242]TASK [ensure packages installed] *******************************************************************************************[DEPRECATION WARNING]: Invoking \"yum\" only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying `name: \"&#123;&#123;item&#125;&#125;\"`, please use `name: ['git', 'tmux']` and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.[DEPRECATION WARNING]: Invoking \"yum\" only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying `name: \"&#123;&#123;item&#125;&#125;\"`, please use `name: ['git', 'tmux']` and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.changed: [47.100.98.242] =&gt; (item=['git', 'tmux'])changed: [127.0.0.1] =&gt; (item=['git', 'tmux'])PLAY RECAP *****************************************************************************************************************127.0.0.1 : ok=4 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 47.100.98.242 : ok=4 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 [root@desktop-kh5f5dc ~]# 上面这条命令的效果与上一小节中多条ad-hoc命令的效果是一样的。关于YAML的语法，如何编写playbook以及模块的使用方式等，将在本章的后续小节中进行详细讲解。在这一小节中，我们只需要知道Ansible有两种操作远程服务器的方式，分别是：ad-hoc与Playbook。 三、Inventory管理 在Ansible中，将可管理的服务器的集合称为Inventory。因此，Inventory管理便是服务器管理。这一节中，我们将会详细讨论Inventory管理。 1、hosts文件位置 我们已经演示了Ansible如何对远程服务器执行操作，可以看到，Ansible在执行操作是，首先需要确定对哪些服务器执行操作。默认情况下，Ansible读取/etc/ansible/hosts文件中的服务器配置，获取需要操作的服务器列表。Ansible定义与获取服务器列表的方式比这个要灵活得多。 在Ansible中，有3种方式制定hosts文件，分别是： 默认读取/etc/ansible/hosts文件； 通过命令行参数-i指定hosts文件； 通过ansible.cfg文件中的inventory选项（老版本的Ansible中通过hostfile选项指定）指定hosts文件。 例如：当前系统中除了/etc/ansible/hosts文件以外，在test用户的home目录下也存在一个名为hosts的文件，该hosts文件的内容如下所示： 123[test]127.0.0.1192.168.1.80 使用/etc/ansible/hosts文件 1234[root@python ~]# ansible test --list-hosts hosts (2): 127.0.0.1 192.168.1.80 -i选项指定hosts文件 1234[root@python ~]# ansible test -i hosts --list-hosts hosts (2): 127.0.0.1 192.168.1.80 修改ansible.cfg文件，添加inventory选项，指定hosts文件的路径 123456[root@python ~]# vim /etc/ansible/ansible.cfg [defaults]remote_user = rootremote_port = 22inventory = /etc/ansible/hosts 2、灵活定义hosts文件内容 （1）分组定义服务器 12345678[root@python ~]# vim /etc/ansible/hosts [demo]127.0.0.1[xgp]192.168.1.80[wsd]192.168.1.60 1）查看单个分组的服务器列表 1234567891011121314[root@python ~]# ansible demo --list-hosts hosts (1): 127.0.0.1[root@python ~]# ansible xgp --list-hosts hosts (1): 192.168.1.80[root@python ~]# ansible wsd --list-hosts hosts (1): 192.168.1.60[root@python ~]# ansible all --list-hosts hosts (3): 127.0.0.1 192.168.1.80 192.168.1.60 2）查看多个分组的服务器列表（冒号分隔组名） 1234[root@python ~]# ansible xgp:wsd -i hosts --list-hosts hosts (2): 192.168.1.80 192.168.1.60 3）使用all和星号匹配服务器 123456[root@python ~]# ansible '*' -i hosts --list-hosts[root@python ~]# ansible 'all' -i hosts --list-hosts hosts (3): 127.0.0.1 192.168.1.60 192.168.1.80 （2）Ansible定义组匹配服务器 12345678910[root@python ~]# vim hosts[demo]127.0.0.1[xgp]192.168.1.80[wsd]192.168.1.60[common:children]xgpwsd 查看服务器列表 1234[root@python ~]# ansible common -i hosts --list-hosts hosts (2): 192.168.1.80 192.168.1.60 （3）批量定义服务器 12345678910111213[root@python ~]# vim hosts[demo]127.0.0.1[xgp]192.168.1.80[1:3].xgp.top[wsd]192.168.1.60[a:d].xgp.top[common:children]xgpwsd 查看服务列表 1234567891011[root@python ~]# ansible xgp:wsd -i hosts --list-hosts hosts (9): 192.168.1.80 1.xgp.top 2.xgp.top 3.xgp.top 192.168.1.60 a.xgp.top b.xgp.top c.xgp.top d.xgp.top 3、灵活匹配hosts文件内容 Ansible还支持通配符和正则表达式等更灵活的方式来匹配服务器。 Ansible官方给出了ansible命令的语法格式： 1ansible &lt;pattern_goes_here&gt; -m &lt;module_name&gt; -a &lt;arguments&gt; 例如：重启所有web服务器中的Apache进程： 12ansible webservers -m service -a \"name=httpd state=restarted\"ansible web*.duxuejun.com =-m service -a \"name=httpd state=restarted\" 远程服务器匹配规则： 匹配规则 含义 192.168.1.10 或者 web.duxuejun.com 匹配目标IP地址或服务器名称，如果含有多个IP或服务器，使用“:”分隔 webservers 匹配目标为webservers，多个分组使用“:”分隔 all或者&quot;*&quot; 匹配所有的服务器 webservers:!dbservers 匹配在webservers中，不在dbservers组中的服务器 webservers:&amp;dbservers 匹配同时在webservers组以及dbservers组中的服务器 *.duxujun.com或192.168.* 使用通配符进行匹配 webservers[0],webservers[1:],webservers[-1] 使用索引或切片操作的方式匹配组中的服务器 ~(web|db).*.duxuejun.com 以~开头的匹配，表示使用正则表达式匹配 4、Inventory行为参数 12345678910参数 默认值 说明ansible_ssh_host 主机的名字 ssh的目的主机或ipansible_ssh_port 22 ssh目的端口ansible_ssh_user root ssh登陆使用的用户名ansible_ssh_pass none ssh认证所使用的密码ansible_connection smart Ansible使用何种连接模式连接到主机ansible_ssh_private_key_file none ssh认证所使用的私钥ansible_shell_type sh 命令所使用的shellansible_python_interpreter /usr/bin/python 主机上的python解释器ansible_*_interpreter none 类似python解释器的其他语言版 5、改变行为参数的默认值 123456可以在ansible.cfg文件的[defaults]部分更改一些行为参数的默认值 ansible.cfg文件 inventory文件 ansible_ssh_user remote_useransible_ssh_port remote_portansible_ssh_private_key_file private_key_fileansible_shell_type executable 6、定义服务器变量 在hosts文件中，除了定义行为参数以外，还可以定义普通的变量，以便在不同的服务器中使用不同的配置。比如：可以在2台服务器中分别启动MySQL，1台服务器的MySQL的端口是3306，另一台服务器MySQL的端口是3307。定义普通参数和定义行为参数的方法是一样的，只是行为参数的名字有Ansible预先定义，普通参数的名称有我们自己定义。在Ansible中，参数名必须为字母、数字和下划线的组合，并且首字符必须为字母。 （1）变量的取值不同 假定，我们在/etc/ansible/hosts文件中为不同的服务器定义一个相同的变量名，但是取值不同。如下所示： 12345[root@python ~]# vim hosts[test]192.168.1.60 ansible_port=22192.168.1.80 ansible_port=22 在测试环境中，我们可以通过echo方式显示变量的值。如下所示： 12345[root@python ~]# ansible test -i ./hosts -a 'echo &#123;&#123;ansible_port&#125;&#125;' 192.168.1.60 | CHANGED | rc=0 &gt;&gt;22192.168.1.80 | CHANGED | rc=0 &gt;&gt;22 （2）变量的取值相同 如果test组下的两个服务器mysql_port变量取值相同，我们也可以通过组的名称加上“:vars”后缀来定义变量，如下所示： 12345678[root@python ~]# vim hosts[test]192.168.1.40192.168.1.80[test:vars]ansible_port = 22 随着业务的发展，管理的hosts文件越来越大，使用的变量越来越多了，依然使用一个hosts文件管理服务器和变量的话，就会逐渐变得难以管理。 Ansible提供了更好的方法来管理服务器和群组的变量，即：为每个服务器和群组创建独立的变量文件。其定义方式是，将组的变量存放在一个名为group_vars命令下，目录下的文件名与组的名称相同，文件的扩展名可以是.yml或.yaml，也可以没有任何扩展名。服务器的变量存放在一个名为host_vars目录下，该目录下的文件名为服务器的名称。 Ansible将依次在Playbook所在的目录、hosts文件所在的目录和/etc/ansible目录下寻找group_vars目录和host_vars目录。目前，假设group_vars目录和host_var目录都位于/etc/ansible目录下。 对于我们前面定义mysql_port变量的例子，将变量存放在独立的文件以后，/etc/ansible目录的结构如下： 12345678[root@192 ansible]# tree.├── ansible.cfg├── group_vars│ └── test.yaml├── hosts└── host_vars └── 127.0.0.1.yaml 其中，test.yaml文件定义了hosts文件中test组的变量，127.0.0.1.yaml文件定义了hosts文件中127.0.0.1这台服务器使用的变量。如：test.yaml文件的内容如下： 12[root@192 ansible]# cat group_vars/test.yaml ansible_port: 22 注意：我们在hosts文件中定义变量时，使用的是“var = value”格式定义。将变量保存在一个独立的文件时，使用的是“var:value”格式定义。这是因为Ansible解析这两个文件时，认为hosts是一个ini格式的文件，而保存变量的文件是一个YAML格式的文件。 12345[root@python ~]# ansible test -i ./hosts -a 'echo &#123;&#123;ansible_port&#125;&#125;' 192.168.1.40 | CHANGED | rc=0 &gt;&gt;22192.168.1.80 | CHANGED | rc=0 &gt;&gt;22 四、YAML语法 1、YAML语法规则 123451. YAML文件第一行为“---”，表示这是一个YAML文件；2. YAML中字段大小写敏感；3. YAML与Python一样，通过缩进来表示层级关系；4. YAML的缩进不允许使用Tab键，只允许使用空格，且空格的数目不重要，只要相同层级的元素左侧对齐即可；5. “#”表示注释，从这个字符一直到行尾都会被解析器忽略 2、YAML支持的3中格式数据 1231. 对象：键值对的集合，有称为映射，类似于Python中的字典；2. 数组：一组按次序排列的值，有称为序列（sequence），类似于Python的列表；3. 纯量（scalars）：单个的、不可再分的值，比如：字符串、布尔值与数字。 3、安装PyYAML库 Python标准库没有包含解析YAML格式的库，需要安装第三方的PyYAML库。 1pip3 install -i https://pypi.douban.com/simple/ PyYAML 4、定义与解析YAML文件 （1）数组格式 使用YAML表示数组非常容易，只需要用“-”将元素按序列出即可。假设我们有下面这样一个YAML文件，文件的内容保存在一个名为data.yaml的文件中，如下所示： 123456---# 一个美味的水果列表- Apple- Orange- Strawberry- Mango 解析结果： 123456In [1]: import yaml In [2]: with open('data.yaml') as f: ...: print(yaml.load(f)) ...: ['Apple', 'Orange', 'Strawberry', 'Mango'] （2）对象 在YAML中，对象以“key:value”的形式进行定义，如下所示： 123456789---# 一个职工的记录name: 爱运维job: devopsskill: Eliteage: 23knowoop: Truelikes_emacs: TRUEusers_cvs: false 解析结果： 1234In [3]: with open('dev.yaml') as f: ...: print(yaml.load(f)) ...:&#123;'name': '爱运维', 'job': 'devops', 'skill': 'Elite', 'age': 23, 'knowoop': True, 'likes_emacs': True, 'users_cvs': False&#125; YAML中可以使用多种方式制定布尔值，如以上YAML文件中的“True”、“TRUE”、“false”，转换为Python代码后，对变量的取值进行了格式化。 （3）对象和数组嵌套 YAML中的对象和数组是可以任意嵌套的，如下所示： 123456789101112131415161718---# 一个职工的记录name: 爱运维job: devopsskill: Eliteage: 23knowoop: Truelikes_emacs: TRUEusers_cvs: falsefoods: - Apple - Orange - Strawberry - Mangolanguages: ruby: Elite python: Elite shell: Lame （4）注意事项 在YAML中定义字符串的时候，不需要使用单引号或者双引号，直接将字符串写在文件中即可。如下所示： 1str: this is a string 如果字符串中包含了特殊字符，需要使用双引号包含起来。比如：字符串中包含冒号。冒号是YAML中的特殊字符，因此需要使用双引号包含起来。 1foo: \"somebody said I should put a colon here: so I did\" 如果字符串内容比较长，可以使用“&gt;”来折叠换行。 123that: &gt; Foo Bar 将以上YAML文件转换为Python的内部对象后，“Foo”和“Bar”都是字符串的一部分。 1&#123;'that': 'Foo Bar\\n'&#125; 五、Ansible模块 1、Ansible的模块工作原理 1231. 将模块拷贝到远程服务器2. 执行模块定义的操作，完成对服务器的修改3. 在远程服务器删除模块 Ansible中的模块是幂等的，也就是说，多次执行相同的操作，只有第一次会起作用。这也是在编写自定义的Ansible模块的时候需要注意的。 2、模块列表与帮助信息 Ansible模块非常多，如果以模块的功能进行分类的话，可以分为以下模块： 12345678910111213141516云模块命令模块数据库模块文件模块资产模块消息模块监控模块网络模块通知模块包管理模块源码控制模块系统模块单元模块web设施模块Windows模块…… 查看Ansible模块帮助信息，如下所示： 1[root@python ~]# ansible-doc -l 查看指定模块的帮助信息，如下所示： 123456789[root@python ~]# ansible file[WARNING]: Could not match supplied host pattern, ignoring: file[WARNING]: No hosts matched, nothing to dousage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD] [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts] [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k] [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER] [-c CONNECTION] [-T TIMEOUT] [--ssh-common-args SSH_COMMON_ARGS] [--sftp-extra-args SFTP_EXTRA_ARGS] [--scp-extra-args SCP_EXTRA_ARGS] [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D] [-e EXTRA_VARS] [--vault-id VAULT_IDS] [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES] [-f 3、常用的Ansible模块 Ansible提供的功能越丰富，所需要的模块也就越多。默认情况下，模块存储在/usr/share/ansible目录中。 （1）ping 12345678910111213141516[root@python ~]# ansible test -m ping192.168.1.40 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125;Enter passphrase for key '/root/.ssh/id_rsa': 192.168.1.80 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125; （2）远程命令模块 1）command模块 123ansible test -m command -a 'hostname'ansible test -m command -a '/sbin/shutdown -t now'ansible test -a 'hostname' command模块在执行Linux命令时，不能使用管道。如下所示： 1ansible test -m command -a 'cat /etc/passwd | wc -l' 执行后报错如下： 123456192.168.1.40 | FAILED | rc=1 &gt;&gt;cat：无效选项 -- lTry 'cat --help' for more information.non-zero return code192.168.1.80 | FAILED | rc=1 &gt;&gt;cat：无效选项 -- lTry 'cat --help' for more information.non-zero return code 2）raw模块 如果执行的命令需要使用管道，可以使用raw模块，如下所示： 12345678[root@python ~]# ansible test -m raw -a 'cat /etc/passwd | wc -l'192.168.1.80 | CHANGED | rc=0 &gt;&gt;45Shared connection to 192.168.1.80 closed.192.168.1.40 | CHANGED | rc=0 &gt;&gt;44Shared connection to 192.168.1.40 closed. raw模块相当于使用ssh直接执行Linux命令，不会进入到Ansible的模块的子系统中。 3）shell模块 除了使用raw模块以外，也可以使用shell模块，如下所示： 12345[root@python ~]# ansible test -m shell -a 'cat /etc/passwd | wc -l'192.168.1.40 | CHANGED | rc=0 &gt;&gt;44192.168.1.80 | CHANGED | rc=0 &gt;&gt;45 shell模块还可以执行远程服务器上的shell脚本，其中，脚本文件的路径需要使用绝对路径，如下所示： 1ansible test -m shell -a '/home/test/test.sh' 统计某个文件有多少行 1234567891011121314[root@python ~]# ansible common -m raw -a 'cat /etc/passwd | wc -l'192.168.1.40 | CHANGED | rc=0 &gt;&gt;43Shared connection to 192.168.1.40 closed.192.168.1.80 | CHANGED | rc=0 &gt;&gt;45Shared connection to 192.168.1.80 closed.[root@python ~]# ansible common -m shell -a 'cat /etc/passwd | wc -l'192.168.1.40 | CHANGED | rc=0 &gt;&gt;43192.168.1.80 | CHANGED | rc=0 &gt;&gt;45 引用文件的方式 1234567891011121314151617181920212223242526272829[root@python ~]# vim test.sh #!/usr/bin/bashcat /etc/passwd | wc -l[root@python ~]# ansible common -m script -a 'test.sh'192.168.1.40 | CHANGED =&gt; &#123; \"changed\": true, \"rc\": 0, \"stderr\": \"Shared connection to 192.168.1.40 closed.\\r\\n\", \"stderr_lines\": [ \"Shared connection to 192.168.1.40 closed.\" ], \"stdout\": \"43\\r\\n\", \"stdout_lines\": [ \"43\" ]&#125;192.168.1.80 | CHANGED =&gt; &#123; \"changed\": true, \"rc\": 0, \"stderr\": \"Shared connection to 192.168.1.80 closed.\\r\\n\", \"stderr_lines\": [ \"Shared connection to 192.168.1.80 closed.\" ], \"stdout\": \"45\\r\\n\", \"stdout_lines\": [ \"45\" ]&#125; （3）file file模块主要用于对远程服务器上的文件（包括链接和目录）进行操作，包括修改文件的权限、修改文件的所有者、创建文件、删除文件等。 file模块使用示例： 1234567891011# 创建一个目录ansible test -m file -a 'path=/tmp/dd state=directory mode=0o755'# 修改文件的权限ansible test -m file -a \"path=/tmp/dd state=touch mode='u=rw,g=r,o=r'\"# 创建一个软链接ansible test -m file -a 'src=/tmp/dd dest=/tmp/dd1 state=link owner=root group=root'# 修改一个文件的所有者ansible test -m file -a \"path=/tmp/dd owner=root group=root mode=0o644\" -become file模块中重要选项： 1234567891. path: 指定文件/目录的路径2. recurse: 递归设置文件属性，只对目录有效3. group: 定义文件/目录的组4. mode: 定义文件/目录的权限5. owner: 定义文件/目录的所有者6. src: 要被链接的源文件路径，只应用于state为link的情况7. dest: 被链接到的路径，只应用于state为link的情况8. force: 在两种情况下会强制创建软链接，一种情况是源文件不存在，但之后会建立的情况；另一种情况是目标软链接已经存在，需要先取消了之前的软链接，然后再创建新的软链接，默认取值为no9. state: 该选项有多个取值，包括directory、file、link、hard、touch、absent。各个取值的含义如下：取值为directory，如果目录不存在，创建目录；取值为file时，即使文件不存在也不会被创建；取值为link时，创建软链接；取值为hard时，创建硬链接；取值为touch时，如果文件不存就创建一个新文件，如果文件或目录已经存在，更新其最后访问时间和修改时间；取值为absent时，删除目录、文件或者链接 &lt;1&gt;创建文件 1[root@python ~]# ansible common -m file -a 'path=/opt/test.md state=touch' 查看一下 &lt;2&gt;创建目录 1[root@python ~]# ansible common -m file -a 'path=/opt/test mode=0755 state=directory' 查看一下 &lt;3&gt;创建并删除文件 12[root@python ~]# ansible common -m file -a 'path=/opt/abc mode=0640 state=touch'//创建 查看一下 1[root@python ~]# ansible common -m file -a 'path=/opt/abc mode=0640 state=absent' &lt;4&gt;创建并改变文件所有者 123[root@python ~]# ansible common -m file -a 'path=/opt/abc mode=0640 state=touch'[root@python ~]# ansible common -m file -a 'path=/opt/abc mode=0640 owner=test group=root' -become （4）copy copy模块用来将主控节点的文件或者目录拷贝到远程服务器上，类似于Linux下的scp命令。但是，copy模块比scp命令更强大，在拷贝文件到远程服务器上的同时，也可以设置文件在远程服务器上的权限和所有者。 copy模块的使用示例： 12345678# 拷贝文件到远程服务器ansible test -m copy -a 'src=test.sh dest=/tmp/test.sh'# 拷贝文件到远程服务器，如果远程服务器已经存在这个文件，则备份文件ansible test -m copy -a 'src=test.sh dest=/tmp/test.sh backup=yes force=yes'# 拷贝文件到远程服务器，并且修改文件的所有者和权限ansible test -m copy -a 'src=tes.sh dest=/tmp/tes.sh owner=root group=root mode=644 force=yes' -become copy模块中重要选项： 1234561. src：要复制到远程服务器的文件地址，可以是绝对路径，也可以是相对路径。如果路径时一个目录，将递归复制。在这种情况下，如果使用“/”结尾，则复制目录里的内容；如果没有用“/”来结尾，则将包含目录在内的整个内容复制，类似于rsync2. dest：文件要复制到的目的地，必须是一个绝对路径，如果源文件是一个目录，那么dest指向的也必须是一个目录3. force：默认取值为yes，表示目标主机包含该文件，但是内容不同时，会强制覆盖；如果该选项设置为no，只有当目标主机的目标位置不存在该文件时，才会进行复制4. backup：默认取值为no，如果取值为yes，那么在覆盖之前将原文件进行备份5. directory_mode：递归设定目录权限，默认为系统默认权限6. others：所有file模块里的选项都可以在这里使用 （5）user/group user模块请求的是useradd、userdel、usermod这三个指令，group模块请求的是groupadd、groupdel、groupmod这三个指令。 user/group模块的使用示例： 1234567891011121314# 创建一个用户ansible test -m user -a 'name=John comment=\"John Doe\" uid=1239 group=root' -become# 删除一个用户ansible test -m user -a 'name=John state=absent' -become# 创建一个用户，并且产生一对密钥ansible test -m user -a 'name=John comment=\"John Doe\" generate_ssh_key=yes ssh_key_bits=2048' -become# 创建群组ansible test -m group -a 'name=ansible state=present gid=1234' -become# 删除群组ansible test -m group -a 'name=ansible state=absent' -become user/group模块重要选项： 12345678910111. name：需要操作的用户名或群组名2. comment：用户的描述信息3. createhome：创建用户时，是否创建家目录，默认为yes4. home：指定用户的家目录，需要与createhome选项配合使用5. group：指定用户的属组6. uid：设置用户的id7. gid：设置群组的id8. password：设置用户的密码9. state：是创建用户或群组，还是删除用户后群组，取值包括present和absent10. expires：用户的过期时间11. shell：指定用户的shell环境 （6）yum yum模块可以帮助我们在远程主机上通过yum源管理软件包。 yum模块使用示例： 123456789# 安装软件包ansible test -m yum -a 'name=nginx disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=present disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=installed disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=latest disable_gpg_check=yes'# 卸载软件包ansible test70 -m yum -a 'name=nginx state=absent'ansible test70 -m yum -a 'name=nginx state=removed' yum模块重要选项： 1234561. name：必须参数，用于指定需要管理的软件包，比如nginx2. state：用于指定软件包的状态 ，默认值为present，表示确保软件包已经安装，除了present，其他可用值有installed、latest、absent、removed，其中installed与present等效，latest表示安装yum中最新的版本，absent和removed等效，表示删除对应的软件包3. disable_gpg_check：用于禁用对rpm包的公钥gpg验证，默认值为no，表示不禁用验证，设置为yes表示禁用验证，即不验证包，直接安装，在对应的yum源没有开启gpg验证的情况下，需要将此参数的值设置为yes，否则会报错而无法进行安装4. enablerepo：用于指定安装软件包时临时启用的yum源，假如你想要从A源中安装软件，但是你不确定A源是否启用了，你可以在安装软件包时将此参数的值设置为yes，即使A源的设置是未启用，也可以在安装软件包时临时启用A源5. disablerepo：用于指定安装软件包时临时禁用的yum源，某些场景下需要此参数，比如，当多个yum源中同时存在要安装的软件包时，你可以使用此参数临时禁用某个源，这样设置后，在安装软件包时则不会从对应的源中选择安装包6. enablerepo参数和disablerepo参数可以同时使用 （7）get_url 从互联网上下载数据到本地，作用类似于Linux下的curl命令。get_url模块比curl命令更加灵活，可以控制下载以后的数据所有者、权限以及检查下载数据的checksum等。 get_url模块使用示例： 为了进行get_url测试，使用命令“python -m http.server”启动一个下载服务器，将下载服务器中的文件地址传给url选项。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 下载文件到远程服务器ansible test -m get_url -a 'url=http://localhost:8000/data.tar.gz dest=/tmp/data.tar.gz'# 下载文件到远程服务器，并且修改文件的权限ansible test -m get_url -a 'url=http://localhost:8000/data.tar.gz dest=/tmp/data.tar.gz mode=0777'# 下载文件到远程服务器，并且检查文件的MD5校验是否与控制端的MD5校验相同[root@bogon ~]# md5sum s.txtd41d8cd98f00b204e9800998ecf8427e s.txt[root@bogon ~]# ansible 127.0.0.1 -m get_url -a 'url=http://localhost:8000/s.txt dest=/tmp/s.txt checksum=md5:d41d8cd98f00b204e9800998ecf8427e'127.0.0.1 | CHANGED =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": true, \"checksum_dest\": null, \"checksum_src\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"dest\": \"/tmp/s.txt\", \"elapsed\": 0, \"gid\": 0, \"group\": \"root\", \"md5sum\": \"d41d8cd98f00b204e9800998ecf8427e\", \"mode\": \"0644\", \"msg\": \"OK (0 bytes)\", \"owner\": \"root\", \"secontext\": \"unconfined_u:object_r:admin_home_t:s0\", \"size\": 0, \"src\": \"/root/.ansible/tmp/ansible-tmp-1584171703.8607588-137457225931919/tmpG3otIP\", \"state\": \"file\", \"status_code\": 200, \"uid\": 0, \"url\": \"http://localhost:8000/s.txt\"&#125;[root@bogon ~]# ansible 127.0.0.1 -m get_url -a 'url=http://localhost:8000/s.txt dest=/tmp/s.txt checksum=md5:d41d8cd98f00b204e9800998ecf84270'127.0.0.1 | FAILED! =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"checksum_dest\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"checksum_src\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"dest\": \"/tmp/s.txt\", \"elapsed\": 0, \"msg\": \"The checksum for /tmp/s.txt did not match d41d8cd98f00b204e9800998ecf84277e; it was d41d8cd98f00b204e9800998ecf8427e.\", \"src\": \"/root/.ansible/tmp/ansible-tmp-1584171717.7448506-78799482489470/tmpyczfH3\", \"url\": \"http://localhost:8000/s.txt\"&#125; get_url模块重要选项： 1234567891011121. dest：必传选项，指定将文件下载的绝对路径2. url：必传选项，文件的下载地址（网址）3. url_username: 用于http基本认证的用户名4. url_password： 用于http基本认证的密码5. validate_certs： 如果否，SSL证书将不会验证。这只应在使用自签名证书的个人控制站点上使用6. owner： 指定属主7. group： 指定属组8. mode： 指定权限9. checksum：文件的校验码10. headers：传递给下载服务器的HTTP Headers11. backup：如果本地已经存在同名文件，备份文件12. timeout：下载的超时时间 （8）unarchive unarchive模块用于解压文件，其作用类似于Linux下的tar命令。默认情况下，unarchive的作用是将控制节点的压缩包拷贝到远程服务器，然后进行解压。 unarchive模块使用示例： 1234567891011# 先创建一个目录ansible test - m file -a 'path=/tmp/data state=directory'# 解压本地文件ansible test - m unarchive -a 'src=data.tar.gz dest=/tmp/data list_files=yes'# 将本地文件拷贝到远程服务器ansible test -m copy -a 'src=data.tar.bz2 dest=/tmp/data.tar.bz2'# 解压远程的文件ansible test -m unarchive -a 'src=/tmp/data.tar.bz2 dest=/tmp remote_src=yes' unarchive模块重要选项： 1234567891. remote_src：该选项可以取值为yes或no，用来表示解压的文件存在远程服务器中，还是存在控制节点所在的服务器中。默认取值为no，表示在解压文件之前，先将控制节点的文件复制到远程主机中，然后在进行解压2. src：指定压缩文件的路径，该选项的取值取决于remote_src的取值。如果remote_src取值为yes，则src指定的是远程服务器中压缩包的地址；如果remote_src的取值为no，则src指向的是控制节点中的路径3. dest：该选项指定的是远程服务器上的绝对路径，表示压缩文件解压的路径4. list_files：默认情况下该选项取值为no，如果该选项取值为yes，也会解压文件，并且在ansible的返回值中列出压缩包里的文件5. exclude：解压文件时排除exclude选项指定的文件或目录列表6. keep_newer：默认取值为False，如果该选项取值为True，那么当目标地址中存在同名的文件，并且文件比压缩包中的文件更新时，不进行覆盖7. owner：文件或目录解压以后的所有者8. group：文件或目录解压以后所属的群组9. mode：文件或目录解压以后的权限 （9）git git模块非常好理解，就是在远程服务器执行git相关的操作。该模块一般应用于需要源码安装软件时，从github这样的源码托管网站将软件下载到本地，然后执行命令进行源码安装。需要注意的是，该模块依赖于git软件，因此在使用该模块前应该使用yum模块先安装git软件。 git模块的使用示例： 12345678#将requests克隆到/tmp/requests目录下ansible test -m git -a 'repo=https://github.com/psf/requests.git dest=/tmp/requests version=HEAD'# 从源码安装requestsansible test -a 'python setup.py install chdir=/tmp/requests' -become# 验证requests是否安装成功ansible test -a \"python -c 'import requests'\" git模块常用选项： 123451. repo：远程git库的地址，可以是一个git协议、ssh协议或http协议的git库地址2. dest：必选选项，git库clone到本地服务器以后保存的绝对路径3. version：克隆远程git库的版本，取值可以为HEAD、分支的名称、tag的名称，也可以是一个commit的hash值4. force：默认取值为no，当该选项取值为yes时，如果本地的git库有修改，将会抛弃本地的修改5. accept_hostkey：当该选项取值为yes时，如果git库的服务器不在know_hosts中，则添加到konw_hosts中，key_file指定克隆远程git库地址是使用的私钥 （10）stat stat模块用于获取远程服务器上的文件信息，其作用类似于Linux下的stat命令。stat模块可以获取atime、ctime、mtime、checksum、size、uid、gid等信息。 stat只有path这一个必选选项，用来指定文件或目录的路径。stat模块的使用方法如下： 12# 获取文件的详细信息ansible test -m stat -a 'path=/etc/passwd' （11）cron 顾名思义，cron是管理Linux下计划任务的模块。 cron模块的使用示例： 12345# 增加一个crontab任务ansible test -m cron -a 'backup=yes name=\"测试计划任务\" minute=*/2 hour=* job=\"ls /tmp &gt;/dev/null\"'# 进入服务器，查看新增的crontab任务crontab -l 该模块包含以下重要选项： 12345671. backup：取值为yes或no，默认为no，表示修改之前先做备份2. state：取值为present或absent，用来确认该任务计划是创建还是删除3. name：该任务的描述4. job：添加或删除任务，主要取决于state的取值5. user：操作哪一个用户的crontab6. cron_file：如果指定该选项，则用该文件替换远程主机上cron.d命令下的用户任务计划7. month weekday 打印minute hour：取值与crontab类似。例如：对于minute的取值范围0~59，也可以选择“*”表示每分钟运行，或者“*/5”表示每5分钟运行 （12）service service模块的作用类似于Linux下的service命令，用来启动、停止、重启服务。 service模块的使用示例： 12345678# 安装Apache，默认情况下，Apache安装完成以后就会启动ansible test -m yum -a 'name=httpd state=present' -become# 停止Apacheansible test -m service -a 'name=httpd state=stopped'# 重启Apacheansible 127.0.0.1 -m service -a 'name=httpd state=restarted' service模块的常用选项： 123451. name：服务的名称，该选项为必选项2. state：可以取值为started、stopped、restarted和reload。其中，started和stopped是幂等的，也就是说，如果服务已经启动了，执行started不会执行任何操作3. sleep：重启的过程中，先停止服务，然后sleep几秒在启动4. pattern：定义一个模式，ansible首先通过status命令查看服务的状态，依次判断服务是否在运行。如果通过status查看服务状态时没有响应，ansible会尝试匹配ps命令的输出，当匹配到相应模式时，认为服务已经启动，否则认为服务没有启动5. enabled：取值为yes或no，用来设置服务是否开机启动 （13）sysctl 该模块的作用与Linux下的sysctl命令相似，用于控制Linux的内核参数。 sysctl模块使用示例： 12# 设置overcommit_memory参数的值为1ansible test -m sysctl -a 'name=vm.overcommit_memory value=1' -become sysctl模块的常用选项： 12341. name：需要设置的参数2. value：需要设置的值3. sysctl_file：sysctl.conf文件的绝对路径，默认路径是/etc/sysctl.conf4. reload：该选项可以取值为yes或no，默认为yes，用于表示设置完成以后是否需要执行sysctl -p操作 （14）setup setup模块用于收集远程主机的信息 setup模块的使用示例： 12345678# 获取IP地址ansible test -m setup -a 'filter=ansible_default_ipv4'# 获取内存信息ansible test -m setup -a 'filter=ansible_memory_mb'# 获取主机完整信息ansible test -m setup （15）mount 在远程服务器上挂载磁盘，当进行挂盘操作是，如果挂载点指定的路径不存在，将创建该路径。 mount模块使用示例： 12# 挂载/dev/vda盘到/mnt/data目录ansible test -m mount -a 'name=/mnt/data src=/dev/vda fstype=ext4 state=mounted' mount模块常用选项： 12341. name：挂载点的路径2. state：可以取值为present、absent、mounted、unmounted，其中，mounted与unmounted用来处理磁盘的挂载和卸载，并且会正确配置fstab文件，present与absent只会设置fstab文件，不会去操作磁盘3. fstype：指定文件系统类型，当state取值为present或mounted时，该选项为必填选项4. src：挂载的设备 （16）synchronize synchronize模块是对rsync命令的封装，以便对常见的rsync任务进行处理。我们也可以使用command模块调用rsync命令执行相应的操作。rsync是一个比较复杂的命令，相对来说，使用synchronize简单一些。 synchronize模块的使用示例： 12# 同步本地目录到远程服务器ansible test -m synchronize -a 'src=test dest=/tmp' synchronize模块的常用选项： 123451. src：需要同步到远程服务器的文件和目录2. dest：远程服务器保存数据的路径3. archive：默认取值为yes，相当于同时开启recursive、links、perms、times、owner、group、-D等选项4. compress：默认为yes，表示在文件同步过程中是否启用压缩5. delete：默认为no，当取值为yes时，表示删除dest中存在而src中不存在的文件 4、模块的返回值 Ansible通过模块来执行具体的操作，由于模块的功能千差万别，所以执行模块操作后，Ansible会根据不同的需要返回不同的结果。虽然如此，Ansible中也有一些常见的返回值。如下所示： 返回值的名称 返回值的含义 changed 几乎所有的Ansible模块都会返回该变量，表示模块是否对远程主机执行了修改操作 failed 如果模块未能执行完成，将返回failed为True msg 模块执行失败的原因，常见的错误如ssh连接失败，没有权限执行模块等 rc 与命令行工具相关的模块会返回rc，表示执行Linux命令的返回码 stdout 与rc类似，返回的是标准输出的结果 stderr 与rc类似，返回的是错误输出的结果 backup_file 所有存在backup选项的模块，用来返回备份文件的路径 results 应用在Playbook中存在循环的情况，返回多个结果 错误的 1234[root@python ~]# ansible test -i hosts -a 'echo &#123;&#123;ansible_port&#125;&#125;'192.168.1.60 | CHANGED | rc=0 &gt;&gt;22192.168.1.80 | CHANGED | rc=0 &gt;&gt;22","path":"posts/5017.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"},{"name":"python","slug":"python","permalink":"https://wsdlxgp.top/tags/python/"}]},{"title":"python自动化管理sshy与paramiko","text":"Python自动化管理sshy介绍 ssh优势： 安全传输文件 登录 批量执行命令 对于一名刚开始接触Linux系统管理的工程师来说，他眼里的系统管理的步骤可能是：使用SSH登录服务器，修改应用相关的配置文件，执行一些Linux命令，重启相应的进程，最后退出服务器。如果还有更多的服务器，那么，就重复上述过程。 上面这一系列步骤是Linux系统管理的基础知识，是系统管理的基本功。但是，在实际工作中，一般不会手动对 服务器进行操作，而是使用程序进行自动化管理。即使服务器的数量很少，也推荐大家编写程序进行自动化。相对于手动管理服务器，自动化管理有许多优点。例如： 1）效率高： 自动化操作效率比手动操作效率高。这里的效率高可以从两方面来理解：一方面是程序执行的效率比手动操作的效率高；另一方面是指对工程师来说，使用程序可以提高自身的工作效率，减少不必要的时间浪费。即使只有一台服务器，手动操作虽然可以很快完成，但其操作效率也不能与程序相提并论。如果管理的是服务器集群，显然，人工操作非常不现实，不但效率低下.而且枯操乏味，费时费力。程序的好处是一次编写，多次运行。虽然在编写程序的时候，花费的时间可能比单次手动操作的时间多，但是，只要程序编写完成，就可以多次反复地运行，节省大量时间。 2）不容易犯错： 俗话说“人无完人”，如果一直使用人工管理的方式管理服务器集群，那么，出错是不可避免的。工程师会有情绪的变化，也会有身体健康状况等问题，但程序不会。只要程序编写完成，并且考虑到了相应的异常，程序总是能够严格一致地执行管理操作。 3）享受乐趣： 从事计算机行业有一个天然的好处，那就是不用进行重复性的工作。有任何重复性的工作，找们都可以通过编写程序消灭掉。消灭重复性的工作，不但节省工作时间，还能够获得更多的乐趣和成就感。以管理服务器集群为例，看到自己编写的程序、指挥成百上千的服务器按照既定的需求执行操作，是不是有种指点江山、挥斥方遒的感觉？ 这一章将会讨论如何使用Python批量管理服务器。首先，我们将会介绍批量管理服务器的基础知识，即SSH协议；随后，本章会介绍一个Python编写的批处理工具；然后将会介绍如何在Python程序中对远程服务器进行操作；在本章的最后，我们会介绍一个非常强大的系统管理工具，即Fabric,这一部分是本章的重点和难点。 一、使用SSH协议访问远程服务器 SSH ( Secure Shell)是一种由IETF的网络工作小组制定、创建在应用层和传输层基础上的安全协议，为计算机上的Shell提供安全的传输和使用环境。 1、SSH协议 在互联网早期，通信都是明文的，如rsh、 FTP、POP和Telnet。一旦通信报文被截获，内容就泄漏无疑。1995年，芬兰学者Tatu Ylonen设计了SSH协议。将登录信息全部加密，成为互联网安全的一个基本解决方案。这个方案迅速在全世界获得推广，目前已经成为Linux系统的标准配。 SSH只是一种协议，存在多种实现，既有商业实现也有开源实现。目前。在Linux下广泛使用的是OpenSSH，它是一款应用广泛的开源软件。本文即将介绍的paramiko是SSH协议的一种Python实现。 SSH除了提供安全的传输和登录以外，还可以进行批量命令执行，使用非常方便。正是由于SSH简单好用的特点，本章介绍的几个工具，以及稍后即将介绍的Ansible,都依赖SSH进行远程服务器的管理。使用SSH的好处非常明显，既充分利用了现成的机制，又省去了在远程服务器安装代理(Agent)程序。因此，诸多自动化工其都依赖SSH。 2、OpenSSH实现 OpenSSH (OpenBSD Secure Shell)是OpenBSD的一个子项目，是SSH协议的开源实现。在服务端，OpenSSH启动sshd守护进程，该进程默认监听22端口。客户端使用用户名和密码连接服务端，连接成功以后，OpenSSH返回给用户一个Shell，用户可以使用该Shell在远程服务器执行命令。 在Debian系统中，OpenSSH的服务端默认读取/etc/ssh/sshd_config中的配置。在生产环境中，为了防止黑客攻击，一般会修改ssh服务的默认端口号，修改ssh服务默认端口号就是在/etc/ssh/sshd_config中完成的。我们也可以通过该配置文件禁止用户使用密码进行认证，只能使用密钥认证。修改完配置文件以后，执行下面的命令重启OpenSSH的守护进程才能生效： 对于一名刚开始接触Linux系统管理的工程师来说，他眼里的系统管理的步骤可能是：使用SSH登录服务器，修改应用相关的配置文件，执行一些Linux命令，重启相应的进程，最后退出服务器。如果还有更多的服务器，那么，就重复上述过程。 上面这一系列步骤是Linux系统管理的基础知识，是系统管理的基本功。但是，在实际工作中，一般不会手动对 服务器进行操作，而是使用程序进行自动化管理。即使服务器的数量很少，也推荐大家编写程序进行自动化。相对于手动管理服务器，自动化管理有许多优点。例如： 1/etc/init.d/ssh restart OpenSSH的客户端是一个名为ssh可执行程序，我们可以使用ssh命令连接远程服务器。如下所示: 123456[root@python ~]# ssh xgp@localhost The authenticity of host 'localhost (::1)' can't be established.ECDSA key fingerprint is bf:c7:de:84:e1:28:f4:d4:7e:41:49:9f:54:dc:e9:83.Are you sure you want to continue connecting (yes/no)? yesxgp@localhost's password: [xgp@python ~]$ 如果服务器端不是使用默认的22端口，可以通过SSH命令的-p参数指定建立连接的端口号，格式如下所示： 1ssh username@remote_host -p 端口号 我们也可以不进入交互式的Shell，直接使用ssh命令在远程服务器中执行Linux命令，如下所示： 12345[root@python ~]# ssh root@192.168.1.80 'date'root@192.168.79.129's password: 2020年 05月 15日 星期五 15:55:08 CSTs[root@python ~]# 3、配置ssh的方法： 编辑/etc/ssh/ssh_config 编辑~/.ssh/config ssh会读取/etc/ssh/ssh_config文件中的配置。例如，远程服务器使用的不是默认的22端口号，我们只需要在/etc/ssh/ssh_config进行简单的配置，就可以在连接远程服务器时省去指定端口号的参数。除了修/etc/ssh/ssh_config文件以外，更常见的做法是修改用户home目录下的~/.ssh/config文件。 查看ssh_config文件 1234567891011121314151617181920212223242526272829303132333435363738[root@python ~]# find / -name ssh_config #查看找ssh_config 文件/etc/ssh/ssh_config[root@python ~]# cat /etc/ssh/ssh_config | awk #Usage: awk [POSIX or GNU style options] -f progfile [--] file ...Usage: awk [POSIX or GNU style options] [--] 'program' file ...POSIX options: GNU long options: (standard)true-f progfile --file=progfiletrue-F fs --field-separator=fstrue-v var=val --assign=var=valShort options: GNU long options: (extensions)true-b --characters-as-bytestrue-c --traditionaltrue-C --copyrighttrue-d[file] --dump-variables[=file]true-e 'program-text' --source='program-text'true-E file --exec=filetrue-g --gen-pottrue-h --helptrue-L [fatal] --lint[=fatal]true-n --non-decimal-datatrue-N --use-lc-numerictrue-O --optimizetrue-p[file] --profile[=file]true-P --posixtrue-r --re-intervaltrue-S --sandboxtrue-t --lint-oldtrue-V --versionTo report bugs, see node `Bugs' in `gawk.info', which issection `Reporting Problems and Bugs' in the printed version.gawk is a pattern scanning and processing language.By default it reads standard input and writes standard output.Examples:truegawk '&#123; sum += $1 &#125;; END &#123; print sum &#125;' filetruegawk -F: '&#123; print $1 &#125;' /etc/passwd 例如，我们经常要使用某一个用户名、端口号访问某一台远程服务器。为了省去记住服务器ip的负担，很多工程师会编写一个Shell脚本，在脚本中保存用户名、端口号和ip地址。在下次登录时，可以省去输入的烦恼。如下所示： 12345678910111213141516171819[root@python ~]# vim /opt/login.sh#!/usr/bin/bashssh test@127.0.0.1 -p 22[root@python ~]# useradd test[root@python ~]# passwd test更改用户 test 的密码 。新的 密码：无效的密码： 密码少于 8 个字符重新输入新的 密码：passwd：所有的身份验证令牌已经成功更新。[root@python ~]# sh /opt/login.sh The authenticity of host '127.0.0.1 (127.0.0.1)' can't be established.ECDSA key fingerprint is bf:c7:de:84:e1:28:f4:d4:7e:41:49:9f:54:dc:e9:83.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '127.0.0.1' (ECDSA) to the list of known hosts.test@127.0.0.1's password: [test@python ~]$ 对于这里的需求，还有更好的解决方案。命令会读取~/.ssh/config文件中配置，因此，我们可以在~/.ssh/config文件中提前配置好访问远程服务器的信息。如下所示： 12345678910111213141516[root@python ~]# cp /etc/ssh/ssh_config -p ~/.ssh/config[root@python ~]# vim ~/.ssh/config Host python ForwardAgent yes StrictHostKeyChecking no port 22 User test Controlpath ~/.ssh/ssh-%r@%h:%p.sockHost * StrictHostKeyChecking no HostName %h Port 22 User test Controlpath ~/.ssh/ssh-%r@%h:%p.sock 配置完成后，直接在命令行执行ssh host2就可以使用用户名test，以及端口号2092登录到10.166.224.14中。此外，我们还使用通配符的方式定义了ssh默认用户名与端口号。假设我们要使用用户名laoyu、端口号2092访问10.166.226.153，有了前面的配置以后，可以在命令行直接进行登录。如下所示： 1234567[root@python ~]# ssh pythonWarning: Permanently added 'python,fe80::c64e:c937:2ea8:6676%ens33' (ECDSA) to the list of known hosts.test@python's password: Permission denied, please try again.test@python's password: Last login: Fri May 15 14:34:54 2020 from localhost[test@python ~]$ 可以看到，我们只需要在~/.ssh/config文件中进行简单的配置就能够有效提高工作效率。 4、使用密钥登录远程服务器 ssh使用密码 ssh不使用密码，使用密钥 在上面的例子中，我们没有指定认证的方式，默认使用密码进行认证。在生产环境中一般不使用密码认证，一方面是因为密码认证没有密钥认证安全；另一方面，密码认证每次登录时都需要输入密码，比较繁琐。使用密钥认证，省去了输入密码的烦恼。因此，在生产环境中，一般会使用密钥进行登录。 密钥登录的原理也很简单，即事先将用户的公钥储存在远程服务器上（~/.ssh/authorized_keys文件)。使用密钥登录时，远程服务器会向用户发送一段随机字符串，SSH使用用户的私钥加密字符串后发送给远程服务器。远程服务器用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录Shell，不再要求密码。 OpenSSH除了提供服务端的sshd、客户端的SSH程序以外，还提供了若干与密钥认证相关的工其。其中，ssh-keygen是用来生成密钥对的工具。如下所示： 1[root@python ~]# ssh-keygen ssh-keygen执行完以后，用户的~/.ssh目录下会存在一个名为id_ rsa的私钥文件与一个名为id_rsa.pub的公钥文件。 接下来要做的是将公钥保存到远程服务器的~/.ssh/authorized_keys文件中。可以使用下面的命令将公钥保存到远程服务器的authorized_keys文件中： 12345678[root@python ~]# ssh root@192.168.1.80 'mkdir -p .ssh &amp;&amp; cat &gt;&gt;.ssh/authorized_keys' &lt;~/.ssh/id_rsa.pub The authenticity of host '192.168.1.80 (192.168.1.80)' can't be established.ECDSA key fingerprint is SHA256:UbtfIBIs2tGQU1m/SIvSZX72VUQ+r1fH/aIMxVbdobg.ECDSA key fingerprint is MD5:56:10:49:b1:ae:f6:3c:d3:5e:2d:c5:d9:38:2c:45:e7.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '192.168.1.80' (ECDSA) to the list of known hosts.root@192.168.1.80's password: [root@python ~]# 上面的命令是使用Shell脚本的方式将公钥保存到远程服务器，除此之外，OpenSSH专门提供了一个名为ssh-copy-id的工具。我们可以使用该工具将公钥保存到远程服务器中，这种方式比前面Shell脚本的方式更加方便。如下所示: 123456789101112131415[root@python ~]# [root@python ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.1.80/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.1.80's password: Number of key(s) added: 1Now try logging into the machine, with: \"ssh '192.168.1.80'\"and check to make sure that only the key(s) you wanted were added.[root@python ~]# rm -rf ~/.ssh/config[root@python ~]# ssh 192.168.1.80Last login: Fri May 15 15:16:23 2020 from 192.168.1.80[root@python ~]# 配置私钥认证以后，就可以直接使用私钥进行登录。ssh命令会默认读取~/.ssh/id_rsa这个私钥文件。如果私钥文件保存在其他位置，或者是其他名称，可以使用-t参放指定私钥文件的地址。如下所示： 1ssh test@192.168.1.80 -p 22 -i ~/私钥文件所在的位置（含文件名） 使用私钥登录时需要注意，私钥文件与远程服务器中authorized_keys文件的权限都必须为600，否则登录会出错，这也是工程师使用私钥登录时最容易遇到的错误。 测试登陆一下 123456789[root@python ~]# vim ~/.ssh/config Host python ForwardAgent yes StrictHostKeyChecking no HostName 192.168.1.80 Port 22 User test Controlpath ~/.ssh/ssh-%r@%h:%p.sock 1234[root@python ~]# ssh pythontest@192.168.1.80's password: Last login: Fri May 15 14:49:17 2020 from fe80::c64e:c937:2ea8:6676%ens33[test@python ~]$ 查看公钥是否一致 123456789101112[root@python ~]# ssh 192.168.1.80Last login: Fri May 15 15:16:23 2020 from 192.168.1.80[root@python ~]# cat ~/.ssh/authorized_keys #远程的ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWLJAYWCpbRPQX8gDbr2mIyXMw/qEKd46u4QhcaDPY7CeGd/buIGsWsuz+DAcnowk095rIwspGGHOdt54s+aeXGXcsRh7Hpuf0Py20Krim+v2LIUQW8vQSJDj1HiQUSnNQNPT3HAm0aqQp8u2EZ0StLYtf/uYSbg6rSzW08mKwhBQkrP0olWb+hD4ak3LxA05OI/WnanGKqtqjLg+4MbgGK96fY53dKvwrdt9NWiuof3pLgTw9fTvPU6CD+cH4LmRg8IVhthlBRhrXPA7oa8gvupTvpMYdNPPUSBsVR2rBcimrUFwdOpzb6T30C7o566noRd3t3nNxkQ/HrKalo9Bn root@python[root@python ~]# exit登出Connection to python closed.[root@python ~]# cat ~/.ssh/id_rsa.pub #本地的ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWLJAYWCpbRPQX8gDbr2mIyXMw/qEKd46u4QhcaDPY7CeGd/buIGsWsuz+DAcnowk095rIwspGGHOdt54s+aeXGXcsRh7Hpuf0Py20Krim+v2LIUQW8vQSJDj1HiQUSnNQNPT3HAm0aqQp8u2EZ0StLYtf/uYSbg6rSzW08mKwhBQkrP0olWb+hD4ak3LxA05OI/WnanGKqtqjLg+4MbgGK96fY53dKvwrdt9NWiuof3pLgTw9fTvPU6CD+cH4LmRg8IVhthlBRhrXPA7oa8gvupTvpMYdNPPUSBsVR2rBcimrUFwdOpzb6T30C7o566noRd3t3nNxkQ/HrKalo9Bn root@python 二、使用ssh-agent管理私钥 OpenSSH还提供了一个名为ssh-agent的程序，该程序可以简化SSH私钥的管理操作。ssh-agent是个长时间持续运行的守护进程(daemon)，它的唯一目的就是对私钥进行高速缓存。 使用ssh-agent有以下几个好处： （1）如果我们使用了一个加密的私钥，那么，使用这个私钥时将需要输入密码才能使用私钥文件。如果我们使用加密的私钥并且没有使用ssh-agent，那么将不得不在每次使用这个私钥时都输入密码。如果使用ssh-agent管理私钥，只需要在私钥加入到ssh-agent的那一刻输入密码，在之后的使用中都不用输入私钥的密码； （2）如果我们有多台远程服务器与多个私钥文件，使用ssh-agent以后，不用在每次登录服务器时都使用-i参数指定使用哪一个私钥文件。ssh-agent将会尝试使用不同的私钥文件建立连接。直至成功； （3）使用ssh-agent可以实现私钥转发功能。假设现在有三台服务器，分别是A, B, C。其中，A是我们的控制节点，我们可以在A上直接访问B，但是我们无法直接访问C。如果要访问C，就只能先登最B，再从B登录C。对于这种情况，是否需要在B中保存用户的私钥呢？对于这里的情况，我们可以使用agent forwarding。使用agent forwarding以后，不用将私钥保存到B服务器上，只需要在A中保存私钥，在B和C中保存公钥，便可在A中访问B与C这两台服务器。为了使用agent forwarding，我们必须使用ssh-agent管理私钥。 如果在Windows下使用Xshell进行SSH访问，要启动ssh-agent非常简单，只需要在“连接“–&gt;&quot;SSH“中勾选“使用密码处理的Xagent (SSH代理)”即可。 （1）先把原先的密钥删除并生成新的密钥 123456789101112131415161718192021222324252627282930313233343536373839[root@python .ssh]# cd ~/.ssh/[root@python .ssh]# rm -rf id*[root@python .ssh]# ssh-keygen Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:dc:57:da:10:e5:1a:8b:15:e3:98:61:d4:02:9f:56:8f root@pythonThe key's randomart image is:+--[ RSA 2048]----+| .o+.=.. || o.B.B || *.E + || . o o O || S o = . || . || || || |+-----------------+[root@python .ssh]# ssh-copy-id -i id_rsa.pub 192.168.1.80/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.1.80's password: Number of key(s) added: 1Now try logging into the machine, with: \"ssh '192.168.1.80'\"and check to make sure that only the key(s) you wanted were added.[root@python .ssh]# ssh 192.168.1.80Enter passphrase for key '/root/.ssh/id_rsa': Last login: Fri May 15 15:28:54 2020 from fe80::c64e:c937:2ea8:6676%ens33[root@python ~]# exit登出Connection to 192.168.1.80 closed. 现在登陆需要私钥 （2）使用ssh-agent保存密钥 在Linux下，直接执行ssh-agent命令启动ssh-agent即可。启动以后，使用ssh-add命令将私钥添加到ssh-agent中。如下所示： 12345[root@python ~]# ssh-agent bash[root@python ~]# ssh-add ~/.ssh/id_rsaEnter passphrase for /root/.ssh/id_rsa: Identity added: /root/.ssh/id_rsa (/root/.ssh/id_rsa)[root@python ~]# 私钥添加完成后，可以执行ssh_add -L命令查看哪些私钥已经被添加到ssh-agent中。如下所示： 12[root@python ~]# ssh-add -Lssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDsP4VSOhnnCfidbg7e0OAQFcW5wAgPHld9S8KDTWv3X0/LNilYM3RkXQZ10XQ8Mw34i9rXa3SfqaHk6QYHXjNEUv6PEA/rKWY3kLXH9VUVHry4iwt9kVg9PowfccKLXPi8iWpqS7tk5ZEAnxihBtQattMTC44iz9X6hJDEn1r3r3YplJJGilIR+NaYJrM3ltxUBVuoJ82MfHOomhirc37ihLEwNbqRBMPYC4u1SoXDkagFsh0+HcuE0436yEByFxFw87jPmrjl7bgFsPahQsydrXySXOVdCzQJ8WuzJa1RvKr0xmgCjhZKExUYnMGAN9M79UBAyzZf2vUrwvvpPqWd /root/.ssh/id_rsa 启动ssh-agent以后，当我们尝试与远程服务器建立连接时，ssh客户端将会尝试使用存储在ssh-agent中的私钥与远程服务器进行认证。 12345[root@python ~]# ssh 192.168.1.80Last login: Fri May 15 15:38:28 2020 from 192.168.1.80[root@python ~]# exit登出Connection to 192.168.1.80 closed. 现在因为本地保持了私钥，所以不需要输入私钥了","path":"posts/d003.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python的网络","text":"一、端口扫描 仅仅知道网络上的主机是否可达还不够，很多情况下，我们需要的是一个端口扫描器。使用端口扫描器吋以进行安全检测与攻击防范。例如，在2017年5月12日，全球范围内爆发了基于Windows网络共享协议的永恒之蓝（Wannacry)勒索蠕虫。仅仅五个小时，包 括美国、中国、俄罗斯以及整个欧洲在内的100多个国家都不问程度地遭受永恒之蓝病毒攻击，尤其是高校、大型企业内网和政府机构专网，被攻击的电脑被勒索支付高额赎金才能解密恢复文件，对重要数据造成严重损失。永恒之蓝利用Windows系统的445端口进行蠕虫攻击，部分运营商已经在主干网络上封禁了 445端口，但是教育网以及大量企业内网并没有此限制，从而导致了永恒之蓝勒索蠕虫的泛滥。 所以作为工程师，一方面需要在日常维护养成良好的习惯，如配置防火墙、进行网络隔离、关闭不必要的服务、及时更新补丁；另一方面可以掌握一些安全相关的工具，在日常中进行安全防范，在紧急悄况下进行安全检测。在这一小节，我们将介绍如何使用Python进行端口扫描。有了端口扫描器，我们可以快速了解主机打开了哪些不必要的端口，以便及时消灭安全隐患。 在这一小节中，我们将使用Python语言编写一个端口扫描器，然后介绍大名鼎鼎的端 口扫描工具nmap，最后，通过python-nmap在Python代码中调用nmap进行端口扫描。 1、使用nmap扫描端口 Python-nmap模块是对nmap命令的封装。nmap是知名的网络探测和安全扫描程序, 是Network Mapper的简称。nmap可以进行主机发现（Host Discovery)、端口扫描（Port Scanning)、版本侦测（Version Detection〉、操作系统侦测（Operating System Detection)，nmap是网络管理员必用的软件之一。nmap因为功能强大、跨平台、开源、文档丰富等诸多优点，在安全领域使用非常广泛。 在使用之前，需要先安装nmap。如下所示： （1）安装namp 1-bash-4.2# yum -y install nmap nmap的使用非常灵活，功能又很强大，因此nmap有很多命令行选项。使用nmap时， 首先需要确定要对哪些主机进行扫描，然后确定怎么进行扫描（如使用何种技术，对哪些端 口进行扫描）。 nmap具有非常灵活的方式指定需要扫描的主机，我们可以使用nmap命令的-sL选项 来进行测试。-sL选项仅仅打印IP列表，不会进行任何操作。如下所示： 1234567891011121314Starting Nmap 6.40 ( http://nmap.org ) at 2020-05-14 16:57 CSTNmap scan report for 192.168.0.0 (192.168.0.0)Nmap scan report for 192.168.0.1 (192.168.0.1)Nmap scan report for 192.168.0.2 (192.168.0.2)Nmap scan report for 192.168.0.3 (192.168.0.3)Nmap done: 4 IP addresses (0 hosts up) scanned in 2.01 seconds-bash-4.2# nmap -sL 192.168.1.80/30Starting Nmap 6.40 ( http://nmap.org ) at 2020-05-14 16:57 CSTNmap scan report for 192.168.1.80 (192.168.1.80)Nmap scan report for 192.168.1.81 (192.168.1.81)Nmap scan report for 192.168.1.82 (192.168.1.82)Nmap scan report for 192.168.1.83 (192.168.1.83)Nmap done: 4 IP addresses (0 hosts up) scanned in 2.01 seconds nmap提供了非常灵活的方式来指定主机，包括同时指定多个IP、通过网段指定主机、通过通配符指定主机等。如下所示： 123456nmap -sL 47.100.98.242 14.215.177.39nmap -sL 47.100.98.*nmap -sL 47.100.98.242,243,245nmap -sL 47.100.98.242-250nmap -sL 47.100.98.* --exclude 47.100.98.242nmap -sL 47.100.98.242/30 除了上面指定主机的方式，我们也可以将IP地址保存到文本中，通过-iL选项读取文件中的IP地址。如下所示： 12345678910111213141516171819202122232425-bash-4.2# vim ip.list 192.168.1.80127.0.0.1-bash-4.2# nmap -iL ip.listStarting Nmap 6.40 ( http://nmap.org ) at 2020-05-14 21:32 CSTNmap scan report for 192.168.1.80 (192.168.1.80)Host is up (0.0000050s latency).Not shown: 997 closed portsPORT STATE SERVICE22/tcp open ssh111/tcp open rpcbind8888/tcp open sun-answerbookNmap scan report for localhost (127.0.0.1)Host is up (0.0000060s latency).Not shown: 995 closed portsPORT STATE SERVICE22/tcp open ssh25/tcp open smtp111/tcp open rpcbind631/tcp open ipp8888/tcp open sun-answerbook （2）扫描连续端口 1-bash-4.2# nmap -p20-25 47.100.98.242 （3）不进行端口扫描，仅仅判断主机是否可达 12nmap -sL ipnmap -sn ip 测试 1234567891011-bash-4.2# nmap -sL 192.168.1.80Starting Nmap 6.40 ( http://nmap.org ) at 2020-05-14 17:03 CSTNmap scan report for 192.168.1.80 (192.168.1.80)Nmap done: 1 IP address (0 hosts up) scanned in 2.01 seconds-bash-4.2# nmap -sn 192.168.1.80Starting Nmap 6.40 ( http://nmap.org ) at 2020-05-14 17:03 CSTNmap scan report for 192.168.1.80 (192.168.1.80)Host is up.Nmap done: 1 IP address (1 host up) scanned in 2.01 seconds （4）主机发现 端口扫描是nmap的重点，除此之外，我们也可以使用nmap检查网络上所有在线的主机，实现类似前边小节中列出网络上所有活跃的主机的功能。使用-sP或-sn选项可以告诉nmap不要进行端口扫描，仅仅判断主机是否可达。如下所示： 1234567[root@bogon ~]# nmap -sP 47.100.98.*Starting Nmap 6.40 ( http://nmap.org ) at 2020-03-01 00:25 CSTNmap done: 256 IP addresses (0 hosts up) scanned in 206.44 seconds [root@bogon ~]# nmap -sn 47.100.98.*Starting Nmap 6.40 ( http://nmap.org ) at 2020-03-01 00:35 CSTNmap done: 256 IP addresses (0 hosts up) scanned in 205.38 seconds （5）端口扫描 端口扫描是nmap最基本，也是最核心的功能，用于确定目标主机TCP/UDP端口的开放情况。不添加任何参数便是对主机进行端口扫描。默认情况下，nmap将会扫描1000个最常用的端口号。如下所示： 1[root@192 ~]# nmap 10.166.224.140 在进行端口扫描时，nmap提供了大M的参数控制端口扫描。包括端口扫描协议、端口扫描类型、扫描的端口号。如下所示： 端口扫描协议：T (TCP)、U (UDP)、S (SCTP&gt;、P (IP); 端口扫描类型：-sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans; 扫描的端口号：-p 80,443 -p 80-160 nmap中的端口扫描协议、扫描类型和端口号相关的选项，可以结合起来使用。如下所示： -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 nmap通过探测将端口划分为6个状态，下表给出了每个状态的含义。 端口状态 状态含义 open 端口是开放的 closed 端口是关闭的 filtered 端口被防火墙IDS/IPS屏蔽，无法确认其状态 unfiltered 端口没有被屏蔽，但是否开放需要进一步确定 open|filtered 端口是开放的或被屏蔽 closed|filtered 端口是关闭的或被屏蔽 在进行端口扫描时，可以使用不同的端口扫描类型。常见的端口扫描类型如下： 123TCP SYNC SCAN:半开放扫描，这种类沏的扫描为发送一个SYN包，启动一个TCP会话，并等待响应的数据包。如果收到的是一个reset包，表明端口是关闭的; 如果收到的是一个SYNC&#x2F;ACK包，则表示端口是打开的。TCP NULL SCAN: NULL扫描把TCP头中的所有标志位都设置为NULL。如果收到的是一个RST包，则表示相应的端口是关闭的。TCP FIN SCAN : TCP FIN扫描发送一个表示结束一个活跃的TCP连接的FIN包， 让对方关闭连接。如果收到了一个RST包，则表示相应的端口是关闭的。 TCPXMASSCAN: TCPXMAS扫描发送PSH、FIN、URG和TCP标志位被设置为1的数据包，如果收到一个RST包，则表示相砬端口是关闭的。 （6）版本侦测 nmap在进行端口扫描时，还可以进行版本侦测。版本监测功能用于确定开放端口上运行的应用程序及版本信息。如下所示： 123456789-bash-4.2# nmap -sV 10.166.224.140Starting Nmap 6.40 ( http://nmap.org ) at 2020-05-14 17:06 CSTNmap scan report for 10.166.224.140 (10.166.224.140)Host is up (0.00038s latency).All 1000 scanned ports on 10.166.224.140 (10.166.224.140) are filteredService detection performed. Please report any incorrect results at http://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 6.13 seconds （7）操作系统监测 操作系统侦测用于监测主机运行的操作系统类型及设备类型等信息。nmap拥有丰富的系统数据库，可以识别2600多种操作系统与设备类型。如下所示： 12345678910111213141516-bash-4.2# nmap -sO 192.168.1.80Starting Nmap 6.40 ( http://nmap.org ) at 2020-05-14 17:05 CSTNmap scan report for 192.168.1.80 (192.168.1.80)Host is up (0.000018s latency).Not shown: 249 closed protocolsPROTOCOL STATE SERVICE1 open icmp2 open|filtered igmp6 open tcp17 open udp103 open|filtered pim136 open|filtered udplite255 open|filtered unknownNmap done: 1 IP address (1 host up) scanned in 3.21 seconds 2、使用python-nmap进行端口扫描 我们在上一小节中，花f较多的篇幅介绍nmap。Python的Python-nmap仅仅趋对nmap的封装，因此，要使用Python-nmap,必须先了解nmap。Python-nmap相对于nmap, 主要的改进在于对输出结果的处理。Python-nmap将nmap的输出结果保存到宇典之中，我们只需要通过Python的字典就可以获取到nmap的输出信息，不用像Shell脚本一样通过字符串处理和正则表达式来解析nmap的结果。Python-nmap将nmap的强大功能与Python语言优秀的表达能力进行了完美的结合，使用Python语言丰富的数据结构保存结果，以便后续继续进行处理，如使用Python-nmap生成相关的报告。 Python-nmap是开源的库，因此，在使用之前需要手动进行安装。如下所示： 1pip3 install python-nmap Python-nmap的使用非常简单，我们只要创建一个PortScarmer对象，并调用对象的 scan方法就能够完成基本的nmap端口扫描。如下所示： 123456789101112131415161718192021222324252627282930313233343536373839-bash-4.2# ipythonPython 3.8.1 (default, Mar 9 2020, 12:35:12) Type 'copyright', 'credits' or 'license' for more informationIPython 7.13.0 -- An enhanced Interactive Python. Type '?' for help.In [1]: import nmap In [2]: nm = nmap.PortScanner() In [3]: nm.scan('192.168.1.80','22-1000') Out[3]: &#123;'nmap': &#123;'command_line': 'nmap -oX - -p 22-1000 -sV 192.168.1.80', 'scaninfo': &#123;'tcp': &#123;'method': 'syn', 'services': '22-1000'&#125;&#125;, 'scanstats': &#123;'timestr': 'Thu May 14 17:13:44 2020', 'elapsed': '8.15', 'uphosts': '1', 'downhosts': '0', 'totalhosts': '1'&#125;&#125;, 'scan': &#123;'192.168.1.80': &#123;'hostnames': [&#123;'name': '192.168.1.80', 'type': 'PTR'&#125;], 'addresses': &#123;'ipv4': '192.168.1.80'&#125;, 'vendor': &#123;&#125;, 'status': &#123;'state': 'up', 'reason': 'localhost-response'&#125;, 'tcp': &#123;22: &#123;'state': 'open', 'reason': 'syn-ack', 'name': 'ssh', 'product': 'OpenSSH', 'version': '6.6.1', 'extrainfo': 'protocol 2.0', 'conf': '10', 'cpe': 'cpe:/a:openbsd:openssh:6.6.1'&#125;, 111: &#123;'state': 'open', 'reason': 'syn-ack', 'name': 'rpcbind', 'product': '', 'version': '2-4', 'extrainfo': 'RPC #100000', 'conf': '10', 'cpe': ''&#125;&#125;&#125;&#125;&#125; 当我们创建PortScanner对象时，Python-nmap会检査系统中是否已经安装了 nmap，如果没有安装，抛出PortScannerError异常。调用PortScanner对象的scan方法进行扫描以后就可以通过该类的其他方法获取本次扫描的信息。如命令行参数、主机列表、扫描的方法等。如下所示： 12345678In [4]: nm.command_line() Out[4]: 'nmap -oX - -p 22-1000 -sV 192.168.1.80'In [5]: nm.scaninfo() Out[5]: &#123;'tcp': &#123;'method': 'syn', 'services': '22-1000'&#125;&#125;In [6]: nm.all_hosts() #所有主机 Out[6]: ['192.168.1.80'] Python-nmap还提供了以主机地址为键，获取单台主机的详细信息。包括获取主机网络状态、所有的协议、所有打开的端口号，端口号对应的服务等。如下所示： 12345678910111213141516171819202122In [8]: nm['192.168.1.80'].state() Out[8]: 'up'In [9]: nm['192.168.1.80'].all_protocols() Out[9]: ['tcp']In [10]: nm.scan('47.100.98.242,127.0.0.2','21-25') Out[10]: &#123;'nmap': &#123;'command_line': 'nmap -oX - -p 21-25 -sV 47.100.98.242,127.0.0.2', 'scaninfo': &#123;'error': ['Failed to resolve \"47.100.98.242,127.0.0.2\".\\nWARNING: No targets were specified, so 0 hosts scanned.\\n'], 'warning': ['WARNING: No targets were specified, so 0 hosts scanned.\\n'], 'tcp': &#123;'method': 'syn', 'services': '21-25'&#125;&#125;, 'scanstats': &#123;'timestr': 'Thu May 14 17:22:06 2020', 'elapsed': '16.00', 'uphosts': '0', 'downhosts': '0', 'totalhosts': '0'&#125;&#125;, 'scan': &#123;&#125;&#125;In [11]: nm['192.168.1.80'].key() Out[11]: dict_keys(['hostnames', 'addresses', 'vendor', 'status', 'tcp']) 二、使用IPy进行IP管理 在网络设计中，首先要做的就是规划IP地址。IP地址规划的好坏直接影响路由算法的效率，包括网络性能和扩展性。在IP地址规划中，需要进行大量的IP地址计算，包括网段、网络掩码、广播地址、子网数、IP类型等计算操作。在大量的计算操作中，如果没有一个好的工具，计算IP地址是一个很无趣有容易出错的事情。在Perl语言中，可以使用NET::IP模块，在Python语言中，可以使用开源的IPy模块进行操作。 1、IPy模块介绍 IPy模块是一个处理IP地址的模块，它能够自动识别IP地址的版本、IP地址的类型。使用IPy模块，可以方便地进行IP地址的计算。 IPy模块是第三方的开源模块，因此，在使用之前需要进行安装。直接使用pip安装即可： 1pip install ipy 2、IPy模块的基本使用 IPy模块有一个IP类，这个类几乎可以接受任何格式的IP地址和网段。如下所示： 123456789101112131415161718In [1]: import IPy In [2]:from IPy import IP In [3]: IP(0x7f000001) Out[3]: IP('127.0.0.1')In [4]: IP('127.0.0.1') Out[4]: IP('127.0.0.1')In [5]: IP('127.0.0.0/30') Out[5]: IP('127.0.0.0/30')In [6]: IP('1080:0:0:0:8:800:200C:417A')Out[6]: IP('1080::8:800:200c:417a')In [7]: IP('127.0.0.0-127.255.255.255')Out[7]: IP('127.0.0.0/8') IP类包含了许多的方法，用来进行灵活的IP地址操作。例如： （1）version:获取IP地址的版本 12345678In [9]: IP('127.0.0.0-127.255.255.255') Out[9]: IP('127.0.0.0/8')In [10]: IP('10.0.0.0/8').version() Out[10]: 4In [11]: IP('::1').version() Out[11]: 6 （2）len:得到子网IP地址的个数 12345In [12]: IP('127.0.0.0/30').len() Out[12]: 4 In [13]: IP('127.0.0.0/28').len() Out[13]: 16 （3）iptype:返回IP地址的类型 12345In [14]: IP('127.0.0.1').iptype() Out[14]: 'LOOPBACK'In [15]: IP('8.8.8.8').iptype() Out[15]: 'PUBLIC' （4）int:返回IP地址的整数形式 12In [16]: IP('8.8.8.8').int() Out[16]: 134744072 （5）strHex:返回IP地址的十六进制形式 12In [17]: IP('8.8.8.8').strHex() Out[17]: '0x8080808' （6）strBin:返回IP地址的二进制形式 12In [18]: IP('8.8.8.8').strBin()Out[18]: '00001000000010000000100000001000' 有一个方便的函数能够将IP转换为不同的格式，在工作环境中将会非常有用。例如，以数宇的形式在数据库中存储IP地址，在数据库中存储IP地址有两种形式，第一种是以变长字符串的形式将IP地址保存到数据库中，另一种是将IP地址转换为整数以后保存到数据库中。将IP地址转换为整数进行存储能够有效地节省存储空间，提高数据库的存储效率和访问速度。因此，在最佳实践中，我们一般将IP地址以数字的形式保存到数据库中。需要 IP地址时，再将数字形式的IP地址转换为字符串格式的IP地址。这个需求十分常见，因 此，MySQL提供了两个函数，分别用以将字符串形式的IP地址转换为数据格式的IP地址，以及将数字格式的IP地址转换为字符串形式的IP地址。如下所示： 123456789101112131415mysql&gt; select INET_ATON('10.166.224.14');+----------------------------+| INET_ATON('10.166.224.14') |+----------------------------+| 178708494 |+----------------------------+1 row in set (0.00 sec)mysql&gt; select INET_NTOA('178708494');+------------------------+| INET_NTOA('178708494') |+------------------------+| 10.166.224.14 |+------------------------+1 row in set (0.00 sec) 除了使用MySQL自带的函数以外，我们也可以使用IP类提供的int方法将字符串形式的IP地址转换为数字形式的IP地址。要将数字形式的IP地址转换会字符串形式的IP地址，可以直接使用数字的方式创建IP对象。如下所示： 12345In [9]: IP('178708494') Out[9]: IP('10.166.224.14')In [10]: '&#123;0&#125;'.format(IP(\"178708494\"))Out[11]: '10.166.224.14' 3、网段管理 IP类的构造函数可以接受不同格式的IP地址，也可以接受网段。如下所示： 12345678910In [1]: from IPy import IP In [2]: IP('127.0.0.0/24') Out[2]: IP('127.0.0.0/24')In [3]: IP('127.0.0.0-127.255.255.255')Out[3]: IP('127.0.0.0/8')In [4]: IP('127.0.0.0/127.255.255.255')Out[4]: IP('127.0.0.0/31') 网段包含多个IP地址，我们可以直接使用len方法或者Python内置的len函数得到网段中IP地址的个数，也可以直接使用for循环迭代网段，以此遍历各个IP。如下所示： 12345678910111213141516171819In [19]: ips = IP('10.166.224.144/28') In [20]: ips.len() Out[20]: 16In [21]: len(ips) Out[21]: 16 In [22]: ip = [ip for ip in ips] In [23]: ip = [ip for i in ips] In [24]: ip Out[24]: [[IP('10.166.224.144'), IP('10.166.224.145'), IP('10.166.224.146'), IP('10.166.224.147'), IP('10.166.224.148'), 通过IP类，我们也可以方便地判断一个IP是否属于一个网段，判断子网是否包含于另一个网段中，以及两个网段是否有重叠。如下所示： 123456789101112In [25]: '10.166.224.146' in IP('10.166.224.144/28') //测试ip是否在某网段内Out[25]: True In [16]: '10.166.224.144' in IP('10.166.224.144/28')Out[16]: TrueIn [17]: IP('10.166.224.144/29') in IP('10.166.224.144/28')Out[17]: TrueIn [18]: IP('10.166.224.0/28').overlaps('10.166.224.144/28')Out[18]: 0 对于网段，我们可以方便地获取网络地址掩码以及网络的广播地址。如下所示： 12345In [22]: ips.netmask() Out[22]: IP('255.255.255.240')In [23]: ips.broadcast() Out[23]: IP('10.166.224.159') 三、使用dnspython解析DNS 1、dnspython简介与安装 dnspython是Python实现的一个DNS工具集，它支持几乎所有的记录类型，可以用于查询、传输并动态更新ZONE信息，同时支持TSIG（事务签名）验证消息和EDNS0（扩展DNS）。使用dnspython可以代替Linux命令行下的nslookup以及dig等工具。 dnspython是第三方的开源模块，因此，使用之前需要先进行安装： 1pip3 install dnspython 2、使用dnspython进行域名解析 dnspython提供了丰富的API，其中，高层次的API根据名称和类型执行查询操作，低层次的API可以直接更新ZONE信息、消息、名称和记录。在所有的API中，最常使用的是域名查询。dnspython提供了一个DNS解析类resolver，使用它的query方法可以实现域名的查询功能。 1dns.resolver.query(qname,rdtype=1,rdclass=1,tcp=False,source=None,raise_on_no_answer=True,source_port=0) query方法各参数的含义如下： qname:査询的域名； rdtype:指定RR资源； 12345A:地址记录（Address),返回域名指向的IP地址；NS:域名服务器记录（Name Server)，返回保存下一级域名信息的服务器地址。该记录只能设罝为域名，不能设置为IP地址；MX:邮件记录（Mail exchange),返回接收电子邮件的服务器地址；CNAME:规范名称记录（Canonical Name)，别名记录，实现域名间的映射；PTR:逆向査询记录（Pointer Record),反向解析，与A记录相反，将IP地址转换为主机名。 rdclass:网络类型； tcp:指定査询是否启用TCP协议； source:査询源的地址； source_port:査询源的端口 ; raise_on_no_answer:指定査询无应答时是否触发异常，默认为True。 在使用dnspython查询DNS相关信息之前，我们先简单了解一下dig命令，以便对照查看Python程序的输出结果与dig命令的输出结果。 dig的全称是domain information groper,它是一个灵活探测DNS的工具，可以执行DNS査找，并显示从查询的名称服务器返回的答案。由于dig命令灵活易用、输出明确， 因此，大多数DNS管理员都使用dig解决DNS问题。 在我的主机上运行dig命令査找dnspython.org域名的信息。运行结果如下： 1234567891011121314151617181920212223242526272829[root@192 ~]# dig qiniu.lexizhi.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-72.el7 &lt;&lt;&gt;&gt; qiniu.lexizhi.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 35907;; flags: qr rd ra; QUERY: 1, ANSWER: 12, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;qiniu.lexizhi.com. IN A;; ANSWER SECTION:qiniu.lexizhi.com. 5 IN CNAME www.lexizhi.com.qiniudns.com.www.lexizhi.com.qiniudns.com. 5 IN CNAME dt003.china.line.qiniudns.com.dt003.china.line.qiniudns.com. 5 IN CNAME tinychinacdnweb.qiniu.com.w.kunlunno.com.tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.231tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.234tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.232tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.233tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 219.147.157.66tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.228tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.235tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.229tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.230;; Query time: 633 msec;; SERVER: 192.168.79.2#53(192.168.79.2);; WHEN: 一 3月 02 17:29:51 CST 2020;; MSG SIZE rcvd: 300 （1）在Python代码中，可以使用dnspython查询A记录。如下所示： 123456from __future__ import print_functionimport dns.resolverdata = dns.resolver.query('www.lexizhi.com', 'A')for item in data: print(item) 输出结果如下： 147.100.98.242 （2）使用dnspython实现NS记录，查询方法如下： 123456from __future__ import print_functionimport dns.resolverdata = dns.resolver.query('dnspython.org', 'NS')for item in data: print(item) 输出结果如下： 1234ns-343.awsdns-42.com.ns-518.awsdns-00.net.ns-1253.awsdns-28.org.ns-2020.awsdns-60.co.uk. 从输出结果来看，使用dig命令或dnspython模块都是一样的。如果在命令行操作，建议使用dig命令。如果要使用程序管理DNS或查询DNS的内容，则推荐使用dnspython模块。","path":"posts/5943.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python邮件和网络的简单使用","text":"一、Excel文档操作练习（pycharm） sorted() 函数对所有可迭代的对象进行排序操作。 sort 与 sorted 区别： sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。 list 的 sort 方法返回的是对已经存在的列表进行操作，而内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。 1、需提前在当前目录准备好excel文件（多复制几个）： 2、编写python脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647'''员工角色: 行政工作内容: 做员工调查问卷工作流程: 给每个员工发送统-的问卷的模板要求: 员工按照提供的固定模板，填写调查问卷,并且发送给行政人员行政人员可能会受到多份格式相同而内容不同的Excel文件处理Excel文件:手工合并多个文件内容，比较常见的方法: 以某个文件(result.xlsx)的内容为基础,打开别的文件,复制其中需要的数据,粘贴到result.xlsx'''import osimport globimport openpyxl# 定义函数，获取指定目录下的所有Excel文档def get_all_xlsx_files(path): xlsx_files = glob.glob(os.path.join(path,'*.xlsx')) sorted(xlsx_files, key=str.lower) return xlsx_files# 合并Excel文档的方法def merge_xlsx_files(xlsx_files): wb = openpyxl.load_workbook(xlsx_files[0]) ws = wb[\"Sheet1\"] # 已排序后的Excel文件的第一 顺序的文档作为基础，读取其他文档内容 for filename in xlsx_files[1:]: workbook = openpyxl.load_workbook(filename) worksheet = workbook[\"Sheet1\"] # 从工作表的第二行开始读取,第一行是表头,不读取。 for row in worksheet.iter_rows(min_row=2): values = [cell.value for cell in row] # 将读取到的单元格内容追加到第一顺序的Excel文档指定的sheet内容后面 ws.append(values) return wbdef main(): xlsx_files = get_all_xlsx_files(os.path.basename(\".\")) wb = merge_xlsx_files(xlsx_files) wb.save('result.xlsx')if __name__ == '__main__': main()# 获取指定目录下的所有Excel文档# xlsx_file = get_all_xlsx_files('.') 3、执行过后查看result.xlsx 都合并到一起了 二、python发送邮件（SMTP协议介绍） smtplib发送邮件的步骤： 连接SMTP服务器 smtp = smtplib.SMTP(‘smtp.qq.com’,25) 发送SMTP的“Hello”消息 smtp.ehlo() smtp.starttls() 登录到SMTP服务器 smtp.login(发送邮件的邮箱，邮箱授权码，不是邮箱密码) 发送电子邮件 smtp.send(发件人，收件人，邮件内容) 关闭SMTP服务器的连接 smtp.quit() 1、测试一下 1234567891011121314151617import smtplib# 连接SMTP服务器smtp = smtplib.SMTP('smtp.qq.com',25)# 发送SMTP的\"Hello\"消息print(smtp.ehlo()) #不加密print(smtp.starttls()) #加密# 登录到SMTP服务器print(smtp.login('2877364346@qq.com','gengfveyokhfdffe')) #绑定授权码# 发送电子邮件 smtp.send(发件人，收件人，邮件内容)print(smtp.sendmail('2877364346@qq.com','3552422607@qq.com','Subject:this is title\\nthis is content'))# 关闭SMTP服务器的连接smtp.quit()print('退出连接') 输出结果如下： 123456789101112#不加密(250, b'newxmesmtplogicsvrsza5.qq.com\\nPIPELINING\\nSIZE 73400320\\nSTARTTLS\\nAUTH LOGIN PLAIN\\nAUTH=LOGIN\\nMAILCOMPRESS\\n8BITMIME')#加密(220, b'Ready to start TLS from 113.25.19.201 to newxmesmtplogicsvrsza5.qq.com.')#绑定授权码成功(235, b'Authentication successful')# 发送电子邮件成功&#123;&#125;退出连接 查看成功接收的邮件： 2、较完整的发送 123456789101112131415161718192021222324252627282930313233343536373839404142434445'''发送纯文本邮件'''from __future__ import print_functionimport smtplibfrom email.mime.text import MIMETextSMTP_SERVER = 'smtp.qq.com'SMTP_PORT = 25# 定义发送邮件的方法def send_mail(user,pwd,to,subject,text): # 构建MIMEText邮件对象(纯文本) msg = MIMEText(text) msg['From'] = user msg['To'] = to msg['Subject'] = subject # 连接SMTP服务器 smtp = smtplib.SMTP(SMTP_SERVER,SMTP_PORT) print(\"邮件服务器已连接\") try: smtp.ehlo() print('和服务器打招呼。。。') smtp.starttls() print('加密传输!') smtp.ehlo() print('再次打招呼。。。') smtp.login(user,pwd) print('登陆服务器') smtp.sendmail(user,to,msg.as_string()) print('邮件已发送。。。') except Exception as err: raise SystemExit('邮件发送失败:&#123;0&#125;'.format(err)) finally: smtp.quit()def main(): send_mail('2877364346@qq.com','gengfveyokhfdffe','3552422607@qq.com','这是一封测试邮件','你好xgp！')if __name__ == '__main__': main() 输出结果如下： 123456邮件服务器已连接和服务器打招呼。。。加密传输!再次打招呼。。。登陆服务器邮件已发送。。。 查看成功接收的邮件： 3、发送带附件的邮件 发送带附件的邮件，首先要创建MIMEMultipart()实例，然后构造附件，如果有多个附件，可依次构造，最后利用smtplib.smtp发送。 123456import yagmailyag = yagmail.SMTP(user='2877364346@qq.com', password='gengfveyokhfdffexgp', host='smtp.qq.com', port=465)content = ['yagmail测试邮件内容', '1000263.jpg']yag.send('3552422607@qq.com', 'this is from yagmailtest email.', content) 查看成功接收的邮件： 三、网络管理 1、列出活跃的主机 在这一小节中，我们将会学习如何在shell脚本中调用ping命令得到网络上活跃的主机列表，随后，我们使用Python语言改造这个程序，以此支持并发的判断。 ping一下 （1）创建测试的网络 123456789-bash-4.2# vim ips.txt # 本机ip192.168.1.80 # 本机127.0.0.1 # 不可达的地址192.168.2.2 （2）创建shell脚本，批量测IP是否可用 123456789101112-bash-4.2# vim ping.sh #/usr/bin/bashfor ip in $(cat ips.txt) do if ping $ip -c 2 &amp;&gt;/dev/null then echo \"$ip 是活跃的。\" else echo \"$ip 是不可达的。\" fi done 执行结果如下： 1234-bash-4.2# sh ping.sh 192.168.1.80 是活跃的。127.0.0.1 是活跃的。192.168.2.2 是不可达的。 （3）线程模块 Python中使用线程有两种方式：函数或者用类来包装线程对象。 函数式：调用thread模块中的start_new_thread()函数来产生新线程。语法如下: 1thread.start_new_thread ( function, args[, kwargs] ) 参数说明: function - 线程函数。 args - 传递给线程函数的参数,他必须是个tuple类型。 kwargs - 可选参数。 Python通过两个标准库thread和threading提供对线程的支持。thread提供了低级别的、原始的线程以及一个简单的锁。 threading 模块提供的其他方法： threading.currentThread(): 返回当前的线程变量。 threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 除了使用方法外，线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法: run(): 用以表示线程活动的方法。 start(): 启动线程活动。 join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。 isAlive(): 返回线程是否活动的。 getName(): 返回线程名。 setName(): 设置线程名。 （4）创建python脚本，批量测IP是否可用 12345678910111213141516171819202122232425262728293031#!/usr/bin/python3# encodig=utf-8import osimport threadingdef ping(ip): '''测试网卡的连通性''' res = os.system(u'ping -c 2 '+ip) if res == 0: print('网卡正常！') else: print('网卡异常！') return resdef main(): with open('ips.txt') as f: # 使用多线程 threads = [] lines = f.readlines() for line in lines: thread = threading.Thread(target=ping, args=(line,)) thread.start() threads.append(thread) for thr in threads: thr.join()if __name__ == '__main__': main() 执行结果如下： 2、端口扫描 在Linux下，可以便用ping命令要判断一台主机是否可达。而判断一个端口是否打开可以使用telnet命令。 我们可以模仿前面小节中并行ping的例子，在Python代码中调用telnet命令判断一个端口是否打开。但是telnet命令存在一个问题，当我们telnet一个不可达的端口时，telnet需要很久才 能够超时返回，井且telnet命令没有参数控制超时时间。此外， 如果Python标准库中有相应的模块，应该尽可能地使用Python的标准库，而不是在Python代码中执行Linux命令。这一方面能够增加代码的可读性、可维护性.另一方面也能够保证程序跨平台运行。 为了使用Python编写端口扫描器，我们需要简单了解socket模块。socket模块为操作系统的socket连接提供了一个Python接口，有了socket模块，我们可以完成任何使用socket的任务。 （1）安装telnet 1-bash-4.2# yum -y install telnet 测试一下 1234567-bash-4.2# telnet 192.168.1.80 22 #测试连接，本机的22端口Trying 192.168.1.80...Connected to 192.168.1.80.Escape character is '^]'.SSH-2.0-OpenSSH_6.6.1exit #退出连接 （2）socket模块 socket模块提供了一个工厂函数socket, socket函数会返向一个socket对象。我们可以给socket函数传递参数，以此创建不同网络协议和网络类塑的socket对象。默认情况下，socket函数会返回一个使用TCP协议的socket对象。 什么是 Socket? Socket又称&quot;套接字&quot;，应用程序通常通过&quot;套接字&quot;向网络发出请求或者应答网络请求，使主机间或者一台计算机上的进程间可以通讯。 socket()函数 Python 中，我们用 socket（）函数来创建套接字，语法格式如下： 1socket.socket([family[, type[, proto]]]) 参数 family: 套接字家族可以使AF_UNIX或者AF_INET type: 套接字类型可以根据是面向连接的还是非连接分为SOCK_STREAM或SOCK_DGRAM protocol: 一般不填默认为0. （1）如下所示: 12345678910111213141516171819-bash-4.2# ipythonPython 3.8.1 (default, Mar 9 2020, 12:35:12) Type 'copyright', 'credits' or 'license' for more informationIPython 7.13.0 -- An enhanced Interactive Python. Type '?' for help.In [1]: import socket In [2]: s = socket.socket() In [4]: s.connect(('47.100.98.242',80)) In [6]: s.send(\"GET/HTTP/1.0\".encode()) Out[6]: 12In [7]: print(s.recv(200)) b''In [8]: s.close Out[8]: &lt;bound method socket.close of &lt;socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('192.168.1.80', 42550), raddr=('47.100.98.242', 80)&gt;&gt; 在这个例子中, socketI厂函数以默认参数AF. INET和SOCK STREAM创建了一个名为s的socket对象,该对象可以在进程间进行TCP通信。创建完对象以后，我们使用connect函数连接到远程服务器的80端口，并发送一个HTTP请求到远程服务器，发送完毕之后，接收服务器响应的前200个字节。最后，调用socket对象的close方法关闭连接。 在这个例子中,我们用到了socket工厂函数、socket的connect方法、 send方法、recv 方法和close方法,这也是socket中最常使用的一些方法。 （2）如下所示 1234567import sockets = socket. socket()s. connect(( '47.100.98.242' ,80))s.send( ' http:/ /www.baidu.com/'.encode())print(s.recv(10))s.close() 执行结果如下 1b'HTTP/1.1 4' （3）接下来，我们就看一下如何使用简单的socket接口编写一个端口扫描器。 如下所示: 123456789101112131415161718192021222324#!/usr/bin/python3# encoding=utf-8from socket import *def conn_scan(host, port): conn = socket(AF_INET, SOCK_STREAM) try: conn.connect((host, port)) print(host, port, '已连接') except Exception as e: print(host, port, '连接失败') finally: conn.close()def main(): host = '47.100.98.242' for port in range(20, 5000): conn_scan(host, port)if __name__ == '__main__': main() 执行结果如下： 1234547.100.98.242 20 连接失败47.100.98.242 21 已连接47.100.98.242 22 已连接47.100.98.242 23 连接失败47.100.98.242 24 连接失败 较快的： 1234567891011121314151617181920212223#encoding=utf-8import telnetlibdef conn_scan(host, port): t = telnetlib.Telnet() try: t.open(host, port, timeout=1) print(host, port, '已连接') except Exception as e: print(host, port, '连接失败') finally: t.close()def main(): host = '47.100.98.242' for port in range(20, 26): conn_scan(host, port)if __name__ == '__main__': main() 输出结果如下： 123447.100.98.242 20 连接失败47.100.98.242 21 已连接47.100.98.242 22 已连接47.100.98.242 23 连接失败","path":"posts/539e.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python的文件处理","text":"一、python操作excel之openpyxl 前言 根据官方文档，openpyxl 是一个第三方库, 它可以可以处理 xlsx/xlsm 格式的 Excel 文件(A Python library to read/write Excel 2010 xlsx/xlsm files)。 openpyxl 中主要的三个概念: Workbook(工作表)，Sheet(表页)和Cell(格)。 openpyxl 中主要的操作: 打开 Workbook，定位 Sheet，操作 Cell。 （1）支持excel格式 xlsx xlsm xltx xltm （2）基本用法 首先介绍下Excel的一些基本概念，Workbook相当于是一个文件,WorkSheet就是文件里面的每个具体的表,比如新建Excel文件里面的’Sheet1’这个,一个Workbook里面有一个或多个WorkSheet. workbook： 工作簿，一个excel文件包含多个sheet。 worksheet：工作表，一个workbook有多个，表名识别，如“sheet1”,“sheet2”等。 cell： 单元格，存储数据对象 1、安装openpyxl 1pip install openpyxl 2、参数介绍 （一）常遇到的情况 就我自己来说，常遇到的情况可能就下面几种： 读取excel整个sheet页的数据。 读取指定行、列的数据 往一个空白的excel文档写数据 往一个已经有数据的excel文档追加数据 下面就以这几种情况为例进行说明。 （二） 涉及的模块及函数说明 就我知道的，有3个模块可以操作excel文档，3个模块通过pip都可以直接安装。 xlrd:读数据 xlwt:写数据 openpyxl：可以读数据，也可以写数据 这里就就只说明openpyxl了，因为这个模块能满足上面的需要了。 openpyxl函数 函数 说明 load_workbook(filename) 打开excel，并返回所有sheet页访问指定sheet页的方法：*#**打开excel文档 *wb = openpyxl.load_workbook(file_name) *#**访问sheet页 *sheet = wb[‘sheet页的名称’]#关闭excel文档wb.close() Workbook() 创建excel文档wb = openpyxl.Workbook()#保存excel文档wb.save（‘文件名.xlsx’） 下面的函数是针对sheet页的sheet = wb[‘sheet页的名称’]访问指定单元格的方式sheet[‘A1’]、sheet[‘B1’]… min_row 返回包含数据的最小行索引，索引从1开始例如：sheet.min_row max_row 返回包含数据的最大行索引，索引从1开始 min_column 返回包含数据的最小列索引，索引从1开始 max_column 返回包含数据的最大列索引，索引从1开始 values 获取excel文档所有的数据，返回的是一个generator对象 iter_rows(min_row=None, max_row=None, min_col=None, max_col=None) min_row:最小行索引max_row:最大行索引min_col:最小列索引max_col:最大列索引获取指定行、列的单元格，没指定就是获取所有的 title WorkSheet的名称 现在我有这么一个excel，下面以这个excel进行说明。 3、读取文件属性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import openpyxl# 打开一个EXcel文档wb = openpyxl.load_workbook('test.xlsx')sheet2 = wb['Sheet2']print('表名为：',sheet2.title)print('数据的行数和列数：',sheet2.dimensions)print('最小行数为：',sheet2.max_row)print('最大行数为：',sheet2.min_row)print('最大列数为：',sheet2.max_column)print('最小列数为：',sheet2.min_column)# 获取指定单元格print('单元格A1：',sheet2['A1'])print('单元格B1：',sheet2.cell(row=1, column=2))# 获取行print('行：',sheet2.rows)# 获取列print('列：',sheet2.columns)# 获取所有的数据print('所有的数据：',sheet2.values)# 查看Excel文档的属性print('是否只读：',wb.read_only)print('文档的属性：',wb.properties)#文档的字符集格式print('字符集格式：',wb.encoding)# 获取活跃的工作表print('活跃的工作表：',wb.active)# 获取所有的工作表print('所有的工作表：',wb.worksheets)# 获取所有的工作表的名称print('输出文件所有工作表名：', wb.sheetnames)# 根据表格名称获取worksheet对象,区分大小写print('表名：',wb['Sheet2']) 输出结果为： 1234567891011121314151617181920表名为： Sheet2数据的行数和列数： A1:C8最小行数为： 8最大行数为： 1最大列数为： 3最小列数为： 1单元格A1： &lt;Cell 'Sheet2'.A1&gt;单元格B1： &lt;Cell 'Sheet2'.B1&gt;行： &lt;generator object Worksheet._cells_by_row at 0x000002612197F2E0&gt;列： &lt;generator object Worksheet._cells_by_col at 0x000002612197F2E0&gt;所有的数据： &lt;generator object Worksheet.values at 0x000002612197F2E0&gt;是否只读： False文档的属性： &lt;openpyxl.packaging.core.DocumentProperties object&gt;Parameters:creator='小钢炮', title=None, description=None, subject=None, identifier=None, language=None, created=datetime.datetime(2015, 6, 5, 18, 17, 20), modified=datetime.datetime(2020, 5, 7, 4, 9, 19), lastModifiedBy='xxx', category=None, contentStatus=None, version=None, revision=None, keywords=None, lastPrinted=None字符集格式： utf-8活跃的工作表： &lt;Worksheet \"成绩表\"&gt;所有的工作表： [&lt;Worksheet \"Sheet2\"&gt;, &lt;Worksheet \"Sheet3\"&gt;, &lt;Worksheet \"成绩表\"&gt;]输出文件所有工作表名： ['Sheet2', 'Sheet3', '成绩表']表名： &lt;Worksheet \"Sheet2\"&gt; 4、读取文件内容 123456789101112131415161718192021222324252627import openpyxlwb = openpyxl.load_workbook('test.xlsx')sheet2 = wb['Sheet2']# 获取单元格内容# 方式一print('方法一')for row in sheet2.values: print(*row)print('=========================')# 方式二print('方法二')for row in sheet2.rows: print(*[cell.value for cell in row])print('=========================')# 方式三print('方法三')for row in sheet2.iter_rows(): print(*[cell.value for cell in row])print('=========================')# 方式四(最复杂，最原始)print('方法四')for i in range(sheet2.min_row, sheet2.max_row + 1): for j in range(sheet2.min_column, sheet2.max_column + 1): print(sheet2.cell(row=i,column=j).value,end=' ') print() 输出结果为： 123456789101112131415161718192021222324252627282930313233343536373839方法一序号 姓名 年龄1 发生的 252 浮动视 263 好的 274 经回复 285 好的话 296 套网 307 太温柔 31=========================方法二序号 姓名 年龄1 发生的 252 浮动视 263 好的 274 经回复 285 好的话 296 套网 307 太温柔 31=========================方法三序号 姓名 年龄1 发生的 252 浮动视 263 好的 274 经回复 285 好的话 296 套网 307 太温柔 31=========================方法四序号 姓名 年龄 1 发生的 25 2 浮动视 26 3 好的 27 4 经回复 28 5 好的话 29 6 套网 30 7 太温柔 31 5、删除和创建表 12345678910111213141516171819import openpyxl# 打开一个EXcel文档wb = openpyxl.load_workbook('test.xlsx')sheet2 = wb['Sheet2']# 删除表sheet1 = wb.get_sheet_by_name('Sheet1')wb.remove_sheet(sheet1)# 保存workbook的修改wb.save('test.xlsx')# 创建一个新的worksheetwb.create_sheet('成绩表')# 保存workbook的修改wb.save('test.xlsx') 6、在Excel中存储学生成绩 12345678910111213141516171819202122232425262728293031323334353637import openpyxl# 打开workbookwb = openpyxl.load_workbook(\"成绩表.xlsx\")# #创建一个成绩表# wb.create_sheet(\"学生成绩表\")## # 删除表# wb.remove_sheet(wb['Sheet1'])# 获取“学生成绩表”score = wb[\"学生成绩表\"]# title = ['序号','姓名','语文','数学']# no = range(6)# names = ['张三','李四','王五','赵柳','田七']# wen = [80,88,85,81,89]# 第一行数据score['A1'].value = '序号'score['B1'].value = '姓名'score['C1'].value = '语文'score['D1'].value = '数学'# 第二行数据score['A2'].value = int('1')score['B2'].value = '张三'score['C2'].value = int('52')score['D2'].value = int('64')# 第三行数据score['A3'].value = int('2')score['B3'].value = '李四'score['C3'].value = int('28')score['D3'].value = int('95')# 保存workbookwb.save('成绩表.xlsx') 7、插入工作表内容 123456789101112131415161718192021222324252627282930313233343536373839#coding=utf-8import openpyxldef process_worksheet(sheet): # 总分所在的列 sum_column = sheet.max_column + 2 # 平均分所在的列 avg_column = sheet.max_column + 1 # 将总分和平均分保存到最后两列 for row in sheet.iter_rows(min_row=2, min_col=3): # 单元格 score = [cell.value for cell in row] # 总分 sum_score = sum(score) # 平均分 avg_score = sum_score / len(score) # 将总分和平均分保存到最后两列 sheet.cell(row=row[0].row, column=avg_column).value = avg_score sheet.cell(row=row[0].row, column=sum_column).value = sum_score # 设置平均分和总分的标题 sheet.cell(row=1, column=avg_column).value = \"平均分\" sheet.cell(row=1, column=sum_column).value = \"总分\"def main(): # 打开Excel文档 wb = openpyxl.load_workbook(\"成绩.xlsx\") # 获取一个工作表 sheet = wb[\"成绩表\"] # 把外部Excel文件（成绩表）中的sheet（成绩）插入当前Excel中 process_worksheet(sheet) # 保存“练习.xlsx” wb.save(\"练习-copy.xlsx\")if __name__ == '__main__': main() 查看练习-copy.xlsx的数据 二、Python 读、写Excel文件（三种模块三种方式 python读写excel的方式有很多，不同的模块在读写的讲法上稍有区别： 用xlrd和xlwt进行excel读写； 用openpyxl进行excel读写； 用pandas进行excel读写； pandas介绍 Pandas是Python的一个数据分析包，该工具为解决数据分析任务而创建。 Pandas纳入大量库和标准数据模型，提供高效的操作数据集所需的工具。 Pandas提供大量能使我们快速便捷地处理数据的函数和方法。 Pandas是字典形式，基于NumPy创建，让NumPy为中心的应用变得更加简单。 作者：谓之小一 链接：https://www.jianshu.com/p/218baa41bab9 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 1、xlrd模块 xlrd是用来从Excel中读写数据的，但我平常只用它进行读操作，写操作会遇到些问题。用xlrd进行读取比较方便，流程和平常手动操作Excel一样，打开工作簿(Workbook)，选择工作表(sheets)，然后操作单元格(cell)。下面举个例子，例如要打开当前目录下名为”data.xlsx”的Excel文件，选择第一张工作表，然后读取第一行的全部内容并打印出来。 1234567891011#打开excel文件data=xlrd.open_workbook('data.xlsx') #获取第一张工作表（通过索引的方式）table=data.sheets()[0] #data_list用来存放数据data_list=[] #将table中第一行的数据读取并添加到data_list中data_list.extend(table.row_values(0))#打印出第一行的全部数据for item in data_list: print item 上面的代码中读取一行用table.row_values(number)，类似的读取一列用table.column_values(number)，其中number为行索引，在xlrd中行和列都是从0开始索引的，因此Excel中最左上角的单元格A1是第0行第0列。 xlrd中读取某个单元格用table.cell(row,col)即可，其中row和col分别是单元格对应的行和列。 下面简单归纳一下xlrd的用法 （1）安装xlrd模块 到python官网下载http://pypi.python.org/cmdpypi/xlrd模块安装，前提是已经安装了python 环境。 1pip install xlrd （2）使用技巧 sheet.name：sheet的名字 sheet.nrows：sheet的行数 sheet.ncols：sheet的列数 sheet.get_rows()：返回一个迭代器，遍历所有行，给出每个行的值列表 sheet.row_values(index)：返回某一行的值列表 sheet.row(index)：返回一个row对象，可通过row[index]获取这行里的单元格cell对象 sheet.col_values(index)：返回某一列的值列表 sheet.cell(row,col)：获取一个cell对象（row和col都从0开始算 12345678910111213141516171819202122232425262728293031323334table = data.sheets()[0] #通过索引顺序获取table = data.sheet_by_index(0) #通过索引顺序获取table = data.sheet_by_name(u'Sheet1')#通过名称获取# 获取整行和整列的值（数组） table.row_values(i)table.col_values(i) # 获取行数和列数 nrows = table.nrows ncols = table.ncols # 循环行列表数据for i in range(nrows): print table.row_values(i) # 单元格cell_A1 = table.cell(0,0).valuecell_C4 = table.cell(2,3).value # 使用行列索引cell_A1 = table.row(0)[0].valuecell_A2 = table.col(1)[0].value # 简单的写入row = 0col = 0 # 类型 0 empty,1 string, 2 number, 3 date, 4 boolean, 5 errorctype = 1 value = '单元格的值'xf = 0 # 扩展的格式化table.put_cell(row, col, ctype, value, xf)table.cell(0,0) #单元格的值'table.cell(0,0).value #单元格的值' （3）查看文件数据 12345678910111213141516171819import xlrdbook = xlrd.open_workbook('练习-copy.xlsx')sheet1 = book.sheets()[0]nrows = sheet1.nrowsprint('表格总行数：', nrows)ncols = sheet1.ncolsprint('表格总列数：', ncols)row3_values = sheet1.row_values(2)print('第3行的值：', row3_values)col3_values = sheet1.col_values(2)print('第3列的值：', col3_values)cell_2_2 = sheet1.cell(2,2).valueprint('3行3列的值',cell_2_2) 输出结果如下 12345表格总行数： 8表格总列数： 3第3行的值： [2.0, '浮动视', 26.0]第3列的值： ['年龄', 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0]3行3列的值 26.0 2、xlwt模块 1pip install xlwt 如果说xlrd不是一个单纯的Reader（如果把xlrd中的后两个字符看成Reader，那么xlwt后两个字符类似看成Writer），那么xlwt就是一个纯粹的Writer了，因为它只能对Excel进行写操作。xlwt和xlrd不光名字像，连很多函数和操作格式也是完全相同。下面简要归纳一下常用操作 （1）xlwt常用操作 新建一个Excel文件（只能通过新建写入） 1data=xlwt.Workbook() 新建一个工作表 1table=data.add_sheet('name') 写入数据到A1单元格 1table.write(0,0,u'呵呵') 注意：如果对同一个单元格重复操作，会引发overwrite Exception，想要取消该功能，需要在添加工作表时指定为可覆盖，像下面这样 1table=data.add_sheet('name',cell_overwrite_ok=True) 保存文件 1data.save('test.xls') 这里只能保存扩展名为xls的，xlsx的格式不支持 xlwt支持一定的样式，操作如下 1234567891011121314151617#初始化样式style=xlwt.XFStyle()#为样式创建字体font=xlwt.Font()#指定字体名字font.name='Times New Roman'#字体加粗font.bold=True#将该font设定为style的字体style.font=font#写入到文件时使用该样式sheet.write(0,1,'just for test',style) （2）实例 123456import xlwt # 貌似不支持excel2007的xlsx格式wb = xlwt.Workbook()wb_sheet = wb.add_sheet('ddd')wb_sheet.write(0,0,'测试内容')wb.save('d.xls') 查看d.xls文件 3、openpyxl模块 1pip install openpyxl 该模块支持最新版的Excel文件格式，对Excel文件具有响应的读写操作，对此有专门的Reader和Writer两个类，便于对Excel文件的操作。虽然如此，但我一般还是用默认的workbook来进行操作。常用操作归纳如下： （1）openpyxl常用操作 读取Excel文件 123from openpyxl.reader.excel import load_workbookwb=load_workbook(filename) 显示工作表的索引范围 1wb.get_named_ranges() 显示所有工作表的名字 1wb.get_sheet_names() 取得第一张表 12sheetnames = wb.get_sheet_names() ws = wb.get_sheet_by_name(sheetnames[0]) 获取表名 1ws.title 获取表的行数 1ws.get_highest_row() 获取表的列数 1ws.get_highest_column() 单元格的读取，此处和xlrd的读取方式很相近，都是通过行和列的索引来读取 12#读取B1单元格中的内容ws.cell(0,1).value 当然也支持通过Excel坐标来读取数据，代码如下 12#读取B1单元格中的内容ws.cell(\"B1\").value （2）实例 123456789101112131415import pandas as pdfrom pandas import DataFrame# df = pd.read_excel(r'练习-copy.xlsx',sheet_name='学生成绩表')# print(df.head())data = &#123; 'name':['张三','李四','王五'], 'age':[11,12,13], 'sex':['男','女','未知'],&#125;df = DataFrame(data)df.to_excel('new.xlsx') 查看new.xlsx文件 4、案例 把提供的原始Excel文档中的两个表格提取到另外一个新的Excel文档中，横向排列 代码如下： 12345678910111213141516171819202122232425import openpyxlimport pandasfrom pandas import DataFramewb = openpyxl.load_workbook('Live数据库及表结构.xlsx')sheet = wb['Sheet1']aa = []for row1 in sheet.iter_rows(min_row=3,max_row=6): score1 = [cell.value for cell in row1] aa.append(score1)df = DataFrame(aa)df.to_excel('xgp.xlsx')bb = []for row2 in sheet.iter_rows(min_row=8,max_row=14): score2 = [cell.value for cell in row2] bb.append(score2)df = pandas.DataFrame(bb)book = openpyxl.load_workbook('xgp.xlsx')with pandas.ExcelWriter('xgp.xlsx')as E: E.book = book E.sheets = dict((ws.title, ws) for ws in book.worksheets) df.to_excel(E,sheet_name='Sheet1',index=False,startcol=12) 查看xgp.xlsx文件 5、总结 读取Excel时，选择openpyxl和xlrd差别不大，都能满足要求 写入少量数据且存为xls格式文件时，用xlwt更方便 写入大量数据（超过xls格式限制）或者必须存为xlsx格式文件时，就要用openpyxl了。","path":"posts/e80d.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"Python监控Linux系统（1）","text":"一、使用开源库监控Linux 在这一小节，我们将介绍一个在Python生态中广泛使用的开源项目，即psutil。随后，我们将使用psutil重构前一小节编写的监控程序。另外，还会简单介绍psutil提供的进程管理功能。 1、psutil介绍 psutil = process and system utilities psutil是一个开源且跨平台的库，其提供了便利的函数用来获取操作系统的信息，比如CPU，内存，磁盘，网络等。此外，psutil还可以用来进行进程管理，包括判断进程是否存在、获取进程列表、获取进程详细信息等。而且psutil还提供了许多命令行工具提供的功能，包括：ps，top，lsof，netstat，ifconfig， who，df，kill，free，nice，ionice，iostat，iotop，uptime，pidof，tty，taskset，pmap。 psutil是一个跨平台的库，支持Linux、Windows、OSX、FreeBSD、OpenBSD、NetBSD、Sun Solaris、AIX等操作系统。同时，psutil也支持32位与64位的系统架构，支持Python2.6到Python3.x之间的所有Python版本。 psutil具有简单易用、功能强大、跨平台等诸多优点，广泛应用于开源项目中，比较有名的有glances、Facebook的osquery、Google的grr等。psutil不但广泛应用于Python语言开发的开源项目中，还被移植到了其他编程语言中，如Go语言的gopsutil、C语言的cpslib、Rust语言的rust-psutil、Ruby语言的posixpsutil等。 pip安装psutil psutil是一个第三方的开源项目，因此，需要先安装才能够使用。如果安装了Anaconda，psutil就已经可用了。否则，需要在命令行下通过pip安装： 12345678[root@localhost ~]# pip3 install psutilCollecting psutil Downloading psutil-5.7.0.tar.gz (449 kB) |████████████████████████████████| 449 kB 4.6 kB/s Installing collected packages: psutil Running setup.py install for psutil ... doneSuccessfully installed psutil-5.7.0[root@python scripts]# ipython #打开ipython psutil包含了异常、类、功能函数和常量，其中功能函数用来获取系统的信息，如CPU、磁盘、内存、网络等。类用来实现进程的管理功能。 2、psutil提供的功能函数 根据函数的功能，主要分为CPU、磁盘、内存、网络几类，下面将会总几个方面来介绍psutil提供的功能函数。在这一小节，我们也将学习如何使用psutil来简化使用shell脚本获取监控信息的程序，并获取CPU、内存、磁盘和网络等不同维度。 （1）CPU 与CPU相关的功能函数如下： 函数 描述 psutil.cpu_count() cpu_count(,[logical]):默认返回逻辑CPU的个数,当设置logical的参数为False时，返回物理CPU的个数。 psutil.cpu_percent() cpu_percent(,[percpu],[interval])：返回CPU的利用率,percpu为True时显示所有物理核心的利用率,interval不为0时,则阻塞时显示interval执行的时间内的平均利用率 psutil.cpu_times() cpu_times(,[percpu])：以命名元组(namedtuple)的形式返回cpu的时间花费,percpu=True表示获取每个CPU的时间花费 psutil.cpu_times_percent() cpu_times_percent(,[percpu])：功能和cpu_times大致相同，看字面意思就能知道，该函数返回的是耗时比例。 psutil.cpu_stats() cpu_stats()以命名元组的形式返回CPU的统计信息，包括上下文切换，中断，软中断和系统调用次数。 psutil.cpu_freq() cpu_freq([percpu])：返回cpu频率 1）cpu_count 默认返回逻辑CPU的个数,当设置logical的参数为False时，返回物理CPU的个数。 1234567In [1]: import psutil In [2]: psutil.cpu_count() #查看处理器内核数Out[2]: 1In [3]: psutil.cpu_count(logical=False) #查看目前使用的处理器内核数 Out[3]: 1 2）cpu_percent 返回CPU的利用率，percpu为True时显示所有物理核心的利用率，interval不为0时，则阻塞时显示interval执行的时间内的平均利用率。 12345678In [5]: psutil.cpu_percent() #查看每个内核使用率 Out[5]: 0.2In [6]: psutil.cpu_percent(percpu=True) Out[6]: [0.5]In [7]: psutil.cpu_percent(percpu=True,interval=2) Out[7]: [0.0] 3）cpu_times 以命名元组(namedtuple)的形式返回cpu的时间花费，percpu=True表示获取每个CPU的时间花费。 12345In [8]: psutil.cpu_times() Out[8]: scputimes(user=11.1, nice=0.0, system=14.05, idle=3252.64, iowait=0.98, irq=0.0, softirq=0.18, steal=0.0, guest=0.0, guest_nice=0.0)In [9]: psutil.cpu_times_percent() Out[9]: scputimes(user=0.2, nice=0.0, system=0.1, idle=99.6, iowait=0.0, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0) 4）cpu_stats 以命名元组的形式返回CPU的统计信息，包括上下文切换，中断，软中断和系统调用次数。 12In [10]: psutil.cpu_stats() Out[10]: scpustats(ctx_switches=403960, interrupts=214204, soft_interrupts=217258, syscalls=0) 5）cpu_freq 返回cpu频率。 12In [11]: psutil.cpu_freq() Out[11]: scpufreq(current=1799.453, min=0.0, max=0.0) （2）内存 与内存相关的功能函数如下： 1）virtual_memory 以命名元组的形式返回内存使用情况，包括总内存、可用内存、内存利用率、buffer和cache等。除了内存利用率，其它字段都以字节为单位返回。 1234In [1]: import psutil In [12]: psutil.virtual_memory() Out[12]: svmem(total=1023934464, available=383610880, percent=62.5, used=481861632, free=67833856, active=436379648, inactive=340885504, buffers=2166784, cached=472072192, shared=7598080, slab=79253504) 单位转换 12345678910111213141516171819202122#/usr/bin/python#-*- conding:utf-8 _*_import psutildef bytes2human(n): symbols = ('K','M','G','T','P','E','Z','Y') prefix = &#123;&#125; for i,s in enumerate(symbols): prefix[s] = 1 &lt;&lt; (i + 1) * 10 print(prefix[s]) print('============') for s in reversed(symbols): if n &gt;= prefix[s]: value = float(n) / prefix[s] return '%.1f%s' % (value,s) # return '&#123;0&#125;.1f&#123;1&#125;'.format(value, s) return \"%sB\" % n # return \"&#123;0&#125;B\" .format(n)print(\"总内存：\"+bytes2human(psutil.virtual_memory().total)) 运行结果如下所示： 1234567891011[root@python scripts]# python3 monitor_mem.py 10241048576107374182410995116277761125899906842624115292150460684697611805916207174113034241208925819614629174706176============总内存：976.5M 分析一下 2）swap_memory 以命名元组的形式返回swap/memory使用情况，包含swap中页的换入和换出。 12In [13]: psutil.swap_memory() Out[13]: sswap(total=2147479552, used=0, free=2147479552, percent=0.0, sin=0, sout=0) （3）磁盘 与磁盘相关的功能如下： 函数 描述 psutil.disk_io_counters() disk_io_counters([perdisk])：以命名元组的形式返回磁盘io统计信息(汇总的)，包括读、写的次数，读、写的字节数等。 当perdisk的值为True，则分别列出单个磁盘的统计信息(字典：key为磁盘名称，value为统计的namedtuple)。 psutil.disk_partitions() disk_partitions([all=False])：以命名元组的形式返回所有已挂载的磁盘，包含磁盘名称，挂载点，文件系统类型等信息。 当all等于True时，返回包含/proc等特殊文件系统的挂载信息 psutil.disk_usage() disk_usage(path)：以命名元组的形式返回path所在磁盘的使用情况，包括磁盘的容量、已经使用的磁盘容量、磁盘的空间利用率等。 1）psutil.disk_io_counters 以命名元组的形式返回磁盘io统计信息(汇总的)，包括读、写的次数，读、写的字节数等。 当perdisk的值为True，则分别列出单个磁盘的统计信息(字典：key为磁盘名称，value为统计的namedtuple)。有了disk_io_counters函数，省去了解析/proc/diskstats文件的烦恼。 12345678910111213In [1]: import psutil In [2]: psutil.disk_io_counters() Out[2]: sdiskio(read_count=86913, write_count=46560, read_bytes=5038501376, write_bytes=408987648, read_time=77974, write_time=79557, read_merged_count=5933, write_merged_count=35916, busy_time=42153)In [3]: psutil.disk_io_counters(perdisk=TruOut[3]: &#123;'sda': sdiskio(read_count=41472, write_count=5340, read_bytes=2524417024, write_bytes=205662720, read_time=38302, write_time=4484, read_merged_count=5933, write_merged_count=35916, busy_time=21074), 'sda1': sdiskio(read_count=1854, write_count=4, read_bytes=6441472, write_bytes=2097152, read_time=370, write_time=35, read_merged_count=0, write_merged_count=0, busy_time=396), 'sda2': sdiskio(read_count=39587, write_count=5337, read_bytes=2516263424, write_bytes=203570688, read_time=37925, write_time=4449, read_merged_count=5933, write_merged_count=35916, busy_time=20675), 'sr0': sdiskio(read_count=0, write_count=0, read_bytes=0, write_bytes=0, read_time=0, write_time=0, read_merged_count=0, write_merged_count=0, busy_time=0), 'dm-0': sdiskio(read_count=38566, write_count=5197, read_bytes=2483773952, write_bytes=55885312, read_time=37685, write_time=3546, read_merged_count=0, write_merged_count=0, busy_time=19410), 'dm-1': sdiskio(read_count=6875, write_count=36059, read_bytes=30310400, write_bytes=147697664, read_time=1987, write_time=71537, read_merged_count=0, write_merged_count=0, busy_time=1673)&#125; 2）psutil.disk_partitions 以命名元组的形式返回所有已挂载的磁盘，包含磁盘名称，挂载点，文件系统类型等信息。当all等于True时，返回包含/proc等特殊文件系统的挂载信息。 12345678910111213141516171819In [4]: psutil.disk_partitions() #查看挂载点信息 Out[4]: [sdiskpart(device='/dev/mapper/centos-root', mountpoint='/', fstype='xfs', opts='rw,seclabel,relatime,attr2,inode64,noquota'), sdiskpart(device='/dev/sda1', mountpoint='/boot', fstype='xfs', opts='rw,seclabel,relatime,attr2,inode64,noquota')]In [5]: [device for device in psutil.disk_partitions() if device.mountpoint == '/']Out[5]: [sdiskpart(device='/dev/mapper/centos-root', mountpoint='/', fstype='xfs', opts='rw,seclabel,relatime,attr2,inode64,noquota')]In [6]: def get_disk_via_mountpoint(point): #创建一个函数 ...: disk = [item for item in psutil.disk_partitions() if item.mountpoint == point] ...: return disk[0].device //没有任何输出 In [7]: get_disk_via_mountpoint('/') #调用get_disk_via_mountpoint查看“/”的挂载点Out[7]: '/dev/mapper/cl-root' In [8]: get_disk_via_mountpoint('/boot') #调用get_disk_via_mountpoint查看“/boot”的挂载点Out[8]: '/dev/sda1' 3）psutil.disk_usage 以命名元组的形式返回path所在磁盘的使用情况，包括磁盘的容量、已经使用的磁盘容量、磁盘的空间利用率等。 12345678In [9]: psutil.disk_usage('/') Out[9]: sdiskusage(total=18238930944, used=6775488512, free=11463442432, percent=37.1)In [10]: psutil.disk_usage('/').percentOut[10]: 37.2In [11]: type(psutil.disk_usage('/').percent)Out[11]: float （4）网络 与网络相关的函数如下： 函数 详情 psutil.net_io_counter([pernic]) 以命名元组的形式返回当前系统中每块网卡的网络io统计信息，包括收发字节数，收发包的数量、出错的情况和删包情况。当pernic为True时，则列出所有网卡的统计信息。 psutil.net_connections([kind]) 以列表的形式返回每个网络连接的详细信息(namedtuple)。命名元组包含fd, family, type, laddr, raddr, status, pid等信息。kind表示过滤的连接类型，支持的值如下：(默认为inet) psutil.net_if_addrs() 以字典的形式返回网卡的配置信息，包括IP地址和mac地址、子网掩码和广播地址。 psutil.net_if_stats() 返回网卡的详细信息，包括是否启动、通信类型、传输速度与mtu。 psutil.users() 以命名元组的方式返回当前登陆用户的信息，包括用户名，登陆时间，终端，与主机信息 psutil.boot_time() 以时间戳的形式返回系统的启动时间 1）psutil.net_io_counter 以命名元组的形式返回当前系统中每块网卡的网络io统计信息，包括收发字节数，收发包的数量、出错的情况和删包情况。当pernic为True时，则列出所有网卡的统计信息。使用net_io_counter函数与自己解析/proc/net/dev文件内容实现的功能相同。 123456789101112In [1]: import psutil In [2]: psutil.net_io_counters() Out[2]: snetio(bytes_sent=720405, bytes_recv=3661606, packets_sent=5520, packets_recv=14886, errin=0, errout=0, dropin=0, dropout=0)In [3]: psutil.net_io_counters(pernic=True) Out[3]: &#123;'ens37': snetio(bytes_sent=724145, bytes_recv=3365944, packets_sent=5538, packets_recv=10017, errin=0, errout=0, dropin=0, dropout=0), 'lo': snetio(bytes_sent=0, bytes_recv=0, packets_sent=0, packets_recv=0, errin=0, errout=0, dropin=0, dropout=0), 'virbr0-nic': snetio(bytes_sent=0, bytes_recv=0, packets_sent=0, packets_recv=0, errin=0, errout=0, dropin=0, dropout=0), 'virbr0': snetio(bytes_sent=0, bytes_recv=0, packets_sent=0, packets_recv=0, errin=0, errout=0, dropin=0, dropout=0), 'ens33': snetio(bytes_sent=0, bytes_recv=298202, packets_sent=0, packets_recv=4899, errin=0, errout=0, dropin=0, dropout=0)&#125; 2）net_connections 以列表的形式返回每个网络连接的详细信息(namedtuple)，可以使用该函数查看网络连接状态，统计连接个数以及处于特定状态的网络连接个数。 123456789101112In [4]: psutil.net_connections() Out[4]: [sconn(fd=6, family=&lt;AddressFamily.AF_INET6: 10&gt;, type=&lt;SocketKind.SOCK_STREAM: 1&gt;, laddr=addr(ip='::', port=111), raddr=(), status='LISTEN', pid=6558), sconn(fd=7, family=&lt;AddressFamily.AF_INET6: 10&gt;, type=&lt;SocketKind.SOCK_DGRAM: 2&gt;, laddr=addr(ip='::', port=111), raddr=(), status='NONE', pid=6558), sconn(fd=8, family=&lt;AddressFamily.AF_INET6: 10&gt;, type=&lt;SocketKind.SOCK_STREAM: 1&gt;, laddr=addr(ip='::1', port=6010), raddr=(), status='LISTEN', pid=9047), sconn(fd=6, family=&lt;AddressFamily.AF_INET: 2&gt;, type=&lt;SocketKind.SOCK_STREAM: 1&gt;,......In [5]: conns = psutil.net_connections()In [6]: len([conn for conn in conns if conn.status == 'TIME_WAIT']) Out[6]: 0 3）net_if_addrs 以字典的形式返回网卡的配置信息，包括IP地址和mac地址、子网掩码和广播地址。 1234567In [7]: psutil.net_if_addrs() Out[7]: &#123;'lo': [snicaddr(family=&lt;AddressFamily.AF_INET: 2&gt;, address='127.0.0.1', netmask='255.0.0.0', broadcast=None, ptp=None), snicaddr(family=&lt;AddressFamily.AF_INET6: 10&gt;, address='::1', netmask='ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff', broadcast=None, ptp=None), snicaddr(family=&lt;AddressFamily.AF_PACKET: 17&gt;, address='00:00:00:00:00:00', netmask=None, broadcast=None, ptp=None)], 'ens37': [snicaddr(family=&lt;AddressFamily.AF_INET: 2&gt;, address='192.168.1.131', netmask='255.255.255.255', broadcast='192.168.1.131', ptp=None), snicaddr(family=&lt;AddressFamily.AF_INET6: 10&gt;, address='240e:82:e03:7342:4378:7be3:558c:fc88', netmask='ffff:ffff:ffff:ffff::', broadcast=None, ptp=None)...... 4）psutil.net_if_stats 返回网卡的详细信息，包括是否启动、通信类型、传输速度与mtu。 1234567In [8]: psutil.net_if_stats() Out[8]: &#123;'ens37': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_FULL: 2&gt;, speed=1000, mtu=1500), 'lo': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_UNKNOWN: 0&gt;, speed=0, mtu=65536), 'virbr0-nic': snicstats(isup=False, duplex=&lt;NicDuplex.NIC_DUPLEX_FULL: 2&gt;, speed=10, mtu=1500), 'virbr0': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_UNKNOWN: 0&gt;, speed=0, mtu=1500), 'ens33': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_FULL: 2&gt;, speed=1000, mtu=1500)&#125; （5）其他 1）users 以命名元组的方式返回当前登陆用户的信息，包括用户名，登陆时间，终端，与主机信息。 123456In [9]: psutil.users() Out[9]: [suser(name='root', terminal=':0', host='localhost', started=1582366080.0, pid=7991), suser(name='root', terminal='pts/0', host='localhost', started=1582366208.0, pid=8927), suser(name='root', terminal='pts/1', host='192.168.1.4', started=1582370816.0, pid=10099), suser(name='root', terminal='pts/3', host='192.168.1.4', started=1582369408.0, pid=9787)] 2）boot_time 以时间戳的形式返回系统的启动时间。 1234567In [9]: import datetimeIn [10]: psutil.boot_time() Out[10]: 1582527367.0 In [11]: datetime.datetime.fromtimestamp(psutil.boot_time()).strftime('%Y-%m-%d %H:%M:%S') Out[11]: '2020-02-24 14:56:07' 3、综合案例：使用psutil实现监控程序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# coding=utf-8# !/usr/bin/pythonimport psutilimport datetimedef bytes2human(n): '''内存单位转换的方法''' symbols = ('K', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y') prefix = &#123;&#125; for i, s in enumerate(symbols): prefix[s] = 1 &lt;&lt; (i + 1) * 10 for s in reversed(symbols): if n &gt;= prefix[s]: value = float(n) / prefix[s] return '%.1f%s' % (value, s) return \"%sB\" % ndef get_cpu_info(): '''获取CPU使用率''' cpu_count = psutil.cpu_count() cpu_percent = psutil.cpu_percent(interval=1) return dict(cpu_count=cpu_count, cpu_percent=cpu_percent)def get_memory_info(): '''获取内存信息''' virtual_mem = psutil.virtual_memory() mem_total = bytes2human(virtual_mem.total) mem_percent = virtual_mem.percent mem_free = bytes2human(virtual_mem.free + virtual_mem.buffers + virtual_mem.cached) mem_used = bytes2human(virtual_mem.total * mem_percent / 100) return dict(mem_total=mem_total, mem_percent=mem_percent, mem_free=mem_free, mem_used=mem_used)def get_disk_info(): '''获取磁盘信息''' disk_usage = psutil.disk_usage('/') disk_total = bytes2human(disk_usage.total) disk_percent = disk_usage.percent disk_free = bytes2human(disk_usage.free) disk_used = bytes2human(disk_usage.used) return dict(disk_total=disk_total, disk_percent=disk_percent, disk_free=disk_free, disk_used=disk_used)def get_boot_info(): '''获取启动时间''' boot_time = datetime.datetime.fromtimestamp(psutil.boot_time()).strftime(\"%Y-%m-%d %H:%M:%S\") return dict(boot_time=boot_time)def collect_monitor_data(): '''集中监控硬件信息''' data = &#123;&#125; data.update(get_boot_info()) data.update(get_cpu_info()) data.update(get_memory_info()) data.update(get_disk_info()) print(data) return datacollect_monitor_data() 执行结果如下 12[root@python scripts]# python3 monitor_psutil.py&#123;'boot_time': '2020-05-06 16:23:37', 'cpu_count': 1, 'cpu_percent': 0.0, 'mem_total': '976.5M', 'mem_percent': 71.4, 'mem_free': '448.0M', 'mem_used': '697.2M', 'disk_total': '17.0G', 'disk_percent': 30.4, 'disk_free': '11.8G', 'disk_used': '5.2G'&#125; 4、psutil进程管理 psutil还提供了作为进程管理的功能函数，包括获取进程列表，判断是否存在，以及进程管理的类封装。 函数 详情 psutil.Process() 对进程进行封装，可以使用该类的方法获取进行的详细信息，或者给进程发送信号。 psutil.pids() 以列表的形式返回当前正在运行的进程 psutil.pid_exists(1) 判断给点定的pid是否存在 psutil.process_iter() 迭代当前正在运行的进程，返回的是每个进程的Process对象 1）Process类 对进程进行封装，可以使用该类的方法获取进行的详细信息，或者给进程发送信号。 123456In [1]: import psutil In [2]: init_process = psutil.Process()In [3]: init_process.cmdline() Out[3]: ['/usr/local/python38/bin/python3.8', '/usr/local/python38/bin/ipython'] Process类包含很多方法来获取进程的详细信息。下面是几个较常用的方法： 123456789name：获取进程的名称cmdline：获取启动进程的命令行参数create_time：获取进程的创建时间(时间戳格式)num_fds：进程打开的文件个数num_threads：进程的子进程个数is_running：判断进程是否正在运行send_signal：给进程发送信号，类似与os.kill等kill：发送SIGKILL信号结束进程terminate：发送SIGTEAM信号结束进程 2）pids 以列表的形式返回当前正在运行的进程。 123456789In [1]: import psutil In [2]: init_process = psutil.Process()In [3]: init_process.cmdline() Out[3]: ['/usr/local/python38/bin/python3.8', '/usr/local/python38/bin/ipython']In [4]: psutil.pids()[:5] Out[4]: [1, 2, 3, 5, 7] 3）pid_exists 判断给点定的pid是否存在。 12345In [5]: psutil.pid_exists(1) Out[5]: TrueIn [6]: psutil.pid_exists(10245) Out[6]: False 4）process_iter 迭代当前正在运行的进程，返回的是每个进程的Process对象，而pids返回的是进程的列表。 二、使用Python监控MongoDB 对于MongoDB数据库来说，获取监控的方法比较简单，因为MongoDB本身流返回给我们一个字典形式的数据。如下所示： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pymongo 1234567891011121314#/usr/bin/python#_*_ coding:utf-8 _*_from __future__ import print_functionimport pymongoclient = pymongo.MongoClient(host='127.0.0.1:27017')client.admin.authenticate('laoyu','laoyu')rs = client.admin.command('replSetGetStatus')print(\"set:\",rs['set'])print(\"myState:\",rs['myState'])print('num of members:',len(rs['members']))","path":"posts/54c9.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"Python监控Linux系统（2）","text":"使用Python监控Linux系统 Linux下有许多使用Python语言编写的监控工具，如inotify-sync, dstat和glances. 此外，如果要根据业务编写简单的监控脚本，很多工程师也会选择Python语言。Python语言是一门简单 易学/语法清晰/表达能力强的编程语言,非常适合于编写监控程序的场景。使用Python语言编写监控程序具有以下几个优势: Python语言开发效率高。 Python语言有自 己的优势与劣势，使用Python开发监控程序是一个充分发挥Python优势，避免Python劣势的领域。对于监控程序来说，能够利用Python语言开发效率高的优势尽快完成程序的编写工作。同时，监控程序也不要求性能，因此避免了Python语言性能不如C、C++和Java的劣势。 Python语言表达能力强。相信任何-个学习Linux的工程师都使用过shel脚本编写过监控程序。虽然Linux下有很多监控工具,也有很多文本处理程序，但是获取监控与解析结果是完全不同的工具。解析监控结果的程序不理解监控程序输出结果的具体含义。Python语言中有非常丰富的数据结构，可以用各种方式保存监控结果，以便后续处理。 利用第三方库开发监控程序。Python的标准库本身非常强大,被称为”连电池都包含在内”。对于-个问题,如果标准库没有提供相应的工具,那么也会有开源的项目来填补这个空白。监控程序正式这样一种情况， 在Python语言中，具有非常成熟的第三方库帮助开发者简化监控程序的编写工作。 一、Python编写的监控工具 我们将介绍两个Python语言编写的监控工具，分别是dstat和glances。 1、多功能系统资源统计工具dstat dstat是一个用Python语言实现的多功能系统资源统计工具，用来取代Linux下的vmstat、iostat、netstat和ifstat等命令。并且，dstat克服了这些命令的限制，增加了额外的功能、以及更多的计数器与更好的灵活性。dstat可以在一个界面上展示非常全面的监控信息，因此，在系统监控、基准测试和故障排除等应用场景下特别有用。 我们可以使用dstat监控所有系统资源的使用情况，并且可以结合不同的场景定制监控的资源。例如，在同一时间段以相同的时间频率比较网络带宽与磁盘的吞吐率。 dstat将以列表的形式显示监控信息，并且用不同的颜色进行输出，以可读性较强的单位展示监控数值。例如，对于字节数值，dstat自动根据数值的大小，以K、M、G等单位进行显示，避免了开发者使用其他命令时因为数值太大造成的困惑和错误。此外，使用dstat还可以非常方便地编写插件用来收集默认情况下没有收集的监控信息。dstat是专门为人们实时查看监控信息设计的，因此，默认将监控结果输出到屏幕终端。我们也可以将监控信息以CSV格式输出到文件，以便后续处理。 2、dstat介绍 作为一个多功能系统资源统计工具， dstat具有以下特性: 结合了 vmstat, iostat, ifstat, netstat 等监控工具的功能，并且提供了更多的监控信息； 实时显示监控数据； 在问题分析和故障排查时，可以监视最重要的计数器，也可以对计数器进行排序； 模块化设计； 使用 Python 语言编写，更方便扩展现有的工作任务； 容易扩展，便于添加自定义的计数器； 包含的许多扩展插件充分说明了增加新的监控项目是很方便的； 可以分组统计块设备/网络设备，并给出、汇总信息； 可以显示每台设备中断信息； 非常准确的时间精度，即便是系统负荷较高也不会延迟显示； 准确显示单位，限制转换误差范围； 用不同的颜色显示不同的单位，增加可读性； 显示中间结果延时小于1秒 支持 csv 格式输出，便于将监控信息导人 Gnumeric 和 Excel 以生成图形。 3、安装使用 如果操作系统默认没有安装dstat.那么需要我们手动进行安装。如下所示: 1[root@python ~]# yum -y install dstat &lt;1&gt;dstat命令的–version选项，除了显示出tat的版本以外，还会显示操作系统的版本、Python语言的版本、cpu的个数，以及dstat支持的插件列表等详细信息。如下所示： 1[root@python ~]# dstat --version &lt;2&gt;dstat --list获取dstat的插件列表 1dstat --list &lt;3&gt;直接在终端输入dstat命令，dstat将以默认参数运行。默认情况下，dstat会收集cpu、磁盘、网络、换页和系统信息，并以一秒钟一次的频率进行输出，直到我们按 ctrl+c 结束。 1[root@python ~]# dstat 4、常用选项如下: . 直接跟数字，表示#秒收集一次数据，默认为1秒; dstat 5表示5秒更新一次 -c,–cpu：统计CPU状态，包括system，user，idle，wait，hardware interrupt，software，interrupt等; -d，–disk：统计磁盘读写状态 -D total,sda：统计指定磁盘或汇总信息 -l，–load：统计系统负载情况，包括1分钟、5分钟、15分钟平均值 -m，- -mem：统计系统物理内存使用情况，包括used, buffers， cache，free -s，–swap：统计swap已使用和剩余量 -n，–net：统计网络使用情况，包括接收和发送数据 -N eth1,total 统计eth1接口汇总流量 -r，–io：统计I/0请求，包括读写请求 -p，–proc：统计进程信息，包括runnable、uninterruptible、new -y，–sys：统计系统信息，包括中断、上下文切换 -t：显示统计时时间，对分析历史数据非常有用 –fs：统计文件打开数和inodes数 除了前面介绍的与监控相关的参数以外，dstat还可以像vmstat和iostat- 样使用参数控制报告的时间间隔，或者同时指定时间间隔与报告次数。 例如，下面的命令表示以默认的选项运行dstat,每2秒钟输出1条监控信息，并在输出10条监控信息以后退出dstat。如下所示: 12345678910111213141516[root@python ~]# dstat 2 10You did not select any stats, using -cdngy by default.Terminal width too small, trimming output.----total-cpu-usage---- -dsk/total- -net/total- ---paging--&gt;usr sys idl wai hiq siq| read writ| recv send| in out &gt; 2 1 96 0 0 0| 270k 233k| 0 0 | 75B 1812B&gt; 0 0 100 0 0 0| 0 0 | 60B 510B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 60B 294B| 0 0 &gt; 0 1 100 0 0 0| 0 0 | 60B 294B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 182B 294B| 0 0 &gt; 1 0 100 0 0 0| 0 0 | 60B 294B| 0 0 &gt; 0 1 99 0 0 0| 0 0 | 60B 294B| 0 0 &gt; 0 1 100 0 0 0| 0 0 | 60B 294B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 60B 294B| 0 0 &gt; 1 0 100 0 0 0| 0 0 | 60B 294B| 0 0 &gt; 0 0 100 0 0 0| 0 25k| 60B 298B| 0 0 &gt; dstat命令中有很多参数可选，你可以通过man dstat命令查看，大多数常用的参数有这些： -l ：显示负载统计量 -m ：显示内存使用率（包括used，buffer，cache，free值） -r ：显示I/O统计 -s ：显示交换分区使用情况 -t ：将当前时间显示在第一行 –fs ：显示文件系统统计数据（包括文件总数量和inodes值） –nocolor ：不显示颜色（有时候有用） –socket ：显示网络统计数据 –tcp ：显示常用的TCP统计 –udp ：显示监听的UDP接口及其当前用量的一些动态数据 dstat附带了一些插件很大程度地扩展了它的功能。你可以通过查看/usr/share/dstat目录来查看它们的一些使用方法，常用的有这些： -–disk-util ：显示某一时间磁盘的忙碌状况 -–freespace ：显示当前磁盘空间使用率 -–proc-count ：显示正在运行的程序数量 -–top-bio ：指出块I/O最大的进程 -–top-cpu ：图形化显示CPU占用最大的进程 -–top-io ：显示正常I/O最大的进程 -–top-mem ：显示占用最多内存的进程 5、 dstat高级用法 dstat的强大之处不仅仅是因为它聚合了多种工具的监控结果，还因为它能通过附带的插件事项一些更高级功能。 如:找出磁盘重占用资源最高的进程和用户。 dstat -cdlmnpsyt 5 可以得到较全面的系统性能数据。 dstat的–top-(io|bio|cpu|cputime|cputime-avg |mem)通过这几个选项，可以看到具体是那个用户哪个进程占用了相关系统资源, 对系统调优非常有效。如查看当前占用I/O、 cpu、内存等最高的进程信息可以使用dstat --top-mem --top-io --top-cpu选项。以下示例演示了如何找出占用资源最多的进程。 12345678910111213[root@python scripts]# dstat --top-mem --top-io --top-cpu//查看当前占用I/O、CPU、内存等最高的进程信息--most-expensive- ----most-expensive---- -most-expensive- memory process | i/o process | cpu process gnome-shell 53.0M|bash 420k 119k|vmtoolsd 0.1gnome-shell 53.0M|BT-Task 1026B 0 | gnome-shell 53.0M|gnome-shell 352B 82k|kworker/0:0 1.0gnome-shell 53.0M|sshd: root@ 230B 196B| gnome-shell 53.0M|sshd: root@ 155B 196B| gnome-shell 53.0M|sshd: root@ 155B 196B| gnome-shell 53.0M|sshd: root@ 155B 196B| gnome-shell 53.0M|BT-Task 1406B 0 | dstat的插件保存在/usr/share/dstat目录下， 我们可以参考它们的实现，编写自己的插件。 6、将结果输出到CSV文件 dstat还可以将监控信息保存到CSV文件中，以便后续进行处理。通过–output选项指定监控数据输出的文件。如下所示: 1234567891011121314[root@python ~]# dstat -a --output dstat_output.csvTerminal width too small, trimming output.----total-cpu-usage---- -dsk/total- -net/total- ---paging--&gt;usr sys idl wai hiq siq| read writ| recv send| in out &gt; 2 1 97 0 0 0| 175k 158k| 0 0 | 59B 1973B&gt; 0 0 100 0 0 0| 0 0 | 150B 822B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 60B 298B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 60B 298B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 60B 298B| 0 0 &gt; 0 1 99 0 0 0| 0 0 | 60B 298B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 210B 448B| 0 0 &gt; 1 0 99 0 0 0| 0 49k| 60B 298B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 210B 396B| 0 0 &gt; 0 0 100 0 0 0| 0 0 | 60B 298B| 0 0 &gt;^C 用excel查看信息 12[root@python ~]# sz dstat_output.csv//导出本地文件到windows指定位置 二、交互性监控工具glances 1、glances简介 glances是一款使用Python语言开发、基于psutil的跨平台系统监控工具。在所有的Linux命令行工具中，它与top命令最相似，都是命令行交互式监控工具。但是，glances实现了比top命令更齐全的监控，提供了更加丰富的功能。 在紧急情况下，工程师需要在尽可能短的时间内查看尽可能多的信息。此时，glances是一个不错的选择。 glances的设计初衷就是在当前窗口中尽可能多地显示系统消息。 glances可以在用户终端上实时显示重要的系统信息，并动态刷新内容。glances每隔3秒钟对其进行刷新，我们也可以使用命令行参数修改刷新的频率。与dstat相同的是，glances可以将捕获到的数据保存到文件中；而不同的是glances提供了API接口以便应用程序从glances中获取数据。 2、glances 提供的系统信息 CPU使用率； 内存使用情况； 内核统计信息和运行队列信息； 磁盘I/O速度、传输和读/写比率； 文件系统中的可用空间； 磁盘适配器； 网络I/O速度、传输和读/写比率； 页面空间和页面速度； 消耗资源最多的进程； 计算机信息和系统资源。 glances 工具可以在用户的终端上实时显示重要的系统信息，并动态地对其进行更新。这个高效的工具可以工作于任何终端屏幕。另外它并不会消耗大量的 CPU 资源，通常低于百分之二。glances 在屏幕上对数据进行显示，并且每隔2秒钟对其进行更新。您也可以自己将这个时间间隔更改为更长或更短的数值。 glances 工具还可以将相同的数据捕获到一个文件，便于以后对报告进行分析和绘制图形。输出文件可以是电子表格的格式 (.csv) 或者 html 格式。 3、Linux下安装glances 123#需要epel-release yum -y install epel-release yum -y install glances 或 123#需要python-develyum -y install python-devel -ypip install glances 4、glances的使用 （1）glances的默认输出 glances的使用非常简单，直接输入glances命令便进入了一个类似于top命令的交互式界面。在这个界面中，显示了比top更加全面，更加具有可读性的信息。 为了增加可读性，glances会以不同的颜色表示不同的状态。其中，绿色表示性能良好，元须做任何额外工作；蓝色表示系统性能有一些小问题，用户应当开始关注系统性能；紫色表示性能报警，应当采取措施；红色表示性能问题严重，应当立即处理。 lances是一个交互式的工具．因此，我们也可以输入命令来控制glances的行为。 1[root@python ~]# glances glances 工作界面的说明 : 在图 1 的上部是 CPU 、Load（负载）、Mem（内存使用）、 Swap（交换分区）的使用情况。在图 1 的中上部是网络接口、Processes（进程）的使用情况。通常包括如下字段： VIRT: 虚拟内存大小 RES: 进程占用的物理内存值 %CPU：该进程占用的 CPU 使用率 %MEM：该进程占用的物理内存和总内存的百分比 PID: 进程 ID 号 USER: 进程所有者的用户名 TIME+: 该进程启动后占用的总的 CPU 时间 IO_R 和 IO_W: 进程的读写 I/O 速率 NAME: 进程名称 NI: 进程优先级 S: 进程状态，其中 S 表示休眠，R 表示正在运行，Z 表示僵死状态。 （2）glances的可读性 对比可以发现，glances对屏幕的利用率比top明显高很多，信息量很大，有许多top所没有显示的数据。而且，glances的实时变动比top颜值高太多了。 Glances 会用一下几种颜色来代表状态，如下所示： 绿色：OK（一切正常） 蓝色：CAREFUL（需要注意） 紫色：WARNING（警告） 红色：CRITICAL（严重） （3）glances中常见的命令 h：显示帮助信息 q：离开程序退出 c：按照 CPU 实时负载对系统进程进行排序 m：按照内存使用状况对系统进程排序 i：按照 I/O 使用状况对系统进程排序 p：按照进程名称排序 d：显示磁盘读写状况 w：删除日志文件 l：显示日志 s：显示传感器信息 f：显示系统信息 1：轮流显示每个 CPU 内核的使用情况（次选项仅仅使用在多核 CPU 系统） glances还支持将采集的数据导入到其他服务中心，包括InfluxDB、 Cassandra. CouchDB、 OpenTSDB、Prometheus. StatsD、 ElasticSearch, RabbitMQ/ActiveMQ、ZeroMQ、 Kafaka和Riemann. （4）如果我们安装了 Bottle 这个 web 框架，还能够通过 web 浏览器显示和命令行终端相同的监控界面。 glances还支持将采集的数据导人到其他服务中心，包括InfluxDB，Cassandra，CouchDB，OpenTSDB，Prometheus，StatsD，ElasticSearch，RabbitMQ/ActiveMQ，ZeroMQ，Kafka和Riemann。 1234[root@python ~]# pip install bottle//安装Bottle框架[root@python ~]# glances -w ##默认端口是61208，访问地址没有限制Glances Web User Interface started on http://0.0.0.0:61208/ web访问如下图： 三、Python监控Linux shell查看磁盘的监控信息，如下所示： 1234567[root@python proc]# cat /proc/diskstats 8 0 sda 85935 21845 10913707 101067 3119 81257 743486 15647 0 31410 109079 8 1 sda1 1822 0 12456 397 4 0 4096 74 0 457 462 8 2 sda2 84082 21845 10897907 100659 3115 81257 739390 15573 0 30950 108604 11 0 sr0 0 0 0 0 0 0 0 0 0 0 0 253 0 dm-0 80726 0 10688467 99971 2275 0 82606 10224 0 27927 110196 253 1 dm-1 25123 0 205184 7367 82098 0 656784 616558 0 5167 623924 1、使用shell脚本监控 （1）安装转换工具 dos2unix 和 unix2dos 命令将纯文本文件从 DOS 或 Mac 格式转换为 Unix，反之亦然。 12[root@python scripts]# yum -y install dos2unix//下载dos2unix （2）编写shell脚本 123456789101112131415[root@python scripts]# vim monitor.sh#/bin/shcpu_idle=$(top -n2 | grep 'Cpu' | tail -n 1 | awk '&#123;print $8&#125;')cpu_usage=$(printf \"%.2f\" `echo \"scale=2; 100 - $cpu_idle\" | bc`)mem_free=$(free -m | awk '/Mem:/&#123;print $4 + $6&#125;')mem_total=$(free -m | awk '/Mem:/&#123;print $2&#125;')mem_used=$(echo \"$mem_total - $mem_free\" | bc)mem_rate=$(echo \"$mem_used * 100 / $mem_total\" | bc)disk_usage=$(df -h / | tail -n 1 | awk '&#123;print $5&#125;')disk_used=$(df -h / | tail -n 1 | awk '&#123;print $3&#125;')echo \"CPU利用率：$cpu_usage %\"echo \"内存使用量: $mem_used M\"echo \"内存利用率：$mem_rate %\"echo \"磁盘空间使用量：$disk_used\"echo \"磁盘空间利用率：$disk_usage\" （3）转换并执行 12345678910111213141516171819[root@python scripts]# dos2unix monitor.sh//转换为格式为Unix[root@python scripts]# cat monitor.sh#/bin/shcpu_idle=$(top -n2 | grep 'Cpu' | tail -n 1 | awk '&#123;print $8&#125;')cpu_usage=$(printf \"%.2f\" `echo \"scale=2; 100 - $cpu_idle\" | bc`)mem_free=$(free -m | awk '/Mem:/&#123;print $4 + $6&#125;')mem_total=$(free -m | awk '/Mem:/&#123;print $2&#125;')mem_used=$(echo \"$mem_total - $mem_free\" | bc)mem_rate=$(echo \"$mem_used * 100 / $mem_total\" | bc)disk_usage=$(df -h / | tail -n 1 | awk '&#123;print $5&#125;')disk_used=$(df -h / | tail -n 1 | awk '&#123;print $3&#125;')echo \"CPU利用率：$cpu_usage %\"echo \"内存使用量: $mem_used M\"echo \"内存利用率：$mem_rate %\"echo \"磁盘空间使用量：$disk_used\"echo \"磁盘空间利用率：$disk_usage\"[root@python scripts]# sh monitor.sh//执行编写好的脚本 2、使用python脚本监控 编写一个Python脚本，监控磁盘信息，如下所示： （1）查看服务启动情况 12345678910[root@python scripts]# vim proc_count.py import osn = 0for item in os.listdir('/proc'): if item.isdigit(): n = n+1 # print(len(item))print(n) 执行结果如下: 12[root@python scripts]# python3 proc_count.py 175 （2）简易版 123456789101112131415161718192021222324252627282930[root@python scripts]# vim monitor_dick.py# coding=utf-8# !/usr/bin/pythonfrom __future__ import print_functionfrom collections import namedtupledisk = namedtuple('Disk', 'major_number minor_number device_name' ' read_count read_merged_count read_sections' ' time_spent_reading write_count write_merged_count' ' write_sections time_spent_write io_requests' ' time_spent_doing_io weighted_time_spent_dong_io')def get_disk_info(device): with open('/proc/diskstats') as f: for line in f: if line.split()[2] == device: return disk(*(line.split())) raise RuntimeError('设备(&#123;0&#125;)没找到。。。'.format(device))def main(): disk_info = get_disk_info('sda1') print(disk_info)if __name__ == '__main__': main() 执行脚本： 1[root@python scripts]# python3 monitor_dick.py （3）直观图 12345678910111213141516171819202122232425262728293031# coding=utf-8# !/usr/bin/pythonfrom __future__ import print_functionfrom collections import namedtupledisk = namedtuple('Disk', 'major_number minor_number device_name' ' read_count read_merged_count read_sections' ' time_spent_reading write_count write_merged_count' ' write_sections time_spent_write io_requests' ' time_spent_doing_io weighted_time_spent_dong_io')def get_disk_info(device): with open('/proc/diskstats') as f: for line in f: if line.split()[2] == device: return disk(*(line.split())) raise RuntimeError('设备(&#123;0&#125;)没找到。。。'.format(device))def main(device): disk_info = get_disk_info(device) print(disk_info) print(\"磁盘写入次数:&#123;0&#125;\".format(disk_info.write_count)) print(\"磁盘写入的字节数:&#123;0&#125;\".format(float(disk_info.write_sections) * 512)) print(\"磁盘写入的延时:&#123;0&#125;\".format(disk_info.time_spent_write))if __name__ == '__main__': main('sda1') 执行脚本： 1[root@python scripts]# python3 monitor_dick.py","path":"posts/10c9.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"Python执行外部命令（subprocess，call，Popen）","text":"一、Python执行外部命令 1、subprocess模块简介 subprocess 模块允许我们启动一个新进程，并连接到它们的输入/输出/错误管道，从而获取返回值。 这个模块用来创建和管理子进程。它提供了高层次的接口，用来替换os.system*()、 os.spawn*()、 os.popen*()、os,popen2.*()和commands.*等模块和函数。 subprocess提供了一个名为Popen的类启动和设置子进程的参数，由于这个类比较复杂, subprocess还提供了若干便利的函数，这些函数都是对Popen类的封装。 2、subprocess模块的遍历函数 linux安装ipython 1pip3 install ipython （1）call函数 call函数的定义如下: 12subprocess.ca11(args, *, stdin=None, stdout=None, stderr=None, she11=False)#运行由args参数提供的命令，等待命令执行结束并返回返回码。args参数由字符串形式提供且有多个命令参数时，需要提供shell=True参数 args：表示要执行的命令。必须是一个字符串，字符串参数列表。 stdin、stdout 和 stderr：子进程的标准输入、输出和错误。其值可以是 subprocess.PIPE、subprocess.DEVNULL、一个已经存在的文件描述符、已经打开的文件对象或者 None。subprocess.PIPE 表示为子进程创建新的管道。subprocess.DEVNULL 表示使用 os.devnull。默认使用的是 None，表示什么都不做。另外，stderr 可以合并到 stdout 里一起输出。 shell：如果该参数为 True，将通过操作系统的 shell 执行指定的命令。 示例代码: 12345678910111213141516171819[root@python ~]# ipython #启动ipythonPython 3.8.1 (default, Mar 9 2020, 12:35:12) Type 'copyright', 'credits' or 'license' for more informationIPython 7.13.0 -- An enhanced Interactive Python. Type '?' for help.In [1]: import subprocess #调用函数 In [2]: subprocess.call(['ls','-l']) drwxr-xr-x. 2 root root 6 10月 31 23:04 公共drwxr-xr-x. 2 root root 6 10月 31 23:04 模板drwxr-xr-x. 2 root root 6 10月 31 23:04 视频drwxr-xr-x. 2 root root 4096 10月 31 22:40 图片drwxr-xr-x. 2 root root 6 10月 31 23:04 文档drwxr-xr-x. 2 root root 6 10月 31 23:04 下载drwxr-xr-x. 2 root root 6 10月 31 23:04 音乐drwxr-xr-x. 2 root root 6 10月 31 15:27 桌面Out[2]: 0In [3]: subprocess.call('exit 1',shell=True) Out[3]: 1 （2）check_call函数 check_call函数的作用与call函数类似，区别在于异常情况下返回的形式不同。 对于call函数，工程师通过捕获call命令的返回值判断命令是否执行成功，如果成功则返回0，否则的话返回非0，对于check_call函数，如果执行成功，返回0，如果执行失败，抛出subrocess.CalledProcessError异常。如下所示： 12345678910111213141516171819202122232425In [5]: subprocess.check_call(['ls','-l'])drwxr-xr-x. 2 root root 6 10月 31 23:04 公共drwxr-xr-x. 2 root root 6 10月 31 23:04 模板drwxr-xr-x. 2 root root 6 10月 31 23:04 视频drwxr-xr-x. 2 root root 4096 10月 31 22:40 图片drwxr-xr-x. 2 root root 6 10月 31 23:04 文档drwxr-xr-x. 2 root root 6 10月 31 23:04 下载drwxr-xr-x. 2 root root 6 10月 31 23:04 音乐drwxr-xr-x. 2 root root 6 10月 31 15:27 桌面Out[5]: 0In [6]: subprocess.check_call('exit 1',shell=True) -------------------------------------------------------------CalledProcessError Traceback (most recent call last)&lt;ipython-input-6-5e148d3ce640&gt; in &lt;module&gt;----&gt; 1 subprocess.check_call('exit 1',shell=True)/usr/local/python381/lib/python3.8/subprocess.py in check_call(*popenargs, **kwargs) 362 if cmd is None: 363 cmd = popenargs[0]--&gt; 364 raise CalledProcessError(retcode, cmd) 365 return 0 366 CalledProcessError: Command 'exit 1' returned non-zero exit status 1. （3）check_output Python3中的subprocess.check_output函数可以执行一条sh命令，并返回命令的输出内容，用法如下： 12345678910111213141516171819202122232425262728293031323334353637In [10]: output = subprocess.check_output(['df','-h']) In [11]: print(output.decode()) 文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/cl-root 17G 5.2G 12G 31% /devtmpfs 473M 0 473M 0% /devtmpfs 489M 92K 489M 1% /dev/shmtmpfs 489M 7.1M 482M 2% /runtmpfs 489M 0 489M 0% /sys/fs/cgroup/dev/sda1 1014M 173M 842M 18% /boottmpfs 98M 16K 98M 1% /run/user/42tmpfs 98M 0 98M 0% /run/user/0In [12]: lines = output.decode().split('\\n')In [13]: lines Out[13]: ['文件系统 容量 已用 可用 已用% 挂载点', '/dev/mapper/cl-root 17G 5.2G 12G 31% /', 'devtmpfs 473M 0 473M 0% /dev', 'tmpfs 489M 92K 489M 1% /dev/shm', 'tmpfs 489M 7.1M 482M 2% /run', 'tmpfs 489M 0 489M 0% /sys/fs/cgroup', '/dev/sda1 1014M 173M 842M 18% /boot', 'tmpfs 98M 16K 98M 1% /run/user/42', 'tmpfs 98M 0 98M 0% /run/user/0', '']In [14]: for line in lines[1:-1]: ...: if line: ...: print(line.split()[-2]) ...: #截取挂载点数据 31%0%1%2%0%18%1%0% 在子进程执行命令，以字符串形式返回执行结果的输出。如果子进程退出码不是0，抛出subprocess.CalledProcessError异常，异常的output字段包含错误输出： 1234567891011121314151617In [19]: try: ...: output = subprocess.check_output(['df','-h']).decode() #正确的 ...: except subprocess.CalledProcessError as e: ...: output = e.output ...: code = e.returncode //正确的没有任何输出 In [23]: try: ...: output = subprocess.check_output(['wsd','-h'], stderr=subprocess.STDOUT) ...: .decode() #错误的 ...: except subprocess.CalledProcessError as e: ...: output = e.output ...: code = e.returncode ...: //前面的错误代码省略FileNotFoundError: [Errno 2] No such file or directory: 'wsd' 3、subprocess模块的Popen类（PyCharm） 实际上，我们上面的三个函数都是基于Popen()的封装(wrapper)。这些封装的目的在于让我们容易使用子进程。当我们想要更个性化我们的需求的时候，就要转向Popen类，该类生成的对象用来代表子进程。 subprocess 模块中基本的进程创建和管理由Popen 类来处理 subprocess.popen是用来替代os.popen的 Popen 是 subprocess的核心，子进程的创建和管理都靠它处理。 构造函数： 1234class subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0,restore_signals=True, start_new_session=False, pass_fds=(),*, encoding=None, errors=None) （1）常用参数： args：shell命令，可以是字符串或者序列类型（如：list，元组） bufsize：缓冲区大小。当创建标准流的管道对象时使用，默认-1。 0：不使用缓冲区 1：表示行缓冲，仅当universal_newlines=True时可用，也就是文本模式 正数：表示缓冲区大小 负数：表示使用系统默认的缓冲区大小。 stdin, stdout, stderr：分别表示程序的标准输入、输出、错误句柄 preexec_fn：只在 Unix 平台下有效，用于指定一个可执行对象（callable object），它将在子进程运行之前被调用 shell：如果该参数为 True，将通过操作系统的 shell 执行指定的命令。 cwd：用于设置子进程的当前目录。 env：用于指定子进程的环境变量。如果 env = None，子进程的环境变量将从父进程中继承。 创建一个子进程，然后执行一个简单的命令： 1234567891011&gt;&gt;&gt; import subprocess&gt;&gt;&gt; p = subprocess.Popen('ls -l', shell=True)&gt;&gt;&gt; total 164-rw-r--r-- 1 root root 133 Jul 4 16:25 admin-openrc.sh-rw-r--r-- 1 root root 268 Jul 10 15:55 admin-openrc-v3.sh...&gt;&gt;&gt; p.returncode&gt;&gt;&gt; p.wait()0&gt;&gt;&gt; p.returncode0 这里也可以使用 p = subprocess.Popen(['ls', '-cl']) 来创建子进程。 （2）Popen 对象的属性 &lt;1&gt; p.pid： 子进程的PID。 &lt;2&gt; p.returncode： 该属性表示子进程的返回状态，returncode可能有多重情况： None —— 子进程尚未结束； ==0 —— 子进程正常退出； &gt; 0—— 子进程异常退出，returncode对应于出错码； &lt; 0—— 子进程被信号杀掉了。 &lt;3&gt; p.stdin, p.stdout, p.stderr： 子进程对应的一些初始文件，如果调用Popen()的时候对应的参数是subprocess.PIPE，则这里对应的属性是一个包裹了这个管道的 file 对象。 （3）Popen 对象方法 poll(): 检查进程是否终止，如果终止返回 returncode，否则返回 None。 wait(timeout): 等待子进程终止。 communicate(input,timeout): 和子进程交互，发送和读取数据。 send_signal(singnal): 发送信号到子进程 。 terminate(): 停止子进程,也就是发送SIGTERM信号到子进程。 kill(): 杀死子进程。发送 SIGKILL 信号到子进程。 子进程的PID存储在child.pid 12345678910111213import timeimport subprocessdef cmd(command): subp = subprocess.Popen(command,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE,encoding=\"utf-8\") subp.wait(2) if subp.poll() == 0: print(subp.communicate()[1]) else: print(\"失败\")cmd(\"java -version\")cmd(\"exit 1\") 输出结果如下： 12345java version \"1.8.0_31\"Java(TM) SE Runtime Environment (build 1.8.0_31-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.31-b07, mixed mode)失败 （4）子进程的文本流控制 (沿用child子进程) 子进程的标准输入，标准输出和标准错误也可以通过如下属性表示: child.stdin child.stdout child.stderr 我们可以在Popen()建立子进程的时候改变标准输入、标准输出和标准错误，并可以利用subprocess.PIPE将多个子进程的输入和输出连接在一起，构成管道(pipe): 12345import subprocesschild1 = subprocess.Popen([\"ls\",\"-l\"], stdout=subprocess.PIPE)child2 = subprocess.Popen([\"wc\"], stdin=child1.stdout,stdout=subprocess.PIPE)out = child2.communicate()print(out) 执行结果如下： 1(b' 2 11 60\\n', None) subprocess.PIPE实际上为文本流提供一个缓存区。child1的stdout将文本输出到缓存区，随后child2的stdin从该PIPE中将文本读取走。child2的输出文本也被存放在PIPE中，直到communicate()方法从PIPE中读取出PIPE中的文本。 要注意的是，communicate()是Popen对象的一个方法，该方法会阻塞父进程，直到子进程完成。 我们还可以利用communicate()方法来使用PIPE给子进程输入: 123import subprocesschild = subprocess.Popen([\"cat\"], stdin=subprocess.PIPE)child.communicate(\"vamei\".encode()) 我们启动子进程之后，cat会等待输入，直到我们用communicate()输入&quot;vamei&quot;。 通过使用subprocess包，我们可以运行外部程序。这极大的拓展了Python的功能。如果你已经了解了操作系统的某些应用，你可以从Python中直接调用该应用(而不是完全依赖Python)，并将应用的结果输出给Python，并让Python继续处理。shell的功能(比如利用文本流连接各个应用)，就可以在Python中实现。 4、使用python自动安装并启动mongodb PyCharm记得连接linux 简易流程 Python自动化运维 --&gt; 基于shell命令进行封装 编写自动化脚本 --&gt; 用Python语法封装shell命令的执行过程 python执行shell命令 --&gt; python外部命令 python函数执行shell命令 os.system(cmd)：执行cmd指令 subprocess模块 subprocess.call(['ls','-l']) subprocess.call('ll' , shell=True) 运行成功: 返回0 运行失败: 返回非0 123456- ```python subprocess. check_call (['ls', '-l']) subprocess. check_call ('ll', shell=True) 运行成功: 返回0 运行失败: 返回CalledProcessError subprocess. check_ output(['cat', 'apache.log'], stderr= subprocess.STDOUT) 运行成功:返回命令的输出结果 运行失败:自定义错误输出stderr 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990- **subprocess模块的Popen类**### （1）PyCharm创建文件```python# coding=utf-8import subprocessimport osimport shutilimport tarfile# 执行外部命令的函数def execute_cmd(cmd): '''执行shell命令''' p = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr = p.communicate() if p.returncode != 0: return p.returncode, stderr return p.returncode, stdout# 解压def unpackage_mongo(package, package_dir): # 获取MongoDB压缩包的主文件名，也就是解压后的目录名称 # mongodb-linux-x86_64-rhe170-4.2.3 unpackage_dir = os.path.splitext(package)[0] if os.path.exists(unpackage_dir): shutil.rmtree(unpackage_dir) if os.path.exists(package_dir): shutil.rmtree(package_dir) # 解压 try: t = tarfile.open(package, 'r:gz') t.extractall('.') print('tar is ok.') except Exception as e: print(e) # 重命名 shutil.move(unpackage_dir, 'mongo')# 创建mongodatadef create_datadir(data_dir): if os.path.exists(data_dir): shutil.rmtree(data_dir) os.mkdir(data_dir)# 拼接启动MongoDBdef format_mongod_commamd(package_dir, data_dir, logfile): # mongo/bin/mongod mongod = os.path.join(package_dir, 'bin', 'mongod') # mongo/bin/mongod --fork --logpath mongodata/mongod.log --dbpath mongodata mongod_format = \"\"\"&#123;0&#125; --fork --dbpath &#123;1&#125; --logpath &#123;2&#125;\"\"\" return mongod_format.format(mongod, data_dir, logfile)# 启动MongoDBdef start_mongod(cmd): returncode, out = execute_cmd(cmd) if returncode != 0: raise SystemExit('execute &#123;0&#125; error:&#123;1&#125;'.format(cmd, out)) else: print('execute &#123;0&#125; successfuly.'.format(cmd))#入口函数def main(): package = 'mongodb-linux-x86_64-rhel70-4.2.3.tgz' cur_dir = os.path.abspath('.') package_dir = os.path.join(cur_dir, 'mongo') data_dir = os.path.join(cur_dir, 'mongodata') logfile = os.path.join(data_dir, 'mongod.log') # 判断MongoDB压缩包是否存在 if not os.path.exists(package): raise SystemExit('&#123;0&#125; not found.'.format(package)) # 解压 unpackage_mongo(package, package_dir) create_datadir(data_dir) # 启动mongodb start_mongod(format_mongod_commamd(package_dir, data_dir, logfile)) # 配置环境变量 os.system('echo \"export PATH=./mongo/bin:$PATH\" &gt; ~/.bash_profile') os.system('source ~/.bash_profile') os.system('./mongo/bin/mongo')main() 在这段程序中，我们首先在main函数中定义了几个变量，包括当前目录的路径、MongoDB二进制文件所在的路径、MongoDB数据目录所在的路径，以及MongoDB的日志文件。 随后，我们判断MongoDB的安装包是否存在，如果不存在，则通过抛出SystemExit异常的方式结束程序。 在unpackage_mongo函数中，我们通过Python程序得到MongoDB安装包解压以后的目录。如果目录已经存在，则删除该目录。随后，我们使用tarfile解MongoDB数据库，解压完成后，将命令重命名为mongo目录。 在create_datadir目录中，我们首先判断MongoDB数据库目录是否存在，如果存在，则删除该目录，随后再创建MongoDB数据库目录。 在start_mongod函数中， 我们执行MongoDB数据库的启动命令启动MongoDB数据库。为了在Python代码中执行shell命令，我们使用了subprocess库。 我们将subprocess库执行she11命令的逻辑封装成execute_cmd函数，在执行shell命令时，直接调用该函数即可。 （2）将PyCharm中的文件上传到Linux 如果，是直接调用Linux中文件可用： 如果是本地创建： （3）Linux执行脚本，并测试 记得进入PyCharm与linux连接的目录（目前是/opt） 12345678910111213141516171819202122[root@python opt]# python auto_install_mongodb.py #执行提前编写好的脚本tar is ok.execute /opt/mongo/bin/mongod --fork --dbpath /opt/mongodata --logpath /opt/mongodata/mongod.log successfuly.[root@python opt]# netstat -anpt | grep mongo #查看mongo是否启动tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN 4616mongod [root@python opt]# ls #查看是否生成mongo目录01find_cmd.py bb.bmp mongodb-linux-x86_64-rhel70-4.2.3.tgzaaa.jpg cc.png rhadc.txt mongo subprocess_demoauto_install_mongodb.py mongodata[root@python opt]# cd mongo[root@python mongo]# cd bin/[root@python bin]# ./mongo #进入mongoMongoDB shell version v4.2.3connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&amp;gssapiServiceName=mongodbImplicit session: session &#123; \"id\" : UUID(\"c302ff50-7e27-40b7-8046-8441af8cb965\") &#125;MongoDB server version: 4.2.3&gt; show databases; #查看数据库admin 0.000GBconfig 0.000GBlocal 0.000GB","path":"posts/48ac.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python使用ConfigParser类解析配置文件","text":"前言 使用配置文件来灵活的配置一些参数是一件很常见的事情，配置文件的解析并不复杂，在python里更是如此，在官方发布的库中就包含有做这件事情的库，那就是configParser configParser解析的配置文件的格式比较象ini的配置文件格式，就是文件中由多个section构成，每个section下又有多个配置项 ConfigParser简介 ConfigParser 是用来读取配置文件的包。配置文件的格式如下：中括号“[ ]”内包含的为section。section 下面为类似于key-value 的配置内容。 ConfigParser模块在python3中修改为configparser.这个模块定义了一个ConfigParser类，该类的作用是使用配置文件生效，配置文件的格式和windows的INI文件的格式相同 该模块的作用 就是使用模块中的RawConfigParser()、ConfigParser()、 SafeConfigParser()这三个方法（三者择其一），创建一个对象使用对象的方法对指定的配置文件做增删改查 操作。 ini文件结构 ini文件结构需要注意一下几点： 键值对可用=或者:进行分隔 section的名字是区分大小写的,而key的名字是不区分大小写的 键值对中头部和尾部的空白符会被去掉 值可以为多行 配置文件可以包含注释，注释以#或者;为前缀 注意：configparser有default_section的概念,默认为[DEFAULT]节,也就是之后的所有的section都有该默认section中的键值对,详情参见configparser源码的__init__()方法 一、使用ConfigParser类解析ini配置文件 （PyCharm中实现） 实现查询、添加、删除、保存。 练习目的： 掌握文件基本操作 认识ini文件 了解ConfigParser类 使用ConfigParser类解析配置文件 ini配置文件的格式： 12节： [session]参数(键=值) name=value 1、解析mysql配置文件 **read(filename) 直接读取文件内容** get(section, option) 获取section 下具体某一配置项的值(返回的是字符串) sections() 得到所有的section，并以列表的形式返回 options(section) 得到该section的所有option items(section) 键值对的形式 得到该section的所有option getint(section,option)、cnf.getboolean(section,option)、getfloat(section,option) 获取整型、布尔型和浮点型的option的值 my.ini文件示例： 1234567891011[client]port = 3306user = mysqlpassword = mysqlhost = 127.0.0.1[mysqld]basedir = /usrdatadir = /var/lib/mysqltmpdir = /tmpskip-external-locking 2、ConfigParser类的使用方法 (1)创建configParser对象 123In [1]: import configparserIn [2]: cf = configparser.ConfigParser(allow_no_value=True) (2)读取配置文件内容 12In [4]: cf.read('my.ini')Out[4]: ['my.ini'] (3)获取配置文件信息 sections: 返回一个包含所有章节的列表 options: 返回一个包含章节下所有选项的列表 has_section: 判断章节是否存在 has_options: 判断某个选项是否存在 items: 以元组的形式返回所有的选项 get、getboolean、getint、getfloat: 获取选项的值 同时需要注意getboolean()方法能判断True/False的值有： ‘yes’/‘no’, ‘on’/‘off’, ‘true’/‘false’ 和 ‘1’/‘0’ 1234567891011121314151617In [4]: cf.sections() # 返回一个包含所有章节的列表Out[4]: ['client','mysq1d']In [5]: cf.has_section('client') # 判断章节是否存在0ut[5]: TrueIn [6]cf.options('client ') # 判断某个选项是否存在Out[6]: ['port\", 'user', 'password', 'host' ]In [7]: cf.has_option('client', 'user') # 判断某个选项是否存在0ut[7]: TrueIn [8]: cf.get('client',' port') # 获取选项的值0ut[8]: '3306'In [9]: cf.getint('client','port') # 获取选项的值0ut[9]: 3306 (4)修改配置文件 常用方法: remove_section: 删除一个章节 add_section: 添加一个章节 remove_option: 删除一个选项 set: 添加一个选项 write: 将ConfigParser兑现中的数据保存到文件中 方法测试: 1234567891011121314151617181920In [11]: cf.remove_section('client') # 删除一个章节Out[11]: TrueIn [14]: cf.write(open('my.ini','w')) # 将ConfigParser兑现中的数据保存到文件中#可在PyCharm中my.ini文件查看是否少了'client‘字段。 In [15]: cf.add.section('client') # 添加一个章节In [16]: cf.set('client','port','3306') # 添加一个选项In [17]: cf.set('client','user','mysq1') # 添加一个选项In [18]: cf.set('client','password' 'mysq1') # 添加一个选项In [19]: cf.set('client','host','127.0.0.1') # 添加一个选项In [20]: cf.write(open('my.ini','w')) # 将ConfigParser兑现中的数据保存到文件中#可在PyCharm中my.ini文件查看是否增加了'client‘字段。In [21]: cf.remove_option('client', 'host') # 删除一个选项**Out[21]: TrueIn [22]: cf.write(open('my.ini','w' )) # 将ConfigParser兑现中的数据保存到文件中#可在PyCharm中my.ini文件查看是否减少了指定选项。 可在PyCharm上查看测试效果。 3、常见异常 异常 描述 ConfigParser.Error 所有异常的基类 ConfigParser.NoSectionError 指定的section没有找到 ConfigParser.DuplicateSectionError 调用add_section() 时，section名称已经被使用 ConfigParser.NoOptionError 指定的参数没有找到 ConfigParser.InterpolationError 当执行字符串插值时出现问题时，出现异常的基类 ConfigParser.InterpolationDepthError 当字符串插值无法完成时，因为迭代次数超过了最大的范围，所以无法完成。InterpolationError的子类 InterpolationMissingOptionError 当引用的选项不存在时，会出现异常。InterpolationError的子类 ConfigParser.InterpolationSyntaxError 当产生替换的源文本不符合所需的语法时，就会出现异常。InterpolationError的子类。 ConfigParser.MissingSectionHeaderError 当试图解析一个没有分段标题的文件时，会出现异常。 ConfigParser.ParsingError 当试图解析文件时发生错误时，会出现异常 ConfigParser.MAX_INTERPOLATION_DEPTH 当raw参数为false时，get()的递归插值的最大深度。这只适用于ConfigParser类 二、查找文件 PyCharm创建测试文件，格式如下： 12345678910111213141516G:\\四期\\python\\ConfigParser\\files&gt;tree /f卷 学习 的文件夹 PATH 列表卷序列号为 7C11-994AG:.│ a.jpg│ A.png│ b.jpg│ c.png│ e.bmp│ f.txt│ ff.txt│ find_file.py│ find_file2.py│ find_file3.py│└─test 测试一下 find_file.py 12345import osfor item in os.listdir('.'): if os.path.isfile(item):truetrueprint(item) 输出结果如下： 12345678910a.jpgA.pngb.jpgc.pnge.bmpf.txtff.txtfind_file.pyfind_file2.pyfind_file3.py 1、使用fnmatch找到特定文件 &lt;1&gt;fnmatch支持的通配符 字符 函数 * 匹配所有字符 ？ 匹配单个字符 [seq] 匹配指定范围内的字符 [!seq] 匹配不在指定范围内的字符 &lt;2&gt;fnmatch的基本使用 fnmatch这个库相对比较简单，只有4个函数，分别是fnmatch、fnmatchcase、filter和translate，其中最常用的是fnmatch。主要功能如下： fnmatch：判断文件名是否符合特定的模式。 fnmatchcase：判断文件名是否符合特定的模式，区分大小写。 filter：返回输入列表中，符合特定模式的文件名列表。 translate：将通配符模式转换成正则表达式。 fnmatch和fnmatchcase用法相同，判断名称是否符合表达式，返回True or False （1）fnmatch.fnmatch()：一次只能处理一个文件 find_file2.py 12345678910import osimport fnmatchfor item in os.listdir('.'): if os.path.isfile(item): # if fnmatch.fnmatch(item,'*.jpg'): # if fnmatch.fnmatch(item, '[a-e].*'): # if fnmatch.fnmatch(item, '[a-z]?.txt'): # if fnmatch.fnmatch(item, '[!a-c]*'): print(item) 输出结果如下： 123456789101112131415161718192021#输出以“.jpg”为结尾的文件a.jpgb.jpg#输出以“a-e”为标题的文件a.jpgA.pngb.jpgc.pnge.bmp#输出以“a-z”和一个任意字符为标题，并且以“.txt”为后缀的文件ff.txt#输出除了以“a-c”为开通的文件e.bmpf.txtff.txtfind_file.pyfind_file2.pyfind_file3.py （2）fnmath.filter()：一次可以处理多个文件 find_file3.py 123456import osimport fnmatchitems = os.listdir('.')files = fnmatch.filter(items, '[a-c]*')print(files) 输出结果如下： 1['a.jpg', 'A.png', 'b.jpg', 'c.png'] 2、使用glob找到特定文件 glob模块支持的通配符： 通配符 功能 * 匹配0或多个字符 ** 匹配所有文件、目录、子目录和子目录里的文件（3.5版本新增） ? 匹配1个字符，与正则表达式里的?不同 [exp] 匹配指定范围内的字符，如：[1-9]匹配1至9范围内的字符 [!exp] 匹配不在指定范围内的字符 标准库glob的作用相当于os.listdir()加上fnmatch。使用glob以后，不需要调用os.listdir获取文件列表，直接通过模式匹配即可。如下所示: 1234import globfile = glob.glob('*.txt')print(file) 输出结果如下： 1['f.txt', 'ff.txt'] glob基本使用 glob和iglob的区别在于glob返回的是一个列表，iglob返回的是一个生成器对象 1234567891011&gt;&gt;&gt; import glob&gt;&gt;&gt; glob.glob('*.txt')['a1.txt', 'a2.txt', 'aA.txt'] &gt;&gt;&gt; g = glob.iglob('*.txt') # 使用iglob返回的是一个生成器&gt;&gt;&gt; g&lt;generator object _iglob at 0x1050bbba0&gt; &gt;&gt;&gt; list(g)['a1.txt', 'a2.txt', 'aA.txt']&gt;&gt;&gt; PS：glob同样支持通配符和fnmatch相同，这里不在列举，并且在通配符表达式中支持路径 12&gt;&gt;&gt; glob.glob('/Users/DahlHin/github/test/*.txt')['/Users/DahlHin/github/test/a1.txt','/Users/DahlHin/github/test/a2.txt','/Users/DahlHin/github/test/aA.txt'] 总结：虽然glob模块可以很轻松地匹配特定文件和文件夹，但是仅仅支持少量的通配符，没办法像正则表达式一样匹配更复杂的字符串。使用的时候应当认真考虑使用场景，根据需求针对性地选择解决方案。 3、找到目录下最大(或最老)的10个文件 PyCharm创建测试文件，格式如下： 12345678G:\\四期\\python\\打印最常用的10条linux命令\\exam&gt;tree /f 1000313.jpg 1000367.jpg 1000591.bmp 1000925.tiff 323507.jpg 325738.jpg find_file_max.py 三、高级文件处理接口shutil shutil 是一种高层次的文件操作工具 类似于高级API，而且主要强大之处在于其对文件的复制与删除操作更是比较支持好。 使用方法 copyfile( src, dst) 从源src复制到dst中去。当然前提是目标地址是具备可写权限。抛出的异常信息为IOException. 如果当前的dst已存在的话就会被覆盖掉 copymode( src, dst) 只是会复制其权限其他的东西是不会被复制的 copystat( src, dst) 复制权限、最后访问时间、最后修改时间 copy( src, dst) 复制一个文件到一个文件或一个目录 copy2( src, dst) 在copy上的基础上再复制文件最后访问时间与修改时间也复制过来了，类似于cp –p的东西 copy2( src, dst) 如果两个位置的文件系统是一样的话相当于是rename操作，只是改名；如果是不在相同的文件系统的话就是做move操作 copytree(olddir,newdir,True/Flase) 把olddir拷贝一份newdir，如果第3个参数是True，则复制目录时将保持文件夹下的符号连接，如果第3个参数是False，则将在复制的目录下生成物理副本来替代符号连接 123456789[root@python ~]# mkdir /tmp/demo[root@python ~]# cd /tmp/demo/[root@python demo]# mkdir -p dir1[root@python demo]# touch a.txt b.txt c.txt[root@python demo]# touch sh.py cc.py 001.jpg 002.jpg 003.jpg//创建所需文件[root@python demo]# ipython//打开ipython 也可以在PyCharm中创建文件，进行实施。 1、复制文件和文件夹 12shutil.copy(file1,file2) #文件shutil.copytree(dir1,dir2) #文件夹 （1）复制文件 123456789In [1]: import shutil In [2]: shutil.copy('a.txt','aa.txt') Out[2]: 'aa.txt'//可在PyCharm和Linux的相应路径查看是否有生成的文件 In [3]: ls 001.jpg 003.jpg a.txt cc.py sh.py002.jpg aa.txt b.txt c.txt （2）复制文件夹 123456In [5]: shutil.copytree('dir1','dir11') Out[5]: 'dir11' In [6]: ls 001.jpg 003.jpg a.txt cc.py dir1/ sh.py002.jpg aa.txt b.txt c.txt dir11/ 2、文件和文件夹的重命名与移动 12shutil.move(filel, file2)shutil.move(file, dir) （1）文件的重命名 123456In [7]: shutil.move('aa.txt','dd.txt') Out[7]: 'dd.txt'In [8]: ls 001.jpg 003.jpg b.txt c.txt dir1/ sh.py002.jpg a.txt cc.py dd.txt dir11/ （2）文件移动到文件夹 12345In [9]: shutil.move('dd.txt','dir1') Out[9]: 'dir1/dd.txt'In [11]: ls dir1 dd.txt 3、删除目录 12shutil.rmtree(dir) # 删除目录os.unlink(file) # 删除文件 删除目录 12345In [15]: shutil.rmtree('dir1') In [16]: ls 001.jpg 003.jpg b.txt c.txt sh.py002.jpg a.txt cc.py dir11/ 四、文件内容管理 1、目录和文件的对比 filecmp模块包含了比较目录和文件的操作。 filecmp可以实现文件，目录，遍历子目录的差异对比功能。 自带filecmp模块，无需安装。 （1）目录结构 目录dir1中文件a_copy.txt，a.txt，c.txt内容一样，b.txt内容不一样 1234567891011121314[root@python demo]# mkdir compare[root@python demo]# cd compare/[root@python compare]# mkdir -p dir1 dir2[root@python compare]# mkdir dir1/subdir1[root@python compare]# lsdir1 dir2[root@python compare]# touch dir1/a_copy.txt dir1/a.txt dir1/b.txt dir1/c.txt[root@python compare]# touch dir2/a.txt dir2/b.txt dir2/c.txt[root@python compare]# mkdir -p dir2/subdir1 dir2/subdir2[root@python compare]# touch dir2/subdir1/sb.txt//创建所需文件[root@python compare]# ipython//打开ipython filecmp提供3个操作方法，cmp(单文件对比),cmpfile(多文件对比),dircmp(目录对比)。 （2）示例代码： 使用filecmp模块的cmp函数比较两个文件是否相同，如果文件相同则返回True,否则False 12345678910In [1]: import filecmp In [2]: filecmp.cmp('a.txt','b.txt') Out[2]: FalseIn [3]: filecmp.cmp('a.txt','c.txt') Out[3]: True In [4]: filecmp.cmp('a.txt','a_copy.txt') Out[4]: True （3）比较两个文件 filecmp目录下还有一个名为cmpfiles的函数， 该函数用来同时比较两个不同的目录下的多个文件,并且返回一个三元组，分别包含相同的文件、不同的文件和无法比较的文件。示例如下: 123In [9]: filecmp.cmpfiles('dir1','dir2',['a.txt','b.txt','c.txt','a_copy.txt']) Out[9]: (['b.txt'], ['a.txt', 'c.txt'], ['a_copy.txt'])# 返回一个三元组第一个是一样的第个是不一样的第三个是无法比较(没有这个文件或者其他原因) （4）比较多个文件 cmpfiles函数同时用来比较两个目录下的文件,也可以使用该函数比较两个目录。但是，在比较两个目录时，需要通过参数指定可能的文件，因此比较繁琐。 filecmp中还有一个名为dircmp的函数，用来比较两个目录。调用dircmp函数以后，会返回一个dircmp类的对象,该对象保存了诸多属性，我们可以通过查看这些属性获取目录之间的差异。如下所示: 12345678910In [11]: d = filecmp.dircmp('dir1','dir2') #设置测试目录 In [12]: d.report() diff dir1 dir2Only in dir1 : ['a_copy.txt']Only in dir2 : ['subdir2']Identical files : ['b.txt']Differing files : ['a.txt', 'c.txt']Common subdirectories: ['subdir1'] （5）直接比较目录不指定文件 目录对比，通过filecmp（a,b[,ignore[,hide]]）类创建一个目录比较对象用于比较文件夹，通过该类比较两个文件夹，可以获取一些详细的比较结果（如只在A文件夹存在的文件列表），并支持子文件夹的递归比较。 1234567891011In [17]: d.left_list #查看dir1目录结构 Out[17]: ['a.txt', 'a_copy.txt', 'b.txt', 'c.txt', 'subdir1']In [18]: d.right_list #查看dir2目录结构 Out[18]: ['a.txt', 'b.txt', 'c.txt', 'subdir1', 'subdir2']In [19]: d.left_only #仅第dir1目录存在的 Out[19]: ['a_copy.txt']In [20]: d.right_only #仅第dir2目录存在的 Out[20]: ['subdir2'] 2、MD5校验和比较 校验码是通过散列函数计算而成，是一种从任何数据中创建小的数字”指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，便于进行比较。MDS是目前使用最官方的 MD5哈希一般用于检查文件的完整性，尤其常用于检查文件传输、磁盘错误或其他情况下文件的正确性。 Linux下计算一个文件的MD5校验码，如下所示： 12[root@192 demo]# md5sum a.txtd41d8cd98f00b204e9800998ecf8427e a.txt 在Python中计算文件的MD5校验码也非常简单，使用标准库hashlib模块即可。如下所示： 1234567891011121314151617import hashlibd = hashlib.md5()with open('b.txt') as f: for line in f: d.update(line.encode('utf-8'))print(d.hexdigest())# 或者可以这样（最常见的写法，常用于图片的命名）&gt;&gt;&gt; import hashlib &gt;&gt;&gt; hashlib.md5(b'123').hexdigest()'202cb962ac59075b964b07152d234b70'# 也可以使用hash.new()这个一般方法，hashlib.new(name[, data])，name传入的是哈希加密算法的名称，如md5&gt;&gt;&gt; hashlib.new('md5', b'123').hexdigest()'202cb962ac59075b964b07152d234b70' 记得创建b.txt文件 五、Python管理压缩包 1、tarfile 既然有压缩模块zipfile，那有一个归档模块tarfile也是很自然的。tarfile模块用于解包和打包文件，包括被gzip，bz2或lzma压缩后的打包文件。如果是.zip类型的文件，建议使用zipfile模块，更高级的功能请使用shutil模块。 定义的类和异常 1tarfile.open(name=None, mode='r', fileobj=None, bufsize=10240, \\kwargs) 返回一个TarFile类型的对象。本质上就是打开一个文件对象。Python随处可见这种文件对象类型的设计，你很容易就明白，不是吗？ name是文件名或路径。 bufsize用于指定数据块的大小，默认为20*512字节。 mode是打开模式，一个类似filemode[:compression]格式的字符串，可以有下表所示的组合，默认为“r” 模式 说明 ‘r’or’r:*’ 自动解压并打开文件（推荐模式） ‘r:’ 只打开文件不解压 ‘r:gz’ 采用gzip格式解压并打开文件 ‘r:bz2’ 采用bz2格式解压并打开文件 ‘r:xz’ 采用lzma格式解压并打开文件 ‘x’or’x:’ 仅创建打包文件，不压缩 ‘x:gz’ 采用gzip方式压缩并打包文件 ‘x:bz2’ 采用bzip2方式压缩并打包文件 ‘x:xz’ 采用lzma方式压缩并打包文件 ‘a’or’a:’ 打开文件，并以不压缩的方式追加内容。如果文件不存在，则新建 ‘w’or’w:’ 以不压缩的方式写入 ‘w:gz’ 以gzip的方式压缩并写入 ‘w:bz2’ 以bzip2的方式压缩并写入 ‘w:xz’ 以lzma的方式压缩并写入 注意 不支持’a:gz’, 'a:bz2’和’a:xz’的模式 如果当前模式不能正常打开文件用于读取，将抛出ReadError异常，这种情况下，请使用“r”模式。如果指定的压缩方式不支持，将抛出CompressionError异常。 在w:gz,r:gz,w:bz2,r:bz2,x:gz,x:bz2模式下，tarfile.open()方法额外接受一个压缩等级参数compresslevel，默认值为9。 （1）读取文件 压缩文件提取码：0418 123456789import tarfilewith tarfile.open('tengine-2.3.2.tar.gz') as t: # getmember() 查看文件列表 for member in t.getmembers(): print(member.name)with tarfile.open('tengine-2.3.2.tar.gz') as t: t.extractall('a','tengine-2.3.2/man') t.extract('tengine-2.3.2/man','b') 常用方法说明: getmembers () : 获取tar包中的文件列表 member.name : 获取tar包中文件的文件名 extract(member, path) : 提取单个文件 extractall(path,memebers) : 提取所有的文件 （2）创建tar包 记得创建read.txt文件 1234import tarfilewith tarfile.open( 'readme.tar',mode='w') as out : out.add('read.txt') 可在对应位置查看是否有readme.tar文件 （3）读取与创建压缩包 123456import tarfilewith tarfile.open('tarfile_add.tar ',mode='r:gz') as out: passwith tarfile.open('tarfile_add.tar ',mode='r:bz2') as out: pass （4）备份指定文件到压缩包中 123456789101112131415161718192021222324252627import osimport fnmatchimport tarfileimport datetimedef is_file_math(filename, patterns): '''查找特定类型的文件''' for pattern in patterns: if fnmatch.fnmatch(filename, pattern): return True return Falsedef find_files(root, patterns=['*']): for root, dirnames, filenames in os.walk(root): for filename in filenames: if is_file_math(filename, patterns): yield os.path.join(root, filename)patterns = ['*.txt','*.md']now = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')filename = 'backup_all_file_&#123;0&#125;.tar.gz'.format(now)with tarfile.open(filename, 'w') as f: for item in find_files('.', patterns): f.add(item) 可在对应位置查看是否有readme.tar文件 2、zipfile zipfile 是python里用来做zip格式编码的压缩和解压缩的，由于是很常见的zip格式，所以这个模块使用频率也是比较高。 zipfile里有两个非常重要的class, 分别是ZipFile和ZipInfo, 在绝大多数的情况下，只需要使用这两个class就可以。 ZipFile是主要的类，用来创建和读取zip文件； ZipInfo是存储的zip文件的每个文件的信息的。 (1)读取zip文件 1234567import zipfiledemo_zip = zipfile.ZipFile('read.zip')print(demo_zip.namelist())demo_zip.extractall('1')demo_zip.extract('a.jpg','2')//记得创建名为2的目录，当然第一个字段的路径也必须正确。 常用方法说明: namelist() :返回zip文件中包含的所有文件和文件夹的字符串列表 extract(filename, path): 从zip文件中提取单个文件 extractall(path): 从zip文件中提取所有文件 (2)创建zip文件 12345import zipfilenewZip = zipfile.ZipFile( 'new.zip', mode='w' )newZip.write('a.jpg') #文件必须存在newZip.close() (3) Python命令行调用zipfile 12345678910#创建zip文件python -m zipfile -c new1.zip b.txt#查看zip文件内容python -m zipfile -l new1.zipFile Name Modified Sizeb.txt 2020-04-26 14:35:12 0#提取zip文件到指定目录python -m zipfile -e new1.zip / zipfile模块提供的命令行接口包含的选项: -1: 显示zi p格式压缩包中的文件列表 -e: 提取z i p格式的压缩包 -c:创建zip格式的压缩包 -t: 验证文件是不是一个有效的zi p格式压缩包 (4) zipfile的各个属性 123456789101112131415161718192021import zipfile, oszipFile = zipfile.ZipFile(os.path.join(os.getcwd(), 'duoduo.zip'))zipInfo = zipFile.getinfo('文件中的文件.txt')print ('filename:', zipInfo.filename) #获取文件名称print ('date_time:', zipInfo.date_time) #获取文件最后修改时间。返回一个包含6个元素的元组：(年, 月, 日, 时, 分, 秒)print ('compress_type:', zipInfo.compress_type) #压缩类型print ('comment:', zipInfo.comment) #文档说明print ('extra:', zipInfo.extra) #扩展项数据print ('create_system:', zipInfo.create_system) #获取创建该zip文档的系统。print ('create_version:', zipInfo.create_version) #获取 创建zip文档的PKZIP版本。print ('extract_version:', zipInfo.extract_version) #获取 解压zip文档所需的PKZIP版本。print ('extract_version:', zipInfo.reserved) # 预留字段，当前实现总是返回0。print ('flag_bits:', zipInfo.flag_bits) #zip标志位。print ('volume:', zipInfo.volume) # 文件头的卷标。print ('internal_attr:', zipInfo.internal_attr) #内部属性。print ('external_attr:', zipInfo.external_attr) #外部属性。print ('header_offset:', zipInfo.header_offset) # 文件头偏移位。print ('CRC:', zipInfo.CRC) # 未压缩文件的CRC-32。print ('compress_size:', zipInfo.compress_size) #获取压缩后的大小。print ('file_size:', zipInfo.file_size) #获取未压缩的文件大小。zipFile.close() # 3、shutil创建和读取压缩包 shutil可以简单地理解为sh + util，shell工具的意思。shutil模块是对os模块的补充，主要针对文件的拷贝、删除、移动、压缩和解压操作。 使用方法 copyfile( src, dst) 从源src复制到dst中去。当然前提是目标地址是具备可写权限。抛出的异常信息为IOException. 如果当前的dst已存在的话就会被覆盖掉 copymode( src, dst) 只是会复制其权限其他的东西是不会被复制的 copystat( src, dst) 复制权限、最后访问时间、最后修改时间 copy( src, dst) 复制一个文件到一个文件或一个目录 copy2( src, dst) 在copy上的基础上再复制文件最后访问时间与修改时间也复制过来了，类似于cp –p的东西 copy2( src, dst) 如果两个位置的文件系统是一样的话相当于是rename操作，只是改名；如果是不在相同的文件系统的话就是做move操作 copytree(olddir,newdir,True/Flase) 把olddir拷贝一份newdir，如果第3个参数是True，则复制目录时将保持文件夹下的符号连接，如果第3个参数是False，则将在复制的目录下生成物理副本来替代符号连接 测试 123import shutilprint(shutil.get_archive_formats()) 输出结果如下： 1[('bztar', \"bzip2'ed tar-file\"), ('gztar', \"gzip'ed tar-file\"), ('tar', 'uncompressed tar file'), ('xztar', \"xz'ed tar-file\"), ('zip', 'ZIP file')] （1）创建压缩包 12345import shutil# 参数1：生成的压缩包文件名# 参数2：压缩包的格式# 参数3：压缩的目录shutil.make_archive('a.jpg','gztar', 'ddd') 可在对应位置查看是否有生成的文件 （2）解压 1234import shutil# 参数1：需要解压的压缩包# 参数2：解压的目录print(shutil.unpack_archive('a.jpg.tar.gz','jpg')) 可在对应位置查看是否有生成的文件 （3）将文件内容拷贝到另一个文件中 12345678910111213141516171819202122232425262728293031# _*_ coding:utf-8 _*___author__ = 'junxi'import shutil# 将文件内容拷贝到另一个文件中shutil.copyfileobj(open('old.txt', 'r'), open('new.txt', 'w'))# 拷贝文件shutil.copyfile('old.txt', 'old1.txt')# 仅拷贝权限。内容、组、用户均不变shutil.copymode('old.txt', 'old1.txt')# 复制权限、最后访问时间、最后修改时间shutil.copystat('old.txt', 'old1.txt')# 复制一个文件到一个文件或一个目录shutil.copy('old.txt', 'old2.txt')# 在copy上的基础上再复制文件最后访问时间与修改时间也复制过来了shutil.copy2('old.txt', 'old2.txt')# 把olddir拷贝一份newdir，如果第3个参数是True，则复制目录时将保持文件夹下的符号连接，如果第3个参数是False，则将在复制的目录下生成物理副本来替代符号连接shutil.copytree('C:/Users/xiaoxinsoso/Desktop/aaa', 'C:/Users/xiaoxinsoso/Desktop/bbb')# 移动目录或文件shutil.move('C:/Users/xiaoxinsoso/Desktop/aaa', 'C:/Users/xiaoxinsoso/Desktop/bbb') # 把aaa目录移动到bbb目录下# 删除一个目录shutil.rmtree('C:/Users/xiaoxinsoso/Desktop/bbb') # 删除bbb目录","path":"posts/cbc8.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python的os模块","text":"什么是os模块 os模块提供了多数操作系统的功能接口函数。当os模块被导入后，它会自适应于不同的操作系统平台，根据不同的平台进行相应的操作，在python编程时，经常和文件、目录打交道，这时就离不了os模块，本节内容将对os模块提供的函数进行详细的解读 一、使用脚本自动安装Python版本 要求：没有安装过Python3的系统 如果已经安装过Python3，只能选择一个不用的版本安装 1、PyCharm连接Linux 2、os模块执行shell命令 os.system()的作用： 123执行shell命令返回shell命令的返回值命令的输出会输出到标准输出 代码演示： os.system(‘cls’) 编写自动安装Python的脚本 （1）实现步骤： 123下载Python版本源码安装Python需要的依赖库编译安装Python （2）伪代码： 123451. 判断用户是不是root2. 如果是，等待用户输入Python版本3. 执行shell命令下载源码包4. 安装依赖开发包5. 编译安装Python （3）脚本内容如下（基于Python2）： auto_install_python.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# coding=utf-8import os# 判断用户是否是root用户if os.getuid() == 0: passelse: print('当前用户不是root用户！') SystemExit(1)# 安装Python依赖库cmd_module = 'yum -y install wget gcc zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel'res = os.system(cmd_module)if res != 0: print('Python依赖库安装失败，请重新执行该脚本！') SystemExit(1)else: print('Python依赖库安装成功！')# 输入python版本，下载Python源码包到本地目录# weget urlversion = raw_input('请输入python版本：（3.6/3.8）')if version == '3.6': url = 'https://www.python.org/ftp/python/3.6.10/Python-3.6.10.tgz'else: url = 'https://www.python.org/ftp/python/3.8.2/Python-3.8.2.tgz'cmd = 'wget ' + urlres = os.system(cmd)if res != 0: print('Python源码包下载失败！') SystemExit(1)else: print('===============================&gt;&gt;&gt;Python源码包下载成功！')# 解压Python源码包# tar zxvf Python-3.8.2.tgzif version == '3.6': package_name = 'Python-3.6.10'else: package_name = 'Python-3.8.1'res = os.system('tar zxvf ' + package_name + '.tgz')if res != 0: print('解压失败！') SystemExit(1)else: print('=============&lt;&lt;解压成功！&gt;&gt;===============')# 必要的配置，否则出现错误：“make: *** [pybuilddir.txt] 错误1”# export LANG=zh_CN.UTF-8# export LANGUAGE=zhb_CN.UTF-8cmd_export_lang = 'export LANG=zh_CN.UTF-8'cmd_export_language = 'export LANGUAGE=zhb_CN.UTF-8'res1 = os.system(cmd_export_lang)res2 = os.system(cmd_export_language)if res1 != 0 or res2 != 0: print('配置失败，请检查解脚本后在运行！') SystemExit(1)# 切换Python目录os.chdir(package_name)os.system('./configure --prefix=/usr/local/python3')res = os.system('make &amp;&amp; make install')if res != 0: print('源码编译失败！') SystemExit(1)else: print('=========&lt;&lt;Python安装成功，请进行验证！&gt;&gt;==========')# 修改用户环境变量os.system('echo \"export PYTHON3=/usr/local/python3\" &gt;&gt;~/.bash_profile')os.system('echo \"export PATH=$PYTHON3/bin:$PATH\" &gt;&gt;~/.bash_profile')os.system(\"source ~/.bash_profile\")os.system('cat ~/.bash_profile')print('用户环境变量已更改，请进行验证！')os.system('ln -s /usr/local/python3/bin/* /usr/local/bin')os.system('python3 --version') 3、上传到Linux并执行 Linux执行 12[root@python ~]# cd /opt/[root@python opt]# python test1.py 二、Python的os模块shell Python 的 os 模块封装了常见的文件和目录操作，本文只列出部分常用的方法，更多的方法可以查看官方文档。 下面是部分常见的用法： 方法 说明 os.mkdir 创建目录 os.rmdir 删除目录 os.rename 重命名 os.remove 删除文件 os.getcwd 获取当前工作路径 os.walk 遍历目录 os.path.join 连接目录与文件名 os.path.split 分割文件名与目录 os.path.abspath 获取绝对路径 os.path.dirname 获取路径 os.path.basename 获取文件名或文件夹名 os.path.splitext 分离文件名与扩展名 os.path.isfile 判断给出的路径是否是一个文件 os.path.isdir 判断给出的路径是否是一个目录 1、安装ipython 1[root@root ~]# pip3 install -i https://pypi.douban.com/simple/ ipython 启动ipython 1[root@root ~]# ipython 如果启动不了使用： 1python3 -m IPython --version 来查看ipython版本，如果看到版本信息，那么就可以使用python -m IPython 命令来启动ipython 如果要使用ipython命令来启动，可以在用户目录下的 .bash_profile中增加如下： 1alias ipython=\"python3 -m IPython\" 再次启动ipython 1python3 -m IPython --version 这样就可以了 2、例子 后文的例子以下面的目录结构为参考，工作目录为 /Users/ethan/coding/python。 12345Users/ethan└── coding └── python ├── hello.py - 文件 └── web - 目录 看看例子： （1）os.path.abspath：获取文件或目录的绝对路径 12345678910$ pwd/Users/ethan/coding/python$ python&gt;&gt;&gt; import os # 记得导入 os 模块&gt;&gt;&gt; os.path.abspath('hello.py')'/Users/ethan/coding/python/hello.py'&gt;&gt;&gt; os.path.abspath('web')'/Users/ethan/coding/python/web'&gt;&gt;&gt; os.path.abspath('.') # 当前目录的绝对路径'/Users/ethan/coding/python' （2）os.path.dirname：获取文件或文件夹的路径 123456&gt;&gt;&gt; os.path.dirname('/Users/ethan/coding/python/hello.py')'/Users/ethan/coding/python'&gt;&gt;&gt; os.path.dirname('/Users/ethan/coding/python/')'/Users/ethan/coding/python'&gt;&gt;&gt; os.path.dirname('/Users/ethan/coding/python')'/Users/ethan/coding' （3）os.path.basename：获取文件名或文件夹名 123456&gt;&gt;&gt; os.path.basename('/Users/ethan/coding/python/hello.py')'hello.py'&gt;&gt;&gt; os.path.basename('/Users/ethan/coding/python/')''&gt;&gt;&gt; os.path.basename('/Users/ethan/coding/python')'python' （4）os.path.splitext：分离文件名与扩展名 123456&gt;&gt;&gt; os.path.splitext('/Users/ethan/coding/python/hello.py')('/Users/ethan/coding/python/hello', '.py')&gt;&gt;&gt; os.path.splitext('/Users/ethan/coding/python')('/Users/ethan/coding/python', '')&gt;&gt;&gt; os.path.splitext('/Users/ethan/coding/python/')('/Users/ethan/coding/python/', '') （5）os.path.split：分离目录与文件名 123456&gt;&gt;&gt; os.path.split('/Users/ethan/coding/python/hello.py')('/Users/ethan/coding/python', 'hello.py')&gt;&gt;&gt; os.path.split('/Users/ethan/coding/python/')('/Users/ethan/coding/python', '')&gt;&gt;&gt; os.path.split('/Users/ethan/coding/python')('/Users/ethan/coding', 'python') （6）os.path.isfile：是否是一个文件 os.path.isdir：是否是一个目录 12345678&gt;&gt;&gt; os.path.isfile('/Users/ethan/coding/python/hello.py')True&gt;&gt;&gt; os.path.isdir('/Users/ethan/coding/python/')True&gt;&gt;&gt; os.path.isdir('/Users/ethan/coding/python')True&gt;&gt;&gt; os.path.isdir('/Users/ethan/coding/python/hello.py')False （7）os.walk：遍历目录 os.walk 是遍历目录常用的模块，它返回一个包含 3 个元素的元祖：(dirpath, dirnames, filenames)。dirpath 是以 string 字符串形式返回该目录下所有的绝对路径；dirnames 是以列表 list 形式返回每一个绝对路径下的文件夹名字；filesnames 是以列表 list 形式返回该路径下所有文件名字。 1234567891011121314&gt;&gt;&gt; for root, dirs, files in os.walk('/Users/ethan/coding'):... print root... print dirs... print files.../Users/ethan/coding['python'][]/Users/ethan/coding/python['web2']['hello.py']/Users/ethan/coding/python/web2[][] 3、os模块打开文件 方法如下： os.open(filename, flag, [,mode]) flag参数说明： 12345678910111213141516file # 要打开的文件flags # 该参数可以是以下选项，多个使用 \"|\" 隔开：os.O_RDONLY # 以只读的方式打开os.O_WRONLY # 以只写的方式打开os.O_RDWR # 以读写的方式打开os.O_NONBLOCK # 打开时不阻塞os.O_APPEND # 以追加的方式打开os.O_CREAT # 创建并打开一个新文件os.O_TRUNC # 打开一个文件并截断它的长度为零（必须有写权限）os.O_EXCL # 如果指定的文件存在，返回错误os.O_SHLOCK # 自动获取共享锁os.O_EXLOCK # 自动获取独立锁os.O_DIRECT # 消除或减少缓存效果os.O_FSYNC # 同步写入os.O_NOFOLLOW# 不追踪软链接mode # 类似 chmod()。 4、os模块对文件进行操作 常用方法如下： 12345678# 读取文件os.read(fd, buffersize)# 写入文件os.write(fd, string)# 文件指针操作os.lseek(fd, pos, how)# 关闭文件os.close(fd) 代码演示： 文件创建和写入 123456789101112131415161718import os# 打开文件fd = os.open(\"abc.txt\", os.O_RDWR | os.O_CREAT)# 写入字符串str = \"Hello Python!\"ret = os.write(fd, bytes(str, 'UTF-8'))# 输入返回值print(\"写入的位数为: \")print(ret)print(\"写入成功\")# 关闭文件os.close(fd)print(\"关闭文件成功!!\") 输出结果如下： 1234写入的位数为: 13写入成功关闭文件成功!! 文件读取 123456789101112import os# 打开文件fd = os.open(\"abc.txt\", os.O_RDWR)# 读取文本ret = os.read(fd, 6)print(ret)# 关闭文件os.close(fd)print(\"关闭文件成功!!\") 输出结果如下： 12b'Hello '关闭文件成功!! 5、os模块管理文件和目录 常用方法如下： os方法 说明 remove(path) 删除文件 rename(old, new) 修改文件或者目录名 getcwd() 获取当前目录 listdir(path) 返回当前目录下所有文件组成的列表 mkdir(path [,mode]) 创建目录 makedirs(path [,mode]) 创建多级目录 rmdir(path) 删除目录（目录必须为空目录） removedirs(path) 删除多级目录（目录必须为空目录） 代码演示： 1234567891011121314# coding=utf-8import osprint(os.getcwd()) # pwdprint(os.listdir()) # lsos.rename('abc.txt','test.txt') # mv abc.txt test.txtos.remove('read.py') # rm -f abc.txtos.mkdir('test') # mkdir dir1os.makedirs('demo/abc') # mkdir -p dir2/dir22os.rmdir('test') # 目录必须为空os.removedirs('demo') #目录必须为空 6、os模块管理文件权限 os方法 说明 access(path, mode) 判断该文件权限：F_OK存在；权限：R_OK，W_OK，X_OK chmod(path, mode) 修改文件权限：0o755 chown(path, uid, gid) 更改文件所有者，如果不修改可以设置为 -1 代码演示： 123456789101112131415161718192021222324import os# 测试路径是否存在：os.F_OKres = os.access('test.txt',os.F_OK)print(res)# 测试当前用户对该文件是否有读的权限res = os.access('test.txt',os.R_OK)print(res)# 测试当前用户对该文件是否有写的权限res = os.access('test.txt',os.W_OK)print(res)# 测试当前用户对该文件是否有执行的权限res = os.access('test.txt',os.X_OK)print(res)# 更改当前用户的权限os.chmod('test.txt',0o755)# 更改文件的所有者os.chown('test.txt', 1001, 1002) 执行前提，确保需要文件存在。 7、os.path模块管理文件与路径 （1）拆分路径 os.path方法 说明 split 返回一个二元组，包含文件的路径和文件名 dirname 返回文件的路径 basename 返回文件名 splitext 返回一个去掉文件扩展名的部分和扩展名的二元组 代码演示： 12345678910111213141516171819In [10]: os.getcwd()Out[10]: '/opt/os_demo'In [11]: os.listdir()Out[11]: ['os_access.py', 'test.txt']In [12]: path = '/opt/os_demo/test.txt' In [13]: os.path.split(path)Out[13]: ('/opt/os_demo', 'test.txt')In [14]: os.path.dirname(path)Out[14]: '/opt/os_demo'In [15]: os.path.basename(path)Out[15]: 'test.txt'In [16]: os.path.splitext(path) Out[16]: ('/opt/os_demo/test', '.txt') （2）构建路径 os.path方法 说明 expanduser 展开用户的HOME目录，如~，~oracle abspath 得到文件或路径的绝对路径 join 根据不同的操作系统平台，使用不同的路径分隔符拼接路径 isabs 检查一个路径是不是一个绝对路径 代码演示： 1234567891011121314151617181920212223242526In [19]: os.path.expanduser('~') Out[19]: '/root'In [20]: os.path.expanduser('~oracle') Out[20]: '/home/oracle'In [21]: os.path.expanduser('~accp')Out[21]: '/home/accp'In [22]: os.path.expanduser('~acp') Out[22]: '~acp'In [23]: os.path.abspath('.')Out[23]: '/opt/os_demo'In [24]: os.path.abspath('..')Out[24]: '/opt'In [25]: os.path.join('/opt/os_demo','test.txt')Out[25]: '/opt/os_demo/test.txt'In [26]: os.path.isabs('/opt/os_demo/') Out[26]: TrueIn [27]: os.path.isabs('.') Out[27]: False （3）获取文件属性 os.path 方法 os.path.getmtime(path) 返回最近文件修改时间 os.path.getctime(path) 返回文件 path 创建时间 os.path.getsize(path) 返回文件大小，如果文件不存在就返回错误 代码演示： 1234567891011In [33]: os.path.getatime(path)Out[33]: 1587547270.7306058In [34]: os.path.getmtime(path)Out[34]: 1587547270.7306058In [35]: os.path.getctime(path)Out[35]: 1587548055.4721448In [36]: os.path.getsize(path)Out[36]: 0 （4）判断文件类型 os.path方法 说明 os.path.isfile(path) 判断路径是否为文件 os.path.isdir(path) 判断路径是否为目录 os.path.islink(path) 判断路径是否为链接 os.path.ismount(path) 判断路径是否为挂载点 代码演示： 1234567891011In [37]: os.path.isfile(path)Out[37]: TrueIn [38]: os.path.isdir(path)Out[38]: FalseIn [39]: os.path.islink(path)Out[39]: FalseIn [40]: os.path.ismount(path)Out[40]: False 8、os.walk遍历目录树 os.walk0方法遍历某个目录及其子目录，对于每一个目录，walk()函数返回一 个三元组(dirpath, dirnames.filenames)。其中dirpath保存的是 当前目录，dirnames是 当前目录下的子目录列表，filenames是 当前目录下的文件列表。 1234567# coding=utf-8import osfor root, dirs, files in os .walk(\".\", topdown=False):truefor name in files:truetrueprint (os.path.join(root, name))truefor name in dirs:truetrueprint (os.path.join(root, name)) （1）在Linux用ipython中把/opt目录遍历一下 12345678In [4]: for root, dirs, files in os .walk(\"/opt\"): ...: print(root) ...: print() ...: for name in files: ...: print(os.path.join(root,name)) ...: for dir in dirs: ...: print(os.path.join(root,dir)) ...: 输出结果如下： 1234/opt/opt/rh/opt/rh os.walk()方法是一个简单易用的文件、目录遍历器，可以帮助我们高效的处理文件、目录方面的事情. （2）打印最常用的10条Linux命令 步骤： 读取~/.bash_history文件内容 将读取到的内容格式化（去掉空行） 获取指令：索引为0的元素 指令使用次数进行累加 去除重复的数据 123456789101112[root@python opt]# vim find_cmd.py # coding=utf-8import osfrom collections import Countercount = Counter()with open(os.path.expanduser('~/.bash_history')) as f: for line in f: cmd = line.strip().split() if cmd: count[cmd[0]] += 1print(count.most_common(10)) 输出结果如下： 12[root@python opt]# python3 find_cmd.py [('ip', 8), ('cd', 8), ('systemctl', 7), ('ls', 6), ('vim', 5), ('ping', 3), ('tar', 3), ('vmware-install.pl', 3), ('rm', 3), ('sh', 2)]","path":"posts/b677.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python的pep8编码规范和代码调试","text":"一、python的pep8编码规范 通常会听别人提到PEP8，但是具体指什么内容呢?《Python Enhancement Proposal #8》 （8号python增强提案）又叫PEP8，它是针对python而编订的代码格式指南。 编程语言不是艺术，而是工作或者工具，所以整理并遵循一套编码规范十分必要。 1、每个缩进层级使用4个空格。 2、每行最多79个字符。 3、顶层的函数（def）或类（class）的定义之间空两行。 4、采用ASCII或UTF-8编码文件。（就是在里面表明编码格式，ASCII编码格式或者是UTF-8的编码格式） 5、在文件的顶端，注释和文档说明之下，每行每条import语句只导入一个模块， 同时要按标准库、第三方库和本地库的导入顺序进行分组。（标准库是下载python后就有的，也就是python自带的，要是需要下载，无论是pip还是其他，都是第三方库。而本地库就是自己创建的） 6、在小括号、中括号、大括号之间或者括号之前没有额外的空格 7、类(class)的命名采用驼峰命名法，如CamelCase；异常的定义使用Error前缀（如适用的话）；函数的命名采用下划线分隔的小写字母，如separateed_by_underscores;用下划线开头定义私有的属性或方法，如_private 自动检查代码标准的pep8工具 pep8会在哪里显示哪行哪里违反了pep8的，并为每个问题提供了其错误码，要是违反了那些必要的遵守规范，p便会爆出错误(以E开头的的错误码)，如果是细微的问题则会报警告(以W开头的 错误码)。跟在字母后面的3位数则是错误或者警告，可以从中看出大概的错误类别。例如以E2开 头的错误通常是与空格有关，以3开头的错误通常与空行有关，而以w6开头的警告则表明使用已 经废弃的功能。 1. 代码布局 1.1 缩进 每级缩进用4个空格 括号中使用垂直隐式缩进或悬挂缩进 不使用Tap，更不能混合使用Tap和空格 正确示范 123456789101112131415161718192021222324# (垂直隐式缩进)对准左括号起的第一个字符foo = long_function_name(var_one, var_two, var_three, var_four)# (悬挂缩进) 以行首字符为基准，缩进（一般情况只需一层缩进）foo = long_function_name( var_one, var_two, var_three, var_four)# (悬挂缩进) 但下面情况, 需再加多一层缩进，和函数体的语句块区分开def long_function_name( var_one, var_two, var_three, var_four): print(var_one)# 右括号回退my_list = [ 1, 2, 3, 4, 5, 6,]result = some_function_that_takes_arguments( 'a', 'b', 'c', 'd', 'e', 'f',)123456789101112131415161718192021222324 错误示范 1234567891011121314151617181920# 使用悬挂缩进时，第一行有参数。foo = long_function_name(var_one, var_two, var_three, var_four)# 参数的悬挂缩进和后续代码块缩进不能区别。def long_function_name( var_one, var_two, var_three, var_four): print(var_one)# 右括号不回退，不推荐my_list = [ 1, 2, 3, 4, 5, 6, ]result = some_function_that_takes_arguments( 'a', 'b', 'c', 'd', 'e', 'f', )1234567891011121314151617181920 1.2 最大行宽 每行最大行宽不超过 79 个字符 无括号续行，可使用反斜杠 括号内续行不需要使用反斜杠 12345678910111213141516# 无括号续行， 可使用反斜杠with open('/path/to/some/file/you/want/to/read') as file_1, \\ open('/path/to/some/file/being/written', 'w') as file_2: file_2.write(file_1.read())# 括号内续行，尽量在运算符后再续行class Rectangle(Blob): def __init__(self, width, height, color='black', emphasis=None, highlight=0): if (width == 0 and height == 0 and color == 'red' and emphasis == 'strong' or highlight &gt; 100): raise ValueError(\"sorry, you lose\") if width == 0 and height == 0 and (color == 'red' or emphasis is None): raise ValueError(\"I don't think so, values are %s,%s\"% (width, height))12345678910111213141516 1.3 空行 两行空行用于分割顶层函数和类的定义 单个空行用于分割类定义中的方法 函数内逻辑无关段落之间空一行；其他地方尽量不要再空行 虽然可以使用‘；’，但尽量不要把多个语句写在同一行 if/for/while语句中，即使执行语句只有一句，也必须另起一行 12345678910class A(object): # 类的方法定义用单个空行分割 def method1(): pass def method2(): passdef method3(): # 两行空行分割顶层函数和类的定义 pass12345678910 1.4 模块导入 导入的每个模块应该单独成行 导入顺序如下: 先标准库，再相关的第三方库，最后本地库。(导入不同类型的模块之间，要有空行分割，各组里面的模块顺序按首字母自上而下升序排列) 1234567891011# 正确示范import active # 按模块首字母排序导入, 依此递推import adidasimport create# 错误示范import sys, os, knife # 错误：一行导入多模块import create # 错误：不按模块首字母导入import activeimport beyond1234567891011 1.5 字符串 单引号和双引号作用是一样的，但必须保证成对存在，不能夹杂使用。 (建议句子使用双引号, 单词使用单引号, 但不强制。) 1234# 单引号和双引号效果一样name = 'JmilkFan'name = \"Hey Guys!\"1234 1.6 表达式和语句中的空格 括号里边避免空格 123spam(ham[1], &#123;eggs: 2&#125;) # 正确示范spam( ham[ 1 ], &#123; eggs: 2 &#125; ) # 错误示范123 逗号，冒号，分号之前避免空格 123if x == 4: print x, y; x, y = y, x # 正确示范if x == 4 : print x , y ; x , y = y , x # 错误示范123 函数调用的左括号之前不能有空格 12345spam(1)dct['key'] = lst[index] # 正确示范spam (1)dct ['key'] = lst [index] # 错误示范12345 赋值等操作符前后不能因为对齐而添加多个空格 1234567x = 1 # 正确示范y = 2long_variable = 3x = 1 # 错误示范y = 2long_variable = 31234567 二元运算符两边各放置一个空格 涉及 = 的复合操作符 ( += , -=等) 比较操作符 ( == , &lt; , &gt; , != , &lt;&gt; , &lt;= , &gt;= , in , not in , is , is not ) 逻辑操作符( and , or , not ) 12345a = ba or b# 括号内的操作符两边不需要空格name = get_name(age, sex=None, city=Beijing)12345 1.7 注释 总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是修改注释。 注释块 注释块通常应用在代码前，并和代码有同样的缩进。每行以 ‘# ’ 开头, 而且#后面有单个空格。段落之间以只有‘#’的行间隔 1234# Have to define the param `args(List)`, # otherwise will be capture the CLI option when execute `python manage.py server`.# oslo_config: (args if args is not None else sys.argv[1:])CONF(args=[], default_config_files=[CONFIG_FILE])1234 单行注释(这种方式尽量少使用) 1x = x + 1 # Compensate for border1 文档字符串 1234567# 多行文档, 首行首字母大写，结尾的 \"\"\" 应该单独成行\"\"\"Return a foobangOptional plotz says to frobnicate the bizbaz first.\"\"\"# 单行的文档， 结尾的 \"\"\" 在同一行。\"\"\"Return a foobang\"\"\"1234567 为共有的模块、函数、类、方法写docstrings；非共有的没有必要写docstrings，但是可以写注释（在def的下一行） 应避免无谓的注释 1.8 命名规则 包和模块名 包和模块名应该简短，全部用小写字母, 多字母之间可以使用单下划线连接。 类名 遵循驼峰命名。 12class MyClass(object): pass12 全局变量名 全局变量名应尽量只在模块内部使用, 对可能使用语句from moduleName import variableName而被导入的模块，应采用__all__机制来防止全局变量被别的模块导入, 或者在全局变量名开头加一个前置下划线。 1_name = 'name'1 函数名 函数名应该为全部小写的凹驼峰规则。 1vcenter_connection = ''1 常量名 常量全部使用大写字母的凹驼峰规则来表示, 通常在模块顶格定义。 12MAX_OVERFLOW = ''TOTAL = 112 方法名和实例变量 非公开方法和实例变量开头使用前置下划线 有时候可能会为了避免与子类命名冲突，采用两个前置下划线 需要注意的是: 若 class Foo 的属性名为 a， 该属性是不能以 Foo.a 的方式访问的(执著的用户还是可以通过Foo._Foo__a 来访问), 所以通常双前置下划线仅被用来避免与基类的属性发生命名冲突。 2. 编程建议 编码中应考虑到其他python实现的效率问题，比如运算符‘+’在CPython中效率很高，在Jython中却非常低 None 的比较用 is 或 is not，而不要用 ==；尽可能使用‘is’‘is not’取代‘==’；用 is not 代替 not … is, 前者的可读性更好 123456if foo is not None # Yesif not foo is None # No123if x is not None # if x is not None 要优于if xif x123 使用函数定义关键字 def 代替 lambda 赋值给标识符, 这样更适合于回调和字符串表示 1234def f(x): # Yes return 2*xf = lambda x: 2*x # No1234 异常类应该继承自Exception，而不是 BaseException；捕获异常时尽量指明具体异常, 尽量不用 except Exception；应该捕获出了什么问题，而不是问题发生 123456789try: # Yes (捕获具体异常) import platform_specific_module except ImportError: platform_specific_module = Nonetry: # No (不要全局捕获) import platform_specific_moduleexcept: platform_specific_module = None123456789 try/except 子句中的代码要尽可能的少, 以免屏蔽掉其他的错误 12345678910111213try: # Yes value = collection[key]except KeyError: return key_not_found(key)else: return handle_value(value)try: # No return handle_value(collection[key])except KeyError: # 可能会捕捉到handle_value()中的 KeyError, 而不是collection的 return key_not_found(key)12345678910111213 函数或者方法在没有返回值时要明确返回 None 12345def foo(): # Yes return Nonedef foo(): # No return12345 使用字符串方法而不是 string 模块 python 2.0 以后字符串方法总是更快，而且与 Unicode 字符串使用了相同的 API 使用使用 .startswith() 和 .endswith() 代替字符串切片来检查前缀和后缀 startswith() 和 endswith 更简洁，利于减少错误 123if foo.startswith('bar'): # Yesif foo[:3] == 'bar': # No123 使用 isinstance() 比较对象的类型 123if isinstance(obj, int): # Yesif type(obj) is type(1): # No123 判断序列空或不空 空序列类型对象的 bool 为 False: 123456789if not seq: # Yes passif seq: passif len(seq): # No passif not len(seq): pass123456789 不要使用 == 进行 bool 比较 123456789 # Yesif greeting: pass# Noif greeting == True passif greeting is True: # Worse pass123456789 字符串不要以空格收尾 二进制数据判断使用if boolvalue的方式 使用Map和Reduce，不要使用循环 二、pdb代码调试 程序能一次写完并正常运行的概率很小，基本不超过1%。总会有各种各样的bug需要修正。有的bug很简单，看看错误信息就知道，有的bug很复杂，我们需要知道出错时，哪些变量的值是正确的，哪些变量的值是错误的，因此，需要一整套调试程序的手段来修复bug。 安装ipdb库 1PS G:\\四期\\python&gt; pip install pdb G:\\四期\\python\\4\\1.py文件内容如下： 12345import pdbs = '0'n = int(s)pdb.set_trace()print(10/n) 调试一下 123PS G:\\四期\\python\\4&gt; python 2.py&gt; g:\\四期\\python\\4\\2.py(5)&lt;module&gt;()-&gt; print(10/n) 1、使用pdb进行调试： pdb 是 python 自带的一个包，为 python 程序提供了一种交互的源代码调试功能，主要特性包括设置断点、单步调试、进入函数调试、查看当前代码、查看栈片段、动态改变变量的值等。pdb 提供了一些常用的调试命令，详情见表 1。 pdb 常用命令 命令 解释 break 或 b 设置断点 设置断点 continue 或 c 继续执行程序 list 或 l 查看当前行的代码段 step 或 s 进入函数 return 或 r 执行代码直到从当前函数返回 exit 或 q 中止并退出 next 或 n 执行下一行 pp 打印变量的值 help 帮助 下面结合具体的实例讲述如何使用 pdb 进行调试。 2、测试代码示例 1234567import pdb a = \"aaa\"pdb.set_trace() b = \"bbb\"c = \"ccc\"final = a + b + c print final 开始调试：直接运行脚本，会停留在 pdb.set_trace() 处，选择 n+enter 可以执行当前的 statement。在第一次按下了 n+enter 之后可以直接按 enter 表示重复执行上一条 debug 命令。 （1）利用 pdb 调试 123456789101112131415161718192021222324[root@rcc-pok-idg-2255 ~]# python epdb1.py &gt; /root/epdb1.py(4)?() -&gt; b = \"bbb\" (Pdb) n &gt; /root/epdb1.py(5)?() -&gt; c = \"ccc\" (Pdb) &gt; /root/epdb1.py(6)?() -&gt; final = a + b + c (Pdb) list 1 import pdb 2 a = \"aaa\" 3 pdb.set_trace() 4 b = \"bbb\" 5 c = \"ccc\" 6 -&gt; final = a + b + c 7 print final [EOF] (Pdb) [EOF] (Pdb) n &gt; /root/epdb1.py(7)?() -&gt; print final (Pdb) 退出 debug：使用 quit 或者 q 可以退出当前的 debug，但是 quit 会以一种非常粗鲁的方式退出程序，其结果是直接 crash。 （2）退出 debug 1234567891011121314151617[root@rcc-pok-idg-2255 ~]# python epdb1.py &gt; /root/epdb1.py(4)?() -&gt; b = \"bbb\" (Pdb) n &gt; /root/epdb1.py(5)?() -&gt; c = \"ccc\" (Pdb) q Traceback (most recent call last): File \"epdb1.py\", line 5, in ? c = \"ccc\" File \"epdb1.py\", line 5, in ? c = \"ccc\" File \"/usr/lib64/python2.4/bdb.py\", line 48, in trace_dispatch return self.dispatch_line(frame) File \"/usr/lib64/python2.4/bdb.py\", line 67, in dispatch_line if self.quitting: raise BdbQuit bdb.BdbQuit 打印变量的值：如果需要在调试过程中打印变量的值，可以直接使用 p 加上变量名，但是需要注意的是打印仅仅在当前的 statement 已经被执行了之后才能看到具体的值，否则会报 NameError: &lt; exceptions.NameError … …&gt; 错误。 （3）debug 过程中打印变量 1234567891011121314151617181920212223[root@rcc-pok-idg-2255 ~]# python epdb1.py &gt; /root/epdb1.py(4)?() -&gt; b = \"bbb\" (Pdb) n &gt; /root/epdb1.py(5)?() -&gt; c = \"ccc\" (Pdb) p b 'bbb' (Pdb) 'bbb' (Pdb) n &gt; /root/epdb1.py(6)?() -&gt; final = a + b + c (Pdb) p c 'ccc' (Pdb) p final *** NameError: &lt;exceptions.NameError instance at 0x1551b710 &gt; (Pdb) n &gt; /root/epdb1.py(7)?() -&gt; print final (Pdb) p final 'aaabbbccc' (Pdb) 使用 c 可以停止当前的 debug 使程序继续执行。如果在下面的程序中继续有 set_statement() 的申明，则又会重新进入到 debug 的状态，读者可以在代码 print final 之前再加上 set_trace() 验证。 （4）停止 debug 继续执行程序 12345678[root@rcc-pok-idg-2255 ~]# python epdb1.py &gt; /root/epdb1.py(4)?() -&gt; b = \"bbb\" (Pdb) n &gt; /root/epdb1.py(5)?() -&gt; c = \"ccc\" (Pdb) c aaabbbccc 显示代码：在 debug 的时候不一定能记住当前的代码块，如要要查看具体的代码块，则可以通过使用 list 或者 l 命令显示。list 会用箭头 -&gt; 指向当前 debug 的语句。 （5）debug 过程中显示代码 12345678910111213141516171819202122232425[root@rcc-pok-idg-2255 ~]# python epdb1.py &gt; /root/epdb1.py(4)?() -&gt; b = \"bbb\" (Pdb) list 1 import pdb 2 a = \"aaa\" 3 pdb.set_trace() 4 -&gt; b = \"bbb\" 5 c = \"ccc\" 6 final = a + b + c 7 pdb.set_trace() 8 print final [EOF] (Pdb) c &gt; /root/epdb1.py(8)?() -&gt; print final (Pdb) list 3 pdb.set_trace() 4 b = \"bbb\" 5 c = \"ccc\" 6 final = a + b + c 7 pdb.set_trace() 8 -&gt; print final [EOF] (Pdb) 在使用函数的情况下进行 debug （6）使用函数的例子 1234567891011import pdb def combine(s1,s2): # define subroutine combine, which... s3 = s1 + s2 + s1 # sandwiches s2 between copies of s1, ... s3 = '\"' + s3 +'\"' # encloses it in double quotes,... return s3 # and returns it. a = \"aaa\" pdb.set_trace() b = \"bbb\" c = \"ccc\" final = combine(a,b) print final 如果直接使用 n 进行 debug 则到 final=combine(a,b) 这句的时候会将其当做普通的赋值语句处理，进入到 print final。如果想要对函数进行 debug 如何处理呢 ? 可以直接使用 s 进入函数块。函数里面的单步调试与上面的介绍类似。如果不想在函数里单步调试可以在断点处直接按 r 退出到调用的地方。 （8）对函数进行 debug 123456789101112131415161718192021222324252627282930313233343536373839404142[root@rcc-pok-idg-2255 ~]# python epdb2.py &gt; /root/epdb2.py(10)?() -&gt; b = \"bbb\" (Pdb) n &gt; /root/epdb2.py(11)?() -&gt; c = \"ccc\" (Pdb) n &gt; /root/epdb2.py(12)?() -&gt; final = combine(a,b) (Pdb) s --Call-- &gt; /root/epdb2.py(3)combine() -&gt; def combine(s1,s2): # define subroutine combine, which... (Pdb) n &gt; /root/epdb2.py(4)combine() -&gt; s3 = s1 + s2 + s1 # sandwiches s2 between copies of s1, ... (Pdb) list 1 import pdb 2 3 def combine(s1,s2): # define subroutine combine, which... 4 -&gt; s3 = s1 + s2 + s1 # sandwiches s2 between copies of s1, ... 5 s3 = '\"' + s3 +'\"' # encloses it in double quotes,... 6 return s3 # and returns it. 7 8 a = \"aaa\" 9 pdb.set_trace() 10 b = \"bbb\" 11 c = \"ccc\" (Pdb) n &gt; /root/epdb2.py(5)combine() -&gt; s3 = '\"' + s3 +'\"' # encloses it in double quotes,... (Pdb) n &gt; /root/epdb2.py(6)combine() -&gt; return s3 # and returns it. (Pdb) n --Return-- &gt; /root/epdb2.py(6)combine()-&gt;'\"aaabbbaaa\"' -&gt; return s3 # and returns it. (Pdb) n &gt; /root/epdb2.py(13)?() -&gt; print final (Pdb) 在调试的时候动态改变值 。在调试的时候可以动态改变变量的值，具体如下实例。需要注意的是下面有个错误，原因是 b 已经被赋值了，如果想重新改变 b 的赋值，则应该使用！ B。 （7）在调试的时候动态改变值 123456789[root@rcc-pok-idg-2255 ~]# python epdb2.py &gt; /root/epdb2.py(10)?() -&gt; b = \"bbb\" (Pdb) var = \"1234\" (Pdb) b = \"avfe\" *** The specified object '= \"avfe\"' is not a function or was not found along sys.path. (Pdb) !b=\"afdfd\" (Pdb) 补充 在命令行中进入调试模式的方法：python -m pdb demo.py 在调试模式中按一下Enter键表示执行一下上一条命令。 在ipython中使用PDB（体验更好）：%run -d demo.py 参考1 参考2","path":"posts/8e56.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"Python内置小工具","text":"一、1秒钟启动一个下载服务器 在实际工作中，时常会有这样的一个需求：将文件传给其他同事。将文件传给同事本身并不是一个很繁 琐的工作，现在的聊天工具一般都支持文件传输。但是，如果需要传送的文件较多，操作起来就会比较 麻烦。此外，如果文件在远程的服务器上，则需要先将远程服务器的文件下载到本地，然后再通过聊天 工具传给同事。再或者，你并不是特别清楚要传哪几个文件给同事，所以，你们需要进行交流，而交流 的时间成本是比较高的，会降低办事效率。 此时，如果你知道Python内置了一个下载服务器就能够显著提升效率了。例如，你的同事要让你传的文 件位于某一个目录下，那么，你可以进入这个目录，然后执行下面的命令启动一个下载服务器： 1python -m SimpleHTTPServer 在Python 3中，由于对系统库进行了重新整理，因此，使用方式会有不同： 1python -m http.server 执行上面的命令就会在当前目录下启动一个文件下载服务器，默认打开8000端口。完成以后，只需要将 IP和端口告诉同事，让同事自己去操作即可，非常方便高效。 使用浏览器访问Python启动的下载服务器，可以看到一个类似于FTP下载的界面，这个时候单击文件下 载即可。通过这种方式传输文件，可以降低大家的沟通成本，提高文件传输的效率。 上面使用的Python语句，从工作原理来说，仅仅是启动了一个Python内置的Web服务器。如果当前目 录下存在一个名为index.html的文件，则默认显示该文件的内容。如果当前目录下不存在这样一个文 件，则默认显示当前目录下的文件列表，也就是大家看到的下载服务器。 测试 进入cmd进入一个目录输入python -m http.server即可 ![image-20200420172014212](G:\\四期\\python\\python文档\\21 python工作环境管理.assets\\image-20200420172014212.png) 二、字符串转换为JSON JSON是一种轻量级的数据交换格式，易于人类阅读和编写，同时也易于机器解析和生成。由于JSON的 诸多优点，已被广泛使用在各个系统中。JSON使用越广泛，需要将JSON字符串转换为JSON对象的需求 就越频繁。 例如，在工作过程中，我们的系统会调用底层服务的API。底层服务的API一般都是以JSON的格式返 回，为了便于问题追踪，我们会将API返回的JSON转换为字符串记录到日志文件中。当需要分析问题 时，就需要将日志文件中的JSON字符串拿出来进行分析。这个时候，需要将一个JSON字符串转换为 JSON对象，以提高日志的可读性。 这个需求十分常见，以至于使用搜索引擎搜索&quot;JSON&quot;，处于搜索结果的第一项便是“在线JSON格式化工 具”。除了打开浏览器，使用在线JSON格式化工具以外，我们也可以使用命令行终端的Python解释器来 解析JSON串，如下所示： 123456[root@oracle ~]# echo '&#123;\"job\": \"developer\", \"name\": \"lmx\", \"sex\": \"male\"&#125;' | python -m json.tool &#123; true\"job\": \"developer\", \"name\": \"lmx\", \"sex\": \"male\" &#125; 使用命令行解释器解析JSON串非常方便，而且，为了便于阅读，该工具还会自动将转换的结果进行对齐和格式化。如下所示： 123456789[root@oracle ~]# echo '&#123;\"address\": &#123;\"province\": \"zhejiang\", \"city\": \"hangzhou\"&#125;, \"name\": \"lmx\", \"sex\": \"male\"&#125;' | python -m json.tool &#123; true\"address\": &#123; \"city\": \"hangzhou\", \"province\": \"zhejiang\" &#125;, \"name\": \"lmx\", \"sex\": \"male\"&#125; 三、检查第三方库是否正确安装 安装完Python的第三方库以后，如何确认这个库已经正确安装了呢？答案很简单，只需要尝试进行 import导入即可。如果导入没有任何错误，则认为安装成功；如果导入失败，则认为安装失败。 12345[root@python ~]# python Python 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. &gt;&gt;&gt; 验证Python的第三方库是否安装成功，本身也是一件很简单的事情，但是，如果我们使用脚本对大批量 的服务器进行自动部署，又应该如何验证第三方库安装成功了呢？肯定不能登录每一台服务器进行验 证。这个时候，我们可以使用Python解释器的-c参数快速地执行import语句，如下所示： 12345[root@python ~]# python -c \"import paramiko\" Traceback (most recent call last): File \"&lt;string&gt;\", line 1, in &lt;module&gt; ImportError: No module named paramiko [root@python ~]# 四、pip高级用法 为了便于用户安装和管理第三方库和软件，越来越多的编程语言拥有自己的包管理工具，如nodejs的 npm，ruby的gem。Python也不例外，现在Python生态主流的包管理工具是pip。 1、pip介绍 pip是一个用来安装和管理Python包的工具，是easy_install的替代品，如果读者使用的是Python 2.7.9+或Python 3.4+版本的Python，则已经内置了pip，无须安装直接使用即可。如果系统中没有安装 pip，也可以手动安装。 2、python3安装pip 方法1：python3安装完成后默认已经带有pip3 1234[root@python bin]# pip3 -V pip 19.2.3 from /usr/local/python38/lib/python3.8/site-packages/pip (python 3.8) [root@python bin]# pwd /usr/local/python38/bin [root@python bin]# 你可以用以下命令,创建软链接 1ln -s /usr/local/python38/bin/pip3 /usr/bin/pip 方法2：使用以下方法重新安装pip插件 下载get-pip.py脚本 1wget https://bootstrap.pypa.io/3.2/get-pip.py 运行脚本 1python3 get-pip.py python3创建pip3索引 1ln -s /usr/python3.6.1/bin/pip /usr/bin/pip3 测试是否安装成功 1pip3 install request pip之所以能够成为流行的包管理工具，并不是因为它被Python官方作为默认的包管理器，而是因为 它自身的诸多优点。pip的优点有： pip提供了丰富的功能，其竞争对手easy_install则只支持安装，没有提供卸载和显示已安装列表的功 能； pip能够很好地支持虚拟环境； pip可以通过requirements.txt集中管理依赖； pip能够处理二进制格式(.whl)； pip是先下载后安装，如果安装失败，也会清理干净，不会留下一个中间状态。 如果用户没有将软件打包上传到pypi.python.org，则无法使用pip进行安装。对于这种情况，Python生 态也有标准的做法，例如，我们尝试从源码安装paramiko。需要注意的是，我们也可以通过pip安装 paramiko的，这里只是为了演示Python生态中源码安装： 123$ git clone https://github.com/paramiko/paramiko.git $ cd paramiko $ python setup.py install 3、给pip3重命名 切换至家目录，通过.bashrc添加别名 12345[root@python bin]# cd ~ [root@python ~]# vim .bashrc alias pip=pip3 [root@python ~]# source .bashrc [root@python ~]# pip -V pip 19.2.3 from /usr/local/python38/lib/python3.8/site-packages/pip (python 3.8) 4、pip3常用命令 子命令 解释说明 install 安装软件包 download 下载软件包 uninstall 卸载安装包 freeze 按照requirements格式输出安装包，可以到其他服务器上执行pip install -r requirements.txt直接安装软件 list 列出当前系统中的安装包 show 查看安装包的信息，包括版本、依赖、许可证、作者、主页等信息 check 检查安装包依赖是否完整 search 查找安装包 wheel 打包软件到wheel格式 hash 计算安装包的hash值 completion 生成命令补全配置 help 获取pip和子命令的帮助信息 5、加速pip安装的技巧（linux） 如果大家使用Python的时间比较长的话，会发现Python安装的一个问题，即pypi.python.org不是特别 稳定，有时候会很慢，甚至处于完全不可用的状态。这个问题有什么好办法可以解决呢？根据笔者的经 验，至少有两种不同的方法。 （1）使用豆瓣或阿里云的源加速软件安装 访问pypi.python.org不稳定的主要原因是因为网络不稳定，如果我们从网络稳定的服务器下载安装 包，问题就迎刃而解了。我们国内目前有多个pypi镜像，推荐使用豆瓣的镜像源或阿里的镜像源。如果 要使用第三方的源，只需要在安装时，通过pip命令的-i选项指定镜像源即可。如下所示： 1pip install -i https://pypi.douban.com/simple/ flask 每次都要指定镜像源的地址比较麻烦，我们也可以修改pip的配置文件，将镜像源写入配置文件中。对 于Linux系统来说，需要创建～/.pip/pip.conf文件，然后在文件中保存如下内容： 1234567[root@python ~]# mkdir .pip [root@python ~]# cd .pip [root@python .pip]# touch pip.conf [root@python .pip]# vim pip.conf [global] index-url = https://pypi.douban.com/simple/ [root@python .pip]# （2）将软件下载到本地部署 如果需要对大批量的服务器安装软件包，并且安装包比较多或者比较大，则可以考虑将软件包下载到本 地，然后从本地安装。这对于使用脚本部署大量的服务器非常有用，此外，对于服务器无法连接外网的 情况，也可以使用这种方法。如下所示： 12345# 下载到本地 pip install --download='pwd' -r requirements.txt # 本地安装 pip install --no-index -f file://'pwd' -r requirements.txt 使用这种方式，只需要下载一次，就可以多处安装，不用担心网络不稳定的问题。并且，pip能够自动 处理软件依赖问题。例如，我们通过这种方式下载Flask到当前目录下，则Flask的依赖click、 itsdangerous、Jinja2、MarkupSafe和Werkzeug也会被下载到本地，如下所示： 123456pip install --download='pwd' flask $ ls click-6.7-py2.py3-none-any.whl itsdangerous-0.24.tar.gz MarkupSafe-0.23.tar.gz Flask-0.12-py2.py3-none-any.whl Jinja2-2.9.5-py2.py3-none-any.whl Werkzeug-0.11.15-py2.py3-none-any.whl 6、在windows环境下修改pip镜像源的方法(以python3.5为例) (1):在windows文件管理器中,输入 %APPDATA%`` (2):会定位到一个新的目录下，在该目录下新建pip文件夹，然后到pip文件夹里面去新建个pip.ini文件 (3):在新建的pip.ini文件中输入以下内容，搞定文件路径：“C:\\Users\\Administrator\\AppData\\Roaming\\pip\\pip.ini” 1234[global]timeout = 6000index-url = http://pypi.douban.com/simpletrusted-host = pypi.douban.com 设置完成测试：","path":"posts/ef11.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"pyenv的安装和简单使用","text":"Python工作环境管理 Python 2和Python 3之间存在着较大的差异，并且，由于各种原因导致了Python 2和Python 3的长期 共存。在实际工作过程中，我们可能会同时用到Python 2和Python 3，因此，需要经常在Python 2和 Python 3之间进行来回切换。此外，如果你是喜欢尝鲜的人，那么，你很有可能在Python新版本出来 的时候立即下载Python的版本，试验Python的特性。 在Python世界里，除了需要对Python的版本进行管理以外，还需要对不同的软件包进行管理。大部分 情况下，对于开源的库我们使用版本即可。但是，有时候可能需要对相同的Python版本，在不同的 项目中使用不同版本的软件包。 在这一节里，我们将介绍两个工具，即pyenv和virtualenv。前者用于管理不同的Python版本，后者用 于管理不同的工作环境。有了这两个工具，Python相关的版本问题将不再是问题。 1、问题情景: Python解释器版本混乱, 2和3差别巨大, 而且细分版本也不尽相同, 难以选择和管理. 不同Linux发行版自带Python不同, 如ubuntu16自带2.7和3.5版本, 其中系统许多组件依赖于自带解释器, 一旦删除或者更改都可能会造成系统出问题. 不同的Python解释器软件包管理也是问题, 如pip和ipython等必备包组件, 而且在项目开发中如何保证不同的包环境互不干扰也是一个问题. 那么有没有一个终极的解决办法能在管理不同解释器版本的同时控制不同的包环境呢? 有的, 就是pyenv. 2、使用pyenv管理不同的Python版本** 安装不同的Python版本并不是一件容易的事情，在不同的Python版本之间来回切换更加困难，而且， 多版本并存非常容易互相干扰。因此，我们需要一个名为pyenv的工具。pyenv是一个Python版本管理 工具，它能够进行全局的Python版本切换，也可以为单个项目提供对应的Python版本。使用pyenv以 后，可以在服务器上安装多个不同的Python版本，也可以安装不同的Python实现。不同Python版本之 间的切换也非常简单。接下来我们就一起看一下pyenv的安装和使用。 3、pyenv是什么? 能干什么? pyenv是一个forked自ruby社区的简单、低调、遵循UNIX哲学的Python环境管理工具, 它可以轻松切换全局解释器版本, 同时结合vitualenv插件可以方便的管理对应的包源. 我们知道, 在terminal中输入一个命令比如‘ls’时, shell会从当前环境的PATH中的各个目录里看是不是有ls这个可执行文件, 如果找到就执行, 否则就会报‘command no found’ 的错误, 同理, 只要控制PATH变量就能够做到python版本的切换, pyenv通过在PATH头部插入shims路径来实现对python版本的控制. pyenv和流行的pipenv、virtualenv的关系 pipenv是requests 作者 Kenneth Reitz大神写的一个python虚拟环境管理工具, 结合了pip和virtualenv的功能, 侧重点还是在包环境管理上, 使用思路是先创建一个指定python版本的环境, 然后在此环境上安装相应的包, 好评不错, 看到很多大牛都在推荐. virtualenv是一个比较传统成熟的虚拟环境管理工具了, 用的人也比较多, 思路也是创建虚拟环境, 然后安装相应的包, 要进入环境就source一下activate脚本激活一下, 尽管成熟, 但是我个人不太喜欢用, 在部署项目的时候老是容易出现一些环境问题. pyenv相对来说知名度就差很多了, 不过也很稳定, 这三个环境管理工具我都用过, 我个人更喜欢pyenv, 理由如下: 相对于其他两个工具, pyenv更侧重在python 解释器版本管理上, 比包管理更大一个层级, 使用pyenv我可以方便的下载指定版本的python解释器, pypy, anaconda等, 可以随时自由的在shell环境中本地、全局切换python解释器 开发的时候不需要限定某个版本的虚拟环境, 只需要在部署的时候用pyenv指定某个版本就好了 pyenv切换解释器版本的时候, pip和ipython以及对应的包环境都是一起切换的, 所以如果你要同时运行ipython2.x和ipython3.x多个解释器验证一些代码时就很方便 pyenv也可以创建好指定的虚拟环境, 但不需要指定具体目录, 自由度更高, 使用也简单 4、简单使用 123456789101112131415161718192021222324# 查看当前版本pyenv version# 查看所有版本pyenv versions# 查看所有可安装的版本pyenv install --list# 安装指定版本pyenv install 3.6.5# 安装新版本后rehash一下pyenv rehash# 删除指定版本pyenv uninstall 3.5.2# 指定全局版本pyenv global 3.6.5# 指定多个全局版本, 3版本优先pyenv global 3.6.5 2.7.14# 实际上当你切换版本后, 相应的pip和包仓库都是会自动切换过去的 一、pyenv安装 linux环境 版本 主机 环境 centos7.6 192.168.1.80 python3 1、安装git 1[root@python ~]# yum install git 2、开启终端 本文使用 bash 3、安装 pyenv *说明：本文的所有安装都严格遵守官方文档，与官方文档完全保持一致。* git 地址：https://github.com/pyenv/pyenv 在你的终端中执行如下命令，安全无毒，请放心食用： 首先把项目克隆下来，放在家目录下的隐藏文件夹中：.pyenv 1git clone https://github.com/pyenv/pyenv.git ~/.pyenv 然后配置环境变量 如果你使用 bash，就依次执行如下命令： 123echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.bashrcecho 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.bashrcecho -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\\n eval \"$(pyenv init -)\"\\nfi' &gt;&gt; ~/.bashrc 如果你使用 zsh，就依次执行如下命令： 123echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.zshrcecho 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.zshrcecho -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\\n eval \"$(pyenv init -)\"\\nfi' &gt;&gt; ~/.zshrc echo 命令的含义是：将引号中内容写入某文件中 请注意，以上的三条 echo 命令的最后一条长长的命令，请你保证它引号中的内容处于 ~/.bashrc 或者 ~/.zshrc 的最底部。 因为在 pyenv 初始化期间会操作 path 环境变量，导致不可预测的行为。 查看文件的底部内容，可以使用 tail 命令，用法：tail ~/.bashrc 或者 tail ~/.zshrc，编辑文件可以使用 vim 或者 vscode 最后，在使用 pyenv 之前，重新初始化 shell 环境，执行如下命令 1exec $SHELL 不执行该命令也是完全可以的，你可以关闭当前的终端窗口，重新启动一个就可以了。 此时，你已经完成了 pyenv 的安装了，你使用可以它的全部命令了，但是我建议你先别急着用，一口气装完 pyenv 的一个插件，那就是 pyenv-virtualenv 4、安装 pyenv-virtualenv **virtualenv本身是一个独立的项目，用以隔离不同项目的工作环境。例如，用户lmx希望在项目A中使用 Flask 0.8这个版本，与此同时，又想在项目B中使用Flask 0.9这个版本。如果我们全局安装Flask，必然 无法满足用户的需求。这个时候，我们就可以使用virtualenv。 ** 读者需要注意pyenv和virtualenv的区别。pyenv用以管理不同的Python版本，例如，你的系统工作时 使用Python 2.7.13，学习时使用Python 3.6.0。virtualenv用以隔离项目的工作环境，例如，项目A和 项目B都是使用Python 2.7.13，但是，项目A需要使用Flask 0.8版本，项目B需要使用Flask 0.9版本。我 们只要组合pyenv和virtualenv这两个工具，就能够构造Python和第三方库的任意版本组合，拥有很好 的灵活性，也避免了项目之间的相互干扰。 virtualenv本身是一个独立的工具，用户可以不使用pyenv而单独使用virtualenv。但是，如果你使用了 pyenv，就需要安装pyenv-virtualenv插件，而不是通过virtualenv软件使用virtualenv的功能。 git 地址：https://github.com/pyenv/pyenv-virtualenv (1) 把插件克隆在刚才已经安装完毕的 pyenv 的 plugins 文件夹中 1git clone https://github.com/pyenv/pyenv-virtualenv.git $(pyenv root)/plugins/pyenv-virtualenv (2) 然后配置环境变量 如果你使用 bash，就执行如下命令： 1echo 'eval \"$(pyenv virtualenv-init -)\"' &gt;&gt; ~/.bashrc 如果你使用 zsh，就执行如下命令： 1echo 'eval \"$(pyenv virtualenv-init -)\"' &gt;&gt; ~/.zshrc (3) 最后，在使用 pyenv 之前，重新初始化 shell 环境，执行如下命令 1exec $SHELL 不执行该命令也是完全可以的，你可以关闭当前的终端窗口，重新启动一个就可以了。 至此，pyenv就安装完成了，我们可以通过下面的命令验证pyenv是否正确安装并获取pyenv的帮助信息： 1234567891011121314151617181920212223242526272829[root@python ~]# pyenv --helpUsage: pyenv &lt;command&gt; [&lt;args&gt;]Some useful pyenv commands are: commands List all available pyenv commands exec Run an executable with the selected Python version global Set or show the global Python version(s) help Display help for a command hooks List hook scripts for a given pyenv command init Configure the shell environment for pyenv install Install a Python version using python-build local Set or show the local application-specific Python version(s) prefix Display prefix for a Python version rehash Rehash pyenv shims (run this after installing executables) root Display the root directory where versions and shims are kept shell Set or show the shell-specific Python version shims List existing pyenv shims uninstall Uninstall a specific Python version version Show the current Python version(s) and its origin --version Display the version of pyenv version-file Detect the file that sets the current pyenv version version-name Show the current Python version version-origin Explain how the current Python version is set versions List all Python versions available to pyenv whence List all Python versions that contain the given executable which Display the full path to an executableSee `pyenv help &lt;command&gt;' for information on a specific command.For full documentation, see: https://github.com/pyenv/pyenv#readme 二、使用 pyenv *此处仅仅展示 pyenv 和 virtualenv 的日常用法* 1、检查安装是否正确 检查 pyenv 的版本 12[root@python ~]# pyenv version(set by /root/.pyenv/version) 查看 pyenv 已经托管了哪些 python 版本 12[root@python ~]#pyenv versions* system (set by /root/.pyenv/version) 如果你看到了正常的版本信息，就说明可以了，如果看到了类似于 command not found 之类的，就说明安装失败了。 我们通过pyenv的install命令，可以查看pyenv当前支持哪些Python版本，如下所示： 123456789101112131415[root@python ~]# pyenv install --list Available versions:2.1.3……省略部分信息3.8.03.8-dev3.8.13.9-dev……省略部分信息anaconda3-2018.12anaconda3-2019.03anaconda3-2019.07anaconda3-2019.10……省略部分信息[root@python ~]# 2、pyenv切换python版本 **由于pyenv可以安装的Python版本列表非常长，所以，这里进行了省略。读者可以在自己电脑上安装 pyenv，然后执行pyenv install --list命令进行查看。可以看到，pyenv不但可以安装不同的Python版 本，而且还可以安装不同的Python实现，也可以安装版本的Python用以学习。 ** 查看当前系统中包含的Python版本： 12[root@python ~]# pyenv versions * system (set by /root/.pyenv/version) 使用pyenv安装不同的Python版本： 12[root@python ~]#pyenv install -v 3.8.1 [root@python ~]#pyenv install -v 2.7.13 再次查看当前系统中包含的Python版本 1234[root@python ~]# pyenv versions* system (set by /root/.pyenv/version) 2.7.13 3.8.1 切换版本 12345678910111213#切换前为3.8.1[root@python ~]# pythonPython 3.8.1 (default, Apr 20 2020, 15:00:10) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; exit()#切换为2.7.13[root@python ~]# pyenv global 2.7.13 [root@python ~]# pythonPython 2.7.13 (default, Apr 20 2020, 15:04:15) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux2Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. 使用pyenv以后，可以快速切换Python的版本。切换Python版本以后，与版本相关的依赖也会一起切 换。因此，我们不用担心不同的版本在系统中是否会相互干扰。例如，切换Python版本以后，相应的 pip也会跟着切换，所以不用担心自己使用的pip版本和Python版本不匹配的问题，如下所示： 123[root@python ~]# pyenv global 3.8.1[root@python ~]# pip --versionpip 19.2.3 from /root/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pip (python 3.8) 如果想要删除Python版本，使用uninstall命令即可。如下所示： 1[root@python ~]# pyenv uninstall 2.7.10 三、pyenv-virtualenv的使用 有了pyenv-virtualenv以后，我们可以为同一个Python解释器，创建多个不同的工作环境。例如，我们 新建两个工作环境： 12[root@python ~]# pyenv virtualenv 3.8.1 first_project [root@python ~]# pyenv virtualenv 3.8.1 second_projec 可以使用virtualenvs子命令查看工作环境 12345[root@python ~]# pyenv virtualenvs 3.8.1/envs/first_project (created from /root/.pyenv/versions/3.8.1) 3.8.1/envs/second_projec (created from /root/.pyenv/versions/3.8.1) first_project (created from /root/.pyenv/versions/3.8.1) second_projec (created from /root/.pyenv/versions/3.8.1) 创建完工作环境以后，可以通过activate和deactivate子命令进入或退出一个工作环境。进入工作环境 以后，左边的提示符会显示你当前所在的工作环境，以免因为环境太多导致操作错误。 123456789101112131415161718(first_project) [root@python ~]# pip install flask==1.1.1 Looking in indexes: https://pypi.doubanio.com/simpleCollecting flask==1.1.1 Downloading https://pypi.doubanio.com/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB) |███▌ | 10kB 28.0MB/s eta 0:00: |███████ | 20kB 1.8MB/s eta 0:00:0 |██████████▍ | 30kB 2.7MB/s eta 0:00:0 |█████████████▉ | 40kB 1.8MB/s eta 0:00:0 |█████████████████▍ | 51kB 1.3MB/s eta 0:00:0 |████████████████████▉ | 61kB 1.5MB/s eta 0:00:0 |████████████████████████▎ | 71kB 1.4MB/s eta 0:00:0 |███████████████████████████▊ | 81kB 1.3MB/s eta 0:00:0 |███████████████████████████████▏| 92kB 1.4MB/s eta 0:00:0 |████████████████████████████████| 102kB 1.6MB/s Collecting itsdangerous&gt;=0.24 (from flask==1.1.1)(first_project) [root@python ~]# pyenv deactivate##退出first_project环境[root@python ~]# 接下来，我们看一下在不同的工作环境安装不同的Flask版本 123456789101112131415[root@python ~]# pyenv activate first_project ##切换工作环境(first_project) [root@python ~]# pip install flask==1.1.1 ##安装1.1.1的flask(first_project) [root@python ~]# pyenv deactivate ##退出目前工作环境[root@python ~]#[root@python ~]# pyenv activate second_projec##切换工作环境(second_project) [root@python ~]# pip install flask==0.10.1##安装0.10.1的flask(second_project) [root@python ~]# pyenv deactivate ##退出目前工作环境[root@python ~]# 查看一下两个工作环境源目录 如果想要删除虚拟环境，则使用： 1(first_project) [root@python ~]# pyenv virtualenv-delete first_project 使用pyenv和python-virtualenv插件，我们就能够自由地在不同的版本之间进行切换，相比管理Python 版本，不但节省了时间，也避免了工作过程中的相互干扰。 三、更新 pyenv 由于我们是 git 克隆的，所以更新非常简单 12cd ~/.pyenv` 或者 `cd $(pyenv root)` `git pull 四、卸载 pyenv 由于 pyenv 把一切都放在 ~/.pyenv 下了，所以卸载很方便，两个步骤就行了 首先你需要删除环境变量 然后你需要执行： 1rm -rf ~/.pyenv` 或者 `rm -rf $(pyenv root)","path":"posts/16bd.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"Python3+Django3开发简单的人员管理系统","text":"1、使用PyCharm创建Django项目 记得安装mysqlclient (1)数据库配置 我们在项目的 settings.py 文件中找到 DATABASES 配置项，将其信息修改为： 12345678910DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', # 或者使用 mysql.connector.django 'NAME': 'userinfo', 'USER': 'root', 'PASSWORD': '123456', 'HOST': 'localhost', 'PORT': '3306', &#125;&#125; 这里添加了中文注释，所以你需要在 HelloWorld/settings.py 文件头部添加 # -*- coding: UTF-8 -*-。 上面包含数据库名称和用户的信息，它们与 MySQL 中对应数据库和用户的设置相同。Django 根据这一设置，与 MySQL 中相应的数据库和用户连接起来。 (2)更改语言、时区 和 所有主机都可访问 我们在项目的 settings.py 文件中找到ALLOWED_HOSTS、LANGUAGE_CODE和TIME_ZONE配置项，将其信息修改为： 1234567ALLOWED_HOSTS = ['*']# LANGUAGE_CODE = 'en-us'LANGUAGE_CODE = 'zh-Hans'# TIME_ZONE = 'UTC'TIME_ZONE = 'Asia/Shanghai' (3)修改 TestModel/models.py 文件： 123456789101112from django.db import models# Create your models hereclass User(models.Model): GENDER_CHOICES = ( ('男','男'), ('女','女'), ) name = models.CharField(max_length=20, verbose_name='姓名', unique=True) birthday = models.DateTimeField(max_length=10,verbose_name='生日', null=True,blank=True) gender = models.CharField(max_length=30, choices=GENDER_CHOICES, verbose_name='性别') account = models.IntegerField(default=0,verbose_name='工号') age = models.IntegerField(default=18, verbose_name='年龄') 以上的类名代表了数据库表名，且继承了models.Model，类里面的字段代表数据表中的字段(name)，数据类型则由CharField（相当于varchar）、DateField（相当于datetime）， max_length 参数限定长度。 (4)创建数据库 记得在数据库创建UserInfo数据库 &lt;1&gt;可在cmd命令行中创建数据库 12345G:\\四期\\python\\UserSystem&gt;mysql -uroot -p #登陆数据库mysql&gt; CREATE DATABASE xgp DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;#创建utf8的数据库 &lt;2&gt;mysql管理器中创建数据库 (5)创建表结构 123456$ python manage.py migrate # 创建表结构//失败了可用python manage.py migrate UserInfo//失败了可用python3 manage.py migrate UserInfo$ python manage.py makemigrations UserInfo # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate UserInfo # 创建表结构 数据库生成以下表： (6)访问一下 记得启动项目 2、Django Admin 管理工具 Django 提供了基于 web 的管理工具。 Django 自动管理工具是 django.contrib 的一部分。你可以在项目的 settings.py 中的 INSTALLED_APPS 看到它： 12345678910#/HelloWorld/HelloWorld/settings.py 文件代码：INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'UserInfo.apps.UserinfoConfig',] django.contrib是一套庞大的功能集，它是Django基本代码的组成部分。 （1）激活管理工具 通常我们在生成项目时会在 urls.py 中自动设置好，我们只需去掉注释即可。 配置项如下所示： 1234567#/HelloWorld/HelloWorld/urls.py 文件代码：from django.contrib import adminfrom django.urls import pathurlpatterns = [ path('admin/', admin.site.urls),] 当这一切都配置好后，Django 管理工具就可以运行了。 （2）使用管理工具 启动开发服务器，然后在浏览器中访问 http://127.0.0.1:8000/admin/，得到如下界面： 因为我现在是新建了个项目所以需要创建表结构： 12345$ python manage.py migrate UserInfo # 创建表结构，指定数据库//失败了可用python3 manage.py migrate$ python manage.py makemigrations UserInfo # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate UserInfo # 创建表结构 你可以通过命令 python manage.py createsuperuser 来创建超级用户，如下所示： 123456# python manage.py createsuperuserUsername (leave blank to use 'root'): adminEmail address: admin@runoob.comPassword:Password (again):Superuser created successfully. 之后输入用户名密码登录，界面如下： （3）为了让 admin 界面管理某个数据模型，我们需要先注册该数据模型到 admin。 123456789101112from django.contrib import adminfrom . models import Userclass HostAdmin(admin.ModelAdmin): list_display = [ 'name', 'birthday', 'gender', 'account', 'age', ] search_fields = ('name',)admin.site.register(User,HostAdmin)admin.AdminSite.site_header = '运维系统管理后台'admin.AdminSite.site_title = '运维系统' 浏览器访问一下 设置两个员工信息并查看一下 userinfo数据库的userinfo_user表会保存员工信息：","path":"posts/68e5.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"PyCharm实现（Django的模型、表单、管理工具、引入静态文件）","text":"1234567镜像列表http://mirrors.aliyun.com/pypi/simple/ //阿里https://pypi.tuna.tsinghua.edu.cn/simple/ //清华http://pypi.douban.com/ //豆瓣http://pypi.hustunique.com/ //华中理工大学http://pypi.sdutlinux.org/ //山东理工大学http://pypi.mirrors.ustc.edu.cn/ //中国科学技术大学 一、Django 模型（PyCharm实现） Django 对各种数据库提供了很好的支持，包括：PostgreSQL、MySQL、SQLite、Oracle。 Django 为这些数据库提供了统一的调用API。 我们可以根据自己业务需求选择不同的数据库。 MySQL 是 Web 应用中最常用的数据库。本章节我们将以 Mysql 作为实例进行介绍。你可以通过本站的 MySQL 教程 了解更多Mysql的基础知识。 如果你没安装 mysql 驱动，可以执行以下命令安装： 12sudo pip install mysqlclient #较慢pip install -i https://pypi.douban.com/simple/ mysqlclient #较快 1、PyCharm创建Django 2、数据库配置 我们在项目的 settings.py 文件中找到 DATABASES 配置项，将其信息修改为： 12345678910DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', # 或者使用 mysql.connector.django 'NAME': 'test', 'USER': 'root', 'PASSWORD': '123456', 'HOST':'localhost', 'PORT':'3306', &#125;&#125; 这里添加了中文注释，所以你需要在 HelloWorld/settings.py 文件头部添加 # -*- coding: UTF-8 -*-。 上面包含数据库名称和用户的信息，它们与 MySQL 中对应数据库和用户的设置相同。Django 根据这一设置，与 MySQL 中相应的数据库和用户连接起来。 3、定义模型 创建 APP Django规定，如果要使用模型，必须要创建一个app。我们使用以下命令创建一个 TestModel 的 app: 1django-admin startapp TestModel 目录结构如下： 1234567HelloWorld|-- TestModel| |-- __init__.py| |-- admin.py| |-- models.py| |-- tests.py| `-- views.py 我们修改 TestModel/models.py 文件，代码如下： 12345# models.pyfrom django.db import models class Test(models.Model): name = models.CharField(max_length=20) 以上的类名代表了数据库表名，且继承了models.Model，类里面的字段代表数据表中的字段(name)，数据类型则由CharField（相当于varchar）、DateField（相当于datetime）， max_length 参数限定长度。 接下来在settings.py中找到INSTALLED_APPS这一项，如下： 123456789INSTALLED_APPS = ( 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'TestModel', # 添加此项) 在命令行中运行： 12345$ python manage.py migrate # 创建表结构//失败了可用python3 manage.py migrate$ python manage.py makemigrations TestModel # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate TestModel # 创建表结构 看到几行 “Creating table…” 的字样，你的数据表就创建好了。 创建好了之后可在Navicat for MySQL查看到： 1234Creating tables ...……Creating table TestModel_test #我们自定义的表…… 表名组成结构为：应用名_类名（如：TestModel_test）。 注意：尽管我们没有在models给表设置主键，但是Django会自动添加一个id作为主键。 4、数据库操作 接下来我们在 HelloWorld 目录中添加 testdb.py 文件（下面介绍），并修改 urls.py： 12345678from django.contrib import adminfrom django.urls import pathfrom . import testdburlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb),] 添加数据 添加数据需要先创建对象，然后再执行 save 函数，相当于SQL中的INSERT： 123456789101112#HelloWorld/HelloWorld/testdb.py文件代码# -*- coding: utf-8 -*- from django.http import HttpResponse from TestModel.models import Test # 数据库操作def testdb(request): test1 = Test(name='runoob') test1.save() return HttpResponse(\"&lt;p&gt;数据添加成功！&lt;/p&gt;\") 访问 http://127.0.0.1:8000/testdb 就可以看到数据添加成功的提示。 输出结果如下： 数据库可看到： 当浏览器每刷新一下，数据库里的信息就会增加一条。 二、重新创建一个Django 要提前把数据库里创建的表删除 创建好之后运行一下这个项目 会自动跳到浏览器 1、如果你是按上面继续做的，需要以下步骤： （还原为，原始状态） 删除test的表文件 删除之前创建的XGPtest/XGPtest/testdb.py文件 XGPtest/TestModel/models.py文件内容删除 注释XGPtest/XGPtest/urls.py中关于testdb的内容 然后重新启动 浏览器访问http://127.0.0.1:8000/会和之前的界面一样，有个小火箭！ 删除XGPtest/TestModel/migrations/0001_initial.py文件 2、重新生成表单 12345$ python manage.py migrate # 创建表结构//失败了可用python3 manage.py migrate$ python manage.py makemigrations TestModel # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate TestModel # 创建表结构 3、models.py文件添加类型 12345#XGPtest/TestModel/models.pyfrom django.db import models class Test(models.Model): name = models.CharField(max_length=20) 创建完成之后，数据库中就生成testmodel_test表 4、XGPtest/XGPtest/urls.py中关于testdb的内容，解除注释 12345678from django.contrib import adminfrom django.urls import pathfrom . import testdburlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb),] 3、创建XGPtest/XGPtest/testdb.py测试文件 123456789101112# -*- coding: utf-8 -*-from django.http import HttpResponsefrom TestModel.models import Test# 数据库操作def testdb(request): test1 = Test(name='runoob') test1.save() return HttpResponse(\"&lt;p&gt;数据添加成功！&lt;/p&gt;\") 4、获取数据 首先多访问几次http://127.0.0.1:8000/testdb生成数据 数据库更改一下其中内容（随意编写） Django提供了多种方式来获取数据库的内容，如下代码所示： 1234567891011121314151617181920212223242526272829#XGPtest/XGPtest/testdb.py#XGPtest/XGPtest/testdb.py 文件尾部添加def getdb(request): # 初始化 response = \"\" response1 = \"\" # 通过objects这个模型管理器的all()获得所有数据行，相当于SQL中的SELECT * FROM list = Test.objects.all() # filter相当于SQL中的WHERE，可设置条件过滤结果 response2 = Test.objects.filter(id=1) # 获取单个对象 response3 = Test.objects.get(id=1) # 限制返回的数据 相当于 SQL 中的 OFFSET 0 LIMIT 2; # Test.objects.order_by('name')[0:2] # 数据排序 Test.objects.order_by(\"id\") # 上面的方法可以连锁使用 Test.objects.filter(name=\"runoob\").order_by(\"id\") # 输出所有数据 for var in list: response1 += var.name + \" \" response = response1 return HttpResponse(\"&lt;p&gt;\" + response + \"&lt;/p&gt;\") XGPtest/XGPtest/urls.py文件添加 123456789from django.contrib import adminfrom django.urls import pathfrom . import testdburlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb), path('gitdb/', testdb.gitdb), #添加] 浏览器访问https://www.runoob.com/django/django-model.html 5、更新数据 修改数据可以使用 save() 或 update(): 1234567891011121314#XGPtest/XGPtest/testdb.py#XGPtest/XGPtest/testdb.py 文件尾部添加def modify(request): # 修改其中一个id=1的name字段，再save，相当于SQL中的UPDATE test1 = Test.objects.get(id=1) test1.name = 'Google' test1.save() # 另外一种方式 #Test.objects.filter(id=1).update(name='Google') # 修改所有的列 # Test.objects.all().update(name='Google') return HttpResponse(\"&lt;p&gt;修改成功&lt;/p&gt;\") XGPtest/XGPtest/urls.py文件添加 12345678910from django.contrib import adminfrom django.urls import pathfrom . import testdburlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb), path('gitdb/', testdb.gitdb), #添加 path('modify/', testdb.modify), ] 浏览器访问http://127.0.0.1:8000/modify/ 查看test数据库testmodel_test表 6、删除数据 删除数据库中的对象只需调用该对象的delete()方法即可： 12345678910111213#XGPtest/XGPtest/testdb.py#XGPtest/XGPtest/testdb.py 文件尾部添加def del(request): # 删除id=1的数据 test1 = Test.objects.get(id=1) test1.delete() # 另外一种方式 # Test.objects.filter(id=1).delete() # 删除所有数据 # Test.objects.all().delete() return HttpResponse(\"&lt;p&gt;删除成功&lt;/p&gt;\") XGPtest/XGPtest/urls.py文件添加 1234567891011from django.contrib import adminfrom django.urls import pathfrom . import testdburlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb), path('gitdb/', testdb.gitdb), #添加 path('modify/', testdb.modify), path('del/', testdb.del),] 浏览器访问http://127.0.0.1:8000/del 数据库查看第一个数据是否删除 三、Django 表单 HTML表单是网站交互性的经典方式。 本章将介绍如何用Django对用户提交的表单数据进行处理。 1、HTTP 请求 HTTP协议以&quot;请求－回复&quot;的方式工作。客户发送请求时，可以在请求中附加数据。服务器通过解析请求，就可以获得客户传来的数据，并根据URL来提供特定的服务。 2、GET 方法 我们在之前的项目中创建一个 search.py 文件，用于接收用户的请求： 1234567891011121314151617181920#/HelloWorld/HelloWorld/search.py 文件代码：# -*- coding: utf-8 -*-from django.http import HttpResponsefrom django.shortcuts import render# 表单def search_form(request): return render(request,'search_form.html',&#123;&#125;)# 接收请求数据def search(request): request.encoding = 'utf-8' if 'q' in request.GET and request.GET['q']: message = '你搜索的内容为: ' + request.GET['q'] else: message = '你提交了空表单' return HttpResponse(message) 在模板目录 templates 中添加 search_form.html 表单： 1234567891011121314#/HelloWorld/templates/search_form.html 文件代码：&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;xgp666&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=\"/search\" method=\"get\"&gt; &lt;input type=\"text\" name=\"q\"&gt; &lt;input type=\"submit\" value=\"搜索\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 可在浏览器打开是一个搜索框 urls.py 规则修改为如下形式： 123456789101112131415#/HelloWorld/HelloWorld/urls.py 文件代码：from django.contrib import adminfrom django.urls import pathfrom . import testdbfrom . import searchurlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb), path('gitdb/', testdb.getdb), path('modify/', testdb.modify), path('del/', testdb.dl), path('search/', search.search), path('search-from/', search.search_form),] 访问地址 http://127.0.0.1:8000/search-form 并搜索，结果如下所示: 分析一下 3、POST 方法 上面我们使用了GET方法。视图显示和请求处理分成两个函数处理。 提交数据时更常用POST方法。我们下面使用该方法，并用一个URL和处理函数，同时显示视图和处理请求。 我们在 templates 创建 post.html： 1234567891011121314151617#/HelloWorld/templates/post.html 文件代码：&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;&lt;title&gt;xgp666&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"/search-post/\" method=\"post\"&gt; &#123;% csrf_token %&#125; &lt;input type=\"text\" name=\"q\"&gt; &lt;input type=\"submit\" value=\"Submit\"&gt; &lt;/form&gt; &lt;p&gt;&#123;&#123; rlt &#125;&#125;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 在模板的末尾，我们增加一个 rlt 记号，为表格处理结果预留位置。 表格后面还有一个{% csrf_token %}的标签。csrf 全称是 Cross Site Request Forgery。这是Django提供的防止伪装提交请求的功能。POST 方法提交的表格，必须有此标签。 在HelloWorld目录下新建 search2.py 文件并使用 search_post 函数来处理 POST 请求： 123456789101112#/HelloWorld/HelloWorld/search2.py 文件代码：# -*- coding: utf-8 -*- from django.shortcuts import renderfrom django.views.decorators import csrf # 接收POST请求数据def search_post(request): ctx =&#123;&#125; if request.POST: ctx['rlt'] = request.POST['q'] return render(request, \"post.html\", ctx) urls.py 规则修改为如下形式： 1234567891011121314151617#/HelloWorld/HelloWorld/urls.py 文件代码：from django.contrib import adminfrom django.urls import pathfrom . import testdbfrom . import searchfrom . import search2urlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb), path('gitdb/', testdb.getdb), path('modify/', testdb.modify), path('del/', testdb.dl), path('search/', search.search), path('search-from/', search.search_form), path('search-post/', search2.search_post),] 访问 http://127.0.0.1:8000/search-post 显示结果如下： 3、Request 对象 每个 view 函数的第一个参数是一个 HttpRequest 对象，就像下面这个 hello() 函数: 1234from django.http import HttpResponsedef hello(request): return HttpResponse(\"Hello world\") HttpRequest对象包含当前请求URL的一些信息： 属性 描述 path 请求页面的全路径,不包括域名—例如, “/hello/”。 method 请求中使用的HTTP方法的字符串表示。全大写表示。例如:if request.method == ‘GET’: do_something() elif request.method == ‘POST’: do_something_else() GET 包含所有HTTP GET参数的类字典对象。参见QueryDict 文档。 POST 包含所有HTTP POST参数的类字典对象。参见QueryDict 文档。服务器收到空的POST请求的情况也是有可能发生的。也就是说，表单form通过HTTP POST方法提交请求，但是表单中可以没有数据。因此，不能使用语句if request.POST来判断是否使用HTTP POST方法；应该使用if request.method == “POST” (参见本表的method属性)。注意: POST不包括file-upload信息。参见FILES属性。 REQUEST 为了方便，该属性是POST和GET属性的集合体，但是有特殊性，先查找POST属性，然后再查找GET属性。借鉴PHP’s $_REQUEST。例如，如果GET = {“name”: “john”} 和POST = {“age”: ‘34’},则 REQUEST[“name”] 的值是&quot;john&quot;, REQUEST[“age”]的值是&quot;34&quot;.强烈建议使用GET and POST,因为这两个属性更加显式化，写出的代码也更易理解。 COOKIES 包含所有cookies的标准Python字典对象。Keys和values都是字符串。 FILES 包含所有上传文件的类字典对象。FILES中的每个Key都是标签中name属性的值. FILES中的每个value 同时也是一个标准Python字典对象，包含下面三个Keys:filename: 上传文件名,用Python字符串表示content-type: 上传文件的Content typecontent: 上传文件的原始内容注意：只有在请求方法是POST，并且请求页面中有enctype=&quot;multipart/form-data&quot;属性时FILES才拥有数据。否则，FILES 是一个空字典。 META 包含所有可用HTTP头部信息的字典。 例如:CONTENT_LENGTHCONTENT_TYPEQUERY_STRING: 未解析的原始查询字符串REMOTE_ADDR: 客户端IP地址REMOTE_HOST: 客户端主机名SERVER_NAME: 服务器主机名SERVER_PORT: 服务器端口META 中这些头加上前缀 HTTP_ 为 Key, 冒号(:)后面的为 Value， 例如:HTTP_ACCEPT_ENCODINGHTTP_ACCEPT_LANGUAGEHTTP_HOST: 客户发送的HTTP主机头信息HTTP_REFERER: referring页HTTP_USER_AGENT: 客户端的user-agent字符串HTTP_X_BENDER: X-Bender头信息 user 是一个django.contrib.auth.models.User 对象，代表当前登录的用户。如果访问用户当前没有登录，user将被初始化为django.contrib.auth.models.AnonymousUser的实例。你可以通过user的is_authenticated()方法来辨别用户是否登录：if request.user.is_authenticated(): # Do something for logged-in users. else: # Do something for anonymous users.只有激活Django中的AuthenticationMiddleware时该属性才可用 session 唯一可读写的属性，代表当前会话的字典对象。只有激活Django中的session支持时该属性才可用。 raw_post_data 原始HTTP POST数据，未解析过。 高级处理时会有用处。 Request对象也有一些有用的方法： 方法 描述 getitem(key) 返回GET/POST的键值,先取POST,后取GET。如果键不存在抛出 KeyError。 这是我们可以使用字典语法访问HttpRequest对象。 例如,request[“foo”]等同于先request.POST[“foo”] 然后 request.GET[“foo”]的操作。 has_key() 检查request.GET or request.POST中是否包含参数指定的Key。 get_full_path() 返回包含查询字符串的请求路径。例如， &quot;/music/bands/the_beatles/?print=true&quot; is_secure() 如果请求是安全的，返回True，就是说，发出的是HTTPS请求。 4、QueryDict对象 在HttpRequest对象中, GET和POST属性是django.http.QueryDict类的实例。 QueryDict类似字典的自定义类，用来处理单键对应多值的情况。 QueryDict实现所有标准的词典方法。还包括一些特有的方法： 方法 描述 getitem 和标准字典的处理有一点不同，就是，如果Key对应多个Value，getitem()返回最后一个value。 setitem 设置参数指定key的value列表(一个Python list)。注意：它只能在一个mutable QueryDict 对象上被调用(就是通过copy()产生的一个QueryDict对象的拷贝). get() 如果key对应多个value，get()返回最后一个value。 update() 参数可以是QueryDict，也可以是标准字典。和标准字典的update方法不同，该方法添加字典 items，而不是替换它们:&gt;&gt;&gt; q = QueryDict('a=1') &gt;&gt;&gt; q = q.copy() # to make it mutable &gt;&gt;&gt; q.update({'a': '2'}) &gt;&gt;&gt; q.getlist('a') ['1', '2'] &gt;&gt;&gt; q['a'] # returns the last ['2'] items() 和标准字典的items()方法有一点不同,该方法使用单值逻辑的getitem():&gt;&gt;&gt; q = QueryDict('a=1&amp;a=2&amp;a=3') &gt;&gt;&gt; q.items() [('a', '3')] values() 和标准字典的values()方法有一点不同,该方法使用单值逻辑的getitem(): 此外, QueryDict也有一些方法，如下表： 方法 描述 copy() 返回对象的拷贝，内部实现是用Python标准库的copy.deepcopy()。该拷贝是mutable(可更改的) — 就是说，可以更改该拷贝的值。 getlist(key) 返回和参数key对应的所有值，作为一个Python list返回。如果key不存在，则返回空list。 It’s guaranteed to return a list of some sort… setlist(key,list_) 设置key的值为list_ (unlike setitem()). appendlist(key,item) 添加item到和key关联的内部list. setlistdefault(key,list) 和setdefault有一点不同，它接受list而不是单个value作为参数。 lists() 和items()有一点不同, 它会返回key的所有值，作为一个list, 例如:&gt;&gt;&gt; q = QueryDict('a=1&amp;a=2&amp;a=3') &gt;&gt;&gt; q.lists() [('a', ['1', '2', '3'])] urlencode() 返回一个以查询字符串格式进行格式化后的字符串(例如：“a=2&amp;b=3&amp;b=5”)。 四、Django Admin 管理工具 Django 提供了基于 web 的管理工具。 Django 自动管理工具是 django.contrib 的一部分。你可以在项目的 settings.py 中的 INSTALLED_APPS 看到它： 123456789#/HelloWorld/HelloWorld/settings.py 文件代码：INSTALLED_APPS = ( 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles',) django.contrib是一套庞大的功能集，它是Django基本代码的组成部分。 1、激活管理工具 通常我们在生成项目时会在 urls.py 中自动设置好，我们只需去掉注释即可。 配置项如下所示： 1234567891011121314151617#/HelloWorld/HelloWorld/urls.py 文件代码：from django.contrib import adminfrom django.urls import pathfrom . import testdbfrom . import searchfrom . import search2urlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb), path('gitdb/', testdb.getdb), path('modify/', testdb.modify), path('del/', testdb.dl), path('search/', search.search), path('search-from/', search.search_form), path('search-post/', search2.search_post),] 当这一切都配置好后，Django 管理工具就可以运行了。 2、使用管理工具 启动开发服务器，然后在浏览器中访问 http://127.0.0.1:8000/admin/，得到如下界面： 因为我现在是新建了个项目所以需要创建表结构： 12345$ python manage.py migrate # 创建表结构//失败了可用python3 manage.py migrate$ python manage.py makemigrations TestModel # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate TestModel # 创建表结构 你可以通过命令 python manage.py createsuperuser 来创建超级用户，如下所示： 123456# python manage.py createsuperuserUsername (leave blank to use 'root'): adminEmail address: admin@runoob.comPassword:Password (again):Superuser created successfully. 之后输入用户名密码登录，界面如下： models.py文件添加类型 12345#XGPtest/TestModel/models.pyfrom django.db import models class Test(models.Model): name = models.CharField(max_length=20) 创建完成之后，数据库中就生成testmodel_test表 为了让 admin 界面管理某个数据模型，我们需要先注册该数据模型到 admin。比如，我们之前在 TestModel 中已经创建了模型 Test 。修改 TestModel/admin.py: 123456#HelloWorld/TestModel/admin.py: 文件代码：from django.contrib import adminfrom. models import Test# Register your models here.admin.site.register(Test) 刷新后即可看到 Testmodel 数据表: 可以简单的添加、修改、删除。 3、使用管理工具添加一个用户 4、复杂模型 管理页面的功能强大，完全有能力处理更加复杂的数据模型。 先在 TestModel/models.py 中增加一个更复杂的数据模型： 123456789101112131415161718from django.db import models # Create your models here.class Test(models.Model): name = models.CharField(max_length=20) class Contact(models.Model): name = models.CharField(max_length=20) age = models.IntegerField(default=0) email = models.EmailField() def __unicode__(self): return self.name class Tag(models.Model): contact = models.ForeignKey(Contact, on_delete=models.CASCADE,) name = models.CharField(max_length=50) def __unicode__(self): return self.name 这里有两个表。Tag 以 Contact 为外部键。一个 Contact 可以对应多个 Tag。 我们还可以看到许多在之前没有见过的属性类型，比如 IntegerField 用于存储整数。 在 TestModel/admin.py 注册多个模型并显示： 12345from django.contrib import adminfrom TestModel.models import Test,Contact,Tag# Register your models here.admin.site.register([Test, Contact, Tag]) 刷新管理页面，显示结果如下： 在以上管理工具我们就能进行复杂模型操作。 如果你之前还未创建表结构，可使用以下命令创建： 12$ python manage.py makemigrations TestModel # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate TestModel # 创建表结构 **数据库会生成新的表单testmodel tag和testmodel Contacts) 5、自定义表单 我们可以自定义管理页面，来取代默认的页面。比如上面的 “add” 页面。我们想只显示 name 和 email 部分。修改 TestModel/admin.py: 12345678910#HelloWorld/TestModel/admin.py: 文件代码：from django.contrib import adminfrom . models import Test,Contact,Tagclass ContactAdmin(admin.ModelAdmin): fields = ('name', 'email')# Register your models here.admin.site.register(Contact, ContactAdmin)admin.site.register([Test, Tag]) 以上代码定义了一个 ContactAdmin 类，用以说明管理页面的显示格式。 里面的 fields 属性定义了要显示的字段。 由于该类对应的是 Contact 数据模型，我们在注册的时候，需要将它们一起注册。显示效果如下： 我们还可以将输入栏分块，每个栏也可以定义自己的格式。修改 TestModel/admin.py为： 12345678910111213141516171819from django.contrib import adminfrom TestModel.models import Test, Contact, Tag# Register your models here.class ContactAdmin(admin.ModelAdmin): fieldsets = ( ['Main', &#123; 'fields': ('name', 'email'), &#125;], ['Advance', &#123; 'classes': ('collapse',), # CSS 'fields': ('age',), &#125;] )admin.site.register(Contact, ContactAdmin)admin.site.register([Test, Tag]) 上面的栏目分为了 Main 和 Advance 两部分。classes 说明它所在的部分的 CSS 格式。这里让 Advance 部分隐藏： Advance 部分旁边有一个 Show 按钮，用于展开，展开后可点击 Hide 将其隐藏，如下图所示： 6、内联(Inline)显示 上面的 Contact 是 Tag 的外部键，所以有外部参考的关系。 而在默认的页面显示中，将两者分离开来，无法体现出两者的从属关系。我们可以使用内联显示，让 Tag 附加在 Contact 的编辑页面上显示。 修改TestModel/admin.py： 12345678910111213141516171819202122from django.contrib import adminfrom TestModel.models import Test, Contact, Tag# Register your models here.class TagInline(admin.TabularInline): model = Tagclass ContactAdmin(admin.ModelAdmin): inlines = [TagInline] # Inline fieldsets = ( ['Main', &#123; 'fields': ('name', 'email'), &#125;], ['Advance', &#123; 'classes': ('collapse',), 'fields': ('age',), &#125;] admin.site.register(Contact, ContactAdmin)admin.site.register([Test, Tag]) 显示效果如下： 7、列表页的显示 在 Contact 输入数条记录后，Contact 的列表页看起来如下: 我们也可以自定义该页面的显示，比如在列表中显示更多的栏目，只需要在 ContactAdmin 中增加 list_display 属性: 123456789101112131415161718192021222324#HelloWorld/TestModel/admin.py: 文件代码：from django.contrib import adminfrom TestModel.models import Test,Contact,Tag # Register your models here.class TagInline(admin.TabularInline): model = Tag class ContactAdmin(admin.ModelAdmin): list_display = ('name','age', 'email') # list inlines = [TagInline] # Inline fieldsets = ( ['Main',&#123; 'fields':('name','email'), &#125;], ['Advance',&#123; 'classes': ('collapse',), 'fields': ('age',), &#125;] ) admin.site.register(Contact, ContactAdmin)admin.site.register([Test]) 刷新页面显示效果如下： 搜索功能在管理大量记录时非常有，我们可以使用 search_fields 为该列表页增加搜索栏： 12345678910111213141516171819202122232425#HelloWorld/TestModel/admin.py: 文件代码：from django.contrib import adminfrom TestModel.models import Test,Contact,Tag # Register your models here.class TagInline(admin.TabularInline): model = Tag class ContactAdmin(admin.ModelAdmin): list_display = ('name','age', 'email') search_fields = ('name',) #search inlines = [TagInline] # Inline fieldsets = ( ['Main',&#123; 'fields':('name','email'), &#125;], ['Advance',&#123; 'classes': ('collapse',), 'fields': ('age',), &#125;] ) admin.site.register(Contact, ContactAdmin)admin.site.register([Test]) 在本实例中我们搜索了 name 为xgp的记录，显示结果如下： 五、引入静态文件 文件链接《链接: https://pan.baidu.com/s/133f0ypYOsAi8s8DdV_Uduw 提取码: 4847》 需要将一些静态资源引入项目，新建一个static目录，可以将js、css等文件放入这个目录中： 1、urls.py 规则修改为如下形式： 123456789101112131415161718from django.contrib import adminfrom django.urls import pathfrom . import testdbfrom . import searchfrom . import search2from . import indexurlpatterns = [ path('admin/', admin.site.urls), path('testdb/', testdb.testdb), path('gitdb/', testdb.getdb), path('modify/', testdb.modify), path('del/', testdb.dl), path('search/', search.search), path('search-from/', search.search_form), path('search-post/', search2.search_post), path('index/', index.index),] 2、本目录创建index.py文件 1234from django.shortcuts import renderdef index(request): return render(request, 'index.html' ,&#123;&#125;) 浏览器查看一下 3、需要让Django找到这个目录，需要在setting文件中进行配置： 123STATICFILES_DIRS = ( os.path.join(BASE_DIR, 'static'),) 4、修改一下index.html文件 在html文件中引入静态资源： 把index.html文件中所有的image替换为/image！ ctrl+F：替换 浏览器查看一下","path":"posts/1b1f.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"windows10安装 mysql数据库和Navicat for MySQL(MySQL管理工具)","text":"windows10上安装mysql（详细步骤） 环境：windwos 10（1511） 64bit、mysql 5.7.14 时间：2020年4月18日 一、下载mysql 1、在浏览器里打开mysql的官网http://www.mysql.com/ 2、进入页面顶部的&quot;Downloads&quot; 3、打开页面底部的“Community(GPL) Downloads” 4、在页面中间的位置找到我们windows上要用的下载页面“MySQL Installer for Windows” 5、页面底端找到下载入口“Windows (x86, 32-bit), MSI Installer”，点击Download按钮开始下载，共381.4M 注意：MSI格式是指windows的安装程序，下载后直接双击就能进入安装向导的那种，区别于对文件进行解压的安装方式； 6、这个页面告诉询问你是否登录，告诉你登录之后有哪些好处，我们不登录，点击页面底部的“No thanks, just start my download.”按钮进入下载页面 7、开始下载，等待下载完成（由于直接下载速度太慢，之后我用迅雷下载完成的） 链接: https://pan.baidu.com/s/1p6Dy6YAT-FS0DLOUbuXTmw 提取码: 4847 8、下载完成 二、安装mysql 1、双击下载好的mysql安装文件“mysql-installer-community-5.7.14.0.msi”打开安装程序，打开后需要稍等一下 2、选择安装类型（根据个人需要） 3、我只需要安装mysql server，所以选择最后一项“Custom”，选择Custom之后左边的安装流程和右边的描述文字会改变，然后点击&quot;Next&quot;按钮继续 4、在这里我们需要从安装程序提供的可安装的产品（Products）中选择我们需要的mysql server 我们展开Available Products里的第一项“MySQL Servers”，依次展开其子结点，直到其终端结点，我的操作是64位的，所以选中“MySQL Server 5.7.14 - X64” 然后点击绿色的向右箭头，将当前Product移动需要安装的列表，然后在右边展开“MySQL Server 5.7.14 - X64”项，取消“Development Components”的勾选（因为我们只需要安装mysql server），之后点击“Next”按钮进入下一步 5、点击“Execute”（执行）开始安装，安装过程中会显示安装的Progress（进度），等待安装完成后Status会显示Complete，mysql图标前会出现一个绿色的勾，然后点击“Next”按钮进入产品配置界面 6、点击“Next”按钮进入MySQL Server 的配置 Config Type选择“Development Machine”，选择此项将使用较小的内容来运行我们的mysql server，对应小型软件、学习是完全够用的。之后“Next” 在Root Account Password设置数据库root账号的密码，我填的是123456所以程序提醒我密码强度为弱，我们需要牢记这个密码，然后点击“Next” 这里可以设置mysql server的名称和是否开机启动，我把名称改为了“MySQLZzz1”，取消了开机启动，其它的没改，点击“Next” 点击“Next” 此界面将之前设置的配置内容应用到我们的mysql server，点击“Execute”，等待完成就可以了 配置完成，点击“Finish”完成配置环节 7、配置完成后将回到安装程序，我们点击“Next”继续 提示我们安装完成，点击“Finish” 8、在上一步点击“Finish”之后电脑是如此的平静，让人不知道接下来干什么！按以往安装软件的经验这个时候电脑应该要自动启动刚刚安装好的软件的。所以我在进程里找了一下，确实没有发现类似mysql的进程，那么我们进入下一步。 三、配置mysql环境变量（非必要） 说明：给mysql配置环境变量后我们就可以在cmd里运行mysql（开启、停止等操作） 1、和其实环境变量的配置方法一样，我们打开环境变量配置窗口（组合键win+Pause -&gt; 更改设置 -&gt; 系统属性里选择“高级” -&gt; 环境变量） 2、选中系统变量中的“path”，在path值开头处输入mysql安装目录下的bin文件夹所在路径：C:\\Program Files\\MySQL\\MySQL Server 5.7\\bin，保存退出 之后一路确定 注意：mysql server安装的默认路径为：C:\\Program Files\\MySQL\\MySQL Server 5.7 3、测试是否配置成功：打开cmd，输入“mysql -u root -p”回车，然后输入mysql安装时设置的root账号的密码（123456），若提示“Welcome to the MySQL monitor.”说明配置成功了。 四、启动mysql 是的，到现在我们还没有启动我们的mysql！那么要怎么启动呢？ （基于已配置环境变量的情况） 1、以管理员的身份运行cmd，输入“net start mysqlzzz1”（MySQLZzz1是配置mysql server时填写的服务器名称，cmd里不区分大小写也可以使用） 2、提示启动成功后我们便可以在任务管理器的进程里看到“mysqld.exe”的进程了。 附： 若执行命令时提示：服务名无效。请键入 NET HELPMSG 2185 以获得更多的帮助。 解决办法： 在 mysql bin目录下 以管理员的权限 执行 mysqld -install命令 附：卸载mysql服务的方法。 1、以管理员的权限 net stop mysql ，关闭mysql服务 2、以管理员的权限 mysqld -remove ，卸载mysql服务 五、测试是否安装成功 我们使用MySQL管理软件（Navicat for MySQL）进行连接测试，确保mysql已经可以使用： 1、安装Navicat for MySQL 下载地址如下：（直接点击navicat.exe文件运行就可以） 链接 :https://pan.baidu.com/s/1rkOowXtvIBUhLJawT43boA 密码: rcup 注册码: NAVH-WK6A-DMVK-DKW3** 2、打开Navicat for MySQL 3、新建一个连接，填写连接信息： 连接名称：用于区分不同的连接，自己命名即可 主机名：localhost 端口：3306 用户名：root 密码：123456（之前配置mysql的时候填写的密码） 4、点击“连接测试”按钮，弹出连接成功对话框即表示mysql server已开启 5、之后就是Navicat for MySQL软件的使用 另： 我们也可以在cmd里，再次输入“net start mysqlzzz1”，若提示“请求的服务已经启动。”表示mysql server已正常启动； 至此，mysql server在windows 10 64位上就安装完成了。","path":"posts/3eca.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"初识Django和宝塔面板","text":"1234567镜像列表http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F; &#x2F;&#x2F;阿里https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple&#x2F; &#x2F;&#x2F;清华http:&#x2F;&#x2F;pypi.douban.com&#x2F; &#x2F;&#x2F;豆瓣http:&#x2F;&#x2F;pypi.hustunique.com&#x2F; &#x2F;&#x2F;华中理工大学http:&#x2F;&#x2F;pypi.sdutlinux.org&#x2F; &#x2F;&#x2F;山东理工大学http:&#x2F;&#x2F;pypi.mirrors.ustc.edu.cn&#x2F; &#x2F;&#x2F;中国科学技术大学 一、linux安装“宝塔面板” 12[root@python ~]# yum install -y wget &amp;&amp; wget -O install.sh http:&#x2F;&#x2F;download.bt.cn&#x2F;install&#x2F;install_6.0.sh &amp;&amp; sh install.sh&#x2F;&#x2F;一键安装 安装完成界面 浏览器访问 接下来就可以在这里体验一下，非常方便的一个工具！！！ 1、宝塔面板是什么？ 宝塔面板是一款服务器管理软件，支持windows和linux系统，可以通过Web端轻松管理服务器，提升运维效率。例如：创建管理网站、FTP、数据库，拥有可视化文件管理器，可视化软件管理器，可视化CPU、内存、流量监控图表，计划任务等功能。 2、宝塔面板可以做什么？ 宝塔面板拥有极速方便的一键配置与管理，可一键配置服务器环境（LAMP/LNMP/Tomcat/Node.js），一键部署SSL，异地备份；提供SSH开启关闭服务，SSH端口更改，禁ping，防火墙端口放行以及操作日志查看；CPU、内存、磁盘IO、网络IO数据监测，可设置记录保存天数以及任意查看某天数据；计划任务可按周期添加执行，支持SHELL脚本，提供网站、数据库备份以及日志切割，且支持一键备份到又拍云存储空间，或者其他云存储空间里；通过web界面就可以轻松管理安装所用的服务器软件，还有实用的扩展插件；集成方便高效的文件管理器，支持上传、下载、打包、解压以及文件编辑查看。 3、有哪些特色？ 为了方便用户建立网站，宝塔面板上的一键部署源码插件，可一键部署：discuz,wordpress,ecshop,thinkphp,z-blog,dedecms等程序。还有极其方便的一键迁移，两台服务器安装宝塔Linux面板5.2版本，可实现一键迁移服务器网站、FTP、数据库。 4、定位 总的来说宝塔面板是众多服务器管理软件中拥有友好的界面交互体验、功能完善且每周更新的一款产品。宝塔面板做的就是一款简单好用的服务器管理软件。 二、Django 的简便实用 1、简介 Python下有许多款不同的 Web 框架。Django是重量级选手中最有代表性的一位。许多成功的网站和APP都基于Django。 Django是一个开放源代码的Web应用框架，由Python写成。 Django遵守BSD版权，初次发布于2005年7月, 并于2008年9月发布了第一个正式版本1.0 。 Django采用了MVC的软件设计模式，即模型M，视图V和控制器C。 2. 特点 1） 重量级框架 对比Flask框架，Django原生提供了众多的功能组件，让开发更简便快速。 提供项目工程管理的自动化脚本工具 数据库ORM支持（对象关系映射，英语：Object Relational Mapping） 模板 表单 Admin管理站点 文件管理 认证权限 session机制 缓存 2）MVT模式 有一种程序设计模式叫MVC，其核心思想是分工、解耦，让不同的代码块之间降低耦合，增强代码的可扩展性和可移植性，实现向后兼容。 MVC的全拼为Model-View-Controller，最早由TrygveReenskaug在1978年提出，是施乐帕罗奥多研究中心(Xerox PARC)在20世纪80年代为程序语言Smalltalk发明的一种软件设计模式，是为了将传统的输入（input）、处理（processing）、输出（output）任务运用到图形化用户交互模型中而设计的。随着标准输入输出设备的出现，开发人员只需要将精力集中在业务逻辑的分析与实现上。后来被推荐为Oracle旗下Sun公司Java EE平台的设计模式，并且受到越来越多的使用ColdFusion和PHP的开发者的欢迎。现在虽然不再使用原来的分工方式，但是这种分工的思想被沿用下来，广泛应用于软件工程中，是一种典型并且应用广泛的软件架构模式。后来，MVC的思想被应用在了Ｗeb开发方面，被称为Ｗeb MVC框架。 1、MVC模式说明 M全拼为Model，主要封装对数据库层的访问，对数据库中的数据进行增、删、改、查操作。 V全拼为View，用于封装结果，生成页面展示的html内容。 C全拼为Controller，用于接收请求，处理业务逻辑，与Model和View交互，返回结果。 2、Django的MVT M全拼为Model，与MVC中的M功能相同，负责和数据库交互，进行数据处理。 V全拼为View，与MVC中的C功能相同，接收请求，进行业务处理，返回应答。 T全拼为Template，与MVC中的V功能相同，负责封装构造要返回的html。 注：差异就在于黑线黑箭头标识出来的部分 3、windows安装Django （1）版本对应 Django 版本 Python 版本 1.8 2.7, 3.2 , 3.3, 3.4, 3.5 1.9, 1.10 2.7, 3.4, 3.5 1.11 2.7, 3.4, 3.5, 3.6 2.0 3.4, 3.5, 3.6, 3.7 2.1, 2.2 3.5, 3.6, 3.7 （2）cmd安装 12pip install -i https://pypi.douban.com/simple/ django #较快pip install Django #较慢 （3）检查是否安装成功 123456C:\\WINDOWS\\system32&gt;python #进入python命令行Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)] on win32Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import django&gt;&gt;&gt; django.VERSION #查看版本号(3, 0, 5, 'final', 0) 如果输出了Django的版本号说明安装正确。 三、Django 创建第一个项目 本章我们将介绍Django 管理工具及如何使用 Django 来创建项目，第一个项目我们以 HelloWorld 来命令项目。 1、Django 管理工具 安装 Django 之后，您现在应该已经有了可用的管理工具 django-admin。我们可以使用 django-admin 来创建一个项目: 我们可以来看下django-admin 的命令介绍: 2、创建第一个项目 使用 django-admin 来创建 HelloWorld 项目： 1django-admin startproject HelloWorld 创建完成后我们可以查看下项目的目录结构： 12345678910111213PS G:\\四期\\python\\5\\test&gt; cd .\\HelloWorld\\PS G:\\四期\\python\\5\\test\\HelloWorld&gt; tree /f卷 学习 的文件夹 PATH 列表卷序列号为 7C11-994AG:.│ manage.py│└─HelloWorld asgi.py settings.py urls.py wsgi.py __init__.py 目录说明： HelloWorld: 项目的容器。 manage.py: 一个实用的命令行工具，可让你以各种方式与该 Django 项目进行交互。 HelloWorld/init.py: 一个空文件，告诉 Python 该目录是一个 Python 包。 HelloWorld/settings.py: 该 Django 项目的设置/配置。 HelloWorld/urls.py: 该 Django 项目的 URL 声明; 一份由 Django 驱动的网站&quot;目录&quot;。 HelloWorld/wsgi.py: 一个 WSGI 兼容的 Web 服务器的入口，以便运行你的项目。 接下来我们进入 HelloWorld 目录输入以下命令，启动服务器： 1PS G:\\四期\\python\\5\\test\\HelloWorld&gt; python .\\manage.py runserver 0.0.0.0 让其它电脑可连接到开发服务器，8000 为端口号。如果不说明，那么端口号默认为 8000。 在浏览器输入你服务器的 ip（这里我们输入本机 IP 地址： **127.0.0.1:8000**） 及端口号，如果正常启动，输出结果如下： 3、视图和 URL 配置 在先前创建的 HelloWorld 目录下的 HelloWorld 目录新建一个 view.py 文件，并输入代码： 1234from django.http import HttpResponse def hello(request): return HttpResponse(\"Hello world ! \") 接着，绑定 URL 与视图函数。打开 urls.py 文件，删除原来代码，将以下代码复制粘贴到 urls.py 文件中： 123456789101112from django.contrib import adminfrom django.urls import pathfrom . import view#引用之前创建的view文件urlpatterns = [ path('admin/', admin.site.urls), #关联新创建的view.pytrue#在浏览器输入127.0.0.1:8000/hel1o/,输出view. py中he11o函数返回的内容。 path('hello/', view.hello) #引用函数] 完成后，启动 Django 开发服务器，并在浏览器访问打开浏览器并访问： 我们也可以在 urls.py添加以下规则： 1234567from django.urls import path from . import view urlpatterns = [ path('hello/', view.hello),] 注意：项目中如果代码有改动，服务器会自动监测代码的改动并自动重新载入，所以如果你已经启动了服务器则不需手动重启。 四、path() 函数 Django path() 可以接收四个参数，分别是两个必选参数：route、view 和两个可选参数：kwargs、name。 语法格式： 1path(route, view, kwargs=None, name=None) route: 字符串，表示 URL 规则，与之匹配的 URL 会执行对应的第二个参数 view。 view: 用于执行与正则表达式匹配的 URL 请求。 kwargs: 视图使用的字典类型的参数。 name: 用来反向获取 URL。 Django2. 0中可以使用 re_path() 方法来兼容 1.x 版本中的 url() 方法，一些正则表达式的规则也可以通过 re_path() 来实现 。 12345678from django.urls import include, re_pathurlpatterns = [ re_path(r'^index/$', views.index, name='index'), re_path(r'^bio/(?P&lt;username&gt;\\w+)/$', views.bio, name='bio'), re_path(r'^weblog/', include('blog.urls')), ...] 五、Django 模板 Django 模板的应用，模板是一个文本，用于分离文档的表现形式和内容。 模板应用实例 我们接着上一章节的项目将在 HelloWorld 目录底下创建 templates 目录并建立 hello.html文件，整个目录结构如下： 123456789101112131415HelloWorld/|-- HelloWorld| |-- __init__.py| |-- __init__.pyc| |-- settings.py| |-- settings.pyc| |-- urls.py| |-- urls.pyc| |-- view.py| |-- view.pyc| |-- wsgi.py| `-- wsgi.pyc|-- manage.py`-- templates `-- hello.html hello.html 文件代码如下： 12345678910&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;我的第一个Django项目&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;&#123;&#123; 'hello' &#125;&#125;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 从模板中我们知道变量使用了双括号。 接下来我们需要向Django说明模板文件的路径，修改HelloWorld/settings.py，修改 TEMPLATES 中的 DIRS 为 [BASE_DIR+&quot;/templates&quot;,]，如下所示:d 12345678910111213141516...TEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [BASE_DIR+\"/templates\",], # 修改位置 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], &#125;, &#125;,]... 我们现在修改 view.py，增加一个新的对象，用于向模板提交数据： 123456from django.shortcuts import render def hello(request): context = &#123;&#125; context['hello'] = 'Hello World!' return render(request, 'hello.html', context) 可以看到，我们这里使用 render 来替代之前使用的 HttpResponse。render 还使用了一个字典 context 作为参数。 context 字典中元素的键值 “hello” 对应了模板中的变量 “”。 再访问访问 http://127.0.0.1:8000/hello，可以看到页面： 六、Django 模板标签 1、if/else 标签 基本语法格式如下： 123&#123;% if condition %&#125; ... display&#123;% endif %&#125; 或者： 1234567&#123;% if condition1 %&#125; ... display 1&#123;% elif condition2 %&#125; ... display 2&#123;% else %&#125; ... display 3&#123;% endif %&#125; 根据条件判断是否输出。if/else 支持嵌套。 1&#123;% if %&#125; 标签接受 and ， or 或者 not 关键字来对多个变量做判断 ，或者对变量取反（ not )，例如： 123&#123;% if athlete_list and coach_list %&#125; athletes 和 coaches 变量都是可用的。&#123;% endif %&#125; 2、for 标签 例如，给定一个运动员列表 athlete_list 变量，我们可以使用下面的代码来显示这个列表： 12345&lt;ul&gt;&#123;% for athlete in athlete_list %&#125; &lt;li&gt;&#123;&#123; athlete.name &#125;&#125;&lt;/li&gt;&#123;% endfor %&#125;&lt;/ul&gt; 给标签增加一个 reversed 使得该列表被反向迭代： 123&#123;% for athlete in athlete_list reversed %&#125;...&#123;% endfor %&#125; 1可以嵌套使用 &#123;% for %&#125; 标签： 12345678&#123;% for athlete in athlete_list %&#125; &lt;h1&gt;&#123;&#123; athlete.name &#125;&#125;&lt;/h1&gt; &lt;ul&gt; &#123;% for sport in athlete.sports_played %&#125; &lt;li&gt;&#123;&#123; sport &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt;&#123;% endfor %&#125; 3、ifequal/ifnotequal 标签 1&#123;% ifequal %&#125; 标签比较两个值，当他们相等时，显示在 &#123;% ifequal %&#125; 和 &#123;% endifequal %&#125; 之中所有的值。 下面的例子比较两个模板变量 user 和 currentuser : 123&#123;% ifequal user currentuser %&#125; &lt;h1&gt;Welcome!&lt;/h1&gt;&#123;% endifequal %&#125; 1和 &#123;% if %&#125; 类似， &#123;% ifequal %&#125; 支持可选的 &#123;% else%&#125; 标签：8 12345&#123;% ifequal section 'sitenews' %&#125; &lt;h1&gt;Site News&lt;/h1&gt;&#123;% else %&#125; &lt;h1&gt;No News Here&lt;/h1&gt;&#123;% endifequal %&#125; 4、注释标签 Django 注释使用 。 1&#123;# 这是一个注释 #&#125; 5、过滤器 模板过滤器可以在变量被显示前修改它，过滤器使用管道字符，如下所示： 1&#123;&#123; name|lower &#125;&#125; 变量被过滤器 lower 处理后，文档大写转换文本为小写。 过滤管道可以被 套接 ，既是说，一个过滤器管道的输出又可以作为下一个管道的输入： 1&#123;&#123; my_list|first|upper &#125;&#125; 以上实例将第一个元素并将其转化为大写。 有些过滤器有参数。 过滤器的参数跟随冒号之后并且总是以双引号包含。 例如： 1&#123;&#123; bio|truncatewords:\"30\" &#125;&#125; 这个将显示变量 bio 的前30个词。 其他过滤器： addslashes : 添加反斜杠到任何反斜杠、单引号或者双引号前面。 date : 按指定的格式字符串参数格式化 date 或者 datetime 对象，实例： 1&#123;&#123; pub_date|date:\"F j, Y\" &#125;&#125; length : 返回变量的长度。 6、include 标签 1&#123;% include %&#125; 标签允许在模板中包含其它的模板的内容。 下面这个例子都包含了 nav.html 模板： 1&#123;% include \"nav.html\" %&#125; 七、模板继承 模板可以用继承的方式来实现复用。 接下来我们先创建之前项目的 templates 目录中添加 base.html 文件，代码如下： 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;&lt;title&gt; xgp &lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Hello World!&lt;/h1&gt; &lt;p&gt;xgp Django 测试。&lt;/p&gt; &#123;% block mainbody %&#125; &lt;p&gt;original&lt;/p&gt; &#123;% endblock %&#125;&lt;/body&gt;&lt;/html&gt; 以上代码中，名为 mainbody 的 block 标签是可以被继承者们替换掉的部分。 1所有的 &#123;% block %&#125; 标签告诉模板引擎，子模板可以重载这些部分。 hello.html 中继承 base.html，并替换特定 block，hello.html 修改后的代码如下： 12345&#123;%extends \"base.html\" %&#125; &#123;% block mainbody %&#125;&lt;p&gt;xgp 继承了 base.html 文件&lt;/p&gt;&#123;% endblock %&#125; 第一行代码说明 hello.html 继承了 base.html 文件。可以看到，这里相同名字的 block 标签用以替换 base.html 的相应 block。 重新访问地址 http://127.0.0.1:8000/hello，输出结果如下： 八、Linux开发Django 1234567891011[root@python ~]# cd /opt/[root@python opt]# mkdir django_prject[root@python opt]# cd django_prject/[root@python django_prject]# pip3 install -i https://pypi.douban.com/simple/ django//下载django工具[root@python django_prject]# django-admin startproject HelloWorld//创建第一个项目（HelloWorld）[root@python django_prject]# python3 ./manage.py runserver//进入HelloWorld 目录，启动服务器 报错使用以下命令降低版本 12pip3 uninstall djangopip3 install django==2.1.8","path":"posts/10c6.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"Python数据可视化之Pygal图表类型","text":"一、pygal（图表类型Bar） 将使用Python可视化包Pygal来生成可缩放的矢量图形文件 pygal官方文档 1、安装pygal 1pip install pygal -i https://pypi.tuna.tsinghua.edu.cn/simple 2、简单的python图表 12import pygalpygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4).render() 生成svg图表 1pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4).render_to_file(\"simple.svg\") 需要查看它的源文件，才能显示图片。 3、制作多系列图标（Bar） 12345678import pygal# pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4)(5,7,8,13)(5,7,4,9).render_to_file(\"xgp.svg\")py_bar = pygal.Bar()py_bar.add(\"大标题\",[1, 3, 3, 7])py_bar.add(\"小标题\",[1, 6, 6, 4])py_bar.render_to_file(\"wsd.svg\") 4、堆叠图表（StackedBar） 12345678import pygal# pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4)(5,7,8,13)(5,7,4,9).render_to_file(\"xgp.svg\")py_bar = pygal.StackedBar()py_bar.add(\"大标题\",[1, 3, 3, 7])py_bar.add(\"小标题\",[1, 6, 6, 4])py_bar.render_to_file(\"wsd.svg\") 5、将上面的图表水平（HorizontalStackedBar） 12345678import pygal# pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4)(5,7,8,13)(5,7,4,9).render_to_file(\"xgp.svg\")py_bar = pygal.HorizontalStackedBar()py_bar.add(\"大标题\",[1, 3, 3, 7])py_bar.add(\"小标题\",[1, 6, 6, 4])py_bar.render_to_file(\"wsd.svg\") 二、pygal（各种图表类型） 1、基本的简单线形图（Line） 12345678import pygal# pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4)(5,7,8,13)(5,7,4,9).render_to_file(\"xgp.svg\")py_bar = pygal.Line()py_bar.add(\"大标题\",[1, 3, 3, 7])py_bar.add(\"小标题\",[1, 6, 6, 4])py_bar.render_to_file(\"wsd.svg\") 2、Horizontal Line 相同的图形但水平，范围为0-100。 123456789import pygal# pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4)(5,7,8,13)(5,7,4,9).render_to_file(\"xgp.svg\")py_bar = pygal.HorizontalLine()py_bar.add(\"大标题\",[1, 3, 3, 7])py_bar.add(\"小标题\",[1, 6, 6, 4])py_bar.range = [0, 10]py_bar.render_to_file(\"wsd.svg\") 3、Stacked 相同的图形但具有堆叠值和填充渲染 123456789import pygal# pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4)(5,7,8,13)(5,7,4,9).render_to_file(\"xgp.svg\")py_bar = pygal.StackedLine(fill=True)py_bar.add(\"大标题\",[1, 3, 3, 7])py_bar.add(\"小标题\",[1, 6, 6, 4])py_bar.range = [0, 10]py_bar.render_to_file(\"wsd.svg\") 4、Time 对于与时间相关的图，只需格式化标签或使用xy图表的一种变体 123456789101112import pygalfrom datetime import datetime# x_label_rotation=20是指x轴标签右旋转20度，可负数，负数向左旋转date_chart = pygal.Line(x_label_rotation=-20)date_chart.x_labels = map(lambda d: d.strftime('%Y-%m-%d'), [ datetime(2013, 1, 2), datetime(2013, 1, 12), datetime(2013, 2, 2), datetime(2013, 2, 22)])date_chart.add(\"Visits\", [300, 412, 823, 672])date_chart.render_to_file(\"line-time.svg\") Lambda是一个表达式，也可以是一个匿名函数 12def sum(x, y): return x + y 在Lambda中可以这样写 1p = lambda x, y: x + y 5、Histogram Basic 直方图是特殊条形，它为条形图取3个值：纵坐标高度，横坐标开始和横坐标结束。 123456import pygalhist = pygal.Histogram()hist.add('Wide bars', [(5, 0, 10), (4, 5, 13), (2, 0, 15)])hist.add('Narrow bars', [(10, 1, 2), (12, 4, 4.5), (8, 11, 13)])hist.render_to_file(\"histogram-basic.svg\") 6、Scatter Plot 禁用点和点之间的连线而获得散点图 123456789101112import pygalfrom math import cosxy_chart = pygal.XY()xy_chart.title = 'XY Cosinus'xy_chart.add('x = cos(y)', [(cos(x / 10.), x / 10.) for x in range(-50, 50, 5)])xy_chart.add('y = cos(x)', [(x / 10., cos(x / 10.)) for x in range(-50, 50, 5)])xy_chart.add('x = 1', [(1, -5), (1, 5)])xy_chart.add('x = -1', [(-1, -5), (-1, 5)])xy_chart.add('y = 1', [(-5, 1), (5, 1)])xy_chart.add('y = -1', [(-5, -1), (5, -1)])xy_chart.render_to_file(\"xy-basic.svg\") 7、Pie 简单的饼图 12345678910import pygalpie_chart = pygal.Pie()pie_chart.title = 'Browser usage in February 2012 (in %)'pie_chart.add('IE', 19.5)pie_chart.add('Firefox', 36.6)pie_chart.add('Chrome', 36.3)pie_chart.add('Safari', 4.5)pie_chart.add('Opera', 2.3)pie_chart.render_to_file(\"pie-basic.svg\") 8、Multi-series pie 相同的饼图，但分为子类别 12345678910import pygalpie_chart = pygal.Pie()pie_chart.title = 'Browser usage by version in February 2012 (in %)'pie_chart.add('IE', [5.7, 10.2, 2.6, 1])pie_chart.add('Firefox', [.6, 16.8, 7.4, 2.2, 1.2, 1, 1, 1.1, 4.3, 1])pie_chart.add('Chrome', [.3, .9, 17.1, 15.3, .6, .5, 1.6])pie_chart.add('Safari', [4.4, .1])pie_chart.add('Opera', [.1, 1.6, .1, .5])pie_chart.render_to_file(\"pie-multi-series.svg\") 9、Radar 简单的Kiviat图 123456789import pygal# pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4)(5,7,8,13)(5,7,4,9).render_to_file(\"xgp.svg\")py_bar = pygal.Radar()py_bar.add(\"大标题\",[1, 3, 3, 7])py_bar.add(\"小标题\",[1, 6, 6, 4])py_bar.range = [0, 10]py_bar.render_to_file(\"wsd.svg\") 10、Box Extremes (default) 123456789import pygalbox_plot = pygal.Box()box_plot.title = 'V8 benchmark results'box_plot.add('Chrome', [6395, 8212, 7520, 7218, 12464, 1660, 2123, 8607])box_plot.add('Firefox', [7473, 8099, 11700, 2651, 6361, 1044, 3797, 9450])box_plot.add('Opera', [3472, 2933, 4203, 5229, 5810, 1828, 9013, 4669])box_plot.add('IE', [43, 41, 59, 79, 144, 136, 34, 102])box_plot.render_to_file(\"box-extremes.svg\") 11、Dot 123456789import pygal# pygal.Bar()(1, 3, 3, 7)(1, 6, 6, 4)(5,7,8,13)(5,7,4,9).render_to_file(\"xgp.svg\")py_bar = pygal.Dot(x_label_rotation=30)py_bar.add(\"大标题\",[1, 3, 3, 7])py_bar.add(\"小标题\",[1, 6, 6, 4])py_bar.range = [0, 10]py_bar.render_to_file(\"wsd.svg\") 12、Funnel 漏斗图 123456789import pygalfunnel_chart = pygal.Funnel()funnel_chart.title = 'V8 benchmark results'funnel_chart.x_labels = ['Richards', 'DeltaBlue', 'Crypto', 'RayTrace', 'EarleyBoyer', 'RegExp', 'Splay', 'NavierStokes']funnel_chart.add('Opera', [3472, 2933, 4203, 5229, 5810, 1828, 9013, 4669])funnel_chart.add('Firefox', [7473, 8099, 11700, 2651, 6361, 1044, 3797, 9450])funnel_chart.add('Chrome', [6395, 8212, 7520, 7218, 12464, 1660, 2123, 8607])funnel_chart.render_to_file('funnel-basic.svg') 13、SolidGauge 123456789101112131415161718192021import pygalgauge = pygal.SolidGauge(inner_radius=0.70)# 百分格式percent_formatter = lambda x: '&#123;:.10g&#125;%'.format(x)# 美元格式dollar_formatter = lambda x: '&#123;:.10g&#125;$'.format(x)gauge.value_formatter = percent_formattergauge.add('Series 1', [&#123;'value': 225000, 'max_value': 1275000&#125;], formatter=dollar_formatter)gauge.add('Series 2', [&#123;'value': 110, 'max_value': 100&#125;])gauge.add('Series 3', [&#123;'value': 3&#125;])gauge.add( 'Series 4', [ &#123;'value': 51, 'max_value': 100&#125;, &#123;'value': 12, 'max_value': 100&#125;])gauge.add('Series 5', [&#123;'value': 79, 'max_value': 100&#125;])gauge.add('Series 6', 99)gauge.add('Series 7', [&#123;'value': 100, 'max_value': 100&#125;])gauge.render_to_file('solidgauge-normal.svg') 14、Gauge 仪表图 12345678910import pygalgauge_chart = pygal.Gauge(human_readable=True)gauge_chart.title = 'DeltaBlue V8 benchmark results'gauge_chart.range = [0, 10000]gauge_chart.add('Chrome', 8212)gauge_chart.add('Firefox', 8099)gauge_chart.add('Opera', 2933)gauge_chart.add('IE', 41)gauge_chart.render_to_file('gauge-basic.svg') 15、Maps World map 安装 1pip install pygal_maps_world Countries 123456789101112import pygalworldmap_chart = pygal.maps.world.World()worldmap_chart.title = 'Some countries'worldmap_chart.add('C countries', ['cn', 'ca', 'ch', 'cg'])worldmap_chart.add('F countries', ['fr', 'fi'])worldmap_chart.add('M countries', ['ma', 'mc', 'md', 'me', 'mg', 'mk', 'ml', 'mm', 'mn', 'mo', 'mr', 'mt', 'mu', 'mv', 'mw', 'mx', 'my', 'mz'])worldmap_chart.add('U countries', ['ua', 'ug', 'us', 'uy', 'uz'])worldmap_chart.render_to_file('world-map-countries.svg') 16、Continents 访问各大洲 1234567891011import pygalsupra = pygal.maps.world.SupranationalWorld()supra.add('Asia', [('asia', 1)])supra.add('Europe', [('europe', 1)])supra.add('Africa', [('africa', 1)])supra.add('North america', [('north_america', 1)])supra.add('South america', [('south_america', 1)])supra.add('Oceania', [('oceania', 1)])supra.add('Antartica', [('antartica', 1)])supra.render_to_file('world-map-continents.svg') 三、掷色子 分析点数概率并且绘制直方图 1、创建源文件（引用所需） 1234567891011from random import randintclass Die(): \"\"\"表示一个色子的类\"\"\" def __init__(self,num_sides=6): \"\"\"色子默认为6面\"\"\" self.num_sides=num_sides def roll(self): \"\"\"返回一个位于1和色子面数之间的随机值\"\"\" return randint(1, self.num_sides) 2、创建一个色子 123456789101112131415161718192021222324252627282930from Pygal.示例.die import Dieimport pygal# 创建一个色子die = Die()# 掷几次色子，并且将结果存储在一个列表中results = []for roll in range(1000): r = die.roll() results.append(r)print(results)# 分析结果frequencies = []for value in range(1, die.num_sides+1): frequency = results.count(value) frequencies.append(frequency)print(frequencies)# 对结果进行可视化hist = pygal.Bar()hist.title='掷色子1000次的结果'hist.x_labels = ['1','2','3','4','5','6']hist.x_title='Result'hist.y_title='概率'hist.add('D6',frequencies)hist.render_to_file('die_visual.svg') 使用浏览器打开这个文件，鼠标指向数据，可以看到显示了标题“D6”， x轴的坐标以及y轴坐标。 可以发现，六个数字出现的频次是差不多的（理论上概率是1/6， 随着实验次数的增加，趋势越来越明显） 3、同时掷两个骰子 稍微改下代码就行，再实例化一个骰子 12345678910111213141516171819202122232425262728293031from Pygal.示例.die import Dieimport pygal# 创建两个色子die_1 = Die()die_2 = Die()# 掷几次色子，并且将结果存储在一个列表中results = []for roll in range(1000): r = die_1.roll() + die_2.roll() results.append(r)print(results)# 分析结果frequencies = []max_result= die_1.num_sides + die_2.num_sidesfor value in range(2, max_result + 1): frequency = results.count(value) frequencies.append(frequency)print(frequencies)# 对结果进行可视化hist = pygal.Bar()hist.title='掷色子1000次的结果'hist.x_labels = ['2','3','4','5','6','7','8','9','10','11','12']hist.x_title='Result'hist.y_title='概率'hist.add('D6 + D6',frequencies)hist.render_to_file('die_visualc.svg')**** 从图中可以看出，两个骰子之和为7的次数最多，和为2的次数最少。因为能掷出2的只有一种情况 -&gt; (1, 1);而掷出7的情况有(1, 6) , (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)共6种情况，其余数字的情况都没有7的多，故掷得7得概率最大。 4、同时掷两个骰子（六和十的） 12345678910111213141516171819202122232425262728293031from Pygal.示例.die import Dieimport pygal# 创建两个色子die_1 = Die()die_2 = Die(10)# 掷几次色子，并且将结果存储在一个列表中results = []for roll in range(50000): r = die_1.roll() + die_2.roll() results.append(r)print(results)# 分析结果frequencies = []max_result= die_1.num_sides + die_2.num_sidesfor value in range(2, max_result + 1): frequency = results.count(value) frequencies.append(frequency)print(frequencies)# 对结果进行可视化hist = pygal.Bar()hist.title='掷色子1000次的结果'# hist.x_labels = ['2','3','4','5','6','7','8','9','10','11','12','13','14','15','16']hist.x_labels = [i for i in range(2,max_result+1)]hist.x_title='Result'hist.y_title='概率'hist.add('D6 + D6',frequencies)hist.render_to_file('die_visualcc.svg') 四、Python处理csv文件 CSV(Comma-Separated Values)即逗号分隔值，可以用Excel打开查看。由于是纯文本，任何编辑器也都可打开。与Excel文件不同，CSV文件中： 值没有类型，所有值都是字符串 不能指定字体颜色等样式 不能指定单元格的宽高，不能合并单元格 没有多个工作表 不能嵌入图像图表 在CSV文件中，以,作为分隔符，分隔两个单元格。像这样a,,c表示单元格a和单元格c之间有个空白的单元格。依此类推。 不是每个逗号都表示单元格之间的分界。所以即使CSV是纯文本文件，也坚持使用专门的模块进行处理。Python内置了csv模块。先看看一个简单的例子。 1、从CSV文件中读取数据 123456import csvfilename = 'F:/Jupyter Notebook/matplotlib_pygal_csv_json/sitka_weather_2014.csv'with open(filename) as f: reader = csv.reader(f) print(list(reader)) **data不能直接打印，list(data)最外层是list，里层的每一行数据都在一个list中，有点像这样** 1[['name', 'age'], ['Bob', '14'], ['Tom', '23'], ...] 于是我们可以这样访问到Bob的年龄reader[1][1], 在for循环中遍历如下 12345678import csvfilename = 'F:/Jupyter Notebook/matplotlib_pygal_csv_json/sitka_weather_2014.csv'with open(filename) as f: reader = csv.reader(f) for row in reader: # 行号从1开始 print(reader.line_num, row) 截取一部分输出 1231 ['AKST', 'Max TemperatureF]2 ['2014-1-1', '46', '42', '37', '40', '38', '36', '97', 138']... 前面的数字是行号，从1开始，可以用reader.line_num获取。 要注意的是，reader只能被遍历一次。由于reader是可迭代对象，可以使用next方法一次获取一行。 12345678910import csvfilename = 'F:/Jupyter Notebook/matplotlib_pygal_csv_json/sitka_weather_2014.csv'with open(filename) as f: reader = csv.reader(f) # 读取一行，下面的reader中已经没有该行了 head_row = next(reader) for row in reader: # 行号从2开始 print(reader.line_num, row) 2、写数据到csv文件中 有reader可以读取，当然也有writer可以写入。一次写入一行，一次写入多行都可以。 123456789101112131415import csv# 使用数字和字符串的数字都可以datas = [['name', 'age'], ['Bob', 14], ['Tom', 23], ['Jerry', '18']]with open('example.csv', 'w', newline='') as f: writer = csv.writer(f) for row in datas: writer.writerow(row) # 还可以写入多行 writer.writerows(datas) 如果不指定newline='',则每写入一行将有一空行被写入。上面的代码生成如下内容。 12345678name,ageBob,14Tom,23Jerry,18name,ageBob,14Tom,23Jerry,18 3、DictReader和DictWriter对象 使用DictReader可以像操作字典那样获取数据，把表的第一行（一般是标头）作为key。可访问每一行中那个某个key对应的数据。 123456789import csvfilename = 'F:/Jupyter Notebook/matplotlib_pygal_csv_json/sitka_weather_2014.csv'with open(filename) as f: reader = csv.DictReader(f) for row in reader: # Max TemperatureF是表第一行的某个数据，作为key max_temp = row['Max TemperatureF'] print(max_temp) 使用DictWriter类，可以写入字典形式的数据，同样键也是标头（表格第一行）。 123456789101112131415161718import csvheaders = ['name', 'age']datas = [&#123;'name':'Bob', 'age':23&#125;, &#123;'name':'Jerry', 'age':44&#125;, &#123;'name':'Tom', 'age':15&#125; ]with open('example.csv', 'w', newline='') as f: # 标头在这里传入，作为第一行数据 writer = csv.DictWriter(f, headers) writer.writeheader() for row in datas: writer.writerow(row) # 还可以写入多行 writer.writerows(datas) 4、统计每月最高温度 12345678910111213141516171819202122232425262728293031323334353637import csvfrom matplotlib import pyplot as pltfrom datetime import datetimeplt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号filename = 'Python-sitka_weather_2014.csv'with open(filename) as f: # 调用reader()函数，将f对象作为参数传递给它，从而创建一个与该文件相关联的阅读器对象 reader = csv.reader(f) # 返回文件中的下一行 header_row = next(reader) # print(header_row) # for index, column_header in enumerate(header_row): # print(index, column_header) highs = [] for row in reader: # 使用int()将字符串转换为数字，让matplotlib能够读取它们 high = int(row[1]) highs.append(high) print(highs) # 根据数据绘制图形 fig = plt.figure(dpi=128, figsize=(16, 9)) plt.plot(highs, c='red') # 设置图形格式 plt.title('2014年最高气温', fontsize=24) plt.xlabel('', fontsize=16) plt.ylabel('最高气温', fontsize=16) plt.tick_params(axis='both', which='major', labelsize=16) plt.show() 5、统计每月最高温度和最低温度 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import csvfrom matplotlib import pyplot as pltfrom datetime import datetimeplt.rcParams['font.sans-serif'] = ['SimHei'] # 用来正常显示中文标签plt.rcParams['axes.unicode_minus'] = False # 用来正常显示负号filename = 'Python-sitka_weather_2014.csv'with open(filename) as f: # 调用reader()函数，将f对象作为参数传递给它，从而创建一个与该文件相关联的阅读器对象 reader = csv.reader(f) # 返回文件中的下一行 header_row = next(reader) # print(header_row) dates, highs, lows = [], [], [] for row in reader: current_date = datetime.strptime(row[0], \"%Y/%m/%d\") dates.append(current_date) # print(current_date) # 使用int()将字符串转换为数字，让matplotlib能够读取它们 high = int(row[1]) highs.append(high) low = int(row[3]) lows.append(low) # print(highs) # 根据数据绘制图形 fig = plt.figure(dpi=128, figsize=(16, 9)) plt.plot(dates, highs, c='red', alpha=0.5) plt.plot(dates, lows, c='blue', alpha=0.5) plt.fill_between(dates, highs, lows, facecolor='blue', alpha=0.1) # 设置图形格式 plt.title('2014年最高气温', fontsize=24) plt.xlabel('', fontsize=16) # 绘制斜线标签 fig.autofmt_xdate() plt.ylabel('最高气温', fontsize=16) plt.tick_params(axis='both', which='major', labelsize=16) plt.show() # plt.savefig('hish.png')","path":"posts/c970.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python数据可视化","text":"数据可视化 1.matplotlib Matplotlib 可能是 Python 2D-绘图领域使用最广泛的套件。它能让使用者很轻松地将数据图形化，并且提供多样化的输出格式。这里将会探索 matplotlib 的常见用法。 安装matplotib 1pip install -i https://pypi.douban.com/simple/ matplotlib 测试matplotib 1234$python&gt;&gt;&gt;import matplotlib&gt;&gt;&gt;#没有错误信息输出，则表示matplotlib安装成功。 这个可能pyCharm识别不了，可以进行以下操作 实例一（线条） 1234import matplotlib.pyplot as pltsquares = [1,4,9,16,25]plt.plot(squares)plt.show() 实例二（线条） 12345678910111213141516import matplotlib.pyplot as pltsquares = [1,4,9,16,25]#修改线条的宽度: linewidthplt.plot(squares,linewidth=5)#设置图标的标题，并且给坐标轴加上标签plt.title('queares number',fontsize=24)plt.xlabel('value',fontsize=24)plt.ylabel('quares value',fontsize=24)# 设置刻度标记的大小plt.tick_params(axis=\"both\",labelsize=14)plt.show() 实例三（线条） 1234567891011121314151617181920import matplotlib.pyplot as plt#捕入值input_values = [1,2,3,4,5]#输出值squares = [1,4,9,16,25]#修改线条的宽度: linewidthplt.plot(input_values,squares,linewidth=5)#设置图标的标题，并且给坐标轴加上标签plt.title('queares number',fontsize=24)plt.xlabel('value',fontsize=24)plt.ylabel('quares value',fontsize=24)# 设置刻度标记的大小plt.tick_params(axis=\"both\",labelsize=14)plt.show() 实例四（单点） 1234import matplotlib.pyplot as pltplt.scatter(2,4)plt.show() 实例五（单点） 12345678910111213import matplotlib.pyplot as pltplt.scatter(2,4)#设置图标标题,并且给坐标轴加上标签plt.title('squares numbers',fontsize=24)plt.xlabel('value',fontsize=24)plt.ylabel('squares of value',fontsize=14)# 设置刻度标记的大小plt.tick_params(axis=\"both\",which='major',labelsize=14)plt.show() 实例六（多点） 123456789101112131415import matplotlib.pyplot as pltx_values = [1,2,3,4,5]y_values = [1,4,9,16,25]plt.scatter(x_values,y_values,s=100)#设置图标标题,并且给坐标轴加上标签plt.title('squares numbers',fontsize=24)plt.xlabel('value',fontsize=24)plt.ylabel('squares of value',fontsize=14)# 设置刻度标记的大小plt.tick_params(axis=\"both\",which='major',labelsize=14)plt.show() 实例七（多点连线） 123456789101112131415161718import matplotlib.pyplot as pltx_values = list(range(1,1001))y_values = [x ** 2 for x in x_values]plt.scatter(x_values,y_values,s=100)#设置图标标题,并且给坐标轴加上标签plt.title('squares numbers',fontsize=24)plt.xlabel('value',fontsize=24)plt.ylabel('squares of value',fontsize=14)# 设置刻度标记的大小plt.tick_params(axis=\"both\",which='major',labelsize=14)#设置每个坐标轴的取值范围plt.axis([0,1100,0,1100000])plt.show() 分析一下 实例八（多点连线、自定义颜色） 12345678910111213141516171819# 自定义颜色import matplotlib.pyplot as pltx_values = list(range(1,1001))y_values = [x ** 2 for x in x_values]plt.scatter(x_values,y_values,c='red',s=100)#设置图标标题,并且给坐标轴加上标签plt.title('squares numbers',fontsize=24)plt.xlabel('value',fontsize=24)plt.ylabel('squares of value',fontsize=14)# 设置刻度标记的大小plt.tick_params(axis=\"both\",which='major',labelsize=14)#设置每个坐标轴的取值范围plt.axis([0,1100,0,1100000])plt.show() 实例九（多点连线、自定义颜色） 123456789101112131415161718192021# 自定义颜色import matplotlib.pyplot as pltx_values = list(range(1,1001))y_values = [x ** 2 for x in x_values]#参数c表示紅绿蓝3种颜色的分量plt.scatter(x_values,y_values,c=(0,0.5,0.2),s=100)#设置图标标题,并且给坐标轴加上标签plt.title('squares numbers',fontsize=24)plt.xlabel('value',fontsize=24)plt.ylabel('squares of value',fontsize=14)# 设置刻度标记的大小plt.tick_params(axis=\"both\",which='major',labelsize=14)#设置每个坐标轴的取值范围plt.axis([0,1100,0,1100000])plt.show() 实例十（多点连线、自定义颜色，渐变色，保存图片） 12345678910111213141516171819202122232425# 自定义颜色import matplotlib.pyplot as pltx_values = list(range(1,1001))y_values = [x ** 2 for x in x_values]# 将参数c设置为一个y值的列表，使用参数cmap告诉plot使用哪个颜色映射plt.scatter(x_values,y_values,c=y_values,cmap=plt.cm.Blues,s=100)#设置图标标题,并且给坐标轴加上标签plt.title('squares numbers',fontsize=24)plt.xlabel('value',fontsize=24)plt.ylabel('squares of value',fontsize=14)# 设置刻度标记的大小plt.tick_params(axis=\"both\",which='major',labelsize=14)#设置每个坐标轴的取值范围plt.axis([0,1100,0,1100000])# plt.show()# bbox_inches='tight' --&gt;将图表多余的空白区域哉减掉# 保存图片为squares1.pngplt.savefig('squares1.png',bbox_inches='tight') 实例十一（多点连线、自定义颜色，渐变色，保存图片） 12345678910111213141516171819202122232425import matplotlib.pyplot as plt# plt.scatter(2,4)x_values = list(range(1, 1001))y_values = [x ** 2 for x in x_values]# plt.scatter(x_values, y_values,c='red', s=50)## 参数c表示红绿蓝3种颜色的分量# plt.scatter(x_values, y_values,c=(0,0.5,0.2), s=50)## 将参数c设置为一个y值的列表，使用参数cmap告诉plot使用哪个颜色映射plt.scatter(x_values, y_values,c=y_values,cmap=plt.cm.Reds, s=50)# 设置图标标题，并且 给坐标轴加上标签plt.title('squares numbers', fontsize=24)plt.xlabel('value', fontsize=24)plt.ylabel('square of value', fontsize=14)# 设置刻度的标记大小plt.tick_params(axis='both', which='major', labelsize=14)# 设置每个坐标轴的取值范围plt.axis([0,1100,0,1100000])# plt.show()# 保存图片为squares22.pngplt.savefig('squares22.png',bbox_inches='tight') 2、随机漫步 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 随机漫步from random import choiceclass RandomWalk(): \"\"\"-个生成随机漫步数据的类\"\"\" def __init__(self,num_points=5000): \"\"\"初始化随机漫步的属性\"\"\" self.num_points = num_points # 所有随机漫步都始于(0,0) self.x_values = [0] self.y_values = [0] def fill_walk(self): \"\"\"计算随机漫步包含的所有点\"\"\" # 不断漫步,直到列表达到指定的长度 while len(self.x_values) &lt; self.num_points: # 决定前进方向以及沿着这个方向前进的距离 x_direction = choice([1,-1]) x_distance = choice([0,1,2,3,4]) x_step = x_direction * x_distance y_direction = choice([1,-1]) y_distance = choice([0,1,2,3,4]) y_step = y_direction * y_distance # 拒绝原地踏步 if x_step == 0 and y_step ==0: continue # 计算下一个点的x和y的值 next_x =self.x_values[-1] + x_step next_y =self.y_values[-1] + y_step # # 不断漫步，直到列表达到指定的长度 while len(self.x_values) &lt; self.num_points: # 决定前进方向以及沿着这个方向前进的距离 x_direction = choice([1, -1]) x_distance = choice([0, 1, 2, 3, 4]) x_step = x_direction * x_distance y_direction = choice([1, -1]) y_distance = choice([0, 1, 2, 3, 4]) y_step = y_direction * y_distance # 决绝原地踏步 if x_step == 0 and y_step == 0: continue # 计算下一个点的x和y的值 next_x = self.x_values[-1] + x_step next_y = self.y_values[-1] + y_step # self.x_values.append(next_x) self.y_values.append(next_y) 实例一（随机漫步，自定义颜色） 123456789101112131415import matplotlib.pyplot as pltfrom 示例.mpl_squares import RandomWalk# 创建RandomWalk实例，并且将包含的点都绘制出来rw = RandomWalk()rw.fill_walk()# 给点着色point_numbers = list(range(rw.num_points))plt.scatter(rw.x_values, rw.y_values, c=point_numbers,cmap=plt.cm.Greens,s=15)# 隐藏边框# plt.axes().get_xaxis().set_visible(False)# plt.axes().get_yaxis().set_visible(False)plt.show() 实例二（随机漫步，是否继续生成） 123456789101112131415161718import matplotlib.pyplot as pltfrom 示例.mpl_squares import RandomWalkwhile True: # 创建RandomWalk实例，并且将包含的点都绘制出来 rw = RandomWalk() rw.fill_walk() plt.scatter(rw.x_values, rw.y_values, s=15) # 隐藏边框 # plt.axes().get_xaxis().set_visible(False) # plt.axes().get_yaxis().set_visible(False) plt.show() keep_running = input('继续漫步吗？(y/n)') if keep_running == 'n': break 输出结果： 1继续漫步吗？(y/n) y 实例三（随机漫步，控制点数，多点之间的距离） 12345678910111213141516171819import matplotlib.pyplot as pltfrom 示例.mpl_squares import RandomWalk# 创建RandomWalk实例，并且将包含的点都绘制出来rw = RandomWalk()rw.fill_walk()# 给点着色point_numbers = list(range(rw.num_points))plt.scatter(0,0,c='green',s=100)plt.scatter(rw.x_values[-1],rw.y_values[-1],c='red',s=100)# plt.scatter(rw.x_values, rw.y_values, c=point_numbers,cmap=plt.cm.Greens,s=15)# 隐藏边框# plt.axes().get_xaxis().set_visible(False)# plt.axes().get_yaxis().set_visible(False)plt.show() 实例四（随机漫步，控制点数（控制多点之间的距离）+自定义点数） 1234567891011121314151617181920import matplotlib.pyplot as pltfrom 示例.mpl_squares import RandomWalk# 创建RandomWalk实例，并且将包含的点都绘制出来rw = RandomWalk(500000)rw.fill_walk()# 给点着色point_numbers = list(range(rw.num_points))plt.scatter(0,0,c='green',s=100)plt.scatter(rw.x_values[-1],rw.y_values[-1],c='red',s=100)plt.scatter(rw.x_values, rw.y_values, c=point_numbers,cmap=plt.cm.Blues,s=1)# 隐藏边框# plt.axes().get_xaxis().set_visible(False)# plt.axes().get_yaxis().set_visible(False)plt.figure(dpi=128, figsize=(10,6))plt.show()","path":"posts/ed47.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python文本文件的（读、写、追加）","text":"一、open() 函数 Python open() 函数用于打开一个文件，并返回文件对象，在对文件进行处理过程都需要使用到这个函数，如果该文件无法被打开，会抛出 OSError。 注意：使用 open() 函数一定要保证关闭文件对象，即调用 close() 函数。 open() 函数常用形式是接收两个参数：文件名(file)和模式(mode)。 1open(file, mode='r') 完整的语法格式为： 1open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None) 参数说明: file: 必需，文件路径（相对或者绝对路径）。 mode: 可选，文件打开模式 buffering: 设置缓冲 encoding: 一般使用utf8 errors: 报错级别 newline: 区分换行符 closefd: 传入的file参数类型 opener: mode 参数有： 模式 描述 t 文本模式 (默认)。 x 写模式，新建一个文件，如果该文件已存在则会报错。 b 二进制模式。 + 打开一个文件进行更新(可读可写)。 U 通用换行模式（不推荐）。 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。 w 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 默认为文本模式，如果要以二进制模式打开，加上 b 。 1、写入和读取文件 123456content = 'Python与Linux自动化运维'with open('read.txt',mode='w',encoding='utf-8') as f: f.write(content)with open('read.txt',mode='r',encoding='utf-8') as f: print(f.read()) 执行结果： 1Python与Linux自动化运维 分析一下 2、追加文件内容 12345with open('read.txt',mode='a',encoding='utf-8') as f: f.write('\\nhello word\\t你好')with open('read.txt',mode='r',encoding='utf-8') as f: print(f.read()) 输出结果 12Python与Linux自动化运维hello word 你好 分析一下 3、读取图片和视频（二进制） （1）图片 12345img = ''with open(r\"E:\\软件\\360壁纸\\323244.jpg\",mode='rb') as f: img = f.read() with open('11.jpg',mode='wb') as f1: f1.write(img) 可查看到读取图片 （2）视频 1234with open(r'C:\\Users\\huawei\\Desktop\\11.ts',mode='rb') as f: video = f.read() with open('11.ts',mode='wb') as f1: f1.write(video) 可查看到读取视频（需在文件路径中查看） 点开即可查看视频 二、文件的异常 1、什么是异常？ 异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。 一般情况下，在Python无法正常处理程序时就会发生一个异常。 异常是Python对象，表示一个错误。 当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。 2、异常处理 捕捉异常可以使用try/except语句。 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它。 语法： 以下为简单的try…except…else的语法： 12345678try:&lt;语句&gt; #运行别的代码except &lt;名字&gt;：&lt;语句&gt; #如果在try部份引发了'name'异常except &lt;名字&gt;，&lt;数据&gt;:&lt;语句&gt; #如果引发了'name'异常，获得附加的数据else:&lt;语句&gt; #如果没有异常发生 try的工作原理是，当开始一个try语句后，python就在当前程序的上下文中作标记，这样当异常出现时就可以回到这里，try子句先执行，接下来会发生什么依赖于执行时是否出现异常。 如果当try后的语句执行时发生异常，python就跳回到try并执行第一个匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。 如果在try后的语句里发生了异常，却没有匹配的except子句，异常将被递交到上层的try，或者到程序的最上层（这样将结束程序，并打印默认的出错信息）。 如果在try子句执行时没有发生异常，python将执行else语句后的语句（如果有else的话），然后控制流通过整个try语句。 （1）异常处理 你可以不带任何异常类型使用except，如下实例： 12345678try: 正常的操作 ......................except: 发生异常，执行这块代码 ......................else: 如果没有异常执行这块代码 以上方式try-except语句捕获所有发生的异常。但这不是一个很好的方式，我们不能通过该程序识别出具体的异常信息。因为它捕获所有的异常。 实例 123456789try: #正常的代码 with open(r'E:\\软件\\360壁纸\\32324.jpg',mode='rb') as f: img = f.read() with open('b.jpg',mode='wb') as f1: f1.write(img)except FileNotFoundError: #出现错误后执行的代码 print('文件路径错误') 输出结果： 1文件路径错误 （2）0做除数的错误 12345678910111213141516try: # 根据运算符号确定运算规则 if opt == '+': result = one + two elif opt == '-': result = one - two elif opt == '*': result = one * two elif opt == '/': if two ==0: print('0不能做除数') result = one /two print(result)except ZeroDivisionError: print('需不能做除数!') 输出结果： 12345请输入第一个数:1请输入运算符号:/请输入第二个数:00不能做除数需不能做除数! （3）索引溢出的错误 使用except而带多种异常类型 你也可以使用相同的except语句来处理多个异常信息，如下所示： 12345678try: 正常的操作 ......................except(Exception1[, Exception2[,...ExceptionN]]]): 发生以上多个异常中的一个，执行这块代码 ......................else: 如果没有异常执行这块代码 实例 1234567try: num = input('请输入数字') print (num+str(10))except BaseException: print('输入类型错误! ')else: print('hello') 输出结果： 123请输入数字111110hello （4）try-finally 语句 try-finally 语句无论是否发生异常都将执行最后的代码。 12345try:&lt;语句&gt;finally:&lt;语句&gt; #退出try时总会执行raise 实例 12345try: fh = open(\"testfile\", \"w\") fh.write(\"这是一个测试文件，用于测试异常!!\")finally: print \"Error: 没有找到文件或读取文件失败\" 输出结果： 12$ python test.py Error: 没有找到文件或读取文件失败 同样的例子也可以写成如下方式： 123456789try: fh = open(\"testfile\", \"w\") try: fh.write(\"这是一个测试文件，用于测试异常!!\") finally: print \"关闭文件\" fh.close()except IOError: print \"Error: 没有找到文件或读取文件失败\" 当在try块中抛出一个异常，立即执行finally块代码。 finally块中的所有语句执行后，异常被再次触发，并执行except块代码。 参数的内容不同于异常。 （5）抛出异常 Python 使用 raise 语句抛出一个指定的异常。 raise语法格式如下： 1raise [Exception [, args [, traceback]]] 以下实例如果 x 大于 5 就触发异常: 123x = 10if x &gt; 5: raise Exception('x 不能大于 5。x 的值为: &#123;&#125;'.format(x)) 执行以上代码会触发异常： 1234Traceback (most recent call last): File \"test.py\", line 3, in &lt;module&gt; raise Exception('x 不能大于 5。x 的值为: &#123;&#125;'.format(x))Exception: x 不能大于 5。x 的值为: 10 raise 唯一的一个参数指定了要被抛出的异常。它必须是一个异常的实例或者是异常的类（也就是 Exception 的子类）。 如果你只想知道这是否抛出了一个异常，并不想去处理它，那么一个简单的 raise 语句就可以再次把它抛出。 12345678910&gt;&gt;&gt;try: raise NameError('HiThere') except NameError: print('An exception flew by!') raise An exception flew by!Traceback (most recent call last): File \"&lt;stdin&gt;\", line 2, in ?NameError: HiThere 3、异常类型 一个异常可以带上参数，可作为输出的异常信息参数。 你可以通过except语句来捕获异常的参数，如下所示： 12345try: 正常的操作 ......................except ExceptionType, Argument: 你可以在这输出 Argument 的值... 变量接收的异常值通常包含在异常的语句中。在元组的表单中变量可以接收一个或者多个值。 元组通常包含错误字符串，错误数字，错误位置。 异常名称 描述 BaseException 所有异常的基类 SystemExit 解释器请求退出 KeyboardInterrupt 用户中断执行(通常是输入^C) Exception 常规错误的基类 StopIteration 迭代器没有更多的值 GeneratorExit 生成器(generator)发生异常来通知退出 StandardError 所有的内建标准异常的基类 ArithmeticError 所有数值计算错误的基类 FloatingPointError 浮点计算错误 OverflowError 数值运算超出最大限制 ZeroDivisionError 除(或取模)零 (所有数据类型) AssertionError 断言语句失败 AttributeError 对象没有这个属性 EOFError 没有内建输入,到达EOF 标记 EnvironmentError 操作系统错误的基类 IOError 输入/输出操作失败 OSError 操作系统错误 WindowsError 系统调用失败 ImportError 导入模块/对象失败 LookupError 无效数据查询的基类 IndexError 序列中没有此索引(index) KeyError 映射中没有这个键 MemoryError 内存溢出错误(对于Python 解释器不是致命的) NameError 未声明/初始化对象 (没有属性) UnboundLocalError 访问未初始化的本地变量 ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象 RuntimeError 一般的运行时错误 NotImplementedError 尚未实现的方法 SyntaxError Python 语法错误 IndentationError 缩进错误 TabError Tab 和空格混用 SystemError 一般的解释器系统错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 UnicodeError Unicode 相关的错误 UnicodeDecodeError Unicode 解码时的错误 UnicodeEncodeError Unicode 编码时错误 UnicodeTranslateError Unicode 转换时错误 Warning 警告的基类 DeprecationWarning 关于被弃用的特征的警告 FutureWarning 关于构造将来语义会有改变的警告 OverflowWarning 旧的关于自动提升为长整型(long)的警告 PendingDeprecationWarning 关于特性将会被废弃的警告 RuntimeWarning 可疑的运行时行为(runtime behavior)的警告 SyntaxWarning 可疑的语法的警告 UserWarning 用户代码生成的警告 （1）实例 以下为单个异常的实例： 123456789101112#!/usr/bin/python# -*- coding: UTF-8 -*-# 定义函数def temp_convert(var): try: return int(var) except ValueError, Argument: print \"参数没有包含数字\\n\", Argument# 调用函数temp_convert(\"xyz\"); 以上程序执行结果如下： 123$ python test.py 参数没有包含数字invalid literal for int() with base 10: 'xyz' （2）触发异常 我们可以使用raise语句自己触发异常 raise语法格式如下： 1raise [Exception [, args [, traceback]]] 语句中 Exception 是异常的类型（例如，NameError）参数标准异常中任一种，args 是自已提供的异常参数。 最后一个参数是可选的（在实践中很少使用），如果存在，是跟踪异常对象。 （3）实例 一个异常可以是一个字符串，类或对象。 Python的内核提供的异常，大多数都是实例化的类，这是一个类的实例的参数。 定义一个异常非常简单，如下所示： 1234def functionName( level ): if level &lt; 1: raise Exception(\"Invalid level!\", level) # 触发异常后，后面的代码就不会再执行 注意：为了能够捕获异常，&quot;except&quot;语句必须有用相同的异常来抛出类对象或者字符串。 例如我们捕获以上异常，&quot;except&quot;语句如下所示： 123456try: 正常逻辑except Exception,err: 触发自定义异常 else: 其余代码 （4）实例 1234567891011121314#!/usr/bin/python# -*- coding: UTF-8 -*-# 定义函数def mye( level ): if level &lt; 1: raise Exception,\"Invalid level!\" # 触发异常后，后面的代码就不会再执行try: mye(0) # 触发异常except Exception,err: print 1,errelse: print 2 执行以上代码，输出结果为： 12$ python test.py 1 Invalid level! 4、用户自定义异常 通过创建一个新的异常类，程序可以命名它们自己的异常。异常应该是典型的继承自Exception类，通过直接或间接的方式。 以下为与RuntimeError相关的实例,实例中创建了一个类，基类为RuntimeError，用于在异常触发时输出更多的信息。 在try语句块中，用户自定义的异常后执行except块语句，变量 e 是用于创建Networkerror类的实例。 123class Networkerror(RuntimeError): def __init__(self, arg): self.args = arg 在你定义以上类后，你可以触发该异常，如下所示： 1234try: raise Networkerror(\"Bad hostname\")except Networkerror,e: print e.args 5、文件和异常的总结 （1）network文件写入 1234567891011121314from 文件和异常.总结.network_error import NetWorkErrortry: with open(r\"E:\\软件\\360壁纸\\323244.jpg\", mode='rb') as f: img = f.read() with open('b.jpg', mode='wb') as f1: f1.write(img)except (FileNotFoundError,IndexError, ValueError): print('except') raise NetWorkError('application bad ...')else: print('else')finally: print('finally') （2）network_error写入 123class NetWorkError(RuntimeError): def __init__(self,arg): self.arg=arg 三、json库存储数据 JSON (JavaScript Object Notation) 是一种轻量级的数据交换格式。它基于ECMAScript的一个子集。 Python3 中可以使用 json 模块来对 JSON 数据进行编解码，它包含了两个函数： json.dumps(): 对数据进行编码。 json.loads(): 对数据进行解码。 在json的编解码过程中，python 的原始类型与json类型会相互转换，具体的转化对照如下： Python 编码为 JSON 类型转换对应表： Python JSON dict object list, tuple array str string int, float, int- &amp; float-derived Enums number True true False false None null （1）存入数据到user.json 12345678import jsonusername = input('请输入用户名：')filename = 'user.json'with open(filename,'w') as f: json.dump(username,f) print('您输入的用户名已保存到json文件中。') 执行结果： 12请输入用户名：xgp您输入的用户名已保存到json文件中。 （2）引用json库数据 123456import jsonfilename = 'user.json'with open(filename) as f: username = json.load(f) print('欢迎'+username+\".\") 执行结果： 1欢迎xgp. （3）存入—指定数据—到---num.json 123456import jsonnumbers = [1,2,3,4,5]filename = 'num.json'with open(filename,'w') as f: json.dump(numbers,f) 1、son.dumps 与 json.loads 实例 以下实例演示了 Python 数据结构转换为JSON： 123456789101112import json # Python 字典类型转换为 JSON 对象data = &#123; 'no' : 1, 'name' : 'Runoob', 'url' : 'http://www.runoob.com'&#125; json_str = json.dumps(data)print (\"Python 原始数据：\", repr(data))print (\"JSON 对象：\", json_str) 输出结果： 12Python 原始数据： &#123;'url': 'http://www.runoob.com', 'no': 1, 'name': 'Runoob'&#125;JSON 对象： &#123;\"url\": \"http://www.runoob.com\", \"no\": 1, \"name\": \"Runoob\"&#125; 通过输出的结果可以看出，简单类型通过编码后跟其原始的repr()输出结果非常相似。 接着以上实例，我们可以将一个JSON编码的字符串转换回一个Python数据结构： 1234567891011121314151617import json # Python 字典类型转换为 JSON 对象data1 = &#123; 'no' : 1, 'name' : 'Runoob', 'url' : 'http://www.runoob.com'&#125; json_str = json.dumps(data1)print (\"Python 原始数据：\", repr(data1))print (\"JSON 对象：\", json_str) # 将 JSON 对象转换为 Python 字典data2 = json.loads(json_str)print (\"data2['name']: \", data2['name'])print (\"data2['url']: \", data2['url']) 输出结果： 1234Python 原始数据： &#123;'name': 'Runoob', 'no': 1, 'url': 'http://www.runoob.com'&#125;JSON 对象： &#123;\"name\": \"Runoob\", \"no\": 1, \"url\": \"http://www.runoob.com\"&#125;data2['name']: Runoobdata2['url']: http://www.runoob.com 如果你要处理的是文件而不是字符串，你可以使用 json.dump() 和 json.load() 来编码和解码JSON数据。例如： 1234567# 写入 JSON 数据with open('data.json', 'w') as f: json.dump(data, f) # 读取数据with open('data.json', 'r') as f: data = json.load(f)","path":"posts/5641.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python的正则表达式","text":"我们连接Linux来实现正则表达式 一、Python3 正则表达式 正则表达式是一个特殊的字符序列，它能帮助你方便的检查一个字符串是否与某种模式匹配。 Python 自1.5版本起增加了re 模块，它提供 Perl 风格的正则表达式模式。 re 模块使 Python 语言拥有全部的正则表达式功能。 compile 函数根据一个模式字符串和可选的标志参数生成一个正则表达式对象。该对象拥有一系列方法用于正则表达式匹配和替换。 re 模块也提供了与这些方法功能完全一致的函数，这些函数使用一个模式字符串做为它们的第一个参数。 本章节主要介绍 Python 中常用的正则表达式处理函数，如果你对正则表达式不了解，可以查看我们的 正则表达式 - 教程。 1、re.split split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下： 1re.split(pattern, string[, maxsplit=0, flags=0]) 参数： 参数 描述 pattern 匹配的正则表达式 string 要匹配的字符串。 maxsplit 分隔次数，maxsplit=1 分隔一次，默认为 0，不限制次数。 flags 标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：正则表达式修饰符 - 可选标志 例子 12345678import re# fLags=re.IGNORECASE:忽略大小写data = 'Last login: Tue Mar 31 17:56:11 2020 from 192.168.1.80'new_data = re.split('[:.]\\s*', data)print(new_data)print(data.split(': ')) 以上实例输出结果如下： 12['Last login', 'Tue Mar 31 17', '56', '11 2020 from 192', '168', '1', '80']['Last login', 'Tue Mar 31 17:56:11 2020 from 192.168.1.80'] 以下是正则表达式的基本语法: 模式 描述 ^ 匹配字符串的开头 $ 匹配字符串的末尾。 . 匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。 […] 用来表示一组字符,单独列出：[amk] 匹配 ‘a’，‘m’或’k’ [^…] 不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。 re* 匹配0个或多个的表达式。 re+ 匹配1个或多个的表达式。 re? 匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式 re{ n} 匹配n个前面表达式。例如，&quot;o{2}“不能匹配&quot;Bob&quot;中的&quot;o”，但是能匹配&quot;food&quot;中的两个o。 re{ n,} 精确匹配n个前面表达式。例如，&quot;o{2,}“不能匹配&quot;Bob&quot;中的&quot;o”，但能匹配&quot;foooood&quot;中的所有o。&quot;o{1,}“等价于&quot;o+”。&quot;o{0,}“则等价于&quot;o*”。 re{ n, m} 匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式 2、特殊字符类 实例 描述 . 匹配除 “\\n” 之外的任何单个字符。要匹配包括 ‘\\n’ 在内的任何字符，请使用象 ‘[.\\n]’ 的模式。 \\d 匹配一个数字字符。等价于 [0-9]。 \\D 匹配一个非数字字符。等价于 [^0-9]。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f\\n\\r\\t\\v]。 \\S 匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v]。 \\w 匹配包括下划线的任何单词字符。等价于’[A-Za-z0-9_]’。 \\W 匹配任何非单词字符。等价于 ‘[^A-Za-z0-9_]’。 12345# ?[a-zA-Z]+# ?用来匹配单词前后可能出现的空格，[a-zA-Z]代表一个或多个英文字母# 匹配一个IP地址 192.168.1.80# [0-9]&#123;1,3&#125;\\.[0-9]&#123;1,3&#125;\\.[0-9]&#123;1,3&#125;\\.[0-9]&#123;1,3&#125; 3、findall 函数 在字符串中找到正则表达式所匹配的所有子串，并返回一个列表，如果没有找到匹配的，则返回空列表。 注意： match 和 search 是匹配一次 findall 匹配所有。 语法格式为： 1re.findall(string[, pos[, endpos]]) 参数： string 待匹配的字符串。 pos 可选参数，指定字符串的起始位置，默认为 0。 endpos 可选参数，指定字符串的结束位置，默认为字符串的长度。 查找字符串中的所有数字： 12345678import re pattern = re.compile(r'\\d+') # 查找数字result1 = pattern.findall('runoob 123 google 456')result2 = pattern.findall('run88oob123google456', 0, 10) print(result1)print(result2) 以上实例输出结果如下： 12['123', '456']['88', '12'] 4、compile 函数 compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。 语法格式为： 1re.compile(pattern[, flags]) 参数： pattern : 一个字符串形式的正则表达式 flags 可选，表示匹配模式，比如忽略大小写，多行模式等，具体参数为： re.I 忽略大小写 re.L 表示特殊字符集 \\w, \\W, \\b, \\B, \\s, \\S 依赖于当前环境 re.M 多行模式 re.S 即为’ . ‘并且包括换行符在内的任意字符（’ . '不包括换行符） re.U 表示特殊字符集 \\w, \\W, \\b, \\B, \\d, \\D, \\s, \\S 依赖于 Unicode 字符属性数据库 re.X 为了增加可读性，忽略空格和’ # '后面的注释 例子1 12345678910111213141516171819&gt;&gt;&gt;import re&gt;&gt;&gt; pattern = re.compile(r'\\d+') # 用于匹配至少一个数字&gt;&gt;&gt; m = pattern.match('one12twothree34four') # 查找头部，没有匹配&gt;&gt;&gt; print( m )None&gt;&gt;&gt; m = pattern.match('one12twothree34four', 2, 10) # 从'e'的位置开始匹配，没有匹配&gt;&gt;&gt; print( m )None&gt;&gt;&gt; m = pattern.match('one12twothree34four', 3, 10) # 从'1'的位置开始匹配，正好匹配&gt;&gt;&gt; print( m ) # 返回一个 Match 对象&lt;_sre.SRE_Match object at 0x10a42aac0&gt;&gt;&gt;&gt; m.group(0) # 可省略 0'12'&gt;&gt;&gt; m.start(0) # 可省略 03&gt;&gt;&gt; m.end(0) # 可省略 05&gt;&gt;&gt; m.span(0) # 可省略 0(3, 5) 在上面，当匹配成功时返回一个 Match 对象，其中： group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)； start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0； end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0； span([group]) 方法返回 (start(group), end(group))。 例子2 1234567import re# flags=re. IGNORECASE:忽略大小写data = 'Linux系统内置Python 2.7.5,我们安装了Python 3.8.1。'print(re.findall( 'python [0-9]\\.[0-9]\\.[0-9]', data, flags=re.IGNORECASE))#re_obj = re.compile('python [0-9]\\.[0-9]\\.[0-9]', flags=re.IGNORECASE)print(re_obj.findall(data)) 以上实例输出结果如下： 12['Python 2.7.5', 'Python 3.8.1']['Python 2.7.5', 'Python 3.8.1'] 5、测试findall和compile的读取速度 （1）Linux生成数字文件 1[root@python ~]# seq 10000 &gt; data.txt （2）pycharm创建findall和compile的读取data.txt的文件 findall 123456789import redef main(): pattern = \"[0-9]+\" with open('~/data.txt') as f: for line in f: re.findall(pattern, line)if __name__ == 'main': main() compile 123456789import redef main() : pattern = \"[0-9]+\" re_obj = re.compile(pattern) with open(\"~/data.txt\") as f: for line in f: re_obj.findall(line)if __name__ == \"main\": main( ) （3）上传文件到Linux 底部出现以下信息，上传成功 （4）Linux测试下载速度 进入上传的目录/opt 1234[root@python ~]# cd &#x2F;opt&#x2F;[root@python opt]# cd 练习[root@python 练习]# ls001.py findall.py compile.py 测试 12345678910[root@python 练习]# time python3 findall.pyreal 0m0.058suser 0m0.005ssys 0m0.029s[root@python 练习]# time python3 compile.py real 0m0.018suser 0m0.014ssys 0m0.004s 经测试可看出compile读取的方式更快 二、常用的re函数 123456789101112131415161718192021222324252627data = 'What is the difference between python 2.7.5 and Python 3.8.1 ?'import reprint(re.findall('[0-9]\\.[0-9]\\.[0-9]',data))print(re.findall('python [0-9]\\.[0-9]\\.[0-9]',data))print(re.findall('Python [0-9]\\.[0-9]\\.[0-9]',data))print(re.findall('ython [0-9]\\.[0-9]\\.[0-9]',data))print(data.startswith('What'))print(data.endswith('?'))print(re.match('What',data))word = \"123 is one hender and twentyu-there\"print(re.match('\\d+',word))r = re.match('\\d+',word)print(r)print(r.start())print(r.end())print(r.re)print(r.group())print(r.string)rr = re.finditer('[0-9]\\.[0-9]\\.[0-9]',data)print(rr)# print([r for r in rr])for it in rr: print(it.group(0)) 以上实例输出结果： 123456789101112131415161718192021222324252627282930313233# 输出'x.x.x'类型的数字['2.7.5', '3.8.1']# 输出'python x.x.x'类型的数字['python 2.7.5']# 输出'Python x.x.x'类型的数字['Python 3.8.1']# 输出'ython x.x.x'类型的数字['ython 2.7.5', 'ython 3.8.1']# 查找data中是否有'What'True# 查找data中是否有'J'True# 查找data中是否有'What'&lt;re.Match object; span=(0, 4), match='What'&gt;# 查找data中是否有'数字字符'&lt;re.Match object; span=(0, 3), match='123'&gt;# 查找data中是否有'数字字符'&lt;re.Match object; span=(0, 3), match='123'&gt;# 匹配的子串在整个字符串中的起始位置0# 匹配的子串在整个字符串中的结束位置3# 获取re函数的类型re.compile('\\\\d+')# 获得一个或多个分组匹配的字符串123# 匹配的字符串123 is one hender and twentyu-there# 输出rr&lt;callable_iterator object at 0x000001B92D1613D0&gt;# 一行一行输出rr文件的'x.x.x'类型的数字2.7.53.8.1 （一）匹配类 1、re.match函数 re.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。 函数语法： 1re.match(pattern, string, flags=0) 函数参数说明： 参数 描述 pattern 匹配的正则表达式 string 要匹配的字符串。 flags 标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：正则表达式修饰符 - 可选标志 匹配成功re.match方法返回一个匹配的对象，否则返回None。 我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。 匹配对象方法 描述 group(num=0) 匹配的整个表达式的字符串，group() 可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组。 groups() 返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。 123import reprint(re.match('www', 'www.runoob.com').span()) # 在起始位置匹配print(re.match('com', 'www.runoob.com')) # 不在起始位置匹配 以上实例输出结果： 12(0, 3)None 123456789101112import reline = \"Cats are smarter than dogs\"# .* 表示任意匹配除换行符（\\n、\\r）之外的任何单个或多个字符matchObj = re.match( r'(.*) are (.*?) .*', line, re.M|re.I) if matchObj: print (\"matchObj.group() : \", matchObj.group()) print (\"matchObj.group(1) : \", matchObj.group(1)) print (\"matchObj.group(2) : \", matchObj.group(2))else: print (\"No match!!\") 以上实例输出结果： 123matchObj.group() : Cats are smarter than dogsmatchObj.group(1) : CatsmatchObj.group(2) : smarter 2、compile 函数 compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。 语法格式为： 1re.compile(pattern[, flags]) 参数： pattern : 一个字符串形式的正则表达式 flags 可选，表示匹配模式，比如忽略大小写，多行模式等，具体参数为： re.I 忽略大小写 re.L 表示特殊字符集 \\w, \\W, \\b, \\B, \\s, \\S 依赖于当前环境 re.M 多行模式 re.S 即为’ . ‘并且包括换行符在内的任意字符（’ . '不包括换行符） re.U 表示特殊字符集 \\w, \\W, \\b, \\B, \\d, \\D, \\s, \\S 依赖于 Unicode 字符属性数据库 re.X 为了增加可读性，忽略空格和’ # '后面的注释 实例 1234567891011121314151617181920212223&gt;&gt;&gt;import re&gt;&gt;&gt; pattern = re.compile(r'([a-z]+) ([a-z]+)', re.I) # re.I 表示忽略大小写&gt;&gt;&gt; m = pattern.match('Hello World Wide Web')&gt;&gt;&gt; print( m ) # 匹配成功，返回一个 Match 对象&lt;_sre.SRE_Match object at 0x10bea83e8&gt;&gt;&gt;&gt; m.group(0) # 返回匹配成功的整个子串'Hello World'&gt;&gt;&gt; m.span(0) # 返回匹配成功的整个子串的索引(0, 11)&gt;&gt;&gt; m.group(1) # 返回第一个分组匹配成功的子串'Hello'&gt;&gt;&gt; m.span(1) # 返回第一个分组匹配成功的子串的索引(0, 5)&gt;&gt;&gt; m.group(2) # 返回第二个分组匹配成功的子串'World'&gt;&gt;&gt; m.span(2) # 返回第二个分组匹配成功的子串索引(6, 11)&gt;&gt;&gt; m.groups() # 等价于 (m.group(1), m.group(2), ...)('Hello', 'World')&gt;&gt;&gt; m.group(3) # 不存在第三个分组Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;IndexError: no such group 在上面，当匹配成功时返回一个 Match 对象，其中： group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)； start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0； end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0； span([group]) 方法返回 (start(group), end(group))。 3、re.search方法 re.search 扫描整个字符串并返回第一个成功的匹配。 函数语法： 1re.search(pattern, string, flags=0) 函数参数说明： 参数 描述 pattern 匹配的正则表达式 string 要匹配的字符串。 flags 标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：正则表达式修饰符 - 可选标志 匹配成功re.search方法返回一个匹配的对象，否则返回None。 我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。 匹配对象方法 描述 group(num=0) 匹配的整个表达式的字符串，group() 可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组。 groups() 返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。 实例 1234import re print(re.search('www', 'www.runoob.com').span()) # 在起始位置匹配print(re.search('com', 'www.runoob.com').span()) # 不在起始位置匹配 以上实例输出结果： 12(0, 3)(11, 14) 4、re.match与re.search的区别 re.match 只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回 None，而 re.search 匹配整个字符串，直到找到一个匹配。 123456789101112131415import re line = \"Cats are smarter than dogs\" matchObj = re.match( r'dogs', line, re.M|re.I)if matchObj: print (\"match --&gt; matchObj.group() : \", matchObj.group())else: print (\"No match!!\") matchObj = re.search( r'dogs', line, re.M|re.I)if matchObj: print (\"search --&gt; matchObj.group() : \", matchObj.group())else: print (\"No match!!\") 以上实例输出结果： 12No match!!search --&gt; matchObj.group() : dogs 5、参数： 参数 描述 pattern 匹配的正则表达式 string 要匹配的字符串。 flags 标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：正则表达式修饰符 - 可选标志 实例 12345import re it = re.finditer(r\"\\d+\",\"12a32bc43jf3\") for match in it: print (match.group() ) 输出结果： 123412 32 43 3 （二）修改类 1、检索和替换 Python 的re模块提供了re.sub用于替换字符串中的匹配项。 语法： 1re.sub(pattern, repl, string, count=0, flags=0) 参数： pattern : 正则中的模式字符串。 repl : 替换的字符串，也可为一个函数。 string : 要被查找替换的原始字符串。 count : 模式匹配后替换的最大次数，默认 0 表示替换所有的匹配。 flags : 编译时用的匹配模式，数字形式。 前三个为必选参数，后两个为可选参数。 1234567891011import re phone = \"2004-959-559 # 这是一个电话号码\" # 删除注释num = re.sub(r'#.*$', \"\", phone)print (\"电话号码 : \", num) # 移除非数字的内容num = re.sub(r'\\D', \"\", phone)print (\"电话号码 : \", num) 输出结果： 12电话号码 : 2004-959-559 电话号码 : 2004959559 repl 参数是一个函数 以下实例中将字符串中的匹配的数字乘于 2： 123456789import re # 将匹配的数字乘于 2def double(matched): value = int(matched.group('value')) return str(value * 2) s = 'A23G4HFD567'print(re.sub('(?P&lt;value&gt;\\d+)', double, s)) 输出结果： 1A46G8HFD1134 2、re.split split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下： 1re.split(pattern, string[, maxsplit=0, flags=0]) 参数 描述 pattern 匹配的正则表达式 string 要匹配的字符串。 maxsplit 分隔次数，maxsplit=1 分隔一次，默认为 0，不限制次数。 flags 标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：正则表达式修饰符 - 可选标志 12345678910&gt;&gt;&gt;import re&gt;&gt;&gt; re.split('\\W+', 'runoob, runoob, runoob.')['runoob', 'runoob', 'runoob', '']&gt;&gt;&gt; re.split('(\\W+)', ' runoob, runoob, runoob.') ['', ' ', 'runoob', ', ', 'runoob', ', ', 'runoob', '.', '']&gt;&gt;&gt; re.split('\\W+', ' runoob, runoob, runoob.', 1) ['', 'runoob, runoob, runoob.'] &gt;&gt;&gt; re.split('a*', 'hello world') # 对于一个找不到匹配的字符串而言，split 不会对其作出分割['hello world'] （三）贪婪和非贪婪模式 1、概念 首先举个例子： 12example = \"abbbbbbc\"pattern = re.compile(\"ab+\") 贪婪模式：正则表达式一般趋向于最大长度匹配，也就是所谓的贪婪匹配。如上面使用模式pattern 匹配字符串example，匹配到的结果就是”abbbbbb”整个字符串。 非贪婪模式：在整个表达式匹配成功的前提下，尽可能少的匹配。如上面使用模式pattern 匹配字符串example，匹配到的结果就只是”ab”整个字符串。 2、使用方法 在python中默认采用的是贪婪模式，使用非贪婪模式的话，只需要在量词后面直接加上一个问号”?”。 在第一篇文章中介绍了正则表达式当中的量词一共有五种： 3、原理分析 在正则表达式中一般默认采用的是贪婪模式，在上面的例子当中已经匹配到了“ab”时已经可以使整个表达式匹配成功，但是由于采用的是贪婪模式，所以还需要往后继续匹配，检查时候存在更长的可以匹配成功的字符串。一直到匹配到最后一个”b”的时候，后面已经没有可以成功匹配的字符串了，匹配结束。返回匹配结果“abbbbbb”。 所以，我们可以将贪婪模式理解为：在整个表达式匹配成功的前提下，尽可能多的匹配。 非贪婪模式也就是将我们例子中的正则表达式“ab+”改为”ab+?”，当匹配到“ab”时，已经匹配成功，直接结束匹配，不在向后继续尝试，返回匹配成功的字符串”ab”。 所以，我们可以将非贪婪模式理解为：在整个表达式匹配成功的前提下，尽可能少的匹配 4、实例 1234import retext = 'Beautifulis better than ugly. Explicit is better than implicit.'print(re.findall('Beautifulis.*\\.',text))print(re.findall('Beautifulis.*?\\.',text)) 输出结果： 12['Beautifulis better than ugly. Explicit is better than implicit.']['Beautifulis better than ugly.'] 5、总结 1.从应用角度看贪婪与非贪婪 贪婪与非贪婪模式影响的是被量词修饰的子表达式的匹配行为，贪婪模式在整个表达式匹配成功的前提下，尽可能多的匹配；而非贪婪模式在整个表达式匹配成功的前提下，尽可能少的匹配。 2.从匹配原理角度看贪婪与非贪婪 能达到同样匹配结果的贪婪与非贪婪模式，通常是贪婪模式的匹配效率较高。 所有的非贪婪模式，都可以通过修改量词修饰的子表达式，转换为贪婪模式。 贪婪模式可以与固化分组结合，提升匹配效率，而非贪婪模式却不可以。 （四）Python3 replace()方法 描述 replace() 方法把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。 语法 replace()方法语法： 1str.replace(old, new[, max]) 参数 old – 将被替换的子字符串。 new – 新字符串，用于替换old子字符串。 max – 可选字符串, 替换不超过 max 次 返回值 返回字符串中的 old（旧字符串） 替换成 new(新字符串)后生成的新字符串，如果指定第三个参数max，则替换不超过 max 次。 实例 以下实例展示了replace()函数的使用方法： 123456789101112data = 'What is the difference between python 2.7.5 and Python 3.8.1 ?'print(data)import rer_data = data.replace('2.7.5','x.x.x')r_data2 = r_data.replace('3.8.1','x.x.x')print(r_data2)print(re.sub('[0-9]\\.[0-9]\\.[0-9]','x.x.x',data))print(data.split())print(re.split('[ .]+',data)) 输出结果： 12345What is the difference between python 2.7.5 and Python 3.8.1 ?What is the difference between python x.x.x and Python x.x.x ?What is the difference between python x.x.x and Python x.x.x ?['What', 'is', 'the', 'difference', 'between', 'python', '2.7.5', 'and', 'Python', '3.8.1', '?']['What', 'is', 'the', 'difference', 'between', 'python', '2', '7', '5', 'and', 'Python', '3', '8', '1', '?'] （五）绘制一个简单的疫情地图 12345678910111213141516171819202122232425262728from pyecharts.charts import Mapfrom pyecharts import options as optimport requestsimport json#获取数据data = requests.get( 'https://gwpre.sina.cn/interface/fymap2020_data.json').contentdata = json.loads(data)print(data)#筛选数据sub_data = list()for i in data['data']['list']: sub_data.append((i['name'],i['value']))print(sub_data)#绘制中国地图map_info = Map()#设置地图的基本信息map_info.set_global_opts(title_opts=opt.TitleOpts('实时疫情地图——'+data['data' ]['times'] ,subtitle='数据来源', subtitle_link='https://news.sina.cn/zt_d/yiqing0121?vt=4&amp;pos=222') ,visualmap_opts=opt.VisualMapOpts (max_=1500,is_piecewise=True))map_info.add('确诊', sub_data, maptype='china')#生成网页文件map_info.render( '20200403.html' ) 输出之后会生成一个网页信息，执行一下这个网页即可看到： （六）使用正则表达式解析拉勾网某页面内的所有http或者https链接 123456import reimport requestsr = requests.get('https://www.lagou.com/beijing')# print(r)result = re.findall('\"(https?://.*?)\"',r.content.decode('utf-8'))print(result) 输出结果： 12['https://www.lagou.com/beijing/', 'https://www.lagou.com/', 'https://www.lagou.com/about.html', 'http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010802024043', 'https://www.lagou.com/upload/oss.js?v=1010']-----","path":"posts/6618.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"python创建和使用类","text":"一、通用操作 1、Python len() 方法返回对象（字符、列表、元组等）长度或项目个数。 语法 len()方法语法： 1len( q ) 参数 q – 对象。 返回值 返回对象长度。 实例 以下实例展示了 len() 的使用方法： 123456&gt;&gt;&gt;str = \"runoob\"&gt;&gt;&gt; len(str) # 字符串长度6&gt;&gt;&gt; l = [1,2,3,4,5]&gt;&gt;&gt; len(l) # 列表元素个数5 2、python 成员运算符 in 和 not in Python成员运算符测试给定值是否为序列中的成员，例如字符串，列表或元组。 有两个成员运算符，如下所述 - in 如果在指定的序列中找到一个变量的值，则返回true，否则返回false。 not in 如果在指定序列中找不到变量的值，则返回true，否则返回false。 in 如果在指定的序列中找到值返回 True，否则返回 False。 x 在 y 序列中 , 如果 x 在 y 序列中返回 True。 not in 如果在指定的序列中没有找到值返回 True，否则返回 False。 x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True。 以下实例演示了Python所有成员运算符的操作： 12345678910111213141516171819202122#!/usr/bin/python3 a = 10b = 20list = [1, 2, 3, 4, 5 ]; if ( a in list ): print (\"1 - 变量 a 在给定的列表中 list 中\")else: print (\"1 - 变量 a 不在给定的列表中 list 中\") if ( b not in list ): print (\"2 - 变量 b 不在给定的列表中 list 中\")else: print (\"2 - 变量 b 在给定的列表中 list 中\") # 修改变量 a 的值a = 2if ( a in list ): print (\"3 - 变量 a 在给定的列表中 list 中\")else: print (\"3 - 变量 a 不在给定的列表中 list 中\") 以上实例输出结果： 1231 - 变量 a 不在给定的列表中 list 中2 - 变量 b 不在给定的列表中 list 中3 - 变量 a 在给定的列表中 list 中 3、Python身份运算符 身份运算符用于比较两个对象的存储单元 is is 是判断两个标识符是不是引用自一个对象 x is y, 类似 id(x) == id(y) , 如果引用的是同一个对象则返回 True，否则返回 False is not is not 是判断两个标识符是不是引用自不同对象 x is not y ， 类似 id(a) != id(b)。如果引用的不是同一个对象则返回结果 True，否则返回 False。 注： id() 函数用于获取对象内存地址。 以下实例演示了Python所有身份运算符的操作： 1234567891011121314151617181920212223242526#!/usr/bin/python3 a = 20b = 20 if ( a is b ): print (\"1 - a 和 b 有相同的标识\")else: print (\"1 - a 和 b 没有相同的标识\") if ( id(a) == id(b) ): print (\"2 - a 和 b 有相同的标识\")else: print (\"2 - a 和 b 没有相同的标识\") # 修改变量 b 的值b = 30if ( a is b ): print (\"3 - a 和 b 有相同的标识\")else: print (\"3 - a 和 b 没有相同的标识\") if ( a is not b ): print (\"4 - a 和 b 没有相同的标识\")else: print (\"4 - a 和 b 有相同的标识\") 以上实例输出结果： 12341 - a 和 b 有相同的标识2 - a 和 b 有相同的标识3 - a 和 b 没有相同的标识4 - a 和 b 没有相同的标识 is 与 == 区别： is 用于判断两个变量引用对象是否为同一个， == 用于判断引用变量的值是否相等。 &gt;&gt;&gt;a = [1, 2, 3] &gt;&gt;&gt; b = a &gt;&gt;&gt; b is a True &gt;&gt;&gt; b == a True &gt;&gt;&gt; b = a[:] &gt;&gt;&gt; b is a False &gt;&gt;&gt; b == a True 12345678910111213141516171819202122232425262728293031323334353637383940414243 ## 4、Python运算符优先级 **以下表格列出了从最高到最低优先级的所有运算符：** | 运算符 | 描述 | | :----------------------- | :----------------------------------------------------- | | ** | 指数 (最高优先级) | | ~ + - | 按位翻转, 一元加号和减号 (最后两个的方法名为 +@ 和 -@) | | * / % // | 乘，除，求余数和取整除 | | + - | 加法减法 | | &gt;&gt; &lt;&lt; | 右移，左移运算符 | | &amp; | 位 'AND' | | ^ \\| | 位运算符 | | &lt;= &lt; &gt; &gt;= | 比较运算符 | | == != | 等于运算符 | | = %= /= //= -= += *= **= | 赋值运算符 | | is is not | 身份运算符 | | in not in | 成员运算符 | | not and or | 逻辑运算符 |### **以下实例演示了Python所有运算符优先级的操作：**```python#!/usr/bin/python3 a = 20b = 10c = 15d = 5e = 0 e = (a + b) * c / d #( 30 * 15 ) / 5print (\"(a + b) * c / d 运算结果为：\", e) e = ((a + b) * c) / d # (30 * 15 ) / 5print (\"((a + b) * c) / d 运算结果为：\", e) e = (a + b) * (c / d); # (30) * (15/5)print (\"(a + b) * (c / d) 运算结果为：\", e) e = a + (b * c) / d; # 20 + (150/5)print (\"a + (b * c) / d 运算结果为：\", e) 以上实例输出结果： 1234(a + b) * c / d 运算结果为： 90.0((a + b) * c) / d 运算结果为： 90.0(a + b) * (c / d) 运算结果为： 90.0a + (b * c) / d 运算结果为： 50.0 and 拥有更高优先级: 12345678x = Truey = Falsez = False if x or y and z: print(\"yes\")else: print(\"no\") 以上实例输出结果： 1yes **注意：**Pyhton3 已不支持 &lt;&gt; 运算符，可以使用 != 代替，如果你一定要使用这种比较运算符，可以使用以下的方式： &gt;&gt;&gt; from __future__ import barry_as_FLUFL &gt;&gt;&gt; 1 &lt;&gt; 2 True 1234567891011121314151617181920212223242526272829303132333435363738394041[来自](https://www.runoob.com/python3/python3-basic-operators.html)# 二、与大小写的相关方法![image-20200402134458136](https://gitee.com/xgpqq/tuchuang/raw/master/img/image-20200402134458136.png)```pythonxgp = 'hello,wsd'print(xgp)# upper():将字符串转换为大写xgp1 = xgp.upper()print(xgp1)# isupper():判断字符串是否都为大写print(xgp1.isupper())# lower():将字符串转换为小写xgp2 = xgp1.lower()print(xgp2)# islower():判断字符串是否都为小写print(xgp2.islower())# title():将字符串中的单词转换为标题格式，每个单词首字母大写，其余小写xgp3 = xgp2.title()print(xgp3)# istitle():判断字符事是不是一个标题print(xgp3.istitle())# swapcase():小写转大写，大写转小写xgp4 = xgp3.swapcase()print(xgp4)xgp5 = xgp4.swapcase()print(xgp5)# capitalize():将首字母转换为大写xgp6 = xgp5.capitalize()print(xgp6) 以上实例输出结果： 12345678910111213141516171819# 原始输出hello,wsd# 将字符串转换为大写HELLO,WSD# 判断字符串是否都为大写True# 将字符串转换为小写hello,wsd# 判断字符串是否都为小写True# 将字符串中的单词转换为标题格式，每个单词首字母大写，其余小写Hello,Wsd# 判断字符事是不是一个标题True# 小写转大写，大写转小写hELLO,wSDHello,Wsd# 将首字母转换为大写Hello,wsd 三、判断类方法 ![image-20200402115648558](G:\\四期\\python\\python文档\\12 python的字符串.assets\\image-20200402115648558.png) 1、Python3 isalpha()方法 Python isalpha() 方法检测字符串是否只由字母组成。 语法 isalpha()方法语法： 1str.isalpha() 参数 无。 返回值 如果字符串至少有一个字符并且所有字符都是字母则返回 True，否则返回 False。 实例 12345678str = \"runoob\";print str.isalpha();str = \"runoob小钢炮\";print str.isalpha();str = \"this is string example....wow!!!\";print str.isalpha(); 以上实例输出结果如下： 123TrueFalseFalse 2、Python3 isalnum()方法 Python isalnum() 方法检测字符串是否由字母和数字组成。 语法 isalnum()方法语法： 1str.isalnum() 参数 无。 返回值 如果 string 至少有一个字符并且所有字符都是字母或数字则返回 True,否则返回 False 实例 以下实例展示了isalnum()方法的实例： 12345str = \"this2009\"; # 字符中没有空格print str.isalnum(); str = \"this is string example....wow!!!\";print str.isalnum(); 以上实例输出结果如下： 12TrueFalse 3、Python3 isspace()方法 Python isspace() 方法检测字符串是否只由空白字符组成。 语法 isspace() 方法语法： 1str.isspace() 参数 无。 返回值 如果字符串中只包含空格/指标位/换行符，则返回 True，否则返回 False. 实例 以下实例展示了isspace()方法的实例： 12345str = \" \\n \\t\" print (str.isspace()) str = \"Runoob example....wow!!!\"print (str.isspace()) 以上实例输出结果如下： 12TrueFalse 4、Python3 isdecimal()方法 Python isdecimal() 方法检查字符串是否只包含十进制字符。这种方法只存在于unicode对象。 注意:定义一个十进制字符串，只需要在字符串前添加 ‘u’ 前缀即可。 语法 isdecimal()方法语法： 1str.isdecimal() 参数 无 返回值 如果字符串是否只包含十进制字符返回True，否则返回False。 实例 以下实例展示了 isdecimal()函数的使用方法： 12345str = \"runoob2016\"print (str.isdecimal())str = \"23443434\"print (str.isdecimal()) 以上实例输出结果如下： 12FalseTrue 5、Python3 isdigit()方法 Python isdigit() 方法检测字符串是否只由数字组成。 语法 isdigit()方法语法： 1str.isdigit() 参数 无。 返回值 如果字符串只包含数字则返回 True 否则返回 False。 实例 以下实例展示了isdigit()方法的实例： 12345str = \"123456\"; print (str.isdigit())str = \"Runoob example....wow!!!\"print (str.isdigit()) 以上实例输出结果如下： 12TrueFalse 6、Python3 startswith()方法 startswith() 方法用于检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。 语法 startswith()方法语法： 1str.startswith(substr, beg=0,end=len(string)); 参数 str – 检测的字符串。 substr – 指定的子字符串。 strbeg – 可选参数用于设置字符串检测的起始位置。 strend – 可选参数用于设置字符串检测的结束位置。 返回值 如果检测到字符串则返回True，否则返回False。 实例 以下实例展示了startswith()函数的使用方法： 1234str = \"this is string example....wow!!!\"print (str.startswith( 'this' )) # 字符串是否以 this 开头print (str.startswith( 'string', 8 )) # 从第八个字符开始的字符串是否以 string 开头print (str.startswith( 'this', 2, 4 )) # 从第2个字符开始到第四个字符结束的字符串是否以 this 开头 以上实例输出结果如下： 123TrueTrueFalse 7、Python3 endswith()方法 endswith() 方法用于判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回 True，否则返回 False。可选参数 “start” 与 “end” 为检索字符串的开始与结束位置。 语法 endswith()方法语法： 1str.endswith(suffix[, start[, end]]) 参数 suffix – 该参数可以是一个字符串或者是一个元素。 start – 字符串中的开始位置。 end – 字符中结束位置。 返回值 如果字符串含有指定的后缀返回 True，否则返回 False。 实例 以下实例展示了endswith()方法的实例： 1234567Str='Runoob example....wow!!!'suffix='!!'print (Str.endswith(suffix))print (Str.endswith(suffix,20))suffix='run'print (Str.endswith(suffix))print (Str.endswith(suffix, 0, 19)) 以上实例输出结果如下： 1234TrueTrueFalseFalse 四、小练习 模拟用户注册，要求： 1、用户名不能是纯数字，不能以数字开头，必须包含数字、字母或者下划线其中两项。 2、用户密码长度在6-12位之间，不能是纯数字或纯字母，必须包含数字、字母大写或小写两项。 3、符合以上要求，程序提示注册成功；否则在输入内容之后立即给出错误提示。 1234567891011121314151617181920212223242526272829303132333435def user(): while True: username = input('请输入要注册的账号(不能是纯数字，不能以数字开头，必须包含数字、字母或者下划线其中两项') if username == '' : print('用户名不能为空') continue elif username .isdecimal() or username[0].isdecimal() == True: print('用户名首字母不能为数字或不能为纯数字用户名' ) continue elif username.isalpha() == True: print('必须包含数字字母下 划线其中两项' ) continue else: return username breakdef password(): while True: passwd = input(' 请输入密码: ') if len(passwd) &lt; 6 or len(passwd) &gt; 12: print( '用户密码长度在6 -12位之间') continue elif passwd. isdecimal() or passwd. isalpha(): print('用户密码不能是纯数字或纯字母,必须包含数字、字母大写或小写两项：') continue else: return passwd breakdef xgp(): user() password() print('注册成功')xgp() 以上实例输出结果如下： 123请输入要注册的账号(不能是纯数字，不能以数字开头，必须包含数字、字母或者下划线其中两项f123 请输入密码: sdf456!weq.注册成功 五、查找类的方法 12345str = 'hello,python'print(str.find('p'))print(str.index('e'))print(str.rindex('o'))print(str.rfind('h')) 以上实例输出结果如下： 123461109 1、Python3 find()方法 find() 方法检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果指定范围内如果包含指定索引值，返回的是索引值在字符串中的起始位置。如果不包含索引值，返回-1。 语法 find()方法语法： 1str.find(str, beg=0, end=len(string)) 参数 str – 指定检索的字符串 beg – 开始索引，默认为0。 end – 结束索引，默认为字符串的长度。 返回值 如果包含子字符串返回开始的索引值，否则返回-1。 实例 以下实例展示了find()方法的实例： 123456str1 = \"Runoob example....wow!!!\"str2 = \"exam\"; print (str1.find(str2))print (str1.find(str2, 5))print (str1.find(str2, 10)) 以上实例输出结果如下： 12377-1 例子 1234567&gt;&gt;&gt;info = 'abca'&gt;&gt;&gt; print(info.find('a')) # 从下标0开始，查找在字符串里第一个出现的子串，返回结果：00&gt;&gt;&gt; print(info.find('a', 1)) # 从下标1开始，查找在字符串里第一个出现的子串：返回结果33&gt;&gt;&gt; print(info.find('3')) # 查找不到返回-1-1 2、Python3 index()方法 index() 方法检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。 语法 index()方法语法： 1str.index(str, beg=0, end=len(string)) 参数 str – 指定检索的字符串 beg – 开始索引，默认为0。 end – 结束索引，默认为字符串的长度。 返回值 如果包含子字符串返回开始的索引值，否则抛出异常。 实例 以下实例展示了index()方法的实例： 123456str1 = \"Runoob example....wow!!!\"str2 = \"exam\";print (str1.index(str2))print (str1.index(str2, 5))print (str1.index(str2, 10)) 以上实例输出结果如下(未发现的会出现异常信息)： 12345677Traceback (most recent call last): File \"test.py\", line 8, in &lt;module&gt; print (str1.index(str2, 10))ValueError: substring not found 3、Python3 rfind()方法 Python rfind() 返回字符串最后一次出现的位置，如果没有匹配项则返回-1。 语法 rfind()方法语法： 1str.rfind(str, beg=0 end=len(string)) 参数 str – 查找的字符串 beg – 开始查找的位置，默认为0 end – 结束查找位置，默认为字符串的长度。 返回值 返回字符串最后一次出现的位置，如果没有匹配项则返回-1。 实例 以下实例展示了rfind()函数的使用方法： 1234567891011str1 = \"this is really a string example....wow!!!\"str2 = \"is\"print (str1.rfind(str2))print (str1.rfind(str2, 0, 10))print (str1.rfind(str2, 10, 0))print (str1.find(str2))print (str1.find(str2, 0, 10))print (str1.find(str2, 10, 0)) 以上实例输出结果如下： 12345655-122-1 4、Python3 rindex()方法 rindex() 返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常，你可以指定可选参数[beg:end]设置查找的区间。 语法 rindex()方法语法： 1str.rindex(str, beg=0 end=len(string)) 参数 str – 查找的字符串 beg – 开始查找的位置，默认为0 end – 结束查找位置，默认为字符串的长度。 返回值 返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常。 实例 以下实例展示了rindex()函数的使用方法： 12345str1 = \"this is really a string example....wow!!!\"str2 = \"is\"print (str1.rindex(str2))print (str1.rindex(str2,10)) 以上实例输出结果如下： 123455Traceback (most recent call last): File \"test.py\", line 6, in &lt;module&gt; print (str1.rindex(str2,10))ValueError: substring not found 六、小练习 （1）练习 验证规则： 正确格式：abc@163.com.cn 1、邮箱必须包含“@”和“.” 2、“@”在邮箱字符串中不能是第一个位置 3、“.”右侧至少应该有2-3个字符 4、“.”左侧不能是“@” 123456789101112131415161718192021def vanzheng(): youxiang = input(' 输入您的邮箱:') num = youxiang.index('.') qiepian = youxiang[num:-1] if youxiang[0] =='@' or youxiang[0] == '.' : print('邮箱第一位不能是@或者“.” ') elif '.' not in youxiang or '@' not in youxiang: print('邮箱必须包含“@”和“”') elif len(qiepian) &lt;= 2: print('“.”右侧至少应该有2-3个字符') elif youxiang[-1] == '@' or youxiang[-1] == '.': print('邮箱最后一位不能是@或者.') else: print('邮箱正确')vanzheng()yx=input('请输入您的邮箱')at = yx.find('@' )dian = yx. find('.')if (at &lt;= 0 or dian &lt;=0) or yx[-1]== '.' or (dian - at) &lt;=1 : print('邮箱格式有误' ) 以上实例输出结果如下： 12 输入您的邮箱:123@qq.com邮箱正确 （2）练习 1、提取passwd文件最后5个用户的记录 2、把每个用户的信息按“:”分别提取用户名、所属组、家目录、登录的shell类型 12345678910user_info = '''postfix:x:89:89::/var/spool/postfix:/sbin/nologintcpdump:x:72:72::/:/sbin/nologintest-07:x:1000:1000:test-07:/home/test-07:/bin/bashchou:x:1003:1003::/home/chouchou:/bin/bashtest02:x:1002:1007::/home/test001:/bin/bashtry:x:1004:1004::/home/try:/bin/bashlaoyu:x:1005:1009::/home/laoyu:/bin/bash'''new_info = user_info.split('\\n')for i in new_info: print('用户名:'+i.split(':')[0]+'所属组:'+i.split(':')[4]+'家目录:'+i.split(':')[5]+'登录环境:'+i.split(':')[6]) 以上实例输出结果如下： 1234567用户名:postfix所属组:家目录:/var/spool/postfix登录环境:/sbin/nologin用户名:tcpdump所属组:家目录:/登录环境:/sbin/nologin用户名:test-07所属组:test-07家目录:/home/test-07登录环境:/bin/bash用户名:chou所属组:家目录:/home/chouchou登录环境:/bin/bash用户名:test02所属组:家目录:/home/test001登录环境:/bin/bash用户名:try所属组:家目录:/home/try登录环境:/bin/bash用户名:laoyu所属组:家目录:/home/laoyu登录环境:/bin/bash 七、其他方法 1、Python3 split()方法 split() 通过指定分隔符对字符串进行切片，如果第二个参数 num 有指定值，则分割为 num+1 个子字符串。 语法 split() 方法语法： 1str.split(str=\"\", num=string.count(str)) 参数 str – 分隔符，默认为所有的空字符，包括空格、换行(\\n)、制表符(\\t)等。 num – 分割次数。默认为 -1, 即分隔所有。 返回值 返回分割后的字符串列表。 实例 以下实例展示了 split() 函数的使用方法： 1234str = \"this is string example....wow!!!\"print (str.split( )) # 以空格为分隔符print (str.split('i',1)) # 以 i 为分隔符print (str.split('w')) # 以 w 为分隔符 （1）以下实例以 # 号为分隔符，指定第二个参数为 1，返回两个参数列表。 123456txt = \"Google#Runoob#Taobao#Facebook\" # 第二个参数为 1，返回两个参数列表x = txt.split(\"#\", 1) print(x) 以上实例输出结果如下： 1['Google', 'Runoob#Taobao#Facebook'] 2、Python3 join()方法 Python join() 方法用于将序列中的元素以指定的字符连接生成一个新的字符串。 语法 join()方法语法： 1str.join(sequence) 参数 sequence – 要连接的元素序列。 返回值 返回通过指定字符连接序列中元素后生成的新字符串。 实例 以下实例展示了join()的使用方法： 12345s1 = \"-\"s2 = \"\"seq = (\"r\", \"u\", \"n\", \"o\", \"o\", \"b\") # 字符串序列print (s1.join( seq ))print (s2.join( seq )) 以上实例输出结果如下： 12r-u-n-o-o-brunoob 3、Python3中 strip lstrip rstrip的使用方法 简单来说，三种方法是为了删除字符串中不同位置的指定字符。其中，strip()用于去除字符串的首尾字符，同理，lstrip()用于去除左边的字符，rstrip()用于去除右边的字符 （1）strip() Python strip() 方法用于移除字符串头尾指定的字符（默认为空格）。 若传入的是一个字符数组，编译器将去除字符串两端所有相应的字符，直到没有匹配的字符。 语法 1str.strip([chars]) 参数 chars – 移除字符串头尾指定的字符。 实例 1、默认方法 12string1 = ' Kobe Bryant ' print(string1.strip()) 以上实例输出结果如下： 12Kobe Bryant 默认删除字符串前后的空格。 2、 参数传递 12string2 = 'uuuussssaaaa china aaaassssuuu'print(string2.strip('usa')) 以上实例输出结果如下： 12china 其中， 'u'、's'、'a' 的个数可以为任意，不影响最后输出 &gt; china （2）lstrip() Python lstrip() 方法用于截掉字符串左边的空格或指定字符，默认为空格。 实例 1、默认方法 12string1 = ' Kobe Bryant ' string1.lstrip() 以上实例输出结果如下： 12'Kobe Bryant '默认删除字符串前的空格。 2、 参数传递 12string2 = 'uuuussssaaaa china aaaassssuuu'print(string2.strip('usa')) 以上实例输出结果如下： 1china aaaassssuuu （3）rstrip() Python lstrip() 方法用于截掉字符串右边的空格或指定字符，默认为空格。 实例 1、默认方法 12string1 = ' Kobe Bryant ' string1.lstrip() 以上实例输出结果如下： 12Kobe Bryant'默认删除字符串后的空格。 2、参数传递 12string2 = 'uuuussssaaaa china aaaassssuuu'print(string2.strip('usa')) 以上实例输出结果如下： 1uuuussssaaaa china 4、Python3 replace()方法 描述 replace() 方法把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。 语法 replace()方法语法： 1str.replace(old, new[, max]) 参数 old – 将被替换的子字符串。 new – 新字符串，用于替换old子字符串。 max – 可选字符串, 替换不超过 max 次 返回值 返回字符串中的 old（旧字符串） 替换成 new(新字符串)后生成的新字符串，如果指定第三个参数max，则替换不超过 max 次。 实例 以下实例展示了replace()函数的使用方法： 123456str = \"wsdixgp.top\"print (\"xgp旧地址：\", str)print (\"xgp新地址：\", str.replace(\"wsdixgp.top\", \"wsdlxgp.top\")) str = \"this is string example....wow!!!\"print (str.replace(\"is\", \"was\", 3)) 以上实例输出结果如下： 123xgp旧地址： wsdixgp.topxgp新地址： wsdlxgp.topthwas was string example....wow!!! 八、使用Python分析Apache的访问日志 1、字符串分割 创建access.log文件（存放日志信息即可） log = '182.19.31.129 - - [16/JAN/2020:06:05:35 +0200] “GET /index.php HTTP/1.1” 200 0 “-” “Mozilla/5.0 (compatible; PJBot/3.0; +http://craw1.pagesjaunes.fr/robot)” “-”' log_temp = log.split() print(log_temp) print(‘用户IP：’+log_temp[0]) print(‘访问页面：’+log_temp[6]) print(‘状态码：’+log_temp[8]) 123456789from __future__ import print_functionips = []with open('access.log') as f: for line in f: ips.append(line.split()[0])print('网站请求数[PV]：'+ str(len(ips)))print('网站独立的访客数[UV]：'+ str(len(set(ips)))) 以上实例输出结果如下： 12网站请求数[PV]：120网站独立的访客数[UV]：6 2、使用counter类统计PV和UV 12345678910111213141516171819202122from __future__ import print_functiond = &#123;&#125;with open('access.log') as f: for line in f: key = line.split()[8] d.setdefault(key,0) d[key] += 1print(d)# 出错的页面数量error_requests = 0# 页面总访问量sum_requests = 0# 遍历字典for key, value in d.items(): if int(key) &gt;= 400: error_requests += value sum_requests += valueprint('页面出错率：&#123;0:2f&#125;%'.format(error_requests * 100.0/sum_requests)) 以上实例输出结果如下： 12&#123;'200': 115, '500': 1, '248': 1, '210': 1, '203': 1, '400': 1&#125;页面出错率：1.666667% 九、格式化 1、Python字符串格式化 Python 支持格式化字符串的输出 。尽管这样可能会用到非常复杂的表达式，但最基本的用法是将一个值插入到一个有字符串格式符 %s 的字符串中。 在 Python 中，字符串格式化使用与 C 中 sprintf 函数一样的语法。 1print (\"我叫 %s 今年 %d 岁!\" % ('小明', 10)) 以上实例输出结果： 1我叫 小明 今年 10 岁! python字符串格式化符号: 符 号 描述 %c 格式化字符及其ASCII码 %s 格式化字符串 %d 格式化整数 %u 格式化无符号整型 %o 格式化无符号八进制数 %x 格式化无符号十六进制数 %X 格式化无符号十六进制数（大写） %f 格式化浮点数字，可指定小数点后的精度 %e 用科学计数法格式化浮点数 %E 作用同%e，用科学计数法格式化浮点数 %g %f和%e的简写 %G %f 和 %E 的简写 %p 用十六进制数格式化变量的地址 格式化操作符辅助指令: 符号 功能 * 定义宽度或者小数点精度 - 用做左对齐 + 在正数前面显示加号( + ) 在正数前面显示空格 # 在八进制数前面显示零(‘0’)，在十六进制前面显示’0x’或者’0X’(取决于用的是’x’还是’X’) 0 显示的数字前面填充’0’而不是默认的空格 % ‘%%‘输出一个单一的’%’ (var) 映射变量(字典参数) m.n. m 是显示的最小总宽度,n 是小数点后的位数(如果可用的话) Python2.6 开始，新增了一种格式化字符串的函数 str.format()，它增强了字符串格式化的功能。 练习 123print( '%d' % 3)print( '%09f' % 3.14)print('%s' % 'hello') 以上实例输出结果如下： 123303.140000hello 2、format函数 Python2.6 开始，新增了一种格式化字符串的函数 str.format()，它增强了字符串格式化的功能。 基本语法是通过 {} 和 : 来代替以前的 % 。 format 函数可以接受不限个参数，位置可以不按顺序。 12345678&gt;&gt;&gt;\"&#123;&#125; &#123;&#125;\".format(\"hello\", \"world\") # 不设置指定位置，按默认顺序'hello world' &gt;&gt;&gt; \"&#123;0&#125; &#123;1&#125;\".format(\"hello\", \"world\") # 设置指定位置'hello world' &gt;&gt;&gt; \"&#123;1&#125; &#123;0&#125; &#123;1&#125;\".format(\"hello\", \"world\") # 设置指定位置'world hello world' 也可以设置参数： 123456789print(\"网站名：&#123;name&#125;, 地址 &#123;url&#125;\".format(name=\"xgp\", url=\"wsdlxgp.top\")) # 通过字典设置参数site = &#123;\"name\": \"xgp\", \"url\": \"wsdlxgp.top\"&#125;print(\"网站名：&#123;name&#125;, 地址 &#123;url&#125;\".format(**site)) # 通过列表索引设置参数my_list = ['xgp', 'wsdlxgp.top']print(\"网站名：&#123;0[0]&#125;, 地址 &#123;0[1]&#125;\".format(my_list)) # \"0\" 是必须的 以上实例输出结果如下： 123网站名：xgp, 地址 wsdlxgp.top网站名：xgp, 地址 wsdlxgp.top网站名：xgp, 地址 wsdlxgp.top 也可以向 str.format() 传入对象： 12345class AssignValue(object): def __init__(self, value): self.value = valuemy_value = AssignValue(6)print('value 为: &#123;0.value&#125;'.format(my_value)) # \"0\" 是可选的 以上实例输出结果如下： 1value 为: 6 3、数字格式化 下表展示了 str.format() 格式化数字的多种方法： 数字 格式 输出 描述 3.1415926 {:.2f} 3.14 保留小数点后两位 3.1415926 {:+.2f} +3.14 带符号保留小数点后两位 -1 {:+.2f} -1.00 带符号保留小数点后两位 2.71828 {:.0f} 3 不带小数 5 {:0&gt;2d} 05 数字补零 (填充左边, 宽度为2) 5 {:x&lt;4d} 5xxx 数字补x (填充右边, 宽度为4) 10 {:x&lt;4d} 10xx 数字补x (填充右边, 宽度为4) 1000000 {:,} 1,000,000 以逗号分隔的数字格式 0.25 {:.2%} 25.00% 百分比格式 1000000000 {:.2e} 1.00e+09 指数记法 13 {:&gt;10d} 13 右对齐 (默认, 宽度为10) 13 {:&lt;10d} 13 左对齐 (宽度为10) 13 {:^10d} 13 中间对齐 (宽度为10) 11 '{:b}'.format(11) '{:d}'.format(11) '{:o}'.format(11) '{:x}'.format(11) '{:#x}'.format(11) '{:#X}'.format(11) 1011 11 13 b 0xb 0XB ^, &lt;, &gt; 分别是居中、左对齐、右对齐，后面带宽度， : 号后面带填充的字符，只能是一个字符，不指定则默认是用空格填充。 + 表示在正数前显示 +，负数前显示 -； （空格）表示在正数前加空格 b、d、o、x 分别是二进制、十进制、八进制、十六进制。 12345678910# 精度print('&#123;: .2f&#125;'.format(3.141592656535897))# 符号print('&#123;: .2f&#125;'.format(3.141592656535897))# 宽度print( '&#123;:10.2f&#125;'.format(3.141592656535897))# 对齐方式print('&#123;:^10.2f&#125;'.format(3.141592656535897))# 逗号分隔print('&#123;:,&#125;'.format(23421424231)) 以上实例输出结果如下： 12345 3.14 3.14 3.14 3.14 23,421,424,231 此外我们可以使用大括号 {} 来转义大括号，如下实例： 1print (\"&#123;&#125; 对应的位置是 &#123;&#123;0&#125;&#125;\".format(\"runoob\")) 以上实例输出结果如下： 1runoob 对应的位置是 &#123;0&#125;","path":"posts/fec4.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"初识python","text":"Python 面向对象 记住一句话：类是模板，而实例则是根据类创建的对象。 初学时对类的理解是从类的字面上，可以片面的认为它是一个种类，它是相似特征的抽像，也就是相似的东西，可以把相似特征的事务抽象成一个类。（事务可以是具体的物体或行为） 以圆为例，圆是具有圆周率(pi)和半径®两个相似特征的属性。根据相似特征抽象出圆类，每个圆的半径可以不同，那么半径可以作为圆的实例属性；而每个圆的圆周率pi是相同的，那么圆周率pi就可以作为类属性，这样就定义出了一个圆类。而我们要知道圆的面积，周长等可以通过类方法计算出来。 （看完整篇文章，还是对类不理解，回过头在来看这部分，对照列子多理解。） 类的应用场景： 零散代码(代码块)–&gt;函数(方法)–&gt;类–&gt;模块(文件) 类:表示抽象(模糊)的事物 对象:表示具体(清晰)的事物 1、面向对象技术简介 类(Class): 用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。 **类变量：**类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 **数据成员：**类变量或者实例变量, 用于处理类及其实例对象的相关的数据。 **方法重写：**如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 **局部变量：**定义在方法中的变量，只作用于当前实例的类。 **实例变量：**在类的声明中，属性是用变量来表示的。这种变量就称为实例变量，是在类声明的内部但是在类的其他成员方法之外声明的。 **继承：**即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟&quot;是一个（is-a）&quot;关系（例图，Dog是一个Animal）。 **实例化：**创建一个类的实例，类的具体对象。 **方法：**类中定义的函数。 **对象：**通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。 2、创建类 使用 class 语句来创建一个新类，class 之后为类的名称并以冒号结尾: 123ClassName: '类的帮助信息' #类文档字符串 class_suite #类体 类的帮助信息可以通过ClassName.doc查看。 class_suite 由类成员，方法，数据属性组成。 （1）例子 描述人类的文件 类的结构： 1、动态的行为（动词）：speak、sing 2、静态的属性（名词）：gender、user_name （1）全局：在类中的任何地方都能使用 （2）局部：只能够在方法内部使用 使用类： 实例化对象：对象名 = 类名 ( 参数【可选的】) 1234567891011121314class Human(): \"\"\"模拟人类\"\"\" def __init__(self, sex, name): \"\"\"初始化属性：gender和user_name\"\"\" self.gender = sex self.user_name = name def speak(self): \"\"\"模拟人类说话\"\"\" print(self.user_name.title() + \"正在说话。\") def sing(self): \"\"\"模拟人类唱歌\"\"\" print(self.user_name.title() + \"正在唱歌。\") empCount 变量是一个类变量，它的值将在这个类的所有实例之间共享。你可以在内部类或外部类使用 Employee.empCount 访问。 第一种方法__init__()方法是一种特殊的方法，被称为类的构造函数或初始化方法，当创建了这个类的实例时就会调用该方法 self 代表类的实例，self 在定义类的方法时是必须有的，虽然在调用时不必传入相应的参数。 输出结果如下： 123456# 使用类man = Human('男','xgp')man.speak()lz = Human('男','kk')lz.sing() （2）修改初始值 12345678910111213class Pet(): def __init__(self,sex,strain): \"\"\"给属性赋初始值（默认值）\"\"\" self.nick_name = '咪咪' self.gender = sex self.stain = straincat = Pet('公','土猫')# 修改初始值cat.nick_name = '妙妙'print(cat.nick_name) 输出结果如下： 1妙妙 3、self代表类的实例，而非类 类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称, 按照惯例它的名称是 self。 1234567class Test: def prt(self): print(self) print(self.__class__) t = Test()t.prt() 输出结果如下： 12&lt;__main__.Test instance at 0x10d066878&gt;__main__.Test 从执行结果可以很明显的看出，self 代表的是类的实例，代表当前对象的地址，而 self.__class__ 则指向类。 self 不是 python 关键字，我们把他换成 runoob 也是可以正常执行的: 1234567class Test: def prt(runoob): print(runoob) print(runoob.__class__) t = Test()t.prt() 输出结果如下： 12&lt;__main__.Test instance at 0x10d066878&gt;__main__.Test 4、创建实例对象 实例化类其他编程语言中一般用关键字 new，但是在 Python 中并没有这个关键字，类的实例化类似函数调用方式。 以下使用类的名称 Dn 来实例化，并通过 __init__ 方法接收参数。 123456789101112131415161718192021222324252627\"\"\"小明和小红各自买了一台笔记本电脑,其中小明的电脑品牌是联想, CPU8核, 512G固态硬盘,双飞燕鼠标省红的电脑品牌是机械师, CPU4核, 256G固态硬盘+1T普通硬盘，机械师鼠标使用面向对象的思维，编写代码完成以 上描述。\"\"\"class Dn(): def __init__(self,name,brand,cpu,disk,mouse): self.nice_name = name self.nice_pp = brand self.nice_cpu = cpu self.nice_disk = disk self.nice_mouse = mouse def xgp(self): print(self.nice_name + '的电脑配置：“' + '品牌：' + self.nice_pp + ',' + 'cpu：' +self.nice_cpu + ',' + '硬盘：' +self.nice_disk + ',' + '鼠标：' + self.nice_mouse + ',' + '”。')# 可以使用点号 . 来访问对象的属性。使用如下类的名称访问类变量Dn1 = Dn('小明','联想','8核','512固态硬盘','双飞燕')Dn1.xgp()Dn2 = Dn('小米','机械师','4核','256G固态硬盘+1T普通硬盘','机械师鼠标')Dn2.xgp() 输出结果如下： 12小明的电脑配置：“品牌：联想,cpu：8核,固态硬盘：512固态硬盘,鼠标：双飞燕”。小明的电脑配置：“品牌：机械师,cpu：4核,固态硬盘：256G固态硬盘,机械硬盘1T普通硬盘,鼠标：机械师鼠标”。 5、类的继承 面向对象的编程带来的主要好处之一是代码的重用，实现这种重用的方法之一是通过继承机制。 通过继承创建的新类称为子类或派生类，被继承的类称为基类、父类或超类。 继承语法 12class 派生类名(基类名) ... 在python中继承中的一些特点： 1、如果在子类中需要父类的构造方法就需要显示的调用父类的构造方法，或者不重写父类的构造方法。详细说明可查看：python 子类继承父类构造函数说明。 2、在调用基类的方法时，需要加上基类的类名前缀，且需要带上 self 参数变量。区别在于类中调用普通函数时并不需要带上 self 参数 3、Python 总是首先查找对应类型的方法，如果它不能在派生类中找到对应的方法，它才开始到基类中逐个查找。（先在本类中查找调用的方法，找不到才去基类中找）。 如果在继承元组中列了一个以上的类，那么它就被称作&quot;多重继承&quot; 。 语法： 派生类的声明，与他们的父类类似，继承的基类列表跟在类名之后，如下所示： 12class SubClassName (ParentClass1[, ParentClass2, ...]): ... （1）例子 1234567891011121314151617181920212223242526class Parent: # 定义父类 parentAttr = 100 def __init__(self): print (\"调用父类构造函数\") def parentMethod(self): print('调用父类方法') def setAttr(self, attr): Parent.parentAttr = attr def getAttr(self): print (\"父类属性 :\", Parent.parentAttr)class Child(Parent): # 定义子类 def __init__(self): print (\"调用子类构造方法\") def childMethod(self): print ('调用子类方法')c = Child() # 实例化子类c.childMethod() # 调用子类的方法c.parentMethod() # 调用父类方法c.setAttr(200) # 再次调用父类的方法 - 设置属性值c.getAttr() # 再次调用父类的方法 - 获取属性值 输出结果如下： 1234调用子类构造方法调用子类方法调用父类方法父类属性 : 200 （2）例子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546\"\"\"小明和小红各自买了一台笔记本电脑,其中小明的电脑品牌是联想, CPU8核, 512G固态硬盘,双飞燕鼠标省红的电脑品牌是机械师, CPU4核, 256G固态硬盘+1T普通硬盘，机械师鼠标使用面向对象的思维，编写代码完成以 上描述。\"\"\"class Dn(): def __init__(self,brand,cpu,disk,mouse): self.nice_pp = brand self.nice_cpu = cpu self.nice_disk = disk self.nice_mouse = mouse # 继承:共享某个类的代码class XiaoMing(Dn): def __init__(self,brand,cpu,disk,mouse): super().__init__(brand,cpu,disk,mouse) def xgp(self,name): print(name + '的电脑配置：“' + '品牌：' + self.nice_pp + ',' + 'cpu：' +self.nice_cpu + ',' + '固态硬盘：' +self.nice_disk + ',' + '鼠标：' + self.nice_mouse + '”。')class XiaoHong(Dn): def __init__(self,brand,cpu,disk,sim_disk,mouse): self.sim_disk = sim_disk super() . __init__(brand,cpu,disk,mouse) def wsd(self,name): print(name + '的电脑配置：“' + '品牌：' + self.nice_pp + ',' + 'cpu：' + self.nice_cpu + ',' + '固态硬盘：' + self.nice_disk + ',' + '机械硬盘' + self.sim_disk + ',' + '鼠标：' + self.nice_mouse + '”。')xiaoming = XiaoMing('联想','8核','512固态硬盘','双飞燕')xiaoming.xgp('小明')xiaohong = XiaoHong('机械师','4核','256G固态硬盘','1T普通硬盘','机械师鼠标')xiaohong.wsd('小明') 输出结果如下： 12小明的电脑配置：“品牌：联想,cpu：8核,固态硬盘：512固态硬盘,鼠标：双飞燕”。小明的电脑配置：“品牌：机械师,cpu：4核,固态硬盘：256G固态硬盘,机械硬盘1T普通硬盘,鼠标：机械师鼠标”。 （3）方法重写（员工自我介绍） 如果你的父类方法的功能不能满足你的需求，你可以在子类重写你父类的方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Empoyee(): \"\"\"员工类\"\"\" def __init__(self,name,years_old,money): \"\"\"初始化普通员工属性\"\"\" self.user_name = name self.user_years_old = years_old self.user_money = money def say_hi(self): \"\"\"模拟员工自我介绍的方法\"\"\" print('我叫'+self.user_name +',工龄' + self.user_years_old +'年，年工资为' + self.user_money +'元。' )class SE(Empoyee): def __init__(self,name,years_old,money): super().__init__(name,years_old,money) def say_hi(self): \"\"\"模拟员工自我介绍的方法\"\"\" print('我叫'+self.user_name +',工龄' + self.user_years_old +'年，年工资为' + self.user_money +'元。' )class PM(Empoyee): def __init__(self,name,years_old,money,bonus): super().__init__(name,years_old,money) # 编写子类特有的属性 self.pm_bonus = bonus def say_hi(self): \"\"\"模拟项目经理自我介绍的方法\"\"\" print('我叫'+self.user_name +',工龄' + self.user_years_old +'年，月工资为' + self.user_money +'元，' + '管理奖金' + self.pm_bonus + '元。' )class CTO(Empoyee): def __init__(self,name,years_old,money,bonus,annual_bonus): super().__init__(name,years_old,money) self.cto_bonus = bonus self.cto_annual_bonus = annual_bonus def say_hi(self): \"\"\"模拟项目经理自我介绍的方法\"\"\" print('我叫'+self.user_name +',工龄' + self.user_years_old +'年，月工资为' + self.user_money +'元，' + '管理奖金' + self.cto_bonus + '元，' + '年终奖' + self.cto_annual_bonus + '元。' )# 使用类：实例化对象se = SE('xgp','4','8k')se.say_hi()pm = PM('wsd','6','10000','5000')pm.say_hi()cto = CTO('xgp','10','30000','6000','12000')cto.say_hi() 输出结果如下： 123我叫xgp,工龄4年，年工资为8k元。我叫wsd,工龄6年，月工资为10000元，管理奖金5000元。我叫xgp,工龄10年，月工资为30000元，管理奖金6000元，年终奖12000元。 分析以上代码 6、Python内置类属性 __dict__ : 类的属性（包含一个字典，由类的数据属性组成） ~ :类的文档字符串 __name__: 类名 __module__: 类定义所在的模块（类的全名是’__main__.className’，如果类位于一个导入模块mymod中，那么className.__module__ 等于 mymod） __bases__ : 类的所有父类构成元素（包含了一个由所有父类组成的元组） Python内置类属性调用实例如下： 1234567891011121314151617181920212223#!/usr/bin/python# -*- coding: UTF-8 -*- class Employee: '所有员工的基类' empCount = 0 def __init__(self, name, salary): self.name = name self.salary = salary Employee.empCount += 1 def displayCount(self): print \"Total Employee %d\" % Employee.empCount def displayEmployee(self): print \"Name : \", self.name, \", Salary: \", self.salary print \"Employee.__doc__:\", Employee.__doc__print \"Employee.__name__:\", Employee.__name__print \"Employee.__module__:\", Employee.__module__print \"Employee.__bases__:\", Employee.__bases__print \"Employee.__dict__:\", Employee.__dict__ 输出结果如下： 12345Employee.__doc__: 所有员工的基类Employee.__name__: EmployeeEmployee.__module__: __main__Employee.__bases__: ()Employee.__dict__: &#123;'__module__': '__main__', 'displayCount': &lt;function displayCount at 0x10a939c80&gt;, 'empCount': 0, 'displayEmployee': &lt;function displayEmployee at 0x10a93caa0&gt;, '__doc__': '\\xe6\\x89\\x80\\xe6\\x9c\\x89\\xe5\\x91\\x98\\xe5\\xb7\\xa5\\xe7\\x9a\\x84\\xe5\\x9f\\xba\\xe7\\xb1\\xbb', '__init__': &lt;function __init__ at 0x10a939578&gt;&#125; 7、python对象销毁(垃圾回收) Python 使用了引用计数这一简单技术来跟踪和回收垃圾。 在 Python 内部记录着所有使用中的对象各有多少引用。 一个内部跟踪变量，称为一个引用计数器。 当对象被创建时， 就创建了一个引用计数， 当这个对象不再需要时， 也就是说， 这个对象的引用计数变为0 时， 它被垃圾回收。但是回收不是&quot;立即&quot;的， 由解释器在适当的时机，将垃圾对象占用的内存空间回收。 1234567a = 40 # 创建对象 &lt;40&gt;b = a # 增加引用， &lt;40&gt; 的计数c = [b] # 增加引用. &lt;40&gt; 的计数del a # 减少引用 &lt;40&gt; 的计数b = 100 # 减少引用 &lt;40&gt; 的计数c[0] = -1 # 减少引用 &lt;40&gt; 的计数 垃圾回收机制不仅针对引用计数为0的对象，同样也可以处理循环引用的情况。循环引用指的是，两个对象相互引用，但是没有其他变量引用他们。这种情况下，仅使用引用计数是不够的。Python 的垃圾收集器实际上是一个引用计数器和一个循环垃圾收集器。作为引用计数的补充， 垃圾收集器也会留心被分配的总量很大（及未通过引用计数销毁的那些）的对象。 在这种情况下， 解释器会暂停下来， 试图清理所有未引用的循环。 实例 析构函数 __del__ ，__del__在对象销毁的时候被调用，当对象不再被使用时，__del__方法运行： 123456789101112131415161718#!/usr/bin/python# -*- coding: UTF-8 -*- class Point: def __init__( self, x=0, y=0): self.x = x self.y = y def __del__(self): class_name = self.__class__.__name__ print class_name, \"销毁\" pt1 = Point()pt2 = pt1pt3 = pt1print id(pt1), id(pt2), id(pt3) # 打印对象的iddel pt1del pt2del pt3 输出结果如下： 123083401324 3083401324 3083401324Point 销毁 **注意：**通常你需要在单独的文件中定义一个类 8、总结 参数的传递图，翻译与pythoncentral网 In 1 and 2, the arguments are passed to the method. 1和2参数传递给**init方法中的data参数**。 On 3, the self argument refers to the instance. 3****self 参数指向当前实例自身，self代表创建的实例变量 ik1 或者 Kls(‘arun’)。 At 4, we do not need to provide the instance to the method, as it is handled by the interpretor itself. 4 我们不需要传递实例自身给方法，Python解释器自己会做这些操作的；ik14 会自动作为第一个实例参数(self)传入方法中。","path":"posts/e939.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python练习题","text":"1、使用while实现：输出摄氏温度与华氏温度的对照表，要求它从摄氏温度0度到250度，每隔20度为一项，对照表中的条目不超过10条。 转换关系：华氏温度 = 摄氏温度 * 9 / 5.0 + 32 循环操作：计算摄氏温度，并输出对照条目 循环条件： 条目&lt;=10 &amp;&amp; 摄氏温度 &lt;= 250 12345678910def xgp(): t = 1 w = 0 while (t &lt;= 10 and w &lt;= 250): t = t + 1 w = w + 20 s = w*9/5.0+32 print(w,s,end=\" \") print()xgp() 输出结果如下： 1234567891020 68.0 40 104.0 60 140.0 80 176.0 100 212.0 120 248.0 140 284.0 160 320.0 180 356.0 200 392.0 2、输入一个4位数，如果各个数字之和大于20，则为幸运数。 123456789101112131415161718def sw(): num = int(input(\"请您输入四位数的号码：\")) print('您输入的是：'+str(num)) # 分解四位数，获取各位数字 # 获取个位数字 gw = num%10 # 获取十位数字 xw = int(num%100/10) # 获取百位数字 bw = int(num/1000%10) # 获取千位数字 qw = int(num/1000) # 求4个数值的和，并进行判断, 如果大于20, 则输出提示: 是幸运数 if (gw+xw+bw+qw) &gt; 20: print('是幸运数字！') else: print('谢谢参与')sw() 输出结果如下： 123请您输入四位数的号码：9999您输入的是：9999是幸运数字！ 3、编写程序，使用嵌套的if语句，为小飞制定学习计划，星期一、星期三、星期五学习编程，星期二、星期四、星期六学习英语，星期日休息。 12345678910111213141516171819202122232425def xuexi(): ss = input(\"今天是周几:\") for i in range(1,8): if ss == \"周一\": print(\"周1学习编程\") break elif ss == \"周二\": print(\"周2学习英语\") break elif ss == \"周三\": print(\"周3学习编程\") break elif ss == \"周四\": print(\"周4学习英语\") break elif ss == \"周五\": print(\"周5学习编程\") break elif ss == \"周六\": print(\"周6学习英语\") break elif ss == \"周日\": print(\"周日放假!!!\") breakxuexi() 输出结果如下： 12今天是周几:周一周1学习编程 4、编写一个计数器，能够根据提示输入两个操作数和运算符号，计算出结果。 1234567891011121314151617181920def num(): a = int(input(\"请输入第一个数:\")) fh = input(\"+,-,*,/,%:\") b = int(input(\"请输入第二个数:\")) if fh == \"+\": print(\"%s%s%s=%s\"%(a,fh,b,a+b)) elif fh == \"-\": print(\"%s%s%s=%s\"%(a,fh,b,a-b)) elif fh == \"*\": print(\"%s%s%s=%s\"%(a,fh,b,a*b)) elif fh == \"%\": print(\"%s%s%s=%s\"%(a,fh,b,a%b)) elif fh == \"/\": if b == 0: print(\"除数不能是0\") else: print(\"%s%s%s=%s\"%(a,fh,b,a/b)) else: print(\"输入符号有误\")num() 输出结果如下： 1234请输入第一个数:1+,-,*,/,%:+请输入第二个数:5951+595=596 5、猜拳游戏：预先定义一个数值，根据用户输入的数字，分别给出提示：“猜大了”或“猜小了”或“猜对了”，只有3次机会，否则退出程序。 1234567891011121314151617181920212223def cai(): import random a = random.randint(1,10) i = 0 while i &lt; 3: s = int(input(\"请您输入数字：\")) if s &gt; a: print(\"猜大了\") i += 1 elif s &lt; a: print(\"猜小了\") i += 1 else: print(\"恭喜你，答对了！\") break if i == 3: x = input(\"三次都没对，是否还猜？y/n：\") if x == 'y' or x == 'Y': i = 0 continue elif x == 'N' or x == 'n': breakcai() 输出结果如下： 123456789请您输入数字：5猜小了请您输入数字：8猜小了请您输入数字：10猜大了三次都没对，是否还猜？y/n：y请您输入数字：9恭喜你，答对了！ 6、跑马灯特效 12345678910111213import osimport timedef main(): content='免疫靠尿，戒严靠揍' while True: os.system('cls') print(content) time.sleep(0.2) content=content[1:]+content[0]if __name__ == '__main__': main() 输出结果如下： 12345678910 免疫靠尿，戒严靠揍 疫靠尿，戒严靠揍免 靠尿，戒严靠揍免疫 尿，戒严靠揍免疫靠 ，戒严靠揍免疫靠尿 戒严靠揍免疫靠尿， 严靠揍免疫靠尿，戒 靠揍免疫靠尿，戒严 揍免疫靠尿，戒严靠 免疫靠尿，戒严靠揍 7、某人准备去南方旅游，现在要订购机票。机票的价格受季节旺季、淡季的影响，头等舱和经济舱价格也不同。 假设机票原价为5000元，4~10月为旺季，旺季头等舱打9折，经济舱打8折；淡季头等舱打5折，经济舱打4折。 编写程序，使用嵌套的if语句，根据出行的月份和选择的舱位输出实际的机票价格。 1234567891011121314151617def hxq(): wj = [4,5,6,7,8,9,10] y = int(input(\"你打算购买几月份的机票呢?\")) c = input(\"你打算坐头等舱还是经济舱呢?\") if y in wj: if c == \"头等舱\": print(\"请您支付:\" + str(5000 * 0.9) + \"元\") if c == \"经济舱\": print(\"请您支付:\" + str(5000 * 0.8) + \"元\") elif y not in wj and(y &gt; 3 and y &lt; 11): if c == \"头等舱\": print(\"请您支付:\" + str(5000 * 0.5) + \"元\") if c == \"经济舱\": print(\"请您支付:\" + str(5000 * 0.4) + \"元\") else: print(\"请输入正确的月份\")hxq() 输出结果如下： 123你打算购买几月份的机票呢?6你打算坐头等舱还是经济舱呢?经济舱请您支付:4000.0元 8、学生管理系统 必须使用自定义函数，完成对程序的模块化 学生信息至少包含：姓名、年龄、地址，除此以外可以适当添加 必须完成的功能：添加、删除、修改、查询、退出 （1）设置函数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# 新建一个列表，用来保存学生所有信息。card_info = []# 添加def add(): \"\"\"添加名片的方法\"\"\" # 插入一张新名片的功能 # 定义全局变量 global card_info newName = input(\"请输入新的学生名字：\") newSex = input(\"请输入新的学生性别(男/女)：\") newPhone = input(\"请输入新的学生电话：\") # 定义新的字典，存储新名片信息 newInfo = &#123;&#125; newInfo[\"name\"] = newName newInfo[\"sex\"] = newSex newInfo[\"phone\"] = newPhone # 把输入的新名片添加到列表中 card_info.append(newInfo)# 删除def delete(info): delNum = int(input(\"请输入要删除的序号：\")) - 1 del info[delNum]# 修改def modify(): studentId = int(input(\"请输入要修改的序号：\")) - 1 newName = input(\"请输入新的学生名字：\") newSex = input(\"请输入新的学生性别(男/女)：\") newPhone = input(\"请输入新的学生电话：\") newInfo = &#123;&#125; newInfo[\"name\"] = newName newInfo[\"sex\"] = newSex newInfo[\"phone\"] = newPhone card_info[studentId] = newInfo# 查询def query(): \"\"\"查找名片是否存在\"\"\" flag = 0 # 默认为0表示没有此人，1表示有此人 # 请输入要查询的姓名 find_name = input(\"请您输入要查询的姓名:\") for card in card_info : if find_name == card[\"name\"]: print(\"%s\\t%s\\t%s\"%(card[\"name\"],card[\"sex\"],card[\"phone\"])) flag = 1 break #查到了的话就不查了 if flag == 0 : print(\"查无此人\")# 遍历def ergodic(): print(\"=\" * 30) print(\"学生信息如下\") print(\"=\" * 30) print(\"序号 姓名 性别 手机号\") num = 1 for tempInfo in card_info: print(\" %d %s %s %s\" % (num, tempInfo[\"name\"], tempInfo[\"sex\"], tempInfo[\"phone\"])) num += 1# 操作菜单def show_menua(): print('-------------------------学生信息管理系统----------------------') print('1、添加 2、删除 3、修改 4、查询 5、遍历 0、退出') print('--------------------------------------------------------------') （2）调用函数 123456789101112131415161718192021222324252627282930313233# 测试学生管理系统的功能# from student_ sys. CMS import *import python函数.mokuai.学生管理系统.xs as studef main(): while 1 == 1: # 显示操作菜单 stu.show_menua() # 用户操作 key = int(input('请选择:[0、1、2、3、4、5]：')) if key == 1: stu.add() elif key == 2: stu.delete(card_info) elif key == 3: stu.modify() elif key == 4: stu.query() elif key == 5: stu.ergodic() elif key == 0: exit = input(\"真的要退出系统吗？(Yes or No)：\") if exit == \"Yes\": break elif exit == \"No\": pass else: print(\"输入有误，请重新输入\") else: print(\"输入有误，请重新输入\")# 调用主函数，运行程序main() 输出结果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 添加-------------------------学生信息管理系统----------------------1、添加 2、删除 3、修改 4、查询 5、遍历 0、退出--------------------------------------------------------------请选择:[0、1、2、3、4、5]：1请输入新的学生名字：xgp请输入新的学生性别(男/女)：男请输入新的学生电话：17634984710# 遍历-------------------------学生信息管理系统----------------------1、添加 2、删除 3、修改 4、查询 5、遍历 0、退出--------------------------------------------------------------请选择:[0、1、2、3、4、5]：5==============================学生信息如下==============================序号 姓名 性别 手机号 1 xgp 男 17634984710 # 查询-------------------------学生信息管理系统----------------------1、添加 2、删除 3、修改 4、查询 5、遍历 0、退出--------------------------------------------------------------请选择:[0、1、2、3、4、5]：4请您输入要查询的姓名:xgpxgp 男 17634984710# 修改-------------------------学生信息管理系统----------------------1、添加 2、删除 3、修改 4、查询 5、遍历 0、退出--------------------------------------------------------------请选择:[0、1、2、3、4、5]：3请输入要修改的序号：1请输入新的学生名字：wsd请输入新的学生性别(男/女)：男请输入新的学生电话：17634984720# 删除-------------------------学生信息管理系统----------------------1、添加 2、删除 3、修改 4、查询 5、遍历 0、退出--------------------------------------------------------------请选择:[0、1、2、3、4、5]：2请输入要删除的序号：1","path":"posts/d262.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"自定义函数","text":"一、PyCharm基本设置 1、用Ctrl+鼠标滚轮–放大或缩小字体 搜索zoom 2、在Windows资源管理器打开文件或目录 搜索keymap 设置成不常用的键即可，如F3。 3、代码提示 搜索letter 二、自定义函数 ![image-20200319144955045](G:\\四期\\python\\python文档\\7 .assets\\image-20200319144955045.png) 1.为什么要使用函数 函数中的代码一次编写,多处运行; 函数可以让代码复用，减少代码冗余。 函数是组织好的，可重复使用的，用来实现单一，或相关联功能的代码段。 函数能提高应用的模块性，和代码的重复利用率。你已经知道Python提供了许多内建函数，比如print()。但你也可以自己创建函数，这被叫做用户自定义函数。 假设我有这样的需求： 但是我还是觉得太麻烦了，每次想吃饭的时候都要重复这样的步骤。此时，我希望有这样的机器： 将重复的工作封装到一起，我们只要向机器里放入东西，就能得到我们想要的。 这也就是所谓的代码重用。 例子 123456789101112131415161718# 定义方法def print_nums(): \"\"\"此处是函数功能的描述\"\"\" for i in range(1,11): print(i,end=\" \")# 1.三角形 2.正方形 3.梯形key = int(input('请输入要打印的图形：'))if key == 1: # 打印三角形的代码 print_nums() passelif key == 2: # 打印梯形的代码 passelif key == 3: # 正方形的代码 pass 输出结果如下： 123请输入要打印的图形：11 2 3 4 5 6 7 8 9 10 进程已结束，退出代码 0 分析一下 2、定义函数 你可以定义一个由自己想要功能的函数，以下是简单的规则： 关键字: def 函数代码块以 def 关键词开头，后接函数标识符名称和圆括号()，结尾处有冒号。 函数内第一行通常书写注释,表名该函数的意义 注释后空一行,开始写代码块，代码库要缩进 任何传入参数和自变量必须放在圆括号中间。圆括号之间可以用于定义参数。 函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。 函数内容以冒号起始，并且缩进。 return [表达式] 结束函数，选择性地返回一个值给调用方。不带表达式的return相当于返回 None。 函数结束后,空2行 函数调用后空1行,再执行别的代码 语法 12345#代码如下def functionname( parameters ): \"函数_文档字符串\" function_suite return [expression] 默认情况下，参数值和参数名称是按函数声明中定义的的顺序匹配起来的。 三、函数类型 Python函数可以使用的参数类型： 必备参数 命名参数 缺省参数 不定长参数 参数类型： ​ 1、位置参数:参数的位置(顺序)很重要，形参和实参个数要匹配 ​ 2、关键字参数:对参数的位置要求不是很严格 ​ 3、默认值参数: ​ (1)如果形参中指定了默认值,在实参中可以不传递该形参对应的实参 ​ (2)如果形参中指定了默认值，在实参汇总传递该参数后，最终参数以传递的实参为准 ​ 4、不定长参数： ​ (1)*a：接收传递单个值,保存为元组 ​ (2)**b：接收键值对形式的参数，保存为字典格式 1、无参函数 无参函数实现和调用： 12345678# 定义无参函数def say_hi(): \"\"\"介绍自己的函数\"\"\" print('我是xgp，今年18岁，年收入xxxx元')# 调用无参函数say_hi() 输出结果如下： 123我是xgp，今年18岁，年收入xxxx元进程已结束，退出代码 0 2、带参函数 下面说说带参数的函数： 形参：指的是形式参数，是虚拟的，不占用内存空间，形参单元只有被调用的时才分配内存单元 实参：指的是实际参数，是一个变量，占用内存空间，数据传递单向，实参传给形参，形参不能传给实参 例子 12345678# 定义带参函数：形参（形式参数，模板）def say_hi(name,age,money): \"\"\"介绍自己的函数\"\"\" print('我是'+name+'，今年'+str(age)+'岁，年收入'+str(money)+'元。')# 调用带参函数：实参（实际传递的参数）say_hi('xgp',20,20000) 输出结果如下： 123我是xgp，今年20岁，年收入20000元。进程已结束，退出代码 0 注意事项:调用函数时,实参传递的个数 要与形参保持一致| （1）位置参数 从上面的例子可以看出，实际参数和形式参数是一一对应的，如果调换位置，x和y被调用的时，位置也会互换，代码如下： 123456789101112131415def test(x,y): print(x) print(y)print(\"--------互换前-----\")test(1,2)print(\"--------互换后-----\")test(2,1) #输出--------互换前-----12--------互换后-----21 因为定义x,y两个形参，所以传递实参的时候，也只能传递两个实参，多一个或少一个都是有问题的： a：多传递一个参数 123456789101112def test(x,y): print(x) print(y)print(\"--------多一个参数----\")test(1,2,3) #输出--------多一个参数----Traceback (most recent call last): File \"D:/PycharmProjects/pyhomework/day3/函数_带参数.py\", line 8, in &lt;module&gt; test(1,2,3)TypeError: test() takes 2 positional arguments but 3 were given #test()函数需要传两个实参，你传了三个实参 b：少传递一个实参 12345678910111213def test(x,y): print(x) print(y)print(\"--------少一个参数----\")test(1) #输出--------少一个参数----Traceback (most recent call last): File \"D:/PycharmProjects/pyhomework/day3/函数_带参数.py\", line 8, in &lt;module&gt; test(1)TypeError: test() missing 1 required positional argument: 'y' #没有给y参数传实参 （2）关键字参数 上面的位置参数，看起来有点死，必须形参和实参的位置一一对应，不然就会传错参数，为了避免这种问题，就有了关键字参数的玩法：关键字传参不需要一一对应，只需要你指定你的哪个形参调用哪一个实参即可； 12345678910111213141516def test(x,y): print(x) print(y) print(\"--------互换前------\")test(x=1,y=2)print(\"--------互换后------\")test(y=2,x=1) #输出--------互换前------12--------互换后------12 3、默认参数 调用函数时，默认参数的值如果没有传入，则被认为是默认值。下例会打印默认的age，如果age没有被传入： 12345678910111213#!/usr/bin/python# -*- coding: UTF-8 -*- #可写函数说明def printinfo( name, age =35 ): \"打印任何传入的字符串\" print \"Name: \", name print \"Age \", age return #调用printinfo函数printinfo( age=50, name=\"miki\" )printinfo( name=\"miki\" ) 输出结果如下： 1234Name: mikiAge 50Name: mikiAge 35 4、不定长参数 你可能需要一个函数能处理比当初声明时更多的参数。这些参数叫做不定长参数，和上述2种参数不同，声明时不会命名。基本语法如下： 1234def functionname([formal_args,] *var_args_tuple ): \"函数_文档字符串\" function_suite return [expression] 加了星号（*）的变量名会存放所有未命名的变量参数。不定长参数实例如下： 123456789101112131415#!/usr/bin/python# -*- coding: UTF-8 -*- # 可写函数说明def printinfo( arg1, *vartuple ): \"打印任何传入的参数\" print \"输出: \" print arg1 for var in vartuple: print var return # 调用printinfo 函数printinfo( 10 )printinfo( 70, 60, 50 ) 输出结果如下： 123456输出:10输出:706050 （1）例子 123456# 不定长参数的类型def no_test(*args,**b): print((args)) print(b)no_test(1,2,3)no_test(name='test',ages=18) 输出结果如下： 1234(1, 2, 3)&#123;&#125;()&#123;'name': 'test', 'ages': 18&#125; 5、匿名函数 python 使用 lambda 来创建匿名函数。 lambda只是一个表达式，函数体比def简单很多。 lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。 lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数。 虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。 语法 lambda函数的语法只包含一个语句，如下： 1lambda [arg1 [,arg2,.....argn]]:expression 如下实例： 12相加后的值为 : 30相加后的值为 : 40 四、rerun传递列表类型数据 return语句[表达式]退出函数，选择性地向调用方返回一个表达式。不带参数值的return语句返回None。之前的例子都没有示范如何返回数值，下例便告诉你怎么做： 123456789101112#!/usr/bin/python# -*- coding: UTF-8 -*- # 可写函数说明def sum( arg1, arg2 ): # 返回2个参数的和.\" total = arg1 + arg2 print \"函数内 : \", total return total # 调用sum函数total = sum( 10, 20 ) 输出结果如下： 1函数内 : 30 注意：在函数内没有写return语句的时候，默认return的是一个空对象。也就是就算没写，python内部也做了处理。 此时，有部分人分不清函数的输出和返回值的区别。 这样说吧，在函数里print之类的操作能够输出内容，是因为虽然函数的执行环境是独立的，但代码还是有效的。外部能进行的操作，函数内部也可以。但是并不是所有的函数在执行完毕后都有如此明显的输出效果，此时我们需要查看函数是否成功，或者说我放了米进去，你操作一番之后总要把饭给我拿出来吧。 这就是函数中return的意义。返回一个对象。这个对象可以是对执行状态的说明，也可以是处理后的结果等等。 1、return语句返回简单类型 12345678910def test(): return 'hello'print(test())# return 语句返回字典def show_info(name,age): person = &#123;'name':name,'age':age&#125; return personprint(show_info('test',18)) 输出结果如下： 1234hello&#123;'name': 'test', 'age': 18&#125;进程已结束，退出代码 0 2、用户问候 1234567891011121314151617def say_hi(first_name,last_name): \"\"\"返回完整名字\"\"\" full_name = first_name + ' ' + last_name return full_namewhile True: print('请输入您的姓名:') f_name = input('姓：') if f_name =='q': break l_name = input('名：') if l_name == 'q': break # 调用函数 format_name = say_hi(f_name,l_name) print('hello'+format_name+'!') 输出结果如下： 1234请输入您的姓名:姓：x名：gphellox gp! 3、传递列表类型数据 12345def test(names): for name in names: print(name)user_name = ['sdf','fsd','fewfwef','fwefe']test(user_name) 输出结果如下： 123456sdffsdfewfweffwefe进程已结束，退出代码 0 5、range函数的练习 当只用一个变量调用这个函数时，这个变量指的是输出的等差数列的终点，如range(5) 当给定两个变量时，分别指输出的起始值和终点,，如range(2, 5) 当给定三个变量时，在上一条的基础上第三个变量指输出时的步长，如range(2, 5, -1) （假定我们调用这个函数时总是用整数或浮点数） 分析一下如何实现这个函数，下面给出我的思路作为参考 一共需要三个参数是显而易见的； 最直观的感受是起始值是要有默认值的，如果不规定从哪里开始，那就从0开始； 步长也是要有默认值的，如果不规定，那么步长是1； 根据有默认值的参数要放在后面的原则，那么最理所当然的参数设计是range_custom(stop, start=0, step=1) 这个方案看上去可行，但是不满足刚才的后面两个要求，如果我们这样用两个变量调用，起始值和终点是反的； 我们加个判断就可以了，如果start用了初始值，那么说明我们调用的时候只给了一个参数，这个时候stop就是终点，如果start被重新赋值了说明给了至少两个参数，那么这时候把stop和start的值调换一下就可以了； 现在这个函数似乎可以满足大多数情况了，但是有一个bug，如果给定参数的时候给的start值就是0怎么办呢？如range_custom(-5, 0)按目前的规则会被翻译成range(0, -5)，但是我们的目的却是range(-5, 0)； 所以start的初始值不应该是数字而是别的数据类型，为了方便起见，我们把它的初始值赋为None，我们的程序雏形就出来了。 1234def range_custom(stop, start=None, step=1): if start is None: return range(stop) return range(stop, start, step) 现在这个程序已经满足我们的要求了，但是看上去不太舒服，可以改成 1234def range_custom(start, stop=None, step=1): if stop is None: return range(start) return range(start, stop, step) 现在这个函数的参数顺序在逻辑上更好理解一些，可以说基本上满足我们的要求了。当然，本例只是为了说明参数的顺序问题，并不是为了实现range函数。事实上Python的range函数还包括参数实例化，生成器等知识，在后面我们应该还有机会再接触它。 可选参数 说到可选参数，可能有的人见过，却也不明白到底是什么意思，它一般是这样出现的 12def func_option(*args): return args 注意到我们声明函数的时候在参数名前加了个*星号，这是声明可选参数的方法。那么可选参数到底有什么用呢？ 可选参数的作用是用元组把所有多余的变量收集起来，这个元组的名字就是这个可选参数名。在上例func_option中我们可以用任意多个变量调用它，比如a = func_option(1, 2, 3)那么a就会是元组(1, 2, 3)。关于为什么是元组而不是列表，我们在上一篇Python进阶-简单数据结构中说过，元组在Python中往往是比列表更优先考虑使用的数据结构，具体原因在本文靠后深入自定义函数参数部分会讨论。 我们刚才说可选参数会收集多余的变量。我这么说是有原因的。 123456789&gt;&gt;&gt; def func_option(a, *args, c=2):... return args...&gt;&gt;&gt; func_option2(1)()&gt;&gt;&gt; func_option2(1, 2)(2,)&gt;&gt;&gt; func_option2(1, 2, 3)(2, 3) 注意到我们的*args把除了给普通参数的第一个变量以外的值都放进了元组中。这样做导致了一个，问题在于我们的有默认值的参数如果不给定参数名地调用的话，就永远只能用默认值了。而且如果我们在调用函数时不把有默认值的参数放在最后面程序还会报错。 123&gt;&gt;&gt; func_option2(c=1, 2, 3) File \"&lt;stdin&gt;\", line 1SyntaxError: positional argument follows keyword argument 那么有没有好的办法能规避这个问题呢？我们可以试试把可选参数放在有默认值的参数后面。 123456789101112&gt;&gt;&gt; def func_option3(a, c=2, *args):... return args...&gt;&gt;&gt; func_option3(1)()&gt;&gt;&gt; func_option3(1, 2)()&gt;&gt;&gt; func_option3(1, 2, 3)(3,)&gt;&gt;&gt; func_option2(c=1, 2, 3) File \"&lt;stdin&gt;\", line 1SyntaxError: positional argument follows keyword argument 那么这种形式的函数能不能解决之前的问题呢。看上去不行，不过我们知道了，调用函数的时候，要尽量把有默认值的参数放在靠后的位置赋予变量。那么这两种我们到底该用哪个方法呢？在实际操作中，我们倾向于将可选参数放在有默认值的参数之后，而且如果参数较多，我们倾向于调用函数时都会所有变量都加上参数名。而且实际操作中，其实可选参数用得不那么多，相对来说，另一种可选参数其实用得更多。这种可选参数的形式一般是这样 12def func_optionkw(**kwargs): return args 在这种情况下，关键字可选参数都是作为键值对保存在参数名的的字典中。也就是说，在调用函数时，在满足一般参数以后，变量都应该以赋值语句的形式给出，等号左边作为键右边作为值。如果不这样做，就会报错了。 1234&gt;&gt;&gt; func_optionkw(3)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: t2() takes 0 positional arguments but 1 was given 需要说明的是，一个自定义函数只能有一个可选参数，同时也可以有至多一个关键字参数。其中关键字参数应该放在普通可选参数之后。 现在我们来总结一下函数参数顺序一般规律： 一般参数放在最前面 可选参数放在最后面 关键字可选参数放在一般可选参数后面 函数调用时尽量把有默认值的参数对应的变量放在靠后的位置 如果参数比较多，调用函数时，最好所有变量都指明参数名 以上这些，有的是为了防止函数定义时出错，有的是为了防止函数调用时出错，总之，应该养成良好的编程习惯。 五、变量作用域 一个程序的所有的变量并不是在哪个位置都可以访问的。访问权限决定于这个变量是在哪里赋值的。 变量的作用域决定了在哪一部分程序你可以访问哪个特定的变量名称。两种最基本的变量作用域如下： 全局变量 局部变量 六、全局变量和局部变量 定义在函数内部的变量拥有一个局部作用域，定义在函数外的拥有全局作用域。 局部变量只能在其被声明的函数内部访问，而全局变量可以在整个程序范围内访问。调用函数时，所有在函数内声明的变量名称都将被加入到作用域中。如下实例： 实例(Python 2.0+) 1234567891011121314#!/usr/bin/python# -*- coding: UTF-8 -*- total = 0 # 这是一个全局变量# 可写函数说明def sum( arg1, arg2 ): #返回2个参数的和.\" total = arg1 + arg2 # total在这里是局部变量. print \"函数内是局部变量 : \", total return total #调用sum函数sum( 10, 20 )print \"函数外是全局变量 : \", total 输出结果如下： 12函数内是局部变量 : 30函数外是全局变量 : 0","path":"posts/a148.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"PyCharm和JDK安装与配置","text":"一、PyCharm安装与配置 PyCharm 是一款功能强大的 Python 编辑器，具有跨平台性，鉴于目前最新版 PyCharm 使用教程较少，为了节约时间，来介绍一下 PyCharm 在 Windows下是如何安装的。 这是 PyCharm 的下载地址：http://www.jetbrains.com/pycharm/download/#section=windows 进入该网站后，我们会看到如下界面: professional 表示专业版，community 是社区版，推荐安装社区版，因为是免费使用的。 1、安装 双击安装包，点击next。 修改安装路径，我这里放的是D盘，点击“Browse…”修改好以后点击Next。 我们可以根据自己的电脑选择32位还是64位，目前应该基本都是64位系统。 点击“Install”进行安装。 点击“Finish”结束安装。 2、破解 破解工具如下。 将其复制到PyCharm安装目录下的lib目录，选中该文件，按住shift键的同时单击鼠标右键，选择“复制为路径”。 切换到bin目录，用记事本打开如下文件。 在文件中添加如下内容，其中-javaagent:后面是破解文件的路径，但是必须去掉双引号。 -javaagent:E:\\jetbrains-agent.jar 保存该文件后打开PyCharm主程序，如果以前安装过PyCharm，那么可以使用之前的配置信息；反之的话点击“Do not import settings”，不导入配置信息。 点击“OK”，将打开程序主页。 3、创建第一个Python项目 点击“Create New Project”开始创建项目。 选择项目保存的路径，配置开发环境（不同的项目可能用到的Python库不同，此处的配置就是为了满足不同功能的项目需求），并且选择Python代码解释器，点击“Create”完成项目创建。 4、编写python文件 在项目根目录下创建一个目录（暂时不是必须的），如：demo。 输入demo。 在demo目录下再新建python文件。 输入文件名，如hello，生成一个hello.py文件。 输入如下语句。 右键点击“Run ‘hello’”，在控制台输出结果。 ​ 至此，第一个python文件就完成了。 二、JDK安装与配置 1、下载JDK ​ 搜索“jdk官方下载”或是直接进入Sun公司的官网（https://www.oracle.com/） ​ 下拉到页尾，点击“Download Java for Developers”，进入Java开发的下载页面 ​ 可以自行选择需要下载的java SE、java EE和Java ME的相应版本进行下载，我的电脑是32位的，所以我下载的是java SE的 jdk-8u161(如下图) 该页面还有各种相关介绍和开发说明，大家有需要的话，可以自行按需下载。 注：进入下载列表，选择所需下载的文件前，记得勾选列表标题下的 Accept License Agreement（此处默认是 Decline License Agreement），否则会不允许下载的。 2、安装 ​ 下载完成后就可以进行安装了。 ![img](file:///C:/Users/huawei/AppData/Local/Temp/msohtmlclip1/01/clip_image022.jpg) ​ 至此，jdk安装完成。 3、配置环境变量 安装好的jdk需要进行环境变量的配置。 我使用的是Win10的系统，“此电脑/计算机”右键 “属性”，进入“高级系统设置” 然后进入“环境变量”的设置，新建所需的环境变量（记得要在“系统变量”里面创建） （1）新建 JAVA_HOME 变量** ![img](file:///C:/Users/huawei/AppData/Local/Temp/msohtmlclip1/01/clip_image030.jpg) （2）找到Path变量进行编辑，将“%JAVA_HOME%\\bin”和“%JAVA_HOME%\\jre”加入Path的变量值中** ![https://img-blog.csdn.net/20180414194425415](file:///C:/Users/huawei/AppData/Local/Temp/msohtmlclip1/01/clip_image032.png) （3）每次编辑完“环境变量”，都要点击“确定”加以保存，否则，你所“新建/编辑”的环境变量都是无效的 ![https://img-blog.csdn.net/20180414194704411](file:///C:/Users/huawei/AppData/Local/Temp/msohtmlclip1/01/clip_image037.png) ​ 这样，jdk的环境变量就配置好了。 4、测试 ​ 安装好jdk，并配置好环境变量后，可以通过cmd命令进行测试，是否安装并配置正确。 （1） 在“开始”菜单栏键入 cmd，回车后打开cmd窗口； （2）输入 Java，回车，显示出 java 的相关信息；键入 Javac + 回车，显示出 Java 编译的相关信息，即表示安装并配置成功 （3）说明：若想查看所安装jdk的版本信息，可在cmd窗口键入&quot;java -version&quot;（大小写没影响的）。 ![img](file:///C:/Users/huawei/AppData/Local/Temp/msohtmlclip1/01/clip_image042.jpg)****","path":"posts/2b21.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python的input和while循环","text":"python的input和while使用 一、Python input()函数：获取用户输入的字符串 Python3.x 中 input() 函数接受一个标准输入数据，返回为 string 类型。 Python2.x 中 input() 相等于 eval(raw_input(prompt))，用来获取控制台的输入。 raw_input() 将所有输入作为字符串看待，返回字符串类型。而 input() 在对待纯数字输入时具有自己的特性，它返回所输入的数字的类型（ int, float ）。 注意：input() 和 raw_input() 这两个函数均能接收 字符串 ，但 raw_input() 直接读取控制台的输入（任何类型的输入它都可以接收）。而对于 input() ，它希望能够读取一个合法的 python 表达式，即你输入字符串的时候必须使用引号将它括起来，否则它会引发一个 SyntaxError 。 除非对 input() 有特别需要，否则一般情况下我们都是推荐使用 raw_input() 来与用户交互。 注意：python3 里 input() 默认接收到的是 str 类型。 函数语法 1input([prompt]) 参数说明： prompt: 提示信息 解决问题： input 得到的数据到底是什么类型 多个参数接收input的输入，是怎么解包的 如果输入的个数不确定，怎么处理 要判断输入的是不是float 类型 要对输入的参数格式输出，规定参数只能是str或者int 或者float类型 1、例子 1234# 用户输入# 提示输入内容pet = input ('请输入您最喜欢的宠物名称：')print(pet) 输出结果如下： 12请输入您最喜欢的宠物名称：猫咪猫咪 2、吉祥号码 在python 3 里，一切input的得到的东西，都是str类型（可用type()查看类型） 123good_luck_num = input('请输入你的吉祥号码：')print(type(good_luck_num))print('您输入的是：'+good_luck_num) 输出结果如下： 123请输入你的吉祥号码：9898998&lt;class 'str'&gt;您输入的是：9898998 在python2 里 有input 和raw_input raw_input 得到的都是str类型 input 会根据输入数据的类型自动生成类型 我们可以使用 Python 内置函数将字符串转换成想要的类型，比如： int(string) 将字符串转换成 int 类型； float(string) 将字符串转换成 float 类型； bool(string) 将字符串转换成 bool 类型。 3、超市选物 123456789101112131415print('---------超市购物系统---------')print('1.电子产品 2.化妆品 3.生活用品 4.书籍')# print('请选择您要购买的产品类型：')product_type = input('请选择您要购买的产品类型:')# 判断输入的序号if product_type == '1': print('电子产品')elif product_type =='2': print('化妆品')elif product_type =='3': print('生活用品')elif product_type =='4': print('书籍')else: print('只能输入1~4的数字') 输出结果如下： 1234---------超市购物系统---------1.电子产品 2.化妆品 3.生活用品 4.书籍请选择您要购买的产品类型:4书籍 4、小练习 （1）编写一个程序，询问用户最喜欢的IT从业岗位，并输出一条信息，如：“我最喜欢的岗位是Python自动化运维。” 12gz = input('您最喜欢的IT从业岗位：')print('我最喜欢的岗位是'+gz) 输出结果如下： 12您最喜欢的IT从业岗位：Python自动化运维我最喜欢的岗位是Python自动化运维 （2）编写一个程序，询问学生今天的作业完成了吗？如果输入“y”，则输出“今天的作业完成了”；如果输入“no”，则输出“今天的作业还需要一段时间才能完成。” 12345zy = input('今天的作业完成了吗？：（y/n）')if zy == 'y': print('今天的作业完成了')elif zy == 'n': print('今天的作业还需要一段时间才能完成') 输出结果如下： 12今天的作业完成了吗？：（y/n）y今天的作业完成了 （3）让用户输入一个三位数，输出这个数是不是回文数。 1234567num = input('输入一个三位数')num2 = num[::-1]print(num2)if num == num2: print('这是个回文数')elif num != num2: print('这是个普通数字') 输出结果如下： 123输入一个三位数121121这是个回文数 二、Python While 循环语句 Python 编程中 while 语句用于循环执行程序，即在某条件下，循环执行某段程序，以处理需要重复处理的相同任务。其基本形式为： 12while 判断条件(condition)： 执行语句(statements)…… 执行语句可以是单个语句或语句块。判断条件可以是任何表达式，任何非零、或非空（null）的值均为true。 当判断条件假 false 时，循环结束。 执行流程图如下： Gif 演示 Python while 语句执行过程 复杂一点: 1、例子：(while循环：如果这件事情是重复性的去做的) 1234num = 1while num&lt;10: print(num,end=\" \") num = num+1 输出结果如下： 11 2 3 4 5 6 7 8 9 2、使用while循环，计算1-100之间偶数之和。 12345678910#创建一个变量x初始化为2x = 2#创建一个变量sum初始化为0sum = 0#使用while循环求出0-100所有偶数的和while x &lt;= 100 : sum += x x += 2#打印输出求和结果print(sum) 输出结果如下： 12550 3、编写一个程序，模拟用户登录，验证用户名和密码，最大输入次数为3次，否则锁定用户。 1234567891011121314151617count = 3users= 'xgp'password= '123.com'i = 3while i &gt; 0 and i &lt; 4: # 输入提示 user = input('请输入您的用户名：') passwd = input('请输入您的密码：') # 判断用户名和密码 if user == users and passwd == password: print('登陆成功') break else: # 登陆统计次数 i = i - 1 if i == 0: print('账号锁定') 1234567891011相比较上面的简单一点count = 3while count&gt;0: name = input('请输入用户名：') password = input('请输入密码：') if name == 'xgp' and password == '123.com': print('通过验证，即将登陆......') break else: count = count - 1 print('还剩'+str(count)+\"次机会\") 输出结果(1)： 1234567请输入您的用户名：1请输入您的密码：1请输入您的用户名：1请输入您的密码：1请输入您的用户名：1请输入您的密码：1账号锁定 输出结果(2)： 123请输入您的用户名：xgp请输入您的密码：123.com登陆成功 三、while循环处理列表和字典 for循环是一种遍历列表的有效方式，但在for循环中不应修改列表，否则将导致Python难以跟踪其中的元素。要在遍历列表的同时对其进行修改，可使用while循环。 通过将while循环同列表和字典结合起来使用，可收集、存储并组织大量输出，供以后查看和显示。 1、类似列表复制 12345678users = ['alpha','byta','gima']users_shadow = []while users: current_user = users.pop() users_shadow.append(current_user)print(users_shadow) 输出结果如下： 1['gima', 'byta', 'alpha'] for循环复制 123for i in users: users_shdow.append(i)print(users_shadow) 输出结果如下： 1['gima', 'byta', 'alpha'] 2、删除列表当中的指定元素 12345users = ['alpha','byta','gima']print(users)while 'byta' in users: users.remove('byta')print(users) 输出结果如下： 12['alpha', 'byta', 'gima']['alpha', 'gima'] 3、创建一个调查程序，每次循环的时候，提示输入接受调查的名字和回答，将这个收集到的数据存储到一个字典中 123456789101112131415161718192021222324# 创建一个空字典responses = &#123;&#125;# 设置标志：表示调查是否继续flag = True# 循环操作while flag: #提示输入接受调查的名字和回答 name = input('请输入您的名字：') response = input('清输入您的答案：') # 将答案存储到字典中 responses[name] = response # 是否还有人需要参加调查 repeat = input('是否还有人需要参加调查：(yes/no)') if repeat == 'no': flag = False# 显示调查结果print('\\n-------------------调查结果-------------------')for name,response in responses.items(): print(name + \"&gt;&gt;&gt;\" + response) 输出结果如下： 12345678910请输入您的名字：wsd清输入您的答案：123是否还有人需要参加调查：(yes/no)yes请输入您的名字：wushaox清输入您的答案：x是否还有人需要参加调查：(yes/no)no-------------------调查结果-------------------wsd&gt;&gt;&gt;123wushaox&gt;&gt;&gt;x","path":"posts/7b33.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python 字典","text":"一、Python 字典(Dictionary) 字典是另一种可变容器模型，且可存储任意类型对象。 字典的每个键值 key=&gt;value 对用冒号 : 分割，每个键值对之间用逗号 , 分割，整个字典包括在花括号 {} 中 ,格式如下所示： 1d = &#123;key1 : value1, key2 : value2 &#125; 键一般是唯一的，如果重复最后的一个键值对会替换前面的，值不需要唯一。 12345&gt;&gt;&gt;dict = &#123;'a': 1, 'b': 2, 'b': '3'&#125;&gt;&gt;&gt; dict['b']'3'&gt;&gt;&gt; dict&#123;'a': 1, 'b': '3'&#125; 值可以取任何数据类型，但键必须是不可变的，如字符串，数字或元组。 1、例子 1234567891011121314# python的数据类型：字典# 数据类型与变量关联name = 'bily'num = 89key = 88.8list = [3,4,5,6]tuple = (6,4,68)# 字典的例子：键和值dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;print(dict)dict1=&#123;1:101,2:102&#125;print(dict1) 以上实例输出结果： 12&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125;&#123;1: 101, 2: 102&#125; 表和元组直接写入值即可，而字典需要键和值皆有。 2、简单的字典的操作 1234567891011121314151617181920212223# 定义一个字典dict2 = &#123; '河北':'石家庄', '甘肃':'兰州', '四川':'成都'&#125;print（dict2）# 对字典进行访问（取值）==&gt; 值=字典的名称[键]sjz = dict2['河北']print(sjz)# 添加字典的数据（键值对）dict2['山西']='太原'print(dict2)# 修改字典的值dict2['河北']='邢台'print(dict2)# 删除字典的键-值对del dict2['四川']print(dict2) 以上实例输出结果： 1234567891011121314# 原来的数据&#123;'河北':'石家庄','甘肃':'兰州','四川':'成都'&#125;# 访问键（河北）石家庄# 添加键值对（'山西': '太原'）&#123;'河北': '石家庄', '甘肃': '兰州', '四川': '成都', '山西': '太原'&#125;# 修改字典的值（石家庄改为邢台）&#123;'河北': '邢台', '甘肃': '兰州', '四川': '成都', '山西': '太原'&#125;# 删除字典的键-值对（四川）&#123;'河北': '邢台', '甘肃': '兰州', '山西': '太原'&#125; 二、遍历字典 1、定义一个字典 123456dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;# 遍历字典：键值对的集合、健的集合、值的集合for key,value in dict.items(): print(key+\":\"+value) 以上实例输出结果： 123name:老周age:29job:程序员 2、遍历字典常用的方法 123print(dict.items())print(dict.keys())print(dict.values()) 以上实例输出结果： 123dict_items([('name', '老周'), ('age', '29'), ('job', '程序员')])dict_keys(['name', 'age', 'job'])dict_values(['老周', '29', '程序员']) 3、字典元素的个数 1print(len(dict)) 以上实例输出结果： 13 4、复制字典 123dict1 = &#123;&#125;dict1 = dict.copy()print(dict1) 以上实例输出结果： 1&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125; 5、将字典的键排序 123456789print(sorted(dict1.keys()))print(sorted(dict1.values()))for info in sorted(dict1.keys()): print(info,end=\" \")print(\"\\n\")for info in sorted(dict1.keys()): print(value,end=\" \") 以上实例输出结果： 12345['age', 'job', 'name']['29', '程序员', '老周']age job name 程序员 程序员 程序员 6、使用函数获取字典值 1print(dict1.get('age')) 以上实例输出结果： 129 7、删除字典的方法 123456789101112# 删除字典# dicr1.clear()dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;print(dict)# 删除末尾#print(dict.popitem())#print(dict)# 指定删除print(dict.pop('age'))print(dict) 以上实例输出结果： 123&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125;29&#123;'name': '老周', 'job': '程序员'&#125; 8、小练习 （1）编写一个字典，检查给定键是否已经存在于字典中。 123456dict = &#123; 'name':'xgp', 'ah':'sleep', 'yd':'pb',&#125;print(dict) 以上实例输出结果： 1&#123;'name': 'xgp', 'ah': 'sleep', 'yd': 'pb'&#125; （2）编写一个Python程序，把已存在的一个字典添加到一个空字典中。 123dict1 = &#123;&#125;dict1 = dict.copy()print(dict1) 以上实例输出结果： 1&#123;'name': 'xgp', 'ah': 'sleep', 'yd': 'pb'&#125; （3）编写一个字典，遍历出该字典所有的键、值、键值对。 12345678910dict2 = &#123; '1':'1', '2':'2', '3':'3', '4':'4', '5':'5'&#125;print(dict2.keys())print(dict2.values())print(dict2.items()) 以上实例输出结果： 123dict_keys(['1', '2', '3', '4', '5'])dict_values(['1', '2', '3', '4', '5'])dict_items([('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5')]) 三、字典与列表的嵌套 1、定义一个字典 1234dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;dict1 = &#123;'name':'老周','age':'29'&#125;dict2 = &#123;'age':'29','job':'程序员'&#125;print(dict,dict1,dict2) 以上实例输出结果： 1&#123;'name':'老周','age':'29','job':'程序员'&#125;,&#123;'name':'老周','age':'29'&#125;,&#123;'age':'29','job':'程序员'&#125; 2、列表里嵌套字典 12list = [dict,dict1,dict2]print(list) 以上实例输出结果： 12[&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125;, &#123;'name': '老周', 'age': '29'&#125;, &#123;'age': '29', 'job': '程序员'&#125;]&#123;'pet': ['cat', 'dog', 'duck']&#125; 3、字典里嵌套列表 12dict3 =&#123;'pet':['cat','dog','duck']&#125;print(dict3) 以上实例输出结果： 1&#123;'pet': ['cat', 'dog', 'duck']&#125; 4、字典里嵌套字典 12345678910dict4 = &#123; 'age':&#123;'gir1':'18','boy':'20'&#125;, 'job':&#123;'man':'IT','women':'db'&#125;&#125;print(dict4)for key, value in dict4.items(): print('key:'+key,end=\" \") for v in value.items(): print(v) 以上实例输出结果： 12345&#123;'age': &#123;'gir1': '18', 'boy': '20'&#125;, 'job': &#123;'man': 'IT', 'women': 'db'&#125;&#125;key:age ('gir1', '18')('boy', '20')key:job ('man', 'IT')('women', 'db') 四、小测试 1、创建两个字典来表示老师，然后将这两个字典存储到一个名为person的列表中。遍历这个列表，将其中每个老师的信息都打印出来。 （1）创建两个字典来表示老师 1234567891011dict = &#123; 'name':'xgp', 'age':'18', 'job':'编程老师'&#125;dict1 = &#123; 'name':'wsd', 'age':'20', 'job':'运维老师'&#125;print(str(dict)+str(dict1)) 以上实例输出结果： 1&#123;'name': 'xgp', 'age': '18', 'job': '编程老师'&#125;&#123;'name': 'wsd', 'age': '20', 'job': '运维老师'&#125; （2）两个字典存储到一个名为person的列表中 12person = [dict,dict1]print(person) 以上实例输出结果： 1[&#123;'name': 'xgp', 'age': '18', 'job': '编程老师'&#125;, &#123;'name': 'wsd', 'age': '20', 'job': '运维老师'&#125;] （3）遍历这个列表，将其中每个老师的信息都打印出来 123456for key,value in person[0].items(): print(key+\":\"+value) print('\\n')for key,value in person[1].items(): print(key+\":\"+value) 以上实例输出结果： 12345678name:xgpage:18job:编程老师name:wsdage:20job:运维老师 2、创建多个字典，每个字典都使用一种宠物的名字命名；在每个字典中，包含宠物的类型和主人的名字。将这些字典存储在一个名为pets的列表中，再遍历该列表，将宠物的信息都打印出来。 （1）创建多个字典，每个字典都使用一种宠物的名字命名；在每个字典中，包含宠物的类型和主人的名字。 12345678910111213141516171819dog = &#123; 'dog':'柯基', 'type':'Optimistic', 'master':'xgp',&#125;cat = &#123; 'cat':'加菲猫', 'type':'lively', 'master':'wsd'&#125;bird = &#123; 'bird':'鹦鹉', 'type':'free', 'master':'dsw'&#125;print(dog)print(cat)print(bird) 以上实例输出结果： 123&#123;'dog': '柯基', 'type': 'Optimistic', 'master': 'xgp'&#125;&#123;'cat': '加菲猫', 'type': 'lively', 'master': 'wsd'&#125;&#123;'bird': '鹦鹉', 'type': 'free', 'master': 'dsw'&#125; （2）将这些字典存储在一个名为pets的列表中 12pets = [dog,cat,bird]print(pets) 以上实例输出结果： 1[&#123;'dog': '柯基', 'type': 'Optimistic', 'master': 'xgp'&#125;, &#123;'cat': '加菲猫', 'type': 'lively', 'master': 'wsd'&#125;, &#123;'bird': '鹦鹉', 'type': 'free', 'master': 'dsw'&#125;] （3）遍历该列表，将宠物的信息都打印出来 12345678for key,value in pets[0].items(): print(key+\":\"+value)print('\\n')for key,value in pets[1].items(): print(key+\":\"+value)print('\\n')for key,value in pets[2].items(): print(key+\":\"+value) 以上实例输出结果： 12345678910111213dog:柯基type:Optimisticmaster:xgpcat:加菲猫type:livelymaster:wsdbird:鹦鹉type:freemaster:dsw","path":"posts/8e0b.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"布尔表达式","text":"一、if语句判断的定义 如果 条件满足，才能做某件事情， 如果 条件不满足，就做另外一件事情，或者什么也不做 正是因为有了判断，才使得程序世界丰富多彩，充满变化！ 判断语句 又被称为 “分支语句”，正是因为有了判断，才让程序有了很多的分支 Python程序语言指定任何非0和非空（null）值为true，0 或者 null为false。 Python 编程中 if 语句用于控制程序的执行，基本形式为： 1234if 判断条件： 执行语句……else： 执行语句…… 例子：如果天气晴朗，我们去室外散步；否则，继续宅在家里 我们要判断出语句中的关键字然后基于此编写脚本 123456789101112\"\"\"如果 天气晴朗 去室外散步否则 继续宅在家里\"\"\"state = '阴天'if state == '晴朗': print('室外散步！')else: print('继续宅在家里。') 二、if语句的比较运算符 以下假设变量a为10，变量b为20： 运算符 描述 实例 == 等于 - 比较对象是否相等 (a == b) 返回 False。 != 不等于 - 比较两个对象是否不相等 (a != b) 返回 true. &lt;&gt; 不等于 - 比较两个对象是否不相等。python3 已废弃。 (a &lt;&gt; b) 返回 true。这个运算符类似 != 。 &gt; 大于 - 返回x是否大于y (a &gt; b) 返回 False。 &lt; 小于 - 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量True和False等价。 (a &lt; b) 返回 true。 &gt;= 大于等于 - 返回x是否大于等于y。 (a &gt;= b) 返回 False。 &lt;= 小于等于 - 返回x是否小于等于y。 (a &lt;= b) 返回 true。 例子 1、算数运算符在条件表达式中的应用：ATM/客服 123456key = 1if key == 1: print('存款')else: print('取款')#当数值等于1时存款，否则取款 2、!=的使用 12345if key != 1: print('不存款')else: print('存款')#当数值不等于1时不存款，否则取款 3、&gt;=的使用 123456age = 18if age &gt;= 18: print('允许进入网吧')else: print('未成年人禁止进入！')#当年龄大于18可以进网吧，否则不行 三、if语句的逻辑运算符 Python语言支持逻辑运算符，以下假设变量 a 为 10, b为 20: 运算符 逻辑表达式 描述 实例 and x and y 布尔&quot;与&quot; - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20。 or x or y 布尔&quot;或&quot; - 如果 x 是非 0，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。 not not x 布尔&quot;非&quot; - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 注意：if 有多个条件时可使用括号来区分判断的先后顺序，括号中的判断优先执行，此外 and 和 or 的优先级低于 &gt;（大于）、&lt;（小于）等判断符号，即大于和小于在没有括号的情况下会比与或要优先判断。 例子 当年龄大于等于18岁，或有100块钱并且有身份证就可进入，否则不得进入 123456789# 逻辑运算符：and/orage = 16money = 100id_card = Trueif (age &gt;= 18 or money &gt;= 100) and id_card: print('欢迎光临！')else: print('抱歉') 四、if语句的成员运算符 除了以上的一些运算符之外，Python还支持成员运算符，测试实例中包含了一系列的成员，包括字符串，列表或元组。 运算符 描述 实例 in 如果在指定的序列中找到值返回 True，否则返回 False。 x 在 y 序列中 , 如果 x 在 y 序列中返回 True。 not in 如果在指定的序列中没有找到值返回 True，否则返回 False。 x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True。 例子 1、成员运算符：in/not in 当names列表中包含小写的Kety，就输出存在，否则不存在 1234567names = ['Job','Bili','Laoyew','kety']name = 'Kety'if name.lower() in names: print('存在')else: print('不存在') 当names列表中不包含大写的Kety，就输出不存在，否则存在 1234if name.upper() not in names: print('不存在')else: print('存在') 五、小练习 1、检查是否相等 12345num = 1if num == 1: print('ok')else: print('no') 2、检查是否不相等 12345num1 = 2if num1 != 1: print('no')else: print('yes') 3、比较数字 123456num2 = 3num3 = 4if num2 &lt;= num3: print('ok')else: print('no') 4、检查多个条件 1234567num4 = 5num5 = 6num6 = 7if (num4 &gt;= 5 or num5 &gt;= 6) and num6 ==7: print ('ok')else: print('no') 5、检查特定的值是否包含在列表中 123456num7 = ['a','b','c']num8 = ['D']if num8 in num7: print('yes')else: print('no') 1234if str(num8).lower() in num7: print('yes')else: print('no') 6、检查特定的值是否不包含在列表中 12345if str(num8).upper() not in num7: print('no')else: print('yes') 六、if语句结构 1、简单的if语句 12345# 简单的ifage = 0if age ==0: print('婴儿')print() 注意：Python 区分语句块采用的是缩进规则。具有相同缩进的代码被视是同一结构的代码块，上面的2，3行 print 语句就构成一个代码块（ 但不包括第6行的 print 语句），他们都属于 if 下的语句块。 如果 age大于等于18，就会执行第 2 和 3 行的 if 语句块。 缩进要严格按照 Python 的习惯写法：4个空格，或者使用 Tab，不要混合 Tab 和空格，否则很容易造成因为缩进而引起的语法错误。 （一）if…else… 语句 if…else… 语句，当 if 的条件为 True 时执行 if 下的语句块，否则执行 else 下语句块。 if…else… 语句格式如下： 1234if &lt;条件&gt;: 【if 的语句块】else: 【else 的语句块】 释：条件为 True 时执行【if的语句块】，否则执行【else的语句块】 注意：if 和 else 语句以及各自的缩进部分共同是一个 完整的代码块 例子 1234567# if-elseage = 3if age &gt;= 2 and age &lt;= 4: print('蹒跚学步')else: print('婴儿') （二）if…elif…else… 语句 在开发中，使用 if 可以 判断条件，使用 else 可以处理 条件不成立 的情况 如果希望 再增加一些条件，条件不同，需要执行的代码也不同 时，就可以使用 elif 语法格式如下： 123456789101112if 条件1: 条件1满足执行的代码 ……elif 条件2: 条件2满足时，执行的代码 ……elif 条件3: 条件3满足时，执行的代码 ……else: 以上条件都不满足时，执行的代码 …… 注意：elif 和 else 都必须和 if 联合使用，而不能单独使用 可以将 if、 elif 和 else 以及各自缩进的代码，看成一个 完整的代码块 例子： 12345678910# if-elif-elseage = 3if age ==0: print('婴儿')elif age &gt;= 2 and age &lt;= 4: print('蹒跚学步')elif age &gt; 4 and age &lt;=5: print('上幼儿园')else: print('其他') （三）if 的嵌套 **elif 的应用场景是：同时 判断 多个条件，所有的条件是 平级 的** 在开发中，使用 if 进行条件判断，如果希望 在条件成立的执行语句中 再 增加条件判断，就可以使用 if 的嵌套 if 的嵌套 的应用场景就是：在之前条件满足的前提下，再增加额外的判断 if 的嵌套 的语法格式，除了缩进之外 和之前的没有区别 语法格式如下： 12345678910111213141516if 条件 1: 条件 1 满足执行的代码 …… if 条件 1 基础上的条件 2: 条件 2 满足时，执行的代码 …… # 条件 2 不满足的处理 else: 条件 2 不满足时，执行的代码# 条件 1 不满足的处理else: 条件1 不满足时，执行的代码 …… 例子 1、当百米赛跑时间小于等于10秒时，男女分组进入决赛 123456789101112second = 6gender = '男'if second &lt;= 10: print('进入决赛') if gender == '男': print('进入男子组') elif gender == '女': print('进入女子组')else: print('重在参与，杭氧体育精神') 2、if 的嵌套 演练 —— 火车站安检 需求 定义布尔型变量 has_ticket 表示是否有车票 定义整型变量 knife_length 表示刀的长度，单位：厘米 首先检查是否有车票，如果有，才允许进行 安检 安检时，需要检查刀的长度，判断是否超过 20 厘米 如果超过 20 厘米，提示刀的长度，不允许上车 如果不超过 20 厘米，安检通过 如果没有车票，不允许进门 123456789101112131415161718192021# 定义布尔型变量 has_ticket 表示是否有车票has_ticket = True# 定义整数型变量 knife_length 表示刀的长度，单位：厘米knife_length = 20# 首先检查是否有车票，如果有，才允许进行 安检if has_ticket: print(\"有车票，可以开始安检...\") # 安检时，需要检查刀的长度，判断是否超过 20 厘米 # 如果超过 20 厘米，提示刀的长度，不允许上车 if knife_length &gt;= 20: print(\"不允许携带 %d 厘米长的刀上车\" % knife_length) # 如果不超过 20 厘米，安检通过 else: print(\"安检通过，祝您旅途愉快……\")# 如果没有车票，不允许进门else: print(\"大哥，您要先买票啊\") 六、小练习（2） 1、 求100以内数字的偶数之和与奇数之和 123j = list(range(1,101,2))print(sum(j))print(sum(range(2,101,2))) 2、输出100以内7的倍数的数字 123for i in range(1,101): if i%7 == 0: print(i,end=' ') 3、打印直角三角形，奇数用*号代替，偶数用#号代替 123456789xgp = list(range(1,10,2))wsd = list(range(2,10,2))for i in range(1,10): for j in range(i+1): if j in xgp: print(\"*\",end='') elif j in wsd: print(\"#\",end='') print() 4、 查看fruits列表中是否有apper 12345# 定义列表fruits = ['apper','banana','pear','orange']fruit = 'apper'if fruit in fruits: print('存在') if嵌套 123456789for f in fruits: if f == 'pear': print('做梨罐头') elif f == 'orange': print('做橘子罐头') elif f == 'apple': print('做苹果罐头') else: print('做沙拉') 12345678910#fruits = []fruits = ['apple','banana','pear','orange']print(fruits)if len(fruits) == 0: print('没有水果')else: print('开始做水果罐头了') for fruit in fruits: print(fruit,end=\" \")","path":"posts/9b8f.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"Python 列表","text":"Python 列表(List) Python的基本数据类型有整数，浮点数，布尔，字符串，它们是最基本的数据。在实际编程中，我们要经常组织由很多基本数据组成的集合，这些集合的不同组织方式就是：数据结构，今天讲的是数据结构中的Python list(列表)。数据结构就是一些数据组合得到的“复合”数据类型。 Python内置的数据结构有： 列表(list) 元组(tuple) 字典(dict) 集合(set) 在Python语言中，以上4种数据结构和基础数据类型（整数、浮点数等）统称为“内置类型”（Built-in Types）。 一、什么是列表 序列是Python中最基本的数据结构。序列中的每个元素都分配一个数字 - 它的位置，或索引，第一个索引是0，第二个索引是1，依此类推。 Python有6个序列的内置类型，但最常见的是列表和元组。 序列都可以进行的操作包括索引，切片，加，乘，检查成员。 此外，Python已经内置确定序列的长度以及确定最大和最小的元素的方法。 列表是最常用的Python数据类型，它可以作为一个方括号内的逗号分隔值出现。 列表的数据项不需要具有相同的类型 （1）创建一个列表，只要把逗号分隔的不同的数据项使用方括号括起来即可。如下所示： 1234567# 定义列表name = ['Tom','Jack','John']pet = ['cat','dog','bird']# 打印列表print(name)print(pet) （2）用索引访问列表元素 使用下标索引来访问列表中的值，同样你也可以使用方括号的形式截取字符，如下所示： 1234567# 通过索引读取列表中的元素，索引从0开始，-1代表最后一个元素print(name[0]) #查看列表中第一个print(pet[2]) #查看列表中第二个print(name[-1]) #查看列表中最后一个print(pet[-2]) #查看列表中倒数第二个print (name[0:2]) #查看索引2之前的元素 二、基本操作 Python包含以下方法: 序号 方法 1 list.append(obj) 在列表末尾添加新的对象 2 list.count(obj) 统计某个元素在列表中出现的次数 3 list.extend(seq) 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） 4 list.index(obj) 从列表中找出某个值第一个匹配项的索引位置 5 list.insert(index, obj) 将对象插入列表 6 [list.pop(index=-1]) 移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 7 list.remove(obj) 移除列表中某个值的第一个匹配项 8 list.reverse() 反向列表中元素 9 list.sort(cmp=None, key=None, reverse=False) 对原列表进行排序 1、通过素引获取元素,进行修改 123#修改列表的元素name[1] = 'Sean' #修改name列表，索引1的内容为Seanprint(name) #打印列表 2、 向列表里面加元素 向python列表里面添加元素主要有三种方法： （1）append（） append()对于列表的操作主要实现的是在特定的列表最后添加一个元素，并且只能一次添加一个元素，并且只能在列表最后； name.append(元素A) 123# 在列表末尾添加新元素name.append('Bob')print(name) （2）extend（） extend（）对于列表的操作主要实现的是对于特定列表的扩展和增长，可以一次添加多个元素，不过也只能添加在列表的最后； ​ name.extend([元素A，元素B，……]) 12name.extend(['Xgp','Wsd'])print(name) （3）insert（） insert（）对于列表的操作主要是在列表的特定位置添加想要添加的特定元素，比较常用，这里的特定位置是指元素所在列表中的位置索引号，需要注意的是这里的索引号都是从0开始的，不是从1开始的，这个大家需要特别注意。 ​ pet.insert(A,元素B)：表示在列表m里面的第A+1处加入元素B 123456# 在列表指定位置添加新元素print(pet)pet.insert(0,'penguin') #在列表最前面添加数据print(pet)pet.insert(-2,'pig') #在列表倒数第三个添加数据print(pet) 3、删减列表中的一些元素； 与之前python列表的添加元素相对，删减列表里面的一些元素也有三种方法： （1）del pet[n] 它的作用是删除掉列表里面的索引号位置为n 的元素，这里需要注意的是del是一种操作语句。 del m[n] 1234# 根据索引从列表中删除元素print(pet)del pet[0] #删除开头的元素print (pet) （2）pet.pop（） 它的作用是将列表m的最后一个元素返回，并且在此基础上进行删除掉 Temp=pet.pop() %这里temp就会直接等于吗列表里最后一个元素。 Print(pet) %这里再次输出m的时候已经是删掉最后一个元素的m列表 pop():弹出列表末尾的元素 123print(pet)new_pet=pet.pop()print(new_pet) 弹出指定位置的元素 1234# 弹出指定位置的元素print(pet)pet.pop(2)print(pet) （3）pet.remove() m.remove的作用是移除掉列表m里面的特定元素； m.remove(元素A) 1234# 根据元素的值进行删除：remove()print(pet) #查看源列表pet.remove('cat') #删除catprint(pet) #打印列表 三、排序 （1）永久排序（正索引，从头到尾） sort()排序方法：此函数方法对列表内容进行正向排序，排序后的新列表会覆盖原列表（id不变），也就是sort排序方法是直接修改原列表list排序方法。 （2）临时排序（正索引，从头到尾） sorted()方法：即可以保留原列表，又能得到已经排序好的列表 （3）倒序（从头到尾从尾到头） reverse列表反转排序：是把原列表中的元素顺序从左至右的重新存放，而不会对列表中的参数进行排序整理。如果需要对列表中的参数进行整理，就需要用到列表的另一种排序方式sort正序排序。 （4）列表长度 len() 方法返回列表元素个数。 操作 12345678910111213141516171819202122# 定义列表：汽车的品牌print('原始排序：')brand = ['audi','bmw','toyota','luhu']print(brand)#临时排序print('临时排序：')print(sorted(brand))# 永久排序: sort()print('正序排序：')brand.sort()print(brand)# 倒序排序print('倒序排序:')brand.sort(reverse=True)print(brand)# 获取列表长度print('列表长度:')print(len(brand)) 四、小练习 列表练习（一） 定义一个列表，存储5个科目名称 12kemu = ['语文','数学','英语','地理','生物']print(kemu) 新增科目（末尾新增） 12kemu.append('化学')print(kemu) 修改科目 12kemu[2] = '计算机'print(kemu) 删除科目，并且在打印科目列表的时候，能够显示删除了哪个科目 123print(kemu)new_kemu=kemu.pop(3)print(new_kemu) 删除第2个科目 12kemu.pop(1)print(kemu) 指定位置新增 12kemu.insert(0,'科学')print(kemu) 删除指定名称的科目 12kemu.remove('生物')print(kemu) 列表练习（二） 将5个城市的名称存储到列表中，并且保证名称不是按照字母顺序排列的 12city = ['北京','上海','广州','深圳','山西']print(city) 打印出原始的城市列表信息 1print(city) 使用sorted()方法按字母顺序打印城市列表，但是不要修改列表元素的顺序 1print(sorted(city)) 打印该列表，确认城市名称排列顺序没有被修改 1print(city) 使用sort()方法排列城市名称，确保永久性修改排列顺序 12city.sort()print(city) 五、进阶操作 （一）遍历列表 1、for循环 Python for循环可以遍历任何序列的项目，如一个列表或者一个字符串。 语法： for循环的语法格式如下： 12for iterating_var in sequence: statements(s) 流程图： （1）简单的for循环 123456# 定义一个列表names = ['张三','李四','王五','赵六','田七']zhang_san = names[0]li_si = names[1]wang_wu = names[2]print(zhang_san+\" \"+li_si+\" \"+wang_wu) 123# for循环for name in names: print(name) 注意: name 这个变量是在 for 循环中定义的，意思是，依次取出 names中的每一个元素，并把元素赋值给 name，然后执行for循环体。 （2）多重for循环 &lt;1&gt;直角三角形 12345678910# 打印直角三角形# 外层循环控制行数# 内层循环控制列数# 外层循环执行1次，内层循环执行1轮for i in range(1,10): for j in range(i): print(j+1,end='') print() &lt;2&gt;九九乘法表 12345# 打印九九乘法表for i in range(1, 10): for j in range(i): print(str((j+1))+\"x\"+str(i)+\"=\"+str(i*(j+1)),end=' ') print() （二）创建数值类表 1、range() 的使用 range ( ) 为 Python 的自有类，range() 带有内置的迭代方法iter() 和 next() ，它是一个可迭代对象，我们可以通过 for 访问 range() 创建的迭代器。 range 类初始化参数说明： range(stop) 从0开始到stop结束（不包含 stop）返回一个产生整数序列的迭代对象 range(start, stop[, step]) 从 start 开始到 stop 结束（不包含 stop）返回一个整数序列的迭代对象, step 为他的步长 （1） 循环输出1-10之间的数字 12for num in range(11): print(num,end=\" \") （2）输出1-10之间的偶数 12for num in range(2,11,2): print(num,end=\" \") （3） 输出1-10之间的奇数 12for num in range(1,11,2): print(num,end=\" \") （4）输出1-10之间的奇数的平方 12for num in range(1,11,2): print(num**2,end=\" \") （5）创建一个数字列表 12numbers = list(range(1,11))print(numbers) 2、数字列表的简单统计（计算） Python包含以下函数: 序号 函数 1 cmp(list1, list2) 比较两个列表的元素 2 len(list) 列表元素个数 3 max(list) 返回列表元素最大值 4 min(list) 返回列表元素最小值 5 list(seq) 将元组转换为列表 1234# 数字列表的最大值、最小值、总和print(max(numbers)) #最大值print(min(numbers)) #最小值print(sum(numbers)) #总值 （三）Python列表切片 切片是Python序列的重要操作之一，适用于列表、元组、字符串、range对象等类型。切片使用2个冒号分隔的3个数字来完成：第一个数字表示切片的开始位置，默认为0，第二个数字表是切片的截止（但不包含）位置（默认为列表长度），第三个数字表示切片的步长(默认为1)，当步长省略时，顺便可以省略最后一个冒号。 可以使用切片来截取列表中的任何部分，得到一个新列表，也可以通过切片来修改和删除列表中部分元素，甚至可以通过切片操作为列表对象增加元素。与使用下标访问列表元素不同，切片操作不会因为下标越界而抛出异常，而是简单地在列表尾部截断或者返回一个空列表，代码具有更强的健壮性。# 切片 123# 创建一个列表pets = ['cat','dog','duck','pig']print(pets) 1、读取列表中2和3的元素 1pets[1:3] 2、读取列表中1到4的元素 1pets[0:4] 3、读取列表中的第一个元素 1pets[0] 4、读取列表中的最后一个元素 1pets[-1] 5、读取列表中，从第二个元素开始的所有元素 1pets[1:] 6、读取列表中，从第一个元素开始的所有元素 1pets[0:] 7、读取列表中，从倒数第三个元素开始的所有元素 1pets[-3:] 8、循环输出列表中，从倒数第三个元素开始的所有元素 12for pet in pets[-3:]: print(pet,end=\" \") 9.读取列表中，从第三个开始的所有数据，并组合一下数据 12345games = ['王者','吃鸡','抢滩登陆']# friend_games = ['王者','吃鸡']friend_games = games[:2]print('我喜欢的游戏有:'+str(games))print('我朋友喜欢的游戏有:'+str(friend_games)) （四）元组 Python 的元组与列表类似，不同之处在于元组的元素不能修改。 元组使用小括号，列表使用方括号。 元组创建很简单，只需要在括号中添加元素，并使用逗号隔开即可。 1、定义元组 12numbers = (4,5,6) #定义元组print(numbers[0]) #查看元组中第一个元素 2、循环输出numbers元组中的数据 12for num in numbers: print(num,end=\" \") 3、修改元组 元组中的元素值是不允许修改的，但我们可以对元组进行连接组合，如下实例: 123print(numbers)numbers = (0,1,2)print(numbers) 4、删除元组 1234print(numbers) #查看元组del numbers #删除元组print (\"删除后的元组 numbers : \")print(numbers) #因为删除了元组，所以看不到了，就会报错 元组运算符 与字符串一样，元组之间可以使用 + 号和 * 号进行运算。这就意味着他们可以组合和复制，运算后会生成一个新的元组。 Python 表达式 结果 描述 len((1, 2, 3)) 3 计算元素个数 (1, 2, 3) + (4, 5, 6) (1, 2, 3, 4, 5, 6) 连接 (‘Hi!’,) * 4 (‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’) 复制 3 in (1, 2, 3) True 元素是否存在 for x in (1, 2, 3): print (x,) 1 2 3 迭代 元组索引，截取 因为元组也是一个序列，所以我们可以访问元组中的指定位置的元素，也可以截取索引中的一段元素，如下所示： 元组： 1L = ('Google', 'Taobao', 'Runoob') Python 表达式 结果 描述 L[2] ‘Runoob’ 读取第三个元素 L[-2] ‘Taobao’ 反向读取，读取倒数第二个元素 L[1:] (‘Taobao’, ‘Runoob’) 截取元素，从第二个开始后的所有元素。","path":"posts/46cd.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"python变量","text":"变量和简单的数据类型 一、变量 12C:\\WINDOWS\\system32&gt;jupyter notebook//启动编辑器jupyter，会自动跳到默认浏览器或让你选择一个浏览器。 创建一个python3的文件 1、变量命名规则 变量要先定义才能使用 123message = '北京欢迎你' #定义变量print (message) #输出变量北京欢迎你 #输出成功 （1）只能包含的字母、数字、下划线，但是不能以数字打头 12$xpg = 'hello' #定义变量以特殊符号开头print ($xgp) #输出变量 语法错误，所以不能使用特殊符号和数字开头 （2）不能包含空格，但是可以用下划线分隔其中的单词 12a b=666 #定义变量名称以空格间隔a b #输出变量 语法错误，所以定义变量名称不能以空格间隔 123a_b=666 #定义变量名称以空格间隔a_b #输出变量666 #输出成功 （3）不能使用Python关键字和函数的名称用做变量 12import = 'ere' #以Python关键字定义变量名称import #输出变量 可以看出输出失败了，并且只要是Python关键字他会变成绿色的 （3）变量名应该简短并且见名知意 应该把自己要说明情况以简短明了的方式在变量名称体现出来 如 name： 123name = 'xgp' #定义变量name #输出变量'xgp' #输出成功（通过变量名称就可以知道xgp是个名字） （4）慎用大写字母I（i），小写字母l（L）和小写字母o 因为I、l和1非常像，还有0和0也非常像，到你要引用的时候非常麻烦（傻傻看不清） （5）变量的表达形式 12345678910str1 = 'hello' #单引号示范str2 = \"world\" #双引号示范str3 = \"\"\" #三引号示范1+1=22+2=44+4=8\"\"\"print(str1) #输出变量print(str2) #输出变量print(str3) #输出变量 变量str1使用单引号，变量str2使用双引号，变量str3使用三引号，他们都是合法的Python字符串类型，需要注意的是，单引号和双引号的作用是一样的，可以根据习惯使用，但是定义多行文字时，必须要使用三引号。 2、字符串 （1）修改字符串大小写 1234name = 'xgp wsd'print(name.title()) #以首写字母大写的方式显示每个单词print(name.upper()) #将所有字母都以大写的方式显示print(name.lower()) #将所有字母都以小写的方式显示 （2）拼接字符 12age = 18 #定义变量 print('我叫'+name.title()+',今年'+str(age)+'岁。') #输出变量&lt;str()引用变量&gt; 这种方式最常用、直观、易懂，是入门级的实现方式。但是，它也存在两处让人容易犯错的地方。 首先，新入门编程的同学容易犯错，他们不知道字符串是不可变类型，新的字符串会独占一块新的内存，而原来的字符串保持不变。上例中，拼接前有两段字符串，拼接后实际有三段字符串。 其次，一些有经验的老程序员也容易犯错，他们以为当拼接次数不超过3时，使用+号连接符就会比其它方式快（ps：不少Python教程都是如此建议），但这没有任何合理根据。 事实上，在拼接短的字面值时，由于CPython中的 常数折叠 （constant folding）功能，这些字面值会被转换成更短的形式，例如’a’+‘b’+‘c’ 被转换成’abc’，‘hello’+‘world’也会被转换成’hello world’。这种转换是在编译期完成的，而到了运行期时就不会再发生任何拼接操作，因此会加快整体计算的速度。 常数折叠优化有一个限度，它要求拼接结果的长度不超过20。所以，当拼接的最终字符串长度不超过20时，+号操作符的方式，会比后面提到的join等方式快得多，这与+号的使用次数无关。 （3）换行\\n 12age = 18print('我叫'+name.title()+',\\n今年'+str(age)+'岁。') （4）去空格 1234conten = ' wsd xgp 'print(conten.lstrip()) #去前面的空格print(conten.rstrip()) #去后面的空格print(conten.strip()) #去前面和后面的空格 3、数字的加减乘除 1234567num1 = 8num2 = 0.5print(num1+num2)print(num1-num2)print(num1*num2)print(num1/num2)print(num1%num2) 小测试 1、将用户的姓名存到一个变量中，并向该用户显示一条信息，显示内容为：“你好，xgp，今天的Python课你学到东西了吗？” 12name = 'xgp'print('你好，'+str(name)+'\\n今天的Python课你学到东西了吗？') 2、将一个人的名字存到变量中，再以小写、大写和首字母大写的方式显示这个人的名字。 1234name = 'wsd'print(name.lower())print(name.upper())print(name.title()) 3、按一下格式打印诗词： 《自由》 为人进出的门紧锁着; 想死的门敞开着。 有个病毒在外面高喊着: “出来玩吧，给你自由！” 但我深深地知道…… 出去了，不一定还能回来。 人的生命只有一次， 算球了， 再关十几天就自由了！ 12345678910biaoti = '《自由》 'print(str(biaoti)+'\\n为人进出的门紧锁着;'+'\\n想死的门敞开着。'+'\\n有个病毒在外面高喊着:'+'\\n“出来玩吧，给你自由！”'+'\\n但我深深地知道……'+'\\n出去了，不一定还能回来。'+'\\n人的生命只有一次，'+'\\n算球了，'+'\\n再关十几天就自由了！')","path":"posts/9a1f.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"初识python","text":"一、PyCharm基本设置 1、用Ctrl+鼠标滚轮–放大或缩小字体 搜索zoom 2、在Windows资源管理器打开文件或目录 搜索keymap 设置成不常用的键即可，如F3。 3、代码提示 搜索letter 二、自定义函数 1.为什么要使用函数 函数中的代码一次编写,多处运行; 函数可以让代码复用，减少代码冗余。 函数是组织好的，可重复使用的，用来实现单一，或相关联功能的代码段。 函数能提高应用的模块性，和代码的重复利用率。你已经知道Python提供了许多内建函数，比如print()。但你也可以自己创建函数，这被叫做用户自定义函数。 假设我有这样的需求： 但是我还是觉得太麻烦了，每次想吃饭的时候都要重复这样的步骤。此时，我希望有这样的机器： 将重复的工作封装到一起，我们只要向机器里放入东西，就能得到我们想要的。 这也就是所谓的代码重用。 例子 123456789101112131415161718# 定义方法def print_nums(): \"\"\"此处是函数功能的描述\"\"\" for i in range(1,11): print(i,end=\" \")# 1.三角形 2.正方形 3.梯形key = int(input('请输入要打印的图形：'))if key == 1: # 打印三角形的代码 print_nums() passelif key == 2: # 打印梯形的代码 passelif key == 3: # 正方形的代码 pass 输出结果如下： 123请输入要打印的图形：11 2 3 4 5 6 7 8 9 10 进程已结束，退出代码 0 分析一下 2、定义函数 你可以定义一个由自己想要功能的函数，以下是简单的规则： 关键字: def 函数代码块以 def 关键词开头，后接函数标识符名称和圆括号()，结尾处有冒号。 函数内第一行通常书写注释,表名该函数的意义 注释后空一行,开始写代码块，代码库要缩进 任何传入参数和自变量必须放在圆括号中间。圆括号之间可以用于定义参数。 函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。 函数内容以冒号起始，并且缩进。 return [表达式] 结束函数，选择性地返回一个值给调用方。不带表达式的return相当于返回 None。 函数结束后,空2行 函数调用后空1行,再执行别的代码 语法 12345#代码如下def functionname( parameters ): \"函数_文档字符串\" function_suite return [expression] 默认情况下，参数值和参数名称是按函数声明中定义的的顺序匹配起来的。 三、函数类型 Python函数可以使用的参数类型： 必备参数 命名参数 缺省参数 不定长参数 参数类型： ​ 1、位置参数:参数的位置(顺序)很重要，形参和实参个数要匹配 ​ 2、关键字参数:对参数的位置要求不是很严格 ​ 3、默认值参数: ​ (1)如果形参中指定了默认值,在实参中可以不传递该形参对应的实参 ​ (2)如果形参中指定了默认值，在实参汇总传递该参数后，最终参数以传递的实参为准 ​ 4、不定长参数： ​ (1)*a：接收传递单个值,保存为元组 ​ (2)**b：接收键值对形式的参数，保存为字典格式 1、无参函数 无参函数实现和调用： 12345678# 定义无参函数def say_hi(): \"\"\"介绍自己的函数\"\"\" print('我是xgp，今年18岁，年收入xxxx元')# 调用无参函数say_hi() 输出结果如下： 123我是xgp，今年18岁，年收入xxxx元进程已结束，退出代码 0 2、带参函数 下面说说带参数的函数： 形参：指的是形式参数，是虚拟的，不占用内存空间，形参单元只有被调用的时才分配内存单元 实参：指的是实际参数，是一个变量，占用内存空间，数据传递单向，实参传给形参，形参不能传给实参 例子 12345678# 定义带参函数：形参（形式参数，模板）def say_hi(name,age,money): \"\"\"介绍自己的函数\"\"\" print('我是'+name+'，今年'+str(age)+'岁，年收入'+str(money)+'元。')# 调用带参函数：实参（实际传递的参数）say_hi('xgp',20,20000) 输出结果如下： 123我是xgp，今年20岁，年收入20000元。进程已结束，退出代码 0 注意事项:调用函数时,实参传递的个数 要与形参保持一致| （1）位置参数 从上面的例子可以看出，实际参数和形式参数是一一对应的，如果调换位置，x和y被调用的时，位置也会互换，代码如下： 123456789101112131415def test(x,y): print(x) print(y)print(\"--------互换前-----\")test(1,2)print(\"--------互换后-----\")test(2,1) #输出--------互换前-----12--------互换后-----21 因为定义x,y两个形参，所以传递实参的时候，也只能传递两个实参，多一个或少一个都是有问题的： a：多传递一个参数 123456789101112def test(x,y): print(x) print(y)print(\"--------多一个参数----\")test(1,2,3) #输出--------多一个参数----Traceback (most recent call last): File \"D:/PycharmProjects/pyhomework/day3/函数_带参数.py\", line 8, in &lt;module&gt; test(1,2,3)TypeError: test() takes 2 positional arguments but 3 were given #test()函数需要传两个实参，你传了三个实参 b：少传递一个实参 12345678910111213def test(x,y): print(x) print(y)print(\"--------少一个参数----\")test(1) #输出--------少一个参数----Traceback (most recent call last): File \"D:/PycharmProjects/pyhomework/day3/函数_带参数.py\", line 8, in &lt;module&gt; test(1)TypeError: test() missing 1 required positional argument: 'y' #没有给y参数传实参 （2）关键字参数 上面的位置参数，看起来有点死，必须形参和实参的位置一一对应，不然就会传错参数，为了避免这种问题，就有了关键字参数的玩法：关键字传参不需要一一对应，只需要你指定你的哪个形参调用哪一个实参即可； 12345678910111213141516def test(x,y): print(x) print(y) print(\"--------互换前------\")test(x=1,y=2)print(\"--------互换后------\")test(y=2,x=1) #输出--------互换前------12--------互换后------12 3、默认参数 调用函数时，默认参数的值如果没有传入，则被认为是默认值。下例会打印默认的age，如果age没有被传入： 12345678910111213#!/usr/bin/python# -*- coding: UTF-8 -*- #可写函数说明def printinfo( name, age = 35 ): \"打印任何传入的字符串\" print \"Name: \", name print \"Age \", age return #调用printinfo函数printinfo( age=50, name=\"miki\" )printinfo( name=\"miki\" ) 输出结果如下： 1234Name: mikiAge 50Name: mikiAge 35 4、不定长参数 你可能需要一个函数能处理比当初声明时更多的参数。这些参数叫做不定长参数，和上述2种参数不同，声明时不会命名。基本语法如下： 1234def functionname([formal_args,] *var_args_tuple ): \"函数_文档字符串\" function_suite return [expression] 加了星号（*）的变量名会存放所有未命名的变量参数。不定长参数实例如下： 123456789101112131415#!/usr/bin/python# -*- coding: UTF-8 -*- # 可写函数说明def printinfo( arg1, *vartuple ): \"打印任何传入的参数\" print \"输出: \" print arg1 for var in vartuple: print var return # 调用printinfo 函数printinfo( 10 )printinfo( 70, 60, 50 ) 输出结果如下： 123456输出:10输出:706050 （1）例子 123456# 不定长参数的类型def no_test(*args,**b): print((args)) print(b)no_test(1,2,3)no_test(name='test',ages=18) 输出结果如下： 1234(1, 2, 3)&#123;&#125;()&#123;'name': 'test', 'ages': 18&#125; 5、匿名函数 python 使用 lambda 来创建匿名函数。 lambda只是一个表达式，函数体比def简单很多。 lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。 lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数。 虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。 语法 lambda函数的语法只包含一个语句，如下： 1lambda [arg1 [,arg2,.....argn]]:expression 如下实例： 12相加后的值为 : 30相加后的值为 : 40 四、rerun传递列表类型数据 return语句[表达式]退出函数，选择性地向调用方返回一个表达式。不带参数值的return语句返回None。之前的例子都没有示范如何返回数值，下例便告诉你怎么做： 123456789101112#!/usr/bin/python# -*- coding: UTF-8 -*- # 可写函数说明def sum( arg1, arg2 ): # 返回2个参数的和.\" total = arg1 + arg2 print \"函数内 : \", total return total # 调用sum函数total = sum( 10, 20 ) 输出结果如下： 1函数内 : 30 注意：在函数内没有写return语句的时候，默认return的是一个空对象。也就是就算没写，python内部也做了处理。 此时，有部分人分不清函数的输出和返回值的区别。 这样说吧，在函数里print之类的操作能够输出内容，是因为虽然函数的执行环境是独立的，但代码还是有效的。外部能进行的操作，函数内部也可以。但是并不是所有的函数在执行完毕后都有如此明显的输出效果，此时我们需要查看函数是否成功，或者说我放了米进去，你操作一番之后总要把饭给我拿出来吧。 这就是函数中return的意义。返回一个对象。这个对象可以是对执行状态的说明，也可以是处理后的结果等等。 1、return语句返回简单类型 12345678910def test(): return 'hello'print(test())# return 语句返回字典def show_info(name,age): person = &#123;'name':name,'age':age&#125; return personprint(show_info('test',18)) 输出结果如下： 123&#123;'name': 'test', 'age': 18&#125;进程已结束，退出代码 0 2、用户问候 1234567891011121314151617def say_hi(first_name,last_name): \"\"\"返回完整名字\"\"\" full_name = first_name + ' ' + last_name return full_namewhile True: print('请输入您的姓名:') f_name = input('姓：') if f_name =='q': break l_name = input('名：') if l_name == 'q': break # 调用函数 format_name = say_hi(f_name,l_name) print('hello'+format_name+'!') 输出结果如下： 1234请输入您的姓名:姓：x名：gphellox gp! 3、传递列表类型数据 12345def test(names): for name in names: print(name)user_name = ['sdf','fsd','fewfwef','fwefe']test(user_name) 输出结果如下： 123456sdffsdfewfweffwefe进程已结束，退出代码 0 5、range函数的练习 当只用一个变量调用这个函数时，这个变量指的是输出的等差数列的终点，如range(5) 当给定两个变量时，分别指输出的起始值和终点,，如range(2, 5) 当给定三个变量时，在上一条的基础上第三个变量指输出时的步长，如range(2, 5, -1) （假定我们调用这个函数时总是用整数或浮点数） 分析一下如何实现这个函数，下面给出我的思路作为参考 一共需要三个参数是显而易见的； 最直观的感受是起始值是要有默认值的，如果不规定从哪里开始，那就从0开始； 步长也是要有默认值的，如果不规定，那么步长是1； 根据有默认值的参数要放在后面的原则，那么最理所当然的参数设计是range_custom(stop, start=0, step=1) 这个方案看上去可行，但是不满足刚才的后面两个要求，如果我们这样用两个变量调用，起始值和终点是反的； 我们加个判断就可以了，如果start用了初始值，那么说明我们调用的时候只给了一个参数，这个时候stop就是终点，如果start被重新赋值了说明给了至少两个参数，那么这时候把stop和start的值调换一下就可以了； 现在这个函数似乎可以满足大多数情况了，但是有一个bug，如果给定参数的时候给的start值就是0怎么办呢？如range_custom(-5, 0)按目前的规则会被翻译成range(0, -5)，但是我们的目的却是range(-5, 0)； 所以start的初始值不应该是数字而是别的数据类型，为了方便起见，我们把它的初始值赋为None，我们的程序雏形就出来了。 1234def range_custom(stop, start=None, step=1): if start is None: return range(stop) return range(stop, start, step) 现在这个程序已经满足我们的要求了，但是看上去不太舒服，可以改成 1234def range_custom(start, stop=None, step=1): if stop is None: return range(start) return range(start, stop, step) 现在这个函数的参数顺序在逻辑上更好理解一些，可以说基本上满足我们的要求了。当然，本例只是为了说明参数的顺序问题，并不是为了实现range函数。事实上Python的range函数还包括参数实例化，生成器等知识，在后面我们应该还有机会再接触它。 可选参数 说到可选参数，可能有的人见过，却也不明白到底是什么意思，它一般是这样出现的 12def func_option(*args): return args 注意到我们声明函数的时候在参数名前加了个*星号，这是声明可选参数的方法。那么可选参数到底有什么用呢？ 可选参数的作用是用元组把所有多余的变量收集起来，这个元组的名字就是这个可选参数名。在上例func_option中我们可以用任意多个变量调用它，比如a = func_option(1, 2, 3)那么a就会是元组(1, 2, 3)。关于为什么是元组而不是列表，我们在上一篇Python进阶-简单数据结构中说过，元组在Python中往往是比列表更优先考虑使用的数据结构，具体原因在本文靠后深入自定义函数参数部分会讨论。 我们刚才说可选参数会收集多余的变量。我这么说是有原因的。 123456789&gt;&gt;&gt; def func_option(a, *args, c=2):... return args...&gt;&gt;&gt; func_option2(1)()&gt;&gt;&gt; func_option2(1, 2)(2,)&gt;&gt;&gt; func_option2(1, 2, 3)(2, 3) 注意到我们的*args把除了给普通参数的第一个变量以外的值都放进了元组中。这样做导致了一个，问题在于我们的有默认值的参数如果不给定参数名地调用的话，就永远只能用默认值了。而且如果我们在调用函数时不把有默认值的参数放在最后面程序还会报错。 123&gt;&gt;&gt; func_option2(c=1, 2, 3) File \"&lt;stdin&gt;\", line 1SyntaxError: positional argument follows keyword argument 那么有没有好的办法能规避这个问题呢？我们可以试试把可选参数放在有默认值的参数后面。 123456789101112&gt;&gt;&gt; def func_option3(a, c=2, *args):... return args...&gt;&gt;&gt; func_option3(1)()&gt;&gt;&gt; func_option3(1, 2)()&gt;&gt;&gt; func_option3(1, 2, 3)(3,)&gt;&gt;&gt; func_option2(c=1, 2, 3) File \"&lt;stdin&gt;\", line 1SyntaxError: positional argument follows keyword argument 那么这种形式的函数能不能解决之前的问题呢。看上去不行，不过我们知道了，调用函数的时候，要尽量把有默认值的参数放在靠后的位置赋予变量。那么这两种我们到底该用哪个方法呢？在实际操作中，我们倾向于将可选参数放在有默认值的参数之后，而且如果参数较多，我们倾向于调用函数时都会所有变量都加上参数名。而且实际操作中，其实可选参数用得不那么多，相对来说，另一种可选参数其实用得更多。这种可选参数的形式一般是这样 12def func_optionkw(**kwargs): return args 在这种情况下，关键字可选参数都是作为键值对保存在参数名的的字典中。也就是说，在调用函数时，在满足一般参数以后，变量都应该以赋值语句的形式给出，等号左边作为键右边作为值。如果不这样做，就会报错了。 1234&gt;&gt;&gt; func_optionkw(3)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: t2() takes 0 positional arguments but 1 was given 需要说明的是，一个自定义函数只能有一个可选参数，同时也可以有至多一个关键字参数。其中关键字参数应该放在普通可选参数之后。 现在我们来总结一下函数参数顺序一般规律： 一般参数放在最前面 可选参数放在最后面 关键字可选参数放在一般可选参数后面 函数调用时尽量把有默认值的参数对应的变量放在靠后的位置 如果参数比较多，调用函数时，最好所有变量都指明参数名 以上这些，有的是为了防止函数定义时出错，有的是为了防止函数调用时出错，总之，应该养成良好的编程习惯。 五、变量作用域 一个程序的所有的变量并不是在哪个位置都可以访问的。访问权限决定于这个变量是在哪里赋值的。 变量的作用域决定了在哪一部分程序你可以访问哪个特定的变量名称。两种最基本的变量作用域如下： 全局变量 局部变量 六、全局变量和局部变量 定义在函数内部的变量拥有一个局部作用域，定义在函数外的拥有全局作用域。 局部变量只能在其被声明的函数内部访问，而全局变量可以在整个程序范围内访问。调用函数时，所有在函数内声明的变量名称都将被加入到作用域中。如下实例： 实例(Python 2.0+) 1234567891011121314#!/usr/bin/python# -*- coding: UTF-8 -*- total = 0 # 这是一个全局变量# 可写函数说明def sum( arg1, arg2 ): #返回2个参数的和.\" total = arg1 + arg2 # total在这里是局部变量. print \"函数内是局部变量 : \", total return total #调用sum函数sum( 10, 20 )print \"函数外是全局变量 : \", total 输出结果如下： 12函数内是局部变量 : 30函数外是全局变量 : 0","path":"posts/e939.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"k8s复习","text":"创建镜像的方法 1234567891011121314151617[root@master xgp]# vim DockerfileFROM nginxADD index.htm /usr/share/nginx/html///创建Dockerfile[root@master test]# echo \"&lt;h1&gt;version 01 wsd&lt;/h1&gt;\" &gt; index.html[root@master test]# docker build -t 192.168.1.1:5000/nginx .[root@master test]# echo \"&lt;h1&gt;version 02 wsd&lt;/h1&gt;\" &gt; index.html [root@master test]# docker build -t 192.168.1.1:5000/nginx:v1.14 [root@master test]# echo \"&lt;h1&gt;version 03 wsd&lt;/h1&gt;\" &gt; index.html .[root@master test]# docker build -t 192.168.1.1:5000/nginx:v1.15 .//创建不同index.html文件，生成测试镜像[root@master test]# docker push 192.168.1.1:5000/nginx[root@master test]# docker push 192.168.1.1:5000/nginx:v1.14[root@master test]# docker push 192.168.1.1:5000/nginx:v1.15//上传镜像 2) deployment名字为:nginx,保证运行3个Pod.service名字为：nginx-svc。映射到主机端口：31234.（10分） 12345678910111213141516171819202122232425262728293031[root@master yaml]# docker pull nginx//下载nginx镜像[root@master yaml]# vim deployment.yaml //编写deployment和service的yaml文件apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginxspec: replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx---apiVersion: v1kind: Servicemetadata: name: nginx-svcspec: type: NodePort selector: app: nginx ports: - port: 80 targetPort: 80 nodePort: 31234 执行一下 1[root@master yaml]# kubectl apply -f deployment.yaml 查看一下 1[root@master yaml]# kubectl get pod 1[root@master yaml]# kubectl get svc 访问一下http://192.168.1.21:31234/ 3) 共有3个版本，版本1对应image镜像为：nginx，版本2对应的image为：nginx:1.14.版本3对应的版本为:nginx:1.15.分别运行各版本，每个版本要有在浏览器的访问验证。（10分） 1234[root@master yaml]# docker pull nginx[root@master yaml]# docker pull nginx:1.14[root@master yaml]# docker pull nginx:1.15//下载所需镜像 编写deployment的yaml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@master yaml]# vim banben1.yaml//编写deployment和service的yaml文件apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginxspec: replicas: 3 template: metadata: labels: app: nginx-svc spec: containers: - name: nginx image: nginx #更改一下镜像（1.14和1.15的）[root@master yaml]# vim banben2.yaml//编写deployment和service的yaml文件apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx2spec: replicas: 3 template: metadata: labels: app: nginx-svc spec: containers: - name: nginx image: nginx:1.14 #更改一下镜像（1.14和1.15的）[root@master yaml]# vim banben3.yaml//编写deployment和service的yaml文件apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx3spec: replicas: 3 template: metadata: labels: app: nginx-svc spec: containers: - name: nginx image: nginx:1.15 #更改一下镜像（1.14和1.15的） 编写service的yaml文件 1234567891011121314[root@master yaml]# vim ngnix-svc.yaml apiVersion: v1kind: Servicemetadata: name: nginx-svcspec: type: NodePort selector: app: nginx-svc ports: - port: 80 targetPort: 80 nodePort: 31235 执行一下（记录版本信息） 1234[root@master yaml]# kubectl apply -f banben1.yaml --record [root@master yaml]# kubectl apply -f banben2.yaml --record [root@master yaml]# kubectl apply -f banben3.yaml --record [root@master yaml]# kubectl apply -f ngnix-svc.yaml 查看一下 1[root@master yaml]# kubectl get pod 1[root@master yaml]# kubectl get svc 访问一下 http://192.168.1.21:31235/ 4)运行到版本3之后，进行回滚操作回滚到版本4.（5分） 查看记录的版本信息 1[root@master yaml]# kubectl rollout history deployment nginx 回滚到指定版本 12[root@master ~]# kubectl rollout undo deployment nginx --to-revision=4//这里指定的是版本信息的编号 访问一下 5) 此时更改默认的3个Pod的访问界面,.版本1的访问界面内容为：考生名称+version:No1.版本2的访问界面:考生名称+version:No2,以此类推。（5分） 修改POD页面内容（三台不一样） 12[root@master ~]# kubectl exec -it xgp-web-8d5f9656f-8z7d9 /bin/bash//根据pod名称进入pod之中 进入容器后修改页面内容 12345678910111213141[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-8vcvt /bin/bashroot@nginx-d6c5c85cb-8vcvt:/# echo \"&lt;h1&gt;version 01 wushaodong&lt;/h1&gt;\" &gt; /usr/share/nginx/html/index.html root@nginx-d6c5c85cb-8vcvt:/# exit2[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-bxvvt /bin/bashroot@nginx-d6c5c85cb-bxvvt:/# echo \"&lt;h1&gt;version 02 wushaodong&lt;/h1&gt;\" &gt; /usr/share/nginx/html/index.htmlroot@nginx-d6c5c85cb-bxvvt:/# exit3[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-lhlz9 /bin/bashroot@nginx-d6c5c85cb-lhlz9:/# echo \"&lt;h1&gt;version 03 wushaodong&lt;/h1&gt;\" &gt; /usr/share/nginx/html/index.htmlroot@nginx-d6c5c85cb-lhlz9:/# exit 6) 验证界面是否会会有轮训效果，并加以分析论述。（5分） 不要在浏览器里测试轮询，有缓存 1[root@master ~]# curl 127.0.0.1:31235 答：会有轮询的效果，kubernetes 内部的负载均衡是通过 iptables 的 probability 特性来做到的，kube-proxy通过iptables 将访问 Service 的流量转发到后端 Pod，而且使用类似轮询的负载均衡策略。 7) 创建一个NFS PV，NFS共享目录为：考生名称。PV名称为：new-pv。创建一个PVC，名称为new-pvc。单独创建一个pod，使用new-pv，运行之后，验证nfs是否使用成功。（10分） 12345678910111213[root@master ~]# yum -y install nfs-utils rpcbind[root@master yaml]# mkdir /wushaodong//创建指定名称的共享目录[root@master yaml]# echo \"/wushaodong *(rw,sync,no_root_squash)\" &gt; /etc/exports//编写共享目录的权限[root@master ~]# systemctl start nfs-server[root@master ~]# systemctl start rpcbind//启动服务[root@master yaml]# showmount -e//测试一下 1、创建一个NFS PV的yaml文件 12345678910111213141516171819[root@master yaml]# vim new-pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: new-xgpspec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /wushaodong/new-pv server: 192.168.1.21[root@master yaml]# mkdir /wushaodong/new-pv//创建指定目录 执行一下 1[root@master yaml]# kubectl apply -f new-pv.yaml 查看一下 1[root@master yaml]# kubectl get pv 2、创建一个PVC的yaml文件 123456789101112[root@master yaml]# vim new-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: new-pvcspec: accessModes: #要和pv的一直否则关联不成功 - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: nfs #要和pv的一直否则关联不成功 执行一下 1[root@master yaml]# kubectl apply -f new-pvc.yaml 查看一下 1[root@master yaml]# kubectl get pvc 3、单独创建一个pod，使用new-pv 1234567891011121314151617181920[root@master yaml]# vim pod.yamlapiVersion: v1kind: Podmetadata: name: xgp-podspec: containers: - name: xgp-pod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - mountPath: /wushaodong #容器的被挂载目录 name: volumedata volumes: - name: volumedata persistentVolumeClaim: claimName: new-pvc 执行一下 1[root@master yaml]# kubectl apply -f pod.yaml 查看一下 1[root@master yaml]# kubectl get pod 4、测试一下 12345[root@master yaml]# kubectl exec -it xgp-pod /bin/sh//进入pod# echo \"xgpIwsd\" &gt; /wushaodong/xgp.txt//添加内容到挂载目录# exit 查看一下，挂载目录是否有添加内容 1[root@master yaml]# cat /wushaodong/new-pv/xgp.txt 8）请简述k8s集群中，master节点有哪些组件，node节点有哪些组件，作用分别有什么作用，各组件又是怎么交互的。（5分） master节点 1. API server[资源操作入口]：是k8s集群的前端接口，各种各样客户端工具以及k8s的其他组件可以通过它管理k8s集群的各种资源。它提供了HTTP/HTTPS RESTful API,即K8S API。 提供了资源对象的唯一操作入口，其他所有组件都必须通过它提供的API来操作资源数据，只有API Server与存储通信，其他模块通过API Server访问集群状态。 第一，是为了保证集群状态访问的安全。 第二，是为了隔离集群状态访问的方式和后端存储实现的方式：API Server是状态访问的方式，不会因为后端存储技术etcd的改变而改变。 作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTFul接口方式提供给外部客户和内部组件调用。对相关的资源数据“全量查询”+“变化监听”，实时完成相关的业务功能。 2. Scheduler[集群分发调度器]：负责决定将Pod放在哪个Node上运行。在调度时，会充分考虑集群的拓扑结构，当前各个节点的负载情况，以及应对高可用、性能、数据亲和性和需求。 1.Scheduler收集和分析当前Kubernetes集群中所有Minion节点的资源(内存、CPU)负载情况，然后依此分发新建的Pod到Kubernetes集群中可用的节点。 2.实时监测Kubernetes集群中未分发和已分发的所有运行的Pod。 3.Scheduler也监测Minion节点信息，由于会频繁查找Minion节点，Scheduler会缓存一份最新的信息在本地。 4.最后，Scheduler在分发Pod到指定的Minion节点后，会把Pod相关的信息Binding写回API Server。 4. Controller Manager[内部管理控制中心]：负责管理集群的各种资源，保证资源处于预期的状态。它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等。 实现集群故障检测和恢复的自动化工作，负责执行各种控制器，主要有： 1.endpoint-controller：定期关联service和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的。 2.replication-controller：定期关联replicationController和pod，保证replicationController定义的复制数量与实际运行pod的数量总是一致的。 **5. Etcd：**负责保存k8s集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速的通知k8s相关组件。（第三方组件）它有可替换方案。Consul、zookeeper 6. Pod: k8s集群的最小组成单位。一个Pod内，可以运行一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。 **7. Flanner：**是k8s集群网络，可以保证Pod的跨主机通信。也有替换方案。 Node节点 Kubelet[节点上的Pod管家]：它是Node的agent(代理)，当Scheduler确定某 个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet,kubelet会根据这些信息创建和运行容器，并向Master报告运行状态。 负责Node节点上pod的创建、修改、监控、删除等全生命周期的管理 定时上报本Node的状态信息给API Server。 kubelet是Master API Server和Minion之间的桥梁，接收Master API Server分配给它的commands和work，与持久性键值存储etcd、file、server和http进行交互，读取配置信息。 具体的工作如下： 设置容器的环境变量、给容器绑定Volume、给容器绑定Port、根据指定的Pod运行一个单一容器、给指定的Pod创建network 容器。 同步Pod的状态、同步Pod的状态、从cAdvisor获取Container info、 pod info、 root info、 machine info。 在容器中运行命令、杀死容器、删除Pod的所有容器。 **kube-proxy[负载均衡、路由转发]:**负责将访问service的TCP/UDP数据流转发到后端的容器。如果有多个 副本，kube-proxy会实现负载均衡。 Proxy是为了解决外部网络能够访问跨机器集群中容器提供的应用服务而设计的，运行在每个Node上。Proxy提供TCP/UDP sockets的proxy，每创建一种Service，Proxy主要从etcd获取Services和Endpoints的配置信息（也可以从file获取），然后根据配置信息在Minion上启动一个Proxy的进程并监听相应的服务端口，当外部请求发生时，Proxy会根据Load Balancer将请求分发到后端正确的容器处理。 Proxy不但解决了同一主宿机相同服务端口冲突的问题，还提供了Service转发服务端口对外提供服务的能力，Proxy后端使用了随机、轮循负载均衡算法。 各个组件的作用以及架构工作流程: 1) kubectl发送部署 请求到API server 2) APIserver通知Controller Manager创建一个Deployment资源。 3) Scheduler执行调度任务,将两个副本Pod分发到node01和node02. 上。 4) node01和node02, 上的kubelet在各自节点上创建并运行Pod。 补充 1.应用的配置和当前的状态信息保存在etcd中，执行kubectl get pod时API server会从etcd中读取这些数据。 2.flannel会为每个Pod分配一个IP。 但此时没有创建Service资源，目前kube-proxy还没有参与进来。 9）部署一个dashboard。（5分） 1、下载所需yaml文件和镜像 12[root@master https]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc5/aio/deploy/recommended.yaml[root@master https]# docker pull kubernetesui/dashboard:v2.0.0-rc5 2、修改 recommended.yaml 12345678910111213141516[root@master https]#vim recommended.yaml ---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort #添加40 ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard 执行一下 1[root@master https]# kubectl apply -f recommended.yaml 查看一下 1[root@master https]# kubectl get svc -n kubernetes-dashboard 3、浏览器访问https://192.168.1.21:30949/ PS:如果是使用的旧版本的dashboard, 使用Google浏览器登录，可能是不成功的，需要换成其他的浏览器，比如:火狐。 4、基于token的方法登录dashboard &lt;1&gt;创建一个dashboard的管理用户 1[root@master https]# kubectl create serviceaccount dashboard-admin -n kube-system &lt;2&gt;绑定用户为集群管理用户 1[root@master https]# kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin &lt;3&gt;获取Token 12[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin//先得到Token的名称 12[root@master https]# kubectl describe secrets -n kube-system dashboard-admin-token-j874n//查看上述得到的secret资源的详细信息，会得到token &lt;4&gt;在浏览器上使用token登录。 成功界面 10）使用helm的方式，部署mysql服务，要求使用storageclass作为持久化存储，服务运行之后，进入数据库，创建一个test库，库中一张test表，内容为： 9527. 然后模拟数据库Pod失败，待Pod重启后，查看对应数据是否还存在？（10分） 1、安装部署helm工具 （1）下载helm的包 12[root@master ~]#docker pull gcr.io/kubernetes-helm/tiller:v2.14.3[root@master ~]# wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz （2）把helm包的命令，复制到本地 123456[root@master helm]# mv linux-amd64/helm /usr/local/bin///移动命令目录到/usr/local/bin/[root@master helm]# chmod +x /usr/local/bin/helm //给予执行权限[root@master helm]# helm help//验证是否安装成功 （3）设置命令自动补全 123[root@master helm]# echo 'source &lt;(helm completion bash)' &gt;&gt; /etc/profile[root@master helm]# . /etc/profile//刷新一下 2、安装Tiller server（服务端，需要创建授权用户） 12345678910111213141516171819[root@master ~]# vim tiller-rbac.yaml #创建授权用户apiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system 执行一下 1[root@master ~]# kubectl apply -f tiller-rbac.yaml （1）Tiller server的环境初始化 12[root@master helm]# helm init --service-account=tiller//helm的服务端就是Tiller（因为是访问外国的网站，可能需要多次执行） 查看一下 1[root@master helm]# kubectl get deployment. -n kube-system 现在发现没有开启，那是因为默认下载的Google的镜像，下载不下来 （2）设置镜像源改为阿里云的 1[root@master helm]# helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts 查看一下 1[root@master helm]# helm version 3、基于NFS服务，创建共享。 因为上面已经做过了，所以现在只需创建目录和设置权限即可 123456789[root@master heml]# mkdir /xgpwsd//创建目录[root@master heml]# echo '/xgpwsd *(rw,sync,no_root_squash)' &gt;&gt; /etc/exports//设置共享目录权限[root@master heml]# systemctl restart nfs-server[root@master heml]# systemctl restart rpcbind//重启nfs服务[root@master heml]# showmount -e//测试一下 4、创建pv 12345678910111213141516[root@master xgp]# vim nfs-pv1.yml apiVersion: v1kind: PersistentVolumemetadata: name: mysqlpvspec: capacity: storage: 8Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle nfs: path: /xgpwsd/xgp server: 192.168.1.21[root@master xgp]# mkdir /xgpwsd/xgp//创建所需目录 执行一下 1[root@master xgp]# kubectl apply -f nfs-pv1.yml 查看一下 1[root@master xgp]# kubectl get pv 5、创建StorageClass资源对象。 （1）创建rbac权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@master yaml]# vim rbac.yaml apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: default---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: defaultrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: default #必写字段roleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io 执行一下 1[root@master yaml]# kubectl apply -f rbac.yaml （2）创建Deployment资源对象，用Pod代替 真正的NFS服务。 123456789101112131415161718192021222324252627282930313233343536[root@master yaml]# vim nfs-deployment.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisionerspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: xgp - name: NFS_SERVER value: 192.168.1.21 - name: NFS_PATH value: /xgpwsd/wsd volumes: - name: nfs-client-root nfs: server: 192.168.1.21 path: /xgpwsd/wsd [root@master heml]# mkdir /xgpwsd/wsd//创建指定目录 执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml 查看一下 1[root@master yaml]# kubectl get pod （3）创建storageclass的yaml文件 1234567[root@master yaml]# vim xgp-storageclass.yaml apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: xgp-nfsprovisioner: xgp #通过provisioner字段关联到上述DeployreclaimPolicy: Retain 执行一下 1[root@master yaml]# kubectl apply -f xgp-storageclass.yaml 查看一下 1[root@master yaml]# kubectl get sc 6、创建一个mysql服务 123456789[root@master ~]# docker pull mysql:5.7.14//下载所需镜像[root@master yaml]# helm fetch stable/mysql//直接下载stable/mysql的chart包[root@master yaml]# tar -zxf mysql-0.3.5.tgz //解压mysql包[root@master yaml]# cd mysql/[root@master mysql]# vim values.yaml //修改values.yaml文件，添加storageClass存储卷 12[root@master mysql]# helm install stable/mysql -n xgp-mysql --set mysqlRootPassword=123.com -f values.yaml //基于values.yaml和stable/mysql开启一个密码为123.com的mysqlpod 查看一下 1[root@master mysql]# kubectl get svc 1[root@master mysql]# kubectl get pod -o wide 7、进入mysql数据库，创建一个test库，库中一张test表，内容为： 9527。 1[root@master xgp]# kubectl exec -it bdqn-mysql-mysql-7b89c7b99-8ff2r -- mysql -u root -p123.com 创建数据库 1mysql&gt; create database test; 切换数据库 1mysql&gt; use test; 创建表 1mysql&gt; create table test( id int(4))； 在表中插入数据 1mysql&gt; insert test values(9527); 查看表 1mysql&gt; select * from test; 8、模拟数据库Pod失败，待Pod重启后，查看对应数据是否还存在？ 123[root@master mysql]# kubectl delete pod xgp-mysql-mysql-67c6fb5f9-4h4kz//删除这个pod让他重新生成[root@master mysql]# kubectl get pod 进入新的pod查看 12345678910111213[root@master mysql]# kubectl exec -it xgp-mysql-mysql-67c6fb5f9-k4c29 -- mysql -u root -p123.commysql&gt; use test;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from test;+------+| id |+------+| 9527 |+------+1 row in set (0.00 sec)","path":"posts/h8er.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"k8s的持续集成（jenkins+gitlab+k8s）","text":"应用场景： 问题项目分为app和后台两种，为了保证再同一个环境下面测试，所以不可能链接开发本地服务进行测试，所以需要搭建一个测试环境，供app进行开发测试。这个时候就有一个问题，如果开发新增加功能或者app调试的时候发现问题，这个时候就需要提交新的代码或者修复bug，然后重新发布到测试环境中去。但是后台人员又不能进入Linux服务器中，只能通过Linux运维人员来重新部署，这样的效率就会极低。 方案：基于这种模式下面的，我们引入了Jenkins工具，通过Jenkins来拉取svn/git代码到服务器中，再Jenkins中编写Linux运行脚本，通过脚本我们就可以对代码进行编译运行，然后重新发布到服务器中运行。后端人员也不需要通知Linux运维人员来执行这个操作，直接再Jenkins的控制台就可以执行了。 实验环境 IP 主机名称 服务 192.168.1.21 master k8s 192.168.1.22 node01 k8s 192.168.1.10 git gitlab 192.168.1.13 jenkins jenkins 总体流程： 在开发机开发代码后提交到gitlab 之后通过webhook插件触发jenkins进行构建，jenkins将代码打成docker镜像，push到docker-registry 之后将在k8s-master上执行rc、service的创建，进而创建Pod，从私服拉取镜像，根据该镜像启动容器 应用构建和发布流程说明。 用户向Gitlab提交代码，代码中必须包含Dockerfile 将代码提交到远程仓库 用户在发布应用时需要填写git仓库地址和分支、服务类型、服务名称、资源数量、实例个数，确定后触发Jenkins自动构建 Jenkins的CI流水线自动编译代码并打包成docker镜像推送到Harbor镜像仓库 Jenkins的CI流水线中包括了自定义脚本，根据我们已准备好的kubernetes的YAML模板，将其中的变量替换成用户输入的选项 生成应用的kubernetes YAML配置文件 更新Ingress的配置，根据新部署的应用的名称，在ingress的配置文件中增加一条路由信息 更新PowerDNS，向其中插入一条DNS记录，IP地址是边缘节点的IP地址。关于边缘节点，请查看边缘节点配置 Jenkins调用kubernetes的API，部署应用 一、前期工作 1、先验证k8s集群（1.21和1.22） 1[root@master ~]# kubectl get nodes 2、master部署私有仓库 Docker01部署 12345678910111213141516171872 docker pull registry//下载registry镜像73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest//基于registry镜像，启动一台容器78 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.21:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker76 docker tag httpd:latest 192.168.1.11:5000/web:v1 76 docker tag httpd:latest 192.168.1.11:5000/web:v2//把容器重命名一个标签77 docker ps 123456789101178 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker100 docker push 192.168.1.11:5000/web:v1100 docker push 192.168.1.11:5000/web:v2//上传容器到私有仓库 Docker02和docker03加入私有仓库 12345678978 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker99 docker pull 192.168.1.21:5000/web:v1//测试下载 3、然后重要的地方到了，建立 yaml配置文件让kubernetes自己控制容器集群。 用来模拟我们部署的服务 12345678910111213141516171819[root@master app]# vim deploy.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: webspec: replicas: 2 template: metadata: labels: name: web spec: containers: - name: web image: 192.168.1.21:5000/web:v1 imagePullPolicy: Always #改为本地仓库下载 ports: - containerPort: 80 执行一下 1[root@master app]# kubectl apply -f deploy.yaml 查看一下 1[root@master app]# kubectl get pod 可是容器的ip只能在容器本机上访问，集群内的其他主机和集群外的主机都没办法访问，这个时候就需要将容器的端口映射到服务器上的端口了，所以需要做一个service的模板。service 模板可以将容器的端口映射到服务器的端口上，并且可以固定映射在服务器上的端口。 12345678910111213141516[root@master app]# vim deploy-svc.yamlapiVersion: v1kind: Servicemetadata: labels: name: web name: webspec: type: NodePort ports: - port: 80 targetPort: 80 nodePort: 31234 selector: name: web 执行一下 1[root@master app]# kubectl apply -f deploy-svc.yaml 查看一下 1[root@master app]# kubectl get svc 访问一下http://192.168.1.21:31234/ 《ok kubernetes 完毕， 开始配置 jenkins+gitlab联动》 4、git和jenkins加入私有仓库 12345678978 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker99 docker pull 192.168.1.11/busybox:v1//测试下载 5、jenkins服务器向k8smaster做免密登录 1100 ssh-copy-id 192.168.1.21 二、安装jenkins（1.13） 安装java环境 123456789101112131415[root@jenkins ~]# tar -zxf jdk-8u231-linux-x64.tar.gz[root@jenkins ~]# mv jdk1.8.0_131 /usr/java#注意 这里有位置敏感，不要多一个“/”[root@jenkins ~]# vim /etc/profile #在最下面写export JAVA_HOME=/usr/javaexport JRE_HOME=/usr/java/jreexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATHexport CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar[root@jenkins ~]# source /etc/profile//环境变量生效[root@jenkins ~]# java -version//验证环境变量 安装tomcat 1234567[root@jenkins ~]# tar -zxf apache-tomcat-7.0.54.tar.gz [root@jenkins ~]# mv apache-tomcat-7.0.54 /usr/tomcat7[root@jenkins ~]# cd /usr/tomcat7/webapps/[root@jenkins webapps]# rm -rf *[root@jenkins webapps]# cp /root/jenkins.war . #这几步是jenkins的包放进了tomcat里[root@jenkins webapps]# vim /usr/tomcat7/conf/server.xml //修改tomcat的字符集 12345678910[root@jenkins webapps]# cd /usr/tomcat7/bin/[root@jenkins bin]# vim catalina.sh #!/bin/shexport CATALINA_OPTS=\"-DJENKINS_HOME=/data/jenkins\"export JENKINS_JAVA_OPTIONS=\"-Djava.awt.headless=true -Dhudson.ClassicPluginStrategy.noBytecodeTransformer=true\"//这两行添加的是jenkins的家目录位置，这个很重要[root@jenkins bin]# ./catalina.sh start //启动tomcat 1[root@jenkins bin]# netstat -anput | grep 8080 浏览器安装jenkins http://192.168.1.11:8080/jenkins 12[root@jenkins bin]# cat /data/jenkins/secrets/initialAdminPasswordc577cbf75d934878a94b0f9e00ada328 //复制密码 （1）推荐安装 #左边是自动安装， 右边是自定义安装，我们选左边的，如果不是这个画面则说明网络很卡或者没有网(推荐使用右边的，然后选择不安装插件，之后可以自定义安装） （2）这个是自定义安装（自己上传的包） 12345678[root@autoweb bin]# ./catalina.sh stop[root@autoweb ~]# cd /data/jenkins/plugins/[root@autoweb jenkins]# mv plugins plugins/.bk然后上传plugins.tar.gz包：[root@autoweb jenkins]# tar -zxf plugins.tar.gz [root@autoweb ~]# cd /usr/tomcat7/bin/[root@autoweb bin]# ./catalina.sh stop[root@autoweb bin]# ./catalina.sh start 输入密码后断网 （3）两个剩下的方法一样 下载中文插件 系统管理-----&gt;插件管理-----&gt;avalilable(可选)然后搜索localization-zh-cn 然后还需要3个插件 三、安装gitlab（1.10） GitLab CI 是 GitLab 默认集成的 CI 功能，GitLab CI 通过在项目内 .gitlab-ci.yaml 配置文件读取 CI 任务并进行相应处理；GitLab CI 通过其称为 GitLab Runner 的 Agent 端进行 build 操作；Runner 本身可以使用多种方式安装，比如使用 Docker 镜像启动等；Runner 在进行 build 操作时也可以选择多种 build 环境提供者；比如直接在 Runner 所在宿主机 build、通过新创建虚拟机(vmware、virtualbox)进行 build等；同时 Runner 支持 Docker 作为 build 提供者，即每次 build 新启动容器进行 build；GitLab CI 其大致架构如下 12345# yum -y install curl policycoreutils openssh-server openssh-clients postfix git# systemctl enable sshd# systemctl start sshd# systemctl enable postfix# systemctl start postfix 安装gitlab-ce 1[root@git ~]# curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash 注：由于网络问题，国内用户，使用清华大学的镜像源进行安装： 1234567891011121314151617181920212223242526272829[root@git ~]# vim /etc/yum.repos.d/gitlab-ce.repo[gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7repo_gpgcheck=0gpgcheck=0enabled=1gpgkey=https://packages.gitlab.com/gpg.key[root@git ~]# yum makecache//保存到本地[root@git ~]# yum -y install gitlab-ce #这两条命令是把gitlab源先加入了yum，然后yum下载gitlab[root@git ~]# vim /etc/gitlab/gitlab.rb //修改端口是为了防止端口冲突，因为80默认是http服务的 external_url 'http://192.168.1.21:90' #端口， unicorn默认是8080 也是tomcat的端口 unicorn['listen'] = '127.0.0.1'unicorn['port'] = 3000 [root@git ~]# gitlab-ctl reconfigure //启动gitlab，这个过程可能会有点慢[root@git ~]# ls /etc/yum.repos.d///查看一下 访问192.168.1.10:90 在网页配置用户密码后则安装完毕。用户默认root，这里让设置一个密码再登录，这里设置12345.com（相对较短的密码不让设置） 四、jenkins和gitlab相互关联 jenkins：工具集成平台 gitlab: 软件托管平台 部署这两个服务的联动，需要经过ssh验证。 1、首先我们需要在gitlab上绑定jenkins服务器的ssh公钥，这里我们使用的是root用户的公私钥，切记生产环境是不允许随便用root的 （1）jenkins 12[root@jenkins ~]# ssh-keygen -t rsa //然后不输入只回车会生成一对公私钥 默认在/root/.ssh/目录里 123[root@jenkins ~]# cat /root/.ssh/id_rsa.pub //查看公钥并复制ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDMA4+je3NsxZrF2v8TPLXJp1ejwy1YokXipEFyGVNo5IbtkiBDwBLOAl5i7yromY8YGgoNNriE2g89IM/44BGC5UDCokQ69Ze9Ta9Kynv3/1PDFXIABJJG0f6LsUqt0nKFaFoGz3ZuYAnl6AzLpXEic8DBDrsFk+UGrxvMfSEqHlYO2b7jRXE1HGRnqI/IcVB190cLT1kmBKi7hSqUNBc1cY6t3a6gGiBpp9tc8PW4r/RcLblhAL1LKx8x37NOZkqox8IMh3eM/wtWwAVFlI8XU+sz9akzJOVmd1ArT5Q4w8WA/uVHCDUGVI/fli/ZRv+mNZyF3EH26runctb5LkCT root@jenkins （2）gitlab 在这里放刚才拷贝的公钥保存就行了。 我们先在gitlab上创建一个代码仓库 点击 new project 输入一个仓库的名字，权限选择公共的（public）然后直接点击创建 点击新建一个new.file 写入代码，起一个名字然后保存 创建好了，然后在本地测试一下是否可用 12345678910[root@git ~]# mkdir xgp[root@git ~]# cd xgp/[root@git xgp]# git clone git@192.168.1.10:root/xgp-demo.git//克隆xgp-demo仓库到本地[root@git xgp]# ls xgp-demo/index.html[root@git xgp]# cat xgp-demo/index.html print: \"hello word!!!\"//查看一下 （3）自动构建 安装插件 先进入到之前查看插件的地方 系统设置----插件管理----高级_—上传插件gitlab-oauth、gitlab-plugin、 windows-slaves、ruby-runt ime、gitlab-hook （4）如果可以用，则打开jenkins 点击新建 地址粘贴进去以后没有报错则没错 但是很伤心它报错了，那是因为jenkins和git没有关联上 解决 git主机生成ssh密钥 1234[root@jenkins ~]# ssh-keygen -t rsa //然后不输入只回车会生成一对公私钥[root@jenkins ~]# cat /root/.ssh/id_rsa //查看密钥并复制 下面的这个插件很重要，就是他实现自动化更新的webhook插件，安装过了就会有这条，然后点击这条下面出来的这些东西保持默认就行。同时注意复制 这个里面写的是jenkins构建时候会执行的shell脚本，这个是最重要的，就是他实现了下端kubernetes自动更新容器的操作。 12345678910111213#!/bin/bashbackupcode=\"/data/backcode/$JOB_NAME/$BUILD_NUMBER\" mkdir -p $backupcode #jenkins创建上述目录chmod 644 \"$JENKINS_HOME\"/workspace/\"$JOB_NAME\"/*rsync -acP \"$JENKINS_HOME\"/workspace/\"$JOB_NAME\"/* $backupcode #$JENKINS_HOME和$JOB_NAME同步最新消息#ssh root@192.168.1.21 sed -i 's/v1/v2/g' /root/app/deploy.yaml #更改镜像版本echo From 192.168.1.21:5000/web:v1 &gt; \"$JENKINS_HOME\"/workspace/Dockerfileecho COPY ./\"$JOB_NAME\"/* /usr/local/apache2/htdocs/ &gt;&gt; \"$JENKINS_HOME\"/workspace/Dockerfiledocker rmi 192.168.1.21:5000/web:v1docker build -t 192.168.1.21:5000/web:v1 /\"$JENKINS_HOME\"/workspace/.docker push 192.168.1.21:5000/web:v1ssh root@192.168.1.21 kubectl delete deployment webssh root@192.168.1.21 kubectl apply -f /root/app/deploy.yaml $JOB_NAME：项目名称 $BUILD_NUMBER：第几次构建 $JENKINS_HOME：jenkins的家目录 完事以后先别保存，首先复制一下上面的jenkins地址，然后去gitlab上绑定webhook 保存，登陆gitlab，点击下图这个设置 测试显示下图 的蓝条说明jenkins 已经连通了gitlab 回到Jenkins开启匿名访问权限 测试显示下图 的蓝条说明jenkins 已经连通了gitlab 好了，jenkins和gitlab 都已经互相的ssh通过了，然后我们最后需要做的一个ssh是关于jenkins ///注意，这里是从git和jenkins向master节点做免密登录。 12[root@git ~]# ssh-copy-id root@192.168.1.21[root@jenkins ~]# ssh-copy-id root@192.168.1.21 好了，环境全部部署完毕！！！。开始测试 五、测试 测试的方法很简单，就是在gitlab上新建代码，删除代码，修改代码，都会触发webhook进行自动部署。最终会作用在所有的nginx容器中，也就是我们的web服务器。 这里我修改了之前建立的 index.html文件 保存以后，就打开浏览器 一直访问kubernetes-node 里面的容器了 访问一下http://192.168.1.21:31234/ 如果没有变，应该注意查看是否在jenkins上构建完成，等以小会就可以了。 构建成功 六、GitLab CI 总结 CS 架构 GitLab 作为 Server 端，控制 Runner 端执行一系列的 CI 任务；代码 clone 等无需关心，GitLab 会自动处理好一切；Runner 每次都会启动新的容器执行 CI 任务 容器即环境 在 Runner 使用 Docker build 的前提下；所有依赖切换、环境切换应当由切换不同镜像实现，即 build 那就使用 build 的镜像，deploy 就用带有 deploy 功能的镜像；通过不同镜像容器实现完整的环境隔离 CI即脚本 不同的 CI 任务实际上就是在使用不同镜像的容器中执行 SHELL 命令，自动化 CI 就是执行预先写好的一些小脚本 敏感信息走环境变量 一切重要的敏感信息，如账户密码等，不要写到 CI 配置中，直接放到 GitLab 的环境变量中；GitLab 会保证将其推送到远端 Runner 的 SHELL 变量中","path":"posts/b04b.html","date":"09-13","excerpt":"","tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://wsdlxgp.top/tags/jenkins/"},{"name":"gitlab","slug":"gitlab","permalink":"https://wsdlxgp.top/tags/gitlab/"}]},{"title":"k8s的charts的四种安装方式及helm私有仓库","text":"自定义helm模板 https://hub.helm.sh/ 1、开发自己的chare包 12345678910111213141516[root@master ~]# helm create mychare//创建一个名为mychare的chare包[root@master ~]# tree -C mychare///以树状图查看一下chare包mychare/├── charts├── Chart.yaml├── templates│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── ingress.yaml│ ├── NOTES.txt│ ├── service.yaml│ └── tests│ └── test-connection.yaml└── values.yaml 2、调试chart 123[root@master mychare]# cd[root@master ~]# helm install --dry-run --debug mychare//检查这个mychare是否有问题 3、安装chart 1[root@node02 ~]# docker pull nginx:stable （1）通过仓库安装 123456[root@master mychare]# helm search redis//搜索chare包[root@master mychare]# helm repo list//查看是否有能访问仓库[root@master mychare]# helm install stable/redis//安装 （2）通过tar包安装 1234567891011121314151617[root@master ~]# helm fetch stable/redis//直接下载chare包[root@master ~]# tar -zxf redis-1.1.15.tgz//解压下载的chare包[root@master ~]# tree -C redisredis├── Chart.yaml├── README.md├── templates│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── networkpolicy.yaml│ ├── NOTES.txt│ ├── pvc.yaml│ ├── secrets.yaml│ └── svc.yaml└── values.yaml （3）通过chare本地目录安装 12345[root@master ~]# helm fetch stable/redis//直接下载chare包[root@master ~]# tar -zxf redis-1.1.15.tgz//解压下载的chare包[root@master ~]# helm install redis （4）通过URL安装 1[root@master ~]# helm install https://example.com/charts/foo-1.2.3.tgz （5）使用本地目录安装： 12[root@master ~]# cd mychare/[root@master mychare]# vim values.yaml 12[root@master mychare]# cd templates/[root@master templates]# vim service.yaml 123[root@master templates]# cd ..[root@master mychare]# helm install -n test ../mychare/[root@master ~]# helm upgrade test mychare/ -f mychare/values.yaml 4、例子 使用mychart部署一个实例: xgp。使用镜像为私有镜像v1 版本。 完成之后，镜像版本。 全部成功之后，将实例做一个升级，将镜像改为v2版本。 更改镜像为私有镜像 1[root@master ~]# vim mychare/values.yaml 12[root@master ~]# helm install -n xgp mychare/ -f mychare/values.yaml[root@master ~]# kubectl get deployments. -o wide 1[root@master ~]# vim mychare/values.yaml 12[root@master ~]# helm upgrade xgp mychare/ -f mychare/values.yaml [root@master ~]# kubectl get deployments. -o wide 1[root@master ~]# kubectl edit deployments. xgp-mychare 1[root@master ~]# kubectl get deployments. -o wide 创建自己的Repo仓库 1、node01启动一个httpd的容器 123456[root@node01 ~]# mkdir /var/xgp//创建一个目录[root@node01 ~]# docker pull httpd//下载httpd镜像[root@node02 ~]# docker run -d -p 8080:80 -v /var/xgp:/usr/local/apache2/htdocs httpd//启动一个httpd的容器 2、master节点上，将mychart目录打包。 12[root@master ~]# helm package mychare/Successfully packaged chart and saved it to: /root/mychare-0.1.0.tgz 3、生成仓库的index文件。 12345678[root@master ~]# mkdir myrepo//创建一个目录存放打包的chare[root@master ~]# mv mychare-0.1.0.tgz myrepo///移动打包好的文件[root@master ~]# helm repo index myrepo/ --url http://192.168.1.22:8080/charts//生成仓库的index文件[root@master ~]# ls myrepo/index.yaml mychare-0.1.0.tgz 4、将生成的tar包和index.yaml上传到node01的/var/www/charts目录下. node01创建目录 1[root@node01 ~]# mkdir /var/xgp/charts master移动动到 1[root@master ~]# scp myrepo/* node01:/var/xgp/charts/ node01查看一下 12[root@node01 ~]# ls /var/xgp/charts/index.yaml mychare-0.1.0.tgz 5、添加新的repo仓库。 12[root@master ~]# helm repo add newrepo http://192.168.1.22:8080/charts[root@master ~]# helm repo list 1[root@master ~]# helm search mychare 6、我们就可以直接使用新的repo仓库部署实例了。 12[root@master ~]# helm install newrepo/mychare -n wsd[root@master ~]# helm list 7.如果以后仓库中新添加了chart包,需要用helm repo update命玲更新本地的index文件。 练习： 新创建一个bdqn.的chart包。然后将chart包上传到上述repo源中。 12345678[root@master ~]# helm create bdqn[root@master ~]# helm package bdqn/[root@master ~]# mv bdqn-0.1.0.tgz myrepo/[root@master ~]# helm repo index myrepo/ --url http://192.168.1.22:8080/charts[root@master myrepo]# scp bdqn-0.1.0.tgz index.yaml node01:/var/xgp/charts[root@master myrepo]# helm repo update[root@master myrepo]# helm search bdqn[root@master myrepo]# helm install http://192.168.1.22:8080/charts/bdqn-0.1.0.tgz 1）创建helm的私有仓库，以自己的名字命名。 1、node01启动一个httpd的容器 123456[root@node01 ~]# mkdir /var/xgp//创建一个目录[root@node01 ~]# docker pull httpd//下载httpd镜像[root@node02 ~]# docker run -d -p 8080:80 -v /var/xgp:/usr/local/apache2/htdocs httpd//启动一个httpd的容器 3、生成仓库的index文件。 1234[root@master ~]# mkdir xgprepo//创建一个目录存放打包的chare[root@master ~]# helm repo index xgprepo/ --url http://192.168.1.22:8080/charts//生成仓库的index文件 4、将生成的index.yaml上传到node01的/var/www/charts目录下. node01创建目录 1[root@node01 ~]# mkdir /var/xgp/charts master移动动到 1[root@master ~]# scp xgprepo/* node01:/var/xgp/charts/ node01查看一下 12[root@node01 ~]# ls /var/xgp/charts/index.yaml 5、添加新的repo仓库 12[root@master ~]# helm repo add xgp http://192.168.1.22:8080/charts[root@master ~]# helm repo list 2） 自定义一个chart包，要求这个包运行一个httpd的服务，使用私有镜像v1版本。3个副本Pod，service类型更改为NodePort，端口指定为:30000 自定义一个chart包 12[root@master ~]# helm create wsd//创建一个名为wsd的chares包 按照要求修改配置文件 123456789101112131415161718192021222324252627282930313233343536373839[root@master ~]# cd wsd///进入这个chart包[root@master wsd]# vim values.yaml//修改wsd的配置文件replicaCount: 3 #三个副本image: repository: 192.168.1.21:5000/web #更改镜像为私有镜像 tag: v1 #镜像标签v1 pullPolicy: IfNotPresent imagePullSecrets: []nameOverride: \"\"fullnameOverride: \"\"service: type: NodePort #修改模式为映射端口 port: 80 nodePort: 30000 #添加端口[root@master wsd]# vim templates/service.yaml apiVersion: v1kind: Servicemetadata: name: &#123;&#123; include \"wsd.fullname\" . &#125;&#125; labels:&#123;&#123; include \"wsd.labels\" . | indent 4 &#125;&#125;spec: type: &#123;&#123; .Values.service.type &#125;&#125; ports: - port: &#123;&#123; .Values.service.port &#125;&#125; targetPort: http protocol: TCP name: http nodePort: &#123;&#123; .Values.service.nodePort &#125;&#125; #“添加”能让服务识别到nodePort的端口 selector: app.kubernetes.io/name: &#123;&#123; include \"wsd.name\" . &#125;&#125; app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125; 测试一下 1[root@master ~]# helm install -n wsd wsd/ -f wsd/values.yaml 查看一下镜像版本 1[root@master ~]# kubectl get deployments. -o wide 访问一下 1[root@master ~]# curl 127.0.0.1:30000 3) 将实例进行更新，要求镜像生产v2版本。 私有镜像和官方镜像升级有所不同，官方的只需通过 （helm upgrade --set imageTag=“标签” 服务名称 charts包名 ）进行更改标签即可，而私有镜像需通过更改values.yaml中的标签才行比较麻烦一点。 1、修改values.yaml 1234567891011121314[root@master ~]# vim wsd/values.yaml # Default values for wsd.# This is a YAML-formatted file.# Declare variables to be passed into your templates.replicaCount: 3image: repository: 192.168.1.21:5000/web tag: v2 #修改标签为v2 pullPolicy: IfNotPresent[root@master ~]# helm upgrade wsd wsd/ -f wsd/values.yaml//基于配置文件刷新一下wsd服务 查看一下 1[root@master ~]# kubectl get deployments. -o wide 访问一下 1[root@master ~]# curl 127.0.0.1:30000 2、使用edit进行版本更新 确定wsd这个服务开启 1[root@master ~]# kubectl edit deployments. wsd 查看一下 1[root@master ~]# kubectl get deployments. -o wide 访问一下 1[root@master ~]# curl 127.0.0.1:30000 4）重新定义一个chart包，名称为: new-test,将这个包上传到上述私有仓库中。 1[root@master ~]# helm repo list 1234567891011121314151617[root@master ~]# helm create xgp-wsd//创建一个名为xgp-wsd的charts包[root@master ~]# helm package xgp-wsd///将xgp-wsd打包在当前目录[root@master ~]# mv xgp-wsd-0.1.0.tgz xgprepo///把打包文件放到仓库目录[root@master ~]# helm repo index xgprepo/ --url http://192.168.1.22:8080/charts//把仓库目录新加入的charts包信息记录在index.yaml中，使得其他加入的主机可以识别到，仓库的charts包[root@master ~]# scp xgprepo/* node01:/var/xgp/charts//将仓库目录的文件移动到httpd服务上，使各个主机可以访问，下载仓库的charts包[root@master ~]# helm repo update //更新一下chart存储库 查看一下 1[root@master ~]# helm search xgp-wsd","path":"posts/e7d.html","date":"09-12","excerpt":"","tags":[{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"k8s中helm安装部署，升级和回滚（chart，helm，tiller，StorageClass）","text":"一、Helm介绍 helm是基于kubernetes 的包管理器。它之于 kubernetes 就如 yum 之于 centos，pip 之于 python，npm 之于 javascript 那 helm 的引入对于管理集群有哪些帮助呢？ 更方便地部署基础设施，如 gitlab，postgres，prometheus，grafana 等 更方便地部署自己的应用，为公司内部的项目配置 Chart，使用 helm 结合 CI，在 k8s 中部署应用一行命令般简单 1、Helm用途 Helm把Kubernetes资源(比如deployments、services或 ingress等) 打包到一个chart中，而chart被保存到chart仓库。通过chart仓库可用来存储和分享chart。Helm使发布可配置，支持发布应用配置的版本管理，简化了Kubernetes部署应用的版本控制、打包、发布、删除、更新等操作。 做为Kubernetes的一个包管理工具，用来管理charts——预先配置好的安装包资源，有点类似于Ubuntu的APT和CentOS中的yum。 Helm具有如下功能： 创建新的chart chart打包成tgz格式 上传chart到chart仓库或从仓库中下载chart 在Kubernetes集群中安装或卸载chart 管理用Helm安装的chart的发布周期 使用Helm可以完成以下事情： 管理Kubernetes manifest files 管理Helm安装包charts 基于chart的Kubernetes应用分发 2、Helm组件及相关术语 开始接触Helm时遇到的一个常见问题就是Helm中的一些概念和术语非常让人迷惑，我开始学习Helm就遇到这个问题。 因此我们先了解一下Helm的这些相关概念和术语。 包管理工具: Helm: Kubernetes的应用打包工具，也是命令行工具的名称。 Helm CLI：是 Helm 客户端，可以在本地执行 Tiller: Helm的服务端，部署在Kubernetes集群中，用于处理Helm的相关命令。 helm的作用：像centos7中的yum命令一样，管理软件包，只不过helm这儿管理的是在k8s上安装的各种容器。 tiller的作用：像centos7的软件仓库一样，简单说类似于/etc/yum.repos.d目录下的xxx.repo。 Repoistory: Helm的软件仓库，repository本质上是一个web服务器，该服务器保存了chart软件包以供下载，并有提供一个该repository的chart包的清单文件以供查询。在使用时，Helm可以对接多个不同的Repository。 Charts：是一个Helm的程序包，它包含了运行一个kubernetes应用程序所需要的镜像、依赖关系和资源定义等。 Release：应用程序运行Charts之后，得到的一个实例。 需要特别注意的是， Helm中提到的Release和我们通常概念中的版本有所不同，这里的Release可以理解为Helm使用Chart包部署的一个应用实例。 其实Helm中的Release叫做Deployment更合适。估计因为Deployment这个概念已经被Kubernetes使用了，因此Helm才采用了Release这个术语。 命令介绍 123456789101112131415161718[root@master ~]# helm search//查看可用的Charts包[root@master ~]# helm inspect stable/redis//查看stable/redis包的详细信息[root@master mysql]# helm fetch stable/mysql//直接下载stable/mysql的chart包[root@master ~]# helm install stable/redis -n redis --dry-run //基于stable/redis包运行一个名为redis的服务（把--dry-run去掉之后相当于安装了一个服务）[root@master ~]# helm list//查看安装的服务[root@master ~]# helm delete redis//删除这个服务[root@master mysql]# helm upgrade --set imageTag=5.7.15 xgp-mysql stable/mysql -f values.yaml //mysql服务的升级[root@master mysql]# helm history xgp-mysql//查看历史版本[root@master mysql]# helm rollback xgp-mysql 1 //回滚到版本一 123456789101112131415161718192021222324252627282930http://hub.kubeapps.com/completion # 为指定的shell生成自动完成脚本（bash或zsh）create # 创建一个具有给定名称的新 chartdelete # 从 Kubernetes 删除指定名称的 releasedependency # 管理 chart 的依赖关系fetch # 从存储库下载 chart 并（可选）将其解压缩到本地目录中get # 下载一个命名 releasehelp # 列出所有帮助信息history # 获取 release 历史home # 显示 HELM_HOME 的位置init # 在客户端和服务器上初始化Helminspect # 检查 chart 详细信息install # 安装 chart 存档lint # 对 chart 进行语法检查list # releases 列表package # 将 chart 目录打包成 chart 档案plugin # 添加列表或删除 helm 插件repo # 添加列表删除更新和索引 chart 存储库reset # 从集群中卸载 Tillerrollback # 将版本回滚到以前的版本search # 在 chart 存储库中搜索关键字serve # 启动本地http网络服务器status # 显示指定 release 的状态template # 本地渲染模板test # 测试一个 releaseupgrade # 升级一个 releaseverify # 验证给定路径上的 chart 是否已签名且有效version # 打印客户端/服务器版本信息dep # 分析 Chart 并下载依赖 3、组件架构 Helm Client 是用户命令行工具，其主要负责如下： 本地 chart 开发 仓库管理 与 Tiller sever 交互 发送预安装的 chart 查询 release 信息 要求升级或卸载已存在的 release Tiller Server是一个部署在Kubernetes集群内部的 server，其与 Helm client、Kubernetes API server 进行交互。Tiller server 主要负责如下： 监听来自 Helm client 的请求 通过 chart 及其配置构建一次发布 安装 chart 到Kubernetes集群，并跟踪随后的发布 通过与Kubernetes交互升级或卸载 chart 简单的说，client 管理 charts，而 server 管理发布 release helm客户端 helm客户端是一个命令行工具，负责管理charts、reprepository和release。它通过gPRC API（使用kubectl port-forward将tiller的端口映射到本地，然后再通过映射后的端口跟tiller通信）向tiller发送请求，并由tiller来管理对应的Kubernetes资源。 tiller服务端 tiller接收来自helm客户端的请求，并把相关资源的操作发送到Kubernetes，负责管理（安装、查询、升级或删除等）和跟踪Kubernetes资源。为了方便管理，tiller把release的相关信息保存在kubernetes的ConfigMap中。 tiller对外暴露gRPC API，供helm客户端调用。 4、工作原理 Chart Install 过程： Helm从指定的目录或者tgz文件中解析出Chart结构信息 Helm将指定的Chart结构和Values信息通过gRPC传递给Tiller Tiller根据Chart和Values生成一个Release Tiller将Release发送给Kubernetes运行。 Chart Update过程： Helm从指定的目录或者tgz文件中解析出Chart结构信息 Helm将要更新的Release的名称和Chart结构，Values信息传递给Tiller Tiller生成Release并更新指定名称的Release的History Tiller将Release发送给Kubernetes运行 Chart Rollback helm将会滚的release名称传递给tiller tiller根据release名称查找history tiller从history中获取到上一个release tiller将上一个release发送给kubernetes用于替换当前release Chart处理依赖 Tiller 在处理 Chart 时，直接将 Chart 以及其依赖的所有 Charts 合并为一个 Release，同时传递给 Kubernetes。因此 Tiller 并不负责管理依赖之间的启动顺序。Chart 中的应用需要能够自行处理依赖关系。 二、安装部署helm工具（客户端） 前提要求 Kubernetes1.5以上版本 集群可访问到的镜像仓库 执行helm命令的主机可以访问到kubernetes集群 （1）下载helm的包 12[root@master ~]#docker pull gcr.io/kubernetes-helm/tiller:v2.14.3[root@master ~]# wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz （2）把helm包的命令，复制到本地 123456[root@master helm]# mv linux-amd64/helm /usr/local/bin///移动命令目录到/usr/local/bin/[root@master helm]# chmod +x /usr/local/bin/helm //给予执行权限[root@master helm]# helm help//验证是否安装成功 （3）设置命令自动补全 123[root@master helm]# echo 'source &lt;(helm completion bash)' &gt;&gt; /etc/profile[root@master helm]# . /etc/profile//刷新一下 2、安装Tiller server（服务端，需要创建授权用户） 12345678910111213141516171819[root@master ~]# vim tiller-rbac.yaml #创建授权用户apiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system 执行一下 1[root@master ~]# kubectl apply -f tiller-rbac.yaml （1）Tiller server的环境初始化 12[root@master helm]# helm init --service-account=tiller//helm的服务端就是Tiller（因为是访问外国的网站，可能需要多次执行） 查看一下 1[root@master helm]# kubectl get deployment. -n kube-system 现在发现没有开启，那是因为默认下载的Google的镜像，下载不下来 （2）设置镜像源改为阿里云的 1[root@master helm]# helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts 查看一下 1[root@master helm]# helm version 3、部署一个实例helm install + charts -n Release名称。 1、关于这个Release的描述。 2、关于这个Release资源的描述。 3、怎么使用这个Release。 （1）Helm部署安装一个Mysql服务。 12[root@master ~]# helm search mysql//查看关于mysqk的Charts包 12[root@master ~]# helm install stable/mysql -n mysql //基于stable/mysql包安装一个名为MySQL的服务 查看一下 1[root@master ~]# helm list （2）Charts包解压过后的目录: 123[root@master ~]# cd .helm/cache/archive//查看helm缓存[root@master archive]# ls 123456[root@master mysql]# helm fetch stable/mysql//直接下载stable/mysql的chart包[root@master archive]# tar -zxf mysql-0.3.5.tgz //解压一下MySQL包[root@master archive]# tree -C mysql //树状图查看解压出来的mysql目录，-C:显示颜色 Chart.yaml：这个chart包的概要信息。（name和version 这两是必填项，其他可选。） README md：是这个chart包的一个使用帮助文档。 templates：chart包内各种资源对象的模板。 deployment.yaml：deployment 控制器的 Go 模板文件 _helpers.tpl：以 _ 开头的文件不会部署到 k8s 上，可用于定制通用信息 NOTES.txt：Chart 部署到集群后的一些信息 service.yaml：service 的 Go 模板文件 values.yaml：是这个chart包的默认的值，可以被templet内的yaml文件使用。 （3）Helm部署安装-个Mysql服务。 123456[root@master ~]# docker pull mysql:5.7.14[root@master ~]# docker pull mysql:5.7.15[root@master ~]# docker pull busybox:1.25.0下载所需的mysql镜像[root@master ~]# helm delete mysql --purge //删除之前的MySQL服务并清除缓存 （4）设置共享目录 12345678910111213[root@master ~]# yum -y install rpcbind nfs-utils//安装nfs[root@master ~]# mkdir /data//创建共享目录[root@master ~]# vim /etc/exports/data *(rw,sync,no_root_squash)//设置共享目录权限[root@master ~]# systemctl restart rpcbind[root@master ~]# systemctl restart nfs-server//重启nfs服务测试一下[root@master ~]# showmount -e （5）创建pv 12345678910111213141516[root@master xgp]# vim nfs-pv1.yml apiVersion: v1kind: PersistentVolumemetadata: name: mysqlpvspec: capacity: storage: 8Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle nfs: path: /data/mysqlpv server: 192.168.1.21[root@master xgp]# mkdir /data/mysqlpv//创建所需目录 执行一下 1[root@master xgp]# kubectl apply -f nfs-pv1.yml 查看一下 1[root@master xgp]# kubectl get pv （6）创建一个mysql服务 1[root@master xgp]# helm install stable/mysql -n bdqn-mysql --set mysqlRootPassword=123.com 查看一下 1[root@master xgp]# kubectl get pod （7）进入pod并查看一下 1234567891011[root@master xgp]# kubectl exec -it bdqn-mysql-mysql-7b89c7b99-8ff2r -- mysql -u root -p123.commysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.01 sec) 4、mysql服务的升级与回滚 （1）mysql服务的升级 1[root@master mysql]# helm upgrade --set imageTag=5.7.15 bdqn-mysql stable/mysql -f values.yaml 查看一下 1[root@master mysql]# kubectl get deployments. -o wide （2）mysql服务的回滚 12[root@master mysql]# helm history bdqn-mysql//查看历史版本 回滚到版本一 1[root@master mysql]# helm rollback bdqn-mysql 1 查看一下 1[root@master mysql]# kubectl get deployments. -o wide 三、小实验 在部署mysql的时候，如何开启storageclass，以及如何将service资源对象的类型更改为NodePort, 如何使用? 将上述部署的实例进行升级回滚操作。升级的时候镜像改为： mysql:5.7.15版本。回滚到最初的版本。 1、基于NFS服务，创建NFS服务。 下载nfs所需安装包 1[root@node02 ~]# yum -y install nfs-utils rpcbind 创建共享目录 1[root@master ~]# mkdir -p /xgp/wsd 创建共享目录的权限 12[root@master ~]# vim /etc/exports/xgp *(rw,sync,no_root_squash) 开启nfs和rpcbind（三台都要） 12[root@master ~]# systemctl start nfs-server.service [root@master ~]# systemctl start rpcbind 测试一下 1[root@master ~]# showmount -e 2、创建StorageClass资源对象。 （1）创建rbac权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@master yaml]# vim rbac.yaml apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: default---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: defaultrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: default #必写字段roleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io 执行一下 1[root@master yaml]# kubectl apply -f rbac.yaml （2）创建Deployment资源对象，用Pod代替 真正的NFS服务。 123456789101112131415161718192021222324252627282930313233[root@master yaml]# vim nfs-deployment.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisionerspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: xgp - name: NFS_SERVER value: 192.168.1.21 - name: NFS_PATH value: /xgp/wsd volumes: - name: nfs-client-root nfs: server: 192.168.1.21 path: /xgp/wsd 执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml 查看一下 1[root@master yaml]# kubectl get pod （3）创建storageclass的yaml文件 1234567[root@master yaml]# vim xgp-storageclass.yaml apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: xgp-nfsprovisioner: xgp #通过provisioner字段关联到上述DeployreclaimPolicy: Retain 执行一下 1[root@master yaml]# kubectl apply -f test-storageclass.yaml 查看一下 1[root@master yaml]# kubectl get sc 3、创建一个mysql服务 1234567891011[root@master ~]# docker pull mysql:5.7.14[root@master ~]# docker pull mysql:5.7.15[root@master ~]# docker pull busybox:1.25.0//下载所需镜像[root@master yaml]# helm fetch stable/mysql//直接下载stable/mysql的chart包[root@master yaml]# tar -zxf mysql-0.3.5.tgz //解压mysql包[root@master yaml]# cd mysql/[root@master mysql]# vim values.yaml //修改values.yaml文件，添加storageClass存储卷和更改svc的模式为NodePort 12[root@master mysql]# helm install stable/mysql -n xgp-mysql --set mysqlRootPassword=123.com -f values.yaml //基于values.yaml和stable/mysql开启一个密码为123.com的mysqlpod 查看一下 1[root@master mysql]# kubectl get svc 1[root@master mysql]# kubectl get pod -o wide 4、进入pod并查看一下 1234567891011[root@master mysql]# kubectl exec -it xgp-mysql-mysql-67c6fb5f9-dn7s2 -- mysql -u root -p123.commysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.01 sec) 5、mysql服务的升级与回滚 （1）mysql服务的升级 1[root@master mysql]# helm upgrade --set imageTag=5.7.15 xgp-mysql stable/mysql -f values.yaml 查看一下 1[root@master mysql]# kubectl get deployments. -o wide （2）服务的回滚 12[root@master mysql]# helm history xgp-mysql//查看历史版本 回滚到版本一 1[root@master mysql]# helm rollback xgp-mysql 1 查看一下 1[root@master mysql]# kubectl get deployments. -o wide 6、进入pod并查看一下 1234567891011[root@master mysql]# kubectl exec -it xgp-mysql-mysql-67c6fb5f9-dn7s2 -- mysql -u root -p123.commysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.01 sec) 四、总结 Helm作为kubernetes应用的包管理以及部署工具，提供了应用打包，发布，版本管理以及部署，升级，回退等功能。Helm以Chart软件包的形式简化Kubernetes的应用管理，提高了对用户的友好性。 使用心得 helm 客户端的功能非常简单，直接参考官网文档即可。 列一下相关使用心得： Helm 的所有功能都是围绕着 chart、release 和 repository 的； 仅初始化客户端相关配置且仅建立本地仓库，可执行 helm init --client-only --skip-refresh； 查找 chart 的方式是通过 HELM_HOME（默认是 ~/.helm 目录）下的 repositories 目录进行的，几个重要文件或目录为 cache、repositories/cache； 修改 chart index.yaml 的 url，可执行 helm serve --url http://demo.com 来重新 reindex； 依赖关系管理，requirements定义，子 chart 值定义； install 、 update 的方式管理不方便，这样需要维护 chart 的版本关系，集成 install 和 update ，组成类似 k8s 中的 apply 命令； package 命令 -u 可以更新依赖，建议推到 repositiories 前先 package ，否则后期可能出现依赖检测不全的错误； release 相关的信息存储在 k8s 的 configmap 中，命名形式为 release_name.v1 的格式。 rollback 相关功能就是通过存储在 configmap 中的信息进行回滚的； Helm 客户端与 k8s 中的 TillerServer 是通过 k8s 提供的 port-forward 来实现的，而 port-forward 需要在指定节点上部署 socat； TillerServer 可以不部署在 k8s 中， 此时 Helm 客户端需要通过 HELM_HOST 环境变量来指定 TillerServer 的地址和端口； 建议 TillerServer 部署在 k8s 中，既然 Helm 为 CNCF 的一员，那么就尽量把云原生做到极致吧； 写 chart 时多参考官方最佳实践，The Chart Best Practices Guide； 不足 Helm 虽然提供了 install、update 命令来安装或更新对应的 release，但这给使用者带来了需要维护 release 状态的压力。举个例子，在还没安装 release 之前，release 是不存在的，update 操作是会失败的。反之已经存在的 release，install 操作也会失败。其实大部分情况下我是不需要知道 release 的状态的，不管它存在还是不存在，我执行的命令就是我希望的意图，我希望 release 能成为我执行命令后的状态。这一点上 k8s 的 apply 命令就非常好，不需要用户来维护资源的状态。","path":"posts/5bc1.html","date":"09-11","excerpt":"","tags":[{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"}]},{"title":"k8s的HPA自动扩容与缩容","text":"HPA介绍 Kubernetes HPA（水平Pod自动缩放）Pod水平自动伸缩，通过此功能，只需简单的配置，即可便可以利用监控指标（cpu使用率、磁盘、内存等）自动的扩容或缩容服务中Pod数量，当业务需求增加时，系统将为您无缝地自动增加适量容器，提高系统稳定性。此处将详细讲解HPA的核心设计原理和基于Hepaster的使用方法。 前提条件 系统应该能否获取到当前Pod的资源使用情况 (意思是可以执行kubectl top pod命令,并且能够得到反馈信息)。 若要实现自动扩缩容的功能，还需要部署heapster服务，用来收集及统计资源的利用率，支持kubectl top命令，heapster服务集成在prometheus（普罗米修斯） MertricServer服务中，所以说，为了方便，我这里基于prometheus服务的环境上进行部署HPA（动态扩缩容）的服务。 实验环境 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于https://blog.51cto.com/14320361/2473879 的实验继续进行 heapster：这个组件之前是集成在k8s集群的,不过在1.12版本之后被移除了。如果还想使用此功能，应该部署metricServer, 这个k8s集群资源使用情况的聚合器。 Cousom：同样处于beta阶段(autoscaling/v2beta1)，但是涉及到自定义的REST API的开发，复杂度会大一些，并且当需要从自定义的监控中获取数据时，只能设置绝对值，无法设置使用率。 自动扩展主要分为两种： 水平扩展(scale out)，针对于实例数目的增减。 垂直扩展(scal up)，即单个实例可以使用的资源的增减, 比如增加cpu和增大内存。 HPA属于前者。它可以根据CPU使用率或应用自定义metrics自动扩展Pod数量(支持 replication controller、deployment 和 replica set)。 工作流程 创建HPA资源，设定目标CPU使用率限额，以及最大/最小实例数，一定要设置Pod的资源限制参数: request，否则HPA不会工作。 控制管理器每隔30s(在kube-controller-manager.service中可以通过–-horizontal-pod-autoscaler-sync-period修改)查询metrics的资源使用情况。 然后与创建时设定的值和指标做对比(平均值之和/限额)，求出目标调整的实例个数。 目标调整的实例数不能超过第一条中设定的最大/最小实例数。如果没有超过，则扩容；超过，则扩容至最大的实例个数。 重复第2-4步。 这里，我们使用一个测试镜像， 这个镜像基于php-apache制作的docker镜像，包含了一些可以运行cpu密集计算任务的代码。 1、创建一个deployment控制器 12345[root@master ~]#docker pull mirrorgooglecontainers/hpa-example:latest//下载hpa-example镜像[root@master ~]# kubectl run php-apache --image=mirrorgooglecontainers/hpa-example --requests=cpu=200m --expose --port=80//基于hpa-example镜像，运行一个deployment控制器，请求CPU的资源为200m，暴露一个80端口 查看一下 1[root@master ~]# kubectl get deployments. 2、创建HPA控制器 12[root@master ~]# kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10//当deployment资源对象的CPU使用率达到50%时，就进行扩容，最多可以扩容到10个 查看一下 1[root@master ~]# kubectl get hpa 3、测试（master开启三个端口） 新开启多个终端，对pod进行死循环请求php-apache的pod 端口一 （1）创建一个应用，用来不停的访问我们刚刚创建的php-apache的svc资源。 1[root@master ~]# kubectl run -i --tty load-generator --image=busybox /bin/sh （2）进入Pod内，执行以下这条命令.用来模拟访问php-apache的svc资源。 12[root@master ~]# while true; do wget -q -O- http://php-apache.default.svc.cluster.local ; done//不停地向php-apache的svc资源，发送ok 端口二 12[root@master ~]# kubectl get hpa -w//实时查看pod的cpu状态 可以看到php-apache的cpu使用情况已经超过了50% 端口三 12[root@master images]# kubectl get pod -w//实时查看pod的状态 可以看到当php-apache的cpu使用情况超过50%后，就会不断生成新的php-apache来进行负载均衡（目前设置的上线时10个），当然，如果cpu使用情况下降到50%，master就会陆续地删除php-apache，这样的使用可以减少不必要的资源浪费、资源分配不均等情况。 二、资源限制 1、基于Pod Kubernetes对资源的限制实际上是通过cgroup来控制的，cgroup 是容器的一组用来控制内核如何运行进程的相关属性集合。针对内存、CPU 和各种设备都有对应的cgroup 默认情况下，Pod运行没有CPU和内存的限额。这意味着系统中的任何 Pod将能够像执行该Pod所在的节点一样，消耗足够多的CPU和内存。一般会针对某些应用的pod资源进行资源限制，这个资源限制是通过 resources的requests和limits来实现 1[root@master ~]# vim cgroup-pod.yaml requests: 要分配的资源，limits为最高请求的资源值。可以简单的理解为初始值和最大值。 2、基于名称空间 1） 计算资源配额 1[root@master ~]# vim compute-resources.yaml 2）配置对象数量配额限制 1[root@master ~]# vim object-counts.yaml 3） 配置CPU和内存的LimitRange 1[root@master ~]# vim limitRange.yaml default 即 limit的值。 defaultRequest 即 request的值。","path":"posts/5f70.html","date":"09-10","excerpt":"","tags":[{"name":"HPA","slug":"HPA","permalink":"https://wsdlxgp.top/tags/HPA/"},{"name":"heapster","slug":"heapster","permalink":"https://wsdlxgp.top/tags/heapster/"},{"name":"top","slug":"top","permalink":"https://wsdlxgp.top/tags/top/"}]},{"title":"k8s群集的三种的Web-UI界面部署（dashboard、weave-scope、Prometheus）","text":"一、k8s的UI访问界面-dashboard 在dashboard中，虽然可以做到创建、删除、修改资源等操作，但通常情况下，我们会把它当做健康k8s集群的软件。 作为Kubernetes的Web用户界面，用户可以通过Dashboard在Kubernetes集群中部署容器化的应用，对应用进行问题处理和管理，并对集群本身进行管理。通过Dashboard，用户可以查看集群中应用的运行情况，同时也能够基于Dashboard创建或修改部署、任务、服务等Kubernetes的资源。通过部署向导，用户能够对部署进行扩缩容，进行滚动更新、重启Pod和部署新应用。当然，通过Dashboard也能够查看Kubernetes资源的状态。 1、Dashboard提供的功能 在默认情况下，Dashboard显示默认(default)命名空间下的对象，也可以通过命名空间选择器选择其他的命名空间。在Dashboard用户界面中能够显示集群大部分的对象类型。 1）集群管理 集群管理视图用于对节点、命名空间、持久化存储卷、角色和存储类进行管理。 节点视图显示CPU和内存的使用情况，以及此节点的创建时间和运行状态。 命名空间视图会显示集群中存在哪些命名空间，以及这些命名空间的运行状态。角色视图以列表形式展示集群中存在哪些角色，这些角色的类型和所在的命名空间。 持久化存储卷以列表的方式进行展示，可以看到每一个持久化存储卷的存储总量、访问模式、使用状态等信息；管理员也能够删除和编辑持久化存储卷的YAML文件。 2） 工作负载 工作负载视图显示部署、副本集、有状态副本集等所有的工作负载类型。在此视图中，各种工作负载会按照各自的类型进行组织。 工作负载的详细信息视图能够显示应用的详细信息和状态信息，以及对象之间的关系。 3） 服务发现和负载均衡 服务发现视图能够将集群内容的服务暴露给集群外的应用，集群内外的应用可以通过暴露的服务调用应用，外部的应用使用外部的端点，内部的应用使用内部端点。 4） 存储 存储视图显示被应用用来存储数据的持久化存储卷申明资源。 5） 配置 配置视图显示集群中应用运行时所使用配置信息，Kubernetes提供了配置字典（ConfigMaps）和秘密字典（Secrets），通过配置视图，能够编辑和管理配置对象，以及查看隐藏的敏感信息。 6） 日志视图 Pod列表和详细信息页面提供了查看日志视图的链接，通过日志视图不但能够查看Pod的日志信息，也能够查看Pod容器的日志信息。通过Dashboard能够根据向导创建和部署一个容器化的应用，当然也可以通过手工的方式输入指定应用信息，或者通过上传YAML和JSON文件来创建和不受应用。 2、下载所需yaml文件和镜像 12[root@master https]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc5/aio/deploy/recommended.yaml[root@master https]# docker pull kubernetesui/dashboard:v2.0.0-rc5 3、修改 recommended.yaml 12345678910111213141516[root@master https]#vim recommended.yaml ---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort #添加40 ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard 执行一下 1[root@master https]# kubectl apply -f recommended.yaml 查看一下 1[root@master https]# kubectl get svc -n kubernetes-dashboard 3、浏览器访问https://192.168.1.21:32306 PS:如果是使用的旧版本的dashboard, 使用谷歌浏览器登录，可能是不成功的，需要换成其他的浏览器，比如:火狐。 4、基于token的方法登录dashboard &lt;1&gt;创建一个dashboard的管理用户 1[root@master https]# kubectl create serviceaccount dashboard-admin -n kube-system &lt;2&gt;绑定用户为集群管理用户 1[root@master https]# kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin &lt;3&gt;获取Token 12[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin//先得到Token的名称 12[root@master https]# kubectl describe secrets -n kube-system dashboard-admin-token-62bh9//查看上述得到的secret资源的详细信息，会得到token &lt;4&gt;在浏览器上使用token登录。 创建一个资源 查看是否创建成功 5、基于kubeconfig配置文件的方法登录dashboard &lt;1&gt;获取Token 12[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin//先得到Token的名称 12[root@master https]# kubectl describe secrets -n kube-system dashboard-admin-token-62bh9//查看上述得到的secret资源的详细信息，会得到token &lt;2&gt;生成kubeconfig配置文件。 设置一个环境变量代表获取的token 1[root@master https]# DASH_TOKEN=$(kubectl get secrets -n kube-system dashboard-admin-token-62bh9 -o jsonpath=&#123;.data.token&#125; | base64 -d) 将k8s集群的配置信息写入kubeconfig配置文件中。 1234[root@master https]# kubectl config set-cluster kubernetes --server=192.168.1.21:6443 --kubeconfig=/root/.dashboard-admin.conf[root@master https]# kubectl config set-credentials dashboard-admin --token=$DASH_TOKEN --kubeconfig=/root/.dashboard-admin.conf[root@master https]# kubectl config set-context dashboard-admin@kubernetes --cluster=kubernetes --user=dashboard-admin --kubeconfig=/root/.dashboard-admin.conf[root@master https]# kubectl config use-context dashboard-admin@kubernetes --kubeconfig=/root/.dashboard-admin.conf &lt;3&gt;将生成的/root/.dashboard-admin.conf的配置文件，导出并做保存。 12[root@master https]# sz /root/.dashboard-admin.conf //导出到自己习惯的位置即可 &lt;4&gt;从浏览器选择kubeconfig的登录方式，然后导入配置文件即可。 二、部署weave-scope监控k8s集群 Weave Scope 是 Docker 和 Kubernetes 可视化监控工具。Scope 提供了至上而下的集群基础设施和应用的完整视图，用户可以轻松对分布式的容器化应用进行实时监控和问题诊断。 使用scope Scope 会自动构建应用和集群的逻辑拓扑。比如点击顶部 PODS，会显示所有 Pod 以及 Pod 之间的依赖关系。 点击 HOSTS，会显示各个节点之间的关系。 实时资源监控 可以在 Scope 中查看资源的 CPU 和内存使用情况。 支持的资源有 Host、Pod 和 Container。** 在线操作 Scope 还提供了便捷的在线操作功能，比如选中某个 Host，点击 &gt;_ 按钮可以直接在浏览器中打开节点的命令行终端 点击 Deployment 的 + 可以执行 Scale Up 操作 可以查看 Pod 的日志 可以 attach、restart、stop 容器，以及直接在 Scope 中排查问题 强大的搜索功能 Scope 支持关键字搜索和定位资源。 还可以进行条件搜索，比如查找和定位 MEMORY &gt; 100M 的 Pod。 1、在github上查找scope的yaml文件 （1）github上搜索scope （2）进入k8s的部署scope的说明 （3）选择k8s的部署 （4）复制上面的链接，并下载yaml文件 1[root@master https]# wget https://cloud.weave.works/k8s/scope.yaml 2、修改下载的yaml文件并运行 123456789[root@master ~]# vim scope.yaml #编辑yaml文件#跳转至213行，修改其service的端口类型 spec: type: NodePort #修改类型为NodePort ports: - name: app port: 80 protocol: TCP targetPort: 4040 （1）执行一下 1[root@master https]# kubectl apply -f scope.yaml （2）查看容器的运行情况，确定处于正常运行 1[root@master https]# kubectl get pod -o wide -n weave DaemonSet weave-scope-agent，集群每个节点上都会运行的 scope agent 程序，负责收集数据。 Deployment weave-scope-app，scope 应用，从 agent 获取数据，通过 Web UI 展示并与用户交互。 Service weave-scope-app，默认是 ClusterIP 类型，我们已经在上面的命令中添加了参数k8s-service-type=NodePort修改为 NodePort。 1[root@master https]# kubectl get svc -n weave #DaemonSet资源对象：weave-scope-agent（代理）：负责收集节点的信息； #deployment资源对象:weave-scope-app(应用)：从agent获取数据，通过web UI展示并与用户交互； #DaemonSet资源对象的特性和deployment相比，就是DaemonSet资源对象会在每个节点上都运行且只能运行一个pod。 #由于每个节点都需要监控，所以用到了DaemonSet这种资源对象 3、浏览器访问一下http://192.168.1.21:31841/ 在scope的web界面中，可以查看很多的东西，pod、node节点等详细信息，包括打开容器的终端，查看其日志信息等等 总结 • weave scope可以以其简洁的可视化为我们更生动形象的展现出service/controller/pod等资源对象的管理及简单的web ui操作，方便故障排除及时定位 • weave scope作为web ui目前缺少登录验证，可以利用其他方式里面web服务器的验证做安全管控。 三、部署Prometheus服务 PS:在这里部署的prometheus,并不是Prometheus官网提供的，而是使用的coreos提供的prometheus项目。 在部署之前，先来了解一下Prometheus各个组件的作用吧！ MetricsServer: 是k8s集群资源使用情况的聚合器，收集数据给k8s集群内使用，如kubectl,hpa,scheduler等。 Prometheus Operator : 是一个系统检测和警报工具箱，用来存储监控数据。 Prometheus node-exporter ：收集k8s集群资源的数据，指定告警规则。 Prometheus ：收集apiserver，scheduler，controller-manager，kubelet组件的数据，通过http协议传输。 Grafana: 可视化数据统计和监控平台。 特征 Prometheus 相比于其他传统监控工具主要有以下几个特点： 具有由 metric 名称和键/值对标识的时间序列数据的多维数据模型 有一个灵活的查询语言 不依赖分布式存储，只和本地磁盘有关 通过 HTTP 的服务拉取时间序列数据 也支持推送的方式来添加时间序列数据 还支持通过服务发现或静态配置发现目标 多种图形和仪表板支持 1、在github上搜索coreos/prometheus 复制链接 2、克隆github上的promethes项目 1234[root@master promethes]# yum -y install git//下载git命令[root@master promethes]# git clone https://github.com/coreos/kube-prometheus.git//克隆github上的项目 3、修改grafapa-service.yaml文件, 更改为nodePort的暴露方式，暴露端口为31001.。 1234567891011121314151617181920[root@master promethes]# cd kube-prometheus/manifests///进入kube-prometheus的manifests目录[root@master manifests]# vim grafana-service.yaml #修改grafana的yaml文件apiVersion: v1kind: Servicemetadata: labels: app: grafana name: grafana namespace: monitoringspec: type: NodePort #改为NodePort类型 ports: - name: http port: 3000 targetPort: http nodePort: 31001 #映射到宿主机31001端口 selector: app: grafana 3.修改prometheus-service.yaml文件， 更改为nodePort的暴露方式，暴露端口为31002. 1234567891011121314151617181920[root@master manifests]# vim prometheus-service.yaml #修改prometheus的yaml文件apiVersion: v1kind: Servicemetadata: labels: prometheus: k8s name: prometheus-k8s namespace: monitoringspec: type: NodePort #改为NodePort类型 ports: - name: web port: 9090 targetPort: web nodePort: 31002 #映射到宿主机31002端口 selector: app: prometheus prometheus: k8s sessionAffinity: ClientIP 4、修改alertmanager-service.yaml文件， 更改为nodePort的暴露方式，暴露端口为31003 1234567891011121314151617181920[root@master manifests]# vim alertmanager-service.yaml #修改alertmanager的yaml文件apiVersion: v1kind: Servicemetadata: labels: alertmanager: main name: alertmanager-main namespace: monitoringspec: type: NodePort #改为NodePort类型 ports: - name: web port: 9093 targetPort: web nodePort: 31003 #映射到宿主机31003端口 selector: alertmanager: main app: alertmanager sessionAffinity: ClientIP 5、将setup目录中所有的yaml文件,全部运行。是运行以上yaml文件的基础环境配置。 1234[root@master manifests]# cd setup///进入setup/目录[root@master manifests]# kubectl apply -f setup///运行setup目录中所有的yaml文件 6、将主目录(kube-prometheus)中所有的yaml文件,全部运行。 1234[root@master manifests]# cd ..//返回上一级目录（kube-prometheus）[root@master kube-prometheus]# kubectl apply -f manifests///运行kube-prometheus目录中所有的yaml文件 查看一下 1[root@master ~]# kubectl get pod -n monitoring 部署成功之后，可以运行一条命令， 查看资源使用情况(MetricsServer必须部署成功) 1[root@master images]# kubectl top node 7、浏览器访问一下http://192.168.1.21:31001 客户端访问群集中任意节点的IP+30100端口，即可看到以下界面（默认用户名和密码都是admin） 根据提示更改密码： （1）添加模板 依次点击“import”进行导入下面三个模板： （2）进行以下点击，即可查看群集内的监控状态 以下可看到监控状态 8、导入监控模板 从grafana的官网搜索https://grafana.com/ 复制以下这个模板的id 现在可以看到监控画面了","path":"posts/4f99.html","date":"09-09","excerpt":"","tags":[{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"weave-scope","slug":"weave-scope","permalink":"https://wsdlxgp.top/tags/weave-scope/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://wsdlxgp.top/tags/Prometheus/"}]},{"title":"k8s中ingress资源的应用","text":"Ingress实现虚拟主机的方案 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 1、首先确定要运行ingress-nginx-controller服务。 在gitbub上找到所需的ingress的yaml文件 4. master下载 1[root@master ingress]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml 5. 修改 mandatory.yaml 文件 12[root@master ingress]# vim mandatory.yaml hostNetwork: true #213 （1）执行一下 1[root@master ingress]# kubectl apply -f mandatory.yaml （2）查看一下 1[root@master ingress]# kubectl get pod -n ingress-nginx 2、将ingress-nginx-controller暴露为一个Service资源对象。 1234567891011121314151617181920212223242526[root@master yaml]# vim service-nodeport.yaml apiVersion: v1kind: Servicemetadata: name: ingress-nginx namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: type: NodePort ports: - name: http port: 80 targetPort: 80 protocol: TCP - name: https port: 443 targetPort: 443 protocol: TCP selector: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx--- （1）执行一下 1[root@master ingress]# kubectl apply -f service-nodeport.yaml （2）查看一下 1[root@master ingress]# kubectl get svc -n ingress-nginx 3、创建一个deployment资源，和一个service资源， 并相互关联。 123456789101112131415161718192021222324252627[root@master yaml]# vim deploy1.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy1spec: replicas: 2 template: metadata: labels: app: nginx1 spec: containers: - name: nginx1 image: nginx---apiVersion: v1kind: Servicemetadata: name: svc-1spec: selector: app: nginx1 ports: - port: 80 targetPort: 80 执行一下 1[root@master yaml]# kubectl apply -f deploy1.yaml 查看一下 1[root@master yaml]# kubectl get pod 1[root@master yaml]# kubectl get svc 然后复制deploy1.yaml资源工创建另外”一对“服务。 123456789101112131415161718192021222324252627[root@master yaml]# vim deploy2.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy2spec: replicas: 2 template: metadata: labels: app: nginx2 spec: containers: - name: nginx2 image: nginx---apiVersion: v1kind: Servicemetadata: name: svc-2spec: selector: app: nginx2 ports: - port: 80 targetPort: 80 执行一下 1[root@master yaml]# kubectl apply -f deploy2.yaml 查看一下 1[root@master yaml]# kubectl get deployments. 4. 创建ingress的yaml文件，关联是svc1和svc2 12345678910111213141516171819202122232425262728[root@master yaml]# vim ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-1spec: rules: - host: www1.bdqn.com http: paths: - path: / backend: serviceName: svc-1 servicePort: 80---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-2spec: rules: - host: www2.bdqn.com http: paths: - path: / backend: serviceName: svc-2 servicePort: 80 执行一下 1[root@master yaml]# kubectl apply -f ingress.yaml 查看一下 1[root@master yaml]# kubectl get ingresses. 1[root@master yaml]# kubectl describe ingresses. ingress-1 1[root@master yaml]# kubectl describe ingresses. ingress-2 5、由于实验环境限制，所以自己用来模拟-一个域名。 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 访问一下 12[root@master yaml]# kubectl get svc -n ingress-nginx //查看映射的端口 http://www1.bdqn.com:30817/ http://www2.bdqn.com:30817/ 总结上述示例的pod是如何一步一步可以使client访问到的，总结如下： 后端pod===》service====》ingress规则====》写入Ingress-nginx-controller配置文件并自动重载使更改生效===》对本机进行域名解析====》实现client通过域名的IP+端口都可以访问到后端pod Ingress资源实现https代理安全访问。 在上面的操作中，实现了使用ingress-nginx为后端所有pod提供一个统一的入口，那么，有一个非常严肃的问题需要考虑，就是如何为我们的pod配置CA证书来实现HTTPS访问？在pod中直接配置CA么？那需要进行多少重复性的操作？而且，pod是随时可能被kubelet杀死再创建的。当然这些问题有很多解决方法，比如直接将CA配置到镜像中，但是这样又需要很多个CA证书。 这里有更简便的一种方法，就拿上面的情况来说，后端有多个pod，pod与service进行关联，service又被ingress规则发现并动态写入到ingress-nginx-controller容器中，然后又为ingress-nginx-controller创建了一个Service映射到群集节点上的端口，来供client来访问。 在上面的一系列流程中，关键的点就在于ingress规则，我们只需要在ingress的yaml文件中，为域名配置CA证书即可，只要可以通过HTTPS访问到域名，至于这个域名是怎么关联到后端提供服务的pod，这就是属于k8s群集内部的通信了，即便是使用http来通信，也无伤大雅。 1. 生成证书 12345[root@master yaml]# mkdir https//创建一个放置证书的目录[root@master yaml]# cd https/[root@master https]# openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/CN=testsvc /O=testsvc\"//生成证书 2. 创建secret资源， 保存证书。 1[root@master https]# kubectl create secret tls tls-secret --key=tls.key --cert tls.crt 3、创建一个deploy3.yaml文件，模拟一个web服务。 123456789101112131415161718192021222324252627[root@master yaml]# vim deploy3.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy3spec: replicas: 2 template: metadata: labels: app: nginx3 spec: containers: - name: nginx3 image: nginx---apiVersion: v1kind: Servicemetadata: name: svc-3spec: selector: app: nginx3 ports: - port: 80 targetPort: 80 执行一下 1[root@master https]# kubectl apply -f deploy3.yaml 查看一下 1[root@master https]# kubectl get pod 1[root@master https]# kubectl get svc 4、创建对应的ingress规则。 12345678910111213141516171819[root@master https]# vim ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-3spec: tls: - hosts: - www3.bdqn.com #域名 secretName: tls-secret #保存的证书 rules: - host: www3.bdqn.com http: paths: - path: / backend: serviceName: svc-3 servicePort: 80 执行一下 1[root@master https]# kubectl apply -f ingress.yaml 查看一下 1[root@master https]# kubectl get ingresses. 5.查找对应service nodePort的443端口映射的端口，直接用浏览器访问即可。 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 查看映射端口 1[root@master https]# kubectl get svc -n ingress-nginx https://www3.bdqn.com:31372/ k8s集群利用了“一切皆为资源”的原理，把生成的ca证书当成一个公共的资源来使用，使用时只需绑定保存的ca证书即可，不像之前一样，需要一个一个的创建ca证书，然后在关联起来，方便好用又快捷。","path":"posts/7f86.html","date":"09-08","excerpt":"","tags":[{"name":"ingress-nginx","slug":"ingress-nginx","permalink":"https://wsdlxgp.top/tags/ingress-nginx/"},{"name":"https","slug":"https","permalink":"https://wsdlxgp.top/tags/https/"},{"name":"ca","slug":"ca","permalink":"https://wsdlxgp.top/tags/ca/"}]},{"title":"K8S的inress-nginx","text":"一、Ingress 及 Ingress Controller 简介 Ingress简单的理解: 原先暴露的service,现在给定个统一的访问入口。 Ingress 是 k8s 资源对象，用于对外暴露服务，该资源对象定义了不同主机名（域名）及 URL 和对应后端 Service（k8s Service）的绑定，根据不同的路径路由 http 和 https 流量。而 Ingress Contoller 是一个 pod 服务，封装了一个 web 前端负载均衡器，同时在其基础上实现了动态感知 Ingress 并根据 Ingress 的定义动态生成 前端 web 负载均衡器的配置文件，比如 Nginx Ingress Controller 本质上就是一个 Nginx，只不过它能根据 Ingress 资源的定义动态生成 Nginx 的配置文件，然后动态 Reload。个人觉得 Ingress Controller 的重大作用是将前端负载均衡器和 Kubernetes 完美地结合了起来，一方面在云、容器平台下方便配置的管理，另一方面实现了集群统一的流量入口，而不是像 nodePort 那样给集群打多个孔。。 所以，总的来说要使用 Ingress，得先部署 Ingress Controller 实体（相当于前端 Nginx），然后再创建 Ingress （相当于 Nginx 配置的 k8s 资源体现），Ingress Controller 部署好后会动态检测 Ingress 的创建情况生成相应配置。Ingress Controller 的实现有很多种：有基于 Nginx 的，也有基于 HAProxy的，还有基于 OpenResty 的 Kong Ingress Controller 等，更多 Controller 见：https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/，本文使用基于 Nginx 的 Ingress Controller：ingress-nginx。 二、Ingress 组成 将Nginx的配置抽象成一个Ingress对象，每添加一个新的服务只需写一个新的Ingress的yaml文件即可 将新加入的Ingress转化成Nginx的配置文件并使之生效 ingress controller ingress服务 三、ingress的工作原理 ingress具体的工作原理如下: ingress contronler通过与k8s的api进行交互，动态的去感知k8s集群中ingress服务规则的变化，然后读取它，并按照定义的ingress规则，转发到k8s集群中对应的service。 而这个ingress规则写明了哪个域名对应k8s集群中的哪个service，然后再根据ingress-controller中的nginx配置模板，生成一段对应的nginx配置。 然后再把该配置动态的写到ingress-controller的pod里，该ingress-controller的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入到nginx的配置文件中，然后reload一下，使其配置生效。以此来达到域名分配置及动态更新的效果。 四、Ingress 可以解决什么问题？ 动态配置服务 如果按照传统方式, 当新增加一个服务时, 我们可能需要在流量入口加一个反向代理指向我们新的k8s服务. 而如果用了Ingress, 只需要配置好这个服务, 当服务启动时, 会自动注册到Ingress的中, 不需要而外的操作. 减少不必要的暴露端口 配置过k8s的都清楚, 第一步是要关闭防火墙的, 主要原因是k8s的很多服务会以NodePort方式映射出去, 这样就相当于给宿主机打了很多孔, 既不安全也不优雅. 而Ingress可以避免这个问题, 除了Ingress自身服务可能需要映射出去, 其他服务都不要用NodePort方式 五、Ingress-nginx配置示例 1) 创建一个web服务，用deployment资源， 用httpd镜像，然后创建一个service资源与之关联。 1234567891011121314151617181920212223242526272829303132333435363738[root@master ingress]# vim deploy_1.yamlapiVersion: v1kind: Namespacemetadata: name: bdqn-ns labels: name: bdqn-ns---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: httpd-deploy namespace: bdqn-nsspec: replicas: 2 template: metadata: labels: app: bdqn-ns spec: containers: - name: httpd image: httpd---apiVersion: v1kind: Servicemetadata: name: httpd-svc namespace: bdqn-nsspec: type: NodePort selector: app: bdqn-ns ports: - name: http-port port: 80 targetPort: 80 nodePort: 31033 执行一下 1[root@master ingress]# kubectl apply -f deploy_1.yaml 查看一下 1[root@master ingress]# kubectl get svc -n bdqn-ns 1[root@master ingress]# kubectl get pod -n bdqn-ns 访问一下 2) 创建一个web服务，用deployment 资源，用tomcat:8.5.45镜像。 1234567891011121314151617181920212223242526272829303132[root@master ingress]# vim deploy_2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: tomcat-deploy namespace: bdqn-nsspec: replicas: 2 template: metadata: labels: app: bdqn-tomcat spec: containers: - name: tomcat image: tomcat:8.5.45---apiVersion: v1kind: Servicemetadata: name: tomcat-svc namespace: bdqn-nsspec: type: NodePort selector: app: bdqn-tomcat ports: - name: tomcat-port port: 8080 targetPort: 8080 nodePort: 32033 执行一下 1[root@master ingress]# kubectl apply -f deploy_2.yaml 查看一下 1[root@master ingress]# kubectl get pod -n bdqn-ns 1[root@master ingress]# kubectl get svc -n bdqn-ns 访问一下 3) 在k8s集群前边部署一个反向代理服务器，这个服务器代理这k8s集群内部的service资源。 1. Ingress: （1）Ingress controller: 将新加入的Ingress转化为反向代理服务器的配置文件，并使之生效。(动态的感知k8s集群内Ingress资源的变化。） （2）Ingress : Ingress:将反向代理服务器的配置抽象成一个Ingress对象，每添加一个新的服务，只需要写一个新的Ingress的yaml文件即可。 2. Nginx :反向代理服务器。 需要解决了两个问题: 1、动态的配置服务。 2、减少不必要的端口暴露。 基于nginx的ingress controller根据不同的开发公司，又分为两种: ​ 1、k8s社区版的: Ingerss - nginx. ​ 2、nginx公司自己开发的: nginx- ingress . 3. 在gitbub上找到所需的ingress的yaml文件 4. master下载 1[root@master ingress]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml 5. 修改 mandatory.yaml 文件 12[root@master ingress]# vim mandatory.yaml hostNetwork: true #213 ---------如果ingress-controller镜像下载不成功，可以直接使用下边的镜像。 docker pull registry.cn-hangzhou.aliyuncs.com/ilanni/nginx-ingress-controller:0.22.0 需要注意的是，如果使用上述镜像，需要将deployment资源指定的镜像名称进行修改。 修改的是madatory.yaml文件里的deployment资源。 在deployment资源中，如果添加了此字段，意味着Pod中运行的应用可以直接使用node节点的端口，这样node节 点主机所在网络的其他主机，就可以通过访问该端口访问此应用。(类似于docker映射到宿主机 上的端口。) （1）执行一下 1[root@master ingress]# kubectl apply -f mandatory.yaml （2）查看一下 1[root@master ingress]# kubectl get pod -n ingress-nginx 6. 创建一个service的yaml文件 （1）执行一下 1[root@master ingress]# kubectl apply -f mandatory.yaml （2）查看一下 1234567891011121314151617[root@master ingress]# vim mandatory-svc.yaml apiVersion: v1kind: Servicemetadata: name: ingress-nginx namespace: ingress-nginxspec: type: NodePort ports: - name: httpd port: 80 targetPort: 80 - name: https port: 443 selector: app: ingress-nginx （1）执行一下 1[root@master ingress]# kubectl apply -f mandatory-svc.yaml （2）查看一下 1[root@master ingress]# kubectl get svc -n ingress-nginx 4）创建Ingress资源。 ingress ： ingress-nginx-controller: 动态感知ingress 资源的变化 ingress: 创建svc与ingress-nginx-controller 关联的规则 （1）编写ingress的yaml文件 123456789101112131415161718192021[root@master yaml]# vim ingress.yaml apiVersion: extensions/v1beta1kind: Ingressmetadata: name: bdqn-ingress namespace: bdqn-ns annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: #规则 - host: ingress.bdqn.com #域名 http: paths: - path: / backend: serviceName: httpd-svc #关联service servicePort: 80 #关联service的映射端口 - path: /tomcat backend: serviceName: tomcat-svc #关联service servicePort: 8080 #关联service的映射端口 执行一下 1[root@master yaml]# kubectl apply -f ingress.yaml 查看一下 1[root@master yaml]# kubectl get pod -n ingress-nginx -o wide 1[root@master yaml]# kubectl get ingresses. -n bdqn-ns 1[root@master yaml]# kubectl describe ingresses. -n bdqn-ns 进入pod查看一下 12[root@master yaml]# kubectl exec -it -n ingress-nginx nginx-ingress-controller-5954d475b6-24k92 /bin/sh/etc/nginx $ cat nginx.conf （2）访问一下 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 访问http://ingress.bdqn.com/ 访问http://ingress.bdqn.com/tomcat 5）为ingress-nginx创建一个service（使用官网的service文件就可以） 复制上面的网址 12[root@master yaml]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/provider/baremetal/service-nodeport.yaml//下载文件到master节点 执行一下，下载的service文件 1[root@master yaml]# kubectl apply -f service-nodeport.yaml 查看一下 1[root@master yaml]# kubectl get service -n ingress-nginx 访问一下 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 访问http://ingress.bdqn.com:30817/ 访问http://ingress.bdqn.com:30817/tomcat Service -Nodeport:因为ingress - nginx - controller运行在了集群内的其中一个节点，为了保证即使这个节点宕机，我们对应的域名仍然能够正常访问服务，所以我们将ingress -nginx- controller也暴露为一个service资源。 六、练习: 创建一个deploymen资源，基于nginx镜像，repolicas：2个.然后创建一个service资源关联这个deployment资源。最后创建一个ingress资源，将上述svc关联到ingress.bdqn.com/nginx 目录下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@master yaml]# vim lianxi.yamlapiVersion: v1kind: Namespacemetadata: name: xgp-666 labels: name: xgp-666---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: xgp namespace: xgp-666spec: replicas: 2 template: metadata: labels: app: xgp-nginx spec: containers: - name: xgp-nginx image: nginx---apiVersion: v1kind: Servicemetadata: name: xgp-svc namespace: xgp-666spec: type: NodePort selector: app: xgp-nginx ports: - name: xgp-port port: 80 targetPort: 80 nodePort: 30000---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: xgp-ingress namespace: xgp-666 annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: ingress.xgp.com http: paths: - path: / backend: serviceName: xgp-svc servicePort: 80 执行一下 1[root@master yaml]# kubectl apply -f lianxi.yaml 查看一下 1[root@master yaml]# kubectl describe ingresses. -n xgp-666 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 添加完之后访问一下http://ingress.xgp.com/","path":"posts/c92f.html","date":"09-07","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"},{"name":"ingress","slug":"ingress","permalink":"https://wsdlxgp.top/tags/ingress/"},{"name":"ingress controller","slug":"ingress-controller","permalink":"https://wsdlxgp.top/tags/ingress-controller/"}]},{"title":"k8s的Secret（密文）和configmap（明文）的使用教程","text":"一、Secret Secret :用来保存一些敏感信息，比如数据库的用户名密码或者秘钥。 概览 Secret是用来保存小片敏感数据的k8s资源，例如密码，token，或者秘钥。这类数据当然也可以存放在Pod或者镜像中，但是放在Secret中是为了更方便的控制如何使用数据，并减少暴露的风险。 用户可以创建自己的secret，系统也会有自己的secret。 Pod需要先引用才能使用某个secret，Pod有2种方式来使用secret：作为volume的一个域被一个或多个容器挂载；在拉取镜像的时候被kubelet引用。 內建的Secrets 由ServiceAccount创建的API证书附加的秘钥 k8s自动生成的用来访问apiserver的Secret，所有Pod会默认使用这个Secret与apiserver通信 1. Secret类型 Secret有三种类型： Opaque：使用base64编码存储信息，可以通过base64 --decode解码获得原始数据，因此安全性弱。 kubernetes.io/dockerconfigjson：用于存储docker registry的认证信息。 kubernetes.io/service-account-token：用于被 serviceaccount 引用。serviceaccout 创建时 Kubernetes 会默认创建对应的 secret。Pod 如果使用了 serviceaccount，对应的 secret 会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中。 举例:保存数据库的用户名和密码 用户名： root 密码： 123.com 1、通过–from-literal（文字的） 1[root@master secret]# kubectl create secret generic mysecret1 --from-literal=username=root --from-literal=password=123.com generic：通用的，一般的加密方式 查看一下 1[root@master secret]# kubectl get secrets 类型是Opaque（不透明的） 2、通过from-file（文件） 新建两个文件并分别写入用户名和密码 12[root@master secret]# echo root &gt; username[root@master secret]# echo 123.com &gt; password 创建一个secret 1[root@master secret]# kubectl create secret generic mysecret2 --from-file=username --from-file=password 查看一下 1[root@master secret]# kubectl get secrets 3、通过-- from- env-file: 创建一个文件写入用户名和密码 123[root@master secret]#vim env.txt username=rootpassword=123.com 创建一个secret 1[root@master secret]# kubectl create secret generic mysecret3 --from-env-file=env.txt 查看一下 1[root@master secret]# kubectl get secrets 4、通过yaml配置文件 （1）把需要保存的数据加密（”base64“的方式） 1234[root@master secret]# echo root | base64cm9vdAo=[root@master secret]# echo 123.com | base64MTIzLmNvbQo= 解码： 1234[root@master secret]# echo -n cm9vdAo | base64 --decode root[root@master secret]# echo -n MTIzLmNvbQo | base64 --decode 123.com （2）编写secre4的yaml文件 12345678[root@master secret]# vim secret4.yamlapiVersion: v1kind: Secretmetadata: name: mysecret4data: username: cm9vdAo= password: MTIzLmNvbQo= 执行一下 1[root@master secret]# kubectl apply -f secret4.yaml （3）查看一下 1[root@master secret]# kubectl get secrets 如果来使用Secret资源 1. 以Volume挂载的方式 使用Secret secret可以作为数据卷挂载或者作为环境变量暴露给Pod中的容器使用，也可以被系统中的其他资源使用。比如可以用secret导入与外部系统交互需要的证书文件等。 在Pod中以文件的形式使用secret 创建一个Secret，多个Pod可以引用同一个Secret 修改Pod的定义，在spec.volumes[]加一个volume，给这个volume起个名字，spec.volumes[].secret.secretName记录的是要引用的Secret名字 在每个需要使用Secret的容器中添加一项spec.containers[].volumeMounts[]，指定spec.containers[].volumeMounts[].readOnly = true，spec.containers[].volumeMounts[].mountPath要指向一个未被使用的系统路径。 修改镜像或者命令行使系统可以找到上一步指定的路径。此时Secret中data字段的每一个key都是指定路径下面的一个文件名 编写pod的yaml文件 12345678910111213141516171819202122[root@master secret]# vim pod.yaml apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: secret-test mountPath: \"/etc/secret-test\" #pod中的路径 readOnly: true #是否只读 volumes: - name: secret-test secret: secretName: mysecret1 还可以自定义存放数据的文件名 执行一下 1[root@master secret]# kubectl apply -f pod.yaml Secret文件权限 可以指定secret文件的权限，类似linux系统文件权限，如果不指定默认权限是0644，等同于linux文件的-rw-r–r--权限 进入容器查看保存的数据 12345678[root@master secret]# kubectl exec -it mypod /bin/sh/ # cd /etc/secret-test//etc/secret-test # lspasword username/etc/secret-test # cat username root/etc/secret-test # cat pasword 123.com 测试是否有只读权限 12123.com/etc/secret-test # echo admin &gt; username/bin/sh: can't create username: Read-only file system 1.1 自定义存放数据的文件名的yaml文件 1234567891011121314151617181920212223242526[root@master yaml]# vim pod.yaml apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: secret-test mountPath: \"/etc/secret-test\" #pod中的路径 readOnly: true #是否只读 volumes: - name: secret-test secret: secretName: mysecret1 items: - key: username path: my-group/my-username #自定义的容器中的目录 - key: password path: my-group/my-password #自定义的容器中的目录 执行一下 1[root@master yaml]# kubectl apply -f pod.yaml 查看一下 123456[root@master secret]# kubectl exec -it mypod /bin/sh//进入容器查看 # cat /etc/secret-test/my-group/my-password 123.com # cat /etc/secret-test/my-group/my-username root 1.2 如果，现在将secret资源内保存的数据进行更新，请问，使用此数据的应用内，数据是是否也会更新? 会实时更新(这里引用数据，是以volumes挂 载使用数据的方式)。 更新mysecret1的数据: password —&gt; admin YWRtaW4K (base64) 可以通过edit 命令，直接修改。 1[root@master secret]# kubectl edit secrets mysecret1 查看一下 123456[root@master secret]# kubectl exec -it mypod /bin/sh//进入容器查看 # cat /etc/secret-test/my-group/my-password admin # cat /etc/secret-test/my-group/my-username root 数据已经成功更新了 2、以环境变量的方式 创建一个Secret，多个Pod可以引用同一个Secret 修改pod的定义，定义环境变量并使用env[].valueFrom.secretKeyRef指定secret和相应的key 修改镜像或命令行，让它们可以读到环境变量 编写pod的yaml文件 123456789101112131415161718192021222324[root@master secret]# vim pod-env.yaml apiVersion: v1kind: Podmetadata: name: mypod2spec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 env: - name: SECRET_USERNAME valueFrom: secretKeyRef: name: mysecret2 key: username - name: SECRET_PASSWORD valueFrom: secretKeyRef: name: mysecret2 key: password 执行一下 1[root@master secret]# kubectl apply -f pod-env.yaml 查看一下 1[root@master secret]# kubectl get pod 进入容器查看保存的数据 12345[root@master secret]# kubectl exec -it mypod2 /bin/sh/ # echo $SECRET_USERNAMEroot/ # echo $SECRET_PASSWORD123.com 2.1 更新sevret文件的内容 12[root@master yaml]# kubectl edit secrets mysecret2//修改保存文件的内容 查看一下 12345[root@master secret]# kubectl exec -it mypod2 /bin/sh/ # echo $SECRET_USERNAMEroot/ # echo $SECRET_PASSWORD123.com 等待了一定时间后，可以看到这个数据并没有没有改变 总结 如果引用secret数据的应用， 要求会随着secret资源对象内保存的数据的更新，而实时更新，那么应该使用volumes挂载的方式引用资源因为用环境变量的方式引用不会实时更新数据。 二、ConfigMap 和Secret资源类似，不同之处在于，secret 资源保存的是敏感信息，而Configmap保存的是以明文方式存放的数据。 Configmap的创建与使用方式与Secret非常类似，不同点只在于数据以明文形式存放（不过，我觉得Secret的密文形式也并不密文，只能算得上是简单编码）。 和Secret资源类似，不同之处在于，secret 资源保存的是敏感信息，而Configmap保存的是以明文方式存放的数据。 username：adam age：18 创建的四种方式 1、通过-- from- literal(文字的): 1[root@master yaml]# kubectl create configmap myconfigmap1 --from-literal=username=adam --from-literal=age=18 查看一下 1[root@master yaml]# kubectl get cm 1[root@master yaml]# kubectl describe cm 2、通过–from-file (文件) : 12[root@master yaml]# echo adam &gt; username[root@master yaml]# echo 18 &gt; age 创建 1[root@master yaml]# kubectl create configmap myconfigmap2 --from-file=username --from-file=age 查看一下 1[root@master yaml]# kubectl describe cm 3、通过–from- env-file: 123[root@master yaml]# vim env.txt username=adamage=18 创建 1[root@master yaml]# kubectl create configmap myconfigmap3 --from-env-file=env.txt 查看一下 1[root@master configmap]# kubectl describe cm 4、通过yaml配置文件: 12345678[root@master yaml]# vim configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: myconfigmap4data: username: 'adam' age: '18' 创建 1[root@master yaml]# kubectl apply -f configmap.yaml 查看一下 1[root@master yaml]# kubectl describe cm 如何来使用configmap资源 1. 以Volume挂载的方式 123456789101112131415161718192021[root@master yaml]# vim v-pod.yaml apiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: cmp-test mountPath: \"/etc/cmp-test\" readOnly: true volumes: - name: cmp-test configMap: name: myconfigmap1 执行一下 1[root@master configmap]# kubectl apply -f v-pod.yaml 查看一下 123456[root@master configmap]# kubectl exec -it pod1 /bin/sh//进入容器查看一下 # cat /etc/cmp-test/age 18/ # cat /etc/cmp-test/username adam/ 1.1 自定义存放数据的文件名的yaml文件 1234567891011121314151617181920212223242526[root@master configmap]# vim v-pod2.yaml apiVersion: v1kind: Podmetadata: name: pod3spec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: cmp-test mountPath: \"/etc/cmp-test\" readOnly: true volumes: - name: cmp-test configMap: name: myconfigmap1 items: - key: username path: my-group/my-username #自定义的容器中的目录 - key: age path: my-group/my-age #自定义的容器中的目录 执行一下 1[root@master configmap]# kubectl apply -f v-pod2.yaml 查看一下 123456[root@master configmap]# kubectl exec -it pod3 /bin/sh//进入容器查看# cat /etc/cmp-test/my-group/my-username adam/ # cat /etc/cmp-test/my-group/my-age 18/ 1.2 如果，现在将secret资源内保存的数据进行更新，请问，使用此数据的应用内，数据是是否也会更新? 1[root@master configmap]# kubectl edit cm myconfigmap1 查看一下 123456[root@master configmap]# kubectl exec -it pod3 /bin/sh//进入容器查看# cat /etc/cmp-test/my-group/my-username adam/ # cat /etc/cmp-test/my-group/my-age 10 可以看到更新成功 2.以环境变量的方式 123456789101112131415161718192021222324[root@master configmap]# vim e-pod.yaml apiVersion: v1kind: Podmetadata: name: pod2spec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 env: - name: CONFIGMAP_NAME valueFrom: configMapKeyRef: name: myconfigmap2 key: username - name: CONFIGMAP_AGE valueFrom: configMapKeyRef: name: myconfigmap2 key: age 执行一下 1[root@master configmap]# kubectl apply -f e-pod.yaml 查看一下 123456[root@master configmap]# kubectl exec -it pod2 /bin/sh//进入容器查看一下 # echo $CONFIGMAP_NAMEadam # echo $CONFIGMAP_AGE18 2.1 更新sevret文件的内容 12[root@master configmap]# kubectl edit cm myconfigmap2 //修改保存文件的内容 查看一下 123456[root@master configmap]# kubectl exec -it pod2 /bin/sh//进入容器查看一下 # echo $CONFIGMAP_NAMEadam # echo $CONFIGMAP_AGE18 等待了一定时间后，可以看到这个数据并没有没有改变 可以看出这个configmap和secret的更新效果基本没有区别。 总结configmap、与secret资源有什么相同和不同之处。 Secret 与 ConfigMap 对比 相同点： key/value的形式 属于某个特定的namespace 可以导出到环境变量 可以通过目录/文件形式挂载 通过 volume 挂载的配置信息均可热更新 不同点： Secret 可以被 ServerAccount 关联 Secret 可以存储 docker register 的鉴权信息，用在 ImagePullSecret 参数中，用于拉取私有仓库的镜像 Secret 支持 Base64 加密 Secret 分为 kubernetes.io/service-account-token、kubernetes.io/dockerconfigjson、Opaque 三种类型，而 Configmap 不区分类型 总结以volumes挂载、和环境变量方式引用资源的相同和不同之处。 volumes挂载(可根据更改数据更新)：引用自己创建的secret（密文）或configmap（明文），挂载到容器中指定的目录下。查看保存的文件时，根据自己所填路径和secret或configmap创建的文件，进行查看。 环境变量(不因更改数据更新)：引用自己创建的secret（密文）或configmap（明文），挂载到容器中指定的目录下。查看保存的文件时，根据自己环境变量，进行查看。","path":"posts/a387.html","date":"09-06","excerpt":"","tags":[{"name":"secret","slug":"secret","permalink":"https://wsdlxgp.top/tags/secret/"},{"name":"pod","slug":"pod","permalink":"https://wsdlxgp.top/tags/pod/"},{"name":"configmap","slug":"configmap","permalink":"https://wsdlxgp.top/tags/configmap/"}]},{"title":"k8s的StatefulSet（有状态服务）实现","text":"StatefulSet介绍 遇到的问题： 使用Deployment创建的Pod是无状态的，当挂在Volume之后，如果该Pod挂了，Replication Controller会再run一个来保证可用性，但是由于是无状态的，Pod挂了的时候与之前的Volume的关系就已经断开了，新起来的Pod无法找到之前的Pod。但是对于用户而言，他们对底层的Pod挂了没有感知，但是当Pod挂了之后就无法再使用之前挂载的磁盘了。 StatefulSet: 是一种给Pod提供唯一标志的控制器，它可以保证部署和扩展的顺序。 Pod一致性：包含次序（启动、停止次序）、网络一致性。此一致性与Pod相关，与被调度到哪个node节点无关。 稳定的次序：对于N个副本的StatefulSet，每个Pod都在[0，N)的范围内分配一个数字序号，且是唯一的。 稳定的网络：Pod的hostname模式为(statefulset名称)- (序号)。 稳定的存储：通过VolumeClaimTemplate为每个Pod创建一个PV。删除、减少副本，不会删除相关的卷。 (1) RC、 RS、Deployment、DS。-----&gt; 无状态服务 template(模板):根据模板 创建出来的Pod,它们J的状态都是一模一样的(除了名称，IP, 域名之外) 可以理解为:任何一个Pod, 都可以被删除，然后用新生成的Pod进行替换。 (2) 有状态的服务: 需要记录前一 次或者多次通信中的相关事件，以作为一下通信的分类标准。比如: mysql等数据库服务。(Pod的名称，不能随意变化。数据持久化的目录也是不一样，每一个Pod都有自己独有的数据持久化存储目录。) mysql:主从关系。 如果把之前无状态的服务比喻为牛、羊等牲畜，因为，这些到一定时候就可以出售。那么，有状态就比喻为:宠物，而宠物不像牲畜一样到达一定时候出售，人们往往会照顾宠物的一生。 (3) 每一个Pod----&gt;对应一个PVC----&gt;每一个PVC对应一个PV。 storageclass:自动创建PV 需要解决:自动创建PVC。 实现原理 与 ReplicaSet 和 Deployment 资源一样，StatefulSet 也使用控制器的方式实现，它主要由 StatefulSetController、StatefulSetControl 和 StatefulPodControl 三个组件协作来完成 StatefulSet 的管理，StatefulSetController 会同时从 PodInformer 和 ReplicaSetInformer 中接受增删改事件并将事件推送到队列中： 控制器 StatefulSetController 会在 Run 方法中启动多个 Goroutine 协程，这些协程会从队列中获取待处理的 StatefulSet 资源进行同步，接下来我们会先介绍 Kubernetes 同步 StatefulSet 的过程。 1，例子 （1）创建一个statefulset的yaml文件 12345678910111213141516171819202122232425262728293031323334[root@master yaml]# vim statefulset.yamlapiVersion: v1kind: Servicemetadata: name: headless-svc labels: app: headless-svcspec: ports: - port: 80 selector: app: headless-pod clusterIP: None #没有同一的ip---apiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-testspec: serviceName: headless-svc replicas: 3 selector: matchLabels: app: headless-pod template: metadata: labels: app: headless-pod spec: containers: - name: myhttpd image: httpd ports: - containerPort: 80 Deployment : Deploy+RS+随机字符串(Pod的名称。)没有顺序的，可 以没随意替代的。 1、headless-svc :无头服务。因为没有IP地址，所以它不具备负载均衡的功能了。因为statefulset要求Pod的名称是有顺序的，每一个Pod都不能被随意取代，也就是即使Pod重建之后，名称依然不变。为后端的每一个Pod去命名。 2、statefulSet:定义具体的应用 3、volumeClaimT emplates:自动创建PVC，为后端的Pod提供专有的存储。 执行一下 1[root@master yaml]# kubectl apply -f statefulset.yaml 查看一下 1[root@master yaml]# kubectl get svc 12[root@master yaml]# kubectl get pod//可看到这些pod是有顺序的 一、创建StorageClass资源对象。 1、基于NFS服务，创建NFS服务。 下载nfs所需安装包 1[root@node02 ~]# yum -y install nfs-utils rpcbind 创建共享目录 1[root@master ~]# mkdir /nfsdata 创建共享目录的权限 12[root@master ~]# vim /etc/exports/nfsdata *(rw,sync,no_root_squash) 开启nfs和rpcbind 12[root@master ~]# systemctl start nfs-server.service [root@master ~]# systemctl start rpcbind 测试一下 1[root@master ~]# showmount -e 2、创建rbac权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@master yaml]# vim rbac-rolebind.yaml apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: default---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: defaultrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: default #必写字段roleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io 执行一下 1[root@master yaml]# kubectl apply -f rbac-rolebind.yaml 3、创建Deployment资源对象，用Pod代替 真正的NFS服务。 123456789101112131415161718192021222324252627282930313233[root@master yaml]# vim nfs-deployment.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisionerspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: bdqn - name: NFS_SERVER value: 192.168.1.21 - name: NFS_PATH value: /nfsdata volumes: - name: nfs-client-root nfs: server: 192.168.1.21 path: /nfsdata 执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml 查看一下 1[root@master yaml]# kubectl get pod 4、创建storageclass的yaml文件 1234567[root@master yaml]# vim test-storageclass.yaml apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: stateful-nfsprovisioner: bdqn #通过provisioner字段关联到上述DeployreclaimPolicy: Retain 执行一下 1[root@master yaml]# kubectl apply -f test-storageclass.yaml 查看一下 1[root@master yaml]# kubectl get sc 二，解决自动创建pvc 1、创建statefulset的yaml文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@master yaml]# vim statefulset.yaml apiVersion: v1kind: Servicemetadata: name: headless-svc labels: app: headless-svcspec: ports: - port: 80 name: myweb selector: app: headless-pod clusterIP: None---apiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-testspec: serviceName: headless-svc replicas: 3 selector: matchLabels: app: headless-pod template: metadata: labels: app: headless-pod spec: containers: - image: httpd name: myhttpd ports: - containerPort: 80 name: httpd volumeMounts: - mountPath: /mnt name: test volumeClaimTemplates: #&gt; 自动创建PVC，为后端的Pod提供专有的存储。** - metadata: name: test annotations: #这是指定storageclass volume.beta.kubernetes.io/storage-class: stateful-nfs spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Mi 在此示例中： 创建了一个名为 headless-svc 的 Service 对象，由 metadata: name 字段指示。该 Service 会定位一个名为 headless-svc 的应用，由 labels: app: headless-svc 和 selector: app: headless-pod 指示。该 Service 会公开端口 80 并将其命名为 web。而且该 Service 会控制网域并将互联网流量路由到 StatefulSet 部署的容器化应用。 使用三个副本 Pod (replicas: 3) 创建了一个名为 web 的 StatefulSet。 Pod 模板 (spec: template) 指示其 Pod 标记为 app: headless-pod。 Pod 规范 (template: spec) 指示 StatefulSet 的 Pod 运行一个容器 myhttpd，该容器运行版本为 httpd 映像。容器映像由 Container Registry 托管。 Pod 规范使用由 Service 打开的 web 端口。 template: spec: volumeMounts 指定一个名为 test 的 mountPath。mountPath 是容器中应装载存储卷的路径。 StatefulSet 预配了一个具有 100mb 预配存储空间的 PersistentVolumeClaim：test。 执行一下 1[root@master yaml]# kubectl apply -f statefulset.yaml 查看一下 1[root@master yaml]# kubectl get pod 如果第一个pod出现了问题，后面的pod就不会生成。 1[root@master yaml]# kubectl get statefulsets 2、 验证一下数据存储 容器中创建文件 1234[root@master yaml]# kubectl exec -it statefulset-test-0 /bin/sh# cd /mnt# touch testfile# exit 宿主机查看一下 12[root@master yaml]# ls /nfsdata/default-test-statefulset-test-0-pvc-bf1ae1d0-f496-4d69-b33b-39e8aa0a6e8d/testfile 三、小实验 以自己的名称创建一个名称空间，以下所有资源都运行在此空间中。用statefuset资源运行一个httpd web服务，要求3个Pod，但是每个Pod的主界面内容不一样，并且都要做专有的数据持久化，尝试删除其中一个Pod，查看新生成的Pod，总结对比与之前Deployment资源控制器控制的Pod有什么不同之处？ （一）创建StorageClass资源对象。 注意：nfs服务要开启 1、创建namespace的yaml文件 12345[root@master yaml]# vim namespace.yaml kind: NamespaceapiVersion: v1metadata: name: xgp-lll #namespave的名称 执行一下 1[root@master yaml]# kubectl apply -f namespace.yaml 查看一下 1[root@master yaml]# kubectl get namespaces 2. 创建rbac权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@master yaml]# vim rbac-rolebind.yamlapiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: xgp-lll---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: xgp-lllrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: xgp-lllroleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io 执行一下 1[root@master yaml]# kubectl apply -f rbac-rolebind.yaml 3、创建Deployment资源对象，用Pod代替 真正的NFS服务。 1234567891011121314151617181920212223242526272829303132333435[root@master yaml]# vim nfs-deployment.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisioner namespace: xgp-lllspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: xgp - name: NFS_SERVER value: 192.168.1.21 - name: NFS_PATH value: /nfsdata volumes: - name: nfs-client-root nfs: server: 192.168.1.21 path: /nfsdata 执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml 查看一下 1[root@master yaml]# kubectl get pod -n xgp-lll 4、创建storageclass的yaml文件 12345678[root@master yaml]# vim test-storageclass.yaml apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: stateful-nfs namespace: xgp-lllprovisioner: xgp #通过provisioner字段关联到上述DeployreclaimPolicy: Retain 执行一下 1[root@master yaml]# kubectl apply -f test-storageclass.yaml 查看一下 1[root@master yaml]# kubectl get sc -n xgp-lll （二）解决自动创建pvc 1、创建statefulset的yaml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apiVersion: v1kind: Servicemetadata: name: headless-svc namespace: xgp-lll labels: app: headless-svcspec: ports: - port: 80 name: myweb selector: app: headless-pod clusterIP: None---apiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-test namespace: xgp-lllspec: serviceName: headless-svc replicas: 3 selector: matchLabels: app: headless-pod template: metadata: labels: app: headless-pod spec: containers: - image: httpd name: myhttpd ports: - containerPort: 80 name: httpd volumeMounts: - mountPath: /usr/local/apache2/htdocs name: test volumeClaimTemplates: #&gt; 自动创建PVC，为后端的Pod提供专有的存储。** - metadata: name: test annotations: #这是指定storageclass volume.beta.kubernetes.io/storage-class: stateful-nfs spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Mi 执行一下 1[root@master yaml]# kubectl apply -f statefulset.yaml 查看一下 1[root@master yaml]# kubectl get pod -n xgp-lll 2、 验证一下数据存储 容器中创建文件 1234567891011第一个[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-0 /bin/bash root@statefulset-test-0:/usr/local/apache2# echo 123 &gt; /usr/local/apache2/htdocs/index.html第二个[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-1 /bin/bash root@statefulset-test-2:/usr/local/apache2# echo 456 &gt; /usr/local/apache2/htdocs/index.html第三个[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-2 /bin/bash root@statefulset-test-1:/usr/local/apache2# echo 789 &gt; /usr/local/apache2/htdocs/index.html 宿主机查看一下 123456789101112第一个[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-0-pvc-ccaa02df-4721-4453-a6ec-4f2c928221d7/index.html 123第二个[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-1-pvc-88e60a58-97ea-4986-91d5-a3a6e907deac/index.html 456第三个[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-2-pvc-4eb2bbe2-63d2-431a-ba3e-b7b8d7e068d3/index.html 789 访问一下 扩容、缩容:在此过程中，Pod的生成或删除操作也是有顺序性的。 升级操作 1kubectl explain sts.spec.updateStrategy.rollingUpdate.partition partition：如果partition后面的值等于N, N+的都会更新。默认值为0（所有都会更新）。 总结： StatefulSet 的控制器直接管理的是 Pod。通过在 Pod 的名字里加上事先约定好的编号，保证应用拓扑状态的服务稳定。 Kubernetes 通过 Headless Service，为这些有编号的 Pod，在 DNS 服务器中生成带有同样编号的 DNS 记录，生成唯一的网络标识。 StatefulSet 为每一个 Pod 分配并创建一个同样编号的 PVC。保证了每一个 Pod 都拥有一个独立的 Volume，保证数据不会丢失。","path":"posts/af4b.html","date":"09-05","excerpt":"","tags":[{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"StatefulSet","slug":"StatefulSet","permalink":"https://wsdlxgp.top/tags/StatefulSet/"},{"name":"nfs-deployment","slug":"nfs-deployment","permalink":"https://wsdlxgp.top/tags/nfs-deployment/"}]},{"title":"k8s的存储类","text":"k8s有很多的服务，很多的资源对象。 如果要去创建服务，做数据持久化，需要预先知道可用PV有哪些? 如果为了这个服务去提前创建PV，那么我们还需要知道，这个服务，大概需要多大的空间? 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 存储类介绍 Kubernetes集群管理员通过提供不同的存储类，可以满足用户不同的服务质量级别、备份策略和任意策略要求的存储需求。动态存储卷供应使用StorageClass进行实现，其允许存储卷按需被创建。如果没有动态存储供应，Kubernetes集群的管理员将不得不通过手工的方式类创建新的存储卷。通过动态存储卷，Kubernetes将能够按照用户的需要，自动创建其需要的存储。 基于StorageClass的动态存储供应整体过程如下图所示： 1）集群管理员预先创建存储类（StorageClass）； 2）用户创建使用存储类的持久化存储声明(PVC：PersistentVolumeClaim)； 3）存储持久化声明通知系统，它需要一个持久化存储(PV: PersistentVolume)； 4）系统读取存储类的信息； 5）系统基于存储类的信息，在后台自动创建PVC需要的PV； 6）用户创建一个使用PVC的Pod； 7）Pod中的应用通过PVC进行数据的持久化； 8）而PVC使用PV进行数据的最终持久化处理。 先来简单看一下这张图实现的过程，然后我们再来研究一下 说在前面的话，静态供给的话，会需要我们手动去创建pv，如果没有足够的资源，找不到合适的pv，那么pod就会处于pending等待的状态，就是说找不到合适的伴侣了，所以解决这两种问题，就给出了这种动态供给，主要是能够自动帮你创建pv ，就是你需要多大的容量，就自动给你创建多大的容量，也就是pv，k8s帮你创建了，创建pvc的时候就需要找pv了，这个时候就交给这个存储类了，而存储类呢，去帮你创建这些pv,存储类呢，就是实现了对指定存储的一个支持，直接帮你去调用api去创建存储类，所以就不需要人工的去帮你创建pv了。 而你去想想，当节点比较多，业务比较多的时候，再去人工手动创建pv，量还是很大的，而且也不是很好去维护。 而动态供给主要的一个实现就是StorageClass存储对象，其实它就是声明你使用哪个存储，然后呢帮你去连接，再帮你去自动创建pv。 举个例子更好去理解 话不多说下图 其实它是一个基于NFS实现的一个pv供给，它大概流程是这样的，我们可能会创建一个statefulset有状态的应用存储，然后有一个管理的nfs-storageClass，因为nfs目前是不支持这个自动的创建pv的，我们可以利用社区实现的插件来完成这个pv的自动创建，也就是StorageClass这一块，创建完之后，然后pod再去引用。 一，Storage Class（存储类） 作用：它可以动态的自动的创建所需要的PV Provisioner（供给方，提供者）：及提供了存储资源的存储系统。k8s内建有多重供给方，这些供给方的名字都以“kubernetes.io”为前缀。并且还可以自定义。 Parameters（参数）：存储类使用参数描述要关联到的存储卷，注意不同的供给方参数也不同。 ReclaimPlicy: PV的回收策略，可用值有Delete(默认)和Retain （1）确定基于NFS服务来做的SC。NFS开启 1[root@master yaml]# showmount -e （2）需要RBAC权限。 RBAC：rbac是k8s的API的安全策略，是基于用户的访问权限的控制。规定了谁，可以有什么样的权限。 为了给SC资源操作k8s集群的权限。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@master yaml]# vim rbac-rolebind.yamlkind: NamespaceapiVersion: v1metadata: name: bdqn-test---apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: bdqn-test---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: bdqn-testrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: bdqn-testroleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io 运行一下 1[root@master yaml]# kubectl apply -f rbac-rolebind.yaml （3）nfs-deployment 作用：其实它是一个NFS客户端。但它通过K8S的内置的NFS驱动挂载远端的NFS服务器到本地目录；然后将自身作为storage provider，关联storage class。 1234567891011121314151617181920212223242526272829303132333435[root@master yaml]# vim nfs-deployment.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisioner namespace: bdqn-testspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner #指定账户 containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes #指定容器内的挂载目录 env: - name: PROVISIONER_NAME #这是这个容器内置的变量 value: bdqn-test #这是上面变量的值（名字） - name: NFS_SERVER #内置变量，用于指定nfs服务的IP value: 192.168.1.21 - name: NFS_PATH #内置变量，指定的是nfs共享的目录 value: /nfsdata volumes: #这下面是指定上面挂载到容器内的nfs的路径及IP - name: nfs-client-root nfs: server: 192.168.1.21 path: /nfsdata 执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml （4）创建storageclass 123456789[root@master yaml]# vim test-storageclass.yamlapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: stateful-nfs namespace: bdqn-testprovisioner: bdqn-test #这里要和第三个nfs-client-provisioner的env环境变量中的value值对应。reclaimPolicy: Retain #回收策略为：retain，还有一个默认的值为“default” 执行一下 1[root@master yaml]# kubectl apply -f test-storageclass.yaml （5）创建PVC 1234567891011121314[root@master yaml]# vim test-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-claim namespace: bdqn-testspec: storageClassName: stateful-nfs #定义存储类的名字，要和SC的名字对应 accessModes: - ReadWriteMany #访问模式为RWM resources: requests: storage: 500Mi 执行一下 1[root@master yaml]# kubectl apply -f test-pvc.yaml 查看一下 1[root@master yaml]# kubectl get pvc （6）创建一个Pod 12345678910111213141516171819202122[root@master yaml]# vim test-pod.yamlkind: PodapiVersion: v1metadata: name: test-pod namespace: bdqn-testspec: containers: - name: test-pod image: busybox args: - /bin/sh - -c - sleep 30000 volumeMounts: - name: nfs-pvc mountPath: /test restartPolicy: OnFailure volumes: - name: nfs-pvc persistentVolumeClaim: claimName: test-claim #这的名字要和PVC的名字一致 执行一下 1[root@master yaml]# kubectl apply -f test-pod.yaml 查看一下 1[root@master yaml]# kubectl get pod -n bdqn-test （7）容器中添加内容，并查看挂载目录 进入容器修改页面内容 123456[root@master yaml]# kubectl exec -it test-pod -n bdqn-test /bin/sh/ # cd test//test # touch test-file/test # echo 123456 &gt; test-file /test # cat test-file 123456 查看挂载目录 123456[root@master yaml]# ls /nfsdata/bdqn-test-test-claim-pvc-79ddfcf1-65ae-455f-9e03-5bcfe6c6ce15web1web2[root@master yaml]# cat /nfsdata/bdqn-test-test-claim-pvc-79ddfcf1-65ae-455f-9e03-5bcfe6c6ce15/test-file 123456 二，如果，K8S集群中， 有很多类似的PV, PVC在去向PV申请空间的时候，不仅会考虑名称以及访问控制模式，还会考虑你申请空间的大小，会分配给你最合适大小的PV。 运行一个web服务，采用Deployment资源，基于nginx镜像，replicas为3个。数据持久化目录为nginx服务的主访问目录：/usr/share/nginx/html 创建一个PVC,与上述资源进行关联。 1. 基于nfs服务来做的PV和pvc 下载nfs所需安装包 1[root@node02 ~]# yum -y install nfs-utils rpcbind 创建共享目录 1[root@master ~]# mkdir /nfsdata 创建共享目录的权限 12[root@master ~]# vim /etc/exports/nfsdata *(rw,sync,no_root_squash) 开启nfs和rpcbind 12[root@master ~]# systemctl start nfs-server.service [root@master ~]# systemctl start rpcbind 测试一下 1[root@master ~]# showmount -e 2.先创建两个PV, web- pV1(1G) ,web-pv2 (2G) web1 12345678910111213141516[root@master yaml]# vim web.yaml apiVersion: v1kind: PersistentVolumemetadata: name: web-pvspec : capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web1 server: 192.168.1.21 web2 12345678910111213141516[root@master yaml]# vim web2.yaml apiVersion: v1kind: PersistentVolumemetadata: name: web-pv2spec : capacity : storage: 2Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web2 server: 192.168.1.21 3.创建所需文件夹 12[root@master yaml]# mkdir /nfsdata/web1[root@master yaml]# mkdir /nfsdata/web2 4.执行一下web和web2 12[root@master yaml]# kubectl apply -f web.yaml [root@master yaml]# kubectl apply -f web2.yaml 5.查看一下 1[root@master yaml]# kubectl get pv 6.创建web的pvc的yaml文件 12345678910111213[root@master yaml]# vim web-pvc.yaml apiVersion: v1kind: PersistentVolumeClaimmetadata: name: web-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: nfs 执行一下 1[root@master yaml]# kubectl apply -f web-pvc.yaml 查看一下 1[root@master yaml]# kubectl get pvc 系统会自动给pvc一个相近内存的pv，所以选择了1G的那个 7.创建pod的yaml文件 123456789101112131415161718192021222324[root@master yaml]# vim web-pod.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: web-podspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - image: nginx name: nginx volumeMounts: - name: web-test mountPath: /usr/share/nginx/html volumes: - name: web-test persistentVolumeClaim: claimName: web-pvc 执行一下 1[root@master yaml]# kubectl apply -f web-pod.yaml 查看一下 1[root@master yaml]# kubectl get pod 8. 访问一下nginx的网页 查看一下nginx的ip 1[root@master yaml]# kubectl get pod -o wide 进入容器设置网页内容 12345root@master yaml]# kubectl exec -it web-pod-8686d9c594-qxhr9 /bin/bashroot@web-pod-8686d9c594-qxhr9:/# cd /usr/share/nginx/html/root@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# lsroot@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# echo 123456 &gt; index.htmlroot@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# exit 访问一下 1[root@master yaml]# curl 10.244.2.17 三，如果两个PV，大小一样，名称一样，访问控制模式不一样，PVC会关联哪一个? (验证PV和PVC 关联的时候，访问模式必须一样) 两个PV，大小一样，名称一样，访问控制模式不一样 &lt;1&gt;创建两个pv web1 123456789101112131415[root@master yaml]# vim web1.yaml apiVersion: v1kind: PersistentVolumemetadata: name: web-pvspec : capacity: storage: 1Gi accessModes: - ReadWriteOnce #能以读-写mount到单个的节点 persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web1 server: 192.168.1.21 web2 123456789101112131415[root@master yaml]# vim web2.yaml apiVersion: v1kind: PersistentVolumemetadata: name: web-pvspec : capacity: storage: 1Gi accessModes: - ReadWriteMany #能以读-写mount到多个的节点 persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web1 server: 192.168.1.21 创建所需文件 1[root@master yaml]# mkdir /nfsdata/web1 执行一下 12[root@master yaml]# kubectl apply -f web1.yaml [root@master yaml]# kubectl apply -f web2.yaml &lt;2&gt;创建pvc 123456789101112[root@master yaml]# vim web-pvc.yaml apiVersion: v1kind: PersistentVolumeClaimmetadata: name: web-pvcspec: accessModes: - ReadWriteMany #能以读-写mount到多个的节点 resources: requests: storage: 1Gi storageClassName: nfs 执行一下 1[root@master yaml]# kubectl apply -f web-pvc.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pv 1[root@master yaml]# kubectl get pvc 现在可以看到pv和pvc关联成功，但是为什么只有一个pv呢？（pv挂载的目录要相同） 那是因为当创建了两个相同名字的pv时它并不会认为这是两个不同的pv，而会把他们当成是同一个pv，后创建的pv会刷新前面创建的pv。然后，当创建了pvc，并且pvc的访问模式和后面创建pv的访问模式一样，他们就会关联成功，反之不成功。（当然这些条件下还需要考虑，pv的内存） 三，小实验 （1）以自己的名称创建一个名称空间。以下所有资源都在此名称空间之下。 &lt;1&gt;编写namespace的yam文件 12345[root@master yaml]# vim namespace.yaml kind: NamespaceapiVersion: v1metadata: name: xgp-znb &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f namespace.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get ns （2）设置rbac权限。 下载所需镜像 1docker pull registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner &lt;1&gt;编写rbac的yam文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@master yaml]# vim rbac-rolebind.yamlkind: NamespaceapiVersion: v1metadata: name: xgp-znb---apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: xgp-znb---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: xgp-znbrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: xgp-znbroleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f rbac-rolebind.yaml （3）创建nfs-deployment.yaml &lt;1&gt;编写deployment的yam文件 1234567891011121314151617181920212223242526272829303132333435[root@master yaml]# vim nfs-deployment.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisioner namespace: xgp-znbspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: xgp-znb - name: NFS_SERVER value: 192.168.1.21 - name: NFS_PATH value: /nfsdata volumes: - name: nfs-client-root nfs: server: 192.168.1.21 path: /nfsdata &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml （4）创建storageclass自动创建PV。 &lt;1&gt;编写storageclass的yam文件 1234567[root@master yaml]# vim storageclass.yamlapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: test-scprovisioner: xgp-znb #通过provisioner字段关联到上述DeployreclaimPolicy: Retain &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f storageclass.yaml （5）创建PVC &lt;1&gt;编写PVC的yaml文件 12345678910111213[root@master yaml]# vim pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-claim namespace: xgp-znbspec: storageClassName: test-sc accessModes: - ReadWriteMany resources: requests: storage: 500Mi &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f pvc.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pvc -n xgp-znb （6）创建一个Pod, 基于nginx运行一个web服务，使用Deployment资源对象，replicas=3.持久化存储目录为默认主目录 &lt;1&gt;编写deployment的yam文件 1234567891011121314151617181920212223242526[root@master yaml]# vim pod.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: web-pod namespace: xgp-znbspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - image: nginx name: nginx volumeMounts: - name: web-test mountPath: /usr/share/nginx/html volumes: - name: web-test persistentVolumeClaim: claimName: test-claim &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f pvc.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pod -n xgp-znb （7）访问nginx页面 修改nginx主页 1234[root@master yaml]# kubectl exec -it web-pod-8cd956cc7-6szjb -n xgp-znb /bin/bash//进入容器之中root@web-pod-8cd956cc7-6szjb:/# echo xgp-znb &gt; /usr/share/nginx/html/index.html//添加自定义内容主机 访问一下 1[root@master yaml]# curl 10.244.2.18 四，五个可移植性建议 把你的 pvc，和 其它一系列配置放一起， 比如说deployment，configmap 不要把你的pv放在其它配置里， 因为用户可能没有权限创建pv 初始化pvc 模版的时候， 提供一个storageclass 在你的工具软件中，watch那些没有bound的pvc，并呈现给用户 集群启动的时候启用DefaultStorageClass， 但是不要指定某一类特定的class， 因为不同provisioner的class，参数很难一致 五，四个阶段(volumn phase) 1. 在PVC中绑定一个PV，可以根据下面几种条件组合选择 Access Modes， 按照访问模式选择pv Resources， 按照资源属性选择， 比如说请求存储大小为8个G的pv Selector， 按照pv的label选择 Class， 根据StorageClass的class名称选择, 通过annotation指定了Storage Class的名字, 来绑定特定类型的后端存储 2. 关于根据class过滤出pv的说明： 所有的 PVC 都可以在不使用 StorageClass 注解的情况下，直接使用某个动态存储。把一个StorageClass 对象标记为 “default” 就可以了。StorageClass 用注解http://storageclass.beta.kubernetes.io/is-default-class 就可以成为缺省存储。有了缺省的 StorageClass，用户创建 PVC 就不用 storage-class 的注解了，1.4 中新加入的DefaultStorageClass 准入控制器会自动把这个标注指向缺省存储类。PVC 指定特定storageClassName，如fast时， 绑定名称为fast的storageClassPVC中指定storageClassName为“”时， 绑定no class的pv（pv中无class annotation， 或者其值为“”）PVC不指定storageClassName时， DefaultStorageClass admission plugin 开启与否（在apiserver启动时可以指定）， 对default class的解析行为是不同的。当DefaultStorageClass admission plugin启用时， 针对没有storageClass annotation的pvc，DefaultStorageClass会分配一个默认的class， 这个默认的class需要用户指定，比如在创建storageclass对象时加入annotation,如 http://storageclass.beta.kubernetes.io/is-default-class: “true” 。如果有多个默认的class， 则pvc会被拒绝创建， 如果用户没有指定默认的class， 则这个DefaultStorageClass admission plugin不会起任何作用。 pvc会找那些no class的pv做绑定。当DefaultStorageClass admission plugin没有启用时， 针对没有storageClass annotation的pvc， 会绑定no class的pv（pv中无class annotation， 或者其值为“”）","path":"posts/15ab.html","date":"09-04","excerpt":"","tags":[{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"}]},{"title":"k8s存储方式的介绍及应用 （持久化，mysql对数据持久化的应用）","text":"k8s存储: (持久化) docker容器是有生命周期的。 volume 1，存储类（Storage class）是k8s资源类型的一种，它是有管理员为管理PV更加方便创建的一个逻辑组，可以按照存储系统的性能高低，或者综合服务质量，备份策略等分类。不过k8s本身不知道类别到底是什么，它这是作为一个描述。 2，存储类的好处之一就是支持PV的动态创建，当用户用到持久性存储时，不必再去提前创建PV，而是直接创建PVC就可以了，非常的方便。 3，存储类对象的名称很重要，并且出了名称之外，还有3个关键字段 Provisioner（供给方）: 及提供了存储资源的存储系统。k8s内建有多重供给方，这些供给方的名字都以“kubernetes.io”为前缀。并且还可以自定义。 Parameters(参数)：存储类使用参数描述要关联到的存储卷，注意不同的供给方参数也不同。 reclaimPolicy:PV的回收策略，可用值有Delete(默认)和Retain 简介 1, 由于容器本身是非持久化的，因此需要解决在容器中运行应用程序遇到的一些问题。首先，当容器崩溃时，kubelet将重新启动容器，但是写入容器的文件将会丢失，容器将会以镜像的初始状态重新开始；第二，在通过一个Pod中一起运行的容器，通常需要共享容器之间一些文件。Kubernetes通过存储卷解决上述的两个问题。 2, 在Docker有存储卷的概念卷，但Docker中存储卷只是磁盘的或另一个容器中的目录，并没有对其生命周期进行管理。Kubernetes的存储卷有自己的生命周期，它的生命周期与使用的它Pod生命周期一致。因此，相比于在Pod中运行的容器来说，存储卷的存在时间会比的其中的任何容器都长，并且在容器重新启动时会保留数据。当然，当Pod停止存在时，存储卷也将不再存在。在Kubernetes支持多种类型的卷，而Pod可以同时使用各种类型和任意数量的存储卷。在Pod中通过指定下面的字段来使用存储卷： spec.volumes：通过此字段提供指定的存储卷 spec.containers.volumeMounts：通过此字段将存储卷挂接到容器中 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 1.emptyDir（空目录）:类似docker 数据持久化的:docer manager volume 使用场景:在同一 个Pod里，不同的容器，共享数据卷。 如果容器被删除，数据仍然存在，如果Pod被 删除，数据也会被删除。 &lt;1&gt; 介绍 一个emptyDir 第一次创建是在一个pod被指定到具体node的时候，并且会一直存在在pod的生命周期当中，正如它的名字一样，它初始化是一个空的目录，pod中的容器都可以读写这个目录，这个目录可以被挂在到各个容器相同或者不相同的的路径下。当一个pod因为任何原因被移除的时候，这些数据会被永久删除。注意：一个容器崩溃了不会导致数据的丢失，因为容器的崩溃并不移除pod. emptyDir的使用场景如下： 空白的初始空间，例如合并/排序算法中，临时将数据保存在磁盘上。 长时间计算中存储检查点（中间结果），以便容器崩溃时，可以从上一次存储的检查点（中间结果）继续进行，而不是从头开始。 作为两个容器的共享存储，使得第一个内容管理的容器可以将生成的数据存入其中，同时由一个webserver容器对外提供这些页面。 默认情况下，emptyDir数据卷存储在node节点的存储介质（机械硬盘、SSD或网络存储）上。 &lt;2&gt;emptyDir 磁盘的作用： （1）普通空间，基于磁盘的数据存储 （2）作为从崩溃中恢复的备份点 （3）存储那些那些需要长久保存的数据，例web服务中的数据 默认的，emptyDir 磁盘会存储在主机所使用的媒介上，可能是SSD，或者网络硬盘，这主要取决于你的环境。当然，我们也可以将emptyDir.medium的值设置为Memory来告诉Kubernetes 来挂在一个基于内存的目录tmpfs，因为 tmpfs速度会比硬盘块度了，但是，当主机重启的时候所有的数据都会丢失。 测试编写一个yaml文件 12345678910111213141516171819202122232425262728[root@master yaml]# vim emptyDir.yamlapiVersion: v1kind: Podmetadata: name: producer-consumerspec: containers: - image: busybox name: producer volumeMounts: - mountPath: /producer_dir name: shared-volume args: - /bin/sh - -c - echo \"hello k8s\" &gt; /producer_dir/hello; sleep 30000 - image: busybox name: consumer volumeMounts: - mountPath: /consumer_dir name: shared-volume args: - /bin/sh - -c - cat /consumer_dir/hello; sleep 30000 volumes: - name: shared-volume emptyDir: &#123;&#125; 执行一下 1[root@master yaml]# kubectl apply -f emptyDir.yaml 查看一下 1[root@master yaml]# kubectl get pod 查看日志 12[root@master yaml]# kubectl logs producer-consumer producer[root@master yaml]# kubectl logs producer-consumer consumer 查看挂载的目录 node节点查看容器名，并通过容器名查看挂载的目录 1[root@node01 shared-volume]# docker ps 1[root@node01 shared-volume]# docker inspect k8s_consumer_producer-consumer_default_9ec83f9e-e58b-4bf8-8e16-85b0f83febf9_0 进入挂载目录查看一下 2.hostPath Volume:类似docker 数据持久化的:bind mount 如果Pod被删除，数据会保留，相比较emptyDir要好一点。不过一旦host崩溃，hostPath也无法访问 了。 docker或者k8s集群本身的存储会采用hostPath这种方式。 &lt;1&gt; 介绍 hostPath宿主机路径，就是把pod所在的宿主机之上的脱离pod中的容器名称空间的之外的宿主机的文件系统的某一目录和pod建立关联关系，在pod删除时，存储数据不会丢失。 &lt;2&gt; 作用 如果Pod被删除，数据会保留，相比较emptyDir要好一点。不过一旦host崩溃，hostPath也无法访问 了。 docker或者k8s集群本身的存储会采用hostPath这种方式。 适用场景如下： 某容器需要访问 Docker，可使用 hostPath 挂载宿主节点的 /var/lib/docker 在容器中运行 cAdvisor，使用 hostPath 挂载宿主节点的 /sys 3.Persistent Volume| PV(持久卷) 提前做好的，数据持久化的数据存放目录。 Psesistent Volume Claim| PVC( 持久卷使用声明|申请) Psesistent Volume Claim| PVC( 持久卷使用声明|申请) PersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 该API对象捕获存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统。 PVC和PV的概念 我们前面提到kubernetes提供那么多存储接口，但是首先kubernetes的各个Node节点能管理这些存储，但是各种存储参数也需要专业的存储工程师才能了解，由此我们的kubernetes管理变的更加复杂的。由此kubernetes提出了PV和PVC的概念，这样开发人员和使用者就不需要关注后端存储是什么，使用什么参数等问题。如下图： PersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 该API对象捕获存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统。 PersistentVolumeClaim（PVC）是用户存储的请求。PVC的使用逻辑：在pod中定义一个存储卷（该存储卷类型为PVC），定义的时候直接指定大小，pvc必须与对应的pv建立关系，pvc会根据定义去pv申请，而pv是由存储空间创建出来的。pv和pvc是kubernetes抽象出来的一种存储资源。 虽然PersistentVolumeClaims允许用户使用抽象存储资源，但是常见的需求是，用户需要根据不同的需求去创建PV，用于不同的场景。而此时需要集群管理员提供不同需求的PV，而不仅仅是PV的大小和访问模式，但又不需要用户了解这些卷的实现细节。 对于这样的需求，此时可以采用StorageClass资源。这个在前面就已经提到过此方案。 PV是集群中的资源。 PVC是对这些资源的请求，也是对资源的索赔检查。 PV和PVC之间的相互作用遵循这个生命周期： 1Provisioning（配置）---&gt; Binding（绑定）---&gt;Using（使用）---&gt; Releasing（释放） ---&gt; Recycling（回收） （1）基于nfs服务来做的PV和pvc nfs使的我们可以挂在已经存在的共享到的我们的Pod中，和emptyDir不同的是，emptyDir会被删除当我们的Pod被删除的时候，但是nfs不会被删除，仅仅是解除挂在状态而已，这就意味着NFS能够允许我们提前对数据进行处理，而且这些数据可以在Pod之间相互传递.并且，nfs可以同时被多个pod挂在并进行读写 注意：必须先保证NFS服务器正常运行在我们进行挂在nfs的时候 下载nfs所需安装包 1[root@node02 ~]# yum -y install nfs-utils rpcbind 创建共享目录 1[root@master ~]# mkdir /nfsdata 创建共享目录的权限 12[root@master ~]# vim /etc/exports/nfsdata *(rw,sync,no_root_squash) 开启nfs和rpcbind 12[root@master ~]# systemctl start nfs-server.service [root@master ~]# systemctl start rpcbind 测试一下 1[root@master ~]# showmount -e &lt;1&gt;创建nfs-pv的yaml文件 12345678910111213141516[root@master yaml]# cd yaml/[root@master yaml]# vim nfs-pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: test-pvspec: capacity: #pv容量的大小 storage: 1Gi accessModes: #访问pv的模式 - ReadWriteOnce #能以读-写mount到单个的节点 persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/pv1 server: 192.168.1.21 1234 accessModes:(PV支持的访问模式) - ReadWriteOnce: 能以读-写mount到单个的节点 - ReadWriteMany: 能以读-写mount到多个的节点。- ReadOnlyMnce: 能以只读的方式mount到多个节点。 1234persistentVolumeReclaimPolicy : (PV存储空间的回收策略是什么)trueRecycle: 自动清除数据。trueRetain: 需要管理员手动回收。trueDelete: 云存储专用。 &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f nfs-pv.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pv &lt;1&gt;创建nfs-pvc的yaml文件 PersistentVolumeClaim（PVC）是用户存储的请求。PVC的使用逻辑：在pod中定义一个存储卷（该存储卷类型为PVC），定义的时候直接指定大小，pvc必须与对应的pv建立关系，pvc会根据定义去pv申请，而pv是由存储空间创建出来的。pv和pvc是kubernetes抽象出来的一种存储资源。 12345678910111213[root@master yaml]# vim nfs-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: nfs &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f nfs-pvc.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pvc 1[root@master yaml]# kubectl get pv （2）创建一个pod资源 1234567891011121314151617181920[root@master yaml]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-podspec: containers: - name: pod1 image: busybox args: - /bin/sh - -c - sleep 30000 volumeMounts: - mountPath: \"/mydata\" name: mydata volumes: - name: mydata persistentVolumeClaim: claimName: test-pvc &lt;1&gt; 执行一下 1[root@master yaml]# kubectl apply -f pod.yaml &lt;2&gt;查看一下 1[root@master yaml]# kubectl get pod -o wide 可以看到现在没有开启成功 查看一下test-pod的信息看看是哪里的问题 1[root@master yaml]# kubectl describe pod test-pod 那是因为pv的本地挂载目录没有创建好 12[root@master yaml]# mkdir /nfsdata/pv1///要和nfs-pv.yaml的名字一样 重新创建一下pod 123[root@master yaml]# kubectl delete -f pod.yaml [root@master yaml]# kubectl apply -f pod.yaml [root@master yaml]# kubectl get pod -o wide （3）test-pod创建hello创建文件并添加内容 1[root@master yaml]# kubectl exec test-pod touch /mydata/hello 进入容器 123[root@master yaml]# kubectl exec -it test-pod /bin/sh/ # echo 123 &gt; /mydata/hello/ # exit 挂载目录查看一下 1[root@master yaml]# cat /nfsdata/pv1/hello 和刚刚的一样 （4）测试回收策略 删除pod和pvc，pv 123[root@master yaml]# kubectl delete pod test-pod [root@master yaml]# kubectl delete pvc test-pvc [root@master yaml]# kubectl delete pv test-pv 查看一下 1[root@master yaml]# kubectl get pv 1[root@master yaml]# cat /nfsdata/pv1/hello 文件已被回收 （5）修改pv的回收策略为手动 修改 123456789101112131415[root@master yaml]# vim nfs-pv.yaml apiVersion: v1kind: PersistentVolumemetadata: name: test-pvspec : capacity : storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain #修改 storageClassName: nfs nfs: path: /nfsdata/pv1 server: 192.168.1.21 执行一下 1[root@master yaml]# kubectl apply -f nfs-pv.yaml 创建pod 1[root@master yaml]# kubectl apply -f pod.yaml 查看一下 1[root@master yaml]# kubectl describe pod test-pod 创建pvc 1[root@master yaml]# kubectl apply -f nfs-pvc.yaml 查看一下pod 1[root@master yaml]# kubectl get pod （6）test-pod创建hello创建文件并添加内容 1[root@master yaml]# kubectl exec test-pod touch /mydata/k8s 查看一下挂载目录 1[root@master yaml]# ls /nfsdata/pv1/ 删除pod和pvc，pv，再次查看挂载目录 123[root@master yaml]# kubectl delete pod test-pod [root@master yaml]# kubectl delete pvc test-pvc[root@master yaml]# kubectl delete pv test-pv 查看挂载目录 1[root@master yaml]# ls /nfsdata/pv1/ 内容还在 4.mysql对数据持久化的应用 下面演示如何为 MySQL 数据库提供持久化存储，步骤为： 创建 PV 和 PVC。 部署 MySQL。 向 MySQL 添加数据。 模拟节点宕机故障，Kubernetes 将 MySQL 自动迁移到其他节点。 验证数据一致性。 最小化安装系统需要 1yum -y install mariadb （1）通过之前的yaml文件，创建pv和pvc 12[root@master yaml]# kubectl apply -f nfs-pv.yaml [root@master yaml]# kubectl apply -f nfs-pvc.yaml 查看一下 1[root@master yaml]# kubectl get pv 1[root@master yaml]# kubectl get pvc （2）编写一个mysql的yaml文件 123456789101112131415161718192021222324252627282930313233343536[root@master yaml]# vim mysql.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: test-mysqlspec: selector: matchLabels: #支持等值的标签 app: mysqlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: test-mysqlspec: selector: matchLabels: app: mysql template: metadata: labels: app: mysql spec: containers: - image: mysql:5.6 name: mysql env: - name: MYSQL_ROOT_PASSWORD value: 123.com volumeMounts: - name: mysql-storage mountPath: /var/lib/mysql volumes: - name: mysql-storage persistentVolumeClaim: claimName: test-pvc 执行一下 1[root@master yaml]# kubectl apply -f mysql.yaml 查看一下 1[root@master yaml]# kubectl get pod （3）进入mysql容器 ① 切换到数据库 mysql。 ② 创建数据库表 my_id。 ③ 插入一条数据。 ④ 确认数据已经写入。 关闭 k8s-node2，模拟节点宕机故障。 1[root@master yaml]# kubectl exec -it test-mysql-569f8df4db-rkpwm -- mysql -u root -p123.com 创建数据库 1mysql&gt; create database yun33; 切换数据库 1mysql&gt; use yun33; 创建表 1mysql&gt; create table my_id( id int(4))； 在表中插入数据 1mysql&gt; insert my_id values(9527); 查看表 1mysql&gt; select * from my_id; （4）查看本地的挂载目录 1[root@master yaml]# ls /nfsdata/pv1/ 查看一下pod 1[root@master yaml]# kubectl get pod -o wide -w 挂起node01 （5）查看node02上面数据是否和刚才一样（验证数据的一致性） 进入数据库 1[root@master yaml]# kubectl exec -it test-mysql-569f8df4db-nsdnz -- mysql -u root -p123.com 查看数据库 1mysql&gt; show databases; 查看表 1mysql&gt; show tables; 1mysql&gt; select * from my_id; 可以看到数据还在 5. 排错方法 kubectl describe //查看详细信息，找出问题 kubectl logs //查看日志，找出问题 /var/ log/messages //查看该节点的kubelet的日志。 5. 总结 本章我们讨论了 Kubernetes 如何管理存储资源。 emptyDir 和 hostPath 类型的 Volume 很方便，但可持久性不强，Kubernetes 支持多种外部存储系统的 Volume。 PV 和 PVC 分离了管理员和普通用户的职责，更适合生产环境。我们还学习了如何通过 StorageClass 实现更高效的动态供给。 最后，我们演示了如何在 MySQL 中使用 PersistentVolume 实现数据持久性。 PV的访问控制类型 accessModes:(PV支持的访问模式) ReadWriteOnce: 能以读-写mount到单个的节点 ReadWriteMany: 能以读-写mount到多个的节点。 ReadOnlyOnce: 能以只读的方式mount到单个节点。 PV的空间回收策略 persistentVolumeReclaimPolicy : (PV存储空间的回收策略是什么) Recycle: 自动清除数据。 Retain: 需要管理员手动回收。 Delete: 云存储专用。 PV和PVC相互关联 是通过accessModes和storageClassName模块关联的 Pod不断的重启: 1、swap,没有关闭，导致集群运行不正常。 2、内存不足，运行服务也会重后。 kubectl describe kubectl logs /var/ log/messages 查看该节点的kubelet的日志。","path":"posts/ba49.html","date":"09-03","excerpt":"","tags":[{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"emptyDir","slug":"emptyDir","permalink":"https://wsdlxgp.top/tags/emptyDir/"}]},{"title":"k8s复习","text":"虚拟化 云计算的分类: 基础及服务: laas 平台及服务: paas 软件及服务: saas **docker虚拟化的底层原理: ** Namespace + Cgroup **Namespace六项隔离: ** IPC: 共享内存,消息列队 MNT: 挂载点 文件系统 NET: 网络栈 PID: 进程编号 USER: 用户 组 UTS: 主机名 域名 namespace 六项隔离 实现了容器与宿主机 容器与容器之间的隔离 **Cgroup 四项作用: ** **1） 资源的限制: **cgroup可以对进程组使用的资源总额进行限制 **2） 优先级分配: **通过分配的cpu时间片数量以及硬盘IO带宽的大小，实际上相当于控制了进程运行的优先级别 **3） 资源统计: ** group可以统计系统资源使用量，比如gpu使用时间，内存使用量等，用于按量计费。同时还支持挂起动能，也就是说通过cgroup把所有 资源限制起来,对资源都不能使用，注意着并不是说我们的程序不能使用了,知识不能使用资源，处于等待状态。 **4） 进程控制: **可以对进程组执行挂起、恢复等操作。 镜像是容器运行的核心，容器是镜像运行的后的实例。 DockerHub| registry ----&gt; pull image : save &gt; | load &lt; run ----&gt; Container ----&gt; commit* Dockerfile Docker 三剑客。 docker machine: 自动化部署多台dockerHost 。 Docker-compose: 它可以同时控制多个容器。 yaml。 **Docker Swarm: ** 从单个的服务向集群的形势发展。 高可用、高性能、高并发 : 为了防止单点故障。 Service: 服务 ----&gt; 包括运行什么服务，需要多个 rep1icas（副本）, 外网如何访问。 k8s 关闭防火墙、禁用selinux、修改主机名并加入域名解析、关闭swap 、时间同步、免密登录、打开iptables桥接 对硬件的基本要求: CPU: 2核 MEM: 2G 主机名: master node01 node02 时间必须同步 kubctl: k8s客户端 kubeadm: 工具 kubelet: 客户端代理 **组件: ** 三层网络: DockerHost &gt; Pod &gt; Service **Deployment: Service: ** **master组件: ** kube- api( application interface) k8s的前端接口 **Scheduler[集群分发调度器]**负责决定将Pod放在哪个Node上运行。在调度时，会充分考虑集群的拓扑结构，当前各个节点的负载情况，以及应对高可用、性能、数据亲和性和需求。 Controller Manager[内部管理控制中心]: 负责管理集群的各种资源，保证资源处于预期的状态。它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等。 **Etcd: **负责保存k8s集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速的通知k8s相关组件。[（第三方组件）它有可替换方案。Consul、zookeeper](https: //wsdlxgp.top/posts/1b18.html) **Flanner: **是k8s集群网络，可以保证Pod的跨主机通信。也有替换方案。 Node组件: Kubelet[节点上的Pod管家]: 它是Node的agent(代理)，当Scheduler确定某 个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet,kubelet会根据这些信息创建和运行容器，并向Master报告运行状态。 **kube-proxy[负载均衡、路由转发]: **负责将访问service的TCP/UDP数据流转发到后端的容器。如果有多个副本，kube-proxy会实现负载均衡。 yaml文件的一级字段: **VERSION: ** ​ **KIND: ** ​ **METADATA: ** ​ **SPEC : ** 12345678910111213141516[root@master ~]# vim web.yamlkind: Deployment #资源对象是控制器apiVersion: extensions/v1beta1 #api的版本metadata: #描述kind（资源类型） name: web #定义控制器名称 namespace: #名称空间spec: replicas: 2 #副本数量 template: #模板 metadata: labels: #标签 app: web_server spec: containers: #指定容器 - name: nginx #容器名称 image: nginx #使用的镜像 **Deployment（控制器): ** **ReplicationController: **用来确保由其管控的Pod对象副本数量，能够满足用户期望，多则删除，少则通过模本创建 **RS（RpelicaSet）: **RS也是用于保证与label selector匹配的pod数量维持在期望状态 **Service: ** type: 默认Cluster IP NodePort: 30000-32767 Deployment和Service关联: 标签和标签选择器 **Namespace: ** Pod: 最小单位 **镜像的下载策略: ** **Always: **镜像标签为“laster”或镜像不存在时，总是从指定的仓库中获取镜像。 **IfNotPresent: **仅当本地镜像不存在时才从目标仓库下载。 **Never: **禁止从仓库中下载镜像，即只使用本地镜像。 默认的标签 为latest: always **Pod的重启策略: ** **Always: **（默认情况下使用）但凡Pod对象终止就将其重启； ​ **OnFailure: **仅在Pod对象出现错误时才将其重启； ​ **Never: **从不重启； **Pod的健康检查: ** ​ Liveness: 探测失败重启pod ​ Readiness: 探测失败将pod设置为不可用 kubelet: 控制pod DaemonSet : 会在每一个节点都会运行，并且只运行一个Pod","path":"posts/fehv.html","date":"09-02","excerpt":"","tags":[{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"}]},{"title":"k8s的Job/CronJob资源对象及添加api版本","text":"Job资源对象 **服务类的Pod容器：**RC、RS、DS、Deployment **工作类的Pod容器：**Job—&gt;执行一次，或者批量执行处理程序，完成之后退出容器。 注意： 如果容器内执行任务有误，会根据容器的重启策略操作容器，不过这里 的容器重启策略只能是: Never和 OnFailure。 概念 在有些场景下，是想要运行一些容器执行某种特定的任务，任务一旦执行完成，容器也就没有存在的必要了。在这种场景下，创建pod就显得不那么合适。于是就是了Job，Job指的就是那些一次性任务。通过Job运行一个容器，当其任务执行完以后，就自动退出，集群也不再重新将其唤醒。 从程序的运行形态上来区分，可以将Pod分为两类：长时运行服务（jboss、mysql等）和一次性任务（数据计算、测试）。RC创建的Pod都是长时运行的服务，Job多用于执行一次性任务、批处理工作等，执行完成后便会停止（status.phase变为Succeeded）。 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 一、kubernetes支持以下几种job 非并行job：通常创建一个pod直至其成功结束。 固定结束次数的job：设置spec.completions,创建多个pod，直到.spec.completions个pod成功结束。 带有工作队列的并行job：设置.spec.Parallelism但不设置.spec.completions,当所有pod结束并且至少一个成功时，job就认为是成功。 Job Controller Job Controller负责根据Job Spec创建pod，并持续监控pod的状态，直至其成功结束，如果失败，则根据restartPolicy（只支持OnFailure和Never，不支持Always）决定是否创建新的pod再次重试任务。 例子 （1）编写一个job的yaml文件 123456789101112131415[root@master yaml]# vim jop.yamlkind: JobapiVersion: batch/v1metadata: name: test-jobspec: template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"echo\",\"hello k8s job!\"] restartPolicy: Never （2）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （3）查看一下 1[root@master yaml]# kubectl get pod 查看日志 1[root@master yaml]# kubectl logs test-job-gs45w 我们可以看到job与其他资源对象不同，仅执行一次性任务，默认pod借宿运行后job即结束，状态为Completed。 （4）修改一下jop的yaml文件，把echo命令换成乱码 123456789101112131415[root@master yaml]# vim jop.yamlkind: JobapiVersion: batch/v1metadata: name: test-jobspec: template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"asdasxsddwefew\",\"hello k8s job!\"] #修改 restartPolicy: Never （5）先删除之前的pod 1[root@master yaml]# kubectl delete jobs.batch test-job （6）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （7）查看一下 1[root@master yaml]# kubectl get pod -w 它会一直创建pod直到完成命令。 （8）修改一下jop的yaml文件，修改重启策略 123456789101112131415[root@master yaml]# vim jop.yaml kind: JobapiVersion: batch/v1metadata: name: test-jobspec: template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"asdasxsddwefew\",\"hello k8s job!\"] restartPolicy: OnFailure （9）先删除之前的pod 1[root@master yaml]# kubectl delete jobs.batch test-job （10）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （11）查看一下 1[root@master yaml]# kubectl get pod -w 它会一直重启pod完成命令，直到重启到一定次数就会删除job。 二、提高Job的执行效率 1. 我们可以在Job.spec字段下加上parallelism选项。表示同时运行多少个Pod执行任务。 （1）编写一个job的yaml文件 12345678910111213141516[root@master yaml]# vim jop.yamlkind: JobapiVersion: batch/v1metadata: name: test-jobspec: parallelism: 2 #同时启用几个pod template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"echo\",\"hello k8s job!\"] restartPolicy: OnFailure （3）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod 查看日志 2. 我们可以在Job.spec字段下加上complations选项。表示总共需要完成Pod的数量 （1）编写一个job的yaml文件 1234567891011121314151617[root@master yaml]# vim jop.yamlkind: JobapiVersion: batch/v1metadata: name: test-jobspec: complations: 8 #运行pod的总数量8个 parallelism: 2 #同时运行2个pod template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"echo\",\"hello k8s job!\"] restartPolicy: OnFailure job 字段解释： 标志Job结束需要成功运行的Pod个数，默认为1 parallelism：标志并行运行的Pod的个数，默认为1 activeDeadlineSeconds：标志失败Pod的重试最大时间，超过这个时间不会继续重试. （2）先删除之前的pod 1[root@master yaml]# kubectl delete jobs.batch test-job （3）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod 可以看到pod是两个两个的启动的。 3. 如何定时执行Job （1）编写一个cronjob的yaml文件 12345678910111213141516[root@master yaml]# vim cronjop.yamlkind: CronJobapiVersion: batch/v1beta1metadata: name: hellospec: schedule: \"*/1 * * * *\" #限定时间 jobTemplate: spec: template: spec: containers: - name: hello image: busybox command: [\"echo\",\"hello\",\"cronjob\"] restartPolicy: OnFailure （2）先删除之前的pod 1[root@master yaml]# kubectl delete jobs.batch test-job （3）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod 1[root@master yaml]# kubectl get cronjobs.batch 此时查看Pod的状态，会发现，每分钟都会运行一个新的Pod来执行命令规定的任 务。 练习：规定2020.1.15.10.5分运行上面的crontab任务。 （1）编写一个cronjob的yaml文件 12345678910111213141516[root@master yaml]# vim cronjop.yamlkind: CronJobapiVersion: batch/v1beta1metadata: name: hellospec: schedule: \"5 10 15 1 *\" #限定时间 jobTemplate: spec: template: spec: containers: - name: hello image: busybox command: [\"echo\",\"hello\",\"cronjob\"] restartPolicy: OnFailure （2）先删除之前的pod 1[root@master yaml]# kubectl delete cronjobs.batch hello （3）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod 这时会发现，如果规定具体时间，可能并不会执行任务。 （5）添加apiVersion库 123456[root@master yaml]# vim /etc/kubernetes/manifests/kube-apiserver.yaml spec: containers: - command: - kube-apiserver - --runtime-config=batch/v2alpha1=true #添加 （6）重启kubelet 1[root@master yaml]# systemctl restart kubelet.service （7）查看api版本 1[root@master yaml]# kubectl api-versions （8）编写一个cronjob的yaml文件 12345678910111213141516[root@master yaml]# vim cronjop.yamlkind: CronJobapiVersion: batch/v1beta1metadata: name: hellospec: schedule: \"47 10 15 1 *\" #限定时间 jobTemplate: spec: template: spec: containers: - name: hello image: busybox command: [\"echo\",\"hello\",\"cronjob\"] restartPolicy: OnFailure （9）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod -w 注意：此时仍然不能正常运行指定时间的Job，这是因为K8s官方在cronjob这个资源对象的支持中还没有完善此功能，还待开发。 跟Job资源一样在cronjob.spec.jobTemplate.spec 下同样支持并发Job参数: parallelism，也支持完成Pod的总数参数: completionsr 总结 Job 作为 Kubernetes 中用于处理任务的资源，与其他的资源没有太多的区别，它也使用 Kubernetes 中常见的控制器模式，监听 Informer 中的事件并运行 syncHandler 同步任务 而 CronJob 由于其功能的特殊性，每隔 10s 会从 apiserver 中取出资源并进行检查是否应该触发调度创建新的资源，需要注意的是 CronJob 并不能保证在准确的目标时间执行，执行会有一定程度的滞后。 两个控制器的实现都比较清晰，只是边界条件比较多，分析其实现原理时一定要多注意。","path":"posts/fbf7.html","date":"09-01","excerpt":"","tags":[{"name":"Job","slug":"Job","permalink":"https://wsdlxgp.top/tags/Job/"},{"name":"apiVersion","slug":"apiVersion","permalink":"https://wsdlxgp.top/tags/apiVersion/"},{"name":"CronJob","slug":"CronJob","permalink":"https://wsdlxgp.top/tags/CronJob/"}]},{"title":"k8s的ReplicaSet，DaemonSet及标签","text":"环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 ReplicaSet简单介绍 1. RC：ReplicationController（老一代的pod控制器） 用来确保由其管控的Pod对象副本数量，能够满足用户期望，多则删除，少则通过模本创建 特点： 确保Pod资源对象的数量精准。 确保pod健康运行。 弹性伸缩 同样，它也可以通过yaml或json格式的资源清单来创建。其中spec字段一般嵌套以下字段： replicas：期望的Pod对象副本数量。 selector：当前控制器匹配Pod对此项副本的标签选择器 template：pod副本的模板 与RC相比而言，RS不仅支持*基于等值*的标签选择器，而且还支持*基于集合*的标签选择器。 2. 标签：解决同类型的资源对象，为了更好的管理，按照标签分组。 常用的标签分类： release（版本）：stable（稳定版）、canary（金丝雀版本）、beta（测试版本） environment（环境变量）：dev（开发）、qa（测试）、production（生产） application（应用）：ui、as（application software应用软件）、pc、sc tier（架构层级）：frontend（前端）、backend（后端）、cache（缓存） partition（分区）：customerA（客户A）、customerB（客户B） track（品控级别）：daily（每天）、weekly（每周） 标签要做到：见名知意。 3.测试 （1）编写一个pod的yaml文件 12345678910111213[root@master ~]# vim label.yaml kind: PodapiVersion: v1metadata: name: labels labels: env: qa tier: frontendspec: containers: - name: myapp image: httpd &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f label.yaml --record &lt;2&gt;查看一下 12[root@master ~]# kubectl get pod --show-labels //通过--show-labels显示资源对象的 12[root@master ~]# kubectl get po -L env,tier//显示某个键对应的值 12[root@master ~]# kubectl get po -l env,tier//通过-l 查看仅包含某个标签的资源。 （2）添加标签 12[root@master ~]# kubectl label pod labels app=pc//给pod资源添加标签 （3）修改标签 1234[root@master ~]# kubectl label pod labels env=dev --overwrite//修改标签[root@master ~]# kubectl get pod -l tier --show-labels //查看标签 （4）编写一个service的yaml文件 1234567891011121314[root@master ~]# vim service.yamlkind: ServiceapiVersion: v1metadata: name: servicespec: type: NodePort selector: env: qa ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30123 &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f service.yaml &lt;2&gt;查看一下 1[root@master ~]# kubectl describe svc &lt;3&gt;访问一下 1[root@master ~]# curl 127.0.0.1:30123 如果标签有多个，标签选择器选择其中一个，也可以关联成功。相反，如果选择器有多个，那么标签必须完全满足条件，才可以关联成功。 4. 标签选择器：标签的查询过滤条件。 基于等值关系的（equality-based）：“=”，“==”，“！ =”前面两个都是相等，最后一个是不等于。 基于集合关系（set-based）:in、notin、exists三种。选择器列表间为“逻辑与”关系，使用ln或者NotIn操作时，其valuas不强制要求为非空的字符串列表，而使用Exists或DostNotExist时，其values必须为空 使用标签选择器的逻辑： 同时指定的多个选择器之间的逻辑关系为“与”操作。 使用空值的标签选择器意味着每个资源对象都将把选中。 空的标签选择器无法选中任何资源。 （1）例子 编写一个selector的yaml’文件 1234567[root@master ~]# vim selector.yamlselector: matchLabels: app: nginx mathExpressions: - &#123;key: name,operator: In,values: [zhangsan,lisi]&#125; - &#123;key: age,operator: Exists,values:&#125; selector：当前控制器匹配Pod对此项副本的标签选择器 matchLabels: 指定键值对表示的标签选择器。 mathExpressions:：基于表达式来指定的标签选择器。 DaemonSet 它也是一种pod控制器。 RC，RS , deployment , daemonset.都是pod控制器。statfukSet，RBAC 1. 使用场景： 如果必须将pod运行在固定的某个或某几个节点，且要优先于其他的pod的启动。通常情况下，默认会将每一个节点都运行，并且只能运行一个pod。这种情况推荐使用DeamonSet资源对象。 监控程序； 日志收集程序； 集群存储程序； 12[root@master ~]# kubectl get ds -n kube-system //查看一下DaemonSet 2. DaemonSet 与 Deployment 的区别 Deployment 部署的副本 Pod 会分布在各个 Node 上，每个 Node 都可能运行好几个副本。 DaemonSet 的不同之处在于：每个 Node 上最多只能运行一个副本。 3. 运行一个web服务，在每一个节点运行一个pod。 123456789101112131415[root@master ~]# vim daemonset.yamlkind: DaemonSetapiVersion: extensions/v1beta1metadata: name: test-dsspec: template: metadata: labels: name: test-ds spec: containers: - name: test-ds image: httpd &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f daemonset.yaml &lt;2&gt;查看一下 1[root@master ~]# kubectl get ds 总结 1）总结RC、RS、Deplyment、DaemonSet控制器的特点及使用场景。 &lt;1&gt;Replication Controller（RC） 介绍及使用场景 Replication Controller简称RC，RC是Kubernetes系统中的核心概念之一，简单来说，RC可以保证在任意时间运行Pod的副本数量，能够保证Pod总是可用的。如果实际Pod数量比指定的多那就结束掉多余的，如果实际数量比指定的少就新启动一些Pod，当Pod失败、被删除或者挂掉后，RC都会去自动创建新的Pod来保证副本数量，所以即使只有一个Pod，我们也应该使用RC来管理我们的Pod。 主要功能 确保pod数量：RC用来管理正常运行Pod数量，一个RC可以由一个或多个Pod组成，在RC被创建后，系统会根据定义好的副本数来创建Pod数量。在运行过程中，如果Pod数量小于定义的，就会重启停止的或重新分配Pod，反之则杀死多余的。 确保pod健康：当pod不健康，运行出错或者无法提供服务时，RC也会杀死不健康的pod，重新创建新的。 弹性伸缩 ：在业务高峰或者低峰期的时候，可以通过RC动态的调整pod的数量来提高资源的利用率。同时，配置相应的监控功能（Hroizontal Pod Autoscaler），会定时自动从监控平台获取RC关联pod的整体资源使用情况，做到自动伸缩。 滚动升级：滚动升级为一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定，在初始化升级的时候就可以及时发现和解决问题，避免问题不断扩大。 &lt;2&gt;Replication Set（RS） 被认为 是“升级版”的RC。RS也是用于保证与label selector匹配的pod数量维持在期望状态。 实际上RS和RC的功能基本一致，目前唯一的一个区别就是RC只支持基于等式的selector（env=dev或app=nginx），但RS还支持基于集合的selector（version in (v1, v2)），这对复杂的运维管理就非常方便了。 kubectl命令行工具中关于RC的大部分命令同样适用于我们的RS资源对象。不过我们也很少会去单独使用RS，它主要被Deployment这个更加高层的资源对象使用，除非用户需要自定义升级功能或根本不需要升级Pod，在一般情况下，我们推荐使用Deployment而不直接使用Replica Set。 区别在于 1、RC只支持基于等式的selector（env=dev或environment!=qa），但RS还支持新的，基于集合的selector（version in (v1.0, v2.0)或env notin (dev, qa)），这对复杂的运维管理很方便。 2、升级方式 RS不能使用kubectlrolling-update进行升级 kubectl rolling-update专用于rc RS升级使用deployment或者kubectl replace命令 社区引入这一API的初衷是用于取代vl中的RC，也就是说当v1版本被废弃时，RC就完成了它的历史使命，而由RS来接管其工作 &lt;3&gt;DaemonSet 1. 特点： 如果必须将pod运行在固定的某个或某几个节点，且要优先于其他的pod的启动。通常情况下，默认会将每一个节点都运行，并且只能运行一个pod。这种情况推荐使用DeamonSet资源对象。 一个DaemonSet对象能确保其创建的Pod在集群中的每一台（或指定）Node上都运行一个副本。如果集群中动态加入了新的Node，DaemonSet中的Pod也会被添加在新加入Node上运行。删除一个DaemonSet也会级联删除所有其创建的Pod。 2. 使用环境 监控程序； 日志收集程序； 集群存储程序； &lt;4&gt;Deployment 1. 什么是Deployment Kubernetes Deployment提供了官方的用于更新Pod和Replica Set（下一代的Replication Controller）的方法，您可以在Deployment对象中只描述您所期望的理想状态（预期的运行状态），Deployment控制器为您将现在的实际状态转换成您期望的状态，例如，您想将所有的webapp:v1.0.9升级成webapp:v1.1.0，您只需创建一个Deployment，Kubernetes会按照Deployment自动进行升级。现在，您可以通过Deployment来创建新的资源（pod，rs，rc），替换已经存在的资源等。 你只需要在Deployment中描述你想要的目标状态是什么，Deployment controller就会帮你将Pod和Replica Set的实际状态改变到你的目标状态。你可以定义一个全新的Deployment，也可以创建一个新的替换旧的Deployment。 2. 典型的用例 使用Deployment来创建ReplicaSet。ReplicaSet在后台创建pod。检查启动状态，看它是成功还是失败。 然后，通过更新Deployment的PodTemplateSpec字段来声明Pod的新状态。这会创建一个新的ReplicaSet，Deployment会按照控制的速率将pod从旧的ReplicaSet移动到新的ReplicaSet中。 如果当前状态不稳定，回滚到之前的Deployment revision。每次回滚都会更新Deployment的revision。 扩容Deployment以满足更高的负载。 暂停Deployment来应用PodTemplateSpec的多个修复，然后恢复上线。 根据Deployment 的状态判断上线是否hang住了。 清除旧的不必要的ReplicaSet。 3. 使用环境 Deployment集成了上线部署、滚动升级、创建副本、暂停上线任务，恢复上线任务，回滚到以前某一版本（成功/稳定）的Deployment等功能，在某种程度上，Deployment可以帮我们实现无人值守的上线，大大降低我们的上线过程的复杂沟通、操作风险。 定义Deployment来创建Pod和ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和继续Deployment 3. DaemonSet 与 Deployment 的区别 Deployment 部署的副本 Pod 会分布在各个 Node 上，每个 Node 都可能运行好几个副本。 DaemonSet 的不同之处在于：每个 Node 上最多只能运行一个副本。 2）使用DaemonSet控制器运行httpd服务，要求名称以自己的名称命名。标签为：tier=backend,env=dev. 123456789101112131415[root@master ~]# vim daemonset.yaml kind: DaemonSetapiVersion: extensions/v1beta1metadata: name: xgp-dsspec: template: metadata: labels: tier: backend env: dev spec: containers: - name: xgp-ds image: httpd 查看一下 1[root@master ~]# kubectl get pod --show-labels 1[root@master ~]# kubectl get pod -L env,tier 3) 创建service资源对象与上述资源进行关联，要有验证。 1234567891011121314[root@master ~]# vim service.yaml kind: ServiceapiVersion: v1metadata: name: servicespec: type: NodePort selector: env: dev ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30123 执行一下 1[root@master ~]# kubectl apply -f service.yaml 查看一下 1[root@master ~]# kubectl describe svc 访问一下 1[root@master ~]# curl 127.0.0.1:30123 4）整理关于标签和标签选择器都有什么作用？ &lt;1&gt;标签：解决同类型的资源对象，为了更好的管理，按照标签分组。 &lt;2&gt;标签选择器：标签的查询过滤条件。","path":"posts/5281.html","date":"08-31","excerpt":"","tags":[{"name":"ReplicaSet","slug":"ReplicaSet","permalink":"https://wsdlxgp.top/tags/ReplicaSet/"},{"name":"SetDaemonSet","slug":"SetDaemonSet","permalink":"https://wsdlxgp.top/tags/SetDaemonSet/"},{"name":"labels","slug":"labels","permalink":"https://wsdlxgp.top/tags/labels/"}]},{"title":"pod健康检查详解（liveness，readiness，滚动更新）","text":"环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s+httpd+nginx node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 一、Pod的liveness和readiness探针 Kubelet使用liveness probe（存活探针）来确定何时重启容器。例如，当应用程序处于运行状态但无法做进一步操作，liveness探针将捕获到deadlock，重启处于该状态下的容器，使应用程序在存在bug的情况下依然能够继续运行下去 Kubelet使用readiness probe（就绪探针）来确定容器是否已经就绪可以接受流量。只有当Pod中的容器都处于就绪状态时kubelet才会认定该Pod处于就绪状态。该信号的作用是控制哪些Pod应该作为service的后端。如果Pod处于非就绪状态，那么它们将会被从service的load balancer中移除。 Probe支持以下三种检查方法： &lt;1&gt;exec-命令 在用户容器内执行一次命令，如果命令执行的退出码为0，则认为应用程序正常运行，其他任务应用程序运行不正常。 12345livenessProbe: exec: command: - cat - /home/laizy/test/hostpath/healthy &lt;2&gt;TCPSocket 将会尝试打开一个用户容器的Socket连接（就是IP地址：端口）。如果能够建立这条连接，则认为应用程序正常运行，否则认为应用程序运行不正常。 123livenessProbe:tcpSocket: port: 8080 &lt;3&gt;HTTPGet 调用容器内Web应用的web hook，如果返回的HTTP状态码在200和399之间，则认为应用程序正常运行，否则认为应用程序运行不正常。每进行一次HTTP健康检查都会访问一次指定的URL。 123456httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常 path: / #URI地址 port: 80 #端口号 #host: 127.0.0.1 #主机地址 scheme: HTTP #支持的协议，http或者httpshttpHeaders：’’ #自定义请求的header 参数说明 **initialDelaySeconds：**容器启动后第一次执行探测是需要等待多少秒。 **periodSeconds：**执行探测的频率。默认是10秒，最小1秒。 **timeoutSeconds：**探测超时时间。默认1秒，最小1秒。 **successThreshold：**探测失败后，最少连续探测成功多少次才被认定为成功。默认是1。对于liveness必须是1。最小值是1。 探针探测的结果有以下三者之一： Success：Container通过了检查。 Failure：Container未通过检查。 Unknown：未能执行检查，因此不采取任何措施。 1. LivenessProbe（活跃度） （1）编写一个livenss的yaml文件 1234567891011121314151617181920212223[root@node02 ~]# vim livenss.yamlkind: PodapiVersion: v1metadata: name: liveness labels: test: livenessspec: restartPolicy: OnFailure containers: - name: liveness image: busybox args: - /bin/sh - -c - touch /tmp/test; sleep 60; rm -rf /tmp/test; sleep 300 livenessProbe: #存活探测 exec: #通过执行命令来检查服务是否正常 command: #命令模式 - cat - /tmp/test initialDelaySeconds: 10 #pod运行10秒后开始探测 periodSeconds: 5 #检查的频率，每5秒探测一次 该配置文件给Pod配置了一个容器。periodSeconds 规定kubelet要每隔5秒执行一次liveness probe。initialDelaySeconds 告诉kubelet在第一次执行probe之前要的等待10秒钟。探针检测命令是在容器中执行 cat /tmp/healthy 命令。如果命令执行成功，将返回0，kubelet就会认为该容器是活着的并且很健康。如果返回非0值，kubelet就会杀掉这个容器并重启它。 （2）运行一下 1[root@master ~]# kubectl apply -f liveness.yaml （3）查看一下 1[root@master ~]# kubectl get pod -w Liveness活跃度探测，根据探测某个文件是否存在，来确定某个服务是否正常运行，如果存在则正常，负责，它会根据你设置的Pod的重启策略操作Pod。 2. Readiness（敏感探测、就绪性探测） ReadinessProbe探针的使用场景livenessProbe稍有不同，有的时候应用程序可能暂时无法接受请求，比如Pod已经Running了，但是容器内应用程序尚未启动成功，在这种情况下，如果没有ReadinessProbe，则Kubernetes认为它可以处理请求了，然而此时，我们知道程序还没启动成功是不能接收用户请求的，所以不希望kubernetes把请求调度给它，则使用ReadinessProbe探针。 ReadinessProbe和livenessProbe可以使用相同探测方式，只是对Pod的处置方式不同，ReadinessProbe是将Pod IP:Port从对应的EndPoint列表中删除，而livenessProbe则Kill容器并根据Pod的重启策略来决定作出对应的措施。 ReadinessProbe探针探测容器是否已准备就绪，如果未准备就绪则kubernetes不会将流量转发给此Pod。 ReadinessProbe探针与livenessProbe一样也支持exec、httpGet、TCP的探测方式，配置方式相同，只不过是将livenessProbe字段修改为ReadinessProbe。 （1）编写一个readiness的yaml文件 1234567891011121314151617181920212223[root@master ~]# vim readiness.yaml kind: PodapiVersion: v1metadata: name: readiness labels: test: readinessspec: restartPolicy: Never containers: - name: readiness image: busybox args: - /bin/sh - -c - touch /tmp/test; sleep 60; rm -rf /tmp/test; sleep 300 readinessProbe: exec: command: - cat - /tmp/test initialDelaySeconds: 10 periodSeconds: 5 （2）运行一下 1[root@master ~]# kubectl apply -f readiness.yaml （3）查看一下 1[root@master ~]# kubectl get pod -w 3. 总结liveness和readiness探测 （1）liveness和readiness是两种健康检查机制，k8s将两种探测采取相同的默认行为，即通过判断容器启动进程的返回值是否为零，来判断探测是否成功。 （2）两种探测配置方法完全一样，不同之处在于探测失败后的行为。 liveness探测是根据重启策略操作容器，大多数是重启容器。 readiness则是将容器设置为不可用，不接收Service转发的请求。 （3）两种探测方法可建议独立存在，也可以同时存在。用livensess判断是否需要重启，实现自愈；用readiness判断容器是否已经准备好对外提供服务。 二、 检测的应用 1. 在scale(扩容/缩容) 中的应用。 （1）编写一个readiness的yaml文件 123456789101112131415161718192021222324252627282930313233343536373839[root@master ~]# vim hcscal.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: webspec: replicas: 3 template: metadata: labels: run: web spec: containers: - name: web image: httpd ports: - containerPort: 80 readinessProbe: httpGet: scheme: HTTP #探测的协议 path: /healthy #访问的目录 port: 80 initialDelaySeconds: 10 periodSeconds: 5---kind: ServiceapiVersion: v1metadata: name: web-svcspec: type: NodePort selector: run: web ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30321 在配置文件中，使用httpd镜像，创建出一个Pod，其中periodSeconds字段指定kubelet每5秒执行一次探测，initialDelaySeconds字段告诉kubelet延迟等待10秒，探测方式为向容器中运行的服务发送HTTP GET请求，请求8080端口下的/healthz, 任何大于或等于200且小于400的代码表示成功。任何其他代码表示失败。 httpGet探测方式有如下可选的控制字段 host：要连接的主机名，默认为Pod IP，可以在http request head中设置host头部。 scheme: 用于连接host的协议，默认为HTTP。 path：http服务器上的访问URI。 httpHeaders：自定义HTTP请求headers，HTTP允许重复headers。 port： 容器上要访问端口号或名称。 （2）运行一下 1[root@master ~]# kubectl apply -f readiness.yaml （3）查看一下 1[root@master ~]# kubectl get pod -w 1[root@master ~]# kubectl get pod -o wide 1[root@master ~]# kubectl get service -o wide （4）访问一下 1[root@master ~]# curl 10.244.1.21/healthy （5）pod在指定目录创建一个文件 1[root@master ~]# kubectl exec web-69d659f974-7s9bc touch /usr/local/apache2/htdocs/healthy （6）查看一下 1[root@master ~]# kubectl get pod -w 2. 在更新过程中的使用 （1）编写一个readiness的yaml文件 1234567891011121314151617181920212223242526[root@master ~]# vim app.v1.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: appspec: replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - /bin/sh - -c - sleep 10; touch /tmp/healthy; sleep 3000 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 10 periodSeconds: 5 （2）运行一下并记录版本信息 1[root@master ~]# kubectl apply -f readiness.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment app （3）查看一下 1[root@master ~]# kubectl get pod -w 3.升级一下Deployment （1）编写一个readiness的yaml文件 12345678910111213141516171819202122232425262728[root@master ~]# cp app.v1.yaml app.v2.yaml[root@master ~]# vim app.v2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: appspec: replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - /bin/sh - -c - sleep 3000 #修改命令 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 10 periodSeconds: 5 （2）运行一下并记录版本信息 1[root@master ~]# kubectl apply -f readiness.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment app （3）查看一下 1[root@master ~]# kubectl get pod -w （4）再次升级一下deployment &lt;1&gt; 编写一个readiness的yaml文件 123456789101112131415161718192021[root@master ~]# cp app.v1.yaml app.v3.yaml[root@master ~]# vim app.v2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: appspec: replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - /bin/sh - -c - sleep 3000 #修改命令 &lt;2&gt; 运行一下并记录版本信息 1[root@master ~]# kubectl apply -f readiness.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment app &lt;3&gt; 查看一下 1[root@master ~]# kubectl get pod -w 4. 回滚v2版本 1[root@master ~]# kubectl rollout undo deployment app --to-revision=2 查看一下 1[root@master ~]# kubectl get pod （1）编写一个readiness的yaml文件 123456789101112131415161718192021222324252627282930[root@master ~]# vim app.v2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: appspec: strategy: rollingUpdate: maxSurge: 2 maxUnavailable: 2 replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - /bin/sh - -c - sleep 3000 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 10 periodSeconds: 5 maxSurge：此参数控制滚动更新过程中，副本总数超过预期数的值。可以是整数，也可以是百分比，默认是1。 maxUnavailable：不可用pod的值，默认为1，可以是整数，也可以是百分比。 参数介绍 minReadySeconds: Kubernetes在等待设置的时间后才进行升级 如果没有设置该值，Kubernetes会假设该容器启动起来后就提供服务了 如果没有设置该值，在某些极端情况下可能会造成服务服务正常运行 maxSurge: 升级过程中最多可以比原先设置多出的POD数量 例如：maxSurage=1，replicas=5,则表示Kubernetes会先启动1一个新的Pod后才删掉一个旧的POD，整个升级过程中最多会有5+1个POD。 maxUnavaible: 升级过程中最多有多少个POD处于无法提供服务的状态 当maxSurge不为0时，该值也不能为0 例如：maxUnavaible=1，则表示Kubernetes整个升级过程中最多会有1个POD处于无法服务的状态 （2） 运行一下并记录版本信息 1[root@master ~]# kubectl apply -f app.v2.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment app （3） 查看一下 1[root@master ~]# kubectl get pod -w 三、小实验 1）写一个Deployment资源对象，要求2个副本，nginx镜像。使用Readiness探测，自定义文件/test是否存在，容器开启之后10秒开始探测，时间间隔为10秒。 （1）编写一个readiness的yaml文件 1234567891011121314151617181920212223[root@master yaml]# vim nginx.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: webspec: replicas: 2 template: metadata: labels: run: web spec: containers: - name: readiness image: 192.168.1.21:5000/nginx:v1 readinessProbe: exec: command: - cat - /usr/share/nginx/html/test initialDelaySeconds: 10 periodSeconds: 10 （2）运行一下并记录版本信息 1[root@master ~]# kubectl apply -f nginx.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment web （3）查看一下 1[root@master ~]# kubectl get pod -w 2）在运行之后两个Pod里，进入一个Pod，创建文件/test。 12[root@master yaml]# kubectl exec -it web-864c7cf7fc-gpxq4 /bin/bashroot@web-68444bff8-xm22z:/# touch /usr/share/nginx/html/test 查看一下 1[root@master yaml]# kubectl get pod -w 3）创建一个Service资源对象，跟上述Deployment进行关联，运行之后，查看Service资源详细信息，确认EndPoint负载均衡后端Pod。 （1）编写service的yaml文件 1234567891011121314[root@master yaml]# vim nginx-svc.yamlkind: ServiceapiVersion: v1metadata: name: web-svcspec: type: NodePort selector: run: web ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30321 （2）执行一下 1[root@master yaml]# kubectl apply -f nginx-svc.yaml （3）给两个pod刚更改页面 查看一下pod 1[root@master yaml]# kubectl get pod -o wide 更改页面 1234567[root@master yaml]# kubectl exec -it web-864c7cf7fc-gpxq4 /bin/bashroot@web-864c7cf7fc-gpxq4:/# echo \"123\"&gt;/usr/share/nginx/html/testroot@web-864c7cf7fc-gpxq4:/# exit[root@master yaml]# kubectl exec -it web-864c7cf7fc-pcrs9 /bin/bashroot@web-864c7cf7fc-pcrs9:/# echo \"321\"&gt;/usr/share/nginx/html/testroot@web-864c7cf7fc-pcrs9:/# exit 4）观察状态之后，尝试将另一个Pod也写入/test文件，然后再去查看SVC对应的EndPoint的负载均衡情况。 （1）查看一下service 1[root@master yaml]# kubectl get service （2）访问一下 1[root@master ~]# curl 192.168.1.21:30321/test 5）通过httpGet的探测方式，重新运行一下deployment资源，总结对比一下这两种Readiness探测方式。 （1）修改deployment的yaml文件 12345678910111213141516171819202122[root@master yaml]# vim nginx.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: webspec: replicas: 2 template: metadata: labels: run: web spec: containers: - name: readiness image: 192.168.1.21:5000/nginx:v1 readinessProbe: httpGet: scheme: HTTP path: /usr/share/nginx/html/test port: 80 initialDelaySeconds: 10 periodSeconds: 10 （2）执行一下 1[root@master yaml]# kubectl apply -f nginx.yaml （3）查看一下pod 1[root@master yaml]# kubectl get pod -w maxSurge：此参数控制滚动更新过程中，副本总数超过预期数的值。可以是整数，也可以是百分比，默认是1。所以现在是3台pod （4）访问一下 1[root@master yaml]# curl 192.168.1.21:30321/test 6）总结对比liveness和readiness探测的相同和不同之处，以及它们的使用场景。 &lt;1&gt;readiness和liveness的核心区别 实际上readiness 和liveness 就如同字面意思。readiness 就是意思是否可以访问，liveness就是是否存活。如果一个readiness 为fail 的后果是把这个pod 的所有service 的endpoint里面的改pod ip 删掉，意思就这个pod对应的所有service都不会把请求转到这pod来了。但是如果liveness 检查结果是fail就会直接kill container，当然如果你的restart policy 是always 会重启pod。 &lt;2&gt;什么样才叫readiness／liveness检测失败呢? 实际上k8s提供了3中检测手段， http get 返回200-400算成功，别的算失败 tcp socket 你指定的tcp端口打开，比如能telnet 上 cmd exec 在容器中执行一个命令 推出返回0 算成功。 每中方式都可以定义在readiness 或者liveness 中。比如定义readiness 中http get 就是意思说如果我定义的这个path的http get 请求返回200-400以外的http code 就把我从所有有我的服务里面删了吧，如果定义在liveness里面就是把我kill 了。 &lt;3&gt;readiness和readiness的使用环境 比如如果一个http 服务你想一旦它访问有问题我就想重启容器。那你就定义个liveness 检测手段是http get。反之如果有问题我不想让它重启，只是想把它除名不要让请求到它这里来。就配置readiness。 注意，liveness不会重启pod，pod是否会重启由你的restart policy（重启策略）控制。 参考： https://www.jianshu.com/p/16a375199cf2","path":"posts/af5b.html","date":"08-30","excerpt":"","tags":[{"name":"liveness","slug":"liveness","permalink":"https://wsdlxgp.top/tags/liveness/"},{"name":"readiness","slug":"readiness","permalink":"https://wsdlxgp.top/tags/readiness/"}]},{"title":"k8s中pod的资源对象（名称空间，获取策略，重启策略，健康检查）","text":"一，k8s的资源对象 Deployment、Service、Pod是k8s最核心的3个资源对象 **Deployment：**最常见的无状态应用的控制器，支持应用的扩缩容、滚动升级等操作。 **Service：**为弹性变动且存在生命周期的Pod对象提供了一个固定的访问接口，用于服务发现和服务访问。 **Pod：**是运行容器以及调度的最小单位。同一个pod可以同时运行多个容器，这些容器共享net、UTS、IPC，除此之外还有USER、PID、MOUNT。 **ReplicationController：**用于确保每个Pod副本在任意时刻都能满足目标数量，简单来说，它用于每个容器或容器组总是运行并且可以访问的：老一代无状态的Pod应用控制器。 **RwplicatSet：**新一代的无状态的Pod应用控制器，它与RC的不同之处在于支持的标签选择器不同，RC只支持等值选择器（键值对），RS还额外支持基于集合的选择器。 **StatefulSet：**用于管理有状态的持久化应用，如database服务程序，它与Deployment不同之处在于，它会为每一个pod创建一个独有的持久性标识符，并确保每个pod之间的顺序性。 **DaemonSet：**用于确保每一个节点都运行了某个pod的一个副本，新增的节点一样会被添加到此类pod，在节点移除时，此pod会被回收。 **Job：**用于管理运行完成后即可终止的应用，例如批量处理做作业任务； **volume：**pv pvc ConfigMap： Secret： Role： ClusterRole： RoleBinding： cluster RoleBinding： service account： Helm： Pod的生命周期被定义为以下几个阶段。 Pending：Pod已经被创建，但是一个或者多个容器还未创建，这包括Pod调度阶段，以及容器镜像的下载过程。 Running：Pod已经被调度到Node，所有容器已经创建，并且至少一个容器在运行或者正在重启。 Succeeded：Pod中所有容器正常退出。 Failed：Pod中所有容器退出，至少有一个容器是一次退出的。 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 二，Namespace：名称空间 默认的名称空间： Namespace（命名空间）是kubernetes系统中的另一个重要的概念，通过将系统内部的对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理。 Kubernetes集群在启动后，会创建一个名为“default”的Namespace，如果不特别指明Namespace，则用户创建的Pod、RC、Service都被系统创建到“default”的Namespace中。 1.查看名称空间 1[root@master ~]# kubectl get namespaces 2.查看名称空间详细信息 1[root@master ~]# kubectl describe ns default 3.创建名称空间 1[root@master ~]# kubectl create ns bdqn 查看一下 1[root@master ~]# kubectl get namespaces 4.创建namespace的yaml文件 （1）查看格式 12[root@master ~]# kubectl explain ns//查看nasespace的yaml文件的格式 （2）创建namespace的yaml文件 12345[root@master ~]# vim test-ns.yamlapiVersion: v1kind: Namespacemetadata: name: test （3）运行namespace的yaml文件 1[root@master ~]# kubectl apply -f test-ns.yaml （4）查看一下 1[root@master ~]# kubectl get ns 4.删除名称空间 12[root@master ~]# kubectl delete ns test [root@master ~]# kubectl delete -f test-ns.yaml 注意：namespace资源对象进用于资源对象的隔离，并不能隔绝不同名称空间的Pod之间的通信。那是网络策略资源的功能。 5.查看指定名称空间 可使用–namespace或-n选项 12[root@master ~]# kubectl get pod -n kube-system [root@master ~]# kubectl get pod --namespace kube-system 三，Pod 1.编写一个pod的yaml文件 123456789[root@master ~]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-podspec: containers: - name: test-app image: 192.168.1.21:5000/web:v1 pod的yaml文件不支持replicas字段 （1）运行一下 1[root@master ~]# kubectl apply -f pod.yaml （2）查看一下 1[root@master ~]# kubectl get pod ps：这个pod因为是自己创建的，所以删除之后k8s并不会自动生成，相当于docker中创建 2.指定pod的namespace名称空间 （1）修改pod的yaml文件 12345678910[root@master ~]# vim pod.yamlkind: Pod #资源类型apiVersion: v1 #api版本metadata: name: test-pod #指定控制器名称 namespace: bdqn #指定namespace（名称空间）spec: containers: #容器 - name: test-app #容器名称 image: 192.168.1.21:5000/web:v1 #镜像 执行一下 1[root@master ~]# kubectl apply -f pod.yaml （2）查看一下 12[root@master ~]# kubectl get pod -n bdqn //根据namespace名称查看 3.pod中镜像获取策略 **Always：**镜像标签为“laster”或镜像不存在时，总是从指定的仓库中获取镜像。 **IfNotPresent：**仅当本地镜像不存在时才从目标仓库下载。 **Never：**禁止从仓库中下载镜像，即只使用本地镜像。 注意：对于标签为“laster”或者标签不存在，其默认的镜像下载策略为“Always”，而对于其他的标签镜像，默认策略为“IfNotPresent”。 4.观察pod和service的不同并关联 （1）pod的yaml文件（指定端口） 1234567891011121314[root@master ~]# vim pod.yaml kind: Pod #资源类型apiVersion: v1 #api版本metadata: name: test-pod #指定控制器名称 namespace: bdqn #指定namespace（名称空间）spec: containers: #容器 - name: test-app #容器名称 image: 192.168.1.21:5000/web:v1 #镜像 imagePullPolicy: IfNotPresent #获取的策略 ports: - protocol: TCP containerPort: 80 &lt;1&gt;删除之前的pod 1[root@master ~]# kubectl delete pod -n bdqn test-pod &lt;2&gt;执行一下 1[root@master ~]# kubectl apply -f pod.yaml &lt;3&gt;查看一下 1[root@master ~]# kubectl get pod -n bdqn （2）pod的yaml文件（修改端口） 1234567891011121314[root@master ~]# vim pod.yaml kind: PodapiVersion: v1metadata: name: test-pod namespace: bdqnspec: containers: - name: test-app image: 192.168.1.21:5000/web:v1 imagePullPolicy: IfNotPresent ports: - protocol: TCP containerPort: 90 #改一下端口 &lt;1&gt;删除之前的pod 1[root@master ~]# kubectl delete pod -n bdqn test-pod &lt;2&gt;执行一下 1[root@master ~]# kubectl apply -f pod.yaml &lt;3&gt;查看一下 1[root@master ~]# kubectl get pod -n bdqn -o wide &lt;4&gt;访问一下 会发现修改的90端口并不生效，他只是一个提示字段并不生效。 （3）pod的yaml文件（添加标签） 12345678910111213141516[root@master ~]# vim pod.yaml kind: PodapiVersion: v1metadata: name: test-pod namespace: bdqn labels: #标签 app: test-web #标签名称spec: containers: - name: test-app image: 192.168.1.21:5000/web:v1 imagePullPolicy: IfNotPresent ports: - protocol: TCP containerPort: 90 #改一下端口 --------------------------------------pod--------------------------------------------- （4）编写一个service的yaml文件 123456789101112[root@master ~]# vim test-svc.yaml apiVersion: v1 #api版本kind: Service #资源类型metadata: name: test-svc #指定控制器名称 namespace: bdqn #指定namespace（名称空间）spec: selector: #标签 app: test-web #标签名称（须和pod的标签名称一致） ports: - port: 80 #宿主机端口 targetPort: 80 #容器端口 会发现添加的80端口生效了，所以不能乱改。 &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f test-svc.yaml &lt;2&gt;查看一下 1[root@master ~]# kubectl get svc -n bdqn 1[root@master ~]# kubectl describe svc -n bdqn test-svc &lt;4&gt;访问一下 1[root@master ~]# curl 10.98.57.97 --------------------------------------service--------------------------------------------- 四，容器的重启策略 Pod的重启策略（RestartPolicy）应用与Pod内所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或者健康检查失败时，kubelet将根据RestartPolicy的设置来进行相应的操作。 Always：（默认情况下使用）但凡Pod对象终止就将其重启； **OnFailure：**仅在Pod对象出现错误时才将其重启； **Never：**从不重启； 五，pod的默认健康检查 每个容器启动时都会执行一个进程，此进程由 Dockerfile 的 CMD 或 ENTRYPOINT 指定。如果进程退出时返回码非零，则认为容器发生故障，Kubernetes 就会根据 restartPolicy 重启容器。 （1）编写健康检查的yaml文件 下面我们模拟一个容器发生故障的场景，Pod 配置文件如下： 12345678910111213141516[root@master ~]# vim healcheck.yaml apiVersion: v1kind: Podmetadata: labels: test: healcheck name: healcheckspec: restartPolicy: OnFailure #指定重启策略 containers: - name: healcheck image: busybox:latest args: #生成pod时运行的命令 - /bin/sh - -c - sleep 20; exit 1 &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f healcheck.yaml &lt;2&gt;查看一下 1[root@master ~]# kubectl get pod -o wide 1[root@master ~]# kubectl get pod -w | grep healcheck 在上面的例子中，容器进程返回值非零，Kubernetes 则认为容器发生故障，需要重启。但有不少情况是发生了故障，但进程并不会退出。 六，小实验 1）以自己的名称创建一个k8s名称空间，以下所有操作都在此名称空间中。 （1）创建名称空间 1[root@master ~]# kubectl create ns xgp （2）查看一下 1[root@master ~]# kubectl get ns xgp 2）创建一个Pod资源对象，使用的是私有仓库中私有镜像，其镜像的下载策略为：NEVER。 Pod的重启策略为： Never. 123456789101112131415161718192021[root@master ~]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-pod namespace: xgp labels: app: test-webspec: restartPolicy: Never containers: - name: www image: 192.168.1.21:5000/web:v1 imagePullPolicy: Never args: - /bin/sh - -c - sleep 90; exit 1 ports: - protocol: TCP containerPort: 80 3）创建出容器之后，执行非正常退出，查看Pod的最终状态。 （1）执行一下上面pod的yaml文件 1[root@master ~]# kubectl apply -f pod.yaml （2）动态查看ns中test-pod的信息 1[root@master ~]# kubectl get pod -n xgp -w | grep test-pod 删除test-pod 1[root@master ~]# kubectl delete pod -n xgp test-pod 4) 创建一个Service资源对象，与上述Pod对象关联，验证他们的关联性。 （1）修改pod的yaml文件 1234567891011121314151617[root@master ~]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-pod namespace: xgp labels: app: test-webspec: restartPolicy: Never containers: - name: www image: 192.168.1.21:5000/web:v1 imagePullPolicy: Never ports: - protocol: TCP containerPort: 80 （1）编写service的yaml文件 123456789101112[root@master ~]# vim svc.yaml apiVersion: v1kind: Servicemetadata: name: test-svc namespace: xgpspec: selector: app: test-web ports: - port: 80 targetPort: 80 （2）执行一下 1[root@master ~]# kubectl apply -f svc.yaml （3）查看一下 1[root@master ~]# kubectl get pod -o wide -n xgp （4）访问一下 1[root@master ~]# curl 10.244.1.21","path":"posts/74b2.html","date":"08-29","excerpt":"","tags":[{"name":"Namespace","slug":"Namespace","permalink":"https://wsdlxgp.top/tags/Namespace/"},{"name":"PodRestart","slug":"PodRestart","permalink":"https://wsdlxgp.top/tags/PodRestart/"},{"name":"Policy","slug":"Policy","permalink":"https://wsdlxgp.top/tags/Policy/"}]},{"title":"k8s创建资源(3)（负载均衡原理，回滚指定版本，label控制pod的位置）","text":"Deployment介绍 Deployment是kubernetes 1.2引入的概念，用来解决Pod的编排问题。Deployment可以理解为RC的升级版（RC+Reolicat Set）。特点在于可以随时知道Pod的部署进度，即对Pod的创建、调度、绑定节点、启动容器完整过程的进度展示。 使用场景 创建一个Deployment对象来生成对应的Replica Set并完成Pod副本的创建过程。 检查Deployment的状态来确认部署动作是否完成（Pod副本的数量是否达到预期值）。 更新Deployment以创建新的Pod(例如镜像升级的场景)。 如果当前Deployment不稳定，回退到上一个Deployment版本。 挂起或恢复一个Deployment。 Service介绍 Service定义了一个服务的访问入口地址，前端应用通过这个入口地址访问其背后的一组由Pod副本组成的集群实例，Service与其后端的Pod副本集群之间是通过Label Selector来实现“无缝对接”。RC保证Service的Pod副本实例数目保持预期水平。 外部系统访问Service的问题 IP类型 说明 Node IP Node节点的IP地址 Pod IP Pod的IP地址 Cluster IP Service的IP地址 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 一，Delpoyment和service的简单使用 1.练习写一个yaml文件，要求使用自己的私有镜像，要求副本数量为三个。 123456789101112131415[root@master ~]# vim xgp.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 （1）执行一下 1[root@master ~]# kubectl apply -f xgp.yaml --recore （2）查看一下 1[root@master ~]# kubectl get pod （3）访问一下 1[root@master ~]# curl 10.244.2.16 （4）更新一下yaml文件，副本加一 123456789101112131415[root@master ~]# vim xgp.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 4 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f xgp.yaml --recore &lt;2&gt;查看一下 1[root@master ~]# kubectl get pod 副本数量加一，如果yaml文件的副本为0，则副本数量还是之前的状态，并不会更新。 2.练习写一个service文件 123456789101112[root@master ~]# vim xgp-svc.yamlkind: ServiceapiVersion: v1metadata: name: xgp-svcspec: selector: app: xgp-server ports: - protocol: TCP port: 80 targetPort: 80 （1）执行一下 1[root@master ~]# kubectl apply -f xgp-svc.yaml （2）查看一下 1[root@master ~]# kubectl get svc （3）访问一下 1[root@master ~]# curl 10.107.119.49 3.修改yaml文件 1234567891011121314151617[root@master ~]# vim xgp.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 ports: - containerPort: 80 #提示端口 注意：在Delpoyment资源对象中，可以添加Port字段，但此字段仅供用户查看，并不实际生效 执行一下 1[root@master ~]# kubectl apply -f xgp.yaml --recore 4.service文件映射端口 1234567891011121314[root@master ~]# vim xgp-svc.yaml kind: ServiceapiVersion: v1metadata: name: xgp-svcspec: type: NodePort selector: app: xgp-server ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30123 执行一下 1[root@master ~]# kubectl apply -f xgp-svc.yaml 查看一下 1[root@master ~]# kubectl get svc 访问一下 1[root@master ~]# curl 127.0.0.1:30123 5.修改三个pod页面内容 （1）查看一下pod信息 1[root@master ~]# kubectl get pod -o wide （2）修改POD页面内容（三台不一样） 12[root@master ~]# kubectl exec -it xgp-web-8d5f9656f-8z7d9 /bin/bash//根据pod名称进入pod之中 进入容器后修改页面内容 12root@xgp-web-8d5f9656f-8z7d9:/usr/local/apache2# echo xgp-v1 &gt; htdocs/index.html root@xgp-web-8d5f9656f-8z7d9:/usr/local/apache2# exit 访问一下 1[root@master ~]# curl 127.0.0.1:30123 二.分析一下k8s负载均衡原理 （1）查看service的暴露IP 1[root@master ~]# kubectl get svc （2）查看一下iptabes规则 12[root@master ~]# iptables-save //查看已配置的规则 SNAT：Source NAT（源地址转换） DNAT：Destination NAT（目标地址转换） MASQ：动态的源地址转换 （3）根据service的暴露IP，查看对应的iptabes规则 1[root@master ~]# iptables-save | grep 10.107.119.49 1[root@master ~]# iptables-save | grep KUBE-SVC-ESI7C72YHAUGMG5S （4）对应一下IP是否一致 1[root@master ~]# iptables-save | grep KUBE-SEP-ZHDQ73ZKUBMELLJB 1[root@master ~]# kubectl get pod -o wide Service实现的负载均衡：默认使用的是iptables规则。IPVS 三.回滚到指定版本 （1）删除之前创建的delpoy和service 12[root@master ~]# kubectl delete -f xgp.yaml [root@master ~]# kubectl delete -f xgp-svc.yaml （2）准备三个版本所使用的私有镜像，来模拟每次升级不同的镜像 123456789101112131415161718[root@master ~]# vim xgp1.yaml （三个文件名不相同）kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: revisionHistoryLimit: 10 replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 （三台版本不同） ports: - containerPort: 80 此处3个yaml文件 指定不同版本的镜像 （3）运行三个服务，并记录三个版本信息 123[root@master ~]# kubectl apply -f xgp-1.yaml --record [root@master ~]# kubectl apply -f xgp-2.yaml --record [root@master ~]# kubectl apply -f xgp-3.yaml --record （4）查看有哪些版本信息 1[root@master ~]# kubectl rollout history deployment xgp-web （5）运行之前的service文件 1[root@master ~]# kubectl apply -f xgp-svc.yaml （6）查看service暴露端口 1[root@master ~]# kubectl get svc （7）测试访问 1[root@master ~]# curl 127.0.0.1:30123 （8）回滚到指定版本 12[root@master ~]# kubectl rollout undo deployment xgp-web --to-revision=1//这里指定的是版本信息的编号 &lt;1&gt;访问一下 1[root@master ~]# curl 127.0.0.1:30123 &lt;2&gt;查看有哪些版本信息 1[root@master ~]# kubectl rollout history deployment xgp-web 编号1已经被编号2替代，从而生的是一个新的编号4 四.用label控制pod的位置 默认情况下，scheduler会将pod调度到所有可用的Node，不过有些情况我们希望将 Pod 部署到指定的 Node，比如将有大量磁盘 I/O 的 Pod 部署到配置了 SSD 的 Node；或者 Pod 需要 GPU，需要运行在配置了 GPU 的节点上。 kubernetes通过label来实现这个功能 label 是 key-value 对，各种资源都可以设置 label，灵活添加各种自定义属性。比如执行如下命令标注 k8s-node1 是配置了 SSD 的节点 首先我们给node1节点打上一个ssd的标签 1[root@master ~]# kubectl label nodes node02 disk=ssd （1）查看标签 1[root@master ~]# kubectl get nodes --show-labels | grep node02 （2）删除副本一 123[root@master ~]# kubectl delete -f xgp-1.yaml deployment.extensions \"xgp-web\" deleted[root@master ~]# kubectl delete svc xgp-svc （3）修改副本一的yaml文件 123456789101112131415161718192021[root@master ~]# vim xgp-1.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: revisionHistoryLimit: 10 replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 ports: - containerPort: 80 nodeSelector: #添加节点选择器 disk: ssd #和标签内容一致 （4）执行一下 1[root@master ~]# kubectl apply -f xgp-1.yaml 查看一下 1[root@master ~]# kubectl get pod -o wide 现在pod都在node02上运行 （5）删除标签 1[root@master ~]# kubectl label nodes node02 disk- 查看一下 1[root@master ~]# kubectl get nodes --show-labels | grep node02 没有disk标签了 五，小实验 1）使用私有镜像v1版本部署一个Deployment资源对象，要求副本Pod数量为3个，并创建一个Service资源对象相互关联，指定要求3个副本Pod全部运行在node01节点上，记录一个版本。 （1）用label控制pod的位置 1[root@master ~]# kubectl label nodes node01 disk=ssd （2）编写源yaml文件 12345678910111213141516171819[root@master ~]# vim xgp.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 ports: - containerPort: 80 nodeSelector: disk: ssd （3）编写源service文件 1234567891011121314[root@master ~]# vim xgp-svc.yamlkind: ServiceapiVersion: v1metadata: name: xgp-svcspec: type: NodePort selector: app: xgp-server ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30123 （4）执行yaml文件，创建控制器。执行service文件创建映射端口 12[root@master ~]# kubectl apply -f xgp.yaml [root@master ~]# kubectl apply -f xgp-svc.yaml （5）查看一下pod节点 1[root@master ~]# kubectl get pod -o wide （6）记录一个版本 1[root@master ~]# kubectl rollout history deployment xgp-web &gt; pod.txt （7）访问一下 2）根据上述Deployment，升级为v2版本，记录一个版本。 （1）修改yaml文件镜像版本 12345678910111213141516171819[root@master ~]# vim xgp.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v2 #修改版本为二 ports: - containerPort: 80 nodeSelector: disk: ssd （2）刷新一下yaml文件 1[root@master ~]# kubectl apply -f xgp.yaml --recore （3）访问一下 （4）记录一个版本 1[root@master ~]# kubectl rollout history deployment xgp-web &gt; pod.txt 3）最后升级到v3版本，这时，查看Service关联，并且分析访问流量的负载均衡详细情况。 1）修改yaml文件镜像版本 12345678910111213141516171819[root@master ~]# vim xgp.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v3 #修改版本为二 ports: - containerPort: 80 nodeSelector: disk: ssd （2）刷新一下yaml文件 1[root@master ~]# kubectl apply -f xgp.yaml --recore （3）访问一下 （5）分析访问流量的负载均衡详细情况 &lt;1&gt;查看一下service映射端口 &lt;2&gt;以ip为起点，分析访问流量的负载均衡详细情况 Service实现的负载均衡：默认使用的是iptables规则。IPVS 12[root@master ~]# iptables-save | grep 10.107.27.229//根据service的暴露IP，查看对应的iptabes规则 1[root@master ~]# iptables-save | grep KUBE-SVC-ESI7C72YHAUGMG5S 这里显示了各节点的负载比例 &lt;3&gt;对应一下IP是否一致 1[root@master ~]# iptables-save | grep KUBE-SEP-VDKW5WQIWOLZMJ6G 1[root@master ~]# kubectl get pod -o wide 4）回滚到指定版本v1，并作验证。 &lt;1&gt;回滚到指定版本 12[root@master ~]# kubectl rollout undo deployment xgp-web --to-revision=1//这里指定的是版本信息的编号 &lt;2&gt;访问一下 1[root@master ~]# curl 127.0.0.1:30123 排错思路 123[root@master ~]# less /var/log/messages | grep kubelet[root@master ~]# kubectl logs -n kube-system kube-scheduler-master [root@master ~]# kubectl describe pod xgp-web-7d478f5bb7-bd4bj","path":"posts/c3bf.html","date":"08-28","excerpt":"","tags":[{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"service","slug":"service","permalink":"https://wsdlxgp.top/tags/service/"}]},{"title":"k8s创建资源(2)<基于配置清单>","text":"一，两种创建资源的方法 1. 基于命令的方式： 简单直观快捷，上手快。 适合临时测试或实验。 2. 基于配置清单的方式： 配置文件描述了 What，即应用最终要达到的状态。 配置文件提供了创建资源的模板，能够重复部署。 可以像管理代码一样管理部署。 适合正式的、跨环境的、规模化部署。 这种方式要求熟悉配置文件的语法，有一定难度。 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 二. 配置清单（yam，yaml） 在k8s中，一般使用yaml格式的文件来创建符合我们预期期望的pod，这样的yaml文件我们一般称为资源清单 /etc/kubernetes/manifests/ k8s存放（yam、yaml）文件的地方 kubectl explain deployment（通过explain参数加上资源类别就能看到该资源应该怎么定义） kubectl explain deployment.metadata 通过资源类别加上带有Object标记的字段，我们就可以看到一级字段下二级字段的内容有那些怎么去定义等 kubectl explain deployment.metadata.ownerReferences 通过加上不同级别的字段名称来看下字段下的内容，而且前面的[]号代表对象列表 1.常见yaml文件写法，以及字段的作用 (1) apiVersion：api版本信息 （用来定义当前属于哪个组和那个版本，这个直接关系到最终提供使用的是那个版本） 12[root@master manifests]# kubectl api-versions//查看到当前所有api的版本 (2) kind: 资源对象的类别 (用来定义创建的对象是属于什么类别，是pod，service，还是deployment等对象，可以按照其固定的语法格式来自定义。) (3) metadata: 元数据 名称字段（必写） 提供以下几个字段： creationTimestamp: &quot;2019-06-24T12:18:48Z&quot; generateName: myweb-5b59c8b9d- labels: （对象标签） pod-template-hash: 5b59c8b9d run: myweb name: myweb-5b59c8b9d-gwzz5 （pods对象的名称，同一个类别当中的pod对象名称是唯一的，不能重复） namespace: default （对象所属的名称空间，同一名称空间内可以重复，这个名称空间也是k8s级别的名称空间，不和容器的名称空间混淆） ownerReferences: - apiVersion: apps/v1 blockOwnerDeletion: true controller: true kind: ReplicaSet name: myweb-5b59c8b9d uid: 37f38f64-967a-11e9-8b4b-000c291028e5 resourceVersion: &quot;943&quot; selfLink: /api/v1/namespaces/default/pods/myweb-5b59c8b9d-gwzz5 uid: 37f653a6-967a-11e9-8b4b-000c291028e5 annotations（资源注解，这个需要提前定义，默认是没有的） 通过这些标识定义了每个资源引用的path：即/api/group/version/namespaces/名称空间/资源类别/对象名称 (4) spec： 用户期望的状态 （这个字段最重要，因为spec是用来定义目标状态的‘disired state’，而且资源不通导致spec所嵌套的字段也各不相同，也就因为spec重要且字段不相同，k8s在内部自建了一个spec的说明用于查询） (5) status：资源现在处于什么样的状态 （当前状态，’current state‘，这个字段有k8s集群来生成和维护，不能自定义，属于一个只读字段） 2.编写一个yaml文件 123456789101112131415[root@master ~]# vim web.yamlkind: Deployment #资源对象是控制器apiVersion: extensions/v1beta1 #api的版本metadata: #描述kind（资源类型） name: web #定义控制器名称spec: replicas: 2 #副本数量 template: #模板 metadata: labels: #标签 app: web_server spec: containers: #指定容器 - name: nginx #容器名称 image: nginx #使用的镜像 执行一下 1[root@master ~]# kubectl apply -f web.yaml 查看一下 12[root@master ~]# kubectl get deployments. -o wide//查看控制器信息 12[root@master ~]# kubectl get pod -o wide//查看pod节点信息 3.编写一个service.yaml文件 123456789101112[root@master ~]# vim web-svc.yamlkind: Service #资源对象是副本apiVersion: v1 #api的版本metadata: name: web-svcspec: selector: #标签选择器 app: web-server #须和web.yaml的标签一致 ports: #端口 - protocol: TCP port: 80 #宿主机的端口 targetPort: 80 #容器的端口 使用相同标签和标签选择器内容，使两个资源对象相互关联。 创建的service资源对象，默认的type为ClusterIP，意味着集群内任意节点都可访问。它的作用是为后端真正服务的pod提供一个统一的接口。如果想要外网能够访问服务，应该把type改为NodePort （1）执行一下 1[root@master ~]# kubectl apply -f web-svc.yaml （2）查看一下 12[root@master ~]# kubectl get svc//查看控制器信息 （3）访问一下 1[root@master ~]# curl 10.111.193.168 4.外网能够访问服务 （1）修改web-svc.yaml文件 12345678910111213kind: Service #资源对象是副本apiVersion: v1 #api的版本metadata: name: web-svcspec: type: NodePort #添加 更改网络类型 selector: #标签选择器 app: web_server #须和web.yaml的标签一致 ports: #端口 - protocol: TCP port: 80 #宿主机的端口 targetPort: 80 #容器的端口 nodePort: 30086 #指定群集映射端口，范围是30000-32767 （2）刷新一下 1[root@master ~]# kubectl apply -f web-svc.yaml （3）查看一下 1[root@master ~]# kubectl get svc （4）浏览器测试 三、小实验 基于上一篇博客实验继续进行 1.使用yaml文件的方式创建一个Deployment资源对象，要求镜像使用个人私有镜像v1版本。replicas为3个。 编写yaml文件 123456789101112131415[root@master ~]# vim www.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgpspec: replicas: 3 template: metadata: labels: app: www_server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 （1）执行一下 1[root@master ~]# kubectl apply -f web-svc.yaml （2）查看一下 12[root@master ~]# kubectl get deployments. -o wide//查看控制器信息 12[root@master ~]# kubectl get pod -o wide//查看pod节点信息 （3）访问一下 2. 使用yaml文件的方式创建一个Service资源对象，要与上述Deployment资源对象关联，type类型为： NodePort，端口为:30123. 编写service文件 1234567891011121314[root@master ~]# vim www-svc.yamlkind: ServiceapiVersion: v1metadata: name: www-svcspec: type: NodePort selector: app: www_server ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30123 执行一下 1[root@master ~]# kubectl apply -f www-svc.yaml 查看一下 1[root@master ~]# kubectl get svc 访问一下 四. 总结 1. Pod的作用 在k8s中pod是最小的管理单位，在一个pod中通常会包含一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。 在每一个Pod中都有一个特殊的Pause容器和一个或多个业务容器，Pause来源于pause-amd64镜像,Pause容器在Pod中具有非常重要的作用： Pause容器作为Pod容器的根容器，其本地于业务容器无关，它的状态代表了整个pod的状态。 Pod里的多个业务容器共享Pause容器的IP，每个Pod被分配一个独立的IP地址，Pod中的每个容器共享网络命名空间，包括IP地址和网络端口。Pod内的容器可以使用localhost相互通信。k8s支持底层网络集群内任意两个Pod之间进行通信。 Pod中的所有容器都可以访问共享volumes，允许这些容器共享数据。volumes还用于Pod中的数据持久化，以防其中一个容器需要重新启动而丢失数据。 2. Service的作用 Service 是后端真实服务的抽象，一个 Service 可以代表多个相同的后端服务 Service 为 POD 控制器控制的 POD 集群提供一个固定的访问端点，Service 的工作还依赖于 K8s 中的一个附件，就是 CoreDNS ，它将 Service 地址提供一个域名解析。 NodePort 类型的 service clusterIP：指定 Service 处于 service 网络的哪个 IP，默认为动态分配 NodePort 是在 ClusterIP 类型上增加了一个暴露在了 node 的网络命名空间上的一个 nodePort，所以用户可以从集群外部访问到集群了，因而用户的请求流程是：Client -&gt; NodeIP:NodePort -&gt; ClusterIP:ServicePort -&gt; PodIP:ContainerPort。 可以理解为 NodePort 增强了 ClusterIP 的功能，让客户端可以在每个集群外部访问任意一个 nodeip 从而访问到 clusterIP，再由 clusterIP 进行负载均衡至 POD。 3.流量走向 我们在创建完成一个服务之后，用户首先应该访问的是nginx反向代理的ip，然后通过nginx访问到后端的k8s服务器（master节点）的“NodePort暴露IP 及 映射的端口“，master的apiserver接受到客户端发送来的访问指令，将访问指令通知Controller Manager控制器，Scheduler执行调度任务，将访问指令分发到各节点之上，通过”master节点“的“ip+映射端口”访问到后端k8s节点的信息，节点的Kubelet（pod代理）当Scheduler确定让那个节点返回访问信息之后，kube-proxy将访问信息负载均衡到该节点的容器上，各容器返回信息，并向Master报告运行状态","path":"posts/9569.html","date":"08-27","excerpt":"","tags":[{"name":"service","slug":"service","permalink":"https://wsdlxgp.top/tags/service/"},{"name":"yaml","slug":"yaml","permalink":"https://wsdlxgp.top/tags/yaml/"}]},{"title":"k8s创建资源(1)、<扩容与缩容>和<升级与回滚>","text":"两种创建资源的方法 基于命令的方式： 简单直观快捷，上手快。 适合临时测试或实验。 基于配置文件的方式： 配置文件描述了 What，即应用最终要达到的状态。 配置文件提供了创建资源的模板，能够重复部署。 可以像管理代码一样管理部署。 适合正式的、跨环境的、规模化部署。 这种方式要求熟悉配置文件的语法，有一定难度。 一，用命令行的方式创建资源 主机 IP地址 master 192.168.1.21 node01 192.168.1.22 node02 192.168.1.23 仅接受json格式 配置清单（yml、yaml） 12[root@master ~]# cd /etc/kubernetes/manifests///k8s的yml、yaml文件 1.node01和node02下载nginx镜像 12docker pull nginx//下载nginx镜像 2.master创建Pod控制器（test-web），deployment 12[root@master ~]# kubectl run test-web --image=nginx --replicas=5//创建Pod控制器，deployment 3.查看控制器情况 （1） 12[root@master ~]# kubectl get deployments.//查看控制器情况 12[root@master ~]# kubectl get pod --all-namespaces -o wide//显示pod的节点信息 （2） 12[root@master ~]# kubectl get namespaces //查看k8s名称空间 12[root@master ~]# kubectl describe deployments. test-web//查看资源详细信息 查看某种资源对象，没有指定名称空间，默认是在default名称空间。可以加上-n选项，查看指定名称空间的资源。 1[root@master ~]# kubectl get pod -n kube-system 3.删除test-web控制器 1[root@master ~]# kubectl delete deployments. test-web 4.master创建Pod控制器（web），deployment 1[root@master ~]# kubectl run web --image=nginx --replicas=5 查看一下pod信息 12[root@master ~]# kubectl get pod -o wide//查看一下pod的节点信息 12[root@master ~]# kubectl describe deployments. web //查看资源详细信息 注意：直接运行创建的deployment资源对象，是经常使用的一个控制器资源类型，除了deployment，还有rc、rs等等pod控制器，deployment是一个高级的pod控制器。 本机测试访问nginx 1[root@master ~]# curl 10.244.1.7 5.创建service资源类型 12[root@master ~]# kubectl expose deployment web --name=web-xgp --port=80 --type=NodePort//创建service资源类型，这里我们设置了映射端口 如果想要外网能够访问服务，可以暴露deployment资源，得到service资源，但svc资源的类型必须为NodePort。 映射端口范围：30000-32767 查看service信息 1[root@master ~]# kubectl get svc 浏览器测试访问http://192.168.1.21:30493/ 二、服务的扩容与缩容 1. 查看控制器信息 1[root@master ~]# kubectl get deployments. -o wide 2.扩容 1[root@master ~]# kubectl scale deployment web --replicas=8 查看一下 1[root@master ~]# kubectl get deployments. -o wide 3.缩容 1[root@master ~]# kubectl scale deployment web --replicas=4 查看一下 1[root@master ~]# kubectl get deployments. -o wide 3.通过修改web的yaml文件进行扩容缩容 备份web的yaml文件 1[root@master ~]# kubectl get deployments. -o yaml &gt; web.yaml 使用edit修改web的yaml文件 1[root@master ~]# kubectl edit deployments. web 查看一下 1[root@master ~]# kubectl get deployments. -o wide 三、服务的升级与回滚 node01和node02下载1.15版本的nginx 1[root@master ~]# docker pull nginx:1.15 1.master设置服务升级 1[root@master ~]# kubectl set image deployment web web=nginx:1.15 查看一下 2.master设置服务回滚 （1）修改配置文件回滚 使用edit修改web的yaml文件 1[root@master ~]# kubectl edit deployments. web 查看一下 1[root@master ~]# kubectl get deployments. -o wide （2）命令回滚 1[root@master ~]# kubectl rollout undo deployment web 注意:只能回滚到上一次操作的状态 四、实验环境 主机 IP地址 服务 master 192.168.1.21 registry+Deployment node01 192.168.1.22 node02 192.168.1.23 1.master 基于httpd制作自己的镜像，需要3个版本，v1,v2,v3.并且对应的版本镜像，访问的主目录内容不一样 （1）master下载httpd镜像 1[root@master ~]# docker pull httpd （2）编写Dockerfile 123[root@master xgp]# vim DockerfileFROM httpdCOPY index.html /usr/local/apache2/htdocs/index.html （3）创建测试网页v1 1[root@master xgp]#echo \"&lt;h1&gt;xgp | test-web | httpd:v1&lt;h1&gt;\" &gt; index.html （4）基于Dockerfile创建镜像 web1 1[root@master xgp]# docker build -t web1 . （5）创建测试网页v2 1[root@master xgp]#echo \"&lt;h1&gt;xgp | test-web | httpd:v1&lt;h1&gt;\" &gt; index.html （6）基于Dockerfile创建镜像 web2 1[root@master xgp]# docker build -t web2 . （7）创建测试网页v3 1[root@master xgp]# echo \"&lt;h1&gt;xgp | test-web | httpd:v3&lt;h1&gt;\" &gt; index.html （8）基于Dockerfile创建镜像 web3 1[root@master xgp]# docker build -t web3 . 2.master部署私有仓库 （1）master下载registry镜像 1[root@master ~]# docker pull registry （2）启动registry 1[root@master xgp]# docker run -itd --name registry -p 5000:5000 --restart=always registry:latest （3）修改docker配置文件，加入私有仓库（三台） 12[root@master xgp]# vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.21:5000 （4）重启docker（三台） 12[root@master xgp]# systemctl daemon-reload [root@master xgp]# systemctl restart docker 3.上传之前创建的三个web镜像到私有仓库 （1）修改镜像标签 123[root@master xgp]# docker tag web1:latest 192.168.1.21:5000/web1:latest[root@master xgp]# docker tag web2:latest 192.168.1.21:5000/web2:latest[root@master xgp]# docker tag web3:latest 192.168.1.21:5000/web3:latest （2）将三个web镜像上传到私有仓库 123[root@master xgp]# docker push 192.168.1.21:5000/web1:latest [root@master xgp]# docker push 192.168.1.21:5000/web2:latest[root@master xgp]# docker push 192.168.1.21:5000/web3:latest 4.部署一个Deployment资源对象，要求镜像使用上述私有镜像v1版本。6个副本Pod。 1[root@master xgp]# kubectl run www1 --image=192.168.1.21:5000/web1:latest --replicas=6 查看一下 1[root@master xgp]# kubectl get pod 本地访问一下 5.将上述Deployment暴露一个service资源对象，使外网能否访问服务。 1[root@master xgp]# kubectl expose deployment www1 --name=web-xgp --port=80 --type=NodePort 查看一下 1[root@master xgp]# kubectl get svc 浏览器访问一下 6.将上述Deployment进行扩容和缩容操作，扩容为8个副本Pod，然后缩容为4个副本Pod。 （1）扩容 1[root@master xgp]# kubectl scale deployment www1 --replicas=8 查看一下 1[root@master xgp]# kubectl get deployments. -o wide （2）缩容 修改k8s配置文件 备份web的yaml文件 1[root@master ~]# kubectl get deployments. -o yaml &gt; www1.yaml 使用edit修改web的yaml文件 1[root@master ~]# kubectl edit deployments. www1 查看一下 1[root@master xgp]# kubectl get deployments. -o wide 7.将上述Deployment进行升级与回滚操作，将v1版本，升级到v2版本。 （1）升级版本为web2 1[root@master ~]# kubectl set image deployment www1 www1=192.168.1.21:5000/web2 本机测试访问 12[root@master ~]# curl 127.0.0.1:30996&lt;h1&gt;xgp | test-web | httpd:v2&lt;h1&gt; 浏览器测试访问 （2）回滚版本到web1 &lt;1&gt;修改配置文件回滚 使用edit修改web的yaml文件 1[root@master ~]# kubectl edit deployments. www1 查看一下 1[root@master ~]# kubectl get deployments. -o wide 访问一下 &lt;2&gt;命令回滚 1[root@master ~]# kubectl rollout undo deployment www1 注意:只能回滚到上一次操作的状态 访问一下","path":"posts/dbea.html","date":"08-26","excerpt":"","tags":[{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"registry","slug":"registry","permalink":"https://wsdlxgp.top/tags/registry/"}]},{"title":"k8s架构，基本概念","text":"主机名 IP地址 服务 master 192.168.1.21 node01 192.168.1.22 node02 192.168.1.23 kubernetes架构 在这张系统架构图中，我们把服务分为运行在工作节点上的服务和组成集群级别控制板的服务。 Kubernetes节点有运行应用容器必备的服务，而这些都是受Master的控制。 每次个节点上当然都要运行Docker。Docker来负责所有具体的映像下载和容器运行。 Kubernetes主要由以下几个核心组件组成： kubectl：k8s是命令行端，用来发送客户的操作指令。 master节点 1. API server[资源操作入口]：是k8s集群的前端接口，各种各样客户端工具以及k8s的其他组件可以通过它管理k8s集群的各种资源。它提供了HTTP/HTTPS RESTful API,即K8S API。 提供了资源对象的唯一操作入口，其他所有组件都必须通过它提供的API来操作资源数据，只有API Server与存储通信，其他模块通过API Server访问集群状态。 第一，是为了保证集群状态访问的安全。 第二，是为了隔离集群状态访问的方式和后端存储实现的方式：API Server是状态访问的方式，不会因为后端存储技术etcd的改变而改变。 作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTFul接口方式提供给外部客户和内部组件调用。对相关的资源数据“全量查询”+“变化监听”，实时完成相关的业务功能。 2. Scheduler[集群分发调度器]：负责决定将Pod放在哪个Node上运行。在调度时，会充分考虑集群的拓扑结构，当前各个节点的负载情况，以及应对高可用、性能、数据亲和性和需求。 1.Scheduler收集和分析当前Kubernetes集群中所有Minion节点的资源(内存、CPU)负载情况，然后依此分发新建的Pod到Kubernetes集群中可用的节点。 2.实时监测Kubernetes集群中未分发和已分发的所有运行的Pod。 3.Scheduler也监测Minion节点信息，由于会频繁查找Minion节点，Scheduler会缓存一份最新的信息在本地。 4.最后，Scheduler在分发Pod到指定的Minion节点后，会把Pod相关的信息Binding写回API Server。 4. Controller Manager[内部管理控制中心]：负责管理集群的各种资源，保证资源处于预期的状态。它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等。 实现集群故障检测和恢复的自动化工作，负责执行各种控制器，主要有： 1.endpoint-controller：定期关联service和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的。 2.replication-controller：定期关联replicationController和pod，保证replicationController定义的复制数量与实际运行pod的数量总是一致的。 5. Etcd：负责保存k8s集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速的通知k8s相关组件。（第三方组件）它有可替换方案。Consul、zookeeper 6. Pod: k8s集群的最小组成单位。一个Pod内，可以运行一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。 7. Flanner：是k8s集群网络，可以保证Pod的跨主机通信。也有替换方案。 12[root@master ~]# kubectl get pod --all-namespaces//查看pod信息 12[root@master ~]# kubectl get pod --all-namespaces -o wide//显示pod的节点信息 Node节点 Kubelet[节点上的Pod管家]：它是Node的agent(代理)，当Scheduler确定某 个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet,kubelet会根据这些信息创建和运行容器，并向Master报告运行状态。 负责Node节点上pod的创建、修改、监控、删除等全生命周期的管理 定时上报本Node的状态信息给API Server。 kubelet是Master API Server和Minion之间的桥梁，接收Master API Server分配给它的commands和work，与持久性键值存储etcd、file、server和http进行交互，读取配置信息。 具体的工作如下： 设置容器的环境变量、给容器绑定Volume、给容器绑定Port、根据指定的Pod运行一个单一容器、给指定的Pod创建network 容器。 同步Pod的状态、同步Pod的状态、从cAdvisor获取Container info、 pod info、 root info、 machine info。 在容器中运行命令、杀死容器、删除Pod的所有容器。 **kube-proxy[负载均衡、路由转发]:**负责将访问service的TCP/UDP数据流转发到后端的容器。如果有多个副本，kube-proxy会实现负载均衡。 Proxy是为了解决外部网络能够访问跨机器集群中容器提供的应用服务而设计的，运行在每个Node上。Proxy提供TCP/UDP sockets的proxy，每创建一种Service，Proxy主要从etcd获取Services和Endpoints的配置信息（也可以从file获取），然后根据配置信息在Minion上启动一个Proxy的进程并监听相应的服务端口，当外部请求发生时，Proxy会根据Load Balancer将请求分发到后端正确的容器处理。 Proxy不但解决了同一主宿机相同服务端口冲突的问题，还提供了Service转发服务端口对外提供服务的能力，Proxy后端使用了随机、轮循负载均衡算法。 除了核心组件，还有一些推荐的Add-ons： kube-dns负责为整个集群提供DNS服务 Ingress Controller为服务提供外网入口 Heapster提供资源监控 Dashboard提供GUI Federation提供跨可用区的集群 Fluentd-elasticsearch提供集群日志采集、存储与查询 一. 分层架构 Kubernetes设计理念和功能其实就是一个类似Linux的分层架构，如下图所示。 核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境 应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等） 管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等） 接口层：kubectl命令行工具、客户端SDK以及集群联邦 生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴 Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等 Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等 二. 在K8s中运行一个容器应用 下面通过运行一个容器应用的过程，来一起理解一下K8s组件是如何协作的。 开发者开发一个应用后，打包Docker镜像，上传到Docker registry；然后编写一个yaml部署描述文件，以描述应用的结构和资源需求。开发者通过kubectl（或其它应用），将部署描述文件提交到API server，API server将部署需求更新到etcd。etcd在K8s管理结点中的作用相当于数据库，其它组件提交到API server的数据都存储于etcd。API server非常轻量，并不会直接去创建或管理Pod等资源，在多数场景下甚至不会去主动调用其它的K8s组件发出指令。其它组件通过建立和API server的长连接，监视关心的对象，监视到变化后，执行所负责的操作。 继续我们的启动应用之旅，如图所示，Controller Manager中的控制器监视到新的部署描述后，根据部署描述，创建ReplicaSet、Pod等资源。Scheduler监视到新的Pod资源后，结合集群的资源情况，选定一或多个工作结点运行Pod。工作结点上的Kubelet监视到有Pod被计划在自己的结点后，向Docker等Container runtime发出启动容器的指令，Docker engineer将按照指令从Docker registy拉取镜像，然后启动并运行容器。 三. K8s集群的高可用部署 通过之前的介绍，我们看到K8s可以在多个工作结点上启动并管理容器，下面来学习一下，如何实现管理结点的高可用部署。 上图的K8s高可用部署中有3个管理结点。etcd自身是一个分布式数据存储系统，按照其多实例部署方案，结点只需在启动时知道其它结点的IP和端口号即可组成高可用环境。和通常的应用服务器一样，API Server是无状态的，可以运行任意多个实例，且彼此之间无需互相知道。为了能使kubectl等客户端和Kubelet等组件连接到健康的API Server、减轻单台API Server的压力，需使用基础架构提供的负载均衡器作为多个API Server实例的入口。如上图的部署方法，每个主结点上都运行了一个etcd实例，这样API Server只需连接本地的etcd实例即可，无需再使用负载均衡器作为etcd的入口。 Controller Manager和Scheduler需要修改K8s集群，同时修改时可能引发并发问题。假设两个ReplicaSet Controller同时监视到需创建一个Pod，然后同时进行创建操作，就会创建出两个Pod。K8s为了避免这个问题，一组此类组件的实例将选举出一个leader，仅有leader处于活动状态，其它实例处于待命状态。Controller Manager和Scheduler也可以独立于API server部署，通过负载均衡器连接到多个API server实例。 范例 分析各个组件的作用以及架构工作流程: 1) kubectl发送部署 请求到API server 2) APIserver通知Controller Manager创建一个Deployment资源。 3) Scheduler执行调度任务,将两个副本Pod分发到node01和node02. 上。 4) node01和node02, 上的kubelet在各自节点上创建并运行Pod。 补充 1.应用的配置和当前的状态信息保存在etcd中，执行kubectl get pod时API server会从etcd中读取这些数据。 2.flannel会为每个Pod分配一个IP。 但此时没有创建Service资源，目前kube-proxy还没有参与进来。 运行一个例子（创建一个deployment资源对象&lt;pod控制器&gt;） 12[root@master ~]# kubectl run test-web --image=httpd --replicas=2//创建一个deployment资源对象。 运行完成之后，如果有镜像可直接开启，没有的话需要等待一会儿，node节点要在docker hup上下载 查看一下 1[root@master ~]# kubectl get deployments.或 kubectl get deploy 1[root@master ~]# kubectl get pod 12[root@master ~]# kubectl get pod -o wide//显示pod的节点信息 如果，node节点没有运行test-web服务，需要在节点上重启一下 如果删除一个pod 1[root@master ~]# kubectl delete pod test-web-5b56bdff65-2njqf 查看一下 1[root@master ~]# kubectl get pod -o wide 现在发现容器还存在，因为控制器会自动发现，一旦与之前执行的命令有误差，他会自动补全。 https://blog.csdn.net/gongxsh00/article/details/79932136 https://www.jianshu.com/p/18edac81c718","path":"posts/e863.html","date":"08-25","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"},{"name":"kubeadml","slug":"kubeadml","permalink":"https://wsdlxgp.top/tags/kubeadml/"}]},{"title":"部署k8s集群","text":"一. Kubernetes 系统简介 首先，他是一个全新的基于容器技术的分布式架构领先方案。Kubernetes(k8s)是Google开源的容器集群管理系统（内部:Borg）。在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。 Kubernetes是一个完备的分布式系统支撑平台，具有完备的集群管理能力，多扩多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。同时Kubernetes提供完善的管理工具，涵盖了包括开发、部署测试、运维监控在内的各个环节。 Kubernetes中，Service是分布式集群架构的核心，一个Service对象拥有如下关键特征： 拥有一个唯一指定的名字 拥有一个虚拟IP（Cluster IP、Service IP、或VIP）和端口号 能够体统某种远程服务能力 被映射到了提供这种服务能力的一组容器应用上 Service的服务进程目前都是基于Socket通信方式对外提供服务，比如Redis、Memcache、MySQL、Web Server，或者是实现了某个具体业务的一个特定的TCP Server进程，虽然一个Service通常由多个相关的服务进程来提供服务，每个服务进程都有一个独立的Endpoint（IP+Port）访问点，但Kubernetes能够让我们通过服务连接到指定的Service上。有了Kubernetes内奸的透明负载均衡和故障恢复机制，不管后端有多少服务进程，也不管某个服务进程是否会由于发生故障而重新部署到其他机器，都不会影响我们队服务的正常调用，更重要的是这个Service本身一旦创建就不会发生变化，意味着在Kubernetes集群中，我们不用为了服务的IP地址的变化问题而头疼了。 容器提供了强大的隔离功能，所有有必要把为Service提供服务的这组进程放入容器中进行隔离。为此，Kubernetes设计了Pod对象，将每个服务进程包装到相对应的Pod中，使其成为Pod中运行的一个容器。为了建立Service与Pod间的关联管理，Kubernetes给每个Pod贴上一个标签Label，比如运行MySQL的Pod贴上name=mysql标签，给运行PHP的Pod贴上name=php标签，然后给相应的Service定义标签选择器Label Selector，这样就能巧妙的解决了Service于Pod的关联问题。 在集群管理方面，Kubernetes将集群中的机器划分为一个Master节点和一群工作节点Node，其中，在Master节点运行着集群管理相关的一组进程kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和纠错等管理能力，并且都是全自动完成的。Node作为集群中的工作节点，运行真正的应用程序，在Node上Kubernetes管理的最小运行单元是Pod。Node上运行着Kubernetes的kubelet、kube-proxy服务进程，这些服务进程负责Pod的创建、启动、监控、重启、销毁以及实现软件模式的负载均衡器。 在Kubernetes集群中，它解决了传统IT系统中服务扩容和升级的两大难题。你只需为需要扩容的Service关联的Pod创建一个Replication Controller简称（RC），则该Service的扩容及后续的升级等问题将迎刃而解。在一个RC定义文件中包括以下3个关键信息。 目标Pod的定义 目标Pod需要运行的副本数量（Replicas） 要监控的目标Pod标签（Label） 在创建好RC后，Kubernetes会通过RC中定义的的Label筛选出对应Pod实例并实时监控其状态和数量，如果实例数量少于定义的副本数量，则会根据RC中定义的Pod模板来创建一个新的Pod，然后将新Pod调度到合适的Node上启动运行，知道Pod实例的数量达到预定目标，这个过程完全是自动化。 1. Kubernetes优势: - 容器编排 - 轻量级 - 开源 - 弹性伸缩 - 负载均衡 2. Kubernetes 特性 Endpoint Slices Kubernetes 集群中网络端点的可扩展跟踪。 服务发现与负载均衡 无需修改您的应用程序即可使用陌生的服务发现机制。Kubernetes 为容器提供了自己的 IP 地址和一个 DNS 名称，并且可以在它们之间实现负载平衡。 自我修复 重新启动失败的容器，在节点死亡时替换并重新调度容器，杀死不响应用户定义的健康检查的容器，并且在它们准备好服务之前不会它们公布给客户端。 自动装箱 根据资源需求和其他约束自动放置容器，同时不会牺牲可用性，将任务关键工作负载和尽力服务工作负载进行混合放置，以提高资源利用率并节省更多资源。 IPv4/IPv6 双协议栈 Allocation of IPv4 and IPv6 addresses to Pods and Services 水平伸缩 使用一个简单的命令、一个UI或基于CPU使用情况自动对应用程序进行伸缩。 3. Kubernetes的Master和Node节点 1.Master k8s集群的管理节点，负责管理集群，提供集群的资源数据访问入口。拥有Etcd存储服务（可选），运行Api Server进程，Controller Manager服务进程及Scheduler服务进程，关联工作节点Node。Kubernetes API server提供HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口。也是集群控制的入口进程；Kubernetes Controller Manager是Kubernetes所有资源对象的自动化控制中心；Kubernetes Schedule是负责资源调度（Pod调度）的进程 2.Node Node是Kubernetes集群架构中运行Pod的服务节点（亦叫agent或minion）。Node是Kubernetes集群操作的单元，用来承载被分配Pod的运行，是Pod运行的宿主机。关联Master管理节点，拥有名称和IP、系统资源信息。运行docker eninge服务，守护进程kunelet及负载均衡器kube-proxy. 每个Node节点都运行着以下一组关键进程 kubelet：负责对Pod对于的容器的创建、启停等任务 kube-proxy：实现Kubernetes Service的通信与负载均衡机制的重要组件 Docker Engine（Docker）：Docker引擎，负责本机容器的创建和管理工作 Node节点可以在运行期间动态增加到Kubernetes集群中，默认情况下，kubelet会想master注册自己，这也是Kubernetes推荐的Node管理方式，kubelet进程会定时向Master汇报自身情报，如操作系统、Docker版本、CPU和内存，以及有哪些Pod在运行等等，这样Master可以获知每个Node节点的资源使用情况，冰实现高效均衡的资源调度策略。 4. Kubernetes Node运行节点，运行管理业务容器，包含如下组件: （1）Kubelet 负责管控容器，Kubelet会从Kubernetes API Server接收Pod的创建请求，启动和停止容器，监控容器运行状态并汇报给Kubernetes API Server。 （2）Kubernetes Proxy 负责为Pod创建代理服务，Kubernetes Proxy会从Kubernetes API Server获取所有的Service信息，并根据Service的信息创建代理服务，实现Service到Pod的请求路由和转发，从而实现Kubernetes层级的虚拟转发网络。 （3）Docker Node上需要运行容器服务 k8s最基本的硬件要求 CPU: 双核 Mem: 2G 3台dockerhost 时间必须同步 实验环境 主机名 IP地址 服务 master 192.168.1.21 dockerhost node01 192.168.1.22 dockerhost node02 192.168.1.23 dockerhost 环境准备 分别将3台虚拟机命名，设置好对应IP，并将其写入域名解析/etc/hosts中，关闭防火墙，iptables，禁用selinux。还有要做到，时间必须一致。全部禁用swap 1.给三台docker命名 k8.1 12[root@localhost ~]# hostnamectl set-hostname master[root@localhost ~]# su - k8.2 12[root@localhost ~]# hostnamectl set-hostname node01[root@localhost ~]# su - k8.3 12[root@localhost ~]# hostnamectl set-hostname node02[root@localhost ~]# su - 验证docker是否能使用及版本是否一样 1[root@master ~]# docker -v 2.关闭防火墙及禁用selinux 123[root@master ~]# systemctl stop firewalld[root@master ~]# systemctl disable firewalld [root@master ~]# vim /etc/selinux/config 3. 禁用swap（三台） 1234[root@master ~]# swapoff -a//临时禁用swap[root@master ~]# free -h[root@master ~]# vim /etc/fstab 4.添加域名解析（三台） 123[root@master ~]# echo 192.168.1.21 master &gt;&gt; /etc/hosts[root@master ~]# echo 192.168.1.22 node01 &gt;&gt; /etc/hosts[root@master ~]# echo 192.168.1.23 node02 &gt;&gt; /etc/hosts 5.做免密登陆（三台） 12[root@master ~]# ssh-keygen -t rsa//生成密钥 复制密钥到其他主机 1254 ssh-copy-id node0155 ssh-copy-id node02 把域名解析复制到其他主机 1263 scp /etc/hosts node01:/etc64 scp /etc/hosts node02:/etc 6.打开路由转发和iptables桥接功能（三台） 1234567891011[root@master ~]# vim /etc/sysctl.d/k8s.conf//开启iptables桥接功能net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1[root@master ~]# echo net.ipv4.ip_forward = 1 &gt;&gt; /etc/sysctl.conf //**打开路由转发[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf [root@master ~]# sysctl -p //刷新一下 如果以上命令执行失败可能是缺少模块，可执行以下命令 1[root@master ~]# modprobe br_netfiler 把路由转发和iptables桥接复制到其他主机 1234[root@master ~]# scp /etc/sysctl.d/k8s.conf node01:/etc/sysctl.d/[root@master ~]# scp /etc/sysctl.d/k8s.conf node02:/etc/sysctl.d/[root@master ~]# scp /etc/sysctl.conf node02:/etc/[root@master ~]# scp /etc/sysctl.conf node01:/etc/ 记得node01和node02也要执行以下命令 12[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf [root@master ~]# sysctl -p master节点安装部署k8s 指定yum安装kubernetes的yum源（三台） 123456789cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 下载完成之后，查看一下仓库是否可用 1[root@master ~]# yum repolist 创建本地缓存（三台） 1[root@master ~]# yum makecache fast 各节点安装所需安装包 master下载 1[root@master ~]# yum -y install kubeadm-1.15.0-0 kubelet-1.15.0-0 kubectl-1.15.0-0 node01和node02下载 1[root@node01 ~]# yum -y install kubeadm-1.15.0-0 kubelet-1.15.0-0 三台主机把 kubelet加入开机自启 1[root@master ~]# systemctl enable kubelet master导入，之前准备好的镜像 123[root@master ~]# mkdir images[root@master ~]# cd images/[root@master images]# ls 创建一个导入镜像的脚本 12345678[root@master images]# cat &gt; image.sh &lt;&lt;EOF&gt; #!/bin/bash&gt; for i in /root/images/*&gt; do&gt; docker load &lt; $i &gt; done&gt; EOF[root@master images]# chmod +x image.sh 导入镜像 1[root@master images]# sh image.sh 初始化Kubernetes集群 1[root@master ~]# kubeadm init --kubernetes-version=v1.15.0 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap 如果以上的命令报错，找出问题后先重置一下（下面的命令），然后再执行以上命令 12[root@master ~]# kubeadm reset//重置kubeadm 12[root@master images]# kubectl get node//查看当前节点信息 可以看出master的状态是未就绪（NotReady），之所以是这种状态是因为还缺少一个附件flannel，没有网络各Pod是无法通信的 也可以通过检查组件的健康状态 1[root@master images]# kubectl get cs 添加网络组件（flannel） 组件flannel可以通过https://github.com/coreos/flannel中获取 1[root@master ~]# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 以上只是方式之一，在网络状况良好的情况下建议使用上述方法（调用远端文件执行一下），若网速较差，建议使用以下方法： 12345[root@master images]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml#将github官网指定的.yml配置文件下载到本地[root@master images]# ls | grep flannel.yml #确定下载到了当前目录kube-flannel.yml[root@master images]# kubectl apply -f kube-flannel.yml #指定下载的.yml文件执行相应命令 上述方法，二选一进行配置即可。 看到很多东西被创建是还不够的，还需要查看flannel是否处于正常启动并运行的状态，才算正在的部署完成 12[root@master images]# kubectl get pods --all-namespaces//查看所有的名称空间的pod（可以看到flannel网络运行正常） 12[root@master images]# kubectl get pod -n kube-system//查看名称空间为kube-system的pod 查看当前节点信息 12kubectl get node//查看当前节点信息（已经准备好了） node两台节点，导入镜像并加入群集 导入镜像 上传所需镜像包，也可以使用docker pull下载 123[root@node01 images]# docker load &lt; kube-proxy-1-15.tar &amp;&amp; docker load -i myflannel-11-0.tar &amp;&amp; docker load -i pause-3-1.tar[root@node01 images]# docker images//查看本地镜像 node01和node02加入群集 这时使用的命令是初始化群集之后生成的令牌（只有24小时的时效） 1[root@node01 ~]# kubeadm join 192.168.1.21:6443 --token z0vknh.s6ib4eu4f8bre2nu --discovery-token-ca-cert-hash sha256:8da72cc83f45d1247f42ce888658129b43726fe2af4ffc0c4e79faedb4050359 加入群集之后查看一下 1[root@master images]# kubectl get node 各节点优化一下 设置table键的默认间距； 123[root@master ~]# vim .vimrcset tabstop=2[root@master ~]# source .vimrc 设置kubectl命令自动补全 1234[root@master ~]# yum -y install bash-completion[root@master ~]# source /usr/share/bash-completion/bash_completion [root@master ~]# source &lt;(kubectl completion bash)[root@master ~]# echo \"source &lt;(kubectl completion bash)\" &gt;&gt; ~/.bashrc 确认k8s群集没有问题，并设置为开机自启 master主机操作如下： 123[root@master ~]# kubectl get pod -n kube-system #查看pod资源，类似于docker中的容器，确保返回的信息都是running#“-n kube-system”：是k8s的名称空间 master和node节点上都需要进行以下操作，以便设置为开机自启： 12[root@master ~]# systemctl enable kubelet[root@master ~]# systemctl enable docker 设置为开机自启后，k8s群集的配置基本完成了，现在可以重启一下这三台服务器，如果重启后，执行下面的命令，状态都还是running，则表示绝对没有问题了。 1[root@master ~]# kubectl get pod -n kube-system #重启后验证状态是否还都是running","path":"posts/6489.html","date":"08-24","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"},{"name":"kubeadml","slug":"kubeadml","permalink":"https://wsdlxgp.top/tags/kubeadml/"}]},{"title":"Docker swarm搭建（2）","text":"什么是docker swarm? Swarm 在 Docker 1.12 版本之前属于一个独立的项目，在 Docker 1.12 版本发布之后，该项目合并到了 Docker 中，成为 Docker 的一个子命令。目前，Swarm 是 Docker 社区提供的唯一一个原生支持 Docker 集群管理的工具。它可以把多个 Docker 主机组成的系统转换为单一的虚拟 Docker 主机，使得容器可以组成跨主机的子网网络。 Docker Swarm 是一个为 IT 运维团队提供集群和调度能力的编排工具。用户可以把集群中所有 Docker Engine 整合进一个「虚拟 Engine」的资源池，通过执行命令与单一的主 Swarm 进行沟通，而不必分别和每个 Docker Engine 沟通。在灵活的调度策略下，IT 团队可以更好地管理可用的主机资源，保证应用容器的高效运行。 Swarm的基本架构如下图所示: Docker Swarm 优点 任何规模都有高性能表现 对于企业级的 Docker Engine 集群和容器调度而言，可拓展性是关键。任何规模的公司——不论是拥有五个还是上千个服务器——都能在其环境下有效使用 Swarm。 经过测试，Swarm 可拓展性的极限是在 1000 个节点上运行 50000 个部署容器，每个容器的启动时间为亚秒级，同时性能无减损。 灵活的容器调度 Swarm 帮助 IT 运维团队在有限条件下将性能表现和资源利用最优化。Swarm 的内置调度器（scheduler）支持多种过滤器，包括：节点标签，亲和性和多种容器部策略如 binpack、spread、random 等等。 服务的持续可用性 Docker Swarm 由 Swarm Manager 提供高可用性，通过创建多个 Swarm master 节点和制定主 master 节点宕机时的备选策略。如果一个 master 节点宕机，那么一个 slave 节点就会被升格为 master 节点，直到原来的 master 节点恢复正常。 此外，如果某个节点无法加入集群，Swarm 会继续尝试加入，并提供错误警报和日志。在节点出错时，Swarm 现在可以尝试把容器重新调度到正常的节点上去。 和 Docker API 及整合支持的兼容性 Swarm 对 Docker API 完全支持，这意味着它能为使用不同 Docker 工具（如 Docker CLI，Compose，Trusted Registry，Hub 和 UCP）的用户提供无缝衔接的使用体验。 Docker Swarm 为 Docker 化应用的核心功能（诸如多主机网络和存储卷管理）提供原生支持 开发的 Compose 文件能（通过 docker-compose up ）轻易地部署到测试服务器或 Swarm 集群上。Docker Swarm 还可以从 Docker Trusted Registry 或 Hub 里 pull 并 run 镜像。 一. 实验环境 主机 IP地址 服务 docker01 192.168.1.11 swarm+service+webUI+registry docker02 192.168.1.13 docker docker03 192.168.1.20 docker 三台主机都关闭防火墙，禁用selinux，修改主机名，时间同步，并添加域名解析。 docker版本必须是：v1.12版本开始（可使用docker version查看版本） 1.关闭防火墙，禁用selinux 123[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# hostnamectl set-hostname docker03[root@localhost ~]# su - 2.时间同步 12mv /etc/localtime /etc/localtime.bkcp /usr/share/zoneinfo/Asia/Shanghai/etc/localtime 3.修改主机名（三台都要） 12[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su - 4.添加域名解析 123[root@docker01 ~]# echo 192.168.1.11 docker01 &gt;&gt; /etc/hosts[root@docker01 ~]# echo 192.168.1.13 docker02 &gt;&gt; /etc/hosts[root@docker01 ~]# echo 192.168.1.20 docker03 &gt;&gt; /etc/hosts 二. docker01 初始化集群 1[root@docker01 ~]# docker swarm init --advertise-addr 192.168.1.11 **–advertise-addr：**指定与其它docker通信的地址。 上边返回的结果告诉我们：初始化成功，并且，如果想要添加work节点运行下面的命令： 注意：token令牌只有24小时的有效期 如果想要添加manager节点：运行下面命令 三，docker02和docker03以worker加入集群 1[root@docker03 ~]# docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-1e60wt0yr5583e4mzwbxnn3a8 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 注意：这里的”*****“代表的是当前所属的节点 四.设置manager node（docker01）不参加工作 1[root@docker01 ~]# docker node update docker01 --availability drain 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 “–availability”选项后面共有三个选项可配置，如下： “active”：工作；“pause”：暂时不工作；“drain”：永久性的不工作 1[root@docker01 ~]# docker node ls 五. docker01部署一个图形化webUI界面 1.docker01 导入镜像 1[root@docker01~]# docker pull dockersamples/visualizer 2.基于镜像启动一台容器 1[root@docker01 ~]# docker run -d -p 8080:8080 -e HOST=192.168.1.100 -e PORT=8080 -v /var/run/docker.sock:/var/run/docker.sock --name visualiaer dockersamples/visualizer 3.通过浏览器访问验证http://192.168.1.11:8080/ 如果访问不到网页，需开启路由转发 12[root@docker01 ~]# echo net.ipv4.ip_forward = 1 &gt;&gt; /etc/sysctl.conf [root@docker01 ~]# sysctl -p 六. Docker01部署一个私有仓库 Docker01部署 123456789101112131415161772 docker pull registry//下载registry镜像73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest//基于registry镜像，启动一台容器78 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker76 docker tag busybox:latest 192.168.1.11:5000/busybox:v1 //把容器重命名一个标签77 docker ps 1234567891078 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker100 docker push 192.168.1.11:5000/busybox:v1//上传容器到私有仓库 Docker02和docker03加入私有仓库 12345678978 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker99 docker pull 192.168.1.11/busybox:v1//测试下载 七. 自定义镜像 要求：基于httpd镜像，更改访问界面内容。镜像tag版本为v1，v2，v3，对应主机面内容为v1，xgp666、v2，xgp666、v2，xgp666 12[root@docker01 ~]# docker pull httpd//下载httpd镜像 创建三个测试目录 12[root@docker01 ~]# mkdir &#123;v1,v2,v3&#125;//创建测试目录 docker01，v1目录操作 1234567891011121314[root@docker01 ~]# cd v1[root@docker01 v1]# echo v1,xgp666 &gt; index.html//创建测试网页[root@docker01 v1]# vim Dockerfile//编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v1]# docker build -t 192.168.1.11:5000/httpd:v1 .//基于dockerfile创建镜像[root@docker01 v1]# docker push 192.168.1.11:5000/httpd:v1//上传刚刚创建镜像到私有仓库 docker01，v2目录操作 12345678910111213[root@docker01 v1]# cd ../v2[root@docker01 v2]# echo v2,xgp666 &gt; index.html[root@docker01 v2]# vim Dockerfile //编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v2]# docker build -t 192.168.1.11:5000/httpd:v2 .//基于dockerfile创建镜像[root@docker01 v2]# docker push 192.168.1.11:5000/httpd:v2//上传刚刚创建镜像到私有仓库 docker01，v3目录操作 12345678910111213[root@docker01 v1]# cd ../v3[root@docker01 v2]# echo v3,xgp666 &gt; index.html[root@docker01 v2]# vim Dockerfile //编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v2]# docker build -t 192.168.1.11:5000/httpd:v3 .//基于dockerfile创建镜像[root@docker01 v2]# docker push 192.168.1.11:5000/httpd:v3//上传刚刚创建镜像到私有仓库 八. 发布一个服务，基于上述镜像 要求:副本数量为3个。服务的名称为: bdqn 1[root@docker01 v3]# docker service create --replicas 3 --name bdqn -p 80:80 192.168.1.11:5000/httpd:v1 查看一下网络 1[root@docker03 ~]# docker network ls 默认的Ingress网络，包括创建的自定义overlay网络, 为后端真正为用户提供服务的container,提供了一个统一的入口。 service 通过 ingress load balancing 来发布服务，且 swarm 集群中所有 node 都参与到 ingress 路由网格（ingress routing mesh） 中，访问任意一个 node+PublishedPort 即可访问到服务。 当访问任何节点上的端口80时，Docker将您的请求路由到活动容器。在群节点本身，端口80可能并不实际绑定，但路由网格知道如何路由流量，并防止任何端口冲突的发生。 路由网格在发布的端口上监听分配给节点的任何IP地址。对于外部可路由的IP地址，该端口可从主机外部获得。对于所有其他IP地址，只能从主机内部访问。 查看一下创建的副本 1[root@docker01 v3]# docker service ps bdqn 浏览器测试访问http://192.168.1.11:80,http://192.168.1.13:80,http://192.168.1.20:80 修改docker02和docker03测试网页内容 docker02 123[root@docker02 ~]# docker exec -it 388f3bd9dd33 /bin/bashroot@388f3bd9dd33:/usr/local/apache2# cd htdocs/root@388f3bd9dd33:/usr/local/apache2/htdocs# echo 123 &gt; index.html docker03 12[root@docker03 ~]# docker exec -it 281454867fac /bin/bashroot@281454867fac:/usr/local/apache2# echo 321 &gt; htdocs/index.html 测试访问（每一台都会显示，会负载均衡） 要求:副本数量为3个。服务的名称为:test 1[root@docker01 v3]# docker service create --replicas 3 --name test -p 80 192.168.1.11:5000/httpd:v1 查看创建的服务映射端口 1[root@docker01 v3]# docker service ls 默认映射端口30000-32767 九. 服务的扩容与缩容 扩容 1[root@docker01 v3]# docker service scale bdqn=6 缩容 1[root@docker01 v3]# docker service scale bdqn=4 扩容与缩容直接直接通过scale进行设置副本数量。 十.服务的升级与回滚 （1）升级 docker service upadte 命令参数详解 –force 强制更新重启服务，无论是否配置或镜像改变都更新 –image image:tag 制定更新的镜像 –with-registry-auth 向 Swarm 代理发送 Registry 认证详细信息，私有仓库需要携带该参数 12[root@docker01 ~]# docker service update --image 192.168.1.11:5000/httpd:v2 bdqn//把bdqn服务升级成v2的版本 测试访问一下 （2）平滑的更新 12[root@docker01 ~]# docker service update --image 192.168.1.11:5000/httpd:v3 --update-parallelism 2 --update-delay 1m bdqn //两个服务一起更新，然后，隔一分钟，继续更新 默认情况下, swarm-次只更新-个副本,并且两个副本之间没有等待时间，我们可以通过 –update-parallelism;设置并行更新的副本数量。 –update-delay：指定滚动更新的时间间隔。 测试访问一下 (3) 回滚操作 1[root@docker01 ~]# docker service rollback bdqn 注意，docker swarm的回滚操作，默认只能回滚到上一-次操作的状态，并不能连续回滚到指定操作。 测试访问一下 十一，注意： 如果一台机器启用多个服务注意，合理分配cpu与内存资源，因tomcat在启动编译时会很吃内存，且docker是多线程启动的，所有最好是限定一下（设置resources.limits）否者会导致内存在同一时刻用光，某些服务启动失败当然也可是设置出错重启（restart_policy.condition:on-failure），另外设置resources.reservations要注意，不要超出总内存或cpu百分比，否者会导致后面服务无法获取cpu或内存资源出现“no suitable node (insufficien”错误（这个错误很奇怪，某个service不启动，也不输出日志，使用“docker stack ps [xxxx]”查看状态会显示此错误）无法启动","path":"posts/420e.html","date":"08-23","excerpt":"","tags":[{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"},{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"},{"name":"webUI","slug":"webUI","permalink":"https://wsdlxgp.top/tags/webUI/"}]},{"title":"Docker swarm搭建（1）","text":"Docker swarm docker swarm集群：三剑客之一 一. 实验环境 主机 IP地址 服务 docker01 192.168.1.11 swarm+overlay+webUI docker02 192.168.1.13 docker docker03 192.168.1.20 docker 三台主机都关闭防火墙，禁用selinux，修改主机名，时间同步，并添加域名解析。 docker版本必须是：v1.12版本开始（可使用docker version查看版本） 1.关闭防火墙，禁用selinux 123[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# hostnamectl set-hostname docker03[root@localhost ~]# su - 2.时间同步 12mv /etc/localtime /etc/localtime.bkcp /usr/share/zoneinfo/Asia/Shanghai/etc/localtime 3.修改主机名（三台都要） 12[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su - 4.添加域名解析 1234567[root@docker01 ~]# vim /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.1.11 docker01192.168.1.13 docker02192.168.1.20 docker03 二. swarm原理 **swarm：**作用运行docker engin的多个主机组成的集群 **node：**每一个docker engin都是一个node（节点），分为manager和worker。 **manager node：**负责执行容器的编排和集群的管理工作，保持并维护swarm处于期望的状态。swarm可以有多个manager node，他们会自动协调并选举一个leader执行编排任务。但相反，不能没有manager node。 **worker node：**接受并执行由manager node派发的任务，并且默认manager node也是一个worker node，不过可以将它设置为manager-only node，让他只负责编排和管理工作。 **service：**用来定义worker上执行的命令。 基本命令操作 **docker swarm leave：**申请离开一个集群，之后查看节点状态会变成down，然后可通过manager node 将其删除 **docker node rm xxx：**删除某个节点 docker swarm join-token [manager|worker]：生成令牌，可以是manager或worker身份。 docker node demote（降级）：将swarm节点的为manager降级为worker docker node promote（升级）：将swarm节点的work升级为manager **docker node ls:**查看群集的信息（只可以在manager角色的主机上查看） docker service scale web05=6:容器的动态扩容及缩容 docker service ps web01: 查看创建的容器运行在哪些节点 docker service ls: 查看创建的服务 docker swarm leave: 脱离这个群集 docker node rm docker03: 在manager角色的服务器上移除docker03 docker node update --availability drain docker01: 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 docker node update --label-add mem=max docker03: 更改docker03主机的标签为mem=max docker service update --replicas 8 --image 192.168.20.6:5000/lvjianzhao:v2.0 --container-label-add ‘node.labels.mem==max’ lvjianzhao05: 将服务升级为8个容器，并且指定在mem=max标签的主机上运行 三. docker01 初始化集群 1[root@docker01 ~]# docker swarm init --advertise-addr 192.168.1.11 **–advertise-addr：**指定与其它docker通信的地址。 上边返回的结果告诉我们：初始化成功，并且，如果想要添加work节点运行下面的命令： 注意：token令牌只有24小时的有效期 如果想要添加manager节点：运行下面命令 四.swarm集群的简单操作 1.docker02和docker03以worker加入集群 1[root@docker03 ~]# docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-1e60wt0yr5583e4mzwbxnn3a8 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 注意：这里的”*****“代表的是当前所属的节点 2.删除集群中节点 docker02和docker03申请离开一个集群 1[root@docker02 ~]# docker swarm leave docker删除docker02和docker03节点 12[root@docker01 ~]# docker node rm docker02 [root@docker01 ~]# docker node rm docker03 docker01查看集群 1[root@docker01 ~]# docker node ls 3.docker02和docker03以manager加入集群 docker01生成manager令牌 1[root@docker01 ~]# docker swarm join-token manager docker02和docker03加入集群 1docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-cz6hbyv9r5htyqwj5tfol65aa 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 4.docker02和docker03降级 docker01（manager）把docker02和docker03降级成worker 12[root@docker01 ~]# docker node demote docker02[root@docker01 ~]# docker node demote docker03 查看集群 1[root@docker01 ~]# docker node ls 五.部署docker swarm集群网络 overlay:覆盖型网络 overlay networks 管理Swarm中docker守护进程间的通信。可以将容器附加到一个或多个已存在的overlay网络上，使容器与容器之间能够通信； 12[root@docker01 ~]# docker network create -d overlay --attachable docker//attachable：这个参数必须要加，否则不能用于容器。 在创建网络的时候，我们并没有部署一个存储服务，比如consul，那是因为docker swarm自带存储。 docker01查看网络 但是会发现其他两台并不会发现此网络，需等基于此网络创建service服务就可以看到了 1[root@docker01 ~]# docker network ls 六. docker01部署一个图形化webUI界面 1.docker01 导入镜像 1[root@docker01~]# docker pull dockersamples/visualizer 2.基于镜像启动一台容器 1[root@docker01 ~]# docker run -d -p 8080:8080 -e HOST=192.168.1.100 -e PORT=8080 -v /var/run/docker.sock:/var/run/docker.sock --name visualiaer dockersamples/visualizer 3.通过浏览器访问验证http://192.168.1.11:8080/ 如果访问不到网页，需开启路由转发 12[root@docker01 ~]# echo net.ipv4.ip_forward = 1 &gt;&gt; /etc/sysctl.conf [root@docker01 ~]# sysctl -p 七. 创建service（服务） 1. 基于nginx容器创建一个service服务 1234[root@docker01 ~]#docker pull nginx//下载nginx镜像（三台都要）[root@docker01 ~]# docker service create --replicas 1 --network docker --name web1 -p 80:80 nginx:latest [root@docker01 ~]# docker service create --replicas 1 --network docker --name web2 -p 80 nginx:latest //–replicas：副本数量 大概可以理解为一个副本等于一个容器 2. 查看创建的service服务 1[root@docker01 ~]# docker service ls 单独查看一个servicefuw 1[root@docker01 ~]# docker service ps web1 1[root@docker01 ~]# docker service ps web2 3. web界面查看 4. 基于nginx容器创建五个service服务 1[root@docker01 ~]# docker service create --replicas 5 --network docker --name web -p 80 nginx:latest web界面查看 5. 挂起docker02 web查看（发现服务都分配到其他服务器了） 6. 恢复docker02 web查看（发现服务没有回到docker02） 八、实现docker容器的扩容及缩容 1. 删除web1和web2服务 1[root@docker01 ~]# docker service rm web1 web2 2. 容器的扩容和缩减 （1）扩容 1[root@docker01 ~]# docker service scale web=8 （2）缩减 1[root@docker01 ~]# docker service scale web=3 3.设置manager node不参加工作 1[root@docker01 ~]# docker node update docker01 --availability drain 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 “–availability”选项后面共有三个选项可配置，如下： “active”：工作；“pause”：暂时不工作；“drain”：永久性的不工作 1[root@docker01 ~]# docker node ls web界面查看 九、docker Swarm总结 在我对docker Swarm群集进行一定了解后，得出的结论如下： 参与群集的主机名一定不能冲突，并且可以互相解析对方的主机名； 集群内的所有节点可以都是manager角色，但是不可以都是worker角色； 当指定运行的镜像时，如果群集中的节点本地没有该镜像，那么它将会自动下载对应的镜像； 当群集正常工作时，若一个运行着容器的docker服务器发生宕机，那么，其所运行的所有容器，都将转移到其他正常运行的节点之上，而且，就算发生宕机的服务器恢复正常运行，也不会再接管之前运行的容器；","path":"posts/60e.html","date":"08-22","excerpt":"","tags":[{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"},{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"},{"name":"webUI","slug":"webUI","permalink":"https://wsdlxgp.top/tags/webUI/"}]},{"title":"docker swarm版本回滚","text":"Docker swarm docker swarm集群：三剑客之一 一. Docker Swarm 的基本概念和原理 Docker Swarm 简介 Swarm是Docker公司推出的用来管理docker集群，它将一群Docker宿主机变成一个单一的，虚拟的主机。Swarm使用标准的Docker API接口作为其前端访问入口，换言之，各种形式的Docker Client(docker client in Go, docker_py, docker等)均可以直接与Swarm通信。Swarm几乎全部用go语言来完成开发，Swarm0.2发布，相比0.1版本，0.2版本增加了一个新的策略来调度集群中的容器，使得在可用的节点上传播它们，以及支持更多的Docker命令以及集群驱动。 Swarm deamon只是一个调度器（Scheduler）加路由器(router)，Swarm自己不运行容器，它只是接受docker客户端发送过来的请求，调度适合的节点来运行容器，这意味着，即使Swarm由于某些原因挂掉了，集群中的节点也会照常运行，当Swarm重新恢复运行之后，它会收集重建集群信息． Docker Swarm 工作原理 Docker 客户端通过 Docker API 向 Swarm 管理端发送请求，Swarm Manager 通过守护进程调用集群中的某个节点来执行任务。因为容器都是运行在节点上，Swarm 作为一个独立的集群管理工具，故并不会因某些原因导致不能正常工作而影响集群内所有节点的正常运行。当服务恢复正常后，Swarm 会读取日志来执行集群的恢复动作。架构图如图 1： 图 1.Docker Swarm 架构图 二. Docker Swarm要点 **Swarm的负载非常低。**据我观察，Swarm进行调度和通信的CPU负载非常低。因此，Swarm的管理节点(Manager)可以同时作为工作节点(Worker)。如果你需要搭建一个非常大的集群(1000+ 节点)，管理节点需要更多资源，但是对于中小型集群来说，管理节点需要的资源可以忽略不计。 **Swarm集群的网络通信(服务发现，负载均衡以及容器间通信)非常可靠。**当你开启一个服务的端口之后，在Swarm集群中的任何一个节点都可以访问它。负载均衡也是由Swarm提供的。后文会提到一些之前遇到的问题，但是Docker 1.13之后，这些问题都解决了。 三. 实验环境 主机 IP地址 服务 docker01 192.168.1.11 swarm+service+webUI+registry docker02 192.168.1.13 docker docker03 192.168.1.20 docker 三台主机都关闭防火墙，禁用selinux，修改主机名，时间同步，并添加域名解析。 docker版本必须是：v1.12版本开始（可使用docker version查看版本） 1.关闭防火墙，禁用selinux 123[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# hostnamectl set-hostname docker03[root@localhost ~]# su - 2.时间同步 12mv /etc/localtime /etc/localtime.bkcp /usr/share/zoneinfo/Asia/Shanghai/etc/localtime 3.修改主机名（三台都要） 12[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su - 4.添加域名解析 123[root@docker01 ~]# echo 192.168.1.11 docker01 &gt;&gt; /etc/hosts[root@docker01 ~]# echo 192.168.1.13 docker02 &gt;&gt; /etc/hosts[root@docker01 ~]# echo 192.168.1.20 docker03 &gt;&gt; /etc/hosts 四. swarm原理 **swarm：**作用运行docker engin的多个主机组成的集群 **node：**每一个docker engin都是一个node（节点），分为manager和worker。 **manager node：**负责执行容器的编排和集群的管理工作，保持并维护swarm处于期望的状态。swarm可以有多个manager node，他们会自动协调并选举一个leader执行编排任务。但相反，不能没有manager node。 **worker node：**接受并执行由manager node派发的任务，并且默认manager node也是一个worker node，不过可以将它设置为manager-only node，让他只负责编排和管理工作。 **service：**用来定义worker上执行的命令。 基本命令操作 **docker swarm leave：**申请离开一个集群，之后查看节点状态会变成down，然后可通过manager node 将其删除 **docker node rm xxx：**删除某个节点 docker swarm join-token [manager|worker]：生成令牌，可以是manager或worker身份。 docker node demote（降级）：将swarm节点的为manager降级为worker docker node promote（升级）：将swarm节点的work升级为manager **docker node ls:**查看群集的信息（只可以在manager角色的主机上查看） docker service scale web05=6:容器的动态扩容及缩容 docker service ps web01: 查看创建的容器运行在哪些节点 docker service ls: 查看创建的服务 docker swarm leave: 脱离这个群集 docker node rm docker03: 在manager角色的服务器上移除docker03 docker node update --availability drain docker01: 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 docker node update --label-add mem=max docker03: 更改docker03主机的标签为mem=max docker service update --replicas 8 --image 192.168.20.6:5000/lvjianzhao:v2.0 --container-label-add ‘node.labels.mem==max’ lvjianzhao05: 将服务升级为8个容器，并且指定在mem=max标签的主机上运行 五. docker01 初始化集群 1[root@docker01 ~]# docker swarm init --advertise-addr 192.168.1.11 **–advertise-addr：**指定与其它docker通信的地址。 上边返回的结果告诉我们：初始化成功，并且，如果想要添加work节点运行下面的命令： 注意：token令牌只有24小时的有效期 上面命令执行后，该机器自动加入到swarm集群。这个会创建一个集群token，获取全球唯一的 token，作为集群唯一标识。后续将其他节点加入集群都会用到这个token值。 其中，–advertise-addr参数表示其它swarm中的worker节点使用此ip地址与manager联系。命令的输出包含了其它节点如何加入集群的命令。 如果想要添加manager节点：运行下面命令 六.swarm集群的简单操作 1、docker02和docker03以worker加入集群 1[root@docker03 ~]# docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-1e60wt0yr5583e4mzwbxnn3a8 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 注意：这里的”*****“代表的是当前所属的节点 2.删除集群中节点 docker02和docker03申请离开一个集群 1[root@docker02 ~]# docker swarm leave docker删除docker02和docker03节点 12[root@docker01 ~]# docker node rm docker02 [root@docker01 ~]# docker node rm docker03 docker01查看集群 1[root@docker01 ~]# docker node ls 3.docker02和docker03以manager加入集群 docker01生成manager令牌 1[root@docker01 ~]# docker swarm join-token manager docker02和docker03加入集群 1docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-cz6hbyv9r5htyqwj5tfol65aa 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 4.docker02和docker03降级 docker01（manager）把docker02和docker03降级成worker 12[root@docker01 ~]# docker node demote docker02[root@docker01 ~]# docker node demote docker03 查看集群 1[root@docker01 ~]# docker node ls 五.设置manager node（docker01）不参加工作 1[root@docker01 ~]# docker node update docker01 --availability drain 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 “–availability”选项后面共有三个选项可配置，如下： “active”：工作；“pause”：暂时不工作；“drain”：永久性的不工作 1[root@docker01 ~]# docker node ls 八. docker01部署一个图形化webUI界面 1.docker01 导入镜像 1[root@docker01~]# docker pull dockersamples/visualizer 2.基于镜像启动一台容器 1[root@docker01 ~]# docker run -d -p 8080:8080 -e HOST=192.168.1.100 -e PORT=8080 -v /var/run/docker.sock:/var/run/docker.sock --name visualiaer dockersamples/visualizer 3.通过浏览器访问验证http://192.168.1.11:8080/ 如果访问不到网页，需开启路由转发 12[root@docker01 ~]# echo net.ipv4.ip_forward = 1 &gt;&gt; /etc/sysctl.conf [root@docker01 ~]# sysctl -p 一. Docker01部署一个私有仓库 Docker01部署 123456789101112131415161772 docker pull registry//下载registry镜像73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest//基于registry镜像，启动一台容器78 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker76 docker tag busybox:latest 192.168.1.11:5000/busybox:v1 //把容器重命名一个标签77 docker ps 1234567891078 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker100 docker push 192.168.1.11:5000/busybox:v1//上传容器到私有仓库 Docker02和docker03加入私有仓库 12345678978 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker99 docker pull 192.168.1.11/busybox:v1//测试下载 2. 自定义镜像 要求：基于httpd镜像，更改访问界面内容。镜像tag版本为v1，v2，v3，对应主机面内容为v1，xgp666、v2，xgp666、v2，xgp666 12[root@docker01 ~]# docker pull httpd//下载httpd镜像 创建三个测试目录 12[root@docker01 ~]# mkdir &#123;v1,v2,v3&#125;//创建测试目录 docker01，v1目录操作 1234567891011121314[root@docker01 ~]# cd v1[root@docker01 v1]# echo v1,xgp666 &gt; index.html//创建测试网页[root@docker01 v1]# vim Dockerfile//编写DockerfileFROM httpdADD index.html /c[root@docker01 v1]# docker build -t 192.168.1.11:5000/httpd:v1 .//基于dockerfile创建镜像[root@docker01 v1]# docker push 192.168.1.11:5000/httpd:v1//上传刚刚创建镜像到私有仓库 docker01，v2目录操作 12345678910111213[root@docker01 v1]# cd ../v2[root@docker01 v2]# echo v2,xgp666 &gt; index.html[root@docker01 v2]# vim Dockerfile //编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v2]# docker build -t 192.168.1.11:5000/httpd:v2 .//基于dockerfile创建镜像[root@docker01 v2]# docker push 192.168.1.11:5000/httpd:v2//上传刚刚创建镜像到私有仓库 docker01，v3目录操作 12345678910111213[root@docker01 v1]# cd ../v3[root@docker01 v2]# echo v3,xgp666 &gt; index.html[root@docker01 v2]# vim Dockerfile //编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v2]# docker build -t 192.168.1.11:5000/httpd:v3 .//基于dockerfile创建镜像[root@docker01 v2]# docker push 192.168.1.11:5000/httpd:v3//上传刚刚创建镜像到私有仓库 3. 发布一个服务，基于上述镜像 要求:副本数量为3个。服务的名称为: bdqn 1[root@docker01 v3]# docker service create --replicas 3 --name bdqn -p 80:80 192.168.1.11:5000/httpd:v1 查看一下网络 1[root@docker03 ~]# docker network ls 默认的Ingress网络，包括创建的自定义overlay网络, 为后端真正为用户提供服务的container,提供了一个统一的入口。 查看一下创建的副本 1[root@docker01 v3]# docker service ps bdqn 浏览器测试访问http://192.168.1.11:80,http://192.168.1.13:80,http://192.168.1.20:80 修改docker02和docker03测试网页内容 docker02 123[root@docker02 ~]# docker exec -it 388f3bd9dd33 /bin/bashroot@388f3bd9dd33:/usr/local/apache2# cd htdocs/root@388f3bd9dd33:/usr/local/apache2/htdocs# echo 123 &gt; index.html docker03 12[root@docker03 ~]# docker exec -it 281454867fac /bin/bashroot@281454867fac:/usr/local/apache2# echo 321 &gt; htdocs/index.html 测试访问（每一台都会显示，会负载均衡） 要求:副本数量为3个。服务的名称为:test 1[root@docker01 v3]# docker service create --replicas 3 --name test -p 80 192.168.1.11:5000/httpd:v1 查看创建的服务映射端口 1[root@docker01 v3]# docker service ls 默认映射端口30000-32767 4. 服务的扩容与缩容 扩容 1[root@docker01 v3]# docker service scale bdqn=6 缩容 1[root@docker01 v3]# docker service scale bdqn=4 扩容与缩容直接直接通过scale进行设置副本数量。 5.服务的升级与回滚 （1）升级 12[root@docker01 ~]# docker service update --image 192.168.1.11:5000/httpd:v2 bdqn//把bdqn服务升级成v2的版本 测试访问一下 （2）平滑的更新 12[root@docker01 ~]# docker service update --image 192.168.1.11:5000/httpd:v3 --update-parallelism 2 --update-delay 1m bdqn //两个服务一起更新，然后，隔一分钟，继续更新 默认情况下, swarm-次只更新-个副本,并且两个副本之间没有等待时间，我们可以通过 –update-parallelism;设置并行更新的副本数量。 –update-delay：指定滚动更新的时间间隔。 测试访问一下 (3) 回滚操作 1[root@docker01 ~]# docker service rollback bdqn 注意，docker swarm的回滚操作，默认只能回滚到上一-次操作的状态，并不能连续回滚到指定操作。 测试访问一下","path":"posts/4890.html","date":"08-21","excerpt":"","tags":[{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"},{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"},{"name":"webUI","slug":"webUI","permalink":"https://wsdlxgp.top/tags/webUI/"}]},{"title":"Docker+Consul+registrator实现服务发现及nginx反向代理","text":"更改时间 12mv /etc/localtime/etc/localtime. bkcp /usr/share/zoneinfo/Asia/Shanghai/etc/localtime 查看端口 1[root@docker01 consul]# ss -lnt Consul:分布式、高可用的，服务发现和配置服务的工具。数据中心 Rigistrator:负责收集dockerhost_上,容器服务的信息，并且发送给consul Consul-tpmplate:根据编辑好的模板，生产新的nginx配置文件，并负责重新加载nginx配置文件 一. 架构设计 在现实中，我们一直渴望着追求提供高质量、高可用的服务架构体系，同时减少不必要的部署和维护代价，减少容错率。面对如此高的要求，可以有两种架构方案： Docker+Etcd+Confd+Nginx Docker+Consul+Nginx 本文中我们主要来介绍 Docker+Etcd+Confd+Nginx方案，此方案更加高效、快捷，并且维护代价和容错率更低，分布式支持力度更强，如下图所示： 上面示意图的大概流程如下： 1、docker01主机上以二进制包的方式部署consul服务并后台运行，其身份为leader； 2、docker02、docker03以容器的方式运行consul服务，并加入到docker01的consul群集中； 3、在主机docker02、docker03上后台运行registrator容器，使其自动发现docker容器提供的服务； 4、在docker01上部署Nginx，提供反向代理服务，docker02、docker03主机上基于Nginx镜像，各运行两个web容器，提供不同的网页文件，以便测试效果； 5、在docker01上安装consul-template命令，将收集到的信息（registrator收集到容器的信息）写入template模板中，并且最终写入Nginx的配置文件中。 6、至此，实现客户端通过访问Nginx反向代理服务器（docker01），获得docker02、docker03服务器上运行的Nginx容器提供的网页文件。 注：registrator是一个自动发现docker container提供的服务，并且在后端服务注册中心（数据中心）注册服务。主要用来收集容器运行服务的信息，并且发送给consul。数据中心除了consul外，还有etcd、zookeeper等。 二. 架构优势 Docker+Consul+Nginx虽然看起来是三个组件的运用，但却证明是一个有机的整体。它们互相联系、互相作用，完全满足我们对高可用、高效服务架构方案的需求，是Docker生态圈中最理想的组合之一，具有以下优势： 1.发现与注册组件consul使用 Raft 算法来保证一致性，比复杂的Paxos 算法更直接。相比较而言，zookeeper 采用的是 Paxos，而 etcd 使用的则是 Raft； 2.多数据中心，多数据中心集群可以避免单数据中心的单点故障，zookeeper 和 etcd 均不提供多数据中心功能的支持； 3.、实时发现及无感知服务刷新，具备资源弹性，伸缩自如； 4.健康检查，负载能动态在可用的服务实例上进行均衡，etcd 不提供此功能； 5.足够多台Docker容器(前提架构资源足以保证性能支撑)； 6.http 和dns 协议接口，zookeeper 的集成较为复杂，etcd 只支持 http 协议； 7.规模方便进行快速调整，官方提供web管理界面，etcd 无此功能； 8.nsul template 搭配consul使用，支持多种接入层，如Nginx、Haproxy。 三. 实验环境 主机 iP地址 服务 docker01 192.168.1.11 consul+consul-template+nginx docker02 192.168.1.13 consul+registrator docker03 192.168.1.20 consul+registrator 三台主机关闭防火墙，禁用selinux，更改主机名如上所述。 四. 部署consul服务 （1）docker01去官网https://www.consul.io/downloads.html下载consul服务 123456[root@docker01 ~]# unzip consul_1.5.1_linux_amd64.zip //现在是本地导入压缩包，需要解压 [root@docker01 ~]# mv consul /usr/local/bin///移动服务到bin目录[root@docker01 ~]# chmod +x /usr/local/bin/consul//给予一个可执行权限 （2）启动consul 1[root@docker01 ~]# consul agent -server -bootstrap -ui -data-dir=/var/lib/consul-data -bind=192.168.1.11 -client=0.0.0.0 -node=master PS: //-bootstrap: 加入这个选项时，一般都在server单节点的时候用，自选举为leader。 参数解释： -server：添加一个服务 -bootstrap：一般在server单节点的时候使用，自选举为leader。 -data-dir：key/volume指定数据存放的目录 -ui：开启内部的web界面 -bind：指定开启服务的ip -client：指定访问的客户端 -node：在集群内部通信使用的名称，默认是主机名。 现在这个ip是外部使用 PS:开启的端口 8300 集群节点 8301 集群内部的访问 8302 跨数据中心的通信 8500 web ui界面 8600 使用dns协议查看节点信息的端口 可参考下图查看端口的意思： 这时，这条命令会占用终端，可以使用nohup命令让它保持后台运行。 1[root@docker01 ~]# nohup consul agent -server -bootstrap -ui -data-dir=/var/lib/consule-data -bind=192.168.1.11 -client=0.0.0.0 -node=master &amp; （3）查看consul端口的信息 1[root@docker01 ~]# consul info （4）查看consul集群成员的信息 1[root@docker01 ~]# consul members 现在这个ip是内部使用 五. docker01下载部署consul-template 在 https://github.com/hashicorp/consul-template 上，下载consul-template 123456[root@docker01 ~]# unzip consul-template_0.19.5_linux_amd64.zip//解压安装好的consul-template包[root@docker01 ~]# mv consul-template /usr/local/bin///移动到命令目录[root@docker01 ~]# chmod +x /usr/local/bin/consul-template //给予一个可执行权限 六和七步骤简要说明 在docker01和docker02上操作 先来说一下在docker服务器上操作的大概思路： 分别在两台docker服务器上都创建registrator容器，注意到consul服务中心； 在docker01上运行两台nginx容器（端口随机生成），在docker02上运行两台nginx容器（端口随机生成）； 修改这4台nginx容器中的index.html页面内容为（xgp-web01、xgp-web02、xgp-web03、xgp-web04） 访问consul web界面验证 访问nginx服务器地址 http://192.168.1.11:8000 进行验证； 六. docker02，docker03，加入consul集群 这里我们采用容器的方式去运行consul服务。 （1）下载consu所需的l镜像 1[root@docker02 ~]# docker pull consul （2）基于consul镜像开启一台容器 1[root@docker02 ~]# docker run -d --name consul -p 8301:8301 -p 8301:8301/udp -p 8500:8500 -p 8600:8600 -p 8600:8600/udp --restart always progrium/consul -join 192.168.1.11 -advertise 192.168.1.13 -client 0.0.0.0 -node=node01 参数解释： -d：守护进程 –name：容器名称 –restart：容器随着docker服务一直运行 -advertise:声明本机地址 -join:声明服务端地址 -node:consul集群中的名称 （3）docker查看consul集群成员的信息 1[root@docker01 ~]# consul members （4）两台docker开启容器后，docker01查看 （5）浏览器访问http://192.168.1.11:8500 七. docker02、docker03 上部署registrator服务 registrator是一个能自动发现docker container提供的服务,并在后端服务注册中心注册服务或取消服务的工具，后端注册中心支持conusl、etcd、 skydns2、zookeeper等。 （1）下载registrator镜像 12[root@docker02 ~]# docker pull registrator//下载registrator镜像 （2）基于registrator镜像，开启一台容器 1[root@docker02 ~]# docker run -d --name registrator -v /var/run/docker.sock:/tmp/docker.sock --restart always gliderlabs/registrator consul://192.168.1.13:8500 参数说明： –network：把运行的docker容器设定为host网络模式； -v /var/run/docker.sock：把宿主机的Docker守护进程(Docker daemon)默认监听的Unix域套接字挂载到容器中； –ip : 刚才把network指定了host模式，所以我们指定下IP为宿主机的IP； consul:j最后这个选项是配置consul服务器的IP和端口。 （3）开启一台nginx容器 1[root@docker02 ~]# docker run -d —P --name nginx nginx:latest （4）浏览器查看一下http://192.168.1.11:8500/ui/dc1/nodes 八.docker01部署一个nginx服务 配置nginx，大概配置的思路为： 在/usr/local/nginx/conf中创建目录consul，目录名自定义； 在consul目录中创建nginx.ctmpl模板； 在nginx.conf配置中添加include项并指向consul目录 ； 重启nginx服务； （1）安装开启nginx服务 安装nginx依赖包 1[root@docker01 ~]# yum -y install pcre pcre-devel openssl openssl-devel zlib zlib-devel 编译安装nginx 12[root@docker01 ~]# cd nginx-1.14.0/[root@docker01 nginx-1.14.0]# ./configure --user=nginx --group=nginx --with-http_stub_status_module --with-http_realip_module --with-pcre --with-http_ssl_module &amp;&amp; make &amp;&amp; make install 创建所需用户和链接命令目录 12[root@docker01 nginx-1.14.0]# useradd -M -s /sbin/nologin nginx[root@docker01 nginx-1.14.0]# ln -s /usr/local/nginx/sbin/* /usr/local/bin/ 检查nginx是否有问题，并开启nginx 1234[root@docker01 nginx-1.14.0]# nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@docker01 nginx-1.14.0]# nginx PS:这里nginx作为反向代理，代理后端docker02、 docker03 上nginx的容器服务,所以我们先去docker02、docker03. 上部署一些服务， 为了方便等会看到负载的效果，所以，我们运行完成容器之后，做一个主界面内容的区分。 （2）安装完成之后，本机测试访问 1[root@docker01 nginx-1.14.0]# curl 127.0.0.1 （3）docker02和docker03部署环境 主机 服务 docker02 nginx web01，web02 docker03 nginx web03，web04 &lt;1&gt;下载nginx镜像（docker02，docker03都要） 12[root@docker02 ~]# docker pull nginx//下载nginx镜像 &lt;2&gt;docker01操作 基于nginx镜像运行上述所说的容器并设置测试页面 1234567891011web01[root@docker02 ~]# docker run -itd --name web01 -P nginx:latest[root@docker02 ~]# docker exec -it web01 /bin/bashroot@44b59d07202f:/# cd /usr/share/nginx/html/root@44b59d07202f:/usr/share/nginx/html# echo web01 &gt; index.htmlweb02[root@docker02 ~]# docker run -itd --name web02 -P nginx:latest[root@docker02 ~]# docker exec -it web02 /bin/bashroot@44b59d07202f:/# cd /usr/share/nginx/html/root@44b59d07202f:/usr/share/nginx/html# echo web02 &gt; index.html &lt;3&gt;docker02操作 基于nginx镜像运行上述所说的容器并设置测试页面 12345678910111213web03[root@docker03 ~]# docker run -itd --name web03 -P nginx:latest[root@docker03 ~]# docker exec -it web03 /bin/bashroot@fd8e8b2df136:/# cd /usr/share/nginx/html/root@fd8e8b2df136:/usr/share/nginx/html# echo web03 &gt; index.htmlroot@fd8e8b2df136:/usr/share/nginx/html# exittrueweb04[root@docker03 ~]# docker run -itd --name web04 -P nginx:latest[root@docker03 ~]# docker exec -it web04 /bin/bashroot@fd8e8b2df136:/# cd /usr/share/nginx/html/root@fd8e8b2df136:/usr/share/nginx/html# echo web04 &gt; index.htmlroot@fd8e8b2df136:/usr/share/nginx/html# exit （4）docker01更改nginx配置文件 123456[root@docker01 ~]# cd /usr/local/nginx///进入nginx配置文件目录[root@docker01 nginx]# mkdir consul//创建consul目录[root@docker01 nginx]# cd consul///进入consul目录 &lt;1&gt;创建nginx.ctmpl模板 1234567891011121314[root@docker01 consul]# vim nginx.ctmplupstream http_backend &#123; &#123;&#123;range service \"nginx\"&#125;&#125; server &#123;&#123; .Address &#125;&#125;:&#123;&#123; .Port &#125;&#125;; &#123;&#123; end &#125;&#125;&#125;server &#123; listen 8000; server_name localhost; location / &#123; proxy_pass http://http_backend; &#125;&#125; &lt;2&gt;修改nginx配置文件，通过 include 参数包含刚刚创建的文件 123[root@docker01 consul]# cd /usr/local/nginx/conf/[root@docker01 conf]# vim nginx.conf include /usr/local/nginx/consul/*.conf; #文件最后添加（要在大括号里面） &lt;3&gt; 生成一个vhost.conf配置文件，并重启nginx（会占用终端) 使用consul-template命令，根据模板生产新的配置文件，并重新加载nginx的配置文件。 1[root@docker01 conf]# consul-template -consul-addr 192.168.1.11:8500 -template \"/usr/local/nginx/consul/nginx.ctmpl:/usr/local/nginx/consul/vhost.conf:/usr/local/bin/nginx -s reload\" 这时，这条命令会占用终端，可以使用nohup命令让它保持后台运行,并重启nginx服务。 1[root@docker01 conf]# nohup consul-template -consul-addr 192.168.1.11:8500 -template \"/usr/local/nginx/consul/nginx.ctmpl:/usr/local/nginx/consul/vhost.conf:/usr/local/sbin/nginx -s reload\" &amp; 查看一下文件是否生成，里面是否有内容 123[root@docker01 ~]# cd /usr/local/nginx/consul/[root@docker01 consul]# lsnginx.ctmpl vhost.conf 1[root@docker01 consul]# cat vhost.conf 此时，应该能够看到，新生产的vhost.conf配置文件已经生效，访问本机8000端口可以得到不同容器提供的服务。 &lt;4&gt;测试访问 12[root@docker01 consul]# curl 127.0.0.1:8000web01 此时可以看到负载均衡的效果！ &lt;5&gt;如果访问不成功 查看端口8000是否开启 1[root@docker01 consul]# ss -lnt 检查nginx配置文件 123[root@docker01 consul]# nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 检查自己编写的nginx配置文件 123456789101112131415[root@docker01 consul]# cd /usr/local/nginx/consul/[root@docker01 consul]# cat nginx.ctmpl upstream http_backend &#123;true&#123;&#123;range service \"nginx\"&#125;&#125;trueserver &#123;&#123; .Address &#125;&#125;:&#123;&#123; .Port &#125;&#125;;true&#123;&#123; end &#125;&#125;&#125;server &#123;truelisten 8000;trueserver_name localhost;truelocation / &#123;truetrueproxy_pass http://http_backend;true&#125;&#125; 如果nginx配置文件没问题，重启nginx 1[root@docker01 consul]# nginx -s reload &lt;6&gt;测试自动发现 docker02 创建测试容器 12345[root@docker02 ~]# docker run -itd --name web05 -P nginx:latest[root@docker02 ~]# docker exec -it web05 /bin/bashroot@44b59d07202f:/# cd /usr/share/nginx/html/root@44b59d07202f:/usr/share/nginx/html# echo web02 &gt; index.html[root@docker02 ~]# docker ps docker01查看 12[root@docker01 consul]# cd /usr/local/nginx/consul/[root@docker01 consul]# cat vhost.conf docker01测试访问 1[root@docker01 consul]# curl 127.0.0.1:8000 //同上 此时可以看到负载均衡的效果！ 这时不需要考虑后端的web服务器添加还是删除都会自动更新的，这是因为在运行consul-template这条命令后添加的/usr/local/sbin/nginx -s reload的作用！","path":"posts/b3c.html","date":"08-20","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"},{"name":"consul","slug":"consul","permalink":"https://wsdlxgp.top/tags/consul/"},{"name":"registrata","slug":"registrata","permalink":"https://wsdlxgp.top/tags/registrata/"}]},{"title":"搭建Prometheus监控报警","text":"基于上一篇博客继续进行部署 一、Prometheus &amp; AlertManager 介绍 Prometheus 是一套开源的系统监控、报警、时间序列数据库的组合，最初有 SoundCloud 开发的，后来随着越来越多公司使用，于是便独立成开源项目。Alertmanager 主要用于接收 Prometheus 发送的告警信息，它支持丰富的告警通知渠道，例如邮件、微信、钉钉、Slack 等常用沟通工具，而且很容易做到告警信息进行去重，降噪，分组等，是一款很好用的告警通知系统。 二、基本概念 Prometheus 官网（https://prometheus.io/） 是一套开源的监控和报警系统，也是一个时序数据库。 架构图 基本原理 Prometheus的基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。 服务过程 Prometheus Daemon负责定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。 2.Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。 3.Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。 4.PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。 Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。 工作流程 通过exporters从数据源主动拉取数据（metrics），保存到时序数据库（TSDB）中，可以通过HTTP Server访问，同时可以发起报警，对于数据库中的时序数据，提供PromeQL进行查询，提供给web UI或者可视化系统Grafana等展示。 Grafana 官网（https://grafana.com/） 开源的数据分析和监控平台 有不同的dashboards支持不同类型的数据可视化 Exporters 数据采集 Prometheus从不同的exorters中拉取数据，有不同的exporter支持不同的数据源 node-exporter 支持机器基本的数据 比如cpu mem 网络 等 docker01 docker02 docker03 192.168.1.11 192.168.1.13 192.168.1.20 NodeEXporter NodeEXporter NodeEXporter cAdvisor cAdvisor cAdvisor Prometheus Server 空 空 Grafana 空 空 全部关闭防火墙，禁用selinux 四、设置prometheus监控报警 接下来，我们需要启动 AlertManager 来接受 Prometheus 发送过来的报警信息，并执行各种方式的告警。同样以 Docker 方式启动 AlertManager，最简单的启动命令如下： 1$ docker run --name alertmanager -d -p 9093:9093 prom/alertmanager:latest 这里 AlertManager 默认启动的端口为 9093，启动完成后，浏览器访问 http://:9093 可以看到默认提供的 UI 页面，不过现在是没有任何告警信息的，因为我们还没有配置报警规则来触发报警。 配置AlertManager AlertManager：用来接收prometheus发送来的报警信息，并且执行设置好的报警方式、报警内容。 下载镜像 12[root@docker01 ~]# docker pull alertmanager//下载alertmanager镜像 基于alertmanager运行一台容器 1[root@docker01 ~]# docker run -d --name alertmanager -p 9093:9093 prom/alertmanager:latest 配置路由转发 12[root@docker01 ~]# echo net.ipv4.ip_forward = 1 &gt;&gt; /etc/sysctl.conf [root@docker01 ~]# sysctl -p 在部署alertmanager之前，我们需要对它的配置文件进行修改,所以我们先运行一个容器，先将其配置文件拷贝出来。 12[root@docker01 ~]# docker cp alertmanager:/etc/alertmanager/alertmanager.yml .///拷贝alertmanager的配置文件到本地 修改alertmanager的配置文件 配置文件简单介绍 AlertManager：用来接收Prometheus发送的报警信息，并且执行设置好的报警方式，报警内容。 AlertManager.yml配置文件： global：全局配置，包括报警解决后的超时时间、SMTP相关配置、各种渠道通知的API地址等消息。 route：用来设置报警的分发策略。 receivers：配置报警信息接收者信息。 inhibit_rules：抑制规则配置，当存在与另一个匹配的报警时，抑制规则将禁用用于有匹配的警报。 修改配置文件 123456789101112131415161718192021222324252627[root@docker01 ~]# vim alertmanager.yml //修改alertmanager配置文件global: resolve_timeout: 5m smtp_from: '2877364346@qq.com' #自己邮箱地址 smtp_smarthost: 'smtp.qq.com:465' #qq的邮箱地址及端口 smtp_auth_username: '2877364346@qq.com' smtp_auth_password: 'osjppnjkbuhcdfff' #需要在qq邮箱获取授权码 smtp_require_tls: false smtp_hello: 'qq.com'route: group_by: ['alertname'] group_wait: 5s group_interval: 5s repeat_interval: 5m receiver: 'email' #接收者改为邮箱receivers:- name: 'email' email_configs: - to: '2877364346@qq.com' send_resolved: true inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 以上配置我反复试验后，发现不同的环境参数配置也不一样，调试期间出现了各种报错问题，将其中几个关键的配置说明一下： 1、smtp_smarthost: 这里为 QQ 邮箱 SMTP 服务地址，官方地址为 smtp.qq.com 端口为 465 或 587，同时要设置开启 POP3/SMTP 服务。 2、smtp_auth_password: 这里为第三方登录 QQ 邮箱的授权码，非 QQ 账户登录密码，否则会报错，获取方式在 QQ 邮箱服务端设置开启 POP3/SMTP 服务时会提示。 3、smtp_require_tls: 是否使用 tls，根据环境不同，来选择开启和关闭。如果提示报错 email.loginAuth failed: 530 Must issue a STARTTLS command first，那么就需要设置为 true。着重说明一下，如果开启了 tls，提示报错 starttls failed: x509: certificate signed by unknown authority，需要在 email_configs 下配置 insecure_skip_verify: true 来跳过 tls 验证。 重新运行 alertmanager 容器 1234[root@docker01 ~]# docker rm -f alertmanager//删除alertmanager容器[root@docker01 ~]# docker run -d --name alertmanager -v /root/alertmanager.yml:/etc/alertmanager/alertmanager.yml -p 9093:9093 prom/alertmanager:latest //运行一台新的alertmanager容器，记得挂载配置文件 Prometheus配置和alertmanager报警规则 创建存放规则的目录 123[root@docker01 ~]# mkdir -p prometheus/rules//创建规则目录[root@docker01 ~]# cd prometheus/rules/ 编写规则 123456789101112[root@docker01 rules]# vim node-up.rules groups:- name: node-up rules: - alert: node-up expr: up&#123;job=\"prometheus\"&#125; == 0 #&#123;job=\"prometheus\"&#125;中的prometheus需要和prometheus配置文件23行的相同 for: 15s labels: severity: 1 team: node annotations: summary: \"&#123;&#123; $labels.instance &#125;&#125; 已停止运行超过 15s！\" 说明一下：该 rules 目的是监测 node 是否存活，expr 为 PromQL 表达式验证特定节点 job=“node-exporter” 是否活着，for 表示报警状态为 Pending 后等待 15s 变成 Firing 状态，一旦变成 Firing 状态则将报警发送到 AlertManager，labels 和 annotations 对该 alert 添加更多的标识说明信息，所有添加的标签注解信息，以及 prometheus.yml 中该 job 已添加 label 都会自动添加到邮件内容中，更多关于 rule 详细配置可以参考 这里。 修改 prometheus配置文件 123456789101112[root@docker01 ~]# vim prometheus.yml # Alertmanager configuration #7alerting: alertmanagers: - static_configs: - targets: - 192.168.1.11:9093 #去注释修改# Load rules once and periodically evaluate them according to the global 'evaluation_interval'. #14行rule_files: - \"/usr/local/prometheus/rules/*.rules\" #添加（这个路径是prometheus容器内的路径） 注意: 这里 rulefiles 为容器内路径，需要将本地 node-up.rules 文件挂载到容器内指定路径，修改 Prometheus 启动命令如下，并重启服务。 重新运行prometheus 容器 1234[root@docker01 ~]# docker rm -f prometheus //删除prometheus容器[root@docker01 ~]# docker run -d -p 9090:9090 --name prometheus --net=host -v /root/prometheus.yml:/etc/prometheus/prometheus.yml -v /root/prometheus/rules/node-up.rules:/usr/local/prometheus/rules/node-up.rules prom/prometheus//运行一台新的alertmanager容器，记得挂载规则文件 浏览器验证一下http://192.168.1.11:9090/rules 这里说明一下 Prometheus Alert 告警状态有三种状态：Inactive、Pending、Firing。 Inactive：非活动状态，表示正在监控，但是还未有任何警报触发。 Pending：表示这个警报必须被触发。由于警报可以被分组、压抑/抑制或静默/静音，所以等待验证，一旦所有的验证都通过，则将转到 Firing 状态。 Firing：将警报发送到 AlertManager，它将按照配置将警报的发送给所有接收者。一旦警报解除，则将状态转到 Inactive，如此循环。 挂起docker02 会收到邮件 这里有几个地方需要解释一下： 每次停止/恢复服务后，15s 之后才会发现 Alert 状态变化，是因为 prometheus.yml中 global -&gt; scrape_interval: 15s 配置决定的，如果觉得等待 15s 时间太长，可以修改小一些，可以全局修改，也可以局部修改。例如局部修改 node-exporter 等待时间为 5s。 … - job_name: ‘node-exporter’ scrape_interval: 5s file_sd_configs: - files: [’/usr/local/prometheus/groups/nodegroups/*.json’] Alert 状态变化时会等待 15s 才发生改变，是因为 node-up.rules 中配置了 for: 15s 状态变化等待时间。 报警触发后，每隔 5m 会自动发送报警邮件(服务未恢复正常期间)，是因为 alertmanager.yml 中 route -&gt; repeat_interval: 5m 配置决定的。 五、AlertManager自定义邮件模板 创建模板目录 1234[root@docker01 ~]# cd prometheus//进入之前创建的prometheus目录[root@docker01 prometheus]# mkdir alertmanager-tmpl//创建AlertManager模板目录 看到上边默认发送的邮件模板，虽然所有核心的信息已经包含了，但是邮件格式内容可以更优雅直观一些，那么，AlertManager 也是支持自定义邮件模板配置的，首先新建一个模板文件 编写模板规则 123456789101112131415[root@docker01 prometheus]# vim email.tmpl &#123;&#123; define \"email.from\" &#125;&#125;2877364346@qq.com&#123;&#123; end &#125;&#125;&#123;&#123; define \"email.to\" &#125;&#125;2877364346@qq.com&#123;&#123; end &#125;&#125;&#123;&#123; define \"email.to.html\" &#125;&#125;&#123;&#123; range .Alerts &#125;&#125;=========start==========&lt;br&gt;告警程序: prometheus_alert&lt;br&gt;告警级别: &#123;&#123; .Labels.severity &#125;&#125; 级&lt;br&gt;告警类型: &#123;&#123; .Labels.alertname &#125;&#125;&lt;br&gt;故障主机: &#123;&#123; .Labels.instance &#125;&#125;&lt;br&gt;告警主题: &#123;&#123; .Annotations.summary &#125;&#125;&lt;br&gt;触发时间: &#123;&#123; .StartsAt.Format \"2019-08-04 16:58:15\" &#125;&#125; &lt;br&gt;=========end==========&lt;br&gt;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125; 简单说明一下，上边模板文件配置了 email.from、email.to、email.to.html 三种模板变量，可以在 alertmanager.yml 文件中直接配置引用。这里 email.to.html 就是要发送的邮件内容，支持 Html 和 Text 格式，这里为了显示好看，采用 Html 格式简单显示信息。下边 {{ range .Alerts }} 是个循环语法，用于循环获取匹配的 Alerts 的信息，下边的告警信息跟上边默认邮件显示信息一样，只是提取了部分核心值来展示。然后，需要增加 alertmanager.yml 文件 templates 配置如下： 修改alertmanager的配置文件 1234567891011121314151617181920212223242526272829[root@docker01 ~]# vim alertmanager.yml global: resolve_timeout: 5m smtp_from: '2877364346@qq.com' smtp_smarthost: 'smtp.qq.com:465' smtp_auth_username: '2877364346@qq.com' smtp_auth_password: 'evjmqipqezlbdfij' smtp_require_tls: false smtp_hello: 'qq.com'templates: #添加模板 - '/etc/alertmanager-tmpl/*.tmpl' #添加路径 route: group_by: ['alertname'] group_wait: 5s group_interval: 5s repeat_interval: 5m receiver: 'email' receivers:- name: 'email' email_configs: - to: '&#123;&#123; template \"email to\" &#125;&#125;' #修改 html: '&#123;&#123; template \"email.to.html\" .&#125;&#125;' #添加 send_resolved: true #删除 inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 重新运行 alertmanager 容器 1234[root@docker01 ~]# docker rm -f alertmanager//删除alertmanager容器[root@docker01 ~]# docker run -itd --name alertmanager -p 9093:9093 -v /root/alertmanager.yml:/etc/alertmanager/alertmanager.yml -v /root/prometheus/alertmanager-tmpl:/etc/alertmanager-tmpl prom/alertmanager:latest//运行一台新的alertmanager容器，记得挂载配置文件 挂起docker02 收到邮件 当然我们还可以配置邮件标题，这里就不在演示了，详细配置可参考 这里。这里除了监控节点是否存活外，还可以监控很多很多指标，例如 CPU 负载告警、Mem 使用量告警、Disk 存储空间告警、Network 负载告警等等，这些都可以通过自定义 PromQL 表达式验证值来定义一些列的告警规则，来丰富日常工作中需要的各种告警。 这里，我们只演示了如何通过 AlertManager 来配置发送邮件告警，其他的告警方式，可以参考 官网文档 来配置，这里就不再演示了。下一篇，我们继续通过 Prometheus 来监控 SpringBoot 工程应用程序 JVM 情况，以及自定义 metrics 来实现特定功能的监控。","path":"posts/babe.html","date":"08-19","excerpt":"","tags":[{"name":"Docker监控","slug":"Docker监控","permalink":"https://wsdlxgp.top/tags/Docker%E7%9B%91%E6%8E%A7/"},{"name":"prometheus","slug":"prometheus","permalink":"https://wsdlxgp.top/tags/prometheus/"},{"name":"alertmanager","slug":"alertmanager","permalink":"https://wsdlxgp.top/tags/alertmanager/"}]},{"title":"基于docker搭建Prometheus+Grafana","text":"一、介绍Prometheus Prometheus（普罗米修斯）是一套开源的监控&amp;报警&amp;时间序列数据库的组合，起始是由SoundCloud公司开发的。随着发展，越来越多公司和组织接受采用Prometheus，社会也十分活跃，他们便将它独立成开源项目，并且有公司来运作。Google SRE的书内也曾提到跟他们BorgMon监控系统相似的实现是Prometheus。现在最常见的Kubernetes容器管理系统中，通常会搭配Prometheus进行监控。 Prometheus基本原理是通过HTTP协议周期性抓取被监控组件的状态，这样做的好处是任意组件只要提供HTTP接口就可以接入监控系统，不需要任何SDK或者其他的集成过程。这样做非常适合虚拟化环境比如VM或者Docker 。 Prometheus应该是为数不多的适合Docker、Mesos、Kubernetes环境的监控系统之一。 与其他监控系统相比，Prometheus的主要特点是： 一个多维数据模型（时间序列由指标名称定义和设置键/值尺寸）。 非常高效的存储，平均一个采样数据占~3.5bytes左右，320万的时间序列，每30秒采样，保持60天，消耗磁盘大概228G。 一种灵活的查询语言。 不依赖分布式存储，单个服务器节点。 时间集合通过HTTP上的PULL模型进行。 通过中间网关支持推送时间。 通过服务发现或静态配置发现目标。 多种模式的图形和仪表板支持。 二、Prometheus架构概览 该图说明了普罗米修斯（Prometheus）及其一些生态系统组件的整体架构： 它的服务过程是这样的Prometheus daemon负责定时去目标上抓取metrics(指标) 数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。 Prometheus：支持通过配置文件、文本文件、zookeeper、Consul、DNS SRV lookup等方式指定抓取目标。支持很多方式的图表可视化，例如十分精美的Grafana，自带的Promdash，以及自身提供的模版引擎等等，还提供HTTP API的查询方式，自定义所需要的输出。 Alertmanager：是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。 PushGateway：这个组件是支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。 如果有使用过statsd的用户，则会觉得这十分相似，只是statsd是直接发送给服务器端，而Prometheus主要还是靠进程主动去抓取。 大多数Prometheus组件都是用Go编写的，它们可以轻松地构建和部署为静态二进制文件。访问prometheus.io以获取完整的文档，示例和指南。 三、Prometheus四种数据类型 Counter Counter用于累计值，例如记录请求次数、任务完成数、错误发生次数。一直增加，不会减少。重启进程后，会被重置。 例如：http_response_total{method=”GET”,endpoint=”/api/tracks”} 100，10秒后抓取http_response_total{method=”GET”,endpoint=”/api/tracks”} 100。 Gauge Gauge常规数值，例如 温度变化、内存使用变化。可变大，可变小。重启进程后，会被重置。 例如： memory_usage_bytes{host=”master-01″} 100 &lt; 抓取值、memory_usage_bytes{host=”master-01″} 30、memory_usage_bytes{host=”master-01″} 50、memory_usage_bytes{host=”master-01″} 80 &lt; 抓取值。 Histogram Histogram（直方图）可以理解为柱状图的意思，常用于跟踪事件发生的规模，例如：请求耗时、响应大小。它特别之处是可以对记录的内容进行分组，提供count和sum全部值的功能。 例如：{小于10=5次，小于20=1次，小于30=2次}，count=7次，sum=7次的求和值。 Summary Summary和Histogram十分相似，常用于跟踪事件发生的规模，例如：请求耗时、响应大小。同样提供 count 和 sum 全部值的功能。 例如：count=7次，sum=7次的值求值。 **它提供一个quantiles的功能，可以按%比划分跟踪的结果。**例如：quantile取值0.95，表示取采样值里面的95%数据。 五、实验环境 docker01 docker02 docker03 192.168.1.11 192.168.1.13 192.168.1.20 NodeEXporter NodeEXporter NodeEXporter cAdvisor cAdvisor cAdvisor Prometheus Server 空 空 Grafana 空 空 全部关闭防火墙，禁用selinux 需要部署的组件： Prometheus Server:普罗米修斯的主服务器。 Prometheus是一个开源的服务监控系统，它通过HTTP协议从远程的机器收集数据并存储在本地的时序数据库上。 多维数据模型（时序列数据由metric名和一组key/value组成） 在多维度上灵活的查询语言(PromQl) 不依赖分布式存储，单主节点工作. 通过基于HTTP的pull方式采集时序数据 可以通过push gateway进行时序列数据推送(pushing) 可以通过服务发现或者静态配置去获取要采集的目标服务器 多种可视化图表及仪表盘支持 Prometheus通过安装在远程机器上的exporter来收集监控数据，后面我们将使用到node_exporter收集系统数据。 NodeEXporter:负责收集Host硬件信息和操作系统信息。 cAdvisor:负责收集Host.上运行的容器信息。 Grafana:负责展示普罗米修斯监控界面。 Grafana 是一个开箱即用的可视化工具，具有功能齐全的度量仪表盘和图形编辑器，有灵活丰富的图形化选项，可以混合多种风格，支持多个数据源特点。 这些可以直接docker pull下载镜像（现在是本地导入镜像） 本地上传镜像 docker01 1[09:05:42][docker01$ docker load -i node-exporter.tar &amp;&amp; docker load -i mycadvisor.tar &amp;&amp; docker load -i prometheus.tar &amp;&amp; docker load -i grafana.tar docker02和docker03 1[09:05:22]docker03]$ docker load -i node-exporter.tar &amp;&amp; docker load -i mycadvisor.tar 六、各主机部署 1) 3个节点，全部部署node-EXporter,和cAdvisor. 部署安装node-EXporter收集节点硬件和操作系统信息。 12[09:21:03[docker01]$ docker run -d -p 9100:9100 -v /proc:/host/proc -v /sys:/host/sys -v /:/rootfs --net=host prom/node-exporter --path.procfs /host/proc --path.sysfs /host/sys --collector.filesystem.ignored-mount-points \"^/(sys|proc|dev|host|etc)($|/)\"//部署node-EXporter,收集硬件和系统信息。 PS: 注意，这里使用了–net=host， 这样Prometheus Server可以直接与Node- EXporter通信。 验证:打开浏览器验证结果。http://192.168.1.11:9100/，http://192.168.1.13:9100/，http://192.168.1.20:9100/ 部署安装cAdvisor,收集节点容器信息。 1[09:39:10[docker01]$ docker run -v /:/rootfs:ro -v /var/run:/var/run/:rw -v /sys:/sys:ro -v /var/lib/docker:/var/lib/docker:ro --detach=true --name=cadvisor --net=host google/cadvisor 验证:打开浏览器验证结果。http://192.168.1.11:8080，http://192.168.1.13:8080，http://192.168.1.20:8080 2)在docker01上部署Prometheus Server服务。 在部署prometheus之前，我们需要对它的配置文件进行修改,所以我们先运行一个容器，先将其配置文件拷贝出来。 123409:51:22][docker01]$ docker run -d -p 9090:9090 --name prometheus --net=host prom/prometheus//打开一台Prometheus[09:51:00[docker01]$ docker cp prometheus:/etc/prometheus/prometheus.yml .///拷贝Prometheus的配置文件到本地 修改Prometheus的配置文件，添加监听端口（29行） 123[09:55:53][docker01][~]$ vim prometheus.yml //修改配置文件这里指定了prometheus的监控项，包括它也会监控自己手机到的数据。- targets: ['localhost:9090','localhost:8080','localhost:9100','192.168.1.13:8080','192.168.1.13:9100','192.168.1.20:8080','192.168.1.20:9100'] 重新运行prometheus容器 1234[10:00:27][docker01][~]$ docker rm -f prometheus //删除 prometheus容器[10:02:45][docker01][~]$ docker run -d -p 9090:9090 --name prometheus --net=host -v /root/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus//运行一台新的 prometheus容器 浏览器访问，验证：http://192.168.1.11:9090/graph ps：这里能够查看到我们各个监控项。 如果现在挂起一台虚拟机（测试完之后继续运行） 3)在docker01.上,部署grafana服务,用来展示prometheus收集到的数据。 1234[root@docker01 ~]# mkdir grafana-storage//创建收集信息的目录[root@docker01 ~]# chmod 777 grafana-storage///给予777权限 1[root@docker01 ~]# docker run -d -p 3000:3000 --name grafana -v /root/grafana-storage:/var/lib/grafana -e \"GF_SECURITY_ADMIN_PASSWORD=123.com\" grafana/grafana **浏览器访问验证：**http://192.168.1.11:3000/login （&lt;默认&gt;用户名：admin，密码：123.com） 添加数据源 PS:看到这个提示， 说明prometheus和grafana服务的是 正常连接的。 此时，虽然grafana收集到了数据，但怎么显示它,仍然是个问题，grafana支持自定 义显示信息,不过要自定义起来非常麻烦，不过好在，grafana官方为我们提供了- -些模板，来供我们使用。 **grafana官网:**https://grafana.com/docs/grafana/latest/ 选中一款模板，然后，我们有2种方式可以套用这个模板。 第一种方式：通过JSON文件使用模板。 下载完成之后，来到grafana控制台 第二种导入模板的方式:** 可以直接通过模板的ID号。 //这个id不好用换成8321了 复制模板id之后，来到grafana控制台 排错思路 防火墙是否关闭，selinux是否禁用 主机名称是否更改 镜像是否正常 各服务启动时挂载目录是否正确 grafana服务，是否创建所需目录，目录是否有权限 Prometheus服务是否修改配置文件 总结 恭喜！您已经设置了Prometheus服务器，Node Exporter和Grafana 等所有这些都可以使用的Docker。尽管这些目前都在同一台机器上运行，但这仅用于演示目的。在生产设置中，通常会在每台受监控的计算机上运行节点导出器，多个Prometheus服务器（根据组织的需要），以及单个Grafana服务器来绘制来自这些服务器的数据。","path":"posts/5755.html","date":"08-18","excerpt":"","tags":[{"name":"Docker监控","slug":"Docker监控","permalink":"https://wsdlxgp.top/tags/Docker%E7%9B%91%E6%8E%A7/"},{"name":"prometheus","slug":"prometheus","permalink":"https://wsdlxgp.top/tags/prometheus/"},{"name":"grafana","slug":"grafana","permalink":"https://wsdlxgp.top/tags/grafana/"}]},{"title":"Docker的监控(简单部署Sysdig和Weave Scope)","text":"一、Docker的监控 Docker自带的监控命令 简单命令介绍 ps docker container ps 是我们早已熟悉的命令了，方便我们查看当前运行的容器。新版的 Docker 提供了一个新命令 docker container ls，其作用和用法与 docker container ps 完全一样。不过 ls 含义可能比 ps 更准确，所以更推荐使用。 top 如果想知道某个容器中运行了哪些进程，可以执行 docker container top [container] 命令。命令后面还可以跟上 Linux 操作系统 ps 命令的参数显示特定的信息，比如 -au。 stats docker container stats 用于显示每个容器各种资源的使用情况。默认会显示一个实时变化的列表，展示每个容器的 CPU 使用率，内存使用量和可用量。注意：容器启动时如果没有特别指定内存 limit，stats 命令会显示 host 的内存总量，但这并不意味着每个 container 都能使用到这么多的内存。 除此之外 docker container stats 命令还会显示容器网络和磁盘的 IO 数据。默认的输出有个缺点，显示的是容器 ID 而非名字。我们可以在 stats 命令后面指定容器的名称只显示某些容器的数据。比如 docker container stats sysdig weave。 命令执行 12[root@docker01 ~]# docker ps//查看容器信息 123[root@docker01 ~]# docker top 容器名称[root@docker01 ~]# docker top wordpress_wordpress_1 //查看容器中运行的进程信息，支持 ps 命令参数。 12[root@docker01 ~]# docker stats wordpress_wordpress_1 //实时查看容器统计信息，查看容器的CPU利用率、内存的使用量以及可用内存总量。 123[root@docker01 ~]# docker logs 容器名称[root@docker01 ~]# docker logs wordpress_wordpress_1 //查看容器的日志 二、用 Sysdig 监控服务器和 Docker 容器 12[root@docker01 ~]# docker pull sysdig//下载sysdig镜像 通过sysdig运行容器 1[root@docker01 ~]# docker run -it --rm --name sysdig --privileged=true --volume=/var/run/docker.sock:/host/var/run/docker.sock --volume=/dev:/host/dev --volume=/proc:/host/proc:ro --volume=/boot:/host/boot:ro --volume=/lib/modules:/host/lib/modules:ro --volume=/usr:/host/usr:ro sysdig/sysdig 下载插件失败后可以运行下边命令，重新下载 12root@10ccab83a512:/# system-sysdig-loader//下载插件失败后可以运行下边命令，重新下载 下载成功后，可以运行sysdig命令，查看监控项 12root@10ccab83a512:/# sysdig//运行sysdig命令，查看监控项，它会动态查看 使用 csysdig csysdig 就是运 ncurses 库的用户界面的 sysdig 软件包，Ncurses 是一个能提供功能键定义 ( 快捷键 ), 屏幕绘制以及基于文本终端的图形互动功能的动态库。在 sysdig 软件包里还提供了一个工具 csysdig，该工具执行后，运行界面和 top 命令类似。csysdig 工作界面如图 5。 运行csysdig命令，查看监控项 12root@10ccab83a512:/# csysdig//运行csysdig命令，图形化界面查看监控项，它会动态查看 csysdig 使用如下快捷键： P：暂停屏幕输出信息 Enter：进入当前突出显示的条目。 Ctrl+F：列表搜索。 F1- 帮助信息 F2- 显示视图选择器。这将让你切换到另一个视图。 F4- 使用过滤器 F5- 查看 IO 输出信息 F7 显示帮助页面当前显示的视图。 F8 打开视图的操作面板。 F9，打开列排序面板。 Q 放弃退出。 Arrows, PgUP, PgDn, Home, End：图标上下左右的移动控制。 sysdig按不同的View来监控不同类型的资源，点击底部Views菜单（或者按F2），显示View选择列表 我们将光标移到Containers这一项，界面右边立即显示出此view的功能介绍，回车或者双击Containers，进入容器监控界面 sysdig会显示该host所有的容器的实时数据，每两秒刷新一次。各列数据的含义也是自解释的，如果不清楚，可以点一下底部的Legend，如果想按某一列排序，比如按使用的内存量，点一下列头VIRT 如果想查看某个容器的进程，将光标移动到目标容器，然后回车或者双击 还可以继续双击查看进程中的线程 返回上一级，按退格键即可 sysdig的交互功能很强，如果界面显示的条目很多，可以点击底部Search菜单，然后输入关键字进行查找 如果觉得界面刷新太快，看不清楚关注的信息，可以点击底部的Pause菜单 sysdig的特点： （1）监控信息全，包括Linux操作系统和容器 （2）界面交互性强 其缺点是sysdig显示的是实时数据，看不到变化和趋势。而且是命令行操作方式，需要ssh到host上执行，不是太方便 总结 这些示例仅仅是展示了 Sysdig 能力的冰山一角，在目前的其他系统监控类工具中，笔者还没有看到像 Sysdig 这样功能如此强大、而又对容器支持这样好的。所以，对于经常使用服务器特别是 Docker 容器作为产品运行方式的用户，这是一款值得使用的系统工具。 三、Docker监控方案之Weave Scope Weave Scope 的最大特点是会自动生成一张 Docker 容器地图，让我们能够直观地理解、监控和控制容器。千言万语不及一张图，先感受一下。 12[root@docker01 ~]# docker pull scope//下载scope镜像 执行如下脚本安装运行Weave Scope 123[root@docker01 ~]# curl -L git.io/scope -o /usr/local/bin/scope[root@docker01 ~]# chmod +x /usr/local/bin/scope[root@docker01 ~]# scope launch 浏览器访问http://192.168.1.11:4040/ 然后就可以更好的监控，管理docker中的容器了 开启第docker02，加入docker01监控项 docker01 删除weavescope容器 1234[root@docker01 ~]# docker stop weavescope weavescope[root@docker01 ~]# docker rm weavescope weavescope docker02 12[root@docker01 ~]# docker pull scope//下载scope镜像 123[root@docker01 ~]# curl -L git.io/scope -o /usr/local/bin/scope[root@docker01 ~]# chmod +x /usr/local/bin/scope[root@docker01 ~]# scope launch docker01 1[root@docker01 ~]# scope launch 192.168.1.11 192.168.1.13 docker02 1[root@docker02 ~]# scope launch 192.168.1.13 192.168.1.11 浏览器访问http://192.168.1.11:4040/ 浏览器访问http://192.168.1.13:4040/也是可以的","path":"posts/eb5f.html","date":"08-17","excerpt":"","tags":[{"name":"Docker监控","slug":"Docker监控","permalink":"https://wsdlxgp.top/tags/Docker%E7%9B%91%E6%8E%A7/"},{"name":"sysdig","slug":"sysdig","permalink":"https://wsdlxgp.top/tags/sysdig/"},{"name":"Weave Scope","slug":"Weave-Scope","permalink":"https://wsdlxgp.top/tags/Weave-Scope/"}]},{"title":"docker三剑客之docker-compose和搭建wordpress的博客","text":"一、简介 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。 通过之前的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 使用微服务架构的系统一般包含若干个微服务，每个微服务一般部署多个实例。如果每个服务都要手动启停，那么效率低，维护量大。 二、 Docker Compose介绍 通过Docker-Compose用户可以很容易地用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成编写。Docker-Compose解决了容器与容器之间如何管理编排的问题。 Docker Compose工作原理图 撰写中有两个重要的概念： **服务（服务）：**一个应用的容器，实际上可以包括多个运行相同相同的容器实例。 **项目（项目）：**由各个关联的应用容器组成的一个完整的业务单元，在docker-compose.yml文件中定义。一个项目可以由多个服务（容器）关联，组成面向项目进行管理，通过子命令对项目中的单个容器进行便捷地生命周期管理。 Compose项目由Python编写，实现上调用了Docker服务提供的API来对容器进行管理。因此，只要所操作的平台支持Docker API，就可以在其上利用Compose来进行编排管理。 Docker三大编排工具： Docker Compose：是用来组装多容器应用的工具，可以在 Swarm集群中部署分布式应用。 Docker Machine：是支持多平台安装Docker的工具，使用 Docker。Machine，可以很方便地在笔记本、云平台及数据中心里安装Docker。 Docker Swarm：是Docker社区原生提供的容器集群管理工具。 Docker Compose命令详解 Docker compose的使用非常类似于docker命令的使用，但是需要注意的是大部分的compose命令都需要到docker-compose.yml文件所在的目录下才能执行。 compose以守护进程模式运行加-d选项 三、Docker Compose安装 123456#下载sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose#安装chmod +x /usr/local/bin/docker-compose#查看版本docker-compose version 四、实验环境 主机 ip地址 服务 docker 192.168.1.11 compose+wordpress 五 docker三剑客之docker-compose docker容器的编排工具: 解决相互有依赖关系的多个容器的管理。 12[root@docker01 ~]# docker-compose -v//验证已有docker-compose命令 docker-compose的配置文件实例 通过识别一个docker-compose.yml的配置文件，去管理容器。 设置tab键的空格数量 12345[root@docker01 ~]# vim .vimrcset tabstop=2//设置tab键的空格数量[root@docker01 ~]# source .vimrc //刷新一下 创建一个docker-compose.yml测试文件 123456789101112131415[root@docker01 ~]# mkdir compose_test//创建测试目录[root@docker01 ~]# cd compose_test/[root@docker01 compose_test]# vim docker-compose.yml//创建测试文件docker-compose.ymlversion: \"3\"services: nginx: container_name: web-nginx image: nginx restart: always ports: - 90:80 volumes: - ./webserver:/usr/share/nginx/html docker-compose.yml文件的解释 第一部分: version: 指定语法格式的版本。 第二部分: service: 定义服务,(想要运行什么样的容器) 通过docker-compose.yml文件运行容器 12[root@docker01 compose_test]# docker-compose up -d//后台运行docker-compose规定的容器。（在执行这条命令的当前目录下，也需要一个docker-compose.yml的配置文件，并且通常只有一个。） 12[root@docker01 compose_test]# docker ps//查看容器信息 12[root@docker01 compose_test]# curl 127.0.0.1:90//访问nginx会失败，因为挂载目录没有页面内容 123456[root@docker01 compose_test]# vim webserver/index.html//创建测试网页xgp666[root@docker01 compose_test]# curl 127.0.0.1:90//再次访问，是成功的xgp666 通过docker-compose.yml文件停止运行容器 1[root@docker01 compose_test]# docker-compose stop 通过docker-compose.yml文件重启容器 1[root@docker01 compose_test]# docker-compose restart 不在docker-compose.yml文件所在目录，要使用-f指定目录 1[root@docker01 ~]# docker-compose -f compose_test/docker-compose.yml stop 并且，在运行container（docker-compose.yml）的过程中，还支持Dockerfile 1234[root@docker01 compose_test]# vim Dockerfile//编写dockerfileFROM nginxADD webserver /usr/share/nginx/html 1234567891011[root@docker01 compose_test]# vim docker-compose.yml //修改docker-compose.yml文件version: \"3\"services: nginx: build: . #添加 container_name: web-nginx image: new-nginx:v1.0 #修改镜像名称 restart: always ports: - 90:80 通过docker-compose.yml文件停止并删除容器 123[root@docker01 compose_test]# docker-compose stopStopping web-nginx ... done[root@docker01 compose_test]# docker-compose rm 通过docker-compose.yml文件运行容器 1234[root@docker01 compose_test]# docker-compose up -d//通过docker-compose.yml文件[运行]()容器[root@docker01 compose_test]# docker ps//查看容器信息 测试nginx访问页面 123[root@docker01 compose_test]# curl 127.0.0.1:90//测试访问nginx页面，成功xgp666 六、搭建wordpress的博客 下载wordpress和mysql:5.7容器 1234[root@docker01 ~]# docker pull wordpress//下载wordpress容器[root@docker01 ~]# docker pull mysql：5.7//下载mysql：5.7容器 编写一个docker-ccompose.yml 1234567891011121314151617181920212223242526[root@docker01 ~]# mkdir wordpress//创建wordpress测试文件[root@docker01 ~]# cd wordpress/[root@docker01 wordpress]# vim docker-compose.yml//编写docker-compose.ymlversion: \"3.1\"services: wordpress: image: wordpress restart: always ports: - 8080:80 environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: 123.com WORDPRESS_DB_NAME: wordpress db: image: mysql:5.7 restart: always environment: MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: 123.com MYSQL_ROOT_PASSWORD: 123.com 通过docker-compose.yml文件运行容器 1[root@docker01 wordpress]# docker-compose up -d 12[root@docker01 wordpress]# docker ps//查看容器信息 12[root@docker01 wordpress]# docker logs 容器名称//查看容器日志 浏览器访问一下 http://192.168.1.11:8080/ 选择语言 安装wordpress 登陆wordpress 登陆成功后，自己就可以进行设置了 排错 首先查看主机名是否更改 防火墙和selinux是否关闭 docker-compose命令是否安装给予权限 docker–compose.yml 编写是否有问题 容器执行是否正常 （如果浏览器访问不到，可以添加一条路由转发） 其他wordpress优化建议 以上步骤之后，基本wordpress搭建和一些必备的设置就算完成了，剩下的更多是个人的选择，每个人可能要求不同，下面就说几点wordpress优化的建议 1.无论你是做百度seo，安装一个SEO插件，就算不想设置文章的TDK，至少网站首页的有必要设置一下，推荐 All in one seo pack 2.定期备份，备份的重要性不用多说，凡是丢过数据的人都会养成备份的习惯，WordPress备份网站方法 3.安装一个安全插件，WordPress安全插件推荐 4.及时更新网站的主题和插件，WordPress插件自动更新方法 5.删除所有没有用的主题和插件，WordPress删除主题方法 6.设置垃圾留言过滤，wordpress防垃圾留言插件Akismet WordPress建站基础主要就是这些，后面的话就是根据自己的站点进行各种设置，不同类型的站点使用主题和插件都是很大区别的。不过如果你能学会本篇所介绍的内容，相信你的站点就已经超过了绝大部分网站，好了今天教程就到这里，如果你有什么问题或者其他更好的建议，欢迎留言讨论","path":"posts/d728.html","date":"08-16","excerpt":"","tags":[{"name":"docker-compose","slug":"docker-compose","permalink":"https://wsdlxgp.top/tags/docker-compose/"},{"name":"wordpress","slug":"wordpress","permalink":"https://wsdlxgp.top/tags/wordpress/"}]},{"title":"nginx+docker+nfs部署","text":"一．体系架构 在Keepalived + Nginx高可用负载均衡架构中，keepalived负责实现High-availability (HA) 功能控制前端机VIP（虚拟网络地址），当有设备发生故障时，热备服务器可以瞬间将VIP自动切换过来，实际运行中体验只有2秒钟切换时间，DNS服务可以负责前端VIP的负载均衡。 nginx负责控制后端web服务器的负载均衡，将客户端的请求按照一定的算法转发给后端Real Server处理，而Real Server将响应直接返回给客户端。 nfs服务器做实时备份，给web服务器提供web界面。 二．简单原理 NGINX_MASTER、NGINX_BACKUP两台服务器均通过keepalived软件把ens33网卡绑上一个虚拟IP（VIP）地址192.168.1.40，此VIP当前由谁承载着服务就绑定在谁的ens32上，当NGINX_MASTER发生故障时，NGINX_BACKUP会通过/etc/keepalived/keepalived.conf文件中设置的心跳时间advert_int 1检查，无法获取NGINX_MASTER正常状态的话，NGINX_BACKUP会瞬间绑定VIP来接替nginx_master的工作，当NGINX_MASTER恢复后keepalived会通过priority参数判断优先权将虚拟VIP地址192.168.1.40重新绑定给NGINX_MASTER的ens33网卡。 使用此方案的优越性 1.实现了可弹性化的架构，在压力增大的时候可以临时添加web服务器添加到这个架构里面去; 2.upstream具有负载均衡能力，可以自动判断后端的机器，并且自动踢出不能正常提供服务的机器； 3.相对于lvs而言，正则分发和重定向更为灵活。而Keepalvied可保证单个nginx负载均衡器的有效性，避免单点故障； 4.用nginx做负载均衡，无需对后端的机器做任何改动。 5.nginx部署在docker容器里，即大量地节约开发、测试、部署的时间，又可以在出现故障时通过镜像快速恢复业务。 三、系统环境 两台负载机器安装：，nginx+docker+nfs 分别命名为：NGINX_MASTER，NGINX_BACKUP。 后端web服务器，可以是提供web服务的任何架构，分别命名为：WEB_1，WEB_2。 后端数据库机器可任意架构，只要能提供数据库服务即可。 服务器 IP地址 安装软件 NGINX_MASTER 192.168.1.10 nginx+keepalived NGINX_BACKUP 192.168.1.20 nginx+keepalived WEB_1 192.168.1.11 docker+nginx WEB_2 192.168.1.13 docker+nginx nfs_MASTER 192.168.1.30 nfs+rsync+inotify nfs_BACKUP 192.168.1.10 nfs+rsync+inotify nginx（两台都是） 安装nginx 12345[root@nginx01 ~]# tar zxf nginx-1.14.0.tar.gz //解压nginx安装包[root@nginx01 ~]# cd nginx-1.14.0/[root@nginx01 nginx-1.14.0]# yum -y install openssl-devel pcre-devel zlib-devel//安装nginx依赖包 12[root@nginx01 nginx-1.14.0]# ./configure --prefix=/usr/local/nginx1.14 --with-http_dav_module --with-http_stub_status_module --with-http_addition_module --with-http_sub_module --with-http_flv_module --with-http_mp4_module --with-pcre --with-http_ssl_module --with-http_gzip_static_module --user=nginx --group=nginx &amp;&amp; make &amp;&amp; make install//编译安装nginx 12345678[root@nginx01 nginx-1.14.0]# useradd nginx -s /sbin/nologin -M//创建所需用户[root@nginx01 nginx-1.14.0]# ln -s /usr/local/nginx1.14/sbin/nginx /usr/local/sbin///链接命令[root@nginx01 nginx-1.14.0]# nginx //开启nginx[root@nginx01 nginx-1.14.0]# netstat -anpt | grep nginx//查看nginx是否开启 部署nginx 12[root@nginx01 ~]# cd /usr/local/nginx1.14/conf/[root@nginx01 conf]# vim nginx.conf ​ http模块加 1234upstream backend &#123;server 192.168.1.11:90 weight=1 max_fails=2 fail_timeout=10s;server 192.168.1.13:90 weight=1 max_fails=2 fail_timeout=10s;&#125; location / { # root html; # index index.html index.htm; proxy_pass http://backend; #添加 } 高可用环境 安装keepalived 1[root@nginx02 nginx-1.14.0]# yum -y install keepalived 配置keepalived 修改主和备nginx服务器上的keepalived 配置文件 /etc/keepalived/keepalived.conf 文件 主nginx 修改主nginx下/etc/keepalived/keepalived.conf文件 123456789101112131415161718! Configuration File for keepalivedglobal_defs &#123; router_id LVS_DEVEL&#125; vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.40 &#125;&#125; 备nginx 修改备nginx下 /etc/keepalived /keepalived.conf文件 配置备nginx时需要注意：需要修改state为BACKUP , priority比MASTER低，virtual_router_id和master的值一致 12345678910111213141516171819! Configuration File for keepalivedglobal_defs &#123; router_id TWO&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 1 priority 99 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.40 &#125;&#125; 测试（在做完docker的时候） 主备nginx都启动keepalived 1systemctl start keepalived 12[root@nginx01 conf]# curl 192.168.1.40wsd666 nfs（两台都是) nfs操作 12345678910[root@localhost ~]# yum -y install nfs-utils//下载nfs服务[root@nfs ~]# mkdir /database//创建共享目录[root@nfs02 ~]# chmod 777 /database///设置权限[root@nfs ~]# vim /etc/exports//设置权限如下/database *(rw,sync,no_root_squash) 开启各项服务 1234[root@nfs ~]# systemctl start rpcbind[root@nfs ~]# systemctl enable rpcbind[root@nfs ~]# systemctl start nfs-server[root@nfs ~]# systemctl enable nfs-server docker01和docker02测试nfs 1234567891011121314[root@nfs01 ~]# vim /etc/rsyncd.conf //建立rsync配置文件uid = nobodygid = nobodyuse chroot = yesaddress = 192.168.1.30port 873log file = /var/log/rsyncd.logpid file = /var/run/rsyncd.pidhosts allow = 192.168.1.0/24[wwwroot]path = /databaseread only = nodont compress = *.gz *.bz2 *.rar *.zip 123456[root@nfs01 ~]# mkdir /database//创建共享目录[root@nfs01 ~]# rsync --daemon//启动rsync[root@nfs01 ~]# netstat -anpt | grep rsync//查看端口 如果需要重启rsync服务，需要： 12345[root@localhost ~]# kill $(cat /var/run/rsyncd.pid)//停止服务[root@localhost ~]# rsync --daemon//启动服务[root@localhost ~]# kill -9 $(cat /var/run/rsyncd.pid) 或者直接使用“netstat -anpt | grep rsync”命令查出进程号，使用“kill 进程号”一样。 使用第一种方法停止rsync服务必须删除存放rsync服务进程的文件： 1[root@localhost ~]# rm -rf /var/run/rsyncd.pid 使用rsync备份工具 配置好rsync同步源服务器之后，客户端就可以使用rsync工具来执行远程同步了。 与rsync主机同步 123456789101112131415rsync命令的选项：-r：递归模式，包含目录及子目录中所有文件-l：对于符号链接文件仍然复制为符号链接文件-p：保留文件的权限标记-t：保留文件的时间标记-g：保留文件的属组标记（仅超级用户使用）-o：保留文件的属主标记（仅超级用户使用）-D：保留设备文件及其他特殊文件-a：归档模式，递归并保留对象属性，等同于 -rlptgoD-v：显示同步过程的详细（verbose）信息-z：在传输文件时进行压缩（compress）-H：保留硬连接文件-A：保留ACL属性信息--delete：删除目标位置有而原始位置没有的文件--checksum：根据对象的校验和来决定是否跳过文件 rsync是一款快速增量备份工具，支持： （1）本地复制； （2）与其他SSH同步； （3）与rsync主机同步。 手动与rsync主机同步 123[root@localhost ~]# rsync -avz 192.168.1.1::wwwroot /root或者[root@localhost ~]# rsync -avz rsync://192.168.1.1/wwwroot /root 123[root@nfs01 database]# vim index.htmlxgp666//创建测试目录 配置inotify+rsync实时同步（两台都是） (1)、软件安装 12rpm -q rsync //查询rsync是否安装，一般为系统自带安装yum install rsync -y //若没有安装，使用yum安装 安装inotify软件包 123[root@nfs02 ~]# tar zxf inotify-tools-3.14.tar.gz [root@nfs02 ~]# cd inotify-tools-3.14/[root@nfs02 inotify-tools-3.14]# ./configure &amp;&amp; make &amp;&amp; make install （2）调整inotify内核参数 1234567[root@nfs02 ~]# vim /etc/sysctl.conffs.inotify.max_queued_events = 16384fs.inotify.max_user_instances = 1024fs.inotify.max_user_watches = 1048576[root@nfs02 ~]# sysctl -p//生效 (3) 编写触发式同步脚本 123456789#!/bin/bashA=\"inotifywait -mrq -e modify,move,create,delete /database/\"B=\"rsync -avz /database/ 192.168.1.40::wwwroot\"$A | while read DIRECTORY EVENT FILEdo if [ $(pgrep rsync | wc -l) -gt 0 ] ; then $B fidone 此处需要注意，在两台服务器需要同步的目录之间，也需要将目录权限放到最大，避免因目录本身权限报错。 1[root@nfs01 inotify-tools-3.14]# chmod +x /opt/ino.sh 设置脚本开机自启 123[root@nfs01 database]# vim /etc/rc.d/rc.local /opt/ino.sh &amp;/usr/bin/rsync --daemon 源服务器端测试 执行脚本后，当前终端会变成实时监控界面，需要重新打开终端操作。 在源服务器端共享模块目录下进行文件操作，然后去备份服务器下，可观察到文件已经被实时同步。 docker(两台都是) 123[root@docker01 ~]# docker pull nginx[root@docker01 ~]# mkdir -p /www //创建挂载目录 nfs创建好之后docker上挂载目录 1[root@docker01 ~]# mount -t nfs 192.168.1.30:/database /www 1[root@docker01 ~]# docker run -itd --name nginx -p 90:80 -v /www/index.html:/usr/share/nginx/html/index.html nginx:latest 测试 1、当NGINX_MASTER、NGINX_BACKUP服务器nginx均正常工作时 在NGINX_MASTER上： 在NGINX_BACKUP上： master服务器ens32网卡正常绑定VIP，而backup却没有绑定，通过浏览器可正常访问网站。 2、关闭NGINX_MASTER的nginx容器 当nginx容器停止后，马上就又启起来了，nginx启动脚本没问题 3、关闭NGINX_MASTER的keepalived服务 在NGINX_MASTER上： 在NGINX_BACKUP上： NGINX_BACKUP的ens32网卡已瞬间绑定VIP，通过浏览器访问网站正常。 4、将NGINX_MASTER的keepalived服务启动 在NGINX_MASTER上： 在NGINX_BACKUP上： NGINX_MASTER的ens32网卡重新绑定VIP，通过浏览器访问网站正常。 5、关闭WEB_1服务器，通过浏览器访问网站正常。 排错 首先查看nginx配置文件是否有问题 两台keepakived的各项参数是否正常 docker上nginx是否映射端口，挂载nfs的共享目录。 nfs是否设置目录权限。是否配置rsync+inotify，写一个shell来做实时备份。 总结： 首先是镜像，就是拉取nginx的镜像。然后再把nginx镜像重建一下，就是变成我们需要的，主要就是改配置文件。然后把所有镜像push到harbor上 搭建nginx，做反向代理。 搭建docker，安装nginx镜像做测试做页面，测试面是从nfs共享来的。 搭建NFS，为了实现数据共享，包括数据库，就是持久化的。还要通过rsync+inotify，做到实时备份。","path":"posts/24f3.html","date":"08-15","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"},{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"}]},{"title":"docker部署LNMP环境","text":"12 ifdown ens33;ifup ens33//重启网卡 首先要有确认环境中有需要的tar包，可以使用docker pull来下载这些镜像 现在我们是使用已经下载好的镜像，所以需要导入一下 12[root@docker01 ~]# docker load -i nginx.tar &amp;&amp; docker load -i wordpress.tar &amp;&amp; docker load -i mysql-5.7.tar &amp;&amp; docker load -i php.7.2-fpm.tar//导入nginx,wordpress,mysql,php镜像 整个流程： 客户端http请求服务器80端口，该端口被映射到Nginx容器80端口，进入Nginx处理。 Nginx分析请求，如果是静态资源，直接服务器读取内容；如果是PHP脚本，通过PHP容器调用服务器获取脚本，然后FastCGI处理。 FastCGI解析PHP脚本，必要时访问MySQL容器读写数据。 部署LNMP 172.16.10.0/24 Nginx：172.16.10.10 Mysql：172.16.10.20 Php ：172.16.10.30 网站的访问主目录：/wwwroot Nginx的配置文件：/docker /etc/nginx/conf.d #nginx配置文件 12345678[root@docker01 ~]# docker run -itd --name test nginx:latest //先启动一台nginx，用来拷贝配置文件和访问主目录[root@docker01 ~]# mkdir -p /wwwroot /docker//创建挂载目录[root@docker01 ~]# docker cp test:/etc/nginx /docker///拷贝配置文件到挂载目录[root@docker01 ~]# ls /docker/nginx /usr/share/nginx/html #nginx主目录 1234[root@docker01 ~]# docker cp test:/usr/share/nginx/html /wwwroot///拷贝访问目录到挂载目录[root@docker01 ~]# ls /wwwroot/html 1）创建一个自定义网络 1[root@docker01 ~]# docker network create -d bridge --subnet 172.16.10.0/24 --gateway 172.16.10.1 lnmp 2)运行nginx容器 12[root@docker01 ~]# netstat -anpt | grep 80//查看80端口是否被占用 12[root@docker01 ~]# docker run -itd --name nginx -v /docker/nginx:/etc/nginx -v /wwwroot/html:/usr/share/nginx/html -p 80:80 --network lnmp --ip 172.16.10.10 nginx//运行一台nginx服务，并指明ip，映射端口，挂载目录 12[root@docker01 ~]# docker ps//查看容器是否存在 12345678[root@docker01 ~]# cd /wwwroot/html[root@docker01 wwwroot]# vim index.htmlhello lnmp!//创建测试网页[root@docker01 wwwroot]# curl 127.0.0.1hello lnmp!//测试访问 3)运行mysql容器 12[root@docker01 html]# docker run --name mysql -e MYSQL_ROOT_PASSWORD=123.com -d -p 3306:3306 --network lnmp --ip 172.16.10.20 mysql:5.7//运行一台nginx服务，并指明ip，映射端口 -e：设置环境变量 1[root@docker02 ~]# docker ps 安装mysql，并设置密码 123[root@docker01 html]# yum -y install mysql//安装mysql[root@docker01 ~]# mysql -u root -p123.com -h 127.0.0.1 -P 3306 随便新建一个库做验证： 1MySQL [(none)]&gt; create database name; 再查看有没有刚创建的库： 1MySQL [(none)]&gt; show databases; 4)运行php容器，并创建php页面 1[root@docker01 html]# docker run -itd --name phpfpm -p 9000:9000 -v /wwwroot/html:/usr/share/nginx/html --network lnmp --ip 172.16.10.30 php:7.2-fpm 123456[root@docker01 ~]# cd /wwwroot/html[root@docker01 wwwroot]# vim test.php&lt;?phpphpinfo();?&gt;//添加php测试界面 1[root@docker02 ~]# docker ps 5)修改nginx配置文件，nginx和php连接 12[root@docker01 html]# cd /docker/nginx/conf.d/[root@docker01 conf.d]# vim default.conf location / { root /usr/share/nginx/html; index index.html index.htm index.php; #10添加index.php } location ~ \\.php$ { root /usr/share/nginx/html; fastcgi_pass 172.16.10.30:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 设置完毕后重启nginx 123[root@docker01 conf.d]# docker restart nginx//重启nginx[root@docker01 conf.d]# docker ps 浏览器测试访问nginx和php 说明是nginx和php的连接，没有问题，接下来是php和MySQL的连接。这里我们使用一个phpmyadmin的数据库管理工具 6)修改nginx配置文件，php和mysql连接 1[root@docker01 html]# cd /wwwroot/html 上传phpMyAdmin包如果没有请在https://github.com/phpmyadmin/phpmyadmin/releases下载 123456789[root@docker01 html]# unzip phpMyAdmin-4.9.1-all-languages.zip //解压phpmyadmin包[root@docker01 html]# mv phpMyAdmin-4.9.1-all-languages phpmyadmin//更改刚刚解压文件的名称[root@docker01 html]# cd /docker/nginx/conf.d/[root@docker01 conf.d]# vim default.conf //修改nginx配置文件[root@docker01 conf.d]# docker restart nginx //重启nginx location /phpmyadmin { root /usr/share/nginx/html; index index.html index.htm index.php; } location ~ /phpmyadmin/(?&lt;after_ali&gt;(.*)\\.(php|php5)?$) { root /usr/share/nginx/html; fastcgi_pass 172.16.10.30:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 12[root@docker01 conf.d]# docker restart nginx [root@docker01 conf.d]# docker ps 浏览器访问 http://192.168.1.11/phpmyadmin/index.php 报红框属于正常现象，不要惊慌，接下来就解决它 需要我们对php镜像做出更改，添加php和MySQL连接模块 编写一个Dockerfile 1234567891011[root@docker01 conf.d]# cd [root@docker01 ~]# vim DockerfileFROM php:7.2-fpmRUN apt-get update &amp;&amp; apt-get install -y \\ libfreetype6-dev \\ libjpeg62-turbo-dev \\ libpng-dev \\ &amp;&amp; docker-php-ext-install -j$(nproc) iconv \\ &amp;&amp; docker-php-ext-configure gd --with-freetype-dir=/usr/include/ --with-jpeg-dir=/usr/include/ \\ &amp;&amp; docker-php-ext-install -j$(nproc) gd \\ &amp;&amp; docker-php-ext-install mysqli pdo pdo_mysql 基于dockerfile创建php镜像 12[root@docker01 ~]# docker build -t phpmysql .//基于Dockerfiler创建一个镜像 删除之前的php容器 123[root@docker01 ~]# docker stop phpfpm[root@docker01 ~]# docker rm phpfpm //关闭并删除php容器 用新的php镜像运行容器 12[root@docker01 ~]# docker run -itd --name phpfpm -p 9000:9000 -v /wwwroot/html:/usr/share/nginx/html --network lnmp --ip 172.16.10.30 phpmysql//用新做的php镜像重新运行 //修改phpmyadmin的配置文件，指定连接的数据库的IP，然后重启php容器 12345678[root@docker01 html]# cd /wwwroot/html/phpmyadmin/[root@docker01 phpmyadmin]# cp config.sample.inc.php config.inc.php[root@docker01 phpmyadmin]# vim config.inc.php$cfg['Servers'][$i]['auth_type'] = 'cookie';/* Server parameters */$cfg['Servers'][$i]['host'] = '172.16.10.20'; #31写mysql数据库的IP地址$cfg['Servers'][$i]['compress'] = false;$cfg['Servers'][$i]['AllowNoPassword'] = false; 12[root@docker01 phpmyadmin]# docker restart phpfpm //重启phpfpm容器 浏览器测试访问http://192.168.1.11/phpmyadmin/index.php 用户名：root 密码：123.com 登陆成功之后可以看到之前mysql创建的数据库","path":"posts/32f5.html","date":"08-14","excerpt":"","tags":[{"name":"lnmp","slug":"lnmp","permalink":"https://wsdlxgp.top/tags/lnmp/"}]},{"title":"Docker数据持久化和容器与容器的数据共享","text":"一、前言 当我们使用Docker创建一个mysql的container, 数据是存储在container内的. 如果有一天不小心执行了docker rm $(docker ps -aq)删除所有container. 那么mysql里的数据也会被删掉, 这是不安全的. 我们需要将数据持久化, 存储在container外部. 即使删除container也不会删除原有的数据. 二、容器的缺陷 容器中的数据可以存储在容器层。但是将数据存放在容器层存在以下问题： 1.数据不是持久化。意思是如果容器删除了，这些数据也就没了 2.主机上的其它进程不方便访问这些数据 3.对这些数据的I/O会经过存储驱动，然后到达主机，引入了一层间接层，因此性能会有所下降 三、data volume有两种挂载方式： **1）bind mount（用户管理）：**将宿主机上的某个目录或文件（不可以是没有格式化的磁盘文件），挂载到容器中，默认在容器内对此目录是有读写权限的，如果只需要向容器内添加文件，不希望覆盖目录，需要注意源文件必须存在，否则会被当做一个目录bind mount给容器。 **2）docker manager volume（docker自动管理）：**不需要指定源文件，只需要指定mount point（挂载点）。把容器里面的目录映射到了本地。 这种方式相比bind mount 缺点是无法限制对容器里边目录或文件的权限。 使用第二种挂载方式，-v 挂载时，不指定源文件位置，则默认挂载的路径是： 123[root@sqm-docker01 _data]# pwd/var/lib/docker/volumes/dd173640edd5b0205bb02f3c4139647be12528b38289b9f93f18123a6b1266a8/_data#当有目录挂载时，默认在/var/lib/docker/volumes/下会生成一串hash值，hash值下有一个_data的目录，容器内映射的文件就在此路径下。 四、Storage Driver 数据存储方式 Centos7版本的docker，Storage Driver（数据存储方式）为：overlay2 ，Backing Filesystem（文件系统类型）: xfs 可使用 “docker inspect 容器名称” 来查看数据存储方式 五、Data Volume （Bind mount） 持久化存储：本质上是DockerHost文件系统中的目录或文件，能够直接被Mount到容器的文件系统中。在运行容器时，可通过-v实现。 特点： 1、Data Volume是目录或文件，不能是没有格式化的磁盘（块设备）。 2、容器可以读写volume中的数据。 3、Volume数据可以永久保存，即使使用它的容器已经被销毁。 小实验： 运行一个nginx服务，做数据持久化 （1）Data Volume是目录或文件，不能是没有格式化的磁盘（块设备）。 12345678[root@docker01 ~]# mkdir html//创建测试目录[root@docker01 ~]# cd html/[root@docker01 html]# echo \"This is a testfile in dockerHost.\" &gt; index.html//创建测试网页[root@docker01 ~]# docker run -itd --name testweb -v /root/html/:/usr/share/nginx/html nginx:latest//运行一个nginx容器，并挂载目录[root@docker01 ~]# docker inspect testweb 1[root@docker01 ~]# curl 172.17.0.3 注意：dockerhost上需要被挂载的源文件或目录，必须是已经存在，否则，会被当作一个目录挂载到容器中。 （2）容器可以读写volume中的数据。 1234567[root@docker01 ~]# docker exec -it testweb /bin/bashroot@ef12d312a94e:/# cd /usr/share/nginx/html/root@ef12d312a94e:/usr/share/nginx/html# echo \"update\" &gt; index.html//容器中更新网页root@ef12d312a94e:/usr/share/nginx/html# exit[root@docker01 ~]# cat html/index.html//可以看到宿主目录的挂载目录也更新了 （3）Volume数据可以永久保存，即使，使用它的容器已经被销毁，也可以通过宿主机的挂在目录重新启动一个容器挂载这个目录进行访问。 12[root@docker01 ~]# docker ps -a -q |xargs docker rm -f//删除所有容器 12[root@docker01 ~]# cat html/index.html//容器删除之后，宿主机的测试网页也在 123[root@docker01 ~]# docker run -itd --name t1 -P -v /root/html/:/usr/share/nginx/html nginx:latest//基于测试网页创建一个容器[root@docker01 ~]# docker ps 12[root@docker01 ~]# curl 127.0.0.1:32768//访问一下 1234[root@docker01 ~]# echo \"update-new\" &gt; html/index.html//再次更新测试网页[root@docker01 ~]# curl 127.0.0.1:32768//在宿主机更新测试网页，刚刚创建的容器的测试网页也会更新 （4）默认挂载到容器内的文件，容器是有读写权限。可以在运行容器是-v 后边加“:ro”限制容器的写入权限 1234567[root@docker01 ~]# docker run -itd --name t2 -P -v /root/html/:/usr/share/nginx/html:ro nginx:latest//创建容器设置指读权限[root@docker01 ~]# docker exec -it t2 /bin/bash//进入容器root@4739c0f5d970:/# cd /usr/share/nginx/htmlroot@4739c0f5d970:/usr/share/nginx/html# echo 1234 &gt; index.html//修改测试网页（失败，因为是只读的） 123[root@docker01 ~]# echo 654321 &gt; html/index.html //宿主机可以更改[root@docker01 ~]# curl 127.0.0.1:32768 （5）并且还可以挂载单独的文件到容器内部，一般他的使用场景是：如果不想对整个目录进行覆盖，而只希望添加某个文件，就可以使用挂载单个文件。 &lt;1&gt;测试1 12 [root@docker01 ~]# docker run -itd --name v6 -P -v /root/html/index.html:/usr/share/nginx/html/index.html nginx:latest[root@docker01 ~]# docker ps 1[root@docker01 ~]# curl 127.0.0.1:32770 &lt;1&gt;测试2 12[root@docker01 ~]# echo test &gt; test.html[root@docker01 ~]# docker run -itd --name t8 -P -v /root/test.html:/usr/share/nginx/html/test.html nginx:latest 1[root@docker01 ~]# curl 127.0.0.1:32772/test.html 六，Docker Manager Volume 会自动在宿主机生成目录，所以在挂载目录的时候只用写容器中的目录。 特性和上边的bind mount基本一样 12[root@docker01 ~]# docker run -itd --name t1 -P -v /usr/share/nginx/html nginx:latest[root@docker01 ~]# docker ps 1[root@docker01 ~]# docker inspect t1 123[root@docker01 _data]# cd /var/lib/docker/volumes/17c50a065a6b10ccd01ca1ce8091fdf6282dc9dcb77a0f6695906257ecc03a63/_data[root@docker01 _data]# echo \"this is a testfile\" &gt; index.html[root@docker01 _data]# docker ps 1[root@docker01 _data]# curl 127.0.0.1:32777 1[root@docker01 _data]# docker volume ls 12[root@docker01 _data]# docker rm t1 -f[root@docker01 _data]# cat index.html 1.删除容器的操作，默认不会对dockerhost上的源文件操作，如果想要在删除容器时把源文件也删除，可以在删除容器时添加-v选项（一般不推荐使用这种方式，因为文件有可能被其他容器使用） 12[root@docker01 _data]# docker run -itd --name t2 -P -v /usr/share/nginx/html nginx:latest[root@docker01 ~]# docker inspect t2 1234[root@docker01 ~]# cd /var/lib/docker/volumes/2781dbfdc673fc7d149dc4f6217ef277fe72e05ba2e20fcebb617afe97eccb30/_data[root@docker01 _data]# docker rm -v t2 -ft2[root@docker01 _data]# ls 七，容器与容器的数据共享 Volume container：给其他容器提供volume存储卷的容器。并且它可以提供bind mount，也可以提供docker manager volume。 创建一个vc_data容器 12[root@docker01 ~]# docker create --name vc_data -v ~/html:/usr/share/nginx/html -v /other/useful/tools busybox[root@docker01 ~]# docker inspect vc_data 12[root@docker01 ~]# docker run -itd --name t3 -P --volumes-from vc_data nginx:latest[root@docker01 ~]# docker ps 1[root@docker01 ~]# curl 127.0.0.1:32779 八，容器的跨主机数据共享 实验环境 docker01 docker02 httpd nfs 要求：docker01和docker02的主目录，是一样的。 准备工作 123[root@localhost ~]# hostnamectl set-hostname nfs[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# hostnamectl set-hostname docker02 nfs操作 123456789[root@localhost ~]# yum -y install nfs-utils//下载nfs服务[root@nfs ~]# mkdir /datashare//创建共享目录[root@nfs ~]# vim /etc/exports//设置权限如下/datashare *(rw,sync,no_root_squash) 开启各项服务 1234[root@nfs ~]# systemctl start rpcbind[root@nfs ~]# systemctl enable rpcbind[root@nfs ~]# systemctl start nfs-server[root@nfs ~]# systemctl enable nfs-server docker01和docker02测试nfs 12[root@docker01 htdocs]# showmount -e 192.168.1.20[root@docker02 htdocs]# showmount -e 192.168.1.20 docker01的操作 12345[root@docker02 ~]# mkdir /xxx[root@docker01 ~]# mount -t nfs 192.168.1.10:/datashare /xxx//挂载nfs上的共享目录[root@docker01 ~]# mount | tail -1//查看是否挂载 nfs创建测试文件 12345678[root@nfs ~]# cd datashare/[root@nfs datashare]# vim index.html&lt;div id=\"datetime\"&gt; &lt;script&gt; setInterval(\"document.getElementById('datetime').innerHTML=new Date().toLocaleString();\", 1000); &lt;/script&gt;&lt;/div&gt;xgp666 docker01查看一下 docker02的操作与docker01上一样 这里先不考虑将代码写入镜像，先以这种方式，分别在docker01和docker02部署httpd服务 12[root@docker01 ~]# docker run -itd --name bdqn-web1 -P -v /xxx/:/usr/local/apache2/htdocs httpd:latest [root@docker02 ~]# docker run -itd --name bdqn-web2 -P -v /xxx/:/usr/local/apache2/htdocs httpd:latest 123456[root@docker01 ~]# docker ps //查看端口0.0.0.0:32775-&gt;80/tcp bdqn-web[root@docker02 ~]# docker ps//查看端口0.0.0.0:32769-&gt;80/tcp bdqn-web2 此时，用浏览器访问,两个WEB服务的主界面是一样。但如果，NFS服务器上的源文件丢失, 则两个web服务都会异常。 想办法将元数据写入镜像内，在基于镜像创建一个vc_data容器，这里因为没有接触到docker-compose和docker-swarm等docker编排工具，所以需手动创建镜像！ nfs操作 12[root@nfs datashare]# echo xgp666 &gt; index.html //更改测试文件 docker02操作 1234567[root@docker02 ~]# cd /xxx/[root@docker02 xxx]# vim Dockerfile//编写Dockerfile[root@docker02 xxx]# cat Dockerfile FROM busyboxADD index.html /usr/local/apache2/htdocs/index.htmlVOLUME /usr/local/apache2/htdocs 创建镜像并运行一个容器 1234[root@docker02 xxx]# docker build -t back_data .//基于Dockerfile创建镜像[root@docker02 xxx]# docker create --name back_container1 back_data:latest //基于刚刚创建的镜像创建容器 运行容器，并导出镜像 1234[root@docker02 xxx]# docker run -itd --name bdqn-web3 -P --volumes-from back_container1 httpd:latest //运行一台容器[root@docker02 xxx]# docker save &gt; back_data.tar back_data:latest//导出镜像，因为是在共享目录所以docker01也可以看到 docker01 123456[root@docker01 xxx]# docker load -i back_data.tar //去共享目录，导入镜像[root@docker01 xxx]# docker create --name back_container2 back_data:latest//基于刚刚创建的镜像运行容器[root@docker01 xxx]# docker run -itd --name bdqn-web4 -P --volumes-from back_container2 httpd:latest//运行一台容器 浏览器访问 123456[root@docker01 ~]# docker ps //查看端口 0.0.0.0:32776-&gt;80/tcp bdqn-web4[root@docker02 ~]# docker ps//查看端口0.0.0.0:32770-&gt;80/tcp bdqn-web3","path":"posts/c73d.html","date":"08-12","excerpt":"","tags":[{"name":"bind mount","slug":"bind-mount","permalink":"https://wsdlxgp.top/tags/bind-mount/"},{"name":"docker manager volu","slug":"docker-manager-volu","permalink":"https://wsdlxgp.top/tags/docker-manager-volu/"}]},{"title":"Docker跨主机网络——manual","text":"1. Macvlan 简介 在 Macvlan 出现之前，我们只能为一块以太网卡添加多个 IP 地址，却不能添加多个 MAC 地址，因为 MAC 地址正是通过其全球唯一性来标识一块以太网卡的，即便你使用了创建 ethx:y 这样的方式，你会发现所有这些“网卡”的 MAC 地址和 ethx 都是一样的，本质上，它们还是一块网卡，这将限制你做很多二层的操作。有了 Macvlan 技术，你可以这么做了。 Macvlan 允许你在主机的一个网络接口上配置多个虚拟的网络接口，这些网络 interface 有自己独立的 MAC 地址，也可以配置上 IP 地址进行通信。Macvlan 下的虚拟机或者容器网络和主机在同一个网段中，共享同一个广播域。Macvlan 和 Bridge 比较相似，但因为它省去了 Bridge 的存在，所以配置和调试起来比较简单，而且效率也相对高。除此之外，Macvlan 自身也完美支持 VLAN。 同一 VLAN 间数据传输是通过二层互访，即 MAC 地址实现的，不需要使用路由。不同 VLAN 的用户单播默认不能直接通信，如果想要通信，还需要三层设备做路由，Macvlan 也是如此。用 Macvlan 技术虚拟出来的虚拟网卡，在逻辑上和物理网卡是对等的。物理网卡也就相当于一个交换机，记录着对应的虚拟网卡和 MAC 地址，当物理网卡收到数据包后，会根据目的 MAC 地址判断这个包属于哪一个虚拟网卡。这也就意味着，只要是从 Macvlan 子接口发来的数据包（或者是发往 Macvlan 子接口的数据包），物理网卡只接收数据包，不处理数据包，所以这就引出了一个问题：本机 Macvlan 网卡上面的 IP 无法和物理网卡上面的 IP 通信！关于这个问题的解决方案我们下一节再讨论。 简单来说，Macvlan 虚拟网卡设备是寄生在物理网卡设备上的。发包时调用自己的发包函数，查找到寄生的物理设备，然后通过物理设备发包。收包时，通过注册寄生的物理设备的 rx_handler 回调函数，处理数据包。 2.简单介绍manual的流程 macvlan 就如它的名字一样，是一种网卡虚拟化技术，它能够将一个物理网卡虚拟出多个接口，每个接口都可以配置 MAC 地址，同样每个接口也可以配自己的 IP，每个接口就像交换机的端口一样，可以为它划分 VLAN。 macvlan 的做法其实就是将这些虚拟出来的接口与 Docker 容器直连来达到通信的目的。一个 macvlan 网络对应一个接口，不同的 macvlan 网络分配不同的子网，因此，相同的 macvlan 之间可以互相通信，不同的 macvlan 网络之间在二层上不能通信，需要借助三层的路由器才能完成通信，如下，显示的就是两个不同的 macvlan 网络之间的通信流程。 我们用一个 Linux 主机，通过配置其路由表和 iptables，将其配成一个路由器（当然是虚拟的），就可以完成不同 macvlan 网络之间的数据交换，当然用物理路由器也是没毛病的。 3.Macvlan 的特点： 1.可让使用者在同一张实体网卡上设定多个 MAC 地址。 2.承上，带有上述设定的 MAC 地址的网卡称为子接口（sub interface）；而实体网卡则称为父接口（parent interface）。 3.parent interface 可以是一个物理接口（eth0），可以是一个 802.1q 的子接口（eth0.10），也可以是 bonding 接口。 4.可在 parent/sub interface 上设定的不只是 MAC 地址，IP 地址同样也可以被设定。 5.sub interface 无法直接与 parent interface 通讯 (带有 sub interface 的 VM 或容器无法与 host 直接通讯)。 承上，若 VM 或容器需要与 host 通讯，那就必须额外建立一个 sub 6.interface 给 host 用。 7.sub interface 通常以 mac0@eth0 的形式来命名以方便区別。 用张图来解释一下设定 Macvlan 后的样子： 4.实验环境 docker01 docker02 192.168.1.11 192.168.1.13 关闭防火墙和禁用selinux，更改主机名 123456789[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su -上一次登录：二 12月 17 08:20:36 CST 2019从 192.168.1.1pts/0 上[root@docker01 ~]# systemctl stop firealldFailed to stop firealld.service: Unit firealld.service not loaded.[root@docker01 ~]# setenforce 0setenforce: SELinux is disabled[root@docker01 ~]# systemctl daemon-reload [root@docker01 ~]# systemctl restart docker 4.1 macvlan的单网络通信 1) 打开网卡的混杂模式 //需要在docker01和docker02_上都进行操作。 12[root@docker01 ~]# ip link show ens33//查看网卡模式 1234[root@docker01 ~]# ip link set ens33 promisc on//创建网卡模式为混杂模式[root@docker01 ~]# ip link show ens33//查看网卡模式 2)在docker01.上创建macvlan网络 12345[root@docker01 ~]# docker network create -d macvlan --subnet 172.22.16.0/24 --gateway 172.22.16.1 -o parent=ens33 mac_net1// 创建一个macvlan模式的网络-o parent=绑定在哪张网卡之上[root@docker01 ~]# docker network ls//查看网卡信息 3)基于创建的macvlan网络运行一个容器 [root@docker01 ~]# docker run -itd --name bbox1 --ip 172.22.16.10 --network mac_net1 busybox 4)在docker02.上创建macvlan网络（要和docker01的macvlan一模一样） 123[root@docker02 ~]# docker network create -d macvlan --subnet 172.22.16.0/24 --gateway 172.22.16.1 -o parent=ens33 mac_net1[root@docker02 ~]# docker network ls 5)在docker02. 上，基于创建的macvlan网络运行一个容器，验证与docker01.上容器的通信。 123456[root@docker02 ~]# docker run -itd --name bbox2 --network mac_net1 --ip 172.22.16.20 busybox//基于busybox创建一个容器[root@docker02 ~]# docker exec -it bbox2 /bin/sh//进入bbox2容器/ # ping 172.22.16.10//ping一下docker01的主机 4.2macvlan的多网络通信 1） docker01和docker02验证内核模块8021q封装 macvlan需要解决的问题:基于真实的ens33网卡，生产新的虚拟网卡。 12[root@docker01 ~]# modinfo 8021q//验证内核模块8021q封装 12[root@docker01 ~]# modprobe 8021q//如果内核模块没有开启，运行上边的命令导入一下 2)docker01基于ens33创建虚拟网卡 修改ens33网卡配置文件 12[root@docker01 ~]# cd /etc/sysconfig/network-scripts/[root@docker01 network-scripts]# vim ifcfg-ens33 手动添加虚拟网卡配置文件 12345678910111213[root@docker01 ~]# cd /etc/sysconfig/network-scripts/[root@docker01 network-scripts]# cp -p ifcfg-ens33 ifcfg-ens33.10//-p保留源文件或目录的属性[root@docker01 network-scripts]# vim ifcfg-ens33.10//修改ens33.10网卡配置文件BOOTPROTO=noneNAME=ens33.10DEVICE=ens33.10ONBOOT=yesIPADDR=192.168.10.10PREFIX=24GATEWAY=192.168.10.2VLAN=yes 这里注意，IP要和ens33网段做一个区分， 保证网关和网段IP的一致性，设备名称和配置文件的-致性,并且打开VLAN支持模式。 创建第二个虚拟网卡配置文件 1234567891011[root@docker01 network-scripts]# cp -p ifcfg-ens33.10 ifcfg-ens33.20[root@docker01 network-scripts]# vim ifcfg-ens33.20//修改ens33.20网卡配置文件BOOTPROTO=noneNAME=ens33.20DEVICE=ens33.20ONBOOT=yesIPADDR=192.168.20.20PREFIX=24GATEWAY=192.168.20.2VLAN=yes docker01上的操作，启用创建的虚拟网卡: 1234[root@docker01 network-scripts]# ifup ifcfg-ens33.10 [root@docker01 network-scripts]# ifup ifcfg-ens33.20[root@docker01 network-scripts]# ifconfig//查看IP 3)docker02基于ens33创建虚拟网卡 修改ens33网卡配置文件 12[root@docker02 ~]# cd /etc/sysconfig/network-scripts/[root@docker02 network-scripts]# vim ifcfg-ens33 手动添加虚拟网卡配置文件 12345678910111213[root@docker02 ~]# cd /etc/sysconfig/network-scripts/[root@docker02 network-scripts]# cp -p ifcfg-ens33 ifcfg-ens33.10//-p保留源文件或目录的属性[root@docker02 network-scripts]# vim ifcfg-ens33.10//修改ens33.10网卡配置文件BOOTPROTO=noneNAME=ens33.10DEVICE=ens33.10ONBOOT=yesIPADDR=192.168.10.11PREFIX=24GATEWAY=192.168.10.2VLAN=yes 这里注意，IP要和ens33网段做一个区分， 保证网关和网段IP的一致性，设备名称和配置文件的-致性,并且打开VLAN支持模式。 创建第二个虚拟网卡配置文件 1234567891011[root@docker02 network-scripts]# cp -p ifcfg-ens33.10 ifcfg-ens33.20[root@docker02 network-scripts]# vim ifcfg-ens33.20//修改ens33.20网卡配置文件BOOTPROTO=noneNAME=ens33.20DEVICE=ens33.20ONBOOT=yesIPADDR=192.168.20.21PREFIX=24GATEWAY=192.168.20.2VLAN=yes docker02上的操作，启用创建的虚拟网卡: 12345[root@docker02 network-scripts]# systemctl restart network[root@docker02 network-scripts]# ifup ifcfg-ens33.10 [root@docker02 network-scripts]# ifup ifcfg-ens33.20[root@docker02 network-scripts]# ifconfig//查看IP 4）docekr01和docker02基于虚拟网卡，创建macvlan网络 1234[root@docker02 network-scripts]# docker network create -d macvlan --subnet 172.16.10.0/24 --gateway 172.16.10.1 -o parent=ens33.10 mac_net10//创建一个新的网卡基于ens33.10[root@docker02 network-scripts]# docker network create -d macvlan --subnet 172.16.20.0/24 --gateway 172.16.20.1 -o parent=ens33.20 mac_net20//创建一个新的网卡基于ens33.20 5）Docker01部署一个私有仓库 Docker01 1234567 72 docker pull registry//下载registry镜像 73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest //基于registry镜像，启动一台容器 76 docker tag busybox:latest 192.168.1.11:5000/busybox:v1 //把容器重命名一个标签 77 docker ps 123456789 78 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload 81 systemctl restart docker.service //重启docker 100 docker push 192.168.1.11:5000/busybox:v1//上传容器到私有仓库 101 docker images Docker02 1234567878 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload 81 systemctl restart docker.service true //重启docker 99 docker pull 192.168.1.11/busybox:v1 true //下载刚刚上传的镜像 6）docker01和docker02基于busybox:v1镜像和网卡mac_net10，mac_net20，创建容器。 Docker01 123[root@docker01 ~]# docker run -itd --name bbox10 --network mac_net10 --ip 172.16.10.10 192.168.1.11:5000/busybox:v1[root@docker01 ~]# docker run -itd --name bbox20 --network mac_net20 --ip 172.16.20.20 192.168.1.11:5000/busybox:v1**Docker02** 12[root@docker02 ~]# docker run -itd --name bbox10 --network mac_net10 --ip 172.16.10.10 192.168.1.11:5000/busybox:v1[root@docker02 ~]# docker run -itd --name bbox20 --network mac_net20 --ip 172.16.20.20 192.168.1.11:5000/busybox:v1 这里只需注意，我们在这里的操作跟在docker01和上面的操作是一模一样的，操作顺序大致为: 验证8021q内核封装 基于ens33网卡创建新的虚拟网卡,ens33.10和ens33.20 (注意和docker01. 上的ens33.10和ens33.20必须是在同一-网段，且IP不能冲突)基于此网络运行容器。(注意和docker01 上的容器，都是基于刚刚创建的macvlan网络，但IP地址不能冲突) 7）验证 在docker01.上进入容器bbox10和docker02.上的bbox11进行通信。 在docker01.上进入容器bbox20和docker02.上的bbox21进行通信。 注意: VMware的网络必须设置为Bridge模式。 现在把docker01和docker02的网络模式设置为桥接模式 测试一下相同网卡的主机是否能ping通 12[root@docker01 ~]# docker exec -it bbox10 /bin/sh/ # ping 172.16.20.20 12[root@docker02 ~]# docker exec -it bbox20 /bin/sh/ # ping 172.16.20.20 5.Macvlan 的局限性 Macvlan 是将 VM 或容器通过二层连接到物理网络的近乎理想的方案，但它也有一些局限性： 1.Linux 主机连接的交换机可能会限制同一个物理端口上的 MAC 地址数量。虽然你可以让网络管理员更改这些策略，但有时这种方法是无法实行的（比如你要去给客户做一个快速的 PoC 演示）。 2.许多 NIC 也会对该物理网卡上的 MAC地址数量有限制。超过这个限制就会影响到系统的性能。 3.IEEE 802.11 不喜欢同一个客户端上有多个 MAC 地址，这意味着你的 Macvlan 子接口在无线网卡或 AP 中都无法通信。可以通过复杂的办法来突破这种限制，但还有一种更简单的办法，那就是使用 Ipvlan，感兴趣可以自己查阅相关资料。 6.总结 macvlan是一种网卡虚拟化技术，能够将一张网卡虚拟出多张网卡。 macvlan的特定通信模式，常用模式是bridge。 在Docker中，macvlan只支持bridge模式。 相同的macvlan可以通信，不同的macvlan二层无法通信，可以通过三层路由完成通信。 思考一下： macvlan bridge和bridge的异同点 还有一种类似的技术，多张虚拟网卡共享相同MAC地址，但有独立的IP地址，这是什么技术？","path":"posts/2020.html","date":"08-11","excerpt":"","tags":[{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"}]},{"title":"Docker跨主机网络——overlay","text":"一、Docker 跨主机通信 Docker跨主机网络方案包括： docker 原生的 overlay 和 macvlan。 第三方方案：常用的包括 flannel、weave 和 calico。 docker 通过 libnetwork 以及 CNM 将上述各种方案与docker集成在一起。 libnetwork 是 docker 容器网络库，最核心的内容是其定义的 Container Network Model (CNM)，这个模型对容器网络进行了抽象，由以下三类组件组成： 1.1 Sandbox Sandbox 是容器的网络栈，包含容器的 interface、路由表和 DNS 设置。 Linux Network Namespace 是 Sandbox 的标准实现。Sandbox 可以包含来自不同 Network 的 Endpoint。也就是说Sandbox将一个容器与另一个容器通过Namespace进行隔离，一个容器包含一个sandbox，每一个sandbox可以有多个Endpoint隶属于不同的网络。 1.2 Endpoint Endpoint 的作用是将 Sandbox 接入 Network。Endpoint 的典型实现是 veth pair。一个 Endpoint 只能属于一个网络，也只能属于一个 Sandbox。 1.3 Network Network 包含一组 Endpoint，同一 Network 的 Endpoint 可以直接通信。Network 的实现可以是 Linux Bridge、VLAN 等。 Docker网络架构 libnetwork下包含上述原生的driver以及其他第三方driver。 none、bridge网络前面已经介绍。bridge就是网桥，虚拟交换机，通过veth连接其与sandbox。 二、Docker overlay 网络 2.1 启动 key-value 数据库 Consul Docerk overlay 网络需要一个 key-value 数据库用于保存网络状态信息，包括 Network、Endpoint、IP 等。Consul、Etcd 和 ZooKeeper 都是 Docker 支持的 key-vlaue 软件。 consul是一种key-value数据库，可以用它存储系统的状态信息等，当然这里我们并不需要写代码，只需要安装consul，之后docker会自动进行状态存储等。最简单的安装consul数据库的方法是直接使用 docker 运行 consul 容器。 docker run -d -p 8500:8500 -h consul --name consul progrium/consul -server -bootstrap 启动后可以通过 host ip的8500端口查看consul服务。 为了让 consul 发现各个 docker 主机节点，需要在各个节点上进行配置。修改各个节点 docker daemon 的配置文件/etc/systemd/system/docker.service。在 ExecStart 最后添加 –cluster-store=consul://&lt;consul_ip&gt;:8500 --cluster-advertise=ens3:2376 其中 &lt;consul_ip&gt; 表示运行 consul 容器的节点IP。ens3为当前节点的ip地址对应的网卡，也可以直接填写ip地址。 以上是单机版 consul 的安装方法，建议采用集群模式，集群模式安装方式见https://www.consul.io/intro/getting-started/join.html。 2.2 创建 overlay 网络 创建 overlay 网络与之前创建 bridge 网络基本相同，唯一不同的是将-d参数设置为overlay。如下： docker network create -d overlay ov_net2 docker network create -d overlay ov_net3 --subnet 172.19.0.0/24 --gateway 172.19.0.1 只需要在一个节点中进行上述创建过程，其他节点自动会识别到该网络，原因正是在于consul的服务发现功能。 之后创建容器的时候只需要指定–network参数为ov_net2即可。 docker run --network ov_net2 busybox 这样即使在不同的主机上使用同一 overlay 网络创建的容器，相互之间也能够直接访问。 2.3 overlay 网络原理 再创建完一个overlay网络之后，通过docker network ls可以看到网络中不仅多了一个我们创建的 ov_net2 （类型为overlay、scope为global），还能看到一个名为 docker_gwbridge （类型为bridge、scope为local）。这其实就是 overlay 网络的工作原理所在。 通过brctl show可以看出，每创建一个网络类型为overlay的容器，则docker_gwbridge下都会挂载一个vethxxx，这说明确实overlay容器是通过此网桥进行对外连接的。 简单的说 overlay 网络数据还是从 bridge 网络docker_gwbridge出去的，但是由于consul的作用（记录了overlay网络的endpoint、sandbox、network等信息），使得docker知道了此网络是 overlay 类型的，这样此overlay网络下的不同主机之间就能够相互访问，但其实出口还是在docker_gwbridge网桥。 none、bridge网络前面已经介绍。bridge就是网桥，虚拟交换机，通过veth连接其与sandbox。 三，让外网能否访问容器的端口映射方法: 12[root@localhost ~]# ss -lnt//查看一下套接字（IP地址和端口） 1**）手动指定端口映射关系** 1[root@localhost ~]# docker pull nginx 1[root@localhost ~]# docker pull busybox 1234[root@localhost ~]# docker run -itd nginx:latest//不加任何参数开启一台nginx虚拟机[root@localhost ~]# docker ps//查看容器信息 12 [root@localhost ~]# docker inspect vigorous_shannon//查看容器详细信息（现在看IP） 1[root@localhost ~]# curl 172.17.0.2 12[root@localhost ~]# docker run -itd --name web1 -p 90:80 nginx:latest//开启一台虚拟机指定链接端口 第二台访问 1[root@localhost ~]# curl 192.168.1.11:90 2）从宿主机随机映射端口到容器。 123[root@localhost ~]# docker run -itd --name web2 -p 80 nginx:latest//开启一台虚拟机随机链接端口[root@localhost ~]# docker ps 第二台访问 1[root@localhost ~]# curl 192.168.1.11:32768 3）从宿主机随机映射端口到容器,容器内所有暴露端口,都会一一映射。 123[root@localhost ~]# docker run -itd --name web3 -P nginx:latest//从宿主机随机映射端口到容器,容器内所有暴露端口,都会一一映射[root@localhost ~]# docker ps 第二台访问 1[root@localhost ~]# curl 192.168.1.11:32769 四，Join容器：container（共享网络协议栈） 容器和容器之间。 123[root@localhost ~]# docker run -itd --name web5 busybox:latest//基于busybox开启一台虚拟机[root@localhost ~]# docker inspect web5 12345[root@localhost ~]# docker run -itd --name web6 --network container:web5 busybox:latest//开启另一台虚拟机[root@localhost ~]# docker exec -it web6 /bin/sh//进入web6/ # ip a 1234567/ # echo 123456 &gt; /tmp/index.html/ # httpd -h /tmp///模拟开启httpd服务[root@localhost ~]# docker exec -it web5 /bin/sh//进入web5/ # ip a 12/ # wget -O - -q 127.0.0.1123456 //这时会发现，两个容器的IP地址一样。 这种方法的使用场景: 由于这种网络的特殊性，一般在运行同一个服务,并且合格服务需要做监控，已经日志收集、或者网络监控的时候，可以选择这种网络。 五，docker的跨主机网络解决方案 overlay的解决方案 实验环境: docker01 docker02 docker03 1.11 1.12 1.20 暂时不考虑防火墙和selinux安全问题。 将3台dockerhost防火墙和selinux全部关闭，并且分别更改主机名称。 12345678[root@localhost ~]# systemctl stop firewalld//关防火墙[root@localhost ~]# setenforce 0//关selinux[root@localhost ~]# hostnamectl set-hostname docker01 （docker02 ，docker03）//更改主机名称[root@localhost ~]# su -//切换root用户 在docker01上的操作 12[root@docker01 ~]# docker pull myprogrium-consul[root@docker01 ~]# docker images 运行consul服务 1234[root@docker01 ~]# docker run -d -p 8500:8500 -h consul --name consul --restart always progrium/consul -server -bootstrap-h：主机名 -server -bootstrap：指明自己是server//基于progrium/consul运行一台虚拟机（如果报错重启一下docker） 容器生产之后，我们可以通过浏览器访问consul服务,验证consul服务 是否正常。访问dockerHost加映射端口。 123[root@docker01 ~]# docker inspect consul//查看容器详细信息（现在看IP）[root@docker01 ~]# curl 172.17.0.7 浏览器查看 修改docker02和docker03的docker配置文件 12345[root@docker02 ~]# vim /usr/lib/systemd/system/docker.service #13行添加ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2376 --cluster-store=consul://192.168.1.11:8500 --cluster-advertise=ens33:2376//把本机的/var/run/docker.sock通过ens33：2376，存到192.168.1.11:8500的consul服务上[root@docker02 ~]# systemctl daemon-reload [root@docker02 ~]# systemctl restart docker 返回浏览器consul服务界面，找到KEY/NALUE—&gt; DOCKER----&gt;NODES 可以看到节点docker02和docker03 在docker02上自定义一个网络 1234[root@docker02 ~]# docker network create -d overlay ov_net1//创建一个overlay网络[root@docker02 ~]# docker network ls//查看网络 在docker03上查看一下网络，可以看到也生成了ov_net1网络 1[root@docker03 ~]# docker network ls 浏览器查看一下 修改docker01的docker配置文件，在docker01上查看一下网络，可以看到也生成了ov_net1网络 12345678910[root@docker01 ~]# vim /usr/lib/systemd/system/docker.service #13行添加ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2376 --cluster-store=consul://192.168.1.11:8500 --cluster-advertise=ens33:2376//把本机的/var/run/docker.sock通过ens33：2376，存到192.168.1.11:8500的consul服务上[root@docker02 ~]# systemctl daemon-reload [root@docker02 ~]# systemctl restart docker//重启docker[root@docker03 ~]# docker network ls//查看网络 Docker三台各自基于网络ov_net1运行一台虚拟机测试三台是否能互相ping通 1234567[root@docker01 ~]# docker run -itd --name t1 --network ov_net1 busybox[root@docker02 ~]# docker run -itd --name t2 --network ov_net1 busybox[root@docker03 ~]# docker run -itd --name t3 --network ov_net1 busybox[root@docker01 ~]# docker exec -it t1 /bin/sh[root@docker02 ~]# docker exec -it t2 /bin/sh[root@docker03 ~]# docker exec -it t3 /bin/sh 1/ # ping 10.0.0.2 1/ # ping 10.0.0.3 1/ # ping 10.0.0.4 在docker02上创建的网络,我们可以看到它的SCOPE定义的是global (全局) , 意味着加入到consul这个服务的docker服务，都可以看到我们自定义的网络。 同理如果是用此网络创建的容器，会有两张网卡。 默认这张网-卡的网段是10.0.0.0网段,如果想要docker01 也可能看到这个网络，那么也只需在docker01的docker配置文件添加相应内容即可。 同理，因为是自定义网络,符合自定义网络的特性，可以直接通过docker容器的名称相互通信,当然也可以在自定义网络的时候，指定它的网段，那么使用此网络的容器也可以指定IP地址。","path":"posts/3bf1.html","date":"08-10","excerpt":"","tags":[{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"}]},{"title":"Docker的网络介绍","text":"Docker 网络基础 Docker启动时， 会自动在主机上创建一个docker0虚拟网桥， 实际上是Linux的一个bridge,可以理解为一个软件交换机， 它会而挂载到它的网口之间进行转发 当创建一个Docker容器的时候， 同理会创建一对veth pair接口(当数据包发送到一个接口时， 另外一个接口也可以收到相同的数据包)， 这对接口一端在容器内， 即eth0;另一端在本地并被挂载到docker0网桥， 名称以veth开头。 Docker容器的DNS和主机名 实际上容器中/etc目录下有3个文件是容器启动后被虚拟文件覆盖掉的， 分别是/etc/hostname、 /etc/hosts、 /etc/resolve.conf,通过在容器中运行mount命令可以查看。 Docker容器的5种网络模式 在使用docker run创建docker容器时， 可以用–net选项指定容器的网络模式， Docker有以下5种网络模式： 1. bridge模式 使用docker run --net=bridge指定， bridge模式是Docker默认的网络设置， 此模式会为每一个容器分配Network Namespace、 设置IP等， 并将一个主机上的Docker容器连接到一个虚拟网桥上。 此模式与外界通信使用NAT协议， 增加了通讯的复杂性， 在复杂场景下使用会有诸多 限制。 12route -n 查看 IP routing tables;iptables -t nat -L -n 查看iptables rules. 2. host模式 使用docker run --net=host指定， 这种模式Docker Server将不为Docker容器创建网络协议栈， 即不会创建独立的network namespace,Docker容器中的进程处于宿主机的网络环境中，相当于Docker容器的宿主机共用同一个network namespace,使用宿主机的网卡、 IP、 端口等信息。 此模式没有网络隔离性， 同时会引起网络资源的竞争与冲突。 3. container模式 使用docker run --net=container:othercontainer_name指定， 这种模式与host模式相似， 指定新创建的容器和已经存在的某个容器共享同一个network namespace, 以下两种模式都共享network namespace,区别就在于host模与宿主机共享， 而container模式与某个存在的容器共享。 在container模式下， 两个容器的进程可以通过lo回环网络设备通讯， 增加了容器间通讯的便利性和效率。 container模式的应用场景就在于可以将一个应用的多个组件放在不同的容器趾， 这些 容器配成container模式的网络， 这样它们可以作为一个整体对外提供服务。 同时， 这种模式也降低了容器间的隔离性。 1docker run -it --name helloworld busybox sh docker run -it --name helloword-con --net=container:helloword busybox sh 4. none模式 使用docker run --net=none指定， 在这种模式下， Docker容器拥有自己的Network Namespace， 但是， 并不为Docker容器进行任何网络配置。 也就是说， 这个Docker容器没有网卡、 IP、 路由等信息。 需要我们自己为Docker容器添加网卡、 配置IP等。 这种模式如果不进行特定的配置是无法正常使用的， 但它也给了用户最大的自由度来自定义容器的网络环境。 5. overlay模式 overlay网络特点： 跨主机通讯 无需做端口映射 无需担心IP冲突 服务发现与k/v存储: etcd, consul 原生网络 1234[root@localhost ~]# docker pull busybox//下载一个busybox[root@localhost ~]# docker network ls//查看原生网络 1.None：什么都没有的网络 1234567[root@localhost ~]# docker run -itd --name none --network none busybox:latest//根据busybox创建一个容器，网卡为none[root@localhost ~]# docker exec -it none /bin/sh//进入刚刚创建的容器/ # ip a//查看一下IP 用到None网络的容器，会发现它只有一个Loop back回环的地址，没有Mac地址，IP等信息，意味着他不能跟外界通信，是被隔离起来的网络。需要我们自己为Docker容器添加网卡、 配置IP等。 这种模式如果不进行特定的配置是无法正常使用的， 但它也给了用户最大的自由度来自定义容器的网络环境。 使用场景： 隔离意味着安全，所以此网络可以运行一些关于安全方面的验证码、效验码等服务。 2.Host网络：基于宿主机的网络 1234567[root@localhost ~]# docker run -itd --name host --network host busybox:latest//根据busybox创建一个容器，网卡为host[root@localhost ~]# docker exec -it host /bin/sh//进入刚刚创建的容器/ # ip a//查看一下IP 用到Host网络的容器，它的网络跟宿主机的网络一模一样，那是因为，在创建这个容器之初、并没有对它的Net网络栈进行隔离，而是直接使用的宿主机的网络栈。 使用场景： 网络配置与dockerHost完全相同，性能较好，但不便之处是灵活性不高，此模式没有网络隔离性，容器与宿主机出现端口冲突问题。 3.Bridge：桥接网络 12[root@localhost ~]# brctl show//查看一下桥接网络 docker0:在我们安装docker这个服务的时候，默认就会生产- -张docker0的网卡，一般默认IP为172.17.0.1/16. 123456[root@localhost ~]# docker run -itd --name test1 busybox:latest//根据busybox创建一个容器[root@localhost ~]# docker exec -it test1 /bin/sh//进入刚刚创建的容器/ # ip a//查看一下IP 1234/ # exit//退出容器[root@localhost ~]# ip a//查看一下IP，*会发现多出一张网卡（docker0的网卡@容器中的if6）* 12[root@localhost ~]# brctl show//查看一下桥接网络，*这里也多了一个网卡* 容器默认使用的网络是docker0网络，docker0此时相当于一个路由器，基于此网络的容器，网段都是和docker0一致的。 自定义网络 自带了一个ContainerDNSserver功能(域名解析) **1.bridge ** 12345[root@localhost ~]# docker network create -d bridge my_net//创建一个名称为my_net的bridge网络-d：设置网卡模式[root@localhost ~]# ip a//查看ip，会发现多了一个网卡 12[root@localhost ~]# brctl show//查看一下桥接网络，这里也多了一个网卡 123456[root@localhost ~]# docker run -itd --name test3 --network my_net busybox:latest//开启一台容器，网卡为刚刚创建的my_net[root@localhost ~]# docker exec -it test3 /bin/sh//进入刚刚创建的容器/ # ip a//查看一下IP 12[root@localhost ~]# ip a//查看ip，会发现多了一个网卡 12[root@localhost ~]# brctl show//查看一下桥接网络，这里也多了一个网卡 12345[root@localhost ~]# docker run -itd --name test4 --network my_net busybox:latest//开启一台容器，网卡为刚刚创建的my_net[root@localhost ~]# docker exec -it test3 /bin/sh/ # ping test4//ping 刚刚创建的容器名称 自定义网络优点，它可以通过容器的名称通信。 2.指定容器IP 12[root@localhost ~]# docker run -itd --name t1 --network my_net --ip 172.18.0.8 busybox:latest//开启一个容器并指定IP ! 1234[root@localhost ~]# docker network create -d bridge --subnet 172.30.16.0/24 --gateway 172.30.16.1 my_net3//创建一个自定义网络，并且指定网关和网段[root@localhost ~]# docker network ls//查看网络 1[root@localhost ~]# ip a 如果想要给容器指定IP地址，那么自定义网络的时候，必须指定网关gate和subnet网段选项。 如果想要给容器指定IP地址，那么自定义网络的时候，必须指定网关gate和subnet网段选项。 开启两个容器测试一下 1234[root@localhost ~]# docker run -itd --name test5 --network my_net3 --ip 172.30.16.5 busybox:latest//开启一个容器test5并指定IP[root@localhost ~]# docker exec -it test5 /bin/sh/ # ip a 1234[root@localhost ~]# docker run -itd --name test6 --network my_net3 --ip 172.30.16.6 busybox:latest//开启一个容器test6并指定IP[root@localhost ~]# docker exec -it test6 /bin/sh/ # ip a 1/ # ping test5 3.各网卡互通 [root@localhost ~]# iptables-save //查看网卡信息的配置规则（可以看到防火墙的规则当另一个网卡信息来到自己这里时直接丢弃） 1234[root@localhost ~]# docker network connect my_net3 test4//my_net3网卡桥接test4 （网卡名称 容器名称）[root@localhost ~]# docker exec -it test5 /bin/sh/ # ping test4 剩下的以此类推，然后就可以各个网卡互通了","path":"posts/5d5d.html","date":"08-09","excerpt":"","tags":[{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"}]},{"title":"docker私有仓库","text":"私有仓库 有时候使用 Docker Hub 这样的公共仓库可能不方便，用户可以创建一个本地仓库供私人使用。 本节介绍如何使用本地仓库。 docker-registry 是官方提供的工具，可以用于构建私有的镜像仓库。本文内容基于 docker-registry v2.x 版本。 安装运行 docker-registry 容器运行 你可以通过获取官方 registry 镜像来运行。 $ docker run -d -p 5000:5000 --restart=always --name registry registry 这将使用官方的 registry 镜像来启动私有仓库。默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下。你可以通过 -v 参数来将镜像文件存放在本地的指定路径。例如下面的例子将上传的镜像放到本地的 /opt/data/registry 目录。 1234$ docker run -d \\ -p 5000:5000 \\ -v /opt/data/registry:/var/lib/registry \\ registry 在私有仓库上传、搜索、下载镜像 创建好私有仓库之后，就可以使用 docker tag 来标记一个镜像，然后推送它到仓库。例如私有仓库地址为 127.0.0.1:5000。 先在本机查看已有的镜像。 123$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB 使用 docker tag 将 ubuntu:latest 这个镜像标记为 127.0.0.1:5000/ubuntu:latest。 格式为 docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]。 123456$ docker tag ubuntu:latest 127.0.0.1:5000/ubuntu:latest$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB127.0.0.1:5000/ubuntu:latest latest ba5877dc9bec 6 weeks ago 192.7 MB 使用 docker push 上传标记的镜像。 123456789$ docker push 127.0.0.1:5000/ubuntu:latestThe push refers to repository [127.0.0.1:5000/ubuntu]373a30c24545: Pusheda9148f5200b0: Pushedcdd3de0940ab: Pushedfc56279bbb33: Pushedb38367233d37: Pushed2aebd096e0e2: Pushedlatest: digest: sha256:fe4277621f1026266932ddf760f5a756d2facd505a94d2da12f4f52f71f5a size: 1568 用 curl 查看仓库中的镜像。 12$ curl 127.0.0.1:5000/v2/_catalog&#123;\"repositories\":[\"ubuntu\"]&#125; 这里可以看到 {“repositories”:[“ubuntu”]}，表明镜像已经被成功上传了。 先删除已有镜像，再尝试从私有仓库中下载这个镜像。 1234567891011121314$ docker image rm 127.0.0.1:5000/ubuntu:latest$ docker pull 127.0.0.1:5000/ubuntu:latestPulling repository 127.0.0.1:5000/ubuntu:latestba5877dc9bec: Download complete511136ea3c5a: Download complete9bad880da3d2: Download complete25f11f5fb0cb: Download completeebc34468f71d: Download complete2318d26665ef: Download complete$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE127.0.0.1:5000/ubuntu:latest latest ba5877dc9bec 6 weeks ago 192.7 MB 注意事项 如果你不想使用 127.0.0.1:5000 作为仓库地址，比如想让本网段的其他主机也能把镜像推送到私有仓库。你就得把例如 192.168.199.100:5000 这样的内网地址作为私有仓库地址，这时你会发现无法成功推送镜像。 这是因为 Docker 默认不允许非 HTTPS 方式推送镜像。我们可以通过 Docker 的配置选项来取消这个限制，或者查看下一节配置能够通过 HTTPS 访问的私有仓库。 Ubuntu 16.04+, Debian 8+, centos 7 对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） 12345678&#123; \"registry-mirror\": [ \"https://dockerhub.azk8s.cn\" ], \"insecure-registries\": [ \"192.168.199.100:5000\" ]&#125; 注意：该文件必须符合 json 规范，否则 Docker 将不能启动。 其他 对于 Docker Desktop for Windows 、 Docker Desktop for Mac 在设置中的 Docker Engine 中进行编辑 ，增加和上边一样的字符串即可。 链接：https://blog.51cto.com/14320361/2458049 链接：https://yeasy.gitbooks.io/docker_practice/content/repository/registry.html","path":"posts/99ea.html","date":"08-08","excerpt":"","tags":[{"name":"docker-registry","slug":"docker-registry","permalink":"https://wsdlxgp.top/tags/docker-registry/"},{"name":"docker私有仓库","slug":"docker私有仓库","permalink":"https://wsdlxgp.top/tags/docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"}]},{"title":"Dockerfile常用指令","text":"1.FROM：构建镜像基于哪个镜像 123语法：FROM &lt;image&gt;[:&lt;tag&gt;]例如：FROM centos：7解释：设置要制作的镜像基于哪个镜像，FROM指令必须是整个Dockerfile的第一个指令，如果指定的镜像不存在默认会自动从Docker Hub上下载。 2.MAINTAINER：镜像维护者姓名或邮箱地址 123语法：MAINTAINER &lt;name&gt;例如：MAINTAINER adam解释：MAINTAINER指令允许你给将要制作的镜像设置作者信息 3.RUN：构建镜像时运行的shell命令 123456语法： ①RUN &lt;command&gt; #将会调用/bin/sh -c &lt;command&gt; ②RUN [\"executable\", \"param1\", \"param2\"] #将会调用exec执行，以避免有些时候shell方式执行时的传递参数问题，而且有些基础镜像可能不包含/bin/shtrue 例如：trueRUN [“yum”,”install”,”httpd”]trueRUN yum -y install httpd解释：RUN指令会在一个新的容器中执行任何命令，然后把执行后的改变提交到当前镜像，提交后的镜像会被用于Dockerfile中定义的下一步操作，RUN中定义的命令会按顺序执行并提交，这正是Docker廉价的提交和可以基于镜像的任何一个历史点创建容器的好处，就像版本控制工具一样。 4.CMD：运行容器时执行的shell命令 1234567语法：①CMD [\"executable\", \"param1\", \"param2\"] #将会调用exec执行，首选方式 ②CMD [\"param1\", \"param2\"] #当使用ENTRYPOINT指令时，为该指令传递默认参数 ③CMD &lt;command&gt; [ &lt;param1&gt;|&lt;param2&gt; ] #将会调用/bin/sh -c执行true例如： CMD [“/bin/bash”]解释：CMD指令中指定的命令会在镜像运行时执行，在Dockerfile中只能存在一个，如果使用了多个CMD指令，则只有最后一个CMD指令有效。当出现ENTRYPOINT指令时，CMD中定义的内容会作为ENTRYPOINT指令的默认参数，也就是说可以使用CMD指令给ENTRYPOINT传递参数。注意：RUN和CMD都是执行命令，他们的差异在于RUN中定义的命令会在执行docker build命令创建镜像时执行，而CMD中定义的命令会在执行docker run命令运行镜像时执行，另外使用第一种语法也就是调用exec执行时，命令必须为绝对路径。 5.EXPOSE:声明容器的服务端口 123 语法：EXPOSE &lt;port&gt; [ ...]例如：EXPOSE 80 443 解释：EXPOSE指令用来告诉Docker这个容器在运行时会监听哪些端口，Docker在连接不同的容器(使用–link参数)时使用这些信息。 6.ENV：设置容器环境变量 1234 语法：ENV &lt;key&gt; &lt;value&gt;例如：ENV MYSQL_ROOT_PASSWORD 123.com 解释：ENV指令用于设置环境变量，在Dockerfile中这些设置的环境变量也会影响到RUN指令，当运行生成的镜像时这些环境变量依然有效，如果需要在运行时更改这些环境变量可以在运行docker run时添加–env &lt;key&gt;=&lt;value&gt;参数来修改。 注意：最好不要定义那些可能和系统预定义的环境变量冲突的名字，否则可能会产生意想不到的结果。 7.ADD：拷贝文件或目录到镜像，如果是URL或压缩包会自动下载或自动解压 1234567891011 语法：ADD &lt;src&gt; &lt;dest&gt; 解释：ADD指令用于从指定路径拷贝一个文件或目录到容器的指定路径中，&lt;src&gt;是一个文件或目录的路径，也可以是一个url，路径是相对于该Dockerfile文件所在位置的相对路径，&lt;dest&gt;是目标容器的一个绝对路径，例如/home/yooke/Docker/Dockerfile这个文件中定义的，那么ADD /data.txt /db/指令将会尝试拷贝文件从/home/yooke/Docker/data.txt到将要生成的容器的/db/data.txt，且文件或目录的属组和属主分别为uid和gid为0的用户和组，如果是通过url方式获取的文件，则权限是600。true例如：ADD &lt;源文件&gt;。。。&lt;目标目录&gt;ADD [“源文件”…”目标目录”] 注意：①如果执行docker build – &lt; somefile即通过标准输入来创建时，ADD指令只支持url方式，另外如果url需要认证，则可以通过RUN wget …或RUN curl …来完成，ADD指令不支持认证。 ②&lt;src&gt;路径必须与Dockerfile在同级目录或子目录中，例如不能使用ADD ../somepath，因为在执行docker build时首先做的就是把Dockerfile所在目录包含子目录发送给docker的守护进程。 ③如果&lt;src&gt;是一个url且&lt;dest&gt;不是以”/“结尾，则会下载文件并重命名为&lt;dest&gt;。 ④如果&lt;src&gt;是一个url且&lt;dest&gt;以“/”结尾，则会下载文件到&lt;dest&gt;/&lt;filename&gt;，url必须是一个正常的路径形式，“http://example.com”像这样的url是不能正常工作的。 ⑤如果&lt;src&gt;是一个本地的压缩包且&lt;dest&gt;是以“/”结尾的目录，则会调用“tar -x”命令解压缩，如果&lt;dest&gt;有同名文件则覆盖，但&lt;src&gt;是一个url时不会执行解压缩。 8.COPY：拷贝文件或目录到镜像容器内，跟ADD类似，但不具备自动下载或解压功能 12345678语法：COPY &lt;src&gt; &lt;dest&gt;解释：用法与ADD相同，不过&lt;src&gt;不支持使用url，所以在使用docker build – &lt; somefile时该指令不能使用。ENTRYPOINT语法：①ENTRYPOINT [\"executable\", \"param1\", \"param2\"] #将会调用exec执行，首选方式②ENTRYPOINT command param1 param2 #将会调用/bin/sh -c执行解释：ENTRYPOINT指令中指定的命令会在镜像运行时执行，在Dockerfile中只能存在一个，如果使用了多个ENTRYPOINT指令，则只有最后一个指令有效。ENTRYPOINT指令中指定的命令(exec执行的方式)可以通过docker run来传递参数，例如docker run &lt;images&gt; -l启动的容器将会把-l参数传递给ENTRYPOINT指令定义的命令并会覆盖CMD指令中定义的默认参数(如果有的话)，但不会覆盖该指令定义的参数，例如ENTRYPOINT [\"ls\",\"-a\"]，CMD [\"/etc\"],当通过docker run &lt;image&gt;启动容器时该容器会运行ls -a /etc命令，当使用docker run &lt;image&gt; -l启动时该容器会运行ls -a -l命令，-l参数会覆盖CMD指令中定义的/etc参数。注意：①当使用ENTRYPOINT指令时生成的镜像运行时只会执行该指令指定的命令。②当出现ENTRYPOINT指令时CMD指令只可能(当ENTRYPOINT指令使用exec方式执行时)被当做ENTRYPOINT指令的参数使用，其他情况则会被忽略。 9.VOLUME: 指定容器挂载点到宿主机自动生成的目录或其他容器 123语法：VOLUME [\"samepath\"]例如：VOLUME [\"/var/lib/mysql\"]解释：VOLUME指令用来设置一个挂载点，可以用来让其他容器挂载以实现数据共享或对容器数据的备份、恢复或迁移，具体用法请参考其他文章。 10.USER:为RUN、CMD、和ENTRYPOINT执行命令指定运行用户 12语法：USER [username|uid]解释：USER指令用于设置用户或uid来运行生成的镜像和执行RUN指令。 11.WORKDIR: 为RUN、CMD、ENTRYPOINT、 COPY和ADD设置工作目录，意思为切换目录 12语法：WORKDIR /path/to/workdir解释：WORKDIR指令用于设置Dockerfile中的RUN、CMD和ENTRYPOINT指令执行命令的工作目录(默认为/目录)，该指令在Dockerfile文件中可以出现多次，如果使用相对路径则为相对于WORKDIR上一次的值，例如WORKDIR /data，WORKDIR logs，RUN pwd最终输出的当前目录是/data/logs。 12.ONBUILD 12345678语法：ONBUILD [INSTRUCTION] 解释：ONBUILD指令用来设置一些触发的指令，用于在当该镜像被作为基础镜像来创建其他镜像时(也就是Dockerfile中的FROM为当前镜像时)执行一些操作，ONBUILD中定义的指令会在用于生成其他镜像的Dockerfile文件的FROM指令之后被执行，上述介绍的任何一个指令都可以用于ONBUILD指令，可以用来执行一些因为环境而变化的操作，使镜像更加通用。 注意：①ONBUILD中定义的指令在当前镜像的build中不会被执行。 ②可以通过查看docker inspeat &lt;image&gt;命令执行结果的OnBuild键来查看某个镜像ONBUILD指令定义的内容。 ③ONBUILD中定义的指令会当做引用该镜像的Dockerfile文件的FROM指令的一部分来执行，执行顺序会按ONBUILD定义的先后顺序执行，如果ONBUILD中定义的任何一个指令运行失败，则会使FROM指令中断并导致整个build失败，当所有的ONBUILD中定义的指令成功完成后，会按正常顺序继续执行build。 ④ONBUILD中定义的指令不会继承到当前引用的镜像中，也就是当引用ONBUILD的镜像创建完成后将会清除所有引用的ONBUILD指令。 ⑤ONBUILD指令不允许嵌套，例如ONBUILD ONBUILD ADD . /data是不允许的。 ⑥ONBUILD指令不会执行其定义的FROM或MAINTAINER指令。 13.HEALTHCHECK:健康检查 14.ARG: 构建时指定的一些参数 1234例如:FROM centos:7ARG userUSER $user 设置环境变量除了ENV 外对容器还可能用以下两种方式 ： 1234docker exec -i CONTAINER_ID /bin/bash -c \"exportDOCKER_HOST=tcp://localhost:port\"+echo 'export DOCKER_HOST=tcp://localhost:port' &gt;&gt; ~/.bashrc 注意: 1、RUN在building时运行， 可以写多条 2、CMD和ENTRYPOINT在运行container时运行， 只能写一条，如果写多条,最后一条生效 3、CMD在run时可以被COMMAND覆盖，ENTRYPOINT不会被COMMAND覆盖，但可以指定–entrypoint覆盖。 4、如果在Dockerfile里需要往镜像内导入文件，则此文件必须在dockerfile所在目录或子目录下。 小实验 1）使用dockerifle制作一个镜像，基于centos：7镜像部署安装nginx服务。 12[root@localhost ~]# mkdir web[root@localhost ~]# rz 12345678910111213141516[root@localhost ~]# cp nginx-1.14.0.tar.gz web/[root@localhost ~]# cd web///创建测试目录[root@localhost web]# vim DockerfileFROM centos:7RUN yum -y install make gcc pcre pcre-devel zlib zlib-devel openssl openssl-develCOPY nginx-1.14.0.tar.gz /RUN tar -zxf nginx-1.14.0.tar.gz -C /usr/srcRUN useradd -M -s /sbin/nologin nginxWORKDIR /usr/src/nginx-1.14.0RUN ./configure --prefix=/usr/local/nginx --user=nginx --group=nginxRUN make &amp;&amp; make installRUN ln -s /usr/local/nginx/sbin/* /usr/local/sbin/RUN nginx -tRUN nginxEXPOSE 80 //如果想要保证容器运行之后，nginx服务就直接开启，不必手动开启，我们可以在命令最后加上:nginx -g &quot;daemon off;&quot; 1234[root@localhost web]# docker build -t test-web .//创建镜像[root@localhost web]# docker images//查看一下镜像 12345678[root@localhost web]# docker run -itd --name testweb test-web:latest[root@localhost web]# docker exec -it testweb /bin/bash//进入容器testweb[root@a3a21e68cb99 nginx-1.14.0]# nginx//开启nginx[root@a3a21e68cb99 nginx-1.14.0]# exit[root@localhost web]# docker inspect testweb//查看容器testweb的详细信息（现在看IP） 12[root@localhost web]# curl 172.17.0.2:80//访问一下nginx 2）将制作的镜像运行一个容器，使容器运行时自动开启nginx服务。验证服务正常运行。 1234[root@localhost web]# docker run -itd --name testweb_2 test-web:latest nginx -g \"daemon off;\"//开启容器时一并开启nginx[root@localhost web]# docker inspect testweb_2//查看容器testweb_2的详细信息（现在看IP） 12[root@localhost web]# curl 172.17.0.3:80//访问一下nginx 3）运行一个私有仓库，将自制镜像上传到私有仓库，且开启另外一台虚拟机同样加入私有仓库，在docker02上下载私有仓库镜像并运行一个容器，验证服务正常运行。 12[root@localhost web]# docker pull registry:2//先下载一个镜像 用docker容器运行registry私有仓库 123456[root@localhost web]# docker run -itd --name registry --restart=always -p 5000:5000 -v /registry:/var/lib/registry registry:2//运行一下registery私有仓库服务（会返回一个进程编号）-p：端口映射。宿主机端口:容器暴露的端口。-v：挂载目录。宿主机目录：容器内的目录。[root@localhost web]# docker ps//查看一下容器 123[root@localhost web]# docker tag test-web1 192.168.1.11:5000/test//镜像重命名[root@localhost web]# docker images 12345678[root@localhost web]# vim /usr/lib/systemd/system/docker.service//修改docker配置文件ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 #13行[root@localhost web]# systemctl daemon-reload [root@localhost web]# systemctl restart docker//重启docker[root@localhost web]# docker ps//查看容器 12[root@localhost web]# docker push 192.168.1.11:5000/test:latest//上传私有仓库 12[root@localhost web]# ls/registry/docker/registry/v2/repositories//查看一下私有仓库 打开第二台docker测试一下 123456789 39 vim /usr/lib/systemd/system/docker.service //修改docker配置文件ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 #13行 40 systemctl daemon-reload 41 systemctl restart docker44 docker pull 192.168.1.11:5000/test:latest//从私有仓库下载镜像 53 docker run -itd --name xgp1 192.168.1.11:5000/test:latest nginx -g \"daemon off;\"true //开启容器时一并开启nginx 12 54 docker inspect xgp1//查看容器testweb_2的详细信息（现在看IP） 1256 curl 172.17.0.2 //访问一下nginx","path":"posts/30ad.html","date":"08-07","excerpt":"","tags":[{"name":"dockerfile","slug":"dockerfile","permalink":"https://wsdlxgp.top/tags/dockerfile/"}]},{"title":"理解Docker镜像分层","text":"目录 关于base镜像 关于存储结构（About storage drivers） 先来创建一个自己的镜像 docker镜像的分层结构 容器的大小 修改时复制策略 copy-on-write (CoW) Copying makes containers efficient 关于base镜像 base 镜像有两层含义： 不依赖其他镜像，从 scratch 构建。 其他镜像可以之为基础进行扩展。 所以，能称作 base 镜像的通常都是各种 Linux 发行版的 Docker 镜像，比如 Ubuntu, Debian, CentOS 等。 base 镜像提供的是最小安装的 Linux 发行版。 我们大部分镜像都将是基于base镜像构建的。所以，通常使用的是官方发布的base镜像。可以在docker hub里找到。比如centos： https://hub.docker.com/_/centos 点击版本可以看到github里的Dockerfile 12345678910FROM scratchADD centos-7-docker.tar.xz /LABEL org.label-schema.schema-version=\"1.0\" \\ org.label-schema.name=\"CentOS Base Image\" \\ org.label-schema.vendor=\"CentOS\" \\ org.label-schema.license=\"GPLv2\" \\ org.label-schema.build-date=\"20181205\"CMD [\"/bin/bash\"] ADD命令将本地的centos7的tar包添加到镜像，并解压到根目录/下。生成/dev,/proc/,/bin等。 我们可以自己构建docker base镜像，也可以直接使用已有的base镜像。比如centos。我们可以直接从docker hub上拉取。 拉取 1docker pull centos 查看 123# docker images centos REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 1e1148e4cc2c 2 months ago 202MB 可以看到最新的centos镜像只有200mb，是不是觉得太小了？这是因为docker镜像在运行的时候直接使用docker宿主机器的kernel。 Linux操作系统由内核空间和用户空间组成。 内核空间是kernel，用户空间是rootfs, 不同Linux发行版的区别主要是rootfs.比如 Ubuntu 14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS 7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。 所以 Docker 可以同时支持多种 Linux 镜像，模拟出多种操作系统环境。 需要注意的是： base镜像只是用户空间和发行版一致。kernel使用的是docker宿主机器的kernel。例如 CentOS 7 使用 3.x.x 的 kernel，如果 Docker Host 是 Ubuntu 16.04（比如我们的实验环境），那么在 CentOS 容器中使用的实际是是 Host 4.x.x 的 kernel。 ① Host kernel 为 4.4.0-31 ② 启动并进入 CentOS 容器 ③ 验证容器是 CentOS 7 ④ 容器的 kernel 版本与 Host 一致 关于存储结构（About storage drivers） 上文里展示了如何下载一个base镜像。我们通常是基于这份base镜像来构建我们自己的镜像。比如，在centos里添加一个nginx负载均衡。首先，得需要了解镜像的结构是什么。 官方文档： https://docs.docker.com/storage/storagedriver/ 先来创建一个自己的镜像 首先，base镜像是基于docker宿主机器kernel之上的Linux发行版。 现在，我们给这台机器安装一个vim，一个httpd. 基于Dockerfile来创建一个新的镜像。 123456789101112我们的DockerfileFROM centos:7RUN yum install -y vimRUN yum install -y httpdCMD [\"/bin/bash\"]含义：基于centos7的base镜像构建安装vim安装httpd执行bash 在当前目录下新建一个文件Dockerfile, 填充上述内容。然后执行 123456789101112131415# docker build -t ryan/httpd:v1.0 .Sending build context to Docker daemon 6.144kBStep 1/4 : FROM centos:7 ---&gt; 1e1148e4cc2cStep 2/4 : RUN yum install -y vim ---&gt; Using cache ---&gt; 74bdbea98f73Step 3/4 : RUN yum install -y httpd ---&gt; Using cache ---&gt; 17d8c4095dc4Step 4/4 : CMD /bin/bash ---&gt; Using cache ---&gt; f2b58b1192deSuccessfully built f2b58b1192deSuccessfully tagged ryan/httpd:latest -t 指定我们创建的镜像名称，镜像名称可以用组织/id:version的方式标记 最后一个参数是Dockerfile所在的路径., 表示当前目录 然后我们添加一个tag latest docker tag ryan/httpd:v1.0 ryan/httpd:latest 即给镜像ryan/httpd:v1.0标记为ryan/httpd:latest 构建完成之后，查看 12345# docker images | grep -E '(ryan|centos)'ryan/httpd latest f2b58b1192de About an hour ago 444MBryan/httpd v1.0 f2b58b1192de About an hour ago 444MBcentos 7 1e1148e4cc2c 2 months ago 202MBcentos latest 1e1148e4cc2c 2 months ago 202MB 可以运行我们创建的镜像： 1234# docker run -d --privileged=true -it ryan/httpd:v1.0 /usr/sbin/init48a4a128cd7b6924149cd97670919d4e2af6cb96c73c901af60d05fe4478225a# docker ps | grep ryan48a4a128cd7b ryan/httpd:v1.0 \"/usr/sbin/init\" 8 seconds ago Up 8 seconds 现在我们的基于原生base centos7的httpd服务器已经启动了。可以通过docker exec -it zealous_kirch /bin/bash来进入容器内部，查看启动httpd。 docker镜像的分层结构 我们可以查看镜像的历史，用上一步的镜像id f2b58b1192de 12345678# docker history f2b58b1192deIMAGE CREATED CREATED BY SIZE COMMENTf2b58b1192de About an hour ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0B 17d8c4095dc4 About an hour ago /bin/sh -c yum install -y httpd 110MB 74bdbea98f73 About an hour ago /bin/sh -c yum install -y vim 133MB 1e1148e4cc2c 2 months ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0B &lt;missing&gt; 2 months ago /bin/sh -c #(nop) LABEL org.label-schema.... 0B &lt;missing&gt; 2 months ago /bin/sh -c #(nop) ADD file:6f877549795f479... 202MB 启动镜像的时候，一个新的可写层会加载到镜像的顶部。这一层通常称为“容器层”， 之下是“镜像层”。 容器层可以读写，容器所有发生文件变更写都发生在这一层。镜像层read-only,只允许读取。 (上图来自官方文档，和本次实验内容略有不同，但原理一样) 第一列是imageid, 最上面的id就是我们新创建ryan/httpd:latest. 下面几行都是我们dockerfile里定义的步骤堆栈。由此可以看出，每个步骤都将创建一个imgid, 一直追溯到1e1148e4cc2c正好是我们的base镜像的id。关于的部分，则不在本机上。 最后一列是每一层的大小。最后一层只是启动bash，所以没有文件变更，大小是0. 我们创建的镜像是在base镜像之上的，并不是完全复制一份base，然后修改，而是共享base的内容。这时候，如果我们新建一个新的镜像，同样也是共享base镜像。 那修改了base镜像，会不会导致我们创建的镜像也被修改呢？ 不会！因为不允许修改历史镜像，只允许修改容器，而容器只可以在最上面的容器层进行写和变更。 容器的大小 创建镜像的时候，分层可以让docker只保存我们添加和修改的部分内容。其他内容基于base镜像，不需要存储，读取base镜像即可。如此，当我们创建多个镜像的时候，所有的镜像共享base部分。节省了磁盘空间。 对于启动的容器，查看所需要的磁盘空间可以通过docker ps -s 123456# docker run -d -it centos4b0df4bc3e705c540144d545441930689124ade087961d01f56c2ac55bfd986d# docker ps -s | grep -E '(ryan|centos)'4b0df4bc3e70 centos \"/bin/bash\" 23 seconds ago Up 23 seconds vigorous_elion 0B (virtual 202MB)b36421d05005 ryan/httpd:v1.0 \"/usr/sbin/init\" 32 minutes ago Up 32 minutes gracious_swirles 61.6kB (virtual 444MB) 首先启动一个base镜像用来对比 可以看到第一行就是base镜像centos，第2列的size是0和202MB, 0表示容器层可写层的大小，virtual则是容器层+镜像层的大小。这里对比可以看到一共202M,正好是最初centos镜像的大小。 第二行是我们自己创建的镜像。virtual达到了444MB。对比前面的history部分，可以发现这个数字是每一层大小之和。同时，由于共享base，其中的202M是和第一行的镜像共享的。 修改时复制策略 copy-on-write (CoW) docker通过一个叫做copy-on-write (CoW) 的策略来保证base镜像的安全性，以及更高的性能和空间利用率。 1234567891011121314151617Copy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.Copying makes containers efficientWhen you start a container, a thin writable container layer is added on top of the other layers. Any changes the container makes to the filesystem are stored here. Any files the container does not change do not get copied to this writable layer. This means that the writable layer is as small as possible.When an existing file in a container is modified, the storage driver performs a copy-on-write operation. The specifics steps involved depend on the specific storage driver. For the aufs, overlay, and overlay2 drivers, the copy-on-write operation follows this rough sequence:Search through the image layers for the file to update. The process starts at the newest layer and works down to the base layer one layer at a time. When results are found, they are added to a cache to speed future operations.Perform a copy_up operation on the first copy of the file that is found, to copy the file to the container’s writable layer.Any modifications are made to this copy of the file, and the container cannot see the read-only copy of the file that exists in the lower layer.Btrfs, ZFS, and other drivers handle the copy-on-write differently. You can read more about the methods of these drivers later in their detailed descriptions.Containers that write a lot of data consume more space than containers that do not. This is because most write operations consume new space in the container’s thin writable top layer. 简单的说，启动容器的时候，最上层容器层是可写层，之下的都是镜像层，只读层。 当容器需要读取文件的时候 从最上层镜像开始查找，往下找，找到文件后读取并放入内存，若已经在内存中了，直接使用。(即，同一台机器上运行的docker容器共享运行时相同的文件)。 当容器需要添加文件的时候 直接在最上面的容器层可写层添加文件，不会影响镜像层。 当容器需要修改文件的时候 从上往下层寻找文件，找到后，复制到容器可写层，然后，对容器来说，可以看到的是容器层的这个文件，看不到镜像层里的文件。容器在容器层修改这个文件。 当容器需要删除文件的时候 从上往下层寻找文件，找到后在容器中记录删除。即，并不会真正的删除文件，而是软删除。这将导致镜像体积只会增加，不会减少。 综上，Docker镜像通过分层实现了资源共享，通过copy-on-write实现了文件隔离。 对于文件只增加不减少问题，我们应当在同一层做增删操作，从而减少镜像体积。比如，如下测试。 Dockerfile.A: 分层删除文件** 12345678FROM centos:7RUN yum install -y vimRUN yum install -y httpdWORKDIR /homeRUN dd if=/dev/zero of=50M.file bs=1M count=50#创建大小为50M的测试文件RUN rm -rf 50M.fileCMD [\"/bin/bash\"] 构建 docker build -t test:a -f Dockerfile.A . Dockerfile.B: 同层删除 12345FROM centos:7RUN yum install -y vimRUN yum install -y httpdWORKDIR /homeRUN dd if=/dev/zero of=50M.file bs=1M count=50 &amp;&amp; rm -rf 50M.file 构建 1docker build -t test:b -f Dockerfile.B . 比较二者大小 123[root@sh-k8s-001 tmp]# docker images | grep testtest a ae673aa7db48 9 minutes ago 497MBtest b 21b2bc49f0bd 12 minutes ago 444MB 显然，分层删除操作并没有真正删除掉文件。 来源 **链接：**https://www.cnblogs.com/woshimrf/p/docker-container-lawyer.html https://www.cnblogs.com/CloudMan6/p/6799197.html https://www.cnblogs.com/CloudMan6/p/6806193.html https://docs.docker.com/storage/storagedriver/","path":"posts/2fbc.html","date":"08-06","excerpt":"","tags":[{"name":"bash","slug":"bash","permalink":"https://wsdlxgp.top/tags/bash/"}]},{"title":"Dockers镜像分层","text":"1,Dockers的最小镜像 1234[root@localhost ~]# docker pull hello-world//下载一个最小的镜像[root@localhost ~]# docker images//查看镜像 12[root@localhost ~]# docker run hello-world//运行一下hello-world （里面是一个文本对docker运行的简单介绍） dockerfile的组成 1）FROM：scratch（抓、挠） 2）COPY：hello / 3）CMD：[“/hello”] FROM 12语法：FROM &lt;image&gt;[:&lt;tag&gt;]解释：设置要制作的镜像基于哪个镜像，FROM指令必须是整个Dockerfile的第一个指令，如果指定的镜像不存在默认会自动从Docker Hub上下载。 COPY 12语法：COPY &lt;src&gt; &lt;dest&gt;解释：用法与ADD相同，不过&lt;src&gt;不支持使用url，所以在使用docker build – &lt; somefile时该指令不能使用。 CMD 12345语法：①CMD [\"executable\", \"param1\", \"param2\"] #将会调用exec执行，首选方式 ②CMD [\"param1\", \"param2\"] #当使用ENTRYPOINT指令时，为该指令传递默认参数 ③CMD &lt;command&gt; [ &lt;param1&gt;|&lt;param2&gt; ] #将会调用/bin/sh -c执行解释：CMD指令中指定的命令会在镜像运行时执行，在Dockerfile中只能存在一个，如果使用了多个CMD指令，则只有最后一个CMD指令有效。当出现ENTRYPOINT指令时，CMD中定义的内容会作为ENTRYPOINT指令的默认参数，也就是说可以使用CMD指令给ENTRYPOINT传递参数。注意：RUN和CMD都是执行命令，他们的差异在于RUN中定义的命令会在执行docker build命令创建镜像时执行，而CMD中定义的命令会在执行docker run命令运行镜像时执行，另外使用第一种语法也就是调用exec执行时，命令必须为绝对路径。 2、Base镜像（基础镜像） Centos:7镜像的dockerfile 1234567891011FROM scratchADD centos-7-x86_ _64-docker.tar.xz /LABEL org. label-schema. schema-version=\"1.0\" \\|org. label-schema. name=\"Centos Base Image\" \\org. labe1-schema. vendor=\"centos\" \\org. labe1-schema. 1icense=\"GPLV2\" \\org. labe1-schema build-date=\"20190305 'CMD [\"/bin/bash\"] 3、镜像的分层 1）dockerfile的书写格式为：Dockerfile（首字母大写，包括文件名称） 2）From：构建镜像有两种方式，一种scratch(从零构建)，另一种可以基于某个镜像开始构建 3）镜像所运行的操作（用户所期望的） 12345678910[root@localhost ~]# mkdir test//创建测试目录[root@localhost ~]# cd test//进入测试目录[root@localhost ~]#vim Dockerfile//编写DockerfileFROM centos:7 RUN yum -y install vim #或[\"yum\",\"install\",\"vim\"]RUN yum -y install net-toolsCMD [\"/bin/bash\"] 执行一下 12345[root@localhost test]# docker build -t centos7-vim-net-tools:12-11 .//使用当前目录的 Dockerfile 创建镜像，标签为 centos7-vim-net-tools:12-11build： 使用 Dockerfile 创建镜像-t：标签. :当前目录 执行的层次 4.Dockerfile镜像分层总结 镜像时容器的基石，容器是镜像运行后的实例。当镜像运行为容器之后,对镜像的所有数据仅有只读权限，如果需要对镜像源文件进行修改或删除操作,此时是在容器层（可写层）进行的，用到了COW（copy on write）写时复制机制。 Docker镜像的缓存特性 1.创建一个新的Dockerfile文件 12345678[root@localhost ~]# vim DockerfileFROM centos:7RUN yum -y install vimRUN yum -y install net-toolsRUN yum -y install wgetCMD [\"/bin/bash\"][root@localhost ~]# docker build -t new-centos .//使用当前目录的 Dockerfile 创建镜像，名称为new-centos 如果在相同的层，有用到相同的镜像，可以不必再去下载，直接使用缓存。（如果第一层的不相同了，那么下面的相同也没用了，需要重新下载） 2.再次创建一个新的Dockerfile 1234567891011[root@localhost ~]# mkdir test1[root@localhost ~]# cd test[root@localhost test]# cd ../test1[root@localhost test1]# vim DockerfileFROM centos:7RUN yum -y install vimRUN yum -y install wgetRUN yum -y install net-toolsCMD [\"/bin/bash\"][root@localhost test1]# docker build -t centos-new .//使用当前目录的 Dockerfile 创建镜像，名称为centos-new 即使镜像层里的操作一样，也必须是在同一层才可以使用dockerfile的缓存特性 如果制作镜像过程中，不想使用缓存，可以–no-cache选项","path":"posts/4e5d.html","date":"08-05","excerpt":"","tags":[{"name":"base","slug":"base","permalink":"https://wsdlxgp.top/tags/base/"},{"name":"dockerfile","slug":"dockerfile","permalink":"https://wsdlxgp.top/tags/dockerfile/"}]},{"title":"DOCKER源码分析（一）：DOCKER架构","text":"1 背景 1.1 Docker简介 Docker是Docker公司开源的一个基于轻量级虚拟化技术的容器引擎项目,整个项目基于Go语言开发，并遵从Apache 2.0协议。目前，Docker可以在容器内部快速自动化部署应用，并可以通过内核虚拟化技术（namespaces及cgroups等）来提供容器的资源隔离与安全保障等。由于Docker通过操作系统层的虚拟化实现隔离，所以Docker容器在运行时，不需要类似虚拟机（VM）额外的操作系统开销，提高资源利用率，并且提升诸如IO等方面的性能。 由于众多新颖的特性以及项目本身的开放性，Docker在不到两年的时间里迅速获得诸多厂商的青睐，其中更是包括Google、Microsoft、VMware等业界行业领导者。Google在今年六月份推出了Kubernetes，提供Docker容器的调度服务，而今年8月Microsoft宣布Azure上支持Kubernetes，随后传统虚拟化巨头VMware宣布与Docker强强合作。今年9月中旬，Docker更是获得4000万美元的C轮融资，以推动分布式应用方面的发展。 从目前的形势来看，Docker的前景一片大好。本系列文章从源码的角度出发，详细介绍Docker的架构、Docker的运行以及Docker的卓越特性。本文是Docker源码分析系列的第一篇———Docker架构篇。 1.2 Docker版本信息 本文关于Docker架构的分析都是基于Docker的源码与Docker相应版本的运行结果，其中Docker为最新的1.2版本。 2 Docker架构分析内容安排 本文的目的是：在理解Docker源代码的基础上，分析Docker架构。分析过程中主要按照以下三个步骤进行： • Docker的总架构图展示 • Docker架构图内部各模块功能与实现分析 • 以Docker命令的执行为例，进行Docker运行流程阐述 3 Docker总架构图 学习Docker的源码并不是一个枯燥的过程，反而可以从中理解Docker架构的设计原理。Docker对使用者来讲是一个C/S模式的架构，而Docker的后端是一个非常松耦合的架构，模块各司其职，并有机组合，支撑Docker的运行。 在此，先附上Docker总架构，如图3.1。 图3.1 Docker总架构图 如图3.1，不难看出，用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。 而Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求；而后Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。 Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储；当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境；当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。 而libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。 当执行完运行容器的命令后，一个实际的Docker容器就处于运行状态，该容器拥有独立的文件系统，独立并且安全的运行环境等。 3.1 DOCKER架构总体包含七个部分：client,daemon,driver,libcontainer,container,graph,registry。 外表来看，docker是一个C/S的架构，用户可以在客户端输入各种指令，客户端负责接受请求并作出相应的响应返回给客户。 3.2 DockerClient DockerClient 负责接受并传递请求指令 。 3.3 DockerDaemon DockerDaemon的功能主要有两个： 负责接受client的请求 管理docker容器 dockerdaemon的架构主要可以分为两部分：dockerserver和engine 3.4 DockerServer DockerServer作为服务端最主要的作用就是配合client端将请求指令接受过来，如图所示，DockerServer主要分为三个部分：Http.server,mux.server,Handler。 DockerServer运行时会从一个名为mux的包中创建一个mux.Router路由器，然后为路由器中添加相关的路由项用于路由信息， 每个路由项由HTTP请求方法（get,post,put,delete）+URL+Handler三部分组成。 DockerServer每收到一个请求就会生成一个goroutine然后进行相应的解析、匹配相应的路由项最后会找到相匹配的Handler来处理，Handler处理玩请求之后给DockerClient返回响应。 3.5 Engine Engine是docker中的运行引擎，存储着大量的容器信息并管理着大部分job的执行。 job是docker中的最小执行单元，类似于unix中的进程，也会有相应的名字、参数、环境变量、标准输入输出、返回状态等等。docker每进行一次相应的操作都会 生成一个相应的Job，比如创建一个容器、下载一个文件等等都是由job完成的。 3.6 DockerDriver DockerDriver是docker内部的驱动模块，负责容器内部相关网络、文件系统等的构建 3.6 libcontainer libcontainer主要是对linux内核的一些诸如namespace、cgroups、capabilities等特性做了封装 4 Docker架构内各模块的功能与实现分析 接下来，我们将从Docker总架构图入手，抽离出架构内各个模块，并对各个模块进行更为细化的架构分析与功能阐述。主要的模块有：Docker Client、Docker Daemon、Docker Registry、Graph、Driver、libcontainer以及Docker container。 4.1 Docker Client Docker Client是Docker架构中用户用来和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker，通过docker命令行工具可以发起众多管理container的请求。 Docker Client可以通过以下三种方式和Docker Daemon建立通信：tcp://host:port，unix://path_to_socket和fd://socketfd。为了简单起见，本文一律使用第一种方式作为讲述两者通信的原型。与此同时，与Docker Daemon建立连接并传输请求的时候，Docker Client可以通过设置命令行flag参数的形式设置安全传输层协议(TLS)的有关参数，保证传输的安全性。 Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。当需要继续发送容器管理请求时，用户必须再次通过docker可执行文件创建Docker Client。 4.2 Docker Daemon Docker Daemon是Docker架构中一个常驻在后台的系统进程，功能是：接受并处理Docker Client发送的请求。该守护进程在后台启动了一个Server，Server负责接受Docker Client发送的请求；接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。 Docker Daemon启动所使用的可执行文件也为docker，与Docker Client启动所使用的可执行文件docker相同。在docker命令执行时，通过传入的参数来判别Docker Daemon与Docker Client。 Docker Daemon的架构，大致可以分为以下三部分：Docker Server、Engine和Job。Daemon架构如图4.1。 图4.1 Docker Daemon架构示意图 4.2.1 DOCKER SERVER Docker Server在Docker架构中是专门服务于Docker Client的server。该server的功能是：接受并调度分发Docker Client发送的请求。Docker Server的架构如图4.2。 ** 图4.2 Docker Server架构示意图 在Docker的启动过程中，通过包gorilla/mux，创建了一个mux.Router，提供请求的路由功能。在Golang中，gorilla/mux是一个强大的URL路由器以及调度分发器。该mux.Router中添加了众多的路由项，每一个路由项由HTTP请求方法（PUT、POST、GET或DELETE）、URL、Handler三部分组成。 若Docker Client通过HTTP的形式访问Docker Daemon，创建完mux.Router之后，Docker将Server的监听地址以及mux.Router作为参数，创建一个httpSrv=http.Server{}，最终执行httpSrv.Serve()为请求服务。 在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。 需要注意的是：Docker Server的运行在Docker的启动过程中，是靠一个名为”serveapi”的job的运行来完成的。原则上，Docker Server的运行是众多job中的一个，但是为了强调Docker Server的重要性以及为后续job服务的重要特性，将该”serveapi”的job单独抽离出来分析，理解为Docker Server。 4.2.2 ENGINE Engine是Docker架构中的运行引擎，同时也Docker运行的核心模块。它扮演Docker container存储仓库的角色，并且通过执行job的方式来操纵管理这些容器。 在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：{“create”: daemon.ContainerCreate,}，则说明当名为”create”的job在运行时，执行的是daemon.ContainerCreate的handler。 4.2.3 JOB 一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job。例如：在容器内部运行一个进程，这是一个job；创建一个新的容器，这是一个job，从Internet上下载一个文档，这是一个job；包括之前在Docker Server部分说过的，创建Server服务于HTTP的API，这也是一个job，等等。 Job的设计者，把Job设计得与Unix进程相仿。比如说：Job有一个名称，有参数，有环境变量，有标准的输入输出，有错误处理，有返回状态等。 4.3 Docker Registry Docker Registry是一个存储容器镜像的仓库。而容器镜像是在容器被创建时，被加载用来初始化容器的文件架构与目录。 在Docker的运行过程中，Docker Daemon会与Docker Registry通信，并实现搜索镜像、下载镜像、上传镜像三个功能，这三个功能对应的job名称分别为”search”，”pull” 与 “push”。 其中，在Docker架构中，Docker可以使用公有的Docker Registry，即大家熟知的Docker Hub，如此一来，Docker获取容器镜像文件时，必须通过互联网访问Docker Hub；同时Docker也允许用户构建本地私有的Docker Registry，这样可以保证容器镜像的获取在内网完成。 4.4 Graph Graph在Docker架构中扮演已下载容器镜像的保管者，以及已下载容器镜像之间关系的记录者。一方面，Graph存储着本地具有版本信息的文件系统镜像，另一方面也通过GraphDB记录着所有文件系统镜像彼此之间的关系。Graph的架构如图4.3。 图4.3 Graph架构示意图 其中，GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录。它仅仅实现了大多数图数据库所拥有的一个小的子集，但是提供了简单的接口表示节点之间的关系。 同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs。 4.5 Driver Driver是Docker架构中的驱动模块。通过Driver驱动，Docker可以实现对Docker容器执行环境的定制。由于Docker运行的生命周期中，并非用户所有的操作都是针对Docker容器的管理，另外还有关于Docker运行信息的获取，Graph的存储与记录等。因此，为了将Docker容器的管理从Docker Daemon内部业务逻辑中区分开来，设计了Driver层驱动来接管所有这部分请求。 在Docker Driver的实现中，可以分为以下三类驱动：graphdriver、networkdriver和execdriver。 graphdriver主要用于完成容器镜像的管理，包括存储与获取。即当用户需要下载指定的容器镜像时，graphdriver将容器镜像存储在本地的指定目录；同时当用户需要使用指定的容器镜像来创建容器的rootfs时，graphdriver从本地镜像存储目录中获取指定的容器镜像。 在graphdriver的初始化过程之前，有4种文件系统或类文件系统在其内部注册，它们分别是aufs、btrfs、vfs和devmapper。而Docker在初始化之时，通过获取系统环境变量”DOCKER_DRIVER”来提取所使用driver的指定类型。而之后所有的graph操作，都使用该driver来执行。 graphdriver的架构如图4.4： 图4.4 graphdriver架构示意图 networkdriver的用途是完成Docker容器网络环境的配置，其中包括Docker启动时为Docker环境创建网桥；Docker容器创建时为其创建专属虚拟网卡设备；以及为Docker容器分配IP、端口并与宿主机做端口映射，设置容器防火墙策略等。networkdriver的架构如图4.5： 图4. 5 networkdriver架构示意图 execdriver作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。在execdriver的实现过程中，原先可以使用LXC驱动调用LXC的接口，来操纵容器的配置以及生命周期，而现在execdriver默认使用native驱动，不依赖于LXC。具体体现在Daemon启动过程中加载的ExecDriverflag参数，该参数在配置文件已经被设为”native”。这可以认为是Docker在1.2版本上一个很大的改变，或者说Docker实现跨平台的一个先兆。execdriver架构如图4.6： 图4.6 execdriver架构示意图 4.6 libcontainer libcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API。 正是由于libcontainer的存在，Docker可以直接调用libcontainer，而最终操纵容器的namespace、cgroups、apparmor、网络设备以及防火墙规则等。这一系列操作的完成都不需要依赖LXC或者其他包。libcontainer架构如图4.7： 图4.7 libcontainer示意图 另外，libcontainer提供了一整套标准的接口来满足上层对容器管理的需求。或者说，libcontainer屏蔽了Docker上层对容器的直接管理。又由于libcontainer使用Go这种跨平台的语言开发实现，且本身又可以被上层多种不同的编程语言访问，因此很难说，未来的Docker就一定会紧紧地和Linux捆绑在一起。而于此同时，Microsoft在其著名云计算平台Azure中，也添加了对Docker的支持，可见Docker的开放程度与业界的火热度。 暂不谈Docker，由于libcontainer的功能以及其本身与系统的松耦合特性，很有可能会在其他以容器为原型的平台出现，同时也很有可能催生出云计算领域全新的项目。 4.7 Docker container Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。 Docker按照用户的需求与指令，订制相应的Docker容器： • 用户通过指定容器镜像，使得Docker容器可以自定义rootfs等文件系统； • 用户通过指定计算资源的配额，使得Docker容器使用指定的计算资源； • 用户通过配置网络及其安全策略，使得Docker容器拥有独立且安全的网络环境； • 用户通过指定运行的命令，使得Docker容器执行指定的工作。 Docker容器示意图如图4.8： 图4.8 Docker容器示意图 5 Docker运行案例分析 上一章节着重于Docker架构中各个部分的介绍。本章的内容，将以串联Docker各模块来简要分析，分析原型为Docker中的docker pull与docker run两个命令。 5.1 docker pull docker pull命令的作用为：从Docker Registry中下载指定的容器镜像，并存储在本地的Graph中，以备后续创建Docker容器时的使用。docker pull命令执行流程如图5.1。 图5.1 docker pull命令执行流程示意图 如图，图中标记的红色箭头表示docker pull命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。 (1) Docker Client接受docker pull命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/images/create? “+”xxx”； (2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler； (3) mux.Router将请求路由分发至相应的handler，具体为PostImagesCreate； (4) 在PostImageCreate这个handler之中，一个名为”pull”的job被创建，并开始执行； (5) 名为”pull”的job在执行过程中，执行pullRepository操作，即从Docker Registry中下载相应的一个或者多个image； (6) 名为”pull”的job将下载的image交给graphdriver； (7) graphdriver负责将image进行存储，一方创建graph对象，另一方面在GraphDB中记录image之间的关系。 5.2 docker run docker run命令的作用是在一个全新的Docker容器内部运行一条指令。Docker在执行这条命令的时候，所做工作可以分为两部分：第一，创建Docker容器所需的rootfs；第二，创建容器的网络等运行环境，并真正运行用户指令。因此，在整个执行流程中，Docker Client给Docker Server发送了两次HTTP请求，第二次请求的发起取决于第一次请求的返回状态。Docker run命令执行流程如图5.2。 图5.2 docker run命令执行流程示意图 如图，图中标记的红色箭头表示docker run命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。 (1) Docker Client接受docker run命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/containers/create? “+”xxx”； (2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler； (3) mux.Router将请求路由分发至相应的handler，具体为PostContainersCreate； (4) 在PostImageCreate这个handler之中，一个名为”create”的job被创建，并开始让该job运行； (5) 名为”create”的job在运行过程中，执行Container.Create操作，该操作需要获取容器镜像来为Docker容器创建rootfs，即调用graphdriver； (6) graphdriver从Graph中获取创建Docker容器rootfs所需要的所有的镜像； (7) graphdriver将rootfs所有镜像，加载安装至Docker容器指定的文件目录下； (8) 若以上操作全部正常执行，没有返回错误或异常，则Docker Client收到Docker Server返回状态之后，发起第二次HTTP请求。请求方法为”POST”，请求URL为”/containers/”+containerID+”/start”； (9) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler； (10) mux.Router将请求路由分发至相应的handler，具体为PostContainersStart； (11) 在PostContainersStart这个handler之中，名为”start”的job被创建，并开始执行； (12) 名为”start”的job执行完初步的配置工作后，开始配置与创建网络环境，调用networkdriver； (13) networkdriver需要为指定的Docker容器创建网络接口设备，并为其分配IP，port，以及设置防火墙规则，相应的操作转交至libcontainer中的netlink包来完成； (14) netlink完成Docker容器的网络环境配置与创建； (15) 返回至名为”start”的job，执行完一些辅助性操作后，job开始执行用户指令，调用execdriver； (16) execdriver被调用，初始化Docker容器内部的运行环境，如命名空间，资源控制与隔离，以及用户命令的执行，相应的操作转交至libcontainer来完成； (17) libcontainer被调用，完成Docker容器内部的运行环境初始化，并最终执行用户要求启动的命令。 6 总结 本文从Docker 1.2的源码入手，分析抽象出Docker的架构图，并对该架构图中的各个模块进行功能与实现的分析，最后通过两个docker命令展示了Docker内部的运行。 通过对Docker架构的学习，可以全面深化对Docker设计、功能与价值的理解。同时在借助Docker实现用户定制的分布式系统时，也能更好地找到已有平台与Docker较为理想的契合点。另外，熟悉Docker现有架构以及设计思想，也能对云计算PaaS领域带来更多的启发，催生出更多实践与创新。 链接：https://www.2cto.com/kf/201701/582655.html 链接：https://blog.csdn.net/gsllovefly/article/details/51083419","path":"posts/c10c.html","date":"08-04","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"}]},{"title":"Docker的基本操作命令","text":"Docker介绍 Docker 是一个能够把开发应用程序自动部署到容器的开源引擎。它由Docker公司的团队编写，基于Apache 2.0开源协议授权。它提供了一个简单、轻量的建模方式，使开发生命周期更高效快速，鼓励了面向服务的架构设计。Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。 Docker 的特点： 更快速的交付和部署 更高效的虚拟化 更轻松的迁移和扩展 更简单的管理 容器技术与传统虚拟机性能对比 Docker与虚拟机建构对比 Docker 容器本质上是宿主机上的一个进程。Docker 通过 namespace 实现了资源隔离，通过 cgroups 实现了资源的限制，通过写时复制机制（copy-on-write）实现了高效的文件操作。 **Docker有五个命名空间：**进程、网络、挂载、宿主和共享内存，为了隔离有问题的应用，Docker运用Namespace将进程隔离，为进程或进程组创建已隔离的运行空间，为进程提供不同的命名空间视图。这样，每一个隔离出来的进程组，对外就表现为一个container(容器)。需要注意的是，Docker让用户误以为自己占据了全部资源，但这并不是”虚拟机”。 Docker 中的三个概念：镜像，容器，仓库 镜像（image）：Docker 镜像就是一个只读的模板，镜像可以用来创建 Docker 容器。Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 镜像是一种文件结构。Dockerfile中的每条命令都会在文件系统中创建一个新的层次结构，文件系统在这些层次上构建起来，镜像就构建于这些联合的文件系统之上。Docker官方网站专门有一个页面来存储所有可用的镜像，网址是：index.docker.io。 容器（ Container）：容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。可以把容器看做是一个简易版的 Linux 环境，Docker 利用容器来运行应用。镜像是只读的，容器在启动的时候创建一层可写层作为最上层。 仓库：仓库是集中存放镜像文件的场所，仓库注册服务器（Registry）上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。目前，最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。 Docker仓库用来保存我们的images，当我们创建了自己的image之后我们就可以使用push命令将它上传到公有或者私有仓库，这样下次要在另外一台机器上使用这个image时候，只需要从仓库上pull下来就可以了。Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的服务。 Docker 基本操作 12 [root@localhost ~]# docker search mysql//查找镜像 这样查找相当于在https://hub.docker.com/中查找，大家尽量使用官方的镜像 12[root@localhost ~]# docker pull busybox//拉取镜像 12[root@localhost ~]# docker save -o busybox.tar busybox:latest//把镜像导出到本地 -o：相当--output导出 12[root@localhost ~]# docker images//查看本地镜像 仓库（镜像名称） 镜像标签 镜像id 创建时间 大小 虽然我们看到镜像标签为latest（最新的），但并不表示他一定是最新的。而且镜像如果没有写标签，默认以latest为标签。 12[root@localhost ~]# docker rmi busybox:latest//删除镜像 12[root@localhost ~]# docker images//查看本地镜像这里没有busybox 12[root@localhost ~]# docker load -i busybox.tar//根据本地镜像包导入镜像 12[root@localhost ~]# docker images//查看本地镜像这里又有busybox 12345678[root@localhost ~]# docker ps//查看容器-正在运行的[root@localhost ~]# docker ps -a//查看所有容器[root@localhost ~]# docker rm c3bb3a6f73eb//删除容器 id或镜像名称（不能删除正在运行的容器） 12[root@localhost ~]# docker stop test//停止容器运行 （记得验证一下docker ps -a） 12[root@localhost ~]# docker start test//启动容器 （记得验证一下docker ps -a） 12[root@localhost ~]# docker rm test -f//强制删除容器 （记得验证一下docker ps -a） 12[root@localhost ~]# docker ps -a -q | xargs docker rm -f//强制删除所有容器（生产环境严禁使用） 1234[root@localhost ~]# docker ps -a -q | xargs docker start -f//强制开启所有容器（生产环境严禁使用）[root@localhost ~]# docker ps -a -q | xargs docker stop -f//强制关闭所有容器（生产环境严禁使用） 123456789[root@localhost ~]# docker run -it --name test1 busybox:latest//开启一个容器-i：可交互-t：伪终端-d：守护进程--name：容器命名--restart=always：始终保持运行（随着docker开启而运行） [root@localhost ~]# docker run -itd --name test2 --restart=always busybox:latest//docker重启后，始终保持运行（随着docker开启而运行） 路由转发 123456[root@localhost ~]# vim /etc/sysctl.conf //添加路由转发[root@localhost ~]# sysctl -pnet.ipv4.ip_forward = 1net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1 进入容器方法 12345678910[root@localhost ~]# docker exec -it test2 /bin/sh//进入一个容器（退出容器后还在运行）[root@localhost ~]# docker attach test2//也是进入一个容器（退出容器不在运行）区别：exec进入的方式需要添加-i -t选项,后边还需要给容器一个shell环境。但attach就不需要这么麻烦。exec进入的方式:如果执行exit退出， 容器仍然保持运行。attach:如果执行exit退出, 容器会被关闭。如果想要保持容器不被关闭，可以使用用键盘: Ctrl + p Ctrl +q可以实现。本质上去区别: exec 进入的方法，会生产新的进程。attach不会生产新进程。 强制删除镜像 123 [root@localhost ~]# docker rmi centos:7 -f//强制删除镜像上面是把镜像标签给删了，要想彻底删除镜像，用下面的命令把镜像id也删了，docker有缓存机制，即使把这个镜像给删了，但是会有缓存，其他的容器依旧可以使用 Docker的基本操作逻辑 基于centos: 7镜像运行-个容器，并且,在这个容器内部署Nginx服务。 1)下载centos：7镜像 1[root@localhost ~]# docker pull centos:7 12[root@localhost ~]# rz上传一个nginx包 2)运行容器 1[root@localhost ~]# docker run -itd --name webapp --restart=always centos:7 3）进入容器，开始部署nginx服务 12345[root@localhost ~]# docker cp nginx-1.14.0.tar.gz webapp:/root//将nginx包导入到容器内[root@localhost ~]# docker exec -it webapp /bin/bash//进入容器[root@8604fb370aab /]# ls root 安装nginx 12345678910111213141516171819[root@8604fb370aab /]# cd /root[root@8604fb370aab ~]# tar zxf nginx-1.14.0.tar.gz[root@8604fb370aab ~]# yum -y install gcc pcre pcre-devel openssl-devel zlib zlib-devel make//安装nginx所需依赖[root@8604fb370aab ~]# cd nginx-1.14.0[root@8604fb370aab nginx-1.14.0]# useradd -M -s /sbin/nologin nginx//创建用户[root@8604fb370aab nginx-1.14.0]# ./configure --prefix=/usr/local/nginx --user=nginx --group=nginx &amp;&amp; make &amp;&amp; make install//编译安装 [root@8604fb370aab nginx-1.14.0]# ln -s /usr/local/nginx/sbin/nginx /usr/local/sbin///链接命令目录[root@8604fb370aab nginx-1.14.0]# nginx//启动nginx[root@8604fb370aab nginx-1.14.0]# cd /usr/local/nginx/html/[root@8604fb370aab html]# echo This is a testweb in container &gt; index.html//创建一个测试页面[root@8604fb370aab html]# curl 127.0.0.1//访问网页 123456[root@8604fb370aab /]# yum provides ip//查看哪一个组件支持这条命令[root@8604fb370aab /]# yum -y install net-tools//安装支持这条命令的[root@8604fb370aab /]# ifconfig//查看ip 宿主机查看网页 1[root@localhost ~]# curl 172.17.0.4 12[root@localhost ~]# docker commit webapp myweb:xgp//把容器制作成镜像 （会返回一个哈希值，代表的是镜像的id号）增加可移植性 12[root@localhost ~]# docker images//查看镜像 123456[root@localhost ~]# docker run -itd --name webapp-2 myweb:xgp[root@localhost ~]# docker exec -it webapp-2 /bin/bash[root@e8d15e9aef29 /]# nginx [root@e8d15e9aef29 /]# curl 127.0.0.1This is a testweb in container[root@e8d15e9aef29 /]# ifconfig 查看网页 1[root@localhost ~]# curl 172.17.0.5","path":"posts/f1f1.html","date":"08-03","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"}]},{"title":"docker底层原理介绍","text":"链接：https://blog.51cto.com/14320361/2457143 1.docker介绍 1.1什么是docker Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上。 1.2docker能解决什么问题 1.2.1高效有序利用资源 机器资源有限； 单台机器得部署多个应用； 应用之间互相隔离； 应用之间不能发生资源抢占，每个应用只能使用事先注册申请的资源。 1.2.2一次编译，到处运行 类似于java代码，应用及依赖的环境构建一次，可以到处运行。 1.2.docker底层原理介绍 1.2.1Linux的namespace和cgroup简单理解 namespace:类似于JAVA的命名空间 controll groups ： controll （system resource） （for） （process）groups 1.2.2Linux中的namespace 在Linux系统中，可以同时存在多用户多进程，那么对他们的运行协调管理，通过进程调度和进度管理可以解决，但是，整体资源是有限的，怎么把有限的资源（进程号、网络资源等等）合理分配给各个用户所在的进程？ Linux Namespaces机制提供一种资源隔离方案。PID,IPC,Network等系统资源不再是全局性的，而是属于某个特定的Namespace。每个namespace下的资源对于其他namespace下的资源都是透明，不可见的。因此在操作系统层面上看，就会出现多个相同pid的进程。系统中可以同时存在两个进程号为0,1,2的进程，由于属于不同的namespace，所以它们之间并不冲突。而在用户层面上只能看到属于用户自己namespace下的资源，例如使用ps命令只能列出自己namespace下的进程。这样每个namespace看上去就像一个单独的Linux系统。 命名空间建立系统的不同视图， 对于每一个命名空间，从用户看起来，应该像一台单独的Linux计算机一样，有自己的init进程(PID为0)，其他进程的PID依次递增，A和B空间都有PID为0的init进程，子容器的进程映射到父容器的进程上，父容器可以知道每一个子容器的运行状态，而子容器与子容器之间是隔离的。 **|** namespace | 引入的相关内核版本 | 被隔离的全局系统资源 | 在容器语境下的隔离效果 | | — | — | — | — | | Mount namespaces | Linux 2.4.19 | 文件系统挂接点 | 将一个文件系统的顶层目录挂到另一个文件系统的子目录上，使它们成为一个整体，称为挂载。把该子目录称为挂载点。 Mount namespace用来隔离文件系统的挂载点, 使得不同的mount namespace拥有自己独立的挂载点信息，不同的namespace之间不会相互影响，这对于构建用户或者容器自己的文件系统目录非常有用。 | | UTS namespaces | Linux 2.6.19 | nodename 和 domainname | UTS，UNIX Time-sharing System namespace提供了主机名和域名的隔离。能够使得子进程有独立的主机名和域名(hostname)，这一特性在Docker容器技术中被用到，使得docker容器在网络上被视作一个独立的节点，而不仅仅是宿主机上的一个进程。 | | IPC namespaces | Linux 2.6.19 | 特定的进程间通信资源，包括System V IPC 和 POSIX message queues | IPC全称 Inter-Process Communication，是Unix/Linux下进程间通信的一种方式，IPC有共享内存、信号量、消息队列等方法。所以，为了隔离，我们也需要把IPC给隔离开来，这样，只有在同一个Namespace下的进程才能相互通信。如果你熟悉IPC的原理的话，你会知道，IPC需要有一个全局的ID，即然是全局的，那么就意味着我们的Namespace需要对这个ID隔离，不能让别的Namespace的进程看到。 | | PID namespaces | Linux 2.6.24 | 进程 ID 数字空间 （process ID number space） | PID namespaces用来隔离进程的ID空间，使得不同pid namespace里的进程ID可以重复且相互之间不影响。 PID namespace可以嵌套，也就是说有父子关系，在当前namespace里面创建的所有新的namespace都是当前namespace的子namespace。父namespace里面可以看到所有子孙后代namespace里的进程信息，而子namespace里看不到祖先或者兄弟namespace里的进程信息。 | | Network namespaces | 始于Linux 2.6.24 完成于 Linux 2.6.29 | 网络相关的系统资源 | 每个容器用有其独立的网络设备，IP 地址，IP 路由表，/proc/net 目录，端口号等等。这也使得一个 host 上多个容器内的同一个应用都绑定到各自容器的 80 端口上。 | | User namespaces | 始于 Linux 2.6.23 完成于 Linux 3.8) | 用户和组 ID 空间 | User namespace用来隔离user权限相关的Linux资源，包括user IDs and group IDs。 这是目前实现的namespace中最复杂的一个，因为user和权限息息相关，而权限又事关容器的安全，所以稍有不慎，就会出安全问题。 在不同的user namespace中，同样一个用户的user ID 和group ID可以不一样，换句话说，一个用户可以在父user namespace中是普通用户，在子user namespace中是超级用户 1.3Namespace（名称空间） 用来隔离容器 12 [root@localhost ~]# docker run -it --name test centos /bin/bash//进入到容器里面 12[root@41052cceb473 /]# ls//查看一下和宿主机差不多，都是从宿主机链接过来的 12[root@41052cceb473 /]# uname -r//查看一下内核，和宿主机也是一样的 如果虚拟机内服务对内核版有要求，这个服务就不太适合用docker来实现了，因为docker就是共用宿主机的内核，可以使用kvm之类的虚拟机。 12[root@localhost ~]# docker pull ubuntu//使用docker下载一个Ubuntu 12[root@localhost ~]# docker images//查看一下 1234[root@localhost ~]# docker run -it ubuntu:latest /bin/bash//进入ubuntu环境root@afbee6750865:/# ls ///查看一下 12root@48c8dd7b098e:/# uname -r//查看一下内核 Docker本身不占用任何端口，他一般是在后台运行，无论在docker里进行什么操作（系统、服务）对于docker来说他们仅仅就是一个进程 Run-centos系统（nginx，web） Busybox：欺骗层。欺骗docker中的虚拟机是在自己独立的环境中 解耦：解除耦合、冲突。 耦合：冲突现象。 1.4 Namespace操作 /proc /sys:虚拟文件系统，伪目录文件 12[root@localhost ~]# cd /proc/[root@localhost proc]# ls 1234567[root@localhost proc]# echo $$//当前的进程编号3864[root@localhost proc]# cd 3864[root@localhost 3864]# cd ns[root@localhost ns]# ll//可以看到一闪一闪的 1[root@localhost ns]# ls IPC:共享内存、消息列队 MNT:挂载点、文件系统 NET:网络栈 PID: 进程编号 USER:用户、组 UTS:主机名、域名 namespec这六项隔离，实现了容器与宿主机，容器与容器之间的隔离 //创建一个用户并设置密码 IPC:共享内存、消息列队 MNT:挂载点、文件系统 NET:网络栈 PID: 进程编号 USER:用户、组 UTS:主机名、域名 namespec这六项隔离，实现了容器与宿主机，容器与容器之间的隔离 //创建一个用户并设置密码 123[root@localhost ns]# useradd bdqn [root@localhost ns]# echo 123.com | passwd --stdin bdqn[root@localhost ns]# id bdqn 查看docker进程 [root@localhost ns]# docker ps -a 12345[root@localhost ns]# docker start test//启动centos[root@localhost ns]# docker exec -it test /bin/bash//进入docker容器[root@41052cceb473 /]# id dbqn 1[root@41052cceb473 /]# echo $$ 2.1linux cgroup介绍 2.1.1有了namespace为什么还要cgroup: Docker 容器使用 linux namespace 来隔离其运行环境，使得容器中的进程看起来就像一个独立环境中运行一样。但是，光有运行环境隔离还不够，因为这些进程还是可以不受限制地使用系统资源，比如网络、磁盘、CPU以及内存 等。关于其目的，一方面，是为了防止它占用了太多的资源而影响到其它进程；另一方面，在系统资源耗尽的时候，linux 内核会触发 OOM，这会让一些被杀掉的进程成了无辜的替死鬼。因此，为了让容器中的进程更加可控，Docker 使用 Linux cgroups 来限制容器中的进程允许使用的系统资源。 2.1.2原理 Linux Cgroup 可为系统中所运行任务（进程）的用户定义组群分配资源 — 比如 CPU 时间、系统内存、网络带宽或者这些资源的组合。可以监控管理员配置的 cgroup，拒绝 cgroup 访问某些资源，甚至在运行的系统中动态配置 cgroup。所以，可以将 controll groups 理解为 controller （system resource） （for） （process）groups，也就是是说它以一组进程为目标进行系统资源分配和控制。它主要提供了如下功能： Resource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。 Prioritization: 优先级控制，比如：CPU利用和磁盘IO吞吐。 Accounting: 一些审计或一些统计，主要目的是为了计费。 Controll: 挂起进程，恢复执行进程。 使用 cgroup，系统管理员可更具体地控制对系统资源的分配、优先顺序、拒绝、管理和监控。可更好地根据任务和用户分配硬件资源，提高总体效率。 在实践中，系统管理员一般会利用CGroup做下面这些事： 隔离一个进程集合（比如：nginx的所有进程），并限制他们所消费的资源，比如绑定CPU的核。 为这组进程分配其足够使用的内存 为这组进程分配相应的网络带宽和磁盘存储限制 限制访问某些设备（通过设置设备的白名单） 2.1.3Cgroup(控制组)操作 资源的限制，docker对于资源的占用 123[root@localhost ~]# cd /sys/fs/cgroup///对cpu，内存限制的目录[root@localhost cgroup]# ls 12[root@localhost cgroup]# cd cpu[root@localhost cpu]# ls cpu.shares：权重 tasks：这个文件内的数字，记录的是进程编号。PID 12[root@localhost cpu]# cd docker/[root@localhost docker]# ls 1234[root@localhost docker]# cat tasks//里面是空的[root@localhost docker]# cd 41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70/[root@localhost41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70]# ls 1[root@localhost41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70]# cat tasks 四大功能： 1） 资源的限制：cgroup可以对进程组使用的资源总额进行限制 2） 优先级分配：通过分配的cpu时间片数量以及硬盘IO带宽的大小，实际上相当于控制了进程运行的优先级别 3） 资源统计： group可以统计系统资源使用量，比如gpu使用时间，内存使用量等，用于按量计费。同时还支持挂起动能，也就是说通过cgroup把所有 资源限制起来,对资源都不能使用，注意着并不是说我们的程序不能使用了,知识不能使用资源，处于等待状态。 4） 进程控制：可以对进程组执行挂起、恢复等操作。 2.1.4 内存限额 容器内存包括两个部分：物理内存和swap 可以通过参数控制容器内存的使用量： -m或者–memory:设置内存的使用限额 –memory-swap:设置内存+ swap的使用限额 举个例子： 运行一个容器，并且限制该容器最多使用200M内存和100M的swap 123[root@localhost ~]# docker run -it -m 200M --memory-swap 300M centos:7[root@fba67fec2718 ~]# cd /sys/fs/cgroup/[root@fba67fec2718 cgroup]# ls 1234[root@fba67fec2718 cgroup]# cd memory/[root@fba67fec2718 memory]# ls[root@fba67fec2718 memory]# cat memory.limit_in_bytes//查看内存使用限制，(单位字节） 12[root@fba67fec2718 memory]# cat memory.memsw.limit_in_bytes//查看交换分区，内存+swap限制 运行一个新容器，并且不限制该容器 1234[root@localhost ~]# docker run -it centos:7[root@5be901bfb093 /]# cd /sys/fs/cgroup/memory/[root@5be901bfb093 memory]# cat memory.limit_in_bytes//查看内存限制 12[root@5be901bfb093 memory]# cat memory.memsw.limit_in_bytes//查看交换分区，内存+swap限制 对比一个没有限制的容器，我们会发现，如果运行容器之后不限制内存的话，意味着没有限制。 2.1.5 CPU使用 通过-c或者–cpu -shares设置容器使用cpu的权重。如果不设置默认为1024. 举个例子： 没有限制 1234[root@localhost ~]# docker run -it --name containerA centos:7//没有限制，1024[root@8683d8ff8234 /]# cd /sys/fs/cgroup/cpu[root@8683d8ff8234 cpu]# cat cpu.shares 限制CPU使用权重为512 1234[root@localhost ~]# docker run -it --name containerB -c 512 centos:7//限制CPU使用权重为512[root@d919d906295d /]# cd /sys/fs/cgroup/cpu//可以看到cpu已经限制了 2.1.6 容器的Block IO 磁盘的读写。 Docker中可以通过设置权重，限制bps和iops的方式控制容器读写磁盘的IO bps:每秒读写的数据量byte per second iopS:每秒IO的次数 io per second。 默认情况下，所有容器都能够平等的读写磁盘，也可以通过–blkig-weight参数改变容器的blocklO的优先级。 –device-read-bps:显示读取某个设备的bps。 –device-write-bps:显示写入某个设备的bps. –device-read-iops:显示读取某个设备的iops. –device-write-iops:显示写入某个设备的iops. 限制testA这个容器，写入/dev/sda这块磁盘的bps为30MB 1234[root@localhost ~]# docker run -it --name testA --device-write-bps /dev/sda:30MB centos:7 [root@60e59e96fc16 /]# time dd if=/dev/zero of=test.out bs=1M count=800 oflag=direct//从/dev/zero输入，然后输出到test.out文件中，每次大小为1M，总共800次,oflag=direct 用来指定directlQ方式写文件，这样才会使--device-write-bps生效。 1[root@60e59e96fc16 /]# du -h test.out docker没有限制 12[root@localhost ~]# docker run -it --name testc centos:7[root@5bf5f3d60d0e /]# time dd if=/dev/zero of=test.out bs=1M count=800 oflag=direct 1[root@5bf5f3d60d0e /]# du -h test.out 3.Docker虚拟化与普通虚拟化的区别是什么？ 虚拟机： 我们传统的虚拟机需要模拟整台机器包括硬件，每台虚拟机都需要有自己的操作系统，虚拟机一旦被开启，预分配给他的资源将全部被占用。，每一个虚拟机包括应用，必要的二进制和库，以及一个完整的用户操作系统。 Docker： 容器技术是和我们的宿主机共享硬件资源及操作系统可以实现资源的动态分配。 容器包含应用和其所有的依赖包，但是与其他容器共享内核。容器在宿主机操作系统中，在用户空间以分离的进程运行。 虚拟机和容器都是在硬件和操作系统以上的，虚拟机有Hypervisor层，Hypervisor是整个虚拟机的核心所在。他为虚拟机提供了虚拟的运行平台，管理虚拟机的操作系统运行。每个虚拟机都有自己的系统和系统库以及应用。 容器没有Hypervisor这一层，并且每个容器是和宿主机共享硬件资源及操作系统，那么由Hypervisor带来性能的损耗，在linux容器这边是不存在的。 但是虚拟机技术也有其优势，能为应用提供一个更加隔离的环境，不会因为应用程序的漏洞给宿主机造成任何问题。同时还支持跨操作系统的虚拟化，例如你可以在linux操作系统下运行windows虚拟机。 从虚拟化层面来看，传统虚拟化技术是对硬件资源的虚拟，容器技术则是对进程的虚拟，从而可提供更轻量 级的虚拟化，实现进程和资源的隔离。 从架构来看，Docker比虚拟化少了两层，取消了hypervisor层和GuestOS层，使用 Docker Engine 进行调度和隔离，所有应用共用主机操作系统，因此在体量上，Docker较虚拟机更轻量级，在性能上优于虚拟化，接近裸机性能。从应用场景来 看，Docker和虚拟化则有各自擅长的领域，在软件开发、测试场景和生产运维场景中各有优劣 具体对比： docker启动快速属于秒级别。虚拟机通常需要几分钟去启动。 docker需要的资源更少，docker在操作系统级别进行虚拟化，docker容器和内核交互，几乎没有性能损耗，性能优于通过Hypervisor层与内核层的虚拟化。； docker更轻量，docker的架构可以共用一个内核与共享应用程序库，所占内存极小。同样的硬件环境，Docker运行的镜像数远多于虚拟机数量。对系统的利用率非常高 与虚拟机相比，docker隔离性更弱，docker属于进程之间的隔离，虚拟机可实现系统级别隔离； 安全性： docker的安全性也更弱。Docker的租户root和宿主机root等同，一旦容器内的用户从普通用户权限提升为root权限，它就直接具备了宿主机的root权限，进而可进行无限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且虚拟机利用如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种隔离技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离，这使得容器容易受到***。 可管理性：docker的集中化管理工具还不算成熟。各种虚拟化技术都有成熟的管理工具，例如VMware vCenter提供完备的虚拟机管理能力。 高可用和可恢复性：docker对业务的高可用支持是通过快速重新部署实现的。虚拟化具备负载均衡，高可用，容错，迁移和数据保护等经过生产实践检验的成熟保障机制，VMware可承诺虚拟机99.999%高可用，保证业务连续性。 快速创建、删除：虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了无论是开发、测试、部署都可以节约大量时间。 交付、部署：虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化；Docker在Dockerfile中记录了容器构建过程，可在集群中实现快速分发和快速部署; 3.1.1 docker结构介绍 基础设施(Infrastructure)。 主操作系统(Host Operating System)。所有主流的Linux发行版都可以运行Docker。对于MacOS和Windows，也有一些办法”运行”Docker。 Docker守护进程(Docker Daemon)。Docker守护进程取代了Hypervisor，它是运行在操作系统之上的后台进程，负责管理Docker容器。 各种依赖。对于Docker，应用的所有依赖都打包在Docker镜像中，Docker容器是基于Docker镜像创建的。 应用。应用的源代码与它的依赖都打包在Docker镜像中，不同的应用需要不同的Docker镜像。不同的应用运行在不同的Docker容器中，它们是相互隔离的。 Docker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源；虚拟机更擅长于资源的完全隔离。 链接：https://blog.51cto.com/14320361/2457143","path":"posts/df9f.html","date":"08-02","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"}]},{"title":"花式安装Docker","text":"//使用docker的基本要求 12[root@localhost ~]# uname -r3.10.0-693.el7.x86_64 内核版本必须是3.10以上的。 一， 安装dockers 在安装docker之前，再说一点，docker现在有两个版本，一个叫做docker-EE企业版，收费的一个叫docker-CE社区版，免费版，其实两个版本并没有太大的偏差，不一样的是docker公司会提供后续的官方的技术支持等服务，对于我们来说，肯定用社区办的多，我们拿来学习社区办更是可以的。 Docker的官网 https://www.docker.com/ 1，从Docker的官方下载 https://www.docker.com/ 2．官网安装docker方法一 1234567891011121314151617181920212223[root@localhost ~]# vim /etc/yum.repos.d/docke-ce.repo//编写yum源[docker-ce]name=docker-cebaseurl=https://download.docker.com/linux/centos/7/x86_64/stable/Packages/gpgcheck=0enabled=1 [root@localhost ~]# yum repolist//查看仓库状态 [root@localhost ~]# vim /etc/yum.repos.d/docke-ce.repo//修改yum源[docker-ce]name=docker-cebaseurl=https://download.docker.com/linux/centos/7/x86_64/stable/gpgcheck=0enabled=1[root@localhost ~]# yum repolist//查看仓库状态 [root@localhost ~]# yum -y install docker-ce//默认下载最新版，时间慢，一般不用这个 因为网速原因，所以我们一般可以采取另外- -种方法，从我们国内下载，国内很多网站都提供了docker-ce的镜像站，比如说阿里云、网易云、清华大学镜像站等。这里我们从阿里云下载的方式来下载。 3.阿里云下载方法二 12[root@localhost ~]# rm -rf /etc/yum.repos.d/docke-ce.repo//删除刚刚的yum源 进入阿里镜像站 https://developer.aliyun.com/mirror 12345[root@localhost ~]# yum install -y yum-utils device-mapper-persistent-data lvm2[root@localhost ~]# yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo[root@localhost ~]# ls /etc/yum.repos.d///查看yum源 12[root@localhost ~]# yum repolist//查看仓库状态 12345[root@localhost ~]# yum makecache//做yum缓存，提速[root@localhost ~]# yum list docker-ce.x86_64 --showduplicates | sort -r//查看docker可用的版本 //这里我们下载指定版本18.9.0，注意并没有采取阿里云官方推荐的方法，我们分别下载了docker-ce,docker-ce-cli和containerd.io这3个组件。 12[root@localhost ~]# yum -y install docker-ce-18.09.0-3.el7 docker-ce-cli-18.09.0-3.el7 tainerd.io-1.2.0-el7//安装docker-ce,docker-ce-cli和containerd.io这3个组件 4.安装完成之后 1234567[root@localhost ~]# systemctl start docker//开启docker[root@localhost ~]# systemctl enable docker//docker加入开机自启[root@localhost ~]# docker -vDocker version 18.09.0, build 4d60db4//查看docker版本是否是指定的版本 12[root@localhost ~]# docker version//查看docker版本信息 12如果是最小化安装，来装一个tab命令补全[root@localhost ~]# yum -y install bash-completion 二，Docker的基本概念 image:镜像 container：容器 repostry:仓库 镜像是容器运行的基石，容器是镜像运行之后的实例。 12[root@localhost ~]# docker pull centos:7//下载一个centos7镜像，特别慢不建议 1，设置加速 浏览器打开加速网站：道客云https://www.daocloud.io/ //使用docker镜像加速器，这里使用的是daocloud的加速器，当然还有其他的加速器，例 如阿里云、清华镜像站等。 [root@localhost ~]# curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io 1234567[root@localhost ~]# systemctl daemon-reload//守护进程[root@localhost ~]# systemctl restart docker//重启docker[root@localhost ~]# docker info//查看docker的详细信息 123[root@localhost ~]# cat /etc/docker/daemon.json&#123;\"registry-mirrors\": [\"http://f1361db2.m.daocloud.io\"]&#125;//都是键值对 12[root@localhost ~]# docker pull centos:7//再次下载centos7 12[root@localhost ~]# docker images//查看本地镜像有哪些 2，更改镜像加速网站为阿里云的 https://www.aliyun.com/product/acr?spm=5176.12825654.eofdhaal5.42.366f2c4axwzdLK&amp;aly_as=kt8HE3oy 1234[root@localhost ~]# cat /etc/docker/daemon.json&#123;\"registry-mirrors\": [\"http://f1361db2.m.daocloud.io\"]&#125; //把刚刚复制的https://x7bv0r2q.mirror.aliyuncs.com，替换掉上面的 也可以更改成这个网址，当然如果你更改之后，还需要执行reload命令，重新加载一下配置文件。 12345[root@docker ~]# systemctl daemon-reload [root@docker ~]# systemctl restart docker[root@docker ~]# docker pull centosUsing default tag: latestlatest: Pulling from library/centos 3，更改镜像加速网站为清华大学的 清华大学镜像站网址：https://mirrors.tuna.tsinghua.edu.cn/ 测试：下载一个nginx [root@localhost ~]# docker pull nginx 12[root@localhost ~]# docker images//查看本地镜像有哪些 12345[root@localhost ~]# docker run -itd -p 80 nginx//多执行几次，运行多台nginx[root@localhost ~]# docker ps//查看docker服务 浏览器测试 **开源项目：**诞生于2013年，dotcloud公司的业余项目，Go语言实现。—公司改名docker 集装箱：目标是实现轻量级的操作系统虚拟化方案。让用户不需要关心容器的管理，使得操作更加简便。 docker和虚拟机、传统虚拟化的区别： 传统的虚拟机：在硬件实现虚拟化，然后创建/安装操作系统。 docker：在操作系统层面实现虚拟化，直接服用本地主机的操作系统。 为什么使用docker 1，与传统虚拟化方式相比，具有众多的优势 a,docker容器启动在秒级 b,docker对系统资源利用率高，一台主机可以同时运行数千个docker容器 c,docker基本不消耗系统资源，使得运行在docker里面的应用的性能很高 2，其他优势： a,更快的支付和部署：开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容易来部署代码； b,更高级的虚拟化，docker容器的运行不需要额外的支持，它是内核级的虚拟化，因此可以实现更高的性能 c,更轻松的迁移和扩展：docker几乎可以在任意平台运行，比如物理机，虚拟机，公有云，私有云，个人电脑，服务器等。 d,更简单的管理：使用docker只需要简单的修改，就可以替代以往大量的更新工作。所有的修改都一增量方式被分发和更新，从而实现自动化并且高效的管理。 docker中的基本概念： 镜像（images):只读的模板，通过这个模板创建docker容器 容器(container):是使用镜像创建并运行的实例。可以简单的将容器看做是简化版的操作系统。(可以看做是操作系统是因为里面包含root用户权限，进程空间和网络空间，还包括运行在里面的应用程序) 仓库(repository):集中存放镜像文件的地方。分为共有仓库和私有仓库。","path":"posts/dd75.html","date":"08-01","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"}]}],"categories":[],"tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"https://wsdlxgp.top/tags/MySQL%E4%BC%98%E5%8C%96/"},{"name":"mysqladmin","slug":"mysqladmin","permalink":"https://wsdlxgp.top/tags/mysqladmin/"},{"name":"--tee","slug":"tee","permalink":"https://wsdlxgp.top/tags/tee/"},{"name":"--prompt","slug":"prompt","permalink":"https://wsdlxgp.top/tags/prompt/"},{"name":"mysqldump","slug":"mysqldump","permalink":"https://wsdlxgp.top/tags/mysqldump/"},{"name":"mysqlslap","slug":"mysqlslap","permalink":"https://wsdlxgp.top/tags/mysqlslap/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"},{"name":"sql结构化查询语句s","slug":"sql结构化查询语句s","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5s/"},{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"python","slug":"python","permalink":"https://wsdlxgp.top/tags/python/"},{"name":"jenkins","slug":"jenkins","permalink":"https://wsdlxgp.top/tags/jenkins/"},{"name":"gitlab","slug":"gitlab","permalink":"https://wsdlxgp.top/tags/gitlab/"},{"name":"HPA","slug":"HPA","permalink":"https://wsdlxgp.top/tags/HPA/"},{"name":"heapster","slug":"heapster","permalink":"https://wsdlxgp.top/tags/heapster/"},{"name":"top","slug":"top","permalink":"https://wsdlxgp.top/tags/top/"},{"name":"weave-scope","slug":"weave-scope","permalink":"https://wsdlxgp.top/tags/weave-scope/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://wsdlxgp.top/tags/Prometheus/"},{"name":"ingress-nginx","slug":"ingress-nginx","permalink":"https://wsdlxgp.top/tags/ingress-nginx/"},{"name":"https","slug":"https","permalink":"https://wsdlxgp.top/tags/https/"},{"name":"ca","slug":"ca","permalink":"https://wsdlxgp.top/tags/ca/"},{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"},{"name":"ingress","slug":"ingress","permalink":"https://wsdlxgp.top/tags/ingress/"},{"name":"ingress controller","slug":"ingress-controller","permalink":"https://wsdlxgp.top/tags/ingress-controller/"},{"name":"secret","slug":"secret","permalink":"https://wsdlxgp.top/tags/secret/"},{"name":"pod","slug":"pod","permalink":"https://wsdlxgp.top/tags/pod/"},{"name":"configmap","slug":"configmap","permalink":"https://wsdlxgp.top/tags/configmap/"},{"name":"StatefulSet","slug":"StatefulSet","permalink":"https://wsdlxgp.top/tags/StatefulSet/"},{"name":"nfs-deployment","slug":"nfs-deployment","permalink":"https://wsdlxgp.top/tags/nfs-deployment/"},{"name":"emptyDir","slug":"emptyDir","permalink":"https://wsdlxgp.top/tags/emptyDir/"},{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"},{"name":"Job","slug":"Job","permalink":"https://wsdlxgp.top/tags/Job/"},{"name":"apiVersion","slug":"apiVersion","permalink":"https://wsdlxgp.top/tags/apiVersion/"},{"name":"CronJob","slug":"CronJob","permalink":"https://wsdlxgp.top/tags/CronJob/"},{"name":"ReplicaSet","slug":"ReplicaSet","permalink":"https://wsdlxgp.top/tags/ReplicaSet/"},{"name":"SetDaemonSet","slug":"SetDaemonSet","permalink":"https://wsdlxgp.top/tags/SetDaemonSet/"},{"name":"labels","slug":"labels","permalink":"https://wsdlxgp.top/tags/labels/"},{"name":"liveness","slug":"liveness","permalink":"https://wsdlxgp.top/tags/liveness/"},{"name":"readiness","slug":"readiness","permalink":"https://wsdlxgp.top/tags/readiness/"},{"name":"Namespace","slug":"Namespace","permalink":"https://wsdlxgp.top/tags/Namespace/"},{"name":"PodRestart","slug":"PodRestart","permalink":"https://wsdlxgp.top/tags/PodRestart/"},{"name":"Policy","slug":"Policy","permalink":"https://wsdlxgp.top/tags/Policy/"},{"name":"service","slug":"service","permalink":"https://wsdlxgp.top/tags/service/"},{"name":"yaml","slug":"yaml","permalink":"https://wsdlxgp.top/tags/yaml/"},{"name":"registry","slug":"registry","permalink":"https://wsdlxgp.top/tags/registry/"},{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"},{"name":"kubeadml","slug":"kubeadml","permalink":"https://wsdlxgp.top/tags/kubeadml/"},{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"},{"name":"webUI","slug":"webUI","permalink":"https://wsdlxgp.top/tags/webUI/"},{"name":"consul","slug":"consul","permalink":"https://wsdlxgp.top/tags/consul/"},{"name":"registrata","slug":"registrata","permalink":"https://wsdlxgp.top/tags/registrata/"},{"name":"Docker监控","slug":"Docker监控","permalink":"https://wsdlxgp.top/tags/Docker%E7%9B%91%E6%8E%A7/"},{"name":"prometheus","slug":"prometheus","permalink":"https://wsdlxgp.top/tags/prometheus/"},{"name":"alertmanager","slug":"alertmanager","permalink":"https://wsdlxgp.top/tags/alertmanager/"},{"name":"grafana","slug":"grafana","permalink":"https://wsdlxgp.top/tags/grafana/"},{"name":"sysdig","slug":"sysdig","permalink":"https://wsdlxgp.top/tags/sysdig/"},{"name":"Weave Scope","slug":"Weave-Scope","permalink":"https://wsdlxgp.top/tags/Weave-Scope/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://wsdlxgp.top/tags/docker-compose/"},{"name":"wordpress","slug":"wordpress","permalink":"https://wsdlxgp.top/tags/wordpress/"},{"name":"lnmp","slug":"lnmp","permalink":"https://wsdlxgp.top/tags/lnmp/"},{"name":"bind mount","slug":"bind-mount","permalink":"https://wsdlxgp.top/tags/bind-mount/"},{"name":"docker manager volu","slug":"docker-manager-volu","permalink":"https://wsdlxgp.top/tags/docker-manager-volu/"},{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"},{"name":"docker-registry","slug":"docker-registry","permalink":"https://wsdlxgp.top/tags/docker-registry/"},{"name":"docker私有仓库","slug":"docker私有仓库","permalink":"https://wsdlxgp.top/tags/docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"},{"name":"dockerfile","slug":"dockerfile","permalink":"https://wsdlxgp.top/tags/dockerfile/"},{"name":"bash","slug":"bash","permalink":"https://wsdlxgp.top/tags/bash/"},{"name":"base","slug":"base","permalink":"https://wsdlxgp.top/tags/base/"}]}