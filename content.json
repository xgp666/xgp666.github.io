{"meta":{"title":"Xgp & Blog","subtitle":"Today is still beautiful","description":"Small steel gun article","author":"Wu Shao Dong","url":"https://wsdlxgp.top","root":"/"},"pages":[{"title":"categories","text":"","path":"categories/index.html","date":"03-11","excerpt":""},{"title":"可爱的我","text":"","path":"about/index.html","date":"05-30","excerpt":""},{"title":"contact","text":"","path":"contact/index.html","date":"03-30","excerpt":""},{"title":"网站感想","text":"","path":"about/site.html","date":"05-30","excerpt":""},{"title":"链接","text":"","path":"link/index.html","date":"06-08","excerpt":""},{"title":"tags","text":"","path":"tags/index.html","date":"03-11","excerpt":""},{"title":"","text":"!function(){ var userAgentInfo = navigator.userAgent; var Agents = [\"iPad\", \"iPhone\", \"Android\", \"SymbianOS\", \"Windows Phone\", \"iPod\", \"webOS\", \"BlackBerry\", \"IEMobile\"]; for (var v = 0; v < Agents.length; v++) { if (userAgentInfo.indexOf(Agents[v]) > 0) { return; } } function o(w,v,i){return w.getAttribute(v)||i}function j(i){return document.getElementsByTagName(i)}function l(){var i=j(\"script\"),w=i.length,v=i[w-1];return{l:w,z:o(v,\"zIndex\",-1),o:o(v,\"opacity\",0.5),c:o(v,\"color\",\"0,0,0\"),n:o(v,\"count\",99)}}function k(){r=u.width=window.innerWidth||document.documentElement.clientWidth||document.body.clientWidth,n=u.height=window.innerHeight||document.documentElement.clientHeight||document.body.clientHeight}function b(){e.clearRect(0,0,r,n);var w=[f].concat(t);var x,v,A,B,z,y;t.forEach(function(i){i.x+=i.xa,i.y+=i.ya,i.xa*=i.x>r||i.xn||i.y","path":"lib/canvas-nest/canvas-nest-nomobile.min.js","date":"03-28","excerpt":""},{"title":"","text":"Theme NexT Canvas Nest canvas-nest.js for NexT. Install Step 1 → Go to Hexo dir Change dir to Hexo directory. There must be scaffolds, source, themes and other directories: 123$ cd hexo$ lsscaffolds $ cd hexo$ lsscaffolds source themes _config.yml package.json Step 2 → Create footer.swig Create a file named footer.swig in hexo/source/_data directory (create _data directory if it does not exist). Edit this file and add the following content: 1&lt;script color=\"0,0,255\" opacity=\"0.5\" zIndex=\"-1\" count=\"99\" src=\"https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\"&gt;&lt;/&lt;script color=\"0,0,255\" opacity=\"0.5\" zIndex=\"-1\" count=\"99\" src=\"https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\"&gt;&lt;/script> You can customize these options. Step 3 → Set it up In the NexT _config.yml, uncomment footer under the custom_file_path section. 12345678910111213# Define custom file paths.# Create your custom files in site directory `source/_data` and uncomment needed files below.custom_file_path: #head: source/_data/head.swig #header: source/_data/header.swig #sidebar: source/_data/sidebar.swig #postMeta: source/_data/post-meta.swig #postBodyEnd: source/_data/post-body-end.swig footer: source/_data/footer.swig #bodyEnd: source/_data/body-end.swig #variable: source/_data/variables.styl #mixin: source/_data/mixins.styl # Define custom file paths.# Create your custom files in site directory `source/_data` and uncomment needed files below.custom_file_path: #head: source/_data/head.swig #header: source/_data/header.swig #sidebar: source/_data/sidebar.swig #postMeta: source/_data/post-meta.swig #postBodyEnd: source/_data/post-body-end.swig footer: source/_data/footer.swig #bodyEnd: source/_data/body-end.swig #variable: source/_data/variables.styl #mixin: source/_data/mixins.styl #style: source/_data/styles.styl","path":"lib/canvas-nest/README.html","date":"03-28","excerpt":""},{"title":"","text":"!function(){function o(w,v,i){return w.getAttribute(v)||i}function j(i){return document.getElementsByTagName(i)}function l(){var i=j(\"script\"),w=i.length,v=i[w-1];return{l:w,z:o(v,\"zIndex\",-1),o:o(v,\"opacity\",0.5),c:o(v,\"color\",\"0,0,0\"),n:o(v,\"count\",99)}}function k(){r=u.width=window.innerWidth||document.documentElement.clientWidth||document.body.clientWidth,n=u.height=window.innerHeight||document.documentElement.clientHeight||document.body.clientHeight}function b(){e.clearRect(0,0,r,n);var w=[f].concat(t);var x,v,A,B,z,y;t.forEach(function(i){i.x+=i.xa,i.y+=i.ya,i.xa*=i.x>r||i.xn||i.y","path":"lib/canvas-nest/canvas-nest.min.js","date":"03-28","excerpt":""}],"posts":[{"title":"MySQL自带工具使用介绍","text":"一、MySQL自带工具使用介绍 MySQL数据库不仅提供了数据库的服务器端应用程序，同时还提供了大量的客户端工具程序，如mysql，mysqladmin，mysqldump等等 。 语法格式： Usage: mysql [OPTIONS] [database] 例如： 1# mysql -e \"select user,host from user\" mysql 大家只要运行一下“mysql --help”就会得到如下相应的基本使用帮助信息： 这里主要介绍一些在运维过程中会用到的相关选项： 首先看看“-e, --execute=name”参数，这个参数是告诉 mysql，我要执行“-e”后面的某个命令，而不是要通过mysql连接登录到MySQL Server 上面。此参数在我们写一些基本的MySQL 检查和监控的脚本中非常有用，运维mysql时经常在脚本中使用到它。 #mysql -hhostname -Pport -uusername -ppassword -e 相关mysql的sql语句 1、mysql命令 Mysql命令是用的最多的一个命令工具了，为用户提供一个命令行接口来操作管理MySQL 服务器。可以通过mysql --help来查看其详细使用方法。 mysql命令选项 作用 说明 -u 指定连接数据库时使用的用户 -p 指定用户的密码 可以-p后面直接写密码，也可以不写，进行交互式输入密码，推荐后者 -h 指定要登录的主机 可选，如果为空，则登录本机 -P 指定要连接的端口 可选，默认是3306 -e 可以通过-e命令直接执行SQL语句，而不用进入数据库 免交互登录数据库执行SQL语句，通常在脚本中使用 -D 指定要登录到哪个库 默认不会登录到库，可以省略此选项，直接写库名 -E 查询到的结果以行来显示 类似于每条SQL语句后面加“\\G” -f 即使出现SQL错误，也强制继续 比如在不登陆数据库执行删除库的操作会有一个交互式的确认操作，可以使用此选项来避免交互式 -X 将查询到的数据导出位xml文件 导出的文件在windows系统中可以使用excel表格打开 -H 将查询到的数据导出位html文件 导出的文件在windows系统中可以使用浏览器打开 –prompt 定制自己的MySQL提示符显示的内容 默认登登录到MySQL后的提示符是“mysql &gt;”，可以使用该选项定制提示符 –tee 将操作数据库所有输入和输出的内容都记录进文件中 在一些较大维护变更的时候，为了方便被查，可以将整个操作过程中的输出信息保存到某个文件中 这里主要介绍一些在运维过程中会用到的相关选项。 1）-e、-u、-p、-h、-P、 等选项的使用语法 首先看看“-e, --execute=name”参数，这个参数是告诉mysql，我要执行“-e”后面的某个命令，而不是要通过mysql连接登录到MySQL Server 上面。此参数在我们写一些基本的MySQL 检查和监控的脚本中非常有用，运维mysql时经常在脚本中使用到它。 语法格式： 1[root@mysql ~]# mysql -hhostname -Pport -uusername -ppassword -e 相关mysql的sql语句 示例1：免登录执行sql语句 123456789101112[root@mysql ~]# mysql -hlocalhost -P3306 -uroot -p mysql -e \"select user,host from user;\"Enter password: +---------------+-----------+| user | host |+---------------+-----------+| bankMaster | % || bankMaster | 127.0.0.1 || epetadmin | localhost || mysql.session | localhost || mysql.sys | localhost || root | localhost |+---------------+-----------+ 示例2： 通过binlog_cache_use 以及 binlog_cache_disk_use来分析设置的binlog_cache_size是否足够 12345678[root@mysql ~]# mysql -uroot -p -e \"show status like 'binlog_cache%'\"Enter password: +-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| Binlog_cache_disk_use | 0 || Binlog_cache_use | 0 |+-----------------------+-------+ 示例3： 通过脚本创建数据库、表及对表进行增、改、删、查操作。 脚本内容如下： 1234567891011121314151617181920212223242526272829303132333435# cat mysql1.sh#!&#x2F;bin&#x2F;bashHOSTNAME&#x3D;\"localhost\"PORT&#x3D;\"3306\"USERNAME&#x3D;\"root\"PASSWORD&#x3D;\"123\"DBNAME&#x3D;\"test_db\"TABLENAME&#x3D;\"tb1\"#create databasecreate_db_sql&#x3D;\"create database if not exists $&#123;DBNAME&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e \"$&#123;create_db_sql&#125;\"#create tablecreate_table_sql&#x3D;\"create table if not exists $&#123;TABLENAME&#125; (name varchar(20),id int default 0)\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;create_table_sql&#125;\"#insert data to tableinsert_sql&#x3D;\"insert into $&#123;TABLENAME&#125; values ('tom',1)\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;insert_sql&#125;\"#select dataselect_sql&#x3D;\"select * from $&#123;TABLENAME&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;select_sql&#125;\"#update dataupdate_sql&#x3D;\"update $&#123;TABLENAME&#125; set id&#x3D;3\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;update_sql&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;select_sql&#125;\"#delete datadelete_sql&#x3D;\"delete from $&#123;TABLENAME&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;delete_sql&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;select_sql&#125;\" 执行一下 12345678910111213141516171819[root@mysql ~]# sh mysql1.sh mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure.+------+------+| name | id |+------+------+| tom | 1 |+------+------+mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure.+------+------+| name | id |+------+------+| tom | 3 |+------+------+mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure. 2、-E 如果在连接时候使用了“-E, --vertical”参数，登入之后的所有查询结果都将以纵列显示，效果和我们在一条query 之后以“\\G”结尾一样。 123456789101112131415161718# mysql -uroot -p123 -Emysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 27Server version: 5.7.22 Source distributionCopyright (c) 2000, 2018, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql> show databases;*************************** 1. row ***************************Database: information_schema*************************** 2. row ***************************Database: mysql*************************** 3. row ***************************Database: test_db10 rows in set (0.00 sec) “-H, --html”与“-X, --xml”，在启用这两个参数之后，select出来的所有结果都会按照“Html”与“Xml”格式来输出，在有些场合之下，比如希望Xml或者Html 文件格式导出某些报表文件的时候，是非常方便的。 123456789101112131415161718192021222324252627282930313233343536373839[root@192 ~]# mysql -utest -p -XEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 40Server version: 5.7.30 MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql> use test_db;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql> select * from tb1; tom 1 tom 2 tom 3 3 rows in set (0.01 sec) 3、-H选项的使用方式 123[root@mysql ~]# mysql -H -uroot -p123.com -e \"select * from mysql.user\" &gt; a.html#[root@mysql ~]# mysql -H -uroot -p123.com -e \"select * from mysql.user\" &gt; a.html#将查询的结果重定向输出到a.html文件中[root@mysql ~]# sz a.html #下载这个文件到本地windows系统 4、创建授予test用户可以在指定的源登录 123# mysql -uroot -p -e \"grant all on test_db.* to root@'192.168.1.10' identified by'123'\"Enter password: 测试test用户连接mysql服务器 1234567891011121314151617[root@mysql ~]# mysql -u root -p -e \"grant all on test_db.* to test@'192.168.1.%' identified by '123'\"Enter password: [root@mysql ~]# mysql -utest -p123 -h 192.168.1.10mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 18Server version: 5.7.22 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql> 二、–prompt使用方法 “–prompt=name”参数对于做运维的人来说是一个非常重要的参数选项，其主要功能是定制自己的mysql提示符的显示内容。 在默认情况下，我们通过mysql登入到数据库之后，mysql的提示符只是一个很简单的内容”mysql&gt;“，没有其他任何附加信息。非常幸运的是mysql通过“--prompt=name”参数给我们提供了自定义提示信息的办法，可以通过配置显示登入的主机地址，登录用户名，当前时间，当前数据库schema，MySQL Server 的一些信息等等。 **个人强烈建议将登录主机名，登录用户名和所在的schema 这三项加入提示内容，因为当大家手边管理的MySQL 越来越多，操作越来越频繁的时候，非常容易因为操作的时候没有太在意自己当前所处的环境而造成在错误的环境执行了错误的命令并造成严重后果的情况。如果我们在提示内容中加入了这几项之后，至少可以更方便的提醒自己当前所处环境，以尽量减少犯错误的概率。 ** 个人强烈建议提示符定义： 1\"\\\\u@\\\\h : \\\\d \\\\r:\\\\m:\\\\s> \" 提示符解释： \\u ：表示用户名, \\h ：表示主机名， \\d ：表示当前数据库， \\r小时：（12小时制）， \\R小时（24小时制）， \\m：分种， \\s秒， 显示效果 1234567891011121314151617181920[root@mysql ~]# mysql -uroot -p --prompt&#x3D;\"\\\\u@\\\\h: \\\\d \\\\r:\\\\m:\\\\s\"Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 26Server version: 5.7.22 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.root@localhost: (none) 04:54:56> use test_dbReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedroot@localhost: (none) 04:54:56> 三、–tee的使用方法 “–tee=name”参数也是对运维人员非常有用的参数选项，用来告诉mysql，将所有输入和输出内容都记录进文件。在我们一些较大维护变更的时候，为了方便被查，最好是将整个操作过程的所有输入和输出内容都保存下来。 假如mysql命令行状态下，要进行大量的交互操作，其实可以把这些操作记录在log中进行审计，很简单 mysql -u root -p --tee=/path/xxxx.log 也可以在服务器上的/etc/my.cnf中的[client]加入 tee =/tmp/client_mysql.log即可. 注：若没有[client]就添加即可 或者在mysql&gt;提示符下执行下面的命令 12345678910111213mysql> tee &#x2F;opt&#x2F;xgp.logLogging to file '&#x2F;opt&#x2F;xgp.log'mysql> show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || test_db |+--------------------+5 rows in set (0.00 sec) 查看一下 1234567891011121314[root@mysql ~]# cat &#x2F;opt&#x2F;xgp.log mysql> tee &#x2F;opt&#x2F;xgp.logLogging to file '&#x2F;opt&#x2F;xgp.log'mysql> show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || test_db |+--------------------+5 rows in set (0.00 sec) 同样，“–tee”这个配置项也可以写入my.cnf这个主配置文件中的client字段下，如下： 1234567891011[root@mysql ~]# vim /etc/my.cnf [client]socket=/usr/local/mysql/mysql.sock[mysqld]basedir=/usr/local/mysqldatadir=/usr/local/mysql/datapid-file=/usr/local/mysql/data/mysql.pidsocket=/usr/local/mysql/mysql.socklog-error=/usr/local/mysql/data/mysql.errtee=/opt/xgp.log 四、mysqladmin命令 mysqladmin,顾名思义,提供的功能都是与MySQL管理相关的各种功能。如MySQL Server状态检查,各种统计信息的flush,创建/删除数据库，关闭MySQL Server等等。mysqladmin所能做的事情，虽然大部分都可以通过mysql连接登录上MySQL Server之后来完成，但是大部分通过mysqladmin来完成操作会更简单更方便。 mysqladmin后面可以接选项，也可以接命令,这里就不说选项了，主要说一下命令 命令字 作用 create databasename 创建一个库 drop databasename 删除一个库 status 查询MySQL的基本状态（显示的信息有限 ） extended-status 查询服务器的详细状态信息（类似于在数据库中执行show status;） flush-hosts 刷新服务器缓存 flush-logs 刷新二进制日志文件（如果二进制日志功能开启，那么执行这个操作会生成新的二进制日志文件） flush-status 刷新状态变量 flush-tables 刷新所有表 flush-threads 刷新所有线程缓存 flush-privileges 重新加载授权表 processlist 查看当前连接数据库的所有ID详细信息 kill id 杀掉某个或多个连接ID（一般需要先使用processlist查看出ID列表，然后根据ID将其kill掉 ） ping 检测某个MySQL服务是否处于启动状态 password 修改用户密码 shutdown 关闭MySQL服务 start-slave 开启主从复制 stop-slave 关闭主从复制 variables 查询MySQL服务中的所有变量 version 查询MySQL的版本详细信息 （1）ping 监测服务是否正常 123[root@mysql ~]# mysqladmin -uroot -p pingEnter password: mysqld is alive （2）status 获取mysql当前状态值 123[root@mysql ~]# mysqladmin -uroot -p statusEnter password: Uptime: 3413 Threads: 2 Questions: 102 Slow queries: 0 Opens: 118 Flush tables: 1 Open tables: 111 Queries per second avg: 0.029 状态值： **mysqladmin status命令结果有下述列 ** **Uptime:是mysql服务器运行的秒数。 ** **Threads:活跃线程的数量即开启的会话数。 ** **Questions： 服务器启动以来客户的问题(查询)数目 （只要跟mysql作交互，不管查询表，还是查询服务器状态都记一次）。 ** **Slow queries：是慢查询的数量。 ** **Opens：mysql已经打开的数据库表的数量 ** **Flush tables: mysql已经执行的flush tables，refresh和reload命令的数量。 注：flush tables //刷新表（清除缓存）reload 重载授权表 refresh 洗掉所有表并关闭和打开日志文件 ** **open：打开数据库的表的数量，以服务器启动开始。 ** Queries per second avg：select语句平均查询时间 Memory in use分配的内存(只有在MySQL用–withdebug编译时可用) Max memory used分配的最大内存(只有在MySQL用–with-debug编译时可用) （3）processlist 获取数据库当前连接信息 12345678[root@mysql ~]# mysqladmin -uroot -p processlistEnter password: +----+------+-----------+---------+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+---------+---------+------+----------+------------------+| 32 | root | localhost | test_db | Sleep | 877 | | || 40 | root | localhost | | Query | 0 | starting | show processlist |+----+------+-----------+---------+---------+------+----------+------------------+ （4）获取数据库当前的连接数 123[root@mysql ~]# mysql -uroot -p -BNe \"select host,count(host) from processlist group by host\" information_schemaEnter password: localhost 2 （5）显示mysql的启动时长 1234[root@mysql ~]# mysql -uroot -p123 -e \"SHOW STATUS LIKE '%uptime%'\" | awk '/ptime/&#123; calc = $NF/3600;print $(NF-1), calc\"Hour\"&#125;'Uptime 1.005HourUptime_since_flush_status 1.005Hour （6）查看数据库所有库大小 1234567891011[root@mysql ~]# mysql -uroot -p123 -e 'select table_schema,round(sum(data_length+index_length)/1024/1024,4) from information_schema.tables group by table_schema'+--------------------+--------------------------------------------------+| table_schema | round(sum(data_length+index_length)/1024/1024,4) |+--------------------+--------------------------------------------------+| information_schema | 0.1563 || mysql | 2.4425 || performance_schema | 0.0000 || sys | 0.0156 || test_db | 0.0156 |+--------------------+--------------------------------------------------+ （7）processlist获取当前数据库的连接线程信息： 监控mysql进程运行状态： 上面的这三个功能在一些简单监控脚本中经常使用到的。 mysqladmin其他参数选项可以通过执行“mysqladmin–help”或man mysqladmin得到帮助信息。 编写一个简单的mysql监控脚本，内容如下： 12345678910111213#!/bin/bash#监测服务是否正常mysqladmin -uroot -p123 -h localhost ping#获取mysql当前状态值mysqladmin -uroot -p123 -h localhost status#获取数据库当前连接信息mysqladmin -uroot -p123 -h localhost processlist#获取数据库当前的连接数mysql -uroot -p123 -BNe \"select host,count(host) from processlist group by host\" information_schema#显示mysql的启动时长mysql -uroot -p123 -e \"SHOW STATUS LIKE '%uptime%'\" | awk '/ptime/&#123; calc = $NF/3600;print $(NF-1), calc\"Hour\"&#125;'##!/bin/bash#监测服务是否正常mysqladmin -uroot -p123 -h localhost ping#获取mysql当前状态值mysqladmin -uroot -p123 -h localhost status#获取数据库当前连接信息mysqladmin -uroot -p123 -h localhost processlist#获取数据库当前的连接数mysql -uroot -p123 -BNe \"select host,count(host) from processlist group by host\" information_schema#显示mysql的启动时长mysql -uroot -p123 -e \"SHOW STATUS LIKE '%uptime%'\" | awk '/ptime/&#123; calc = $NF/3600;print $(NF-1), calc\"Hour\"&#125;'#查看数据库所有库大小mysql -uroot -p123 -e 'select table_schema,round(sum(data_length+index_length)/1024/1024,4) from information_schema.tables group by table_schema' 五、mysqldump 这个工具其功能就是将MySQL Server中的数据以SQL 语句的形式从数据库中dump 成文本文件。mysqldump是做为MySQL 的一种逻辑备份工具，在我之前的博文中有这个工具的使用方法：MySQL的备份与恢复详解 六、mysqlbinlog mysqlbinlog程序的主要功能就是分析MySQL Server 所产生的二进制日志（也就是binlog）。 通过mysqlbinlog，我们可以解析出binlog中指定时间段或者指定日志起始和结束位置的内容解析成SQL 语句。 七、Mysqlslap性能测试 MySQL二种存储引擎 mysqlslap是mysql自带的基准测试工具,优点:查询数据,语法简单,灵活容易使用.该工具可以模拟多个客户端同时并发的向服务器发出查询更新,给出了性能测试数据而且提供了多种引擎的性能比较.mysqlslap为mysql性能优化前后提供了直观的验证依据,建议系统运维和DBA人员应该掌握一些常见的压力测试工具,才能准确的掌握线上数据库支撑的用户流量上限及其抗压性等问题。 现在看一下这个压力测试工具mysqlslap，关于他的选项手册上以及–help介绍的很详细。 这里解释一下一些常用的选项 –concurrency代表并发数量，多个可以用逗号隔开。例如：concurrency=50,100,200 --engines代表要测试的引 擎，可以有多个，用分隔符隔开。 –iterations代表要运行这些测试多少次，即运行多少次后，得到结果。 –auto-generate-sql 代表用系统自己生成的SQL脚本来测试。 –auto-generate-sql-load-type 代表要测试的是读 还是写还是两者混合的（read,write,update,mixed） –number-of-queries 代表总共要运行多少次查询。每个客户运行的查询数量可以用查询总数/并发数来计算。比如倒数第二个结果2=200/100。 –debug-info 代表要额外输出CPU以及内存的相关信息（注：只有在MySQL用–with-debug编译时可）。 –number-int-cols 代表测试表中的INTEGER类型的属性有几个。 –number-char-cols代表测试表的char类型字段的数量。 –create-schema 代表自己定义的模式（在MySQL中也就是库即创建测试的数据库）。 –query 代表自己的SQL脚本。 –only-print如果只想打印看看SQL语句是什么，可以用这个选项。 –csv=name 生产CSV格式数据文件 查看Mysql数据库默认最大连接数 （1）查看Mysql数据库默认最大连接数 可以看到mysql5.7.13默认是151。注：不同版本默认最大连接数不差别。一般生产环境是不够的。 1234567mysql> show variables like '%max_connections%';+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 151 |+-----------------+-------+1 row in set (0.00 sec) 注：不同版本默认最大连接数不差别。一般生产环境是不够的 2、修改MySQL数据库默认最大连接数 方法一 123456789mysql> set GLOBAL max_connections &#x3D; 1024;Query OK, 0 rows affected (0.00 sec)mysql> show variables like '%max_connections%';+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 1024 |+-----------------+-------+1 row in set (0.00 sec) 方法二 12345在my.cnf[mysqld]下添加 max_connections&#x3D;1024 #增加到1024重启Mysql。 总结：修改my.cnf文件并重启mysqld服务 3、查看Mysql默认使用存储引擎， 如下查看： mysql&gt; show engines; 123456789101112131415mysql> show engines;+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || CSV | YES | CSV storage engine | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || BLACKHOLE | YES | &#x2F;dev&#x2F;null storage engine (anything you write to it disappears) | NO | NO | NO || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || ARCHIVE | YES | Archive storage engine | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+9 rows in set (0.00 sec) 4、测试 现在我们来看一下具体测试的例子。 1）用自带的SQL脚本来测试 123456789101112131415161718192021222324252627282930313233[root@mysql ~]# mysqlslap --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --concurrency&#x3D;100,200 --iterations&#x3D;1 --number-int-cols&#x3D;20 --number-char-cols&#x3D;30 --auto-generate-sql --auto-generate-sql-add-autoincrement --auto-generate-sql-load-type&#x3D;mixed --engine&#x3D;myisam,innodb --number-of-queries&#x3D;2000 -uroot -p123 --verboseBenchmarktrueRunning for engine myisamtrueAverage number of seconds to run all queries: 0.330 secondstrueMinimum number of seconds to run all queries: 0.330 secondstrueMaximum number of seconds to run all queries: 0.330 secondstrueNumber of clients running queries: 100trueAverage number of queries per client: 20BenchmarktrueRunning for engine myisamtrueAverage number of seconds to run all queries: 0.341 secondstrueMinimum number of seconds to run all queries: 0.341 secondstrueMaximum number of seconds to run all queries: 0.341 secondstrueNumber of clients running queries: 200trueAverage number of queries per client: 10BenchmarktrueRunning for engine innodbtrueAverage number of seconds to run all queries: 0.610 secondstrueMinimum number of seconds to run all queries: 0.610 secondstrueMaximum number of seconds to run all queries: 0.610 secondstrueNumber of clients running queries: 100trueAverage number of queries per client: 20BenchmarktrueRunning for engine innodbtrueAverage number of seconds to run all queries: 0.457 secondstrueMinimum number of seconds to run all queries: 0.457 secondstrueMaximum number of seconds to run all queries: 0.457 secondstrueNumber of clients running queries: 200trueAverage number of queries per client: 10 测试说明 1模拟测试两次读写并发，第一次100，第二次200，自动生成SQL脚本，测试表包含20个init字段，30个char字段，每次执行2000查询请求。测试引擎分别是myisam，innodb。 测试结果说明 12Myisam第一次100客户端同时发起增查用1.459/s,第二次200客户端同时发起增查用1.420/sInnodb第一次100客户端同时发起增查用1.352/s,第二次200客户端同时发起增查用2.330/s 测试结论 12由此可见MyISAM存储引擎处理性能是最好的，也是最常用的，但不支持事务。InonDB存储引擎提供了事务型数据引擎（ACID），在事务型引擎里使用最多的。具有事务回滚，系统修复等特点。 2）测试结果保存为csv文件 Mysqlslap测试工具生产CSV格式数据文件并转换成图表形式： 1[root@mysql ~]# mysqlslap --defaults-file=/etc/my.cnf --concurrency=100,200 --iterations=1 --number-int-cols=20 --number-char-cols=30 --auto-generate-sql --auto-generate-sql-add-autoincrement --auto-generate-sql-load-type=mixed --engine=myisam,innodb --number-of-queries=2000 -uroot -p123 --csv=/root/a.csv 将/root/a.csv拷贝到windows主机上，打开并生成图表 3）使用自定义sql脚本测试 用我们自己定义的SQL 脚本或语句来测试 首先准备好要测试的数据库表，这里我们编写一个生成表的脚本去完成 脚本内容如下： 12345678910111213141516171819202122232425[root@mysql ~]# cat /root/mysql3.sh#!/bin/bashHOSTNAME=\"localhost\"PORT=\"3306\"USERNAME=\"root\"PASSWORD=\"123\"DBNAME=\"test1\"TABLENAME=\"tb1\"#create databasemysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e \"drop database if exists $&#123;DBNAME&#125;\" create_db_sql=\"create database if not exists $&#123;DBNAME&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e \"$&#123;create_db_sql&#125;\"#create tablecreate_table_sql=\"create table if not exists $&#123;TABLENAME&#125;(stuid int not null primary key,stuname varchar(20) not null,stusex char(1) not null,cardid varchar(20) not null,birthday datetime,entertime datetime,address varchar(100) default null)\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;create_table_sql&#125;\"#insert data to tablei=1while [ $i -le 20000 ]doinsert_sql=\"insert into $&#123;TABLENAME&#125; values($i,'zhangsan','1','1234567890123456','1999-10-10','2016-9-3','zhongguo beijingshi changpinqu')\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;insert_sql&#125;\"let i++done#[root@mysql ~]# cat /root/mysql3.sh#!/bin/bashHOSTNAME=\"localhost\"PORT=\"3306\"USERNAME=\"root\"PASSWORD=\"123\"DBNAME=\"test1\"TABLENAME=\"tb1\"#create databasemysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e \"drop database if exists $&#123;DBNAME&#125;\" create_db_sql=\"create database if not exists $&#123;DBNAME&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e \"$&#123;create_db_sql&#125;\"#create tablecreate_table_sql=\"create table if not exists $&#123;TABLENAME&#125;(stuid int not null primary key,stuname varchar(20) not null,stusex char(1) not null,cardid varchar(20) not null,birthday datetime,entertime datetime,address varchar(100) default null)\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;create_table_sql&#125;\"#insert data to tablei=1while [ $i -le 20000 ]doinsert_sql=\"insert into $&#123;TABLENAME&#125; values($i,'zhangsan','1','1234567890123456','1999-10-10','2016-9-3','zhongguo beijingshi changpinqu')\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;insert_sql&#125;\"let i++done#select dataselect_sql=\"select count(*) from $&#123;TABLENAME&#125;\"mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e \"$&#123;select_sql&#125;\" 授权脚本x执行权限 1[root@192 opt]# chmod +x mysql_test.sh 执行脚本mysql3.sh生成mysqlslap工具需要的测试表 1234[root@mysql ~]# /root/mysql3.sh执行mysqlslap工具进行测试[root@mysql ~]# mysqlslap --defaults-file=/etc/my.cnf --concurrency=10,20 --iterations=1 --create-schema='test1' --query='select * from test1.tb1' --engine=myisam,innodb --number-of-queries=2000 -uroot -p123 –verbose 显示结果： 123456789101112131415161718192021222324252627282930313233[root@192 opt]# mysqlslap --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --concurrency&#x3D;10,20 --iterations&#x3D;1 --create-schema&#x3D;'test1' --query&#x3D;'select * from test1.tb1' --engine&#x3D;myisam,innodb --number-of-queries&#x3D;2000 -uroot -p1234 –verbosemysqlslap: [Warning] Using a password on the command line interface can be insecure.Benchmark Running for engine myisam Average number of seconds to run all queries: 3.261 seconds Minimum number of seconds to run all queries: 3.261 seconds Maximum number of seconds to run all queries: 3.261 seconds Number of clients running queries: 10 Average number of queries per client: 200Benchmark Running for engine myisam Average number of seconds to run all queries: 3.010 seconds Minimum number of seconds to run all queries: 3.010 seconds Maximum number of seconds to run all queries: 3.010 seconds Number of clients running queries: 20 Average number of queries per client: 100Benchmark Running for engine innodb Average number of seconds to run all queries: 3.421 seconds Minimum number of seconds to run all queries: 3.421 seconds Maximum number of seconds to run all queries: 3.421 seconds Number of clients running queries: 10 Average number of queries per client: 200Benchmark Running for engine innodb Average number of seconds to run all queries: 3.252 seconds Minimum number of seconds to run all queries: 3.252 seconds Maximum number of seconds to run all queries: 3.252 seconds Number of clients running queries: 20 Average number of queries per client: 100 注：通过mysqlslap工具对mysql server进行压力测试，可以通过–concurrency、–number-of-queries等选项的值查看每次测试的结果，通过反复测试、优化得出mysql server的最大并发数。 如果mysqlslap工具输出结果为Segmentation fault (core dumped)基本表示走超出mysql server的负载。","path":"posts/f96f.html","date":"06-18","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL数据文件介绍及存放位置","text":"一、MySQL数据库文件介绍 MySQL的每个数据库都对应存放在一个与数据库同名的文件夹中，MySQL数据库文件包括MySQL所建数据库文件和MySQL所用存储引擎创建的数据库文件。 1、MySQL创建并管理的数据库文件： .frm文件：存储数据表的框架结构，文件名与表名相同，每个表对应一个同名frm文件，与操作系统和存储引擎无关，即不管MySQL运行在何种操作系统上，使用何种存储引擎，都有这个文件。 除了必有的.frm文件，根据MySQL所使用的存储引擎的不同（MySQL常用的两个存储引擎是MyISAM和InnoDB），存储引擎会创建各自不同的数据库文件。 2、MyISAM数据库表文件： .MYD文件：即MY Data，表数据文件 .MYI文件：即MY Index，索引文件 .log文件：日志文件 3、InnoDB采用表空间（tablespace）来管理数据，存储表数据和索引， InnoDB数据库文件（即InnoDB文件集，ib-file set）： ibdata1、ibdata2等：系统表空间文件，存储InnoDB系统信息和用户数据库表数据和索引，所有表共用 .ibd文件：单表表空间文件，每个表使用一个表空间文件（file per table），存放用户数据库表数据和索引 日志文件： ib_logfile1、ib_logfile2 二、MySQL数据库存放位置： 1、MySQL如果使用MyISAM存储引擎，数据库文件类型就包括.frm、.MYD、.MYI，默认存放位置是C:\\Documentsand Settings\\All Users\\Application Data\\MySQL\\MySQL Server 5.1\\data 2、MySQL如果使用InnoDB存储引擎，数据库文件类型就包括.frm、ibdata1、.ibd，存放位置有两个， .frm文件默认存放位置是C:\\Documents and Settings\\All Users\\ApplicationData\\MySQL\\MySQL Server 5.1\\data，ibdata1、.ibd文件默认存放位置是MySQL安装目录下的data文件夹 三、操作 看看我的数据库文件的存放位置 12345678910111213141516[root@pacteralinux ~]# cd /mnt/resource/mysqldate/[root@pacteralinux mysqldate]# ll -htotal 173M-rw-rw----. 1 mysql mysql 56 Nov 25 17:17 auto.cnf-rw-rw----. 1 mysql mysql 76M Dec 24 17:02 ibdata1-rw-rw----. 1 mysql mysql 48M Dec 24 17:02 ib_logfile0-rw-rw----. 1 mysql mysql 48M Nov 26 13:39 ib_logfile1drwx------. 2 mysql mysql 4.0K Nov 26 13:41 mysqldrwx------. 2 mysql mysql 20K Nov 26 17:00 mysqldbsrwxrwxrwx. 1 mysql mysql 0 Dec 24 17:02 mysql.sock-rw-rw----. 1 mysql root 499K Dec 25 14:42 pacteralinux.err-rw-rw----. 1 mysql mysql 6 Dec 24 17:02 pacteralinux.piddrwx------. 2 mysql mysql 4.0K Nov 26 13:41 performance_schemadrwx------. 2 mysql mysql 4.0K Nov 26 13:41 testdrwx------. 2 mysql mysql 4.0K Dec 9 16:49 weixindemo[root@pacteralinux mysqldate][root@pacteralinux ~]# cd /mnt/resource/mysqldate/[root@pacteralinux mysqldate]# ll -htotal 173M-rw-rw----. 1 mysql mysql 56 Nov 25 17:17 auto.cnf-rw-rw----. 1 mysql mysql 76M Dec 24 17:02 ibdata1-rw-rw----. 1 mysql mysql 48M Dec 24 17:02 ib_logfile0-rw-rw----. 1 mysql mysql 48M Nov 26 13:39 ib_logfile1drwx------. 2 mysql mysql 4.0K Nov 26 13:41 mysqldrwx------. 2 mysql mysql 20K Nov 26 17:00 mysqldbsrwxrwxrwx. 1 mysql mysql 0 Dec 24 17:02 mysql.sock-rw-rw----. 1 mysql root 499K Dec 25 14:42 pacteralinux.err-rw-rw----. 1 mysql mysql 6 Dec 24 17:02 pacteralinux.piddrwx------. 2 mysql mysql 4.0K Nov 26 13:41 performance_schemadrwx------. 2 mysql mysql 4.0K Nov 26 13:41 testdrwx------. 2 mysql mysql 4.0K Dec 9 16:49 weixindemo[root@pacteralinux mysqldate]# 其中这三个文件我一直很迷惑 123-rw-rw----. 1 mysql mysql 76M Dec 24 17:02 ibdata1-rw-rw----. 1 mysql mysql 48M Dec 24 17:02 ib_logfile0-rw-rw----. 1 mysql mysql 48M Nov 26 13:39 ib_logfile1 再看这些文件（部分） 1234567891011121314[root@pacteralinux mysqldb][root@pacteralinux mysqldb]# ll -htotal 3.6G-rw-rw----. 1 mysql mysql 11K Nov 26 16:47 chen_fundnetvalue_bak.frm-rw-rw----. 1 mysql mysql 62K Nov 26 16:47 chen_fundnetvalue_bak.MYD-rw-rw----. 1 mysql mysql 4.0K Nov 26 16:47 chen_fundnetvalue_bak.MYI-rw-rw----. 1 mysql mysql 11K Nov 26 16:47 chen_fundnetvalue.frm-rw-rw----. 1 mysql mysql 834K Nov 26 16:47 chen_fundnetvalue.MYD-rw-rw----. 1 mysql mysql 18K Nov 26 16:47 chen_fundnetvalue.MYI-rw-rw----. 1 mysql mysql 8.4K Nov 26 16:47 codelist_bak.frm-rw-rw----. 1 mysql mysql 162 Nov 26 16:47 codelist_bak.MYD-rw-rw----. 1 mysql mysql 1.0K Nov 26 16:47 codelist_bak.MYI-rw-rw----. 1 mysql mysql 8.4K Nov 26 16:47 codelist.frm-rw-rw----. 1 mysql mysql 162 Nov 26 16:47 codelist.MYD-rw-rw----. 1 mysql mysql 1.0K Nov 26 16:47 codelist.MYI . 前面是表名，每个表由frm MYD MYI三个后缀名组成，所有表都是！ 在MySQL 中每一个数据库都会在定义好（或者默认）的数据目录下存在一个以数据库名字命名的文件夹，用来存放该数据库中各种表数据文件。不同的MySQL 存储引擎有各自不同的数据文件，存放位置也有区别。 多数存储引擎的数据文件都存放在和MyISAM 数据文件位置相同的目录下，但是每个数据文件的扩展名却各不一样。如MyISAM 用“.MYD”作为扩展名，Innodb 用“.ibd”，Archive 用“.arc”，CSV 用“.csv”，等等。 1、下面就来详细分析一下这些是什么文件！！！！！ （1）“.frm”文件 与表相关的元数据（meta）信息都存放在“.frm”文件中，包括表结构的定义信息等。不论是什么存储引擎，每一个表都会有一个以表名命名的“.frm”文件。所有的“.frm”文件都存放在所属数据库的文件夹下面。（innodb，myisam） （2）“.MYD”文件 “.MYD”文件是MyISAM 存储引擎专用，存放MyISAM 表的数据。每一个MyISAM 表都会有一个“.MYD”文件与之对应，同样存放于所属数据库的文件夹下，和“.frm”文件在一起。 （3）“.MYI”文件 “.MYI”文件也是专属于MyISAM存储引擎的，主要存放MyISAM表的索引相关信息。对于MyISAM存储来说，可以被cache 的内容主要就是来源于“.MYI”文件中。每一个MyISAM表对应一个“.MYI”文件，存放于位置和“.frm”以及“.MYD”一样。 （4）小结一下： MyISAM 存储引擎的表在数据库中，每一个表都被存放为三个以表名命名的物理文件（frm,myd,myi）。 每个表都有且仅有这样三个文件做为MyISAM 存储类型的表的存储，也就是说不管这个表有多少个索引，都是存放在同一个.MYI 文件中。 这个在开始里看的比较清楚。 2、“.ibd”文件和ibdata 文件 这两种文件都是存放Innodb 数据的文件，之所以有两种文件来存放Innodb 的数据（包括索引），是因为Innodb 的数据存储方式能够通过配置来决定是使用共享表空间存放存储数据，还是独享表空间存放存储数据。独享表空间存储方式使用“.ibd”文件来存放数据，且每个表一个“.ibd”文件，文件存放在和MyISAM数据相同的位置。 如果选用共享存储表空间来存放数据，则会使用ibdata 文件来存放，所有表共同使用一个（或者多个，可自行配置）ibdata 文件。ibdata 文件可以通过innodb_data_home_dir 和innodb_data_file_path两个参数共同配置组成， innodb_data_home_dir 配置数据存放的总目录， 而innodb_data_file_path 配置每一个文件的名称。当然，也可以不配innodb_data_home_dir而直接在innodb_data_file_path参数配置的时候使用绝对路径来完成配置。 123456789mysql&gt; showvariables like mysql&gt; showvariables like 'innodb_data%';+-----------------------+------------------------+|Variable_name | Value |+-----------------------+------------------------+|innodb_data_file_path | ibdata1:10M:autoextend || innodb_data_home_dir | |+-----------------------+------------------------+2 rows in set(0.01 sec) innodb_data_file_path中可以一次配置多个ibdata文件。文件可以是指定大小，也可以是自动扩展的，但是Innodb 限制了仅仅只有最后一个ibdata 文件能够配置成自动扩展类型。当我们需要添加新的ibdata 文件的时候，只能添加在innodb_data_file_path配置的最后，而且必须重启MySQL 才能完成ibdata 的添加工作。 3、ibdata文件瘦身法 MySql innodb如果是共享表空间，ibdata1文件越来越大，达到了30多个G，对一些没用的表进行清空： truncate table xxx; 然后optimize table xxx; 没有效果 因为对共享表空间不起作用。 mysql ibdata1存放数据，索引等，是MYSQL的最主要的数据。 如果不把数据分开存放的话，这个文件的大小很容易就上了G，甚至几十G。对于某些应用来说，并不是太合适。因此要把此文件缩小。 无法自动收缩，必须数据导出，删除ibdata1，然后数据导入，比较麻烦，因此需要改为每个表单独的文件。 解决方法：数据文件单独存放(共享表空间如何改为每个表独立的表空间文件)。 步骤如下： 1）备份数据库 从命令行进入MySQL Server 5.0\\bin 备份全部数据库，执行命令 1D:\\&gt;mysqldump -q -umysql -ppassword --add-drop-table --all-databases &gt; c:/D:\\&gt;mysqldump -q -umysql -ppassword --add-drop-table --all-databases &gt; c:/all.sql 做完此步后，停止数据库服务。 2）找到my.ini或my.cnf文件 linux下执行 ./mysqld --verbose --help | grep -A 1 'Default options' 会有类似显示： Default options are read from the following files in the given order: /etc/my.cnf ~/.my.cnf /usr/local/service/mysql3306/etc/my.cnf windows环境下可以： mysqld --verbose --help &gt; mysqlhelp.txt notepad mysqlhelp.txt 在里面查找Default options，可以看到查找my.ini的顺序，以找到真实目录 3）修改mysql配置文件 打开my.ini或my.cnf文件 [mysqld]下增加下面配置 innodb_file_per_table=1 验证配置是否生效，可以重启mysql后,执行 show variables like '%per_table%' 看看innodb_file_per_table变量是否为ON 4）删除原数据文件 删除原来的ibdata1文件及日志文件ib_logfile*，删除data目录下的应用数据库文件夹(mysql文件夹不要删) 5）还原数据库 启动数据库服务 从命令行进入MySQL Server 5.0\\bin 还原全部数据库，执行命令mysql -uusername -pyourpassword &lt; c:/all.sql 经过以上几步后，可以看到新的ibdata1文件就只有几十M了，数据及索引都变成了针对单个表的小ibd文件了，它们在相应数据库的文件夹下面。 四、mysql data文件夹下的ibdata1 文件作用 这个文件超级大， 查了一下， 大概的作用如下 是储存的格式 INNODB类型数据状态下， ibdata用来储存文件的数据 而库名的文件夹里面的那些表文件只是结构而已 由于mysql4.1默认试innodb，所以这个文件默认就存在了https://wsdlxgp.top/ 这个链接试innodb的中文参考， innodb的东西可以在my.ini中设置 使用过MySQL的同学，刚开始接触最多的莫过于MyISAM表引擎了，这种引擎的数据库会分别创建三个文件：表结构、表索引、表数据空间。我们可以将某个数据库目录直接迁移到其他数据库也可以正常工作。 然而当你使用InnoDB的时候，一切都变了。InnoDB 默认会将所有的数据库InnoDB引擎的表数据存储在一个共享空间中：ibdata1，这样就感觉不爽，增删数据库的时候，ibdata1文件不会自动收缩，单个数据库的备份也将成为问题。通常只能将数据使用mysqldump 导出，然后再导入解决这个问题。 在MySQL的配置文件[mysqld]部分，增加innodb_file_per_table参数，可以修改InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。 独立表空间 优点： 1.每个表都有自已独立的表空间。 2.每个表的数据和索引都会存在自已的表空间中。 3.可以实现单表在不同的数据库中移动。 4.空间可以回收（drop/truncate table方式操作表空间不能自动回收） 5.对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。 缺点： 单表增加比共享空间方式更大。 结论： 共享表空间在Insert操作上有一些优势，但在其它都没独立表空间表现好。 当启用独立表空间时，请合理调整一下 innodb_open_files 参数。 两个重要参数： 12innodb_data_file_pathinnodb_data_home_dir 这两个参数看参考文献的时候一直没有理解，先说明如下 我的my.cnf 12#innodb_data_home_dir = /var/lib/mysql/#innodb_data_home_dir = /var/lib/mysql/#innodb_data_file_path = ibdata1:10M:autoextend 为了在 MySQL-Max-3.23 中使用 InnoDB 表，你必须在配置文件‘my.cnf’中的 [mysqld] 区中详细指定配置参数。 作为最小设置，在 3.23 中你必须在 innodb_data_file_path 上指定数据文件名能及大小。 如果在‘my.cnf’中没有指定innodb_data_home_dir，系统将在 MySQL 的 datadir 目录下创建数据文件。 如果将 innodb_data_home_dir 设为一个空串，那可以在 innodb_data_file_path 中给定一个绝对路径。 在 MySQL-4.0 中可以不设定 innodb_data_file_path ：MySQL-4.0 将默认地在 datadir 目录下建立一个 10 MB 大小自扩充(auto-extending)的文件‘ibdata1’(在MySQL-4.0.0 与 4.0.1 中数据文件的大小为 64 MB 并且是非自扩充的(not auto-extending))。 为了得到更好的性能你必须所示的例子明确地设定 InnoDB 启动参数。 从 3.23.50 版和 4.0.2 版开始，InnoDB 允许在 innodb_data_file_path 中设置的最一个数据文件描述为 auto-extending。 innodb_data_file_path 语法如下所示： 12pathtodatafile:sizespecification;pathtodatafile:sizespec;... ...;pathtodatafile:sizespec[:autoextend[:max:sizespecification]] 如果用 autoextend 选项描述最后一个数据文件，当 InnoDB 用尽所有表自由空间后将会自动扩充最后一个数据文件，每次增量为 8 MB。示例： 12innodb_data_home_dir &#x3D;innodb_data_file_path &#x3D; &#x2F;ibdata&#x2F;ibdata1:100M:autoextend 指定 InnoDB 只建立一个最初大小为 100 MB 并且当表空间被用尽时以 8MB 每块增加的数据文件。如果硬盘空间不足，可以再添加一个数据文件并将其放在其它的硬盘中。 举例来说：先检查硬盘空间的大小，设定ibdata1文件使它接近于硬盘空余空间大小并为 1024 * 1024 bytes (= 1 MB)的倍数， 将 ibdata1 明确地指定在 innodb_data_file_path 中。在此之后可以添加另一个数据文件： 12innodb_data_home_dir =innodb_data_file_path = /ibdata/ibdata1:988M;/disk2/ibdata2:50M:autoextend 注意：设定文件大小时一定要注意你的OS是否有最大文件尺寸为2GB的限制！InnoDB是不会注意你的OS文件尺寸限制的， 在一些文件系统中你可能要设定最大容量限制： 12innodb_data_home_dir &#x3D;innodb_data_file_path &#x3D; &#x2F;ibdata&#x2F;ibdata1:100M:autoextend:max:2000M","path":"posts/80a7.html","date":"06-18","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL事务日志","text":"事务日志(或称redo日志) 事务日志（InnoDB特有的日志）可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。事务日志采用追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。事务日志持久以后，内存中被修改的数据在后台可以慢慢的刷回到磁盘。目前大多数的存储引擎都是这样实现的。 如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。具有的恢复方式则视存储引擎而定。 查看事务日志的定义： 1show global variables like '%log%'; 显示结果 123456789101112131415161718| innodb_flush_log_at_timeout | 1 || innodb_flush_log_at_trx_commit | 1 #在事务提交时innodb是否同步日志从缓冲区到文件中，当这个值为1（默认值）之时，在每个事务提交时，日志缓冲被写到日志文件，对日志文件做到磁盘操作的刷新，性能会很差造成大量的磁盘I&#x2F;O但这种方式最安全；如果设为2,每次提交事务都会写日志，但并不会执行刷的操作。每秒定时会刷到日志文件。要注意的是，并不能保证100%每秒一定都会刷到磁盘，这要取决于进程的调度。每次事务提交的时候将数据写入事务日志，而这里的写入仅是调用了文件系统的写入操作，而文件系统是有 缓存的，所以这个写入并不能保证数据已经写入到物理磁盘。设置为0，日志缓冲每秒一次地被写到日志文件，并且对日志文件做到磁盘操作的刷新，但是在一个事务提交不做任何操作。注：刷写的概念刷写其实是两个操作，刷（flush）和写（write），区分这两个概念是很重要的。在大多数的操作系统中，把Innodb的log buffer（内存）写入日志（调用系统调用write），只是简单的把数据移到操作系统缓存中，操作系统缓存同样指的是内存。并没有实际的持久化数据。所以，通常设为0和2的时候，在崩溃或断电的时候会丢失最后一秒的数据，因为这个时候数据只是存在于操作系统缓存。之所以说“通常”，可能会有丢失不只1秒的数据的情况，比如说执行flush操作的时候阻塞了。总结设为1当然是最安全的，但性能页是最差的（相对其他两个参数而言，但不是不能接受）。如果对数据一致性和完整性要求不高，完全可以设为2,如果只最求性能，例如高并发写的日志服务器，设为0来获得更高性能|| innodb_locks_unsafe_for_binlog | OFF || innodb_log_buffer_size | 16777216 || innodb_log_checksums | ON|| innodb_log_compressed_pages | ON || innodb_log_file_size | 50331648 #日志文件大小 || innodb_log_files_in_group | 2 # DB中设置几组事务日志，默认是2|| innodb_log_group_home_dir | .&#x2F; #定义innodb事务日志组的位置,此位置设置默认为MySQL的datadir | 每个事务日志都是大小为50兆的文件（不同版本的mysql有差异）： 在mysql中默认以ib_logfile0,ib_logfile1名称存在 慢查询日志：slow query log 顾名思义，慢查询日志中记录的是执行时间较长的query，也就是我们常说的slow query。 慢查询日志采用的是简单的文本格式，可以通过各种文本编辑器查看其中的内容。其中 记录了语句执行的时刻，执行所消耗的时间，执行用户，连接主机等相关信息。 慢查询日志的作用： 慢查询日志是用来记录执行时间超过指定时间的查询语句。通过慢查询日志，可以查找出哪些查询语句的执行效率很低，以便进行优化。一般建议开启，它对服务器性能的影响微乎其微，但是可以记录mysql服务器上执行了很长时间的查询语句。可以帮助我们定位性能问题的。MySQL 还提供了专门用来分析满查询日志的工具程序mysqldumpslow，用来帮助数据库管理人员解决可能存在的性能问题。 查看慢查询日志的定义： 1234567891011121314151617181920mysql> show global variables like '%slow_query_log%';+---------------------+------------------------------------+| Variable_name | Value |+---------------------+------------------------------------+| slow_query_log | OFF || slow_query_log_file | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;192-slow.log |+---------------------+------------------------------------+2 rows in set (0.00 sec)mysql> show global variables like '%long%';+----------------------------------------------------------+-----------+| Variable_name | Value |+----------------------------------------------------------+-----------+| long_query_time | 10.000000 || performance_schema_events_stages_history_long_size | 10000 || performance_schema_events_statements_history_long_size | 10000 || performance_schema_events_transactions_history_long_size | 10000 || performance_schema_events_waits_history_long_size | 10000 |+----------------------------------------------------------+-----------+5 rows in set (0.00 sec) **启动和设置慢查询日志： ** 方法1：通过配置文件my.cnf开启慢查询日志： 注：在不同的mysql版本中，开启慢查询日志参数不太一样，不过都可以通过 show variables like “%slow%” 和show variables like &quot;%long%&quot;查看出来。 1234567891011mysql> show global variables like '%slow%';+---------------------------+------------------------------------------+| Variable_name | Value |+---------------------------+------------------------------------------+| log_slow_admin_statements | OFF || log_slow_slave_statements | OFF || slow_launch_time | 2 || slow_query_log | OFF || slow_query_log_file | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;localhost-slow.log |+---------------------------+------------------------------------------+5 rows in set (0.00 sec) 其中： slow_query_log： off关闭状态 on开启状态 slow_query_log_file 慢查询日志存放地点 long_query_time选项来设置一个时间值，时间以秒为单位，可以精确到微秒。如果查询时间超过了这个时间值（默认为10秒），这个查询语句将被记录到慢查询日志中, 设置为0的话表示记录所有的查询。 slow_launch_time 表示如果建立线程花费了比这个值更长的时间,slow_launch_threads 计数器将增加 注：如果不指定存储路径，慢查询日志默认存储到mysql数据库的数据文件下，如果不指定文件名，默认文件名为hostname-slow.log 修改my.cnf文件： 12345[mysqld]slow_query_log=1slow_query_log_file=/usr/local/mysql/data/mysql-slow.loglong_query_time=1slow_launch_time=1 重启mysqld服务 再次查询慢查询日志定义 方法2：通过登录mysql服务器直接定义，方式如下： 123456mysql>set global slow_query_log&#x3D;1; #开启慢查询日志Query OK, 0 rowsaffected (0.35 sec)mysql>set session long_query_time&#x3D;0.0001; #更改时间（当前session中，退出则重置）Query OK, 0 rowsaffected (0.00 sec)mysql>set global long_query_time&#x3D;0.0001; #更改时间（全局中，重启服务则重置）mysql> SHOW VARIABLES LIKE 'long%'; #查询定义时间 查看慢查询日志 12345678mysql> use mysqlmysql> select user,host from user where user&#x3D;\"root\"; +------+-----------+| user | host |+------+-----------+| root | localhost |+------+-----------+1 row in set (0.02 sec) 或用系统查看文件内容命令如cat直接查看慢日志文件 第一行表示记录日志时的时间。其格式是 YYYY-MM-DD HH:MM:SS。我们可以看出上面的查询记录于 2016 年 8 月 29 日下午 15:47：24 - 注意：这个是服务器时间. MySql 用户、服务器以及主机名第三行表示总的查询时间、锁定时间、&quot;发送&quot;或者返回的行数 Query_time: 0.000304 表示用了0.000304秒 Lock_time: 0.000128 表示锁了0.000128秒 Rows_sent: 4 表示返回4行 Rows_examined: 4 表示一共查了4行 SETtimestamp=UNIXTIME; 这是查询实际发生的时间 何将其变成一个有用的时间，将 Unix 时间转成一个可读的时间，可以使用 date –d@日志中的时间戳可以看到查询进行的同时记录了该日志 ，但是对于一台超负载的服务器常常并非如此。因此记住：SETtimestamp= value 才是实际的查询的执行时间。 慢查询分析mysqldumpslow 们可以通过打开log文件查看得知哪些SQL执行效率低下。从日志中，可以发现查询时间超过long_query_time时间的query为慢查询，而小于long_query_time时间的没有出现在此日志中。 如果慢查询日志中记录内容很多，可以使用mysqldumpslow工具（MySQL客户端安装自带）来对慢查询日志进行分类汇总。mysqldumpslow对日志文件进行了分类汇总，显示汇总后摘要结果 进入log的存放目录，运行 1[root@localhost data]# mysqldumpslow mysqld-slow.log 123456注： mysqldumpslow -s c -t 10 &#x2F;database&#x2F;mysql&#x2F;slow-query.log 这会输出记录次数最多的10条SQL语句，其中： -s, 是表示按照何种方式排序，c、t、l、r分别是按照记录次数、时间、查询时间、返回的记录数来排序，ac、at、al、ar，表示相应的倒序； -t, 是top n的意思，即为返回前面多少条的数据； -g, 后边可以写一个正则匹配模式，大小写不敏感的； 例如： &#x2F;path&#x2F;mysqldumpslow -s r -t 10&#x2F;database&#x2F;mysql&#x2F;slow-log 得到返回记录集最多的10个查询。&#x2F;path&#x2F;mysqldumpslow -s t -t 10 -g “left join” &#x2F;database&#x2F;mysql&#x2F;slow-log 得到按照时间排序的前10条里面含有左连接的查询语句。","path":"posts/4c37.html","date":"06-17","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"mysql二进制日志","text":"一、什么是二进制日志 MySQL的二进制日志（binary log）是一个二进制文件，主要用于记录修改数据或有可能引起数据变更的MySQL语句。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作，并且记录了语句发生时间、执行时长、操作数据等其它额外信息，但是它不记录SELECT、SHOW等那些不修改数据的SQL语句。二进制日志（binary log）主要用于数据库恢复和主从复制，以及审计（audit）操作。 开启二进制日志对性能的开销很小，带来的好处远大于坏处。 二、开启和设置二进制日志 1、查看二进制日志状态 默认情况下二进制日志是关闭的。 系统变量log_bin的值为OFF表示没有开启二进制日志，ON表示开启了二进制日志，如下所示： 1234567mysql> show variables like 'log_bin';+---------------------------------+------------------------------------+| Variable_name | Value |+---------------------------------+------------------------------------+| log_bin | OFF |+---------------------------------+------------------------------------+1 rows in set (0.00 sec) 2、开启二进制日志 （1）修改配置文件并重启mysql服务 如果需要开启二进制日志，则必须在配置文件中[mysqld]下面添加log-bin [=DIR[filename]] 。 1234DIR参数指定二进制文件的存储路径；filename参数指定二级制文件的文件名。 其中filename可以任意指定，但最好有一定规范。系统变量log_bin是静态参数，不能动态修改的（因为它不是Dynamic Variable）。 内容如下所示： 1234server-id = 1 # mysql5.7必须加，否则mysql服务启动报错log-bin = mysql_bin_log # 路径及命名，默认在data下expire_logs_days = 10 # 过期时间,二进制文件自动删除的天数,0代表不删除max_binlog_size = 100M server-id = 1 # mysql5.7必须加，否则mysql服务启动报错log-bin = mysql_bin_log # 路径及命名，默认在data下expire_logs_days = 10 # 过期时间,二进制文件自动删除的天数,0代表不删除max_binlog_size = 100M # 单个日志文件的大小限制，超出会新建一个 操作步骤： Linux下的配置文件为/etc/my.cnf，Windows下的配置文件为my.ini。 12345678910111213141516171819202122232425[root@192 ~]# vim /etc/my.cnf[mysqld]# 省略部分内容server-id = 1 # mysql5.7必须加，否则mysql服务启动报错log-bin = mysql_bin_log # 路径及命名，默认在data下expire_logs_days = 10 # 过期时间,二进制文件自动删除的天数,0代表不删除max_binlog_size = 100M # 单个日志文件大小[root@192 ~]# systemctl restart mysqld.service[root@192 ~]# systemctl status mysqld.service● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 二 2020-06-16 17:47:34 CST; 35s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 78724 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 78701 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 78726 (mysqld) Tasks: 27 CGroup: /system.slice/mysqld.service └─78726 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid6月 16 17:47:25 my_oracle systemd[1]: Starting MySQL Server...6月 16 17:47:34 my_oracle systemd[[root@192 ~]# vim /etc/my.cnf[mysqld]# 省略部分内容server-id = 1 # mysql5.7必须加，否则mysql服务启动报错log-bin = mysql_bin_log # 路径及命名，默认在data下expire_logs_days = 10 # 过期时间,二进制文件自动删除的天数,0代表不删除max_binlog_size = 100M # 单个日志文件大小[root@192 ~]# systemctl restart mysqld.service[root@192 ~]# systemctl status mysqld.service● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 二 2020-06-16 17:47:34 CST; 35s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 78724 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 78701 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 78726 (mysqld) Tasks: 27 CGroup: /system.slice/mysqld.service └─78726 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid6月 16 17:47:25 my_oracle systemd[1]: Starting MySQL Server...6月 16 17:47:34 my_oracle systemd[1]: Started MySQL Server. （2）查看二进制日志状态 重启MySQL后，你就会发现log_bin变为了ON，二进制日志（binary log）默认放在数据目录下（系统变量datadir下）。 show variables like ‘log_bin%’; 1234567891011mysql> show variables like 'log_bin%';+---------------------------------+------------------------------------+| Variable_name | Value |+---------------------------------+------------------------------------+| log_bin | ON || log_bin_basename | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql_bin_log || log_bin_index | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql_bin_log.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF |+---------------------------------+------------------------------------+5 rows in set (0.00 sec) （3）查看当前服务器所有的二进制日志文件 show binary logs; MySQL二进制日志存储了所有的变更信息，MySQL二进制日志经常使用。当MySQL创建二进制日志文件时，首先创建一个以’filename’为名称，以’.index’为后缀的文件；在创建一个以’filename’为名称，以’.000001’为后缀的文件。当MySQL服务重启一次，以’.000001’为后缀的文件会增加一个，并且后缀名加1递增。如果日志长度超过max_binlog_size的上限，也会创建一个新的日志。 Show binary logs;可以查看当前的*二进制日志文件个数及其文件名。二进制日志并不能直接查看，如果想要查看日志内容，可以通过mysqlbinlog命令查看。 1234567mysql> show binary logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000001 | 120 |+----------------------+-----------+1 rows in set (0.00 sec) 或者： show master logs; 1234567mysql> show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000001 | 120 |+----------------------+-----------+1 rows in set (0.00 sec) （4）查看当前二进制日志文件状态 show master status; 1234567mysql> show master status;+----------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+----------------------+----------+--------------+------------------+-------------------+| mysql_bin_log.000001 | 120 | | | |+----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 三、切换二进制日志 执行 flush logs 可以刷新切换二进制文件。 每次重启MySQL服务也会生成一个新的二进制日志文件，相当于二进制日志切换。 1、重启MySQL服务切换日志 （1）重启MySQL服务器前 查看二进制日志状态，如下所示： 1234567mysql> show master status;+----------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+----------------------+----------+--------------+------------------+-------------------+| mysql_bin_log.000001 | 120 | | | |+----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) （2）重启MySQL服务 service mysql restart 1234[root@192 ~]# service mysql restartShutting down MySQL.... SUCCESS! Starting MySQL.. SUCCESS! [root@192 ~][root@192 ~]# service mysql restartShutting down MySQL.... SUCCESS! Starting MySQL.. SUCCESS! [root@192 ~]# （3）查看日志 1234567mysql> show master status;+----------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+----------------------+----------+--------------+------------------+-------------------+| mysql_bin_log.000002 | 120 | | | |+----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 2、切换二进制日志并查看 执行flush logs刷新，切换二进制文件，并查看二进制日志状态。如下所示： flush logs; show master status; 12345678910mysql> flush logs;Query OK, 0 rows affected (0.06 sec)mysql> show master status;+----------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+----------------------+----------+--------------+------------------+-------------------+| mysql_bin_log.000003 | 120 | | | |+----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 切换二进制日志时，你会看到这些number会不断递增。另外，除了这些二进制日志文件外，你会看到还生成了一个mysql-bin.index的文件，这个文件中存储所有二进制日志文件的清单又称为二进制文件的索引。 1234567891011[root@192 ~]# ll /var/lib/mysql/#源码安装路径是：/usr/[root@192 ~]# ll /var/lib/mysql/#源码安装路径是：/usr/local/mysql/data/-rw-rw----. 1 mysql mysql 171 4月 10 11:25 mysql_bin_log.000001-rw-rw----. 1 mysql mysql 143 4月 10 11:25 mysql_bin_log.000002-rw-rw----. 1 mysql mysql 143 4月 10 11:25 mysql_bin_log.000003-rw-rw----. 1 mysql mysql 92 4月 10 11:25 mysql_bin_log.index[root@192 ~]# cat /var/lib/mysql/mysql_bin_log.index ./mysql_bin_log.000001./mysql_bin_log.000002./mysql_bin_log.000003 四、查看二进制日志 1、查看当前日志 show binlog events; 12345678mysql> show binlog events;+----------------------+-----+-------------+-----------+-------------+---------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+-------------+-----------+-------------+---------------------------------------+| mysql_bin_log.000001 | 4 | Format_desc | 1 | 120 | Server ver: 5.6.42-log, Binlog ver: 4 || mysql_bin_log.000001 | 120 | Rotate | 1 | 171 | mysql_bin_log.000002;pos&#x3D;4 |+----------------------+-----+-------------+-----------+-------------+---------------------------------------+2 rows in set (0.00 sec) 2、查看指定日志 （1）模拟产生二进制日志 建库、建表、插入数据 1234567891011mysql> create database demo;Query OK, 1 row affected (0.00 sec)mysql> use demo;Database changedmysql> create table student(stuNo int, stuName varchar(25));Query OK, 0 rows affected (0.01 sec)mysql> insert into student values(1001,'John');Query OK, 1 row affected (0.00 sec) （2）查看日志 show binlog events in ‘mysql_bin_log.000002’; 123456789101112mysql> show binlog events in 'mysql_bin_log.000002';+----------------------+-----+-------------+-----------+-------------+------------------------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+-------------+-----------+-------------+------------------------------------------------------------------+| mysql_bin_log.000002 | 4 | Format_desc | 1 | 120 | Server ver: 5.6.42-log, Binlog ver: 4 || mysql_bin_log.000002 | 120 | Query | 1 | 214 | create database demo || mysql_bin_log.000002 | 214 | Query | 1 | 340 | use &#96;demo&#96;; create table student(stuNo int, stuName varchar(25)) || mysql_bin_log.000002 | 340 | Query | 1 | 419 | BEGIN || mysql_bin_log.000002 | 419 | Query | 1 | 532 | use &#96;demo&#96;; insert into student values(1001,'John') || mysql_bin_log.000002 | 532 | Xid | 1 | 563 | COMMIT &#x2F;* xid&#x3D;15 *&#x2F; |+----------------------+-----+-------------+-----------+-------------+------------------------------------------------------------------+6 rows in set (0.00 sec) show binlog events in ‘mysql_bin_log.000002’ from 419; 查看某个节点 12345678mysql> show binlog events in 'mysql_bin_log.000002' from 419;+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| mysql_bin_log.000002 | 419 | Query | 1 | 532 | use &#96;demo&#96;; insert into student values(1001,'John') || mysql_bin_log.000002 | 532 | Xid | 1 | 563 | COMMIT &#x2F;* xid&#x3D;15 *&#x2F; |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+2 rows in set (0.00 sec) show binlog events in ‘mysql_bin_log.000002’ from 419 limit 1; 查看从419开始的一条数据 12345678910111213141516mysql> show binlog events in 'mysql_bin_log.000002' from 419 limit 1;+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| mysql_bin_log.000002 | 419 | Query | 1 | 532 | use &#96;demo&#96;; insert into student values(1001,'John') |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+1 row in set (0.00 sec)mysql> show binlog events in 'mysql_bin_log.000002' from 419 limit 2;+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+| mysql_bin_log.000002 | 419 | Query | 1 | 532 | use &#96;demo&#96;; insert into student values(1001,'John') || mysql_bin_log.000002 | 532 | Xid | 1 | 563 | COMMIT &#x2F;* xid&#x3D;15 *&#x2F; |+----------------------+-----+------------+-----------+-------------+-----------------------------------------------------+2 rows in set (0.00 sec) 五、使用二进制日志恢复数据库 如果开启了二进制日志，出现了数据丢失，可以通过二进制日志恢复数据库，语法如下： 1mysqlbinlog [option] filename | mysql -u user -p passwd option的参数主要有两个 --start-datetime --stop-datetime 和 start-position --stop-position ,前者指定恢复的时间点，后者指定恢复的位置（位置指的是二进制文件中 # at 580 580就是位置），原理就是把记录的语句重新执行了一次。如果恢复了两次。会产生重复数据。 1、按时间点恢复数据 （1）从日志开头截止到某个时间点的恢复 1mysqlbinlog [--no-defaults] --stop-datetime&#x3D;’年-月-日 小时:分钟:秒’ 二进制日志 | mysql -u 用户名 -p 例如： 1mysqlbinlog [--no-defaults] --stop-datetime=’2020-03-18 10:30:26’ /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -p （2）从某个时间点到日志结尾的恢复 1mysqlbinlog [--no-defaults] --start-datetime&#x3D;’年-月-日 小时:分钟:秒’ 二进制日志 | mysql -u 用户名 -p 例如： 1mysqlbinlog [--no-defaults] --start-datetime=’2020-01-10 8:20:20’ /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -p （3）从某个时间点到某个时间点的恢复 1mysqlbinlog [--no-defaults] --start-datetime&#x3D;’年-月-日 小时:分钟:秒’ --stop-datetime&#x3D;’年-月-日小时:分钟:秒’ 二进制日志 | mysql -u 用户名 -p 例如： 1mysqlbinlog [--no-defaults] --start-datetime=’2010-11-10 8:20:20’ --stop-datetime=’2020-03-18 10:30:26’ /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -p 2、按位置恢复数据 （1）从某个位置到日志结尾的恢复 123/usr/local/mysql/bin/mysqlbinlog --start-position='275' /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -pEnter password: [root@bogon ~]# （2）从日志开头位置到日志结尾的恢复 123/usr/local/mysql/bin/mysqlbinlog --stop-position='465' /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -pEnter password: [root@bogon ~]# （3）从某个位置到某个位置的恢复 123/usr/local/mysql/bin/mysqlbinlog --start-position='4' --stop-position='120' /var/lib/mysql/mysql_bin_log.000005 | mysql -uroot -pEnter password: [root@bogon ~]# 例子 123456789101112131415161718192021222324252627mysql> drop database demo;Query OK, 1 row affected (0.00 sec)mysql> show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec)[root@192 ~]# &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqlbinlog --start-position&#x3D;'4' --stop-position&#x3D;'313' &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql_bin_log.000002 | mysql -uroot -pmysql> show databases;+--------------------+| Database |+--------------------+| information_schema || demo || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec) 六、删除二进制日志 1、删除某个日志之前的所有二进制日志文件 purge binary logs to xxx; 表示删除某个日志之前的所有二进制日志文件，这个命令会修改index中相关数据。 如下所示： 12345678910111213141516171819202122232425mysql> show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000001 | 143 || mysql_bin_log.000002 | 586 || mysql_bin_log.000003 | 171 || mysql_bin_log.000004 | 171 || mysql_bin_log.000005 | 120 |+----------------------+-----------+5 rows in set (0.00 sec)mysql> purge binary logs to 'mysql_bin_log.000002';Query OK, 0 rows affected (0.03 sec)mysql> show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000002 | 586 || mysql_bin_log.000003 | 171 || mysql_bin_log.000004 | 171 || mysql_bin_log.000005 | 120 |+----------------------+-----------+4 rows in set (0.00 sec) 查看日志清单： 12345[root@192 ~]# cat /var/lib/mysql/mysql_bin_log.index ./mysql_bin_log.000002./mysql_bin_log.000003./mysql_bin_log.000004./mysql_bin_log.000005 2、清除某个时间点以前的二进制日志文件 12mysql> purge binary logs before '2020-03-10 10:10:00';Query OK, 0 rows affected (0.00 sec) 3、清除7天前的二进制日志文件 12mysql> purge master logs before date_sub( now( ), interval 7 day);Query OK, 0 rows affected (0.00 sec) 4、清除所有的二进制日志文件（当前不存在主从复制关系） reset之后，从000001开始生成全新空日志。 123456789101112131415161718192021mysql> show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000002 | 586 || mysql_bin_log.000003 | 171 || mysql_bin_log.000004 | 171 || mysql_bin_log.000005 | 120 |+----------------------+-----------+4 rows in set (0.00 sec)mysql> reset master;Query OK, 0 rows affected (0.01 sec)mysql> show master logs;+----------------------+-----------+| Log_name | File_size |+----------------------+-----------+| mysql_bin_log.000001 | 120 |+----------------------+-----------+1 row in set (0.00 sec) 5、自动清理二进制日志文件 另外，我们也可以设置expire_logs_days参数，设置自动清理，其默认值为0,表示不启用过期自动删除功能，如果启用了自动清理功能，表示超出此天数的二进制日志文件将被自动删除，自动删除工作通常发生在MySQL启动时或flush日志时。 1234567mysql> show variables like 'expire_logs_days';+------------------+-------+| Variable_name | Value |+------------------+-------+| expire_logs_days | 10 |+------------------+-------+1 row in set (0.00 sec) 七、停止二进制日志 可以通过修改配置文件停止二进制日志功能，但是需要重启数据库，mysql提供了语句可以在线停止二进制功能。 12set sql_log_bin &#x3D; 0 # 停止二进制日志功能set sql_log_bin &#x3D; 1 # 开启二进制日志功能","path":"posts/af18.html","date":"06-17","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"mysql日志","text":"mysql日志 MySQL日志记录了MySQL数据库日常操作和错误信息。MySQL有不同类型的日志文件（各自存储了不同类型的日志），从日志当中可以查询到MySQL数据库的运行情况、用户的操作、错误的信息等。 A：MySQL日志分为4大类 错误日志：记录mysql服务的启动，运行或停止mysql服务时出现的问题 查询日志：记录建立的客户端的连接和执行的语句 二进制日志：记录所有更改数据的语句，可以用于数据的复制 慢查询日志：记录所有执行的时间超过long_query_time的所有查询或不使用索引的查询 默认情况下，所有日志创建与MySQL数据目录中，通过刷新日志，可以强制MySQL关闭和重新打开日志文件，Flush logs刷新日志或者执行mysqladmin flush-logs 如果正使用MySQL复制功能，在复制服务器上可以维护更多日志文件，这种日志我们称为接替日志。启动日志功能会降低MySQL数据库的性能。 B：错误日志：Error Log 在mysql数据库中，错误日志功能是默认开启的。默认情况下，错误日志存储在mysql数据库的数据目录中。错误日志文件通常的名称为hostname.err。其中，hostname表示服务器主机名。 错误日志信息可以自己进行配置的，错误日志所记录的信息是可以通过log-error和log-warnings来定义的，其中log-error是定义是否启用错误日志的功能和错误日志的存储位置，log-warnings是定义是否将警告信息也定义至错误日志中。默认情况下错误日志大概记录以下几个方面的信息：服务器启动和关闭过程中的信息（未必是错误信息，如mysql如何启动InnoDB的表空间文件的、如何初始化自己的存储引擎的等等）、服务器运行过程中的错误信息、事件调度器运行一个事件时产生的信息、在从服务器上启动服务器进程时产生的信息 注1：MySQL有很多系统变量可以设置，系统变量设置不同，会导致系统运行状态的不同。因此mysql提供两组命令，分别查看系统设置和运行状态。 C：MySQL日志缓存 一个高速、稳定、可靠的系统，缓存在其中必定起着至关重要的作用。MySQL日志处理也使用了缓存机制。MySQL日志最初存放在MySQL服务器的内存中，若超过指定的存储容量，内存中的日志则写（或者刷新flush）到外存中，以数据库表或者以文件的方式永远的保存在硬盘中。 1、查看系统设置： 1SHOW [GLOBAL | SESSION] VARIABLES [like_or_where] SHOW VARIABLES： shows the values of MySQL system variables. 2、运行状态： 1SHOW [GLOBAL | SESSION] STATUS [like_or_where] SHOW STATUS： provides server status information. D：如何修改系统配置 方法1：配置文件设置my.cnf 如：binlog_cache_size = 1M 方法2：set global binlog_cache_size = 1048576; 注 2：查看mysql的版本 12[root@localhost ~]# mysql -Vmysql Ver 14.14 Distrib 5.7.28, for Linux (x86_64) using EditLine wrapper 或 12345678910111213141516171819202122mysql> status;--------------mysql Ver 14.14 Distrib 5.7.28, for Linux (x86_64) using EditLine wrapperConnection id: 5Current database:Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server version: 5.7.28 Source distributionProtocol version: 10Connection: Localhost via UNIX socketServer characterset: utf8Db characterset: utf8Client characterset: utf8Conn. characterset: utf8UNIX socket: &#x2F;tmp&#x2F;mysql.sockUptime: 1 hour 12 min 8 secThreads: 1 Questions: 10 Slow queries: 0 Opens: 106 Flush tables: 1 Opentables: 99 Queries per second avg: 0.002-------------- 或 1234567mysql> select version();+-----------+| version() |+-----------+| 5.7.28 |+-----------+1 row in set (0.00 sec) E: 一般而言，日志级别的定义没有会话变量都只是在全局级别下进行定义 错误日志的状态： 123456789mysql> show global variables like '%log_error%';+---------------------+---------------------------------+| Variable_name | Value |+---------------------+---------------------------------+| binlog_error_action | ABORT_SERVER || log_error | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql.err || log_error_verbosity | 3 |+---------------------+---------------------------------+3 rows in set (0.00 sec) 其中 log_error定义为错误日志文件路径 log_error_verbosity: 更改错误日志位置可以使用log-error来设置形式如下 12\\#vi /etc/my.cnflog-error = /usr/local/mysql/data/mysqld.err 查看mysql错误日志： 1#tail /usr/#tail /usr/local/mysql/data/mysqld.err 为了方便维护需要，有时候会希望将错误日志中的内容做备份并重新开始记录，这时候就可以利用MySQL 的FLUSH LOGS 命令来告诉MySQL 备份旧日志文件并生成新的日志文件。备份文件名以“.old”结尾。 删除错误日志： 在mysql5.5.7之前：数据库管理员可以删除很长时间之前的错误日志，以保证mysql服务器上的硬盘空间。mysql数据库中，可以使用mysqladmin命令开启新的错误日志。mysqladmin命令的语法如下：mysqladmin –u root –p flush-logs也可以登录mysql数据库中使用FLUSH LOGS语句来开启新的错误日志。 在mysql5.5.7之后：服务器将关闭此项功能。只能使用重命名原来的错误日志文件，手动冲洗日志创建一个新的：方式如下： 123\\# mv mysql.err mysql.old\\# mysqladmin -uroot -p flush-logsEnter password: F： 二进制日志 主要记录MySQL数据库的变化，二进制日志以一种有效的格式，并且是事务安全的方式包含更新日志中可用的信息。二进制日志包含了所有更新了数据或者已经潜在更新了数据。二进制日志还包含关于每个更新数据库的语句的执行时间，它不包含没有修改任何数据的语句。使用二进制日志的主要目的是最大可能地恢复数据库。 启动二进制日志，默认情况下二进制日志是关闭的 编辑配置文件My.ini 或my.cnf 1234567891011[root@localhost ~]# vim &#x2F;etc&#x2F;my.cnf【格式】：[mysqld]log-binexpire_logs_days &#x3D; 10max_binlog_size &#x3D; 100Mlog-bin [&#x3D;path&#x2F;[filename]] &#x2F;&#x2F;二进制日志[路径[指定日志文件的名字Expire_logs_days &#x3D; 10 &#x2F;&#x2F;清除日志的天数Max_binlog_size &#x3D; 100M &#x2F;&#x2F;单个日志文件的大小限制，超出会新建一个默认为1GB【重启mysql】 Show variables 或show variables like 'log_%'; 语句来查询日志设置 123456789101112131415161718192021222324252627mysql> show variables like 'log_%';+---------------------------------+-------------------------------------------------+| Variable_name | Value|+---------------------------------+-------------------------------------------------+| log_bin | ON|| log_bin_trust_function_creators | OFF|| log_error |&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;localhost.localdomain.err || log_output | FILE|| log_queries_not_using_indexes | OFF|| log_slave_updates | OFF|| log_slow_queries | OFF|| log_warnings | 1|+---------------------------------+-------------------------------------------------+8 rows in set (0.00 sec) 【查看二进制日志】 MySQL二进制日志存储了所有的变更信息，MySQL二进制日志经常使用。当MySQL创建二进制日志文件时，首先创建一个以’filename’为名称，以’.index’为后缀的文件；在创建一个以’filename’为名称，以’.000001’为后缀的文件。当MySQL服务重启一次，以’.000001’为后缀的文件会增加一个，并且后缀名加1递增。如果日志长度超过max_binlog_size的上限，也会创建一个新的日志。 Show binary logs;可以查看当前的二进制日志文件个数及其文件名。二进制日志并不能直接查看，如果想要查看日志内容，可以通过mysqlbinlog命令查看 12345678mysql> SHOW BINARY LOGS;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 2189 || mysql-bin.000002 | 107 |+------------------+-----------+2 rows in set (0.06 sec) 【查看二进制日志的内容】 退出mysql在命令行 12345678910[root@localhost data]# mysqlbinlog mysql-bin.000001&#x2F;*!40019 SET @@session.max_insert_delayed_threads&#x3D;0*&#x2F;;&#x2F;*!50003 SET @OLD_COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;0*&#x2F;;DELIMITER &#x2F;*!*&#x2F;;# at 4#170826 11:40:02 server id 1 end_log_pos 107 Start: binlog v 4, server v5.5.22-log created 170826 11:40:02 at startupROLLBACK&#x2F;*!*&#x2F;;BINLOG '... ... 省略 【删除二进制日志】 MySQL的二进制文件可以配置自动删除，同时MySQL提供了手动删除二进制文件的方法RESET MASTER 删除所有的二进制日志文件；PURGE MASTER LOGS只删除部分二进制日志文件。 Reset master; 删除所有二进制日志 Purge master logs to ‘二进制名’ 删除单个二进制日志之前的 12345mysql> PURGE MASTER LOGS TO \"mysql-bin.000012\";Query OK, 0 rows affected (0.02 sec)Purge binary logs before ‘date’ 删除指定日期之前的日志mysql> PURGE MASTER LOGS BEFORE '20170101';Query OK, 0 rows affected (0.07 sec)","path":"posts/b6d.html","date":"06-17","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL创建触发器","text":"一、MySQL创建触发器（CREATE TRIGGER） 基本语法 在 MySQL 5.7 中，可以使用 CREATE TRIGGER 语句创建触发器。 语法格式如下： 123CREATE < BEFORE | AFTER >ON FOR EACH Row 语法说明如下。 1) 触发器名 触发器的名称，触发器在当前数据库中必须具有唯一的名称。如果要在某个特定数据库中创建，名称前面应该加上数据库的名称。 2) INSERT | UPDATE | DELETE 触发事件，用于指定激活触发器的语句的种类。 注意：三种触发器的执行时间如下。 INSERT：将新行插入表时激活触发器。例如，INSERT 的 BEFORE 触发器不仅能被 MySQL 的 INSERT 语句激活，也能被 LOAD DATA 语句激活。 DELETE： 从表中删除某一行数据时激活触发器，例如 DELETE 和 REPLACE 语句。 UPDATE：更改表中某一行数据时激活触发器，例如 UPDATE 语句。 3) BEFORE | AFTER BEFORE 和 AFTER，触发器被触发的时刻，表示触发器是在激活它的语句之前或之后触发。若希望验证新数据是否满足条件，则使用 BEFORE 选项；若希望在激活触发器的语句执行之后完成几个或更多的改变，则通常使用 AFTER 选项。 4) 表名 与触发器相关联的表名，此表必须是永久性表，不能将触发器与临时表或视图关联起来。在该表上触发事件发生时才会激活触发器。同一个表不能拥有两个具有相同触发时刻和事件的触发器。例如，对于一张数据表，不能同时有两个 BEFORE UPDATE 触发器，但可以有一个 BEFORE UPDATE 触发器和一个 BEFORE INSERT 触发器，或一个 BEFORE UPDATE 触发器和一个 AFTER UPDATE 触发器。 5) 触发器主体 触发器动作主体，包含触发器激活时将要执行的 MySQL 语句。如果要执行多个语句，可使用 BEGIN…END 复合语句结构。 6) FOR EACH ROW 一般是指行级触发，对于受触发事件影响的每一行都要激活触发器的动作。例如，使用 INSERT 语句向某个表中插入多行数据时，触发器会对每一行数据的插入都执行相应的触发器动作。 注意：每个表都支持 INSERT、UPDATE 和 DELETE 的 BEFORE 与 AFTER，因此每个表最多支持 6 个触发器。每个表的每个事件每次只允许有一个触发器。单一触发器不能与多个事件或多个表关联。 另外，在 MySQL 中，若需要查看数据库中已有的触发器，则可以使用 SHOW TRIGGERS 语句。 二、创建 BEFORE 类型触发器 在 test_db 数据库中，数据表 tb_emp8 为员工信息表，包含 id、name、deptId 和 salary 字段，数据表 tb_emp8 的表结构如下所示。 1234567891011121314151617181920mysql> create table tb_emp8( -> id int(11) not null PRIMARY KEY, -> name VARCHAR(22) UNIQUE, -> deptId int(11) not null, -> salary FLOAT DEFAULT 0 -> )charset &#x3D; 'utf8mb4';Query OK, 0 rows affected (0.01 sec)mysql> SELECT * FROM tb_emp8;Empty set (0.07 sec)mysql> DESC tb_emp8;+--------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(22) | YES | UNI | NULL | || deptId | int(11) | NO | MUL | NULL | || salary | float | YES | | 0 | |+--------+-------------+------+-----+---------+-------+4 rows in set (0.05 sec) 【实例 1】 创建一个名为 SumOfSalary 的触发器，触发的条件是向数据表 tb_emp8 中插入数据之前，对新插入的 salary 字段值进行求和计算。输入的 SQL 语句和执行过程如下所示。 12345# 创建触发器create TRIGGER SumOfSalarybefore insert on tb_emp8for each ROWset @sum&#x3D;@sum+NEW.salary; 触发器 SumOfSalary 创建完成之后，向表 tb_emp8 中插入记录时，定义的 sum 值由 0 变成了 1500，即插入值 1000 和 500 的和，如下所示。 123456789101112131415SET @sum&#x3D;0;Query OK, 0 rows affected (0.05 sec)#插入数据，会自动调用触发器会自动调用触发器mysql> INSERT INTO tb_emp8 -> VALUES(1,'A',1,1000),(2,'B',1,500);Query OK, 2 rows affected (0.09 sec)Records: 2 Duplicates: 0 Warnings: 0mysql> SELECT @sum;+------+| @sum |+------+| 1500 |+------+1 row in set (0.03 sec) 三、创建 AFTER 类型触发器 在 test_db 数据库中，数据表 tb_emp6 和 tb_emp7 都为员工信息表，包含 id、name、deptId 和 salary 字段，数据表 tb_emp6 和 tb_emp7 的表结构如下所示。 123456789101112131415161718192021222324mysql> SELECT * FROM tb_emp6;Empty set (0.07 sec)mysql> SELECT * FROM tb_emp7;Empty set (0.03 sec)mysql> DESC tb_emp6;+--------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(25) | YES | | NULL | || deptId | int(11) | YES | MUL | NULL | || salary | float | YES | | NULL | |+--------+-------------+------+-----+---------+-------+4 rows in set (0.00 sec)mysql> DESC tb_emp7;+--------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(25) | YES | | NULL | || deptId | int(11) | YES | | NULL | || salary | float | YES | | 0 | |+--------+-------------+------+-----+---------+-------+4 rows in set (0.04 sec) 【实例 2】 创建一个名为 double_salary 的触发器，触发的条件是向数据表 tb_emp6 中插入数据之后，再向数据表 tb_emp7 中插入相同的数据，并且 salary 为 tb_emp6 中新插入的 salary 字段值的 2 倍。输入的 SQL 语句和执行过程如下所示。 123456mysql> CREATE TRIGGER double_salary -> AFTER INSERT ON tb_emp6 -> FOR EACH ROW -> INSERT INTO tb_emp7 -> VALUES (NEW.id,NEW.name,deptId,2*NEW.salary);Query OK, 0 rows affected (0.25 sec) 触发器 double_salary 创建完成之后，向表 tb_emp6 中插入记录时，同时向表 tb_emp7 中插入相同的记录，并且 salary 字段为 tb_emp6 中 salary 字段值的 2 倍，如下所示。 1234567891011121314151617181920212223242526# 插入后触发mysql> INSERT INTO tb_emp6 -> VALUES (1,'A',1,1000),(2,'B',1,500);Query OK, 2 rows affected (0.09 sec)Records: 2 Duplicates: 0 Warnings: 0mysql> SELECT * FROM tb_emp6;+----+------+--------+--------+| id | name | deptId | salary |+----+------+--------+--------+| 1 | A | 1 | 1000 || 2 | B | 1 | 500 |+----+------+--------+--------+3 rows in set (0.04 sec)mysql> SELECT * FROM tb_emp7;+----+------+--------+--------+| id | name | deptId | salary |+----+------+--------+--------+| 1 | A | 1 | 2000 || 2 | B | 1 | 1000 |+----+------+--------+--------+2 rows in set (0.06 sec)#删除触发器drop trigger double_salary;","path":"posts/184.html","date":"06-16","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL触发器","text":"A：MySQL触发器到底是什么？ MySQL 的触发器和存储过程一样，都是嵌入到 MySQL 中的一段程序，是 MySQL 中管理数据的有力工具。不同的是执行存储过程要使用 CALL 语句来调用，而触发器的执行不需要使用 CALL 语句来调用，也不需要手工启动，而是通过对数据表的相关操作来触发、激活从而实现执行。比如当对 student 表进行操作（INSERT，DELETE 或 UPDATE）时就会激活它执行。 触发器与数据表关系密切，主要用于保护表中的数据。特别是当有多个表具有一定的相互联系的时候，触发器能够让不同的表保持数据的一致性。 在 MySQL 中，只有执行 INSERT、UPDATE 和 DELETE 操作时才能激活触发器，其它 SQL 语句则不会激活触发器。 那么为什么要使用触发器呢？比如，在实际开发项目时，我们经常会遇到以下情况： 在学生表中添加一条关于学生的记录时，学生的总数就必须同时改变。 增加一条学生记录时，需要检查年龄是否符合范围要求。 删除一条学生信息时，需要删除其成绩表上的对应记录。 删除一条数据时，需要在数据库存档表中保留一个备份副本。 虽然上述情况实现的业务逻辑不同，但是它们都需要在数据表发生更改时，自动进行一些处理。这时就可以使用触发器处理。例如，对于第一种情况，可以创建一个触发器对象，每当添加一条学生记录时，就执行一次计算学生总数的操作，这样就可以保证每次添加一条学生记录后，学生总数和学生记录数是一致的。 B: 触发器的优缺点 触发器的优点如下： 触发器的执行是自动的，当对触发器相关表的数据做出相应的修改后立即执行。 触发器可以实施比 FOREIGN KEY 约束、CHECK 约束更为复杂的检查和操作。 触发器可以实现表数据的级联更改，在一定程度上保证了数据的完整性。 触发器的缺点如下： 使用触发器实现的业务逻辑在出现问题时很难进行定位，特别是涉及到多个触发器的情况下，会使后期维护变得困难。 大量使用触发器容易导致代码结构被打乱，增加了程序的复杂性， 如果需要变动的数据量较大时，触发器的执行效率会非常低。 C：MySQL 支持的触发器 在实际使用中，MySQL 所支持的触发器有三种：INSERT 触发器、UPDATE 触发器和 DELETE 触发器。 1) INSERT 触发器 在 INSERT 语句执行之前或之后响应的触发器。 使用 INSERT 触发器需要注意以下几点： 在 INSERT 触发器代码内，可引用一个名为 NEW（不区分大小写）的虚拟表来访问被插入的行。 在 BEFORE INSERT 触发器中，NEW 中的值也可以被更新，即允许更改被插入的值（只要具有对应的操作权限）。 对于 AUTO_INCREMENT 列，NEW 在 INSERT 执行之前包含的值是 0，在 INSERT 执行之后将包含新的自动生成值。 2) UPDATE 触发器 在 UPDATE 语句执行之前或之后响应的触发器。 使用 UPDATE 触发器需要注意以下几点： 在 UPDATE 触发器代码内，可引用一个名为 NEW（不区分大小写）的虚拟表来访问更新的值。 在 UPDATE 触发器代码内，可引用一个名为 OLD（不区分大小写）的虚拟表来访问 UPDATE 语句执行前的值。 在 BEFORE UPDATE 触发器中，NEW 中的值可能也被更新，即允许更改将要用于 UPDATE 语句中的值（只要具有对应的操作权限）。 OLD 中的值全部是只读的，不能被更新。 注意：当触发器设计对触发表自身的更新操作时，只能使用 BEFORE 类型的触发器，AFTER 类型的触发器将不被允许。 3) DELETE 触发器 在 DELETE 语句执行之前或之后响应的触发器。 使用 DELETE 触发器需要注意以下几点： 在 DELETE 触发器代码内，可以引用一个名为 OLD（不区分大小写）的虚拟表来访问被删除的行。 OLD 中的值全部是只读的，不能被更新。 总体来说，触发器使用的过程中，MySQL 会按照以下方式来处理错误。 对于事务性表，如果触发程序失败，以及由此导致的整个语句失败，那么该语句所执行的所有更改将回滚；对于非事务性表，则不能执行此类回滚，即使语句失败，失败之前所做的任何更改依然有效。 若 BEFORE 触发程序失败，则 MySQL 将不执行相应行上的操作。 若在 BEFORE 或 AFTER 触发程序的执行过程中出现错误，则将导致调用触发程序的整个语句失败。 仅当 BEFORE 触发程序和行操作均已被成功执行，MySQL 才会执行 AFTER 触发程序。","path":"posts/f9da.html","date":"06-15","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL创建存储过程","text":"一、MySQL创建存储过程 1、基本语法 可以使用 CREATE PROCEDURE 语句创建存储过程。 语法格式如下： 123CREATE PROCEDURE ( [过程参数[,…] ] ) [过程参数[,…] ] 格式[ IN | OUT | INOUT ] 2、语法说明如下： 1) 过程名 存储过程的名称，默认在当前数据库中创建。若需要在特定数据库中创建存储过程，则要在名称前面加上数据库的名称，即 db_name.sp_name。需要注意的是，名称应当尽量避免选取与 MySQL 内置函数相同的名称，否则会发生错误。 2) 过程参数 存储过程的参数列表。其中，&lt;参数名&gt;为参数名，&lt;类型&gt;为参数的类型（可以是任何有效的 MySQL 数据类型）。当有多个参数时，参数列表中彼此间用逗号分隔。存储过程可以没有参数（此时存储过程的名称后仍需加上一对括号），也可以有 1 个或多个参数。 MySQL 存储过程支持三种类型的参数，即输入参数、输出参数和输入/输出参数，分别用 IN、OUT 和 INOUT 三个关键字标识。其中，输入参数可以传递给一个存储过程，输出参数用于存储过程需要返回一个操作结果的情形，而输入/输出参数既可以充当输入参数也可以充当输出参数。 需要注意的是，参数的取名不要与数据表的列名相同，否则尽管不会返回出错信息，但是存储过程的 SQL 语句会将参数名看作列名，从而引发不可预知的结果。 3) 过程体 存储过程的主体部分，也称为存储过程体，包含在过程调用的时候必须执行的 SQL 语句。这个部分以关键字 BEGIN 开始，以关键字 END 结束。若存储过程体中只有一条 SQL 语句，则可以省略 BEGIN-END 标志。 在存储过程的创建中，经常会用到一个十分重要的 MySQL 命令，即 DELIMITER 命令，特别是对于通过命令行的方式来操作 MySQL 数据库的使用者，更是要学会使用该命令。 在 MySQL 中，服务器处理 SQL 语句默认是以分号作为语句结束标志的。然而，在创建存储过程时，存储过程体可能包含有多条 SQL 语句，这些 SQL 语句如果仍以分号作为语句结束符，那么 MySQL 服务器在处理时会以遇到的第一条 SQL 语句结尾处的分号作为整个程序的结束符，而不再去处理存储过程体中后面的 SQL 语句，这样显然不行。 为解决以上问题，通常使用 DELIMITER 命令将结束命令修改为其他字符。语法格式如下： 1DELIMITER $$ 语法说明如下： $$ 是用户定义的结束符，通常这个符号可以是一些特殊的符号，如两个“?”或两个“￥”等。 当使用 DELIMITER 命令时，应该避免使用反斜杠“\\”字符，因为它是 MySQL 的转义字符。 在 MySQL 命令行客户端输入如下 SQL 语句。 1mysql > DELIMITER ?? 成功执行这条 SQL 语句后，任何命令、语句或程序的结束标志就换为两个问号“??”了。 若希望换回默认的分号“;”作为结束标志，则在 MySQL 命令行客户端输入下列语句即可： 1mysql > DELIMITER ; 注意：DELIMITER 和分号“;”之间一定要有一个空格。在创建存储过程时，必须具有 CREATE ROUTINE 权限。可以使用 SHOW PROCEDURE STATUS 命令查看数据库中存在哪些存储过程，若要查看某个存储过程的具体信息，则可以使用 SHOW CREATE PROCEDURE &lt;存储过程名&gt;。 3、创建不带参数的存储过程 例 1 创建名称为 ShowStuScore 的存储过程，存储过程的作用是从学生成绩信息表中查询学生的成绩信息，输入的 SQL 语句和执行过程如下所示。 123456mysql&gt; DELIMITER //mysql&gt; CREATE PROCEDURE ShowStuScore() -&gt; BEGIN -&gt; SELECT * FROM tb_students_score; -&gt; END //Query OK， 0 rows affected (mysql&gt; DELIMITER //mysql&gt; CREATE PROCEDURE ShowStuScore() -&gt; BEGIN -&gt; SELECT * FROM tb_students_score; -&gt; END //Query OK， 0 rows affected (0.09 sec) 创建存储过程 ShowStuScore 后，通过 CALL 语句调用该存储过程的 SQL 语句和执行结果如下所示。 123456789101112131415161718mysql&gt; DELIMITER ;mysql&gt; CALL ShowStuScore();+--------------+---------------+| student_name | student_score |+--------------+---------------+| Dany | 90 || Green | 99 || Henry | 95 || Jane | 98 || Jim | 88 || John | 94 || Lily | 100 || Susan | 96 || Thomas | 93 || Tom |mysql&gt; DELIMITER ;mysql&gt; CALL ShowStuScore();+--------------+---------------+| student_name | student_score |+--------------+---------------+| Dany | 90 || Green | 99 || Henry | 95 || Jane | 98 || Jim | 88 || John | 94 || Lily | 100 || Susan | 96 || Thomas | 93 || Tom | 89 |+--------------+---------------+10 rows in set (0.00 sec)Query OK, 0 rows affected (0.02 sec) 例 2 12345678910# 创建存储过程delimiter $$create PROCEDURE test_bank()BEGINselect * from bank;END$$# 调用存储过程delimiter ;call test_bank(); 4、创建带参数的存储过程 例 3 创建名称为 GetScoreByStu 的存储过程，输入参数是学生姓名。存储过程的作用是通过输入的学生姓名从学生成绩信息表中查询指定学生的成绩信息，输入的 SQL 语句和执行过程如下所示。 12345678mysql> DELIMITER &#x2F;&#x2F;mysql> CREATE PROCEDURE GetScoreByStu -> (IN name VARCHAR(30)) -> BEGIN -> SELECT student_score FROM tb_students_score -> WHERE student_name&#x3D;name; -> END &#x2F;&#x2F;Query OK, 0 rows affected (0.01 sec) 创建存储过程 GetScoreByStu 后，通过 CALL 语句调用该存储过程，SQL 语句和执行结果如下所示。 123456789mysql> DELIMITER ;mysql> CALL GetScoreByStu('Green');+---------------+| student_score |+---------------+| 99 |+---------------+1 row in set (0.03 sec)Query OK, 0 rows affected (0.03 sec) 例 4 12345678910# 创建带参数的存储过程delimiter $$create PROCEDURE show_customer(in name VARCHAR(20))BEGINselect * from bank where cusName&#x3D;name;END $$#调用带参数的存储过程delimiter ;call show_customer('zs'); 二、存储过程的参数 MySQL存储过程的参数用在存储过程的定义，共有三种参数类型,IN,OUT,INOUT,形式如： 1CREATEPROCEDURE 存储过程名([[IN |OUT |INOUT ] 参数名 数据类形...]) IN 输入参数：表示调用者向过程传入值（传入值可以是字面量或变量） OUT 输出参数：表示过程向调用者传出值(可以返回多个值)（传出值只能是变量） INOUT 输入输出参数：既表示调用者向过程传入值，又表示过程向调用者传出值（值只能是变量） 1、in 输入参数 123456789101112# 存储过程的参数delimiter $$create PROCEDURE test(in p_in int)BEGIN SELECT p_in; set p_in &#x3D; 2; select p_in;END $$ delimiter ; set @p_in&#x3D;1;call in_param(@p_in); 1select @p_in; 以上可以看出，p_in 在存储过程中被修改，但并不影响 @p_id 的值，因为前者为局部变量、后者为全局变量。 2、out输出参数 1234567891011121314151617181920212223242526272829303132mysql> delimiter &#x2F;&#x2F;mysql> create procedure out_param(out p_out int) -> begin -> select p_out; -> set p_out&#x3D;2; -> select p_out; -> end -> &#x2F;&#x2F;mysql> delimiter ; mysql> set @p_out&#x3D;1; mysql> call out_param(@p_out);+-------+| p_out |+-------+| NULL |+-------+ #因为out是向调用者输出参数，不接收输入的参数，所以存储过程里的p_out为null+-------+| p_out |+-------+| 2 |+-------+ mysql> select @p_out;+--------+| @p_out |+--------+| 2 |+--------+ #调用了out_param存储过程，输出参数，改变了p_out变量的值 3、inout输入参数 1234567891011121314151617181920212223242526272829303132mysql> delimiter $$mysql> create procedure inout_param(inout p_inout int) -> begin -> select p_inout; -> set p_inout&#x3D;2; -> select p_inout; -> end -> $$mysql> delimiter ; mysql> set @p_inout&#x3D;1; mysql> call inout_param(@p_inout);+---------+| p_inout |+---------+| 1 |+---------+ +---------+| p_inout |+---------+| 2 |+---------+ mysql> select @p_inout;+----------+| @p_inout |+----------+| 2 |+----------+#调用了inout_param存储过程，接受了输入的参数，也输出参数，改变了变量 注意： 1、如果过程没有参数，也必须在过程名后面写上小括号例： 1CREATE PROCEDURE sp_name ([proc_parameter[,...]]) …… 2、确保参数的名字不等于列的名字，否则在过程体中，参数名被当做列名来处理 建议： 输入值使用in参数。 返回值使用out参数。 inout参数就尽量的少用。 三、MySQL删除存储过程（DROP PROCEDURE） 存储过程被创建后，就会一直保存在数据库服务器上，直至被删除。当 MySQL 数据库中存在废弃的存储过程时，我们需要将它从数据库中删除。 MySQL 中使用 DROP PROCEDURE 语句来删除数据库中已经存在的存储过程。语法格式如下： 1DROP &#123; PROCEDURE | FUNCTION &#125; [ IF EXISTS ] 语法说明如下： 过程名：指定要删除的存储过程的名称。 IF EXISTS：指定这个关键字，用于防止因删除不存在的存储过程而引发的错误。 注意：存储过程名称后面没有参数列表，也没有括号，在删除之前，必须确认该存储过程没有任何依赖关系，否则会导致其他与之关联的存储过程无法运行。 实例 1 下面删除存储过程 showstuscore，SQL 语句和运行结果如下： 12mysql&gt; DROP PROCEDURE test;Query OK, 0 rows affected (mysql&gt; DROP PROCEDURE test;Query OK, 0 rows affected (0.08 sec) 删除后，可以通过查询 information_schema 数据库下的 routines 表来确认上面的删除是否成功。SQL 语句和运行结果如下： 12mysql&gt; SELECT * FROM information_schema.routines WHERE routine_name='showstuscore';Empty set (mysql&gt; SELECT * FROM information_schema.routines WHERE routine_name='showstuscore';Empty set (0.03 sec) 结果显示，没有查询出任何记录，说明存储过程 showstuscore 已经被删除了。","path":"posts/bc0b.html","date":"06-14","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL存储过程","text":"A：MySQL存储过程简介 我们前面所学习的 MySQL 语句都是针对一个表或几个表的单条 SQL 语句，但是在数据库的实际操作中，经常会有需要多条 SQL 语句处理多个表才能完成的操作。 例如，为了确认学生能否毕业，需要同时查询学生档案表、成绩表和综合表，此时就需要使用多条 SQL 语句来针对这几个数据表完成处理要求。 存储过程是一组为了完成特定功能的 SQL 语句集合。使用存储过程的目的是将常用或复杂的工作预先用 SQL 语句写好并用一个指定名称存储起来，这个过程经编译和优化后存储在数据库服务器中，因此称为存储过程。当以后需要数据库提供与已定义好的存储过程的功能相同的服务时，只需调用“CALL存储过程名字”即可自动完成。 常用操作数据库的 SQL 语句在执行的时候需要先编译，然后执行。存储过程则采用另一种方式来执行 SQL 语句。 一个存储过程是一个可编程的函数，它在数据库中创建并保存，一般由 SQL 语句和一些特殊的控制结构组成。当希望在不同的应用程序或平台上执行相同的特定功能时，存储过程尤为合适。 MySQL 5.0 版本以前并不支持存储过程，这使 MySQL 在应用上大打折扣。MySQL 从 5.0 版本开始支持存储过程，既提高了数据库的处理速度，同时也提高了数据库编程的灵活性 存储过程是数据库中的一个重要功能，存储过程可以用来转换数据、数据迁移、制作报表，它类似于编程语言，一次执行成功，就可以随时被调用，完成指定的功能操作。 使用存储过程不仅可以提高数据库的访问效率，同时也可以提高数据库使用的安全性。 对于调用者来说，存储过程封装了 SQL 语句，调用者无需考虑逻辑功能的具体实现过程。只是简单调用即可，它可以被 Java 和 C# 等编程语言调用。 B：存储过程有如下优点： 1) 封装性 通常完成一个逻辑功能需要多条 SQL 语句，而且各个语句之间很可能传递参数，所以，编写逻辑功能相对来说稍微复杂些，而存储过程可以把这些 SQL 语句包含到一个独立的单元中，使外界看不到复杂的 SQL 语句，只需要简单调用即可达到目的。并且数据库专业人员可以随时对存储过程进行修改，而不会影响到调用它的应用程序源代码。 2) 可增强 SQL 语句的功能和灵活性 存储过程可以用流程控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。 3) 可减少网络流量 由于存储过程是在服务器端运行的，且执行速度快，因此当客户计算机上调用该存储过程时，网络中传送的只是该调用语句，从而可降低网络负载。 4) 高性能 当存储过程被成功编译后，就存储在数据库服务器里了，以后客户端可以直接调用，这样所有的 SQL 语句将从服务器执行，从而提高性能。但需要说明的是，存储过程不是越多越好，过多的使用存储过程反而影响系统性能。 5) 提高数据库的安全性和数据的完整性 存储过程提高安全性的一个方案就是把它作为中间组件，存储过程里可以对某些表做相关操作，然后存储过程作为接口提供给外部程序。这样，外部程序无法直接操作数据库表，只能通过存储过程来操作对应的表，因此在一定程度上，安全性是可以得到提高的。 6) 使数据独立 数据的独立可以达到解耦的效果，也就是说，程序可以调用存储过程，来替代执行多条的 SQL 语句。这种情况下，存储过程把数据同用户隔离开来，优点就是当数据表的结构改变时，调用表不用修改程序，只需要数据库管理者重新编写存储过程即可。 C：MySQL存储过程的优点 通常存储过程有助于提高应用程序的性能。当创建，存储过程被编译之后，就存储在数据库中。 但是，MySQL实现的存储过程略有不同。 MySQL存储过程按需编译。 在编译存储过程之后，MySQL将其放入缓存中。 MySQL为每个连接维护自己的存储过程高速缓存。 如果应用程序在单个连接中多次使用存储过程，则使用编译版本，否则存储过程的工作方式类似于查询。 存储过程有助于减少应用程序和数据库服务器之间的流量，因为应用程序不必发送多个冗长的SQL语句，而只能发送存储过程的名称和参数。 存储的程序对任何应用程序都是可重用的和透明的。 存储过程将数据库接口暴露给所有应用程序，以便开发人员不必开发存储过程中已支持的功能。 存储的程序是安全的。 数据库管理员可以向访问数据库中存储过程的应用程序授予适当的权限，而不向基础数据库表提供任何权限。 D：MySQL存储过程的缺点 如果使用大量存储过程，那么使用这些存储过程的每个连接的内存使用量将会大大增加。 此外，如果您在存储过程中过度使用大量逻辑操作，则CPU使用率也会增加，因为数据库服务器的设计不当于逻辑运算。 存储过程的构造使得开发具有复杂业务逻辑的存储过程变得更加困难。 很难调试存储过程。只有少数数据库管理系统允许您调试存储过程。不幸的是，MySQL不提供调试存储过程的功能。 开发和维护存储过程并不容易。开发和维护存储过程通常需要一个不是所有应用程序开发人员拥有的专业技能。这可能会导致应用程序开发和维护阶段的问题。","path":"posts/ae29.html","date":"06-13","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL用户管理（2）","text":"一、MySQL root修改普通用户密码 1、使用SET语句修改普通用户的密码 在 MySQL 中，只有 root 用户可以通过更新 MySQL 数据库来更改密码。使用 root 用户登录到 MySQL 服务器后，可以使用 SET 语句来修改普通用户密码。语法格式如下： 1SET PASSWORD FOR 'username'@'hostname' &#x3D; PASSWORD ('newpwd'); 其中，username 参数是普通用户的用户名，hostname 参数是普通用户的主机名，newpwd 是要更改的新密码。 注意：新密码必须使用 PASSWORD() 函数来加密，如果不使用 PASSWORD() 加密，也会执行成功，但是用户会无法登录。 如果是普通用户修改密码，可省略 FOR 子句来更改自己的密码。语法格式如下： 1SET PASSWORD &#x3D; PASSWORD('newpwd'); 示例 1 首先创建一个没有密码的 testuser 用户，SQL 语句和运行结果如下： 12mysql> CREATE USER 'testuser'@'localhost';Query OK, 0 rows affected (0.14 sec) root 用户登录 MySQL 服务器后，再使用 SET 语句将 testuser 用户的密码修改为“newpwd”，SQL 语句和运行结果如下： 12mysql> SET PASSWORD FOR 'testuser'@'localhost' &#x3D; PASSWORD(\"newpwd\");Query OK, 0 rows affected, 1 warning (0.01 sec) 由运行结果可以看出，SET 语句执行成功，testuser 用户的密码被成功设置为“newpwd”。 下面验证 testuser 用户密码是否修改成功。退出 MySQL 服务器，使用 testuser 用户登录，输入密码“newpwd”，SQL 语句和运行结果如下： 12345678910111213C:\\Users\\leovo>mysql -utestuser -pEnter password: ******Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 15Server version: 5.7.29-log MySQL Community Server (GPL) Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. 由运行结果可以看出，testuser 用户登录成功，修改密码成功。 示例 2 使用 testuser 用户登录 MySQL 服务器，再使用 SET 语句将密码更改为“newpwd1”，SQL 语句和运行结果如下所示： 12mysql> SET PASSWORD &#x3D; PASSWORD('newpwd1');Query OK, 0 rows affected, 1 warning (0.00 sec) 由运行结果可以看出，修改密码成功。 2、使用UPDATE语句修改普通用户的密码 使用 root 用户登录 MySQL 服务器后，可以使用 UPDATE 语句修改 MySQL 数据库的 user 表的 authentication_string 字段，从而修改普通用户的密码。UPDATA 语句的语法如下： 1UPDATE MySQL.user SET authentication_string &#x3D; PASSWORD(\"newpwd\") WHERE User &#x3D; \"username\" AND Host &#x3D; \"hostname\"; 其中，username 参数是普通用户的用户名，hostname 参数是普通用户的主机名，newpwd 是要更改的新密码。 注意，执行 UPDATE 语句后，需要执行 FLUSH PRIVILEGES 语句重新加载用户权限。 示例 3 使用 root 用户登录 MySQL 服务器，再使用 UPDATE 语句将 testuser 用户的密码修改为“newpwd2”的 SQL 语句和运行结果如下： 123456mysql> UPDATE MySQL.user SET authentication_string &#x3D; PASSWORD (\"newpwd2\") -> WHERE User &#x3D; \"testuser\" AND Host &#x3D; \"localhost\";Query OK, 1 row affected, 1 warning (0.07 sec)Rows matched: 1 Changed: 1 Warnings: 1mysql> FLUSH PRIVILEGES;Query OK, 0 rows affected (0.03 sec) 由运行结果可以看出，密码修改成功。testuser 的密码被修改成了 newpwd2。使用 FLUSH PRIVILEGES 重新加载权限后，就可以使用新的密码登录 testuser 用户了。 3、使用 GRANT 语句修改普通用户密码 除了前面介绍的方法，还可以在全局级别使用 GRANT USAGE 语句指定某个账户的密码而不影响账户当前的权限。需要注意的是，使用 GRANT 语句修改密码，必须拥有 GRANT 权限。一般情况下最好使用该方法来指定或修改密码。语法格式如下： 1GRANT USAGE ON *.* TO 'user'@’hostname’ IDENTIFIED BY 'newpwd'; 其中，username 参数是普通用户的用户名，hostname 参数是普通用户的主机名，newpwd 是要更改的新密码。 示例 4 使用 root 用户登录 MySQL 服务器，再使用 GRANT 语句将 testuser 用户的密码修改为“newpwd3”，SQL 语句和运行结果如下： 12mysql> GRANT USAGE ON *.* TO 'testuser'@'localhost' IDENTIFIED BY 'newpwd3';Query OK, 0 rows affected, 1 warning (0.05 sec) 由运行结果可以看出，密码修改成功。 二、MySQL修改root密码 1、使用mysqladmin命令在命令行指定新密码 root 用户可以使用 mysqladmin 命令来修改密码，mysqladmin 的语法格式如下： 1mysqladmin -u username -h hostname -p password \"newpwd\" 语法参数说明如下： usermame 指需要修改密码的用户名称，在这里指定为 root 用户； hostname 指需要修改密码的用户主机名，该参数可以不写，默认是 localhost； password 为关键字，而不是指旧密码； newpwd 为新设置的密码，必须用双引号括起来。如果使用单引号会引发错误，可能会造成修改后的密码不是你想要的。 执行完上面的语句，root 用户的密码将被修改为“newpwd”。 示例 1 下面使用 mysqladmin 将 root 用户的密码修改为“rootpwd”，在 Windows 命令行窗口（cmd）中执行命令和运行结果如下： 1234C:\\Users\\leovo>mysqladmin -u root -p password \"rootpwd\"Enter password: ****mysqladmin: [Warning] Using a password on the command line interface can be insecure.Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety. 输入 mysqladmin 命令后，按回车键，然后输入 root 用户原来的密码。执行完毕后，密码修改成功，root 用户登录时将使用新的密码。 运行结果中，输入密码后会提示在命令行界面上使用密码可能不安全的警告信息，因为在命令行输入密码时，MySQL 服务器就会提示这些安全警告信息。 下面使用修改后的“rootpwd”密码登录 root 用户，SQL 语句和运行结果如下： 12345678910111213C:\\Users\\leovo>mysql -uroot -pEnter password: *******Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 23Server version: 5.7.29-log MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. 结果显示，root 用户登录成功，所以使用 mysqladmin 命令修改 root 用户密码成功。 2、修改MySQL数据库的user表 因为所有账户信息都保存在 user 表中，因此可以直接通过修改 user 表来改变 root 用户的密码。 root 用户登录到 MySQL 服务器后，可以使用 UPDATE 语句修改 MySQL 数据库的 user 表的 authentication_string 字段，从而修改用户的密码。 使用 UPDATA 语句修改 root 用户密码的语法格式如下： 1UPDATE mysql.user set authentication_string &#x3D; PASSWORD (\"rootpwd) WHERE User &#x3D; \"root\" and Host&#x3D;\"localhost\"; 新密码必须使用 PASSWORD() 函数来加密。执行UPDATE语句后，需要执行FLUSH PRIVILEGES语句重新加载用户权限。 示例 2 下面使用 UPDATE 语句将 root用户的密码修改为“rootpwd2”。 使用 root 用户登录到 MySQL 服务器后，SQL 语句和运行结果如下所示： 123456mysql> UPDATE mysql.user set authentication_string &#x3D; password (\"rootpwd2\") -> WHERE User &#x3D; \"root\" and Host &#x3D; \"localhost\";Query OK, 1 row affected, 0 warning (0.00 sec)Rows matched: 1 Changed: 1 Warnings:0mysql> FLUSH PRIVILEGES;Query OK, 0 rows affected (0.06 sec) 结果显示，密码修改成功。而且使用了FLUSH PRIVILEGES;语句加载权限。退出后就必须使用新密码来登录了。 3、使用SET语句修改root用户的密码 SET PASSWORD 语句可以用来重新设置其他用户的登录密码或者自己使用的账户的密码。使用 SET 语句修改密码的语法结构如下： 1SET PASSWORD &#x3D; PASSWORD (\"rootpwd\"); 示例 3 下面使用 SET 语句将 root 用户的密码修改为“rootpwd3”。 使用 root 用户登录到 MySQL 服务器后，SQL 语句和运行结果如下所示： 12MySQL> SET PASSWORD &#x3D; password (\"rootpwd3\");Query OK, 0 rows affected (0.00 sec) 结果显示，SET 语句执行成功，root 用户的密码被成功设置为“rootpwd3”。 三、MySQL忘记root密码解决方案 在忘记 MySQL 密码的情况下，可以通过 --skip-grant-tables 关闭服务器的认证，然后重置 root 的密码，具体操作步骤如下。 步骤 1)：关闭正在运行的 MySQL 服务。打开 cmd 进入 MySQL 的 bin 目录。 步骤 2)：输入mysqld --console --skip-grant-tables --shared-memory 命令。–skip-grant-tables 会让 MySQL 服务器跳过验证步骤，允许所有用户以匿名的方式，无需做密码验证就可以直接登录 MySQL 服务器，并且拥有所有的操作权限。 步骤 3)：上一个 DOS 窗口不要关闭，打开一个新的 DOS 窗口，此时仅输入 mysql 命令，不需要用户名和密码，即可连接到 MySQL。 步骤 4)：输入命令 update mysql.user set authentication_string=password('root') where user='root' and Host ='localhost'; 设置新密码。 注意：MySQL 5.7 版本中的 user 表里已经去掉了 password 字段，改为了 authentication_string。 步骤 5)：刷新权限（必须步骤），输入flush privileges;命令。 步骤 6)：因为之前使用 --skip-grant-tables 启动，所以需要重启 MySQL 服务器去掉 --skip-grant-tables。输入无误后输入quit;命令退出 MySQL 服务。 步骤 7)：重启 MySQL 服务，使用用户名 root 和刚才设置的新密码 root 登录就可以了。 四、MySQL修改密码的3种方式 1. 使用 SET PASSWORD 命令 步骤 1)：输入命令mysql -u root -p指定 root 用户登录 MySQL，输入后按回车键输入密码。如果没有配置环境变量，请在 MySQL 的 bin 目录下登录操作。 步骤 2)：使用 SET PASSWORD 修改密码命令格式为 set password for username @localhost = password(newpwd);，其中 username 为要修改密码的用户名，newpwd 为要修改的新密码。如图所示。 步骤 3)：输入quit;命令退出 MySQL 重新登录，输入新密码“root”登录就可以了； 2. 使用mysqladmin修改密码 使用 mysqladmin 命令修改 MySQL 的 root 用户密码格式为 mysqladmin -u用户名 -p旧密码 password 新密码。 注意：下图修改密码的命令中 -uroot 和 -proot 是整体，不要写成 -u root -p root，-u 和 root 间可以加空格，但是会有警告出现，所以就不要加空格了。 3. UPDATE直接编辑user表 步骤 1)：输入命令mysql -u root -p指定 root 用户登录 MySQL，输入后按回车键输入密码。如果没有配置环境变量，请在 MySQL 的 bin 目录下登录操作。 步骤 2)：输入use mysql;命令连接权限数据库。 步骤 3)：输入命令update mysql.user set authentication_string=password('新密码') where user='用户名' and Host ='localhost';设置新密码。 步骤 4)：输入 flush privileges; 命令刷新权限。 步骤 5)：输入quit;命令退出 MySQL 重新登录，此时密码已经修改为刚才输入的新密码了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#创建数据库DROP DATABASE IF EXISTS &#96;bankDB&#96;;CREATE DATABASE &#96;bankDB&#96;;USE &#96;bankDB&#96;;DROP TABLE IF EXISTS &#96;userInfo&#96;;CREATE TABLE &#96;userInfo&#96; #用户信息表( &#96;customerID&#96; INT(4) PRIMARY KEY AUTO_INCREMENT COMMENT '用户编号', &#96;customerName&#96; CHAR(8) NOT NULL COMMENT '用户编号', &#96;PID&#96; CHAR(18) UNIQUE NOT NULL COMMENT '身份证号', &#96;telephone&#96; CHAR(20) NOT NULL COMMENT '手机号码', &#96;address&#96; VARCHAR(50) COMMENT '居住地址')ENGINE &#x3D; INNODB,CHARSET&#x3D;UTF8,COMMENT&#x3D;'用户表';DROP TABLE IF EXISTS &#96;cardInfo&#96;;CREATE TABLE &#96;cardInfo&#96; #银行卡信息表( &#96;cardID&#96; CHAR(19) NOT NULL PRIMARY KEY COMMENT '卡号', &#96;password&#96; CHAR(6) NOT NULL DEFAULT '888888' COMMENT '密码', &#96;curID&#96; VARCHAR(10) NOT NULL DEFAULT 'RMB' COMMENT '币种', &#96;savingID&#96; INT NOT NULL COMMENT '存款类型', &#96;openDate&#96; TIMESTAMP NOT NULL COMMENT '开户日期' , &#96;openMoney&#96; DECIMAL(20,2) NOT NULL DEFAULT 1 COMMENT '开户金额' , &#96;balance&#96; DECIMAL(20,2) NOT NULL DEFAULT 1 COMMENT '余额', &#96;IsReportLoss&#96; BIT NOT NULL DEFAULT 0 COMMENT '是否挂失', &#96;customerID&#96; INT NOT NULL) ENGINE &#x3D; INNODB,CHARSET&#x3D;UTF8,COMMENT&#x3D;'银行卡信息表';DROP TABLE IF EXISTS &#96;tradeInfo&#96;;CREATE TABLE &#96;tradeInfo&#96; #交易信息表( cardID CHAR(16) NOT NULL COMMENT '卡号', tradeDate TIMESTAMP NOT NULL COMMENT '交易日期', tradeMoney DECIMAL(20,2) NOT NULL COMMENT '实际交易金额', tradeType CHAR(4) NOT NULL COMMENT '交易类型', remark TEXT COMMENT '备注' )ENGINE &#x3D; INNODB,CHARSET&#x3D;UTF8,COMMENT&#x3D;'交易信息表';DROP TABLE IF EXISTS &#96;deposit&#96;;CREATE TABLE &#96;deposit&#96; #存款类型表( savingID INT(4) AUTO_INCREMENT PRIMARY KEY, savingName VARCHAR(20) NOT NULL, descrip VARCHAR(50))ENGINE &#x3D; INNODB,CHARSET&#x3D;UTF8,COMMENT&#x3D;'存款类型表';&#x2F;*--加约束--$*&#x2F;ALTER TABLE cardInfo ADD CONSTRAINT FK_customerID FOREIGN KEY(customerID) REFERENCES userInfo(customerID), ADD CONSTRAINT FK_savingID FOREIGN KEY(savingID) REFERENCES deposit(savingID);ALTER TABLE tradeInfo ADD CONSTRAINT FK_cardID FOREIGN KEY(cardID) REFERENCES cardInfo(cardID);","path":"posts/66c1.html","date":"06-12","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL用户管理（1）","text":"A：补充技能点 MySQL用户管理 创建普通用户 执行GRANT语句创建用户并授权 使用mysqladmin命令修改root账户密码 使用SET命令修改用户密码 删除普通用户 MySQL 在安装时会自动创建一个名为 mysql 的数据库，mysql 数据库中存储的都是用户权限表。用户登录以后，MySQL 会根据这些权限表的内容为每个用户赋予相应的权限。 user 表是 MySQL 中最重要的一个权限表，用来记录允许连接到服务器的账号信息。需要注意的是，在 user 表里启用的所有权限都是全局级的，适用于所有数据库。 user 表中的字段大致可以分为 4 类，分别是用户列、权限列、安全列和资源控制列。 B：为什么需要用户管理 root是超级管理员用户，很容易引发由于误操作所导致的数据不安全问题，怎么办? 针对不同用户进行合理的用户角色权限分配，即用户管理 一、MySQL创建用户（3种方式） MySQL 提供了以下 3 种方法创建用户。 使用 CREATE USER 语句创建用户 在 mysql.user 表中添加用户 使用 GRANT 语句创建用户 1. 使用CREATE USER语句创建用户 可以使用 CREATE USER 语句来创建 MySQL 用户，并设置相应的密码。其基本语法格式如下： 1CREATE USER [ IDENTIFIED BY [ PASSWORD ] 'password' ] [ ,用户 [ IDENTIFIED BY [ PASSWORD ] 'password' ]] 例1 1234567# 创建普通用户create user &#96;teacher&#96;@&#96;localhost&#96; IDENTIFIED BY '123456';create user &#96;student&#96;@&#96;localhost&#96;# 查看用户use mysql;select host,user from user; 例2 在 MySQL 中，可以使用 password() 函数获取密码的哈希值，查看 test1 哈希值的 SQL 语句和执行过程如下： 1234567mysql> SELECT password('teacher');+-------------------------------------------+| password('teacher') |+-------------------------------------------+| *977F15BF49C046DA76BC81A80146AAB943F679F1 |+-------------------------------------------+1 row in set, 1 warning (0.00 sec) *“977F15BF49C046DA76BC81A80146AAB943F679F1”就是 test1 的哈希值。下面创建用户 test1，SQL 语句和执行过程如下： 12mysql> CREATE USER 'text1'@'localhost'IDENTIFIED BY PASSWORD '*977F15BF49C046DA76BC81A80146AAB943F679F1';Query OK, 0 rows affected, 1 warning (0.00 sec) 执行成功后就可以使用密码“test1”登录了。 2. 使用 INSERT 语句新建用户 可以使用 INSERT 语句将用户的信息添加到 mysql.user 表中，但必须拥有对 mysql.user 表的 INSERT 权限。通常 INSERT 语句只添加 Host、User 和 authentication_string 这 3 个字段的值。 MySQL 5.7 的 user 表中的密码字段从 Password 变成了 authentication_string，如果你使用的是 MySQL 5.7 之前的版本，将 authentication_string 字段替换成 Password 即可。 使用 INSERT 语句创建用户的代码如下： 1INSERT INTO mysql.user(Host, User, authentication_string, ssl_cipher, x509_issuer, x509_subject) VALUES ('hostname', 'username', PASSWORD('password'), '', '', ''); 由于 mysql 数据库的 user 表中，ssl_cipher、x509_issuer 和 x509_subject 这 3 个字段没有默认值，所以向 user 表插入新记录时，一定要设置这 3 个字段的值，否则 INSERT 语句将不能执行。 例 3 下面使用 INSERT 语句创建名为 test2 的用户，主机名是 localhost，密码也是 test2。SQL 语句和执行过程如下： 12mysql> INSERT INTO mysql.user(Host, User, authentication_string, ssl_cipher, x509_issuer, x509_subject) VALUES ('localhost', 'test2', PASSWORD('test2'), '', '', '');Query OK, 1 row affected, 1 warning (0.02 sec) 结果显示，新建用户成功。但是这时如果通过该账户登录 MySQL 服务器，不会登录成功，因为 test2 用户还没有生效。 可以使用 FLUSH 命令让用户生效，命令如下： 1FLUSH PRIVILEGES; 使用以上命令可以让 MySQL 刷新系统权限相关表。执行 FLUSH 命令需要 RELOAD 权限。 注意：user 表中的 User 和 Host 字段区分大小写，创建用户时要指定正确的用户名称或主机名。 3. 使用GRANT语句新建用户 虽然 CREATE USER 和 INSERT INTO 语句都可以创建普通用户，但是这两种方式不便授予用户权限。于是 MySQL 提供了 GRANT 语句。 使用 GRANT 语句创建用户的基本语法形式如下: 1GRANT priv_type ON database.table TO user [IDENTIFIED BY [PASSWORD] 'password'] 其中： priv_type 参数表示新用户的权限； database.table 参数表示新用户的权限范围，即只能在指定的数据库和表上使用自己的权限； user 参数指定新用户的账号，由用户名和主机名构成； IDENTIFIED BY 关键字用来设置密码； password 参数表示新用户的密码。 例 4 下面使用 GRANT 语句创建名为 test3 的用户，主机名为 localhost，密码为 test3。该用户对所有数据库的所有表都有 SELECT 权限。SQL 语句和执行过程如下： 12mysql> GRANT SELECT ON*.* TO 'test3'@localhost IDENTIFIED BY 'test3';Query OK, 0 rows affected, 1 warning (0.01 sec) 其中，“.” 表示所有数据库下的所有表。结果显示创建用户成功，且 test3 用户对所有表都有查询（SELECT）权限。 技巧：GRANT 语句是 MySQL 中一个非常重要的语句，它可以用来创建用户、修改用户密码和设置用户权限。教程后面会详细介绍如何使用 GRANT 语句修改密码、更改权限。 二、MySQL修改用户（RENAME USER） 在 MySQL中，我们可以使用 RENAME USER 语句修改一个或多个已经存在的用户账号。 语法格式如下： 1RENAME USER TO 其中： &lt;旧用户&gt;：系统中已经存在的 MySQL 用户账号。 &lt;新用户&gt;：新的 MySQL 用户账号。 使用 RENAME USER 语句时应注意以下几点： RENAME USER 语句用于对原有的 MySQL 用户进行重命名。 若系统中旧账户不存在或者新账户已存在，该语句执行时会出现错误。 使用 RENAME USER 语句，必须拥有 mysql 数据库的 UPDATE 权限或全局 CREATE USER 权限。 例 1 使用 RENAME USER 语句将用户名 test1 修改为 testUser1，主机是 localhost。SQL 语句和执行过程如下。 123mysql> RENAME USER 'test1'@'localhost' -> TO 'testUser1'@'localhost';Query OK, 0 rows affected (0.03 sec) 在 cmd 命令行工具中，使用 testUser1 用户登录数据库服务器，如下所示。 12345678910C:\\Users\\USER>mysql -h localhost -u testUser1 -pEnter password: *****Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 7Server version: 5.7.20-log MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. 三、MySQL删除用户（DROP/DELETE USER） 在 MySQL 数据库中，可以使用 DROP USER 语句删除用户，也可以直接在 mysql.user 表中删除用户以及相关权限。 1. 使用 DROP USER 语句删除普通用户 使用 DROP USER 语句删除用户的语法格式如下： 1DROP USER [ , ]… 其中，用户用来指定需要删除的用户账号。 使用 DROP USER 语句应注意以下几点： DROP USER 语句可用于删除一个或多个用户，并撤销其权限。 使用 DROP USER 语句必须拥有 mysql 数据库的 DELETE 权限或全局 CREATE USER 权限。 在 DROP USER 语句的使用中，若没有明确地给出账户的主机名，则该主机名默认为“%”。 注意：用户的删除不会影响他们之前所创建的表、索引或其他数据库对象，因为 MySQL 并不会记录是谁创建了这些对象。 例 1 下面使用 DROP USER 语句删除用户’test1@‘localhost’。SQL 语句和执行过程如下。 12mysql> DROP USER 'test1'@'localhost';Query OK, 0 rows affected (0.00 sec) 在 cmd 命令行工具中，使用 test1 用户登录数据库服务器，发现登录失败，说明用户已经删除，如下所示。 123C:\\Users\\USER>mysql -h localhost -u test1 -pEnter password: ****ERROR 1045 (28000): Access denied for user 'test'@'localhost' (using password: YES) 2. 使用DELETE语句删除普通用户 可以使用 DELETE 语句直接删除 mysql.user 表中相应的用户信息，但必须拥有 mysql.user 表的 DELETE 权限。其基本语法格式如下： 1DELETE FROM mysql.user WHERE Host&#x3D;'hostname' AND User&#x3D;'username'; Host 和 User 这两个字段都是 mysql.user 表的主键。因此，需要两个字段的值才能确定一条记录。 例 2 下面使用 DELETE 语句删除用户’test2’@‘localhost’。SQL 语句和执行过程如下所示。 12DELETE FROM mysql.user WHERE Host&#x3D;'localhost'AND User&#x3D;'test2';Query OK, 1 rows affected (0.00 sec) 结果显示删除成功。可以使用 SELETE 语句查询 mysql.user 表，以确定该用户是否已经成功删除。 四、MySQL查看用户权限 在 MySQL 中，可以通过查看 mysql.user 表中的数据记录来查看相应的用户权限，也可以使用 SHOW GRANTS 语句查询用户的权限。 mysql 数据库下的 user 表中存储着用户的基本权限，可以使用 SELECT 语句来查看。SELECT 语句的代码如下： 1SELECT * FROM mysql.user; 要执行该语句，必须拥有对 user 表的查询权限。 注意：新创建的用户只有登录 MySQL 服务器的权限，没有任何其它权限，不能查询 user 表。 除了使用 SELECT 语句之外，还可以使用 SHOW GRANTS FOR 语句查看权限。其语法格式如下： 1SHOW GRANTS FOR 'username'@'hostname'; 其中，username 表示用户名，hostname 表示主机名或主机 IP。 例 1 下面创建 testuser1 用户并查询权限，SQL 语句和执行过程如下： 12345678910mysql> CREATE USER 'testuser1'@'localhost';Query OK, 0 rows affected (0.00 sec)mysql> SHOW GRANTS FOR 'testuser1'@'localhost';+-----------------------------------------------+| Grants for testuser1@localhost |+-----------------------------------------------+| GRANT USAGE ON *.* TO 'testuser1'@'localhost' |+-----------------------------------------------+1 row in set (0.00 sec) 其中，USAGE ON *.*表示该用户对任何数据库和任何表都没有权限。 例 2 下面查询 root 用户的权限，代码如下： 12345678mysql> SHOW GRANTS FOR 'root'@'localhost';+---------------------------------------------------------------------+| Grants for root@localhost |+---------------------------------------------------------------------+| GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION || GRANT PROXY ON ''@'' TO 'root'@'localhost' WITH GRANT OPTION |+---------------------------------------------------------------------+2 rows in set (0.00 sec) 五、MySQL GRANT：用户授权 授权就是为某个用户赋予某些权限。例如，可以为新建的用户赋予查询所有数据库和表的权限。MySQL 提供了 GRANT 语句来为用户设置权限。 在 MySQL 中，拥有 GRANT 权限的用户才可以执行 GRANT 语句，其语法格式如下： 1234GRANT priv_type [(column_list)] ON database.tableTO user [IDENTIFIED BY [PASSWORD] 'password'][, user[IDENTIFIED BY [PASSWORD] 'password']] ...[WITH with_option [with_option]...] 1、权限类型说明 1）授予数据库权限时，&lt;权限类型&gt;可以指定为以下值： ![image-20200614164858090](G:\\四期\\数据库\\mysql文档\\11 MySQL 事务（2）.assets\\image-20200614164858090.png) 2) 授予表权限时，&lt;权限类型&gt;可以指定为以下值： ![image-20200614164921901](G:\\四期\\数据库\\mysql文档\\11 MySQL 事务（2）.assets\\image-20200614164921901.png) 3) 授予列权限时，&lt;权限类型&gt;的值只能指定为 SELECT、INSERT 和 UPDATE，同时权限的后面需要加上列名列表 column-list。 4) 最有效率的权限是用户权限。 授予用户权限时，&lt;权限类型&gt;除了可以指定为授予数据库权限时的所有值之外，还可以是下面这些值： CREATE USER：表示授予用户可以创建和删除新用户的权限。 SHOW DATABASES：表示授予用户可以使用 SHOW DATABASES 语句查看所有已有的数据库的定义的权限。 例 1 使用 GRANT 语句创建一个新的用户 testUser，密码为 testPwd。用户 testUser 对所有的数据有查询、插入权限，并授予 GRANT 权限。SQL 语句和执行过程如下。 12345mysql> GRANT SELECT,INSERT ON *.* -> TO 'testUser'@'localhost' -> IDENTIFIED BY 'testPwd' -> WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.05 sec) 使用 SHOW GRANTS 语句查询用户 testUser 的权限，如下所示。 1234567mysql> SHOW GRANTS FOR 'testUser'@'localhost';+-------------------------------------------------------------------------+| Grants for testUser@localhost |+-------------------------------------------------------------------------+| GRANT SELECT, INSERT ON *.* TO 'testUser'@'localhost' WITH GRANT OPTION |+-------------------------------------------------------------------------+1 row in set (0.00 sec) 结果显示，testUser 对所有数据库的所有表有查询、插入权限，并可以将这些权限赋予给别的用户。 六、MySQL REVOKE：删除用户权限 在 MySQL 中，可以使用 REVOKE 语句删除某个用户的某些权限（此用户不会被删除），在一定程度上可以保证系统的安全性。例如，如果数据库管理员觉得某个用户不应该拥有 DELETE 权限，那么就可以删除 DELETE 权限。 使用 REVOKE 语句删除权限的语法格式有两种形式，如下所示： 1）第一种 删除用户某些特定的权限，语法格式如下： 123REVOKE priv_type [(column_list)]...ON database.tableFROM user [, user]... REVOKE 语句中的参数与 GRANT 语句的参数意思相同。其中： priv_type 参数表示权限的类型； column_list 参数表示权限作用于哪些列上，没有该参数时作用于整个表上； user 参数由用户名和主机名构成，格式为“username’@‘hostname’”。 2）第二种 删除特定用户的所有权限，语法格式如下： 1REVOKE ALL PRIVILEGES, GRANT OPTION FROM user [, user] ... 删除用户权限需要注意以下几点： REVOKE 语法和 GRANT 语句的语法格式相似，但具有相反的效果。 要使用 REVOKE 语句，必须拥有 MySQL 数据库的全局 CREATE USER 权限或 UPDATE 权限。 例 1 使用 REVOKE 语句取消用户 testUser 的插入权限，SQL 语句和执行过程如下。 1234567891011mysql> REVOKE INSERT ON *.* -> FROM 'testUser'@'localhost';Query OK, 0 rows affected (0.01 sec)mysql> SHOW GRANTS FOR 'testUser'@'localhost';+-----------------------------------------------------------------+| Grants for testUser@localhost |+-----------------------------------------------------------------+| GRANT SELECT ON *.* TO 'testUser'@'localhost' WITH GRANT OPTION |+-----------------------------------------------------------------+1 row in set (0.00 sec) 结果显示，删除 testUser 用户的 INSERT 权限成功。 创建用户并授权 GRANT语句可实现创建用户同时授权或为已存在的用户授权 ![image-20200612151755831](G:\\四期\\数据库\\mysql文档\\11 MySQL用户管理（1）.assets\\image-20200612151755831.png) 12345# 给用户授权grant insert,select on myschool.studentto &#96;xgp&#96;@&#96;localhost&#96; IDENTIFIED by '123456';grant select on myschool.student to &#96;student&#96;@&#96;localhost&#96;; 12use myschool;delete from student; 1234C:\\WINDOWS\\system32&gt;mysqladmin -u xgp -p password \"1111\"Enter password: ******mysqladmin: [Warning] Using a password on the command line interface can be insecure.Warning: Since password will be sent to server in plain text, use ssl connection to ensure password C:\\WINDOWS\\system32&gt;mysqladmin -u xgp -p password \"1111\"Enter password: ******mysqladmin: [Warning] Using a password on the command line interface can be insecure.Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety. ![image-20200612153552461](G:\\四期\\数据库\\mysql文档\\11 MySQL用户管理（1）.assets\\image-20200612153552461.png) 1set password &#x3D; password(\" 8888 ) 1SET PASSWORD FOR &#96;teacher&#96;@localhost&#96; &#x3D; PASSWORD(\"8888\"); 12drop user xgp@localhost;select * from user; ![image-20200612154416018](G:\\四期\\数据库\\mysql文档\\11 MySQL用户管理（1）.assets\\image-20200612154416018.png)","path":"posts/22c1.html","date":"06-11","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL 事务(2)","text":"一、MySQL设置事务自动提交（开启和关闭） MySQL 默认开启事务自动提交模式，即除非显式的开启事务（BEGIN 或 START TRANSACTION），否则每条 SOL 语句都会被当做一个单独的事务自动执行。但有些情况下，我们需要关闭事务自动提交来保证数据的一致性。下面主要介绍如何设置事务自动提交模式。 在 MySQL 中，可以通过 SHOW VARIABLES 语句查看当前事务自动提交模式，如下所示： 1234567mysql> SHOW VARIABLES LIKE 'autocommit';+---------------+-------+| Variable_name | Value |+---------------+-------+| autocommit | ON |+---------------+-------+1 row in set, 1 warning (0.04 sec) 结果显示，autocommit 的值是 ON，表示系统开启自动提交模式。 在 MySQL 中，可以使用 SET autocommit 语句设置事务的自动提交模式，语法格式如下： 1SET autocommit &#x3D; 0|1|ON|OFF; 对取值的说明： 值为 0 和值为 OFF：关闭事务自动提交。如果关闭自动提交，用户将会一直处于某个事务中，只有提交或回滚后才会结束当前事务，重新开始一个新事务。 值为 1 和值为 ON：开启事务自动提交。如果开启自动提交，则每执行一条 SQL 语句，事务都会提交一次。 示例 下面我们关闭事务自动提交，模拟银行转账。 使用 SET autocommit 语句关闭事务自动提交，且张三转给李四 500 元，SQL 语句和运行结果如下： 12345678910111213141516mysql> SET autocommit &#x3D; 0; ;Query OK, 0 rows affected (0.00 sec)mysql> SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 1000.00 || 李四 | 1.00 |+--------------+--------------+2 rows in set (0.00 sec)mysql> UPDATE bank SET cusMoney &#x3D; cusMoney-500 WHERE cusName&#x3D;'张三' ;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql> UPDATE bank SET cusMoney &#x3D; cusMoney+500 WHERE cusName&#x3D;'李四';Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 这时重新打开一个 cmd 窗口，查看 bank 数据表中张三和李四的余额，SQL 语句和运行结果如下所示： 12345678mysql> SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 1000.00 || 李四 | 1.00 |+--------------+--------------+2 rows in set (0.00 sec) 结果显示，张三和李四的余额是事务执行前的数据。 下面在之前的窗口中使用 COMMIT 语句提交事务，并查询 bank 数据表的数据，如下所示： 12345678910mysql> COMMIT;Query OK, 0 rows affected (0.07 sec)mysql> SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 500.00 || 李四 | 501.00 |+--------------+--------------+2 rows in set (0.00 sec) 结果显示，bank 数据表的数据更新成功。 在本例中，关闭自动提交后，该位置会作为一个事务起点，直到执行 COMMIT 语句和 ROLLBACK 语句后，该事务才结束。结束之后，这就是下一个事务的起点。 关闭自动提交功能后，只用当执行 COMMIT 命令后，MySQL 才将数据表中的资料提交到数据库中。如果执行 ROLLBACK 命令，数据将会被回滚。如果不提交事务，而终止 MySQL 会话，数据库将会自动执行回滚操作。 使用 BEGIN 或 START TRANSACTION 开启一个事务之后，自动提交将保持禁用状态，直到使用 COMMIT 或 ROLLBACK 结束事务。之后，自动提交模式会恢复到之前的状态，即如果 BEGIN 前 autocommit = 1，则完成本次事务后 autocommit 还是 1。如果 BEGIN 前 autocommit = 0，则完成本次事务后 autocommit 还是 0。 二、MySQL事务隔离级别详解 在《数据库事务》一节中介绍了 MySQL 事务的四大特性，其中事务的隔离性就是指当多个事务同时运行时，各事务之间相互隔离，不可互相干扰。 如果事务没有隔离性，就容易出现脏读、不可重复读和幻读等情况。 1) 脏读 脏读是指一个事务正在访问数据，并且对数据进行了修改，但是这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 2) 不可重复读 不可重复读是指在一个事务内，多次读取同一个数据。 在这个事务还没有结束时，另外一个事务也访问了该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 3) 幻读 幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 为了解决以上这些问题，标准 SQL 定义了 4 类事务隔离级别，用来指定事务中的哪些数据改变是可见的，哪些数据改变是不可见的。 MySQL 包括的事务隔离级别如下： 读未提交（READ UNCOMITTED） 读提交（READ COMMITTED） 可重复读（REPEATABLE READ） 串行化（SERIALIZABLE） MySQL 事务隔离级别可能产生的问题如下表所示： 隔离级别 脏读 不可重复读 幻读 READ UNCOMITTED √ √ √ READ COMMITTED × √ √ REPEATABLE READ × × √ SERIALIZABLE × × × MySQL 的事务的隔离级别由低到高分别为 READ UNCOMITTED、READ COMMITTED、REPEATABLE READ、SERIALIZABLE。低级别的隔离级别可以支持更高的并发处理，同时占用的系统资源更少。 下面根据实例来一一阐述它们的概念和联系。 1. 读未提交（READ UNCOMITTED，RU） 顾名思义，读未提交就是可以读到未提交的内容。 如果一个事务读取到了另一个未提交事务修改过的数据，那么这种隔离级别就称之为读未提交。 在该隔离级别下，所有事务都可以看到其它未提交事务的执行结果。因为它的性能与其他隔离级别相比没有高多少，所以一般情况下，该隔离级别在实际应用中很少使用。 例 1 主要演示了在读未提交隔离级别中产生的脏读现象。 示例 1 1) 先在 test 数据库中创建 testnum 数据表，并插入数据。SQL 语句和执行结果如下： 123456mysql> CREATE TABLE testnum( -> num INT(4));Query OK, 0 rows affected (0.57 sec)mysql> INSERT INTO test.testnum (num) VALUES(1),(2),(3),(4),(5);Query OK, 5 rows affected (0.09 sec)2) 下面的语句需要在两个命令行窗口中执行。为了方便理解，我们分别称之为 A 窗口和 B 窗口。 在 A 窗口中修改事务隔离级别，因为 A 窗口和 B 窗口的事务隔离级别需要保持一致，所以我们使用 SET GLOBAL TRANSACTION 修改全局变量。SQL 语句如下： 1234mysql> SET GLOBAL TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;Query OK, 0 rows affected (0.04 sec)flush privileges;Query OK, 0 rows affected (0.04 sec) 查询事务隔离级别，SQL 语句和运行结果如下： 12345mysql> show variables like '%tx_isolation%'\\G*************************** 1. row ***************************Variable_name: tx_isolation Value: READ-UNCOMMITTED1 row in set, 1 warning (0.00 sec) 结果显示，现在 MySQL 的事务隔离级别为 READ-UNCOMMITTED。 3) 在 A 窗口中开启一个事务，并查询 testnum 数据表，SQL 语句和运行结果如下： 12345678910111213mysql> BEGIN;Query OK, 0 rows affected (0.00 sec)mysql> SELECT * FROM testnum;+------+| num |+------+| 1 || 2 || 3 || 4 || 5 |+------+5 rows in set (0.00 sec) 4) 打开 B 窗口，查看当前 MySQL 的事务隔离级别，SQL 语句如下： 12345mysql> show variables like '%tx_isolation%'\\G*************************** 1. row ***************************Variable_name: tx_isolation Value: READ-UNCOMMITTED1 row in set, 1 warning (0.00 sec) 确定事务隔离级别是 READ-UNCOMMITTED 后，开启一个事务，并使用 UPDATE 语句更新 testnum 数据表，SQL 语句和运行结果如下： 12345mysql> BEGIN;Query OK, 0 rows affected (0.00 sec)mysql> UPDATE test.testnum SET num&#x3D;num*2 WHERE num&#x3D;2;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0 5) 现在返回 A 窗口，再次查询 testnum 数据表，SQL 语句和运行结果如下： 1234567891011mysql> SELECT * FROM testnum;+------+| num |+------+| 1 || 4 || 3 || 4 || 5 |+------+5 rows in set (0.02 sec) 由结果可以看出，A 窗口中的事务读取到了更新后的数据。 6) 下面在 B 窗口中回滚事务，SQL 语句和运行结果如下： 12mysql> ROLLBACK;Query OK, 0 rows affected (0.09 sec) 7) 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下： 1234567891011mysql> SELECT * FROM testnum;+------+| num |+------+| 1 || 2 || 3 || 4 || 5 |+------+5 rows in set (0.00 sec) 当 MySQL 的事务隔离级别为 READ UNCOMITTED 时，首先分别在 A 窗口和 B 窗口中开启事务，在 B 窗口中的事务更新但未提交之前， A 窗口中的事务就已经读取到了更新后的数据。但由于 B 窗口中的事务回滚了，所以 A 事务出现了脏读现象。 使用读提交隔离级别可以解决实例中产生的脏读问题。 2. 读提交（READ COMMITTED，RC） 顾名思义，读提交就是只能读到已经提交了的内容。 如果一个事务只能读取到另一个已提交事务修改过的数据，并且其它事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值，那么这种隔离级别就称之为读提交。 该隔离级别满足了隔离的简单定义：一个事务从开始到提交前所做的任何改变都是不可见的，事务只能读取到已经提交的事务所做的改变。 这是大多数数据库系统的默认事务隔离级别（例如 Oracle、SQL Server），但不是 MySQL 默认的。 例 2 演示了在读提交隔离级别中产生的不可重复读问题。 示例 2 1) 使用 SET 语句将 MySQL 事务隔离级别修改为 READ COMMITTED，并查看。SQL 语句和运行结果如下： 1234567mysql> SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;Query OK, 0 rows affected (0.00 sec)mysql> show variables like '%tx_isolation%'\\G*************************** 1. row ***************************Variable_name: tx_isolation Value: READ-COMMITTED1 row in set, 1 warning (0.00 sec) 2) 确定当前事务隔离级别为 READ COMMITTED 后，开启一个事务，SQL 语句和运行结果如下： 12mysql> BEGIN;Query OK, 0 rows affected (0.00 sec) 3) 在 B 窗口中开启事务，并使用 UPDATE 语句更新 testnum 数据表，SQL 语句和运行结果如下： 123456mysql> BEGIN;Query OK, 0 rows affected (0.00 sec)mysql> UPDATE test.testnum SET num&#x3D;num*2 WHERE num&#x3D;2;Query OK, 1 row affected (0.07 sec)Rows matched: 1 Changed: 1 Warnings: 0 4) 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下： 1234567891011mysql> SELECT * from test.testnum;+------+| num |+------+| 1 || 2 || 3 || 4 || 5 |+------+5 rows in set (0.00 sec) 5) 提交 B 窗口中的事务，SQL 语句和运行结果如下： 12mysql> COMMIT;Query OK, 0 rows affected (0.07 sec) 6) 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下： 1234567891011mysql> SELECT * from test.testnum;+------+| num |+------+| 1 || 4 || 3 || 4 || 5 |+------+5 rows in set (0.00 sec) 当 MySQL 的事务隔离级别为 READ COMMITTED 时，首先分别在 A 窗口和 B 窗口中开启事务，在 B 窗口中的事务更新并提交后，A 窗口中的事务读取到了更新后的数据。在该过程中，A 窗口中的事务必须要等待 B 窗口中的事务提交后才能读取到更新后的数据，这样就解决了脏读问题。而处于 A 窗口中的事务出现了不同的查询结果，即不可重复读现象。 使用可重复读隔离级别可以解决实例中产生的不可重复读问题。 3. 可重复读（REPEATABLE READ，RR） 顾名思义，可重复读是专门针对不可重复读这种情况而制定的隔离级别，可以有效的避免不可重复读。 在一些场景中，一个事务只能读取到另一个已提交事务修改过的数据，但是第一次读过某条记录后，即使其它事务修改了该记录的值并且提交，之后该事务再读该条记录时，读到的仍是第一次读到的值，而不是每次都读到不同的数据。那么这种隔离级别就称之为可重复读。 可重复读是 MySQL 的默认事务隔离级别，它能确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。在该隔离级别下，如果有事务正在读取数据，就不允许有其它事务进行修改操作，这样就解决了可重复读问题。 例 3 演示了在可重复读隔离级别中产生的幻读问题。 示例 3 1) 在 test 数据库中创建 testuser 数据表，SQL 语句和执行结果如下： 1234mysql> CREATE TABLE testuser( -> id INT (4) PRIMARY KEY, -> name VARCHAR(20));Query OK, 0 rows affected (0.29 sec) 2) 使用 SET 语句修改事务隔离级别，SQL 语句如下： 12mysql> SET GLOBAL TRANSACTION ISOLATION LEVEL REPEATABLE READ;Query OK, 0 rows affected (0.00 sec) 3) 在 A 窗口中开启事务，并查询 testuser 数据表，SQL 语句和运行结果如下： 12345mysql> BEGIN;Query OK, 0 rows affected (0.00 sec)mysql> SELECT * FROM test.testuser where id&#x3D;1;Empty set (0.04 sec) 4) 在 B 窗口中开启一个事务，并向 testuser 表中插入一条数据，SQL 语句和运行结果如下： 123456mysql> BEGIN;Query OK, 0 rows affected (0.00 sec)mysql> INSERT INTO test.testuser VALUES(1,'zhangsan');Query OK, 1 row affected (0.04 sec)mysql> COMMIT;Query OK, 0 rows affected (0.06 sec) 5) 现在返回 A 窗口，向 testnum 数据表中插入数据，SQL 语句和运行结果如下： 1234mysql> INSERT INTO test.testuser VALUES(1,'lisi');ERROR 1062 (23000): Duplicate entry '1' for key 'PRIMARY'mysql> SELECT * FROM test.testuser where id&#x3D;1;Empty set (0.00 sec) 使用串行化隔离级别可以解决实例中产生的幻读问题。 4. 串行化（SERIALIZABLE） 如果一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。那么这种隔离级别就称之为串行化。 SERIALIZABLE 是最高的事务隔离级别，主要通过强制事务排序来解决幻读问题。简单来说，就是在每个读取的数据行上加上共享锁实现，这样就避免了脏读、不可重复读和幻读等问题。但是该事务隔离级别执行效率低下，且性能开销也最大，所以一般情况下不推荐使用。 三、MySQL查看和修改事务隔离级别 在《MySQL事务隔离级别》一节中我们了解了 MySQL 的事务隔离级别，本节主要介绍查看和修改事务隔离级别的几种方法。 查看事务隔离级别 在 MySQL 中，可以通过show variables like '%tx_isolation%'或select @@tx_isolation;语句来查看当前事务隔离级别。 查看当前事务隔离级别的 SQL 语句和运行结果如下： 1234567891011121314mysql> show variables like '%tx_isolation%';+---------------+-----------------+| Variable_name | Value |+---------------+-----------------+| tx_isolation | REPEATABLE-READ |+---------------+-----------------+1 row in set, 1 warning (0.17 sec）mysql> select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set, 1 warning (0.00 sec) 结果显示，目前 MySQL 的事务隔离级别是 REPEATABLE-READ。 另外，还可以使用下列语句分别查询全局和会话的事务隔离级别： 12SELECT @@global.tx_isolation;SELECT @@session.tx_isolation; 提示：在MySQL 8.0.3 中，tx_isolation 变量被 transaction_isolation 变量替换了。在 MySQL 8.0.3 版本中查询事务隔离级别，只要把上述查询语句中的 tx_isolation 变量替换成 transaction_isolation 变量即可。 修改事务隔离级别 MySQL 提供了 SET TRANSACTION 语句，该语句可以改变单个会话或全局的事务隔离级别。语法格式如下： SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE} 其中，SESSION 和 GLOBAL 关键字用来指定修改的事务隔离级别的范围： SESSION：表示修改的事务隔离级别将应用于当前 session（当前 cmd 窗口）内的所有事务； GLOBAL：表示修改的事务隔离级别将应用于所有 session（全局）中的所有事务，且当前已经存在的 session 不受影响； 如果省略 SESSION 和 GLOBAL，表示修改的事务隔离级别将应用于当前 session 内的下一个还未开始的事务。 任何用户都能改变会话的事务隔离级别，但是只有拥有 SUPER 权限的用户才能改变全局的事务隔离级别。 如果使用普通用户修改全局事务隔离级别，就会提示需要超级权限才能执行此操作的错误信息，SQL 语句和运行结果如下： 123456789101112131415161718C:\\Users\\leovo>mysql -utestuser -pEnter password: ******Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 41Server version: 5.7.29-log MySQL Community Server (GPL) Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> SET GLOBAL TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;ERROR 1227 (42000): Access denied; you need (at least one of) the SUPER privilege(s) for this operationmysql> SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;Query OK, 0 rows affected (0.00 sec) 示例 1 使用 SET TRANSACTION 语句分别修改 session 和全局的事务隔离级别SQL 语句和运行结果如下： 123456789101112131415161718mysql> select @@session.tx_isolation;+------------------------+| @@session.tx_isolation |+------------------------+| SERIALIZABLE |+------------------------+1 row in set, 1 warning (0.00 sec)mysql> SET GLOBAL TRANSACTION ISOLATION LEVEL REPEATABLE READ;Query OK, 0 rows affected (0.00 sec)mysql> select @@global.tx_isolation;+-----------------------+| @@global.tx_isolation |+-----------------------+| REPEATABLE-READ |+-----------------------+1 row in set, 1 warning (0.00 sec) 还可以使用 set tx_isolation 命令直接修改当前 session 的事务隔离级别，SQL 语句和运行结果如下： 12345678910mysql> set tx_isolation&#x3D;'READ-COMMITTED';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql> select @@session.tx_isolation;+------------------------+| @@session.tx_isolation |+------------------------+| READ-COMMITTED |+------------------------+1 row in set, 1 warning (0.00 sec)","path":"posts/40d5.html","date":"06-10","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL 事务(1)","text":"A: MySQL 事务 MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你既需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 一般来说，事务是必须满足4个条件（ACID）: :原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。 原子性:一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性:在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性:数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性:事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。 B: 关于事务的一些术语 开启事务：Start Transaction 事务结束：End Transaction 提交事务：Commit Transaction 回滚事务：Rollback Transaction C: MYSQL 事务处理主要有两种方法： 1、用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 2、直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=0 禁止自动提交 SET AUTOCOMMIT=1 开启自动提交 12345678910111213141516171819202122232425262728293031323334353637383940414243444546mysql> use RUNOOB;Database changedmysql> CREATE TABLE runoob_transaction_test( id int(5)) engine&#x3D;innodb; # 创建数据表Query OK, 0 rows affected (0.04 sec) mysql> select * from runoob_transaction_test;Empty set (0.01 sec) mysql> begin; # 开始事务Query OK, 0 rows affected (0.00 sec) mysql> insert into runoob_transaction_test value(5);Query OK, 1 rows affected (0.01 sec) mysql> insert into runoob_transaction_test value(6);Query OK, 1 rows affected (0.00 sec) mysql> commit; # 提交事务Query OK, 0 rows affected (0.01 sec) mysql> select * from runoob_transaction_test;+------+| id |+------+| 5 || 6 |+------+2 rows in set (0.01 sec) mysql> begin; # 开始事务Query OK, 0 rows affected (0.00 sec) mysql> insert into runoob_transaction_test values(7);Query OK, 1 rows affected (0.00 sec) mysql> rollback; # 回滚Query OK, 0 rows affected (0.00 sec) mysql> select * from runoob_transaction_test; # 因为回滚所以数据没有插入+------+| id |+------+| 5 || 6 |+------+2 rows in set (0.01 sec) D: 什么是事务 事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作 多个操作作为一个整体向系统提交，要么都执行、要么都不执行 事务是一个不可分割的工作逻辑单元 转账过程就是一个整体 它需要两条UPDATE语句来完成，这两条语句是一个整体 如果其中任一条出现错误， 则整个转账业务也应取消，两个账户中的余额应恢复 到原来的数据，从而确保转账前和转账后的余额不变，即都是1001元 E: 为什么需要事务 了解事务之前，先来看看数据库为什么需要有事务，假设没有事务会有什么影响？ 举一个转账的例子，假设你朋友向你借10000元，你打开APP，乐呵呵的把钱转了，你的卡里已经少了10000元，但是你打电话给朋友时，你朋友说没有收到啊，你这时候肯定卖银行怎么不靠谱，没到账怎么把我卡里的钱给扣了。 我们来捋一捋上述银行发生的过程，简单的分三步： A发起转账10000给B -&gt; A银行卡减10000元 -&gt; B银行卡增加10000元。 上述案例是第三步出现了问题，如果有事务，则不会发生案例中的事情，可以理解为事务就是这三个步骤是一根绳子上的蚂蚱，要么都成功，要么都失败。 所以数据库引入事务的主要目的是事务会把数据库会从一种一致状态转换到另一种一致状态，数据库提交工作时可以确保要么所有修改都保存，要么所有修改都不保存。 了解事务，还需要了解事务的理论依据ACID，也可以说事务的几个特性。 一、银行转账问题 假定资金从账户A转到账户B，至少需要两步 账户A的资金减少 然后账户B的资金相应增加 123456789101112131415161718192021222324drop database if EXISTS &#96;bankdb&#96;;create database &#96;bankdb&#96;;use &#96;bankdb&#96;;drop table IF EXISTS &#96;bank&#96;;create table &#96;bank&#96;( &#96;cusName&#96; VARCHAR(20), #用户名 &#96;cusMoney&#96; DECIMAL(10,2) #用户名)CHARSET &#x3D; 'utf8mb4';insert into bankVALUES('张三',1000),('李四',1);# 模拟转账UPDATE bankset cusMoney&#x3D;cusMoney-500where cusName&#x3D;'张三';UPDATE bankset cusMoney&#x3D;cusMoney+500where cusName&#x3D;'李四';# 查看账户select * from bank; 下面开始模拟实现转账功能。从张三的账户直接转账 500 元到李四的账户，可以使用 UPDATE 语句分别修改张三的账户和李四的账户。张三的账户减少 500 元，李四的账户增加 500 元， SQL 语句如下所示： 12345678910111213# 模拟转账BEGIN; #开始UPDATE bankset cusMoney&#x3D;cusMoney-500where cusName&#x3D;'张三';UPDATE bankset cusMoney&#x3D;cusMoney+500where cusName&#x3D;'李四';COMMIT; # 结束# 查看一下select * from bank; ![image-20200614160258903](G:\\四期\\数据库\\mysql文档\\09 MySQL 事务+用户权限.assets\\image-20200614160258903.png) 正常情况下，执行以上的转账操作后，余额总和应保持不变，仍为 1001 元。但是，如果在这个过程的其中一个环节出现差错，如在张三的账户减少 500 元之后，这时发生了服务器故障，李四的账户没有立即增加 500 元，此时，第三方读取到两个账户的余额总和变为 500+1=501 元，即账户总额间少了 500 元。 MySQL 为了解决此类问题，提供了事务。事务可以将一系列的数据操作捆绑成一个整体进行统一管理，如果某一事务执行成功，则在该事务中进行的所有数据更改均会提交，成为数据库中的永久组成部分。如果事务执行时遇到错误，则就必须取消或回滚。取消或回滚后，数据将全部恢复到操作前的状态，所有数据的更改均被清除。 MySQL 通过事务保证了数据的一致性。上述提到的转账过程就是一个事务，它需要两条 UPDATE 语句来完成。这两条语句是一个整体，如果其中任何一个环节出现问题，则整个转账业务也应取消，两个账户中的余额应恢复为原来的数据，从而确保转账前和转账后的余额总和不变，即都是 1001 元。 二、执行事务的语法和流程 SQL 使用下列语句来管理事务。 1) 开始事务 1BEGIN; 或 1START TRANSACTION; 这个语句显式地标记一个事务的起始点。 2) 提交事务 MySQL 使用下面的语句来提交事务： 1COMMIT; COMMIT 表示提交事务，即提交事务的所有操作，具体地说，就是将事务中所有对数据库的更新都写到磁盘上的物理数据库中，事务正常结束。 提交事务，意味着将事务开始以来所执行的所有数据都修改成为数据库的永久部分，因此也标志着一个事务的结束。一旦执行了该命令，将不能回滚事务。只有在所有修改都准备好提交给数据库时，才执行这一操作。 3) 回滚（撤销）事务 MySQL 使用以下语句回滚事务： 1ROLLBACK; ROLLBACK 表示撤销事务，即在事务运行的过程中发生了某种故障，事务不能继续执行，系统将事务中对数据库的所有已完成的操作全部撤销，回滚到事务开始时的状态。这里的操作指对数据库的更新操作。 当事务执行过程中遇到错误时，使用 ROLLBACK 语句使事务回滚到起点或指定的保持点处。同时，系统将清除自事务起点或到某个保存点所做的所有的数据修改，并且释放由事务控制的资源。因此，这条语句也标志着事务的结束。 总结 BEGIN 或 START TRANSACTION 语句后面的 SQL 语句对数据库数据的更新操作都将记录在事务日志中，直至遇到 ROLLBACK 语句或 COMMIT 语句。如果事务中某一操作失败且执行了 ROLLBACK 语句，那么在开启事务语句之后所有更新的数据都能回滚到事务开始前的状态。如果事务中的所有操作都全部正确完成，并且使用了 COMMIT 语句向数据库提交更新数据，则此时的数据又处在新的一致状态。 1、实例演示 下面通过两个例子来演示一下 MySQL 事务的具体用法。 示例 1 下面模拟在张三的账户减少 500 元后，李四的账户还未增加 500 时，有其他会话访问数据表的场景。由于代码需要在两个窗口中执行，为了方便阅读，这里我们称为 A 窗口和 B 窗口。 1) 在 A 窗口中开启一个事务，并更新 mybank 数据库中 bank 表的数据，SQL 语句和运行结果如下： 12345678mysql> USE mybank;Database changedmysql> BEGIN;Query OK, 0 rows affected (0.00 sec)mysql> UPDATE bank SET cusMoney &#x3D; cusMoney-500 -> WHERE cusName&#x3D;'张三';Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0 2) 在 B 窗口中查询 bank 数据表中的数据，SQL 语句和运行结果如下： 12345678mysql> SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 1000.00 || 李四 | 1.00 |+--------------+--------------+2 rows in set (0.00 sec) 从结果可以看出，虽然 A 窗口中的事务已经更改了 bank 表中的数据，但没有立即更新数据，这时其他会话读取到的仍然是更新前的数据。 3) 在 A 窗口中继续执行事务并提交事务，SQL 语句和运行结果如下： 123456mysql> UPDATE bank SET cusMoney &#x3D; cusMoney+500 -> WHERE cusName&#x3D;'李四';Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql> COMMIT;Query OK, 0 rows affected (0.07 sec) 4) 在 B 窗口中再次查询 bank 数据表的数据，SQL 语句和运行结果如下： 12345678mysql> SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 500.00 || 李四 | 501.00 |+--------------+--------------+2 rows in set (0.00 sec) 在 A 窗口中执行 COMMIT 提交事务后，对数据所做的更新将一起提交，其他会话读取到的是更新后的数据。从结果可以看出张三和李四的总账户余额和转账前保持一致，这样数据从一个一致性状态更新到另一个一致性状态。 前面提到，当事务在执行中出现问题，也就是不能按正常的流程执行一个完整的事务时，可以使用 ROLLBACK 语句进行回滚，使用数据恢复到初始状态。 在例 1 中，张三的账户余额已经减少到 500 元，如果再转出 1000 元，将会出现余额为负数，因此需要回滚到原始状态。如例 2 所示。 示例 2 将张三的账户余额减少 1000 元，并让事务回滚，SQL 语句和运行结果如下所示： 123456789101112131415161718mysql> BEGIN;Query OK, 0 rows affected (0.00 sec) mysql> UPDATE bank SET cusMoney &#x3D; cusMoney-1000 WHERE cusName&#x3D;'张三';Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0 mysql> ROLLBACK;Query OK, 0 rows affected (0.07 sec) mysql> SELECT * FROM mybank.bank;+--------------+--------------+| cusName | cusMoney |+--------------+--------------+| 张三 | 500.00 || 李四 | 501.00 |+--------------+--------------+2 rows in set (0.00 sec) 从结果可以看出，执行事务回滚后，账户数据恢复到初始状态，即该事务执行之前的状态。 拓展 在数据库操作中，为了有效保证并发读取数据的正确性，提出了事务的隔离级别。在例 1 和例 2 的演示中，事务的隔离级别为默认隔离级别。在 MySQL 中，事务的默认隔离级别是 REPEATABLE-READ （可重读）隔离级别，即事务未结束时（未执行 COMMIT 或 ROLLBACK），其它会话只能读取到未提交数据。 请猛击《MySQL事务隔离级别》了解更多内容。 2、注意事项 MySQL 事务是一项非常消耗资源的功能，大家在使用过程中要注意以下几点。 1) 事务尽可能简短 事务的开启到结束会在数据库管理系统中保留大量资源，以保证事务的原子性、一致性、隔离性和持久性。如果在多用户系统中，较大的事务将会占用系统的大量资源，使得系统不堪重负，会影响软件的运行性能，甚至导致系统崩溃。 2) 事务中访问的数据量尽量最少 当并发执行事务处理时，事务操作的数据量越少，事务之间对相同数据的操作就越少。 3) 查询数据时尽量不要使用事务 对数据进行浏览查询操作并不会更新数据库的数据，因此应尽量不使用事务查询数据，避免占用过量的系统资源。 4) 在事务处理过程中尽量不要出现等待用户输入的操作 在处理事务的过程中，如果需要等待用户输入数据，那么事务会长时间地占用资源，有可能造成系统阻塞。 回滚 1234567BEGIN;UPDATE bankset cusMoney&#x3D;cusMoney+500where cusName&#x3D;'张三';ROLLBACK;select * from bank; 1234567BEGIN;UPDATE bankset cusMoney&#x3D;cusMoney+500where cusName&#x3D;'张三';COMMIT;select * from bank; 1查看事务状态:SHOW VARIABLES LIKE 'AUTOCOMMIT';","path":"posts/b0d5.html","date":"06-09","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL索引","text":"A: 为什么要使用索引 索引是 MySQL 中一种十分重要的数据库对象。它是数据库性能调优技术的基础，常用于实现数据的快速检索。 索引就是根据表中的一列或若干列按照一定顺序建立的列值与记录行之间的对应关系表，实质上是一张描述索引列的列值与原表中记录行之间一一对应关系的有序表。 在 MySQL 中，通常有以下两种方式访问数据库表的行数据： 1) 顺序访问 顺序访问是在表中实行全表扫描，从头到尾逐行遍历，直到在无序的行数据中找到符合条件的目标数据。这种方式实现比较简单，但是当表中有大量数据的时候，效率非常低下。例如，在几千万条数据中查找少量的数据时，使用顺序访问方式将会遍历所有的数据，花费大量的时间，显然会影响数据库的处理性能。 2) 索引访问 索引访问是通过遍历索引来直接访问表中记录行的方式。使用这种方式的前提是对表建立一个索引，在列上创建了索引之后，查找数据时可以直接根据该列上的索引找到对应记录行的位置，从而快捷地查找到数据。索引存储了指定列数据值的指针，根据指定的排序顺序对这些指针排序。 例如，在学生基本信息表 students 中，如果基于 student_id 建立了索引，系统就建立了一张索引列到实际记录的映射表，当用户需要查找 student_id 为 12022 的数据的时候，系统先在 student_id 索引上找到该记录，然后通过映射表直接找到数据行，并且返回该行数据。因为扫描索引的速度一般远远大于扫描实际数据行的速度，所以采用索引的方式可以大大提高数据库的工作效率。 B: 索引的分类 索引的类型和存储引擎有关，每种存储引擎所支持的索引类型不一定完全相同。根据存储方式的不同，MySQL 中常用的索引在物理上分为以下两类。 1) B-树索引 B-树索引又称为 BTREE 索引，目前大部分的索引都是采用 B-树索引来存储的。B-树索引是一个典型的数据结构，其包含的组件主要有以下几个： 叶子节点：包含的条目直接指向表里的数据行。叶子节点之间彼此相连，一个叶子节点有一个指向下一个叶子节点的指针。 分支节点：包含的条目指向索引里其他的分支节点或者叶子节点。 根节点：一个 B-树索引只有一个根节点，实际上就是位于树的最顶端的分支节点。 2) 哈希索引 哈希（Hash）一般翻译为“散列”，也有直接音译成“哈希”的，就是把任意长度的输入（又叫作预映射，pre-image）通过散列算法变换成固定长度的输出，该输出就是散列值。 哈希索引也称为散列索引或 HASH 索引。MySQL 目前仅有 MEMORY 存储引擎和 HEAP 存储引擎支持这类索引。其中，MEMORY 存储引擎可以支持 B- 树索引和 HASH 索引，且将 HASH 当成默认索引。 C: 常用索引类型 普通索引 ●基本索引类型●允许在定义索引的列中插入重复值和空值 唯一索引 ●索引列数据不重复●允许有空值 主键索引 ●主键列中的每个值是非空、唯一的 复合索引 ●一个主键将自动创建主键索引●将多个列组合作为索引 全文索引 ●支持值的全文查找 空间索引 ●允许重复值和空值●对空间数据类型的列建立的索引 D: 索引的使用原则和注意事项 虽然索引可以加快查询速度，提高 MySQL 的处理性能，但是过多地使用索引也会造成以下弊端： 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 除了数据表占数据空间之外，每一个索引还要占一定的物理空间。如果要建立聚簇索引，那么需要的空间就会更大。 当对表中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。 注意：索引可以在一些情况下加速查询，但是在某些情况下，会降低效率。 索引只是提高效率的一个因素，因此在建立索引的时候应该遵循以下原则： 在经常需要搜索的列上建立索引，可以加快搜索的速度。 在作为主键的列上创建索引，强制该列的唯一性，并组织表中数据的排列结构。 在经常使用表连接的列上创建索引，这些列主要是一些外键，可以加快表连接的速度。 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，所以其指定的范围是连续的。 在经常需要排序的列上创建索引，因为索引已经排序，所以查询时可以利用索引的排序，加快排序查询。 在经常使用 WHERE 子句的列上创建索引，加快条件的判断速度。 与此对应，在某些应用场合下建立索引不能提高 MySQL 的工作效率，甚至在一定程度上还带来负面效应，降低了数据库的工作效率，一般来说不适合创建索引的环境如下： 对于那些在查询中很少使用或参考的列不应该创建索引。因为这些列很少使用到，所以有索引或者无索引并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度，并增大了空间要求。 对于那些只有很少数据值的列也不应该创建索引。因为这些列的取值很少，例如人事表的性别列。查询结果集的数据行占了表中数据行的很大比例，增加索引并不能明显加快检索速度。 对于那些定义为 TEXT、IMAGE 和 BIT 数据类型的列不应该创建索引。因为这些列的数据量要么相当大，要么取值很少。 当修改性能远远大于检索性能时，不应该创建索引。因为修改性能和检索性能是互相矛盾的。当创建索引时，会提高检索性能，降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 一、MySQL创建索引 1、MySQL 提供了三种创建索引的方法： 1) 使用 CREATE INDEX 语句 可以使用专门用于创建索引的 CREATE INDEX 语句在一个已有的表上创建索引，但该语句不能创建主键。 语法格式： 1CREATE ON ( [] [ ASC | DESC]) 2) 使用 CREATE TABLE 语句 索引也可以在创建表（CREATE TABLE）的同时创建。在 CREATE TABLE 语句中添加以下语句。语法格式： 1CONSTRAINT PRIMARY KEY [索引类型] (,…) 语法格式： 1KEY | INDEX [] [] (,…) 在 CREATE TABLE 语句中添加此语句，表示在创建新表的同时创建该表的索引。 语法格式： 1UNIQUE [ INDEX | KEY] [] [] (,…) 在 CREATE TABLE 语句中添加此语句，表示在创建新表的同时创建该表的唯一性索引。 语法格式： 1FOREIGN KEY 在 CREATE TABLE 语句中添加此语句，表示在创建新表的同时创建该表的外键。 在使用 CREATE TABLE 语句定义列选项的时候，可以通过直接在某个列定义后面添加 PRIMARY KEY 的方式创建主键。而当主键是由多个列组成的多列索引时，则不能使用这种方法，只能用在语句的最后加上一个 PRIMARY KRY(&lt;列名&gt;，…) 子句的方式来实现。 3) 使用 ALTER TABLE 语句 CREATE INDEX 语句可以在一个已有的表上创建索引，ALTER TABLE 语句也可以在一个已有的表上创建索引。在使用 ALTER TABLE 语句修改表的同时，可以向已有的表添加索引。具体的做法是在 ALTER TABLE 语句中添加以下语法成分的某一项或几项。 语法格式： 1ADD INDEX [] [] (,…) 在 ALTER TABLE 语句中添加此语法成分，表示在修改表的同时为该表添加索引。 语法格式： 1ADD PRIMARY KEY [] (,…) 在 ALTER TABLE 语句中添加此语法成分，表示在修改表的同时为该表添加主键。 语法格式： 1ADD UNIQUE [ INDEX | KEY] [] [] (,…) 在 ALTER TABLE 语句中添加此语法成分，表示在修改表的同时为该表添加唯一性索引。 语法格式： 1ADD FOREIGN KEY [] (,…) 在 ALTER TABLE 语句中添加此语法成分，表示在修改表的同时为该表添加外键。 2、创建一般索引 创建一个表 tb_stu_info，在该表的 height 字段创建一般索引。输入的 SQL 语句和执行过程如下所示。 12345678910111213141516171819202122mysql> CREATE TABLE tb_stu_info -> ( -> id INT NOT NULL, -> name CHAR(45) DEFAULT NULL, -> dept_id INT DEFAULT NULL, -> age INT DEFAULT NULL, -> height INT DEFAULT NULL, -> INDEX(height) -> );Query OK，0 rows affected (0.40 sec)mysql> SHOW CREATE TABLE tb_stu_info\\G*************************** 1. row *************************** Table: tb_stu_infoCreate Table: CREATE TABLE &#96;tb_stu_info&#96; ( &#96;id&#96; int(11) NOT NULL, &#96;name&#96; char(45) DEFAULT NULL, &#96;dept_id&#96; int(11) DEFAULT NULL, &#96;age&#96; int(11) DEFAULT NULL, &#96;height&#96; int(11) DEFAULT NULL, KEY &#96;height&#96; (&#96;height&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;gb23121 row in set (0.01 sec) 3、创建唯一索引 创建一个表 tb_stu_info2，在该表的 id 字段上使用 UNIQUE 关键字创建唯一索引。输入的 SQL 语句和执行过程如下所示。 1234567891011121314151617181920212223mysql> CREATE TABLE tb_stu_info2 -> ( -> id INT NOT NULL, -> name CHAR(45) DEFAULT NULL, -> dept_id INT DEFAULT NULL, -> age INT DEFAULT NULL, -> height INT DEFAULT NULL, -> UNIQUE INDEX(height) -> );Query OK，0 rows affected (0.40 sec)mysql> SHOW CREATE TABLE tb_stu_info2\\G*************************** 1. row *************************** Table: tb_stu_info2Create Table: CREATE TABLE &#96;tb_stu_info2&#96; ( &#96;id&#96; int(11) NOT NULL, &#96;name&#96; char(45) DEFAULT NULL, &#96;dept_id&#96; int(11) DEFAULT NULL, &#96;age&#96; int(11) DEFAULT NULL, &#96;height&#96; int(11) DEFAULT NULL, UNIQUE KEY &#96;height&#96; (&#96;height&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;gb23121 row in set (0.00 sec) 二、查看索引 在 MySQL 中，如果要查看已创建的索引的情况，可以使用 SHOW INDEX 语句查看表中创建的索引。 语法格式： 1SHOW INDEX FROM [ FROM ] 语法说明如下： &lt;表名&gt;：要显示索引的表。 &lt;数据库名&gt;：要显示的表所在的数据库。 显示数据库 mytest 的表 course 的索引情况。 1mysql> SHOW INDEX FROM course FROM mytest; 该语句会返回一张结果表，该表有如下几个字段，每个字段所显示的内容说明如下。 参数 说明 Table 表示创建索引的数据表名，这里是 tb_stu_info2 数据表。 Non_unique 表示该索引是否是唯一索引。若不是唯一索引，则该列的值为 1；若是唯一索引，则该列的值为 0。 Key_name 表示索引的名称。 Seq_in_index 表示该列在索引中的位置，如果索引是单列的，则该列的值为 1；如果索引是组合索引，则该列的值为每列在索引定义中的顺序。 Column_name 表示定义索引的列字段。 Collation 表示列以何种顺序存储在索引中。在 MySQL 中，升序显示值“A”（升序），若显示为 NULL，则表示无分类。 Cardinality 索引中唯一值数目的估计值。基数根据被存储为整数的统计数据计数，所以即使对于小型表，该值也没有必要是精确的。基数越大，当进行联合时，MySQL 使用该索引的机会就越大。 Sub_part 表示列中被编入索引的字符的数量。若列只是部分被编入索引，则该列的值为被编入索引的字符的数目；若整列被编入索引，则该列的值为 NULL。 Packed 指示关键字如何被压缩。若没有被压缩，值为 NULL。 Null 用于显示索引列中是否包含 NULL。若列含有 NULL，该列的值为 YES。若没有，则该列的值为 NO。 Index_type 显示索引使用的类型和方法（BTREE、FULLTEXT、HASH、RTREE）。 Comment 显示评注。 【实例 】 使用 SHOW INDEX 语句查看表 tb_stu_info2 的索引信息，输入的 SQL 语句和执行结果如下所示。 12345678910111213141516mysql> SHOW INDEX FROM tb_stu_info2\\G*************************** 1. row *************************** Table: tb_stu_info2 Non_unique: 0 Key_name: heightSeq_in_index: 1 Column_name: height Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE Comment:Index_comment:1 row in set (0.03 sec) 三、MySQL修改和删除索引 基本语法 当不再需要索引时，可以使用 DROP INDEX 语句或 ALTER TABLE 语句来对索引进行删除。 1) 使用 DROP INDEX 语句 语法格式： 1DROP INDEX ON 语法说明如下： &lt;索引名&gt;：要删除的索引名。 &lt;表名&gt;：指定该索引所在的表名。 2) 使用 ALTER TABLE 语句 根据 ALTER TABLE 语句的语法可知，该语句也可以用于删除索引。具体使用方法是将 ALTER TABLE 语句的语法中部分指定为以下子句中的某一项。 DROP PRIMARY KEY：表示删除表中的主键。一个表只有一个主键，主键也是一个索引。 DROP INDEX index_name：表示删除名称为 index_name 的索引。 DROP FOREIGN KEY fk_symbol：表示删除外键。 注意：如果删除的列是索引的组成部分，那么在删除该列时，也会将该列从索引中删除；如果组成索引的所有列都被删除，那么整个索引将被删除。 删除索引 【实例 1】 删除表 tb_stu_info 中的索引，输入的 SQL 语句和执行结果如下所示。 123456789101112131415mysql&gt; DROP INDEX height -&gt; ON tb_stu_info;Query OK, 0 rows affected (0.27 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; SHOW CREATE TABLE tb_stu_info\\G*************************** 1. row *************************** Table: tb_stu_infoCreate Table: CREATE TABLE `tb_stu_info` ( `id` int(11) NOT NULL, `name` char(45) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, `age` int(11) DEFAULT NULL, `height` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=gb23121 row in mysql&gt; DROP INDEX height -&gt; ON tb_stu_info;Query OK, 0 rows affected (0.27 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; SHOW CREATE TABLE tb_stu_info\\G*************************** 1. row *************************** Table: tb_stu_infoCreate Table: CREATE TABLE `tb_stu_info` ( `id` int(11) NOT NULL, `name` char(45) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, `age` int(11) DEFAULT NULL, `height` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=gb23121 row in set (0.00 sec) 【实例 2】 删除表 tb_stu_info2 中名称为 id 的索引，输入的 SQL 语句和执行结果如下所示。 123456789101112131415mysql&gt; ALTER TABLE tb_stu_info2 -&gt; DROP INDEX height;Query OK, 0 rows affected (0.13 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; SHOW CREATE TABLE tb_stu_info2\\G*************************** 1. row *************************** Table: tb_stu_info2Create Table: CREATE TABLE `tb_stu_info2` ( `id` int(11) NOT NULL, `name` char(45) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, `age` int(11) DEFAULT NULL, `height` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=gb23121 row in mysql&gt; ALTER TABLE tb_stu_info2 -&gt; DROP INDEX height;Query OK, 0 rows affected (0.13 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; SHOW CREATE TABLE tb_stu_info2\\G*************************** 1. row *************************** Table: tb_stu_info2Create Table: CREATE TABLE `tb_stu_info2` ( `id` int(11) NOT NULL, `name` char(45) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, `age` int(11) DEFAULT NULL, `height` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=gb23121 row in set (0.00 sec) 四、MySQL索引的设计原则 索引的设计可以遵循一些已有的原则，创建索引的时候应尽量考虑符合这些原则，便于提升索引的使用效率，更高效的使用索引。本节将介绍一些索引的设计原则。 1. 选择唯一性索引 唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。如果使用姓名的话，可能存在同名现象，从而降低查询速度。 2. 为经常需要排序、分组和联合操作的字段建立索引 经常需要 ORDER BY、GROUP BY、DISTINCT 和 UNION 等操作的字段，排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。 3. 为常作为查询条件的字段建立索引 如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。 注意：常查询条件的字段不一定是所要选择的列，换句话说，最适合索引的列是出现在 WHERE 子句中的列，或连接子句中指定的列，而不是出现在 SELECT 关键字后的选择列表中的列。 4. 限制索引的数目 索引的数目不是“越多越好”。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。在修改表的内容时，索引必须进行更新，有时还可能需要重构。因此，索引越多，更新表的时间就越长。 如果有一个索引很少利用或从不使用，那么会不必要地减缓表的修改速度。此外，MySQL 在生成一个执行计划时，要考虑各个索引，这也要花费时间。创建多余的索引给查询优化带来了更多的工作。索引太多，也可能会使 MySQL 选择不到所要使用的最佳索引。 **5. **尽量使用数据量少的索引 如果索引的值很长，那么查询的速度会受到影响。例如，对一个 CHAR(100) 类型的字段进行全文检索需要的时间肯定要比对 CHAR(10) 类型的字段需要的时间要多。 6. 数据量小的表最好不要使用索引 由于数据较小，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果。 7. 尽量使用前缀来索引 如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT 和 BLOG 类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。 **8. **删除不再使用或者很少使用的索引 表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。应该定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。 总结 选择索引的最终目的是为了使查询的速度变快，上面给出的原则是最基本的准则，但不能只拘泥于上面的准则。应该在学习和工作中不断的实践，根据应用的实际情况进行分析和判断，选择最合适的索引方式。 小练习 1234create index index_fruiton fruit(sid);show index from fruit; 12drop index index_fruit on fruit;show index from fruit; 创建索引的指导原则 按照下列标准选择建立索引的列 ◆频繁搜索的列 ◆经常用作查询选择的列 ◆经常排序、分组的列 ◆经常用作连接的列(主键/外键) 请不要使用下面的列创建索引 ◆仅包含几个不同值的列 ◆表中仅包含几行 使用索引时注意事项 查询时减少使用*返回全部列，不要返回不需要的列 索引应该尽量小，在字节数小的列上建立索引 WHERE子句中有多个条件表达式时，包含索引列的表达式应置3 F其他条件表达式之前 避免在ORDER BY子句中使用表达式","path":"posts/8338.html","date":"06-08","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL视图","text":"A：什么是视图？视图是干什么用的？ 视图（view）是一种虚拟存在的表，是一个逻辑表，本身并不包含数据。作为一个select语句保存在数据字典中的。 通过视图，可以展现基表的部分数据；视图数据来自定义视图的查询中使用的表，使用视图动态生成。 基表：用来创建视图的表叫做基表base table 数据库视图的创建是基于SQL SELECT query和JOIN的。视图和表很相似，它也包含行和列，所以可以直接对它进行查询操作。另外大多数的数据库同样允许进行UPADTE操作，但必须满足一定的条件。视图的数据结构如图： 我们需要理解，数据库并没有存储视图所关联的数据，存储的只是视图的定义也就是相应的SQL SELECT and JOIN。 B：为什么要使用视图？ （a）因为视图的诸多优点，如下 视图可以简化你的复杂查询：视图的定义是基于一个查询声明，这个查询声明可能关联了很多底层表。我们可以使用视图向数据库的使用者或者外部程序隐藏复杂的底层表关系。 视图可以限制特定用户的数据访问权：有时我们希望隐藏某些表的一些数据对一些特定用户，这时视图可以很好的帮助我们实现这个功能。 视图可以使用可计算的列：我们知道表的列一般都不支持动态计算，但是视图的列是支持的。假设在有一张order_details表，其中包含product_nums和price_each两列，当我们需要查询order总价时我们就需要查询出结果后在代码中进行计算，如果我们使用视图的话可以在视图中添加一列total_price(product_nums*price_each)。这样就可以直接查询出order的总价。 视图可以帮助我们兼容旧的系统：假设我们拥有一个数据中心，这个数据中心被很多的程序在使用。如果有一天我们决定重新设计这个数据中心以适应一些新的业务需求，可能需要删除一些旧的表，并且创建一些新的表，但是我们并不希望这些变动影响到那些老的程序。那么我们可以创建一些视图用来适配那些老的程序。 简单：使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。 安全：使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现。 数据独立：一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。 总而言之，使用视图的大部分情况是为了保障数据安全性，提高查询效率。 C：视图简易分析 百度百科定义了什么是视图，但是对缺乏相关知识的人可能还是难以理解或者只有一个比较抽象的概念，笔者举个例子来解释下什么是视图。 朕想要了解皇宫的国库的相关情况，想知道酒窖有什么酒，剩多少，窖藏多少年，于是派最信任的高公公去清点，高公公去国库清点后报给了朕；朕又想知道藏书情况，于是又派高公公去清点并回来报告给朕，又想知道金银珠宝如何，又派高公公清点。。。过一段时间又想知道藏书情况，高公公还得重新再去清点，皇上问一次，高公公就得跑一次路。 后来皇上觉得高公公不容易，就成立了国库管理部门，小邓子负责酒窖，小卓子负责藏书，而小六子负责金库的清点。。。后来皇上每次想了解国库就直接问话负责人，负责人就按照职责要求进行汇报。 安排专人管理后，每次皇上想要了解国库情况，就不必让高公公每次都跑一趟，而是指定的人员按照指定的任务完成指定的汇报工作就可以了。 和数据库相对应，每次进行查询工作，都需要编写查询代码进行查询；而视图的作用就是不必每次都重新编写查询的SQL代码，而是通过视图直接查询即可。因此： 视图是虚拟表，本身不存储数据，而是按照指定的方式进行查询。 D：使用场合 权限控制的时候，不希望用户访问表中某些含敏感信息的列，比如salary… 关键信息来源于多个复杂关联表，可以创建视图提取我们需要的信息，简化操作； E：视图相关的MySQL指令 操作指令 代码 创建视图 CREATE VIEW 视图名(列1，列2…) AS SELECT (列1，列2…) FROM …; 使用视图 当成表使用就好 修改视图 CREATE OR REPLACE VIEW 视图名 AS SELECT […] FROM […]; 查看数据库已有视图 &gt;SHOW TABLES [like...];（可以使用模糊查找） 查看视图详情 DESC 视图名或者SHOW FIELDS FROM 视图名 视图条件限制 [WITH CHECK OPTION] F：使用视图注意事项： 视图中可以使用多个表 一个视图可以嵌套另一个视图 对视图数据进行添加、更新和删除操作直接影响所引用表中的数据 当视图数据来自多个表时，不允许添加和删除数据 创建视图需要足够的访问权限。 创建视图的数目没有限制。 视图不能索引，也不能有关联的触发器、默认值或规则。 视图可以和表一起使用。 视图不包含数据，所以每次使用视图时，都必须执行查询中所需的任何一个检索操作。如果用多个连接和过滤条件创建了复杂的视图或嵌套了视图，可能会发现系统运行性能下降得十分严重。因此，在部署大量视图应用时，应该进行系统测试。 提示：ORDER BY 子句可以用在视图中，但若该视图检索数据的 SELECT 语句中也含有 ORDER BY 子句，则该视图中的 ORDER BY 子句将被覆盖。 一、MySql创建视图 创建视图与创建表语法类似，不同的是创建视图是从一条查询语句创建的。视图创建后，可以像一张表一样使用，但只能用于数据查询，如：可以在一个查询中使用、可以在存储过程中、可以在另一个视图中使用。MySql创建视图语法如下： 1CREATE VIEW 视图名 AS SELECT 查询语句; 创建表 1234567891011create table tb_students_info(true&#96;id&#96; int(4) not null comment 'id' primary key auto_increment,true&#96;name&#96; varchar(50) not null comment 'name',true&#96;dept_id&#96; varchar(20) not null comment 'dept_id',true&#96;age&#96; int(4) unsigned comment 'age',true&#96;sex&#96; varchar(50) comment 'sex',true&#96;height&#96; int(4) unsigned comment 'height',true&#96;login_date&#96; datetime comment 'login_date')charset&#x3D;'utf8' comment&#x3D;'tb_students_info';select * from tb_students_info; 插入数据 1234567891011insert into tb_students_info(id,name,dept_id,age,sex,height,login_date)values(1,'Dany','1','25','F','160','2015-09-10'),(2,'Green','3','23','F','158','2016-10-22'),(3,'Henry','2','23','M','185','2015-05-31'),(4,'Jane','1','22','F','162','2016-12-20'),(5,'Jim','1','24','M','175','2016-01-15'),(6,'John','2','21','M','172','2015-11-11'),(7,'Lily','6','22','F','165','2016-02-26'),(8,'Susan','4','23','F','170','2015-10-01'),(9,'Thomas','3','22','M','178','2016-06-07'),(10,'Tom','4','23','M','165','2016-08-05'); 查看一下 1select * from tb_students_info; 1、创建基于单表的视图 MySQL 可以在单个数据表上创建视图。 查看 test_db 数据库中的 tb_students_info 表的数据，如下所示。 12345678910111213141516mysql> SELECT * FROM tb_students_info;+----+--------+---------+------+------+--------+---------------------+| id | name | dept_id | age | sex | height | login_date |+----+--------+---------+------+------+--------+---------------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 00:00:00 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 00:00:00 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 00:00:00 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 00:00:00 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 00:00:00 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 00:00:00 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 00:00:00 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 00:00:00 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 00:00:00 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 00:00:00 |+----+--------+---------+------+------+--------+---------------------+10 rows in set (0.00 sec) 【实例 1】 在 tb_students_info 表上创建一个名为 view_students_info 的视图，输入的 SQL 语句和执行结果如下所示。 1234567891011121314151617181920mysql> CREATE VIEW view_students_info -> AS SELECT * FROM tb_students_info;Query OK, 0 rows affected (0.00 sec)mysql> SELECT * FROM view_students_info;+----+--------+---------+------+------+--------+---------------------+| id | name | dept_id | age | sex | height | login_date |+----+--------+---------+------+------+--------+---------------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 00:00:00 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 00:00:00 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 00:00:00 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 00:00:00 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 00:00:00 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 00:00:00 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 00:00:00 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 00:00:00 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 00:00:00 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 00:00:00 |+----+--------+---------+------+------+--------+---------------------+10 rows in set (0.00 sec) 默认情况下，创建的视图和基本表的字段是一样的，也可以通过指定视图字段的名称来创建视图。 【实例 2】 在 tb_students_info 表上创建一个名为 v_students_info 的视图，输入的 SQL 语句和执行结果如下所示。 12345678910111213141516171819202122mysql> CREATE VIEW v_students_info -> (s_id,s_name,d_id,s_age,s_sex,s_height,s_date) -> AS SELECT id,name,dept_id,age,sex,height,login_date -> FROM tb_students_info;Query OK, 0 rows affected (0.06 sec)mysql> SELECT * FROM v_students_info;+------+--------+------+-------+-------+----------+---------------------+| s_id | s_name | d_id | s_age | s_sex | s_height | s_date |+------+--------+------+-------+-------+----------+---------------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 00:00:00 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 00:00:00 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 00:00:00 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 00:00:00 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 00:00:00 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 00:00:00 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 00:00:00 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 00:00:00 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 00:00:00 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 00:00:00 |+------+--------+------+-------+-------+----------+---------------------+10 rows in set (0.00 sec) 可以看到，view_students_info 和 v_students_info 两个视图中的字段名称不同，但是数据却相同。因此，在使用视图时，可能用户不需要了解基本表的结构，更接触不到实际表中的数据，从而保证了数据库的安全。 2、创建基于多表的视图 MySQL 中也可以在两个以上的表中创建视图，使用 CREATE VIEW 语句创建。 【实例 3】 在表 tb_student_info 和表 tb_departments 上创建视图 v_students_info，输入的 SQL 语句和执行结果如下所示。 123456789101112131415161718192021mysql> CREATE VIEW v_students_info -> (s_id,s_name,d_id,s_age,s_sex,s_height,s_date) -> AS SELECT id,name,dept_id,age,sex,height,login_date -> FROM tb_students_info;Query OK, 0 rows affected (0.06 sec)mysql> SELECT * FROM v_students_info;+------+--------+------+-------+-------+----------+------------+| s_id | s_name | d_id | s_age | s_sex | s_height | s_date |+------+--------+------+-------+-------+----------+------------+| 1 | Dany | 1 | 24 | F | 160 | 2015-09-10 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 |+------+--------+------+-------+-------+----------+------------+10 rows in set (0.01 sec) 通过这个视图可以很好地保护基本表中的数据。视图中包含 s_id、s_name 和 dept_name，s_id 字段对应 tb_students_info 表中的 id 字段，s_name 字段对应 tb_students_info 表中的 name 字段，dept_name 字段对应 tb_departments 表中的 dept_name 字段。 二、查询视图 视图一经定义之后，就可以如同查询数据表一样，使用 SELECT 语句查询视图中的数据，语法和查询基础表的数据一样。 视图用于查询主要应用在以下几个方面： 使用视图重新格式化检索出的数据。 使用视图简化复杂的表连接。 使用视图过滤数据。 DESCRIBE 可以用来查看视图，语法如下： 1DESCRIBE 视图名； 【实例 4】 通过 DESCRIBE 语句查看视图 v_students_info 的定义，输入的 SQL 语句和执行结果如下所示。 12345678910111213mysql> DESCRIBE v_students_info;+----------+---------------+------+-----+------------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+------------+-------+| s_id | int(11) | NO | | 0 | || s_name | varchar(45) | YES | | NULL | || d_id | int(11) | YES | | NULL | || s_age | int(11) | YES | | NULL | || s_sex | enum('M','F') | YES | | NULL | || s_height | int(11) | YES | | NULL | || s_date | date | YES | | 2016-10-22 | |+----------+---------------+------+-----+------------+-------+7 rows in set (0.04 sec) 1注意：DESCRIBE 一般情况下可以简写成 DESC，输入这个命令的执行结果和输入 DESCRIBE 是一样的。 1、查看视图的字段信息 查看视图的字段信息与查看数据表的字段信息一样，都是使用 DESCRIBE 关键字来查看的。具体语法如下： 1DESCRIBE 视图名; 或简写成： 1DESC 视图名; 示例 1 下面创建学生信息表 studentinfo 的一个视图，用于查询学生姓名和考试分数。 创建学生信息表 studentinfo 的 SQL 语句和运行结果如下： 1234567mysql> CREATE TABLE studentinfo( -> ID INT(11) PRIMARY KEY, -> NAME VARCHAR(20), -> SCORE DECIMAL(4,2), -> SUBJECT VARCHAR(20), -> TEACHER VARCHAR(20));Query OK, 0 rows affected (0.10 sec) 创建查询学生姓名和分数的视图语句如下： 12mysql> CREATE VIEW v_studentinfo AS SELECT name,score FROM studentinfo;Query OK, 0 rows affected (0.04 sec) 通过 DESCRIBE 语句查看视图 v_studentsinfo 中的字段信息，SQL 语句和运行结果如下所示。 12345678mysql> DESCRIBE v_studentinfo;+-------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || score | decimal(4,2) | YES | | NULL | |+-------+--------------+------+-----+---------+-------+2 rows in set (0.01 sec) 注意：使用 DESC 的执行结果和使用 DESCRIBE 是一样的。 由运行结果可以看出，查看视图的字段内容与查看表的字段内容显示的格式是相同的。因此，更能说明视图实际上也是一张数据表了，不同的是，视图中的数据都来自于数据库中已经存在的表。 查看视图的详细信息 在 MySQL 中，SHOW CREATE VIEW 语句可以查看视图的详细定义。其语法如下所示： 1SHOW CREATE VIEW 视图名; 通过上面的语句，还可以查看创建视图的语句。创建视图的语句可以作为修改或者重新创建视图的参考，方便用户操作。 示例 2 使用 SHOW CREATE VIEW 查看视图，SQL 语句和运行结果如下所示： 1234567mysql> SHOW CREATE VIEW v_studentinfo \\G*************************** 1. row *************************** View: v_studentinfo Create View: CREATE ALGORITHM&#x3D;UNDEFINED DEFINER&#x3D;&#96;root&#96;@&#96;localhost&#96; SQL SECURITY DEFINER VIEW &#96;v_studentinfo&#96; AS select &#96;studentinfo&#96;.&#96;NAME&#96; AS &#96;name&#96;,&#96;studentinfo&#96;.&#96;SCORE&#96; AS &#96;score&#96; from &#96;studentinfo&#96;character_set_client: gbkcollation_connection: gbk_chinese_ci1 row in set (0.00 sec) 上述 SQL 语句以\\G结尾，这样能使显示结果格式化。如果不使用\\G，显示的结果会比较混乱，如下所示： 12345678910111213141516mysql> DESCRIBE v_studentinfo;+-------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || score | decimal(4,2) | YES | | NULL | |+-------+--------------+------+-----+---------+-------+2 rows in set (0.01 sec)mysql> SHOW CREATE VIEW v_studentinfo;+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+| View | Create View | character_set_client | collation_connection |+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+| v_studentinfo | CREATE ALGORITHM&#x3D;UNDEFINED DEFINER&#x3D;&#96;root&#96;@&#96;localhost&#96; SQL SECURITY DEFINER VIEW &#96;v_studentinfo&#96; AS select &#96;studentinfo&#96;.&#96;NAME&#96; AS &#96;name&#96;,&#96;studentinfo&#96;.&#96;SCORE&#96; AS &#96;score&#96; from &#96;studentinfo&#96; | gbk | gbk_chinese_ci |+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+1 row in set (0.01 sec) 二、 MySql视图修改 1、基本语法 可以使用 ALTER VIEW 语句来对已有的视图进行修改。 语法格式如下： 1ALTER VIEW 视图名 AS SELECT 查询语句; 语法说明如下： &lt;视图名&gt;：指定视图的名称。该名称在数据库中必须是唯一的，不能与其他表或视图同名。 &lt;SELECT 语句&gt;：指定创建视图的 SELECT 语句，可用于查询多个基础表或源视图。 需要注意的是，对于 ALTER VIEW 语句的使用，需要用户具有针对视图的 CREATE VIEW 和 DROP 权限，以及由 SELECT 语句选择的每一列上的某些权限。 修改视图的定义，除了可以通过 ALTER VIEW 外，也可以使用 DROP VIEW 语句先删除视图，再使用 CREATE VIEW 语句来实现。 2、修改视图内容 视图是一个虚拟表，实际的数据来自于基本表，所以通过插入、修改和删除操作更新视图中的数据，实质上是在更新视图所引用的基本表的数据。 注意：对视图的修改就是对基本表的修改，因此在修改时，要满足基本表的数据定义。 某些视图是可更新的。也就是说，可以使用 UPDATE、DELETE 或 INSERT 等语句更新基本表的内容。对于可更新的视图，视图中的行和基本表的行之间必须具有一对一的关系。 还有一些特定的其他结构，这些结构会使得视图不可更新。更具体地讲，如果视图包含以下结构中的任何一种，它就是不可更新的： 聚合函数 SUM()、MIN()、MAX()、COUNT() 等。 DISTINCT 关键字。 GROUP BY 子句。 HAVING 子句。 UNION 或 UNION ALL 运算符。 位于选择列表中的子查询。 FROM 子句中的不可更新视图或包含多个表。 WHERE 子句中的子查询，引用 FROM 子句中的表。 ALGORITHM 选项为 TEMPTABLE（使用临时表总会使视图成为不可更新的）的时候。 【实例 1】 使用 ALTER 语句修改视图 view_students_info，输入的 SQL 语句和执行结果如下所示。 12345678910111213mysql> ALTER VIEW view_students_info -> AS SELECT id,name,age -> FROM tb_students_info;Query OK, 0 rows affected (0.07 sec)mysql> DESC view_students_info;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | NO | | 0 | || name | varchar(45) | YES | | NULL | || age | int(11) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+3 rows in set (0.03 sec) 用户可以通过视图来插入、更新、删除表中的数据，因为视图是一个虚拟的表，没有数据。通过视图更新时转到基本表上进行更新，如果对视图增加或删除记录，实际上是对基本表增加或删除记录。 查看视图 view_students_info 的数据内容，如下所示。 12345678910111213141516mysql> SELECT * FROM view_students_info;+----+--------+------+| id | name | age |+----+--------+------+| 1 | Dany | 24 || 2 | Green | 23 || 3 | Henry | 23 || 4 | Jane | 22 || 5 | Jim | 24 || 6 | John | 21 || 7 | Lily | 22 || 8 | Susan | 23 || 9 | Thomas | 22 || 10 | Tom | 23 |+----+--------+------+10 rows in set (0.00 sec) 【实例 2】 使用 UPDATE 语句更新视图 view_students_info，输入的 SQL 语句和执行结果如下所示。 1234567891011121314151617181920mysql> UPDATE view_students_info -> SET age&#x3D;25 WHERE id&#x3D;1;Query OK, 0 rows affected (0.24 sec)Rows matched: 1 Changed: 0 Warnings: 0mysql> SELECT * FROM view_students_info;+----+--------+------+| id | name | age |+----+--------+------+| 1 | Dany | 25 || 2 | Green | 23 || 3 | Henry | 23 || 4 | Jane | 22 || 5 | Jim | 24 || 6 | John | 21 || 7 | Lily | 22 || 8 | Susan | 23 || 9 | Thomas | 22 || 10 | Tom | 23 |+----+--------+------+10 rows in set (0.00 sec) 查看基本表 tb_students_info 和视图 v_students_info 的内容，如下所示。 123456789101112131415161718192021222324252627282930313233mysql> SELECT * FROM tb_students_info;+----+--------+---------+------+------+--------+------------+| id | name | dept_id | age | sex | height | login_date |+----+--------+---------+------+------+--------+------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 |+----+--------+---------+------+------+--------+------------+10 rows in set (0.00 sec)mysql> SELECT * FROM v_students_info;+------+--------+------+-------+-------+----------+------------+| s_id | s_name | d_id | s_age | s_sex | s_height | s_date |+------+--------+------+-------+-------+----------+------------+| 1 | Dany | 1 | 25 | F | 160 | 2015-09-10 || 2 | Green | 3 | 23 | F | 158 | 2016-10-22 || 3 | Henry | 2 | 23 | M | 185 | 2015-05-31 || 4 | Jane | 1 | 22 | F | 162 | 2016-12-20 || 5 | Jim | 1 | 24 | M | 175 | 2016-01-15 || 6 | John | 2 | 21 | M | 172 | 2015-11-11 || 7 | Lily | 6 | 22 | F | 165 | 2016-02-26 || 8 | Susan | 4 | 23 | F | 170 | 2015-10-01 || 9 | Thomas | 3 | 22 | M | 178 | 2016-06-07 || 10 | Tom | 4 | 23 | M | 165 | 2016-08-05 |+------+--------+------+-------+-------+----------+------------+10 rows in set (0.00 sec) 3、修改视图名称 修改视图的名称可以先将视图删除，然后按照相同的定义语句进行视图的创建，并命名为新的视图名称。 三、MySql视图删除 1、基本语法 可以使用 DROP VIEW 语句来删除视图。 语法格式如下： 1DROP VIEW [ , …] 其中：&lt;视图名&gt;指定要删除的视图名。DROP VIEW 语句可以一次删除多个视图，但是必须在每个视图上拥有 DROP 权限。 2、删除视图 【实例】删除 v_students_info 视图，输入的 SQL 语句和执行过程如下所示。 1234mysql> DROP VIEW IF EXISTS v_students_info;Query OK, 0 rows affected (0.00 sec)mysql> SHOW CREATE VIEW v_students_info;ERROR 1146 (42S02): Table 'test_db.v_students_info' doesn't exist 可以看到，v_students_info 视图已不存在，将其成功删除。 小练习 123456789101112#删除视图drop view if EXISTS view_student_for_teacher;#创建视图create view view_student_for_teacher asselect studentNo,studentName,sex,gradeName,phonefrom student sjoin grade gon s.gradeId &#x3D; g.gradeID;#查看视图select * from view_student_for_teacher; ![image-20200611173158789](G:\\四期\\数据库\\mysql文档\\06 视图.assets\\image-20200611173158789.png) 1234#查看数据库的视图use information_schema;SELECT * from views\\G;select * from views where table_schema ='myschool'\\G; 视图实例1-创建视图及查询数据操作 现有三张表：用户(user)、课程(course)、用户课程中间表(user_course)，表结构及数据如下： 表定义： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859-- ------------------------------ Table structure for &#96;course&#96;-- ----------------------------DROP TABLE IF EXISTS &#96;course&#96;;CREATE TABLE &#96;course&#96; ( &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT, &#96;name&#96; varchar(200) NOT NULL, &#96;description&#96; varchar(500) NOT NULL, PRIMARY KEY (&#96;id&#96;)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;4 DEFAULT CHARSET&#x3D;utf8;-- ------------------------------ Records of course-- ----------------------------INSERT INTO &#96;course&#96; VALUES ('1', 'JAVA', 'JAVA课程');INSERT INTO &#96;course&#96; VALUES ('2', 'C++', 'C++课程');INSERT INTO &#96;course&#96; VALUES ('3', 'C语言', 'C语言课程');-- ------------------------------ Table structure for &#96;user&#96;-- ----------------------------DROP TABLE IF EXISTS &#96;user&#96;;CREATE TABLE &#96;user&#96; ( &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT, &#96;account&#96; varchar(255) NOT NULL, &#96;name&#96; varchar(255) NOT NULL, &#96;address&#96; varchar(255) DEFAULT NULL, &#96;others&#96; varchar(200) DEFAULT NULL, &#96;others2&#96; varchar(200) DEFAULT NULL, PRIMARY KEY (&#96;id&#96;)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;4 DEFAULT CHARSET&#x3D;utf8;-- ------------------------------ Records of user-- ----------------------------INSERT INTO &#96;user&#96; VALUES ('1', 'user1', '小陈', '美国', '1', '1');INSERT INTO &#96;user&#96; VALUES ('2', 'user2', '小张', '日本', '2', '2');INSERT INTO &#96;user&#96; VALUES ('3', 'user3', '小王', '中国', '3', '3');-- ------------------------------ Table structure for &#96;user_course&#96;-- ----------------------------DROP TABLE IF EXISTS &#96;user_course&#96;;CREATE TABLE &#96;user_course&#96; ( &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT, &#96;userid&#96; bigint(20) NOT NULL, &#96;courseid&#96; bigint(20) NOT NULL, PRIMARY KEY (&#96;id&#96;)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;7 DEFAULT CHARSET&#x3D;utf8;-- ------------------------------ Records of user_course-- ----------------------------INSERT INTO &#96;user_course&#96; VALUES ('1', '1', '2');INSERT INTO &#96;user_course&#96; VALUES ('2', '1', '3');INSERT INTO &#96;user_course&#96; VALUES ('3', '2', '1');INSERT INTO &#96;user_course&#96; VALUES ('4', '2', '2');INSERT INTO &#96;user_course&#96; VALUES ('5', '2', '3');INSERT INTO &#96;user_course&#96; VALUES ('6', '3', '2'); 这时，当我们想要查询小张上的所以课程相关信息的时候，需要这样写一条长长的SQL语句，如下： 12345678910SELECT &#96;uc&#96;.&#96;id&#96; AS &#96;id&#96;, &#96;u&#96;.&#96;name&#96; AS &#96;username&#96;, &#96;c&#96;.&#96;name&#96; AS &#96;coursename&#96;FROM &#96;user&#96; &#96;u&#96;LEFT JOIN &#96;user_course&#96; &#96;uc&#96; ON ((&#96;u&#96;.&#96;id&#96; &#x3D; &#96;uc&#96;.&#96;userid&#96;))LEFT JOIN &#96;course&#96; &#96;c&#96; ON ((&#96;uc&#96;.&#96;courseid&#96; &#x3D; &#96;c&#96;.&#96;id&#96;))WHERE u.&#96;name&#96; &#x3D; '小张' 但是我们可以通过视图简化操作，例如我们创建视图view_user_course如下： 12345678910111213141516171819202122-- ------------------------------ View structure for &#96;view_user_course&#96;-- ----------------------------DROP VIEWIF EXISTS &#96;view_user_course&#96;;CREATE ALGORITHM &#x3D; UNDEFINED DEFINER &#x3D; &#96;root&#96;@&#96;localhost&#96; SQL SECURITY DEFINER VIEW &#96;view_user_course&#96; AS ( SELECT &#96;uc&#96;.&#96;id&#96; AS &#96;id&#96;, &#96;u&#96;.&#96;name&#96; AS &#96;username&#96;, &#96;c&#96;.&#96;name&#96; AS &#96;coursename&#96; FROM ( ( &#96;user&#96; &#96;u&#96; LEFT JOIN &#96;user_course&#96; &#96;uc&#96; ON ((&#96;u&#96;.&#96;id&#96; &#x3D; &#96;uc&#96;.&#96;userid&#96;)) ) LEFT JOIN &#96;course&#96; &#96;c&#96; ON ((&#96;uc&#96;.&#96;courseid&#96; &#x3D; &#96;c&#96;.&#96;id&#96;)) )); 几点说明（MySQL中的视图在标准SQL的基础之上做了扩展）： ALGORITHM=UNDEFINED：指定视图的处理算法； DEFINER=root@localhost：指定视图创建者； SQL SECURITY DEFINER：指定视图查询数据时的安全验证方式； 创建好视图之后，我们可以直接用以下SQL语句在视图上查询小张上的所以课程相关信息，同样可以得到所需结果： 1234567SELECT vuc.username, vuc.coursenameFROM view_user_course vucWHERE vuc.username &#x3D; '小张' 视图实例2-增删改数据操作 继续，我们可以尝试在视图view_user_course上做增删改数据操作，如下： 1update view_user_course set username&#x3D;'test',coursename&#x3D;'JAVASCRIPT' where id&#x3D;3 遗憾的是操作失败，提示错误信息如下： 123[SQL] update view_user_course set username&#x3D;'test',coursename&#x3D;'JAVASCRIPT' where id&#x3D;3[Err] 1393 - Can not modify more than one base table through a join view 'demo.view_user_course' 因为不能在一张由多张关联表连接而成的视图上做同时修改两张表的操作； 那么哪些操作可以在视图上进行呢？ 视图与表是一对一关系情况：如果没有其它约束（如视图中没有的字段，在基本表中是必填字段情况），是可以进行增删改数据操作； 如我们创建用户关键信息视图view_user_keyinfo，如下： 123456789101112-- ------------------------------ View structure for &#96;view_user_keyinfo&#96;-- ----------------------------DROP VIEWIF EXISTS &#96;view_user_keyinfo&#96;;CREATE ALGORITHM &#x3D; UNDEFINED DEFINER &#x3D; &#96;root&#96;@&#96;localhost&#96; SQL SECURITY DEFINER VIEW &#96;view_user_keyinfo&#96; AS SELECT &#96;u&#96;.&#96;id&#96; AS &#96;id&#96;, &#96;u&#96;.&#96;account&#96; AS &#96;account&#96;, &#96;u&#96;.&#96;name&#96; AS &#96;username&#96;FROM &#96;user&#96; &#96;u&#96;; 进行增删改操作如下，操作成功（注意user表中的其它字段要允许为空，否则操作失败）： 1234567891011121314INSERT INTO view_user_keyinfo (account, username)VALUES ('test1', 'test1');DELETEFROM view_user_keyinfoWHERE username &#x3D; 'test1';UPDATE view_user_keyinfoSET username &#x3D; 'updateuser'WHERE id &#x3D; 1 视图与表是一对多关系情况：如果只修改一张表的数据，且没有其它约束（如视图中没有的字段，在基本表中是必填字段情况），是可以进行改数据操作，如以下语句，操作成功； 123update view_user_course set coursename&#x3D;'JAVA' where id&#x3D;1;update view_user_course set username&#x3D;'test2' where id&#x3D;3; 以下操作失败： 123delete from view_user_course where id&#x3D;3;insert into view_user_course(username, coursename) VALUES('2','3');","path":"posts/a0ec.html","date":"06-07","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL子查询","text":"子查询 子查询指一个查询语句嵌套在另一个查询语句内部的查询，这个特性从mysql4.1开始引入。在select子句中先计算子查询，子查询结果作为外层另一个查询的过滤条件，查询可以基于一个表或者多个表。子查询中常用的操作符有any（some）、all、in、exists。子查询可以添加到select、update和delete语句中，而且可以进行多层嵌套。子查询中也可以使用比较运算符，如“&lt;”,“&lt;=”,“&gt;”,“&gt;=”和“!=”等。 示例1 12SELECT * from studentWHERE studentName &#x3D; '李文才'; 示例2 12345SELECT * from studentWHERE studentName &#x3D; true(select studentName from studenttruetruewhere studentNo&#x3D;10001true); 示例3 12345# 请查找出年龄大于15岁的学生# select * from student# where 年龄 > 15;select DATEDIFF(NOW(),'2005-01-01') &#x2F;365 （1）带any、some关键字的子查询 any和some关键字是同义词，表示满足其中任一条件，它们允许创建一个表达式对子查询的返回值列进行比较，只要满足内层子查询中的任何一个比较条件，就返回一个结果作为外层查询的条件。 12345create table tb1(truenum1 int not null);insert into tb1 values(1),(5),(13),(27);select * from tb1; 12345create table tb2(truenum2 int not null);insert into tb2 values(6),(14),(11),(20);select * from tb2; 1234# 查询tb1比tb2大的数select num1 from tb1where num1 > any(select num2 from tb2); （2）带all关键字的子查询 all关键字与any和some不同，使用all时需要同时满足所有内层查询的条件 1234# tb1中大于tb2所有数字select num1 from tb1where num1 > all(select num2 from tb2); （3）带exists关键字的子查询 exists关键字后面的参数是一个任意的子查询，系统对子查询进行运算以判断它是否返回行，如果至少返回一行，那么exists的结果为true，此时外层查询语句将进行查询；如果子查询没有返回任何行，那么exists返回的结果是false，此时外层语句将不进行查询。 12345678910111213141516171819create table suppliers( s_id int not null auto_increment, s_name char(50) not null, s_city char(50) null, s_zip char(10) null, s_call char(50) not null, primary key(s_id));insert into suppliers(s_id,s_name,s_city,s_zip,s_call)values(101,'FastFruit Inc.','tianjin','300000','48075'),(102,'LT Supplies','chongqing','400000','44333'),(103,'acme','shanghai','200000','90046'),(104,'fnk inc.','zhongshan','528437','11111'),(105,'good set','taiyuang','030000','22222'),(106,'just eat ours','beijing','010','45678'),(107,'dk inc.','zhengzhou','450000','33332');select * from suppliers; 123select * from fruit where EXISTS(trueSELECT * from suppliers where s_id&#x3D;107); （4）带in关键字的子查询 in关键字进行子查询时，内层查询语句仅仅返回一个数据列，这个数据列里的值将提供给外层查询语句进行比较操作。 123456789mysql> select c_id from orders where o_num in-> (select o_num from orderitems where f_id &#x3D; 'c0');+-------+| c_id |+-------+| 10004 || 10001 |+-------+2 rows in set (0.00 sec) （5）带比较运算符的子查询 1234567891011mysql> select s_id,f_name from fruits-> where s_id &#x3D;-> (select s1.s_id from suppliers as s1 where s1.s_city&#x3D;'tianjin');+------+------------+| s_id | f_name |+------+------------+| 101 | apple || 101 | blackberry || 101 | cherry |+------+------------+3 rows in set (0.00 sec) 5、合并查询结果 利用union关键字，可以给出多条select语句，并将它们的结果组合成单个结果集。合并时，两个表对应的列数和数据类型必须相同。各个select语句之间使用union或union all关键字分隔。union不使用关键字all，执行的时候删除重复的记录，所有返回的行都是唯一的；使用关键字all的作用是不删除重复行也不对结果进行自动排序。 123456# 合并select sid,sname,sprice from fruitlwhere sprice > 6UNION all select * from fruitwhere sid in (101,104); 123456# 合并select sid,sname,sprice from fruitwhere sprice > 6UNIONselect * from fruitwhere sid in (101,104); union和union all的区别：使用union all的功能是不删除重复行，加上all关键字语句执行时所需要的资源少，所以尽可能地使用它，因此知道有重复行但是想保留这些行，确定查询结果中不会有重复数据或者不需要去掉重复数据的时候，应当使用union all以提高查询效率。 6、为表和字段取别名 前面介绍了分组查询、聚合函数查询和嵌套子查询，取别名使用关键字as为查询结果中的某一列指定一个特别的名字。可以为字段或者表分别取别名，在查询时，使用别名替代指定的内容。 （1）为表取别名 12345678mysql> select * from orders as o-> where o.o_num &#x3D; 30001;+-------+---------------------+-------+| o_num | o_date | c_id |+-------+---------------------+-------+| 30001 | 2008-09-01 00:00:00 | 10001 |+-------+---------------------+-------+1 row in set (0.00 sec) （2）为字段取别名 1234567891011121314151617mysql> select f1.f_name as fruits_name ,f1.f_price as fruits_price-> from fruits as f1-> where f1.f_price < 8;+-------------+--------------+| fruits_name | fruits_price |+-------------+--------------+| apple | 5.20 || apricot | 2.20 || berry | 7.60 || xxxx | 3.60 || cherry | 3.20 || lemon | 6.40 || xbabay | 2.60 || grape | 5.30 || xbababa | 3.60 |+-------------+--------------+9 rows in set (0.01 sec) 7、使用正则表达式查询 正则表达式通常被用来检索或替换那些符合某个模式的文本内容，根据指定的匹配模式匹配文本中符合要求的特殊字符串。例如从一个文本文件中提取电话号码，查找一篇文章中重复的单词或者替换用户输入的某些敏感词语等等，这些地方都可以使用正则表达式。正则表达式强大且灵活，可以应用于非常复杂的查询。mysql中使用regexp关键字指定正则表达式的字符匹配模式。 （1）查询以特定字符或字符串开头的记录 1select * from fruit where sname regexp '^苹'; （2）查询以特定字符或字符串结尾的记录 1select * from fruit where sname regexp '果$'; （3）用符合‘.’来代替字符串中的任意一个字符 1select * from fruit where sname regexp '.果'; （4）匹配指定字符中的任意一个 1select * from student where sex regexp '[男]'; （5）使用“*”和“+”来匹配多个字符 1select studentName from student where studentName regexp '^李*露'; 1select studentName from student where studentName regexp '^李+露'; （6）匹配指定字符以外的字符 1select * from student where sex regexp '[^男]'; （7）使用{n,}或者{n,m}来指定字符串连续出现的次数 1select studentName from student where studentName regexp '李&#123;0,&#125;';","path":"posts/b19d.html","date":"06-06","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL高级查询","text":"回想 123456select studentNo, studentName, sex, gradeNamefrom student s,grade gwhere s.gradeId &#x3D; g.gradeID;select studentNo,studentName,sex,gradeNamefrom student s join grade gon s.gradeId &#x3D; g.gradeID; ![image-20200610140605161](G:\\四期\\数据库\\mysql文档\\05 mysql通算符.assets\\image-20200610140605161.png) 123select count(1), sex from studentgroup by sexHAVING sex &#x3D;'男'; ![image-20200610140916671](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610140916671.png) 123# 排序select * from studentLIMIT 4,5; ![image-20200610141016816](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610141016816.png) 12SELECT * from studentwhere studentNo in ('10005','10001'); ![image-20200610141245878](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610141245878.png) 12SELECT * from studentwhere studentNo BETWEEN 10001 and 10005; ![image-20200610141437404](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610141437404.png) 123select * from studentwhere email is nulland identityCard is null; ![image-20200610141528016](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610141528016.png) 查询数据 数据库管理系统的一个最重要的功能就是数据查询，数据查询不应只是简单查询数据库中存储的数据，还应该根据需要对数据进行筛选，以及确定数据以什么样的格式显示。MySQL提供了功能强大、灵活的语句来实现这些操作。 1、基本查询语句 mysql从数据表中查询数据的基本语句为select语句。select语句的基本格式是： 12SELECT &#123;* | &#125; [ FROM , .... [ where ] [ group by ] [ having ] [ order by ] [ limit ] {*|&lt;字段列表&gt;}包含星号通配符选择字段列表，表示查询的字段，其中字段列至少包含一个字段名称，如果要查询多个字段，多个字段之间用逗号隔开，最后一个字段后不要加逗号。 FROM&lt;表1&gt;,&lt;表2&gt;…：表1和表2表示查询数据的来源，可以是单个或多个。 WHERE子句是可选项，如果选择该项，将限定查询必须满足的查询条件。 GROUP BY&lt;字段&gt;，该子句告诉MySQL按什么样的顺序显示查询出来的数据，可以进行的排序有：升序（asc）、降序（desc）。 [limit]，该子句告诉mysql每次显示查询出来的数据条款。 12345678910111213141516171819202122232425262728mysql> create table fruits-> (-> f_id char(10) not null,-> s_id int not null,-> f_name char(255) not null,-> f_price decimal(8,2) not null,-> primary key(f_id)-> );Query OK, 0 rows affected (0.02 sec)mysql> insert into fruits(f_id,s_id,f_name,f_price)-> values('a1',101,'apple','5.2'),-> ('b1',101,'blackberry','10.2'),-> ('bs1',102,'orange','11.2'),-> ('bs2',105,'melon','8.2'),-> ('t1',102,'banana','10.3'),-> ('t2',102,'grape','5.3'),-> ('o2',103,'coconut','9.2'),-> ('c0',101,'cherry','3.2'),-> ('a2',103,'apricot','2.2'),-> ('l2',104,'lemon','6.4'),-> ('b2',104,'berry','7.6'),-> ('m1',106,'mango','15.7'),-> ('m2',105,'xbabay','2.6'),-> ('t4',107,'xbababa','3.6'),-> ('m3',105,'xxtt','11.6'),-> ('b5',107,'xxxx','3.6');Query OK, 16 rows affected (0.02 sec)Records: 16 Duplicates: 0 Warnings: 0 2、单表查询 单表查询是指从一张表数据中查询所需的数据。主要有：查询所有字段、查询指定字段、查询指定记录、查询空值、多条件的查询、对查询结果进行排序等方式。 &lt;1&gt;查询所有字段 在select语句中使用星号（）通配符查询所有字段。 select查询记录最简单的形式是从一个表中检索所有记录，实现的方法是使用星号（）通配符指定查找所有列的名称。 1mysql> select * from fruits; &lt;2&gt;在select语句中指定所有字段 根据前面select语句的格式，select关键字后面的字段名为将要查询的数据，因此可以将表中所有字段的名称跟在select子句后面，如果忘记了字段名称，可以使用DESC命令查看表的结构。有时候，由于表中的字段多，不一定能记住所有的字段名称。因此很不方便，不建议使用。 1Select f_id,s_id,f_name,f_price from fruit （1）查询指定字段 1select 字段名 from 表名； 12345678910111213141516171819202122mysql> select f_name from fruits;+------------+| f_name |+------------+| apple || apricot || blackberry || berry || xxxx || orange || melon || cherry || lemon || mango || xbabay || xxtt || coconut || banana || grape || xbababa |+------------+16 rows in set (0.00 sec) （2）查询多个字段 使用select声明，可以获取多个字段下的数据，只需要在关键字select后面指定要查询的字段的名称，不同字段名称之间用逗号分隔，最后一个字段后面不需要加逗号 1select 字段1，字段2，字段3 ....，字段n from 表名； 12345678910111213141516171819202122mysql> select f_name,f_price from fruits;+------------+---------+| f_name | f_price |+------------+---------+| apple | 5.20 || apricot | 2.20 || blackberry | 10.20 || berry | 7.60 || xxxx | 3.60 || orange | 11.20 || melon | 8.20 || cherry | 3.20 || lemon | 6.40 || mango | 15.70 || xbabay | 2.60 || xxtt | 11.60 || coconut | 9.20 || banana | 10.30 || grape | 5.30 || xbababa | 3.60 |+------------+---------+16 rows in set (0.01 sec) （3）查询指定记录 数据库中包含大量的数据，根据特殊要求可能只需要查询表中的指定数据，相当于对数据的过滤。在select语句中，通过where子句可以对数据进行过滤。 1select 字段1，字段2....字段n from 表名 where 查询条件； ![image-20200613131557954](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613131557954.png) 123456789mysql> select f_name,f_price-> from fruits-> where f_price &#x3D; 10.2;+------------+---------+| f_name | f_price |+------------+---------+| blackberry | 10.20 |+------------+---------+1 row in set (0.01 sec) （4）带in关键字的查询 in操作符用来查询满足指定范围内的条件的记录，使用IN操作符，将所有检索条件用括号括起来，检索条件之间用逗号分隔开，只要满足条件范围内的一个值即为匹配项。 123456789101112131415mysql> select s_id,f_name,f_price-> from fruits-> where s_id in (101,102)-> order by f_name;+------+------------+---------+| s_id | f_name | f_price |+------+------------+---------+| 101 | apple | 5.20 || 102 | banana | 10.30 || 101 | blackberry | 10.20 || 101 | cherry | 3.20 || 102 | grape | 5.30 || 102 | orange | 11.20 |+------+------------+---------+6 rows in set (0.00 sec) （5）带between and的范围查询 Between and用来查询某个范围内的值，该操作符需要两个参数，即范围的开始值和结束值，如果字段值满足指定的范围查询条件，则这些记录被返回。 1234567891011121314151617181920mysql> select f_name,f_price-> from fruits-> where f_price between 2.00 and 10.20;+------------+---------+| f_name | f_price |+------------+---------+| apple | 5.20 || apricot | 2.20 || blackberry | 10.20 || berry | 7.60 || xxxx | 3.60 || melon | 8.20 || cherry | 3.20 || lemon | 6.40 || xbabay | 2.60 || coconut | 9.20 || grape | 5.30 || xbababa | 3.60 |+------------+---------+12 rows in set (0.00 sec) （7）带like的字符匹配查询 通配符是一种在SQL的where条件子句中拥有特殊意思的字符，SQL语句中支持多种通配符，可以和like一起使用的通配符有‘%’和‘_’。 &lt;1&gt;百分号（%）通配符，匹配任意长度的字符，甚至包括零字符 1234567891011mysql> select f_id,f_name-> from fruits-> where f_name like 'b%';+------+------------+| f_id | f_name |+------+------------+| b1 | blackberry || b2 | berry || t1 | banana |+------+------------+3 rows in set (0.00 sec) &lt;2&gt;下划线（__)通配符，一次只能匹配任意一个字符 123456789mysql> select f_id,f_name-> from fruits-> where f_name like '____y';+------+--------+| f_id | f_name |+------+--------+| b2 | berry |+------+--------+1 row in set (0.00 sec) （8）查询空值 数据表创建的时候，设计者可以指定某列中是否可以包含空值（NULL)。空值不同于0，也不同于空字符串。空值一般表示数据未知、不适用或将在以后添加数据。在select语句中使用IS NULL子句，可以查询某字段内容为空的记录。 1234567891011121314151617181920212223242526272829mysql> create table customers-> (-> c_id int not null auto_increment,-> c_name char(50) not null,-> c_address char(50) null,-> c_city char(50) null,-> c_zip char(50) null,-> c_contact char(50) null,-> c_email char(50) null,-> primary key(c_id)-> );Query OK, 0 rows affected (0.02 sec)mysql> insert into customers(c_id,c_name,c_address,c_city,c_zip,c_contact,c_email)-> values(10001,'RedHook','200Street','Tianjin','300000','LiMing','LMing@163.com'),-> (10002,'Stars','333 FromageLane','Dalian','116000','Zhangbo','Jerry@hotmail.com'),-> (10003,'Netbhood','1 Sunny Place','Qingdao','266000','LuoCong',NULL),->(10004,'JOTO','829 Riverside Drive', 'Haikou','570000','YangShan','sam@hotmail.com');Query OK, 4 rows affected (0.02 sec)Records: 4 Duplicates: 0 Warnings: 0mysql> select c_id,c_name,c_email from customers where c_email IS NULL;+-------+----------+---------+| c_id | c_name | c_email |+-------+----------+---------+| 10003 | Netbhood | NULL |+-------+----------+---------+1 row in set (0.01 sec) （9）带and的多条件查询 使用select查询时，可以增加查询的限制条件，这样可以使查询的结果更加精确。MySQL在where子句中使用and操作符限定只有满足所有查询条件的记录才会被返回。可以使用and连接两个甚至多个查询条件，多个条件表达式之间用and分开。 12345678910mysql> select f_id,f_price,f_name-> from fruits-> where s_id &#x3D; '101' and f_price >&#x3D;5;+------+---------+------------+| f_id | f_price | f_name |+------+---------+------------+| a1 | 5.20 | apple || b1 | 10.20 | blackberry |+------+---------+------------+2 rows in set (0.00 sec) （10）带or的多条件查询 与and相反，在where声明中使用or操作符，表示只需要满足其中一个条件的记录即可返回。or也可以连接两个甚至多个查询条件，多个条件表达式之间用or分开。 1234567891011121314mysql> select s_id,f_name,f_price-> from fruits-> where s_id &#x3D; 101 or s_id &#x3D; 102;+------+------------+---------+| s_id | f_name | f_price |+------+------------+---------+| 101 | apple | 5.20 || 101 | blackberry | 10.20 || 102 | orange | 11.20 || 101 | cherry | 3.20 || 102 | banana | 10.30 || 102 | grape | 5.30 |+------+------------+---------+6 rows in set (0.00 sec) （11）查询结果不重复 12345678910111213141516171819# 查询不重复# 创建表create table &#96;fruit&#96;(true&#96;sid&#96; int(3) PRIMARY KEY not null,true&#96;sname&#96; VARCHAR(20) not NULL,true&#96;sprice&#96; FLOAT not null)CHARSET 'utf8mb4';# 表中添加数据insert into &#96;fruit&#96;(sid,sname,sprice)values(100,'芒果',5.00),(101,'苹果',5.00),(102,'香蕉',7.00),(103,'梨',6.00),(104,'火龙果',10.00),(105,'榴莲',15.00);# 查看一下select * from fruit; ![image-20200613132514405](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613132514405.png) 12345#去掉重复数据select DISTINCT sprice from fruit;select DISTINCT sex from student S join grade gon s.gradeId &#x3D; g.gradeID； ![image-20200613132441783](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613132441783.png) 123#聚合函数select max(sprice) 最高价,min(sprice),sum(sprice),avg(sprice) from fruit; ![](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613132535375.png) 3、对查询结果排序 （1）单列排序 123456789mysql> select f_name from fruits;+------------+| f_name |+------------+| apple || apricot || blackberry || berry || xxxx | （2）多列排序 12345678910111213141516171819202122mysql> select f_name,f_price from fruits order by f_name,f_price;+------------+---------+| f_name | f_price |+------------+---------+| apple | 5.20 || apricot | 2.20 || banana | 10.30 || berry | 7.60 || blackberry | 10.20 || cherry | 3.20 || coconut | 9.20 || grape | 5.30 || lemon | 6.40 || mango | 15.70 || melon | 8.20 || orange | 11.20 || xbababa | 3.60 || xbabay | 2.60 || xxtt | 11.60 || xxxx | 3.60 |+------------+---------+16 rows in set (0.00 sec) 在多列进行排序的时候，首先排序的第一列必须有相同的列值，才会对第二列进行排序。如果第一列数据中所有值都是唯一的，将不再对第二列进行排序。 （3）指定排序方向 默认情况下，查询数据按字母升序进行排序（从A~Z)，但数据的排序并不仅限于此，还可以使用order by对查询结果进行降序排序（从Z~A)，这可以通过关键字DESC实现。 12345678910111213141516171819202122mysql> select f_name,f_price from fruits order by f_name,f_price DESC;+------------+---------+| f_name | f_price |+------------+---------+| apple | 5.20 || apricot | 2.20 || banana | 10.30 || berry | 7.60 || blackberry | 10.20 || cherry | 3.20 || coconut | 9.20 || grape | 5.30 || lemon | 6.40 || mango | 15.70 || melon | 8.20 || orange | 11.20 || xbababa | 3.60 || xbabay | 2.60 || xxtt | 11.60 || xxxx | 3.60 |+------------+---------+16 rows in set (0.01 sec) 与DESC相反ASC是升序 4、分组查询 分组插叙是对数据按照某个或多个字段进行分组，MySQL中使用group by关键字对数据进行分组，基本语法形式为：group by 字段 1、创建分组 Group by 关键字通常和集合函数一起使用，例如：MAX()、MIN()、COUNT()、SUM()、AVG()。 根据s_id对fruits表中的数据进行分组 12345678910111213mysql> select s_id,count(*) as total from fruits group by s_id;+------+-------+| s_id | total |+------+-------+| 101 | 3 || 102 | 3 || 103 | 2 || 104 | 2 || 105 | 3 || 106 | 1 || 107 | 2 |+------+-------+7 rows in set (0.00 sec) （1）根据s_id对fruits表中的数据进行分组，将每个供应商的水果名称显示出来 12345678910111213mysql> select s_id,group_concat(f_name) as name from fruits group by s_id;+------+-------------------------+| s_id | name |+------+-------------------------+| 101 | apple,blackberry,cherry || 102 | orange,banana,grape || 103 | apricot,coconut || 104 | berry,lemon || 105 | melon,xbabay,xxtt || 106 | mango || 107 | xxxx,xbababa |+------+-------------------------+7 rows in set (0.00 sec) （2）使用having过滤分组 根据s_id对fruits表中的数据进行分组，并显示水果种类大于1的分组信息 12345678910111213mysql> select s_id,group_concat(f_name) as name from fruits group by s_id havingcount(f_name) > 1;+------+-------------------------+| s_id | name |+------+-------------------------+| 101 | apple,blackberry,cherry || 102 | orange,banana,grape || 103 | apricot,coconut || 104 | berry,lemon || 105 | melon,xbabay,xxtt || 107 | xxxx,xbababa |+------+-------------------------+6 rows in set (0.00 sec) （3）在group by 子句中使用with rollup 使用with rollup关键字之后，在所有查询出的分组记录之后增加一条记录，该记录计算查询出的所有记录的总和，即统计记录数量。 12345678910111213141516mysql> select s_id,count(*) as total-> from fruits-> group by s_id with rollup;+------+-------+| s_id | total |+------+-------+| 101 | 3 || 102 | 3 || 103 | 2 || 104 | 2 || 105 | 3 || 106 | 1 || 107 | 2 || NULL | 16 |+------+-------+8 rows in set (0.00 sec) （4）多字段分组 使用group by可以对多个字段进行分组，group by关键字后面跟需要分组的字段，MySQL根据多字段的值来进行层次分组，分组层次从左到右，即先按第1个字段分组，然后在第1个字段值相同的记录中，再根据第2个字段的值进行分组，以此类推 12345678910111213141516171819202122mysql> select * from fruits group by s_id,f_name;+------+------+------------+---------+| f_id | s_id | f_name | f_price |+------+------+------------+---------+| a1 | 101 | apple | 5.20 || b1 | 101 | blackberry | 10.20 || c0 | 101 | cherry | 3.20 || t1 | 102 | banana | 10.30 || t2 | 102 | grape | 5.30 || bs1 | 102 | orange | 11.20 || a2 | 103 | apricot | 2.20 || o2 | 103 | coconut | 9.20 || b2 | 104 | berry | 7.60 || l2 | 104 | lemon | 6.40 || bs2 | 105 | melon | 8.20 || m2 | 105 | xbabay | 2.60 || m3 | 105 | xxtt | 11.60 || m1 | 106 | mango | 15.70 || t4 | 107 | xbababa | 3.60 || b5 | 107 | xxxx | 3.60 |+------+------+------------+---------+16 rows in set (0.00 sec) （5）group by和order by一起使用 某些情况下需要对分组进行排序 12345678910111213141516171819202122232425mysql> create table orderitems-> (-> o_num int not null,-> o_item int not null,-> f_id char(10) not null,-> quantity int not null,-> item_price decimal(8,2) not null,-> primary key(o_num,o_item)-> );Query OK, 0 rows affected (0.03 sec)mysql> insert into orderitems(o_num,o_item,f_id,quantity,item_price)-> values(30001,1,'a1',10,'5.2'),-> (30001,2,'b2',3,'7.6'),-> (30001,3,'bs1',5,'11.2'),-> (30001,4,'bs2',15,'9.2'),-> (30002,1,'b3',2,'20.0'),-> (30003,1,'c0',100,10),-> (30004,1,'o2',50,'2.50'),-> (30005,1,'c0',5,'10'),-> (30005,2,'b1',10,'8.99'),-> (30005,3,'a2',10,'2.2'),-> (30005,4,'m1',5,'14.99');Query OK, 11 rows affected (0.00 sec)Records: 11 Duplicates: 0 Warnings: 0 查询价格大于100的订单号和总价订单价格 12345678910111213mysql> select o_num,sum(quantity*item_price) as ordertotal-> from orderitems-> group by o_num-> having sum(quantity*item_price) >&#x3D; 100;+-------+------------+| o_num | ordertotal |+-------+------------+| 30001 | 268.80 || 30003 | 1000.00 || 30004 | 125.00 || 30005 | 236.85 |+-------+------------+4 rows in set (0.00 sec) 5、使用limit限制查询结果的数量 select返回所有匹配的行，有可能是表中所有的行，如仅仅需要返回第一行或者前几行，使用limit关键字，语法格式如下：limit [位置偏移量] 行数 12345678910111213141516171819mysql> select * from fruits limit 4;+------+------+------------+---------+| f_id | s_id | f_name | f_price |+------+------+------------+---------+| a1 | 101 | apple | 5.20 || a2 | 103 | apricot | 2.20 || b1 | 101 | blackberry | 10.20 || b2 | 104 | berry | 7.60 |+------+------+------------+---------+4 rows in set (0.02 sec)mysql> select * from fruits limit 4,3;+------+------+--------+---------+| f_id | s_id | f_name | f_price |+------+------+--------+---------+| b5 | 107 | xxxx | 3.60 || bs1 | 102 | orange | 11.20 || bs2 | 105 | melon | 8.20 |+------+------+--------+---------+3 rows in set (0.00 sec) 6、使用聚合函数查询 ![image-20200613133729764](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613133729764.png) （1）count()函数 Count()函数统计数据表中包含的记录行的总数，或者根据查询结果返回列中包含的数据行数。 Count(*)计算表中总的函数，不管某列有数列或者为空值 Count(字段名)计算指定列下总的行数，计算时将忽略空值的行 1234567891011121314151617181920212223242526272829mysql> select count(*) as cust_num-> from customers;+----------+| cust_num |+----------+| 4 |+----------+1 row in set (0.00 sec)mysql> select count(c_email) as email_num-> from customers;+-----------+| email_num |+-----------+| 3 |+-----------+1 row in set (0.00 sec)mysql> select o_num,count(f_id)-> from orderitems-> group by o_num;+-------+-------------+| o_num | count(f_id) |+-------+-------------+| 30001 | 4 || 30002 | 1 || 30003 | 1 || 30004 | 1 || 30005 | 4 |+-------+-------------+5 rows in set (0.00 sec) （2）sum()函数 sum()是一个求总和的函数，返回指定列值得总和。 12345678910111213141516171819202122mysql> select sum(quantity) as items_total-> from orderitems-> where o_num &#x3D; 30005;+-------------+| items_total |+-------------+| 30 |+-------------+1 row in set (0.01 sec)mysql> select o_num,sum(quantity) as items_total-> from orderitems-> group by o_num;+-------+-------------+| o_num | items_total |+-------+-------------+| 30001 | 33 || 30002 | 2 || 30003 | 100 || 30004 | 50 || 30005 | 30 |+-------+-------------+5 rows in set (0.00 sec) 注意：sum()函数在计算时，忽略列值为NULL的行。 （3）avg()函数 avg()函数通过计算返回的行数和每一行数据的和，求得指定列数据的平均值。 123456789101112131415161718mysql> select avg(f_price) as avg_price-> from fruits-> where s_id&#x3D;103;+-----------+| avg_price |+-----------+| 5.700000 |+-----------+1 row in set (0.00 sec)mysql> select avg(f_price) as avg_price-> from fruits-> where s_id&#x3D;103;+-----------+| avg_price |+-----------+| 5.700000 |+-----------+1 row in set (0.00 sec) （4）max()函数 12345678910111213141516171819202122mysql> select max(f_price) as max_price from fruits;+-----------+| max_price |+-----------+| 15.70 |+-----------+1 row in set (0.00 sec)mysql> select s_id,max(f_price) as max_price-> from fruits-> group by s_id;+------+-----------+| s_id | max_price |+------+-----------+| 101 | 10.20 || 102 | 11.20 || 103 | 9.20 || 104 | 7.60 || 105 | 11.60 || 106 | 15.70 || 107 | 3.60 |+------+-----------+7 rows in set (0.00 sec) （5）min()函数 min()返回查询列中的最小值 1234567891011121314151617181920mysql> select min(f_price) as min_price from fruits;+-----------+| min_price |+-----------+| 2.20 |+-----------+1 row in set (0.00 sec)mysql> select s_id,min(f_price) as max_price from fruits group by s_id;+------+-----------+| s_id | max_price |+------+-----------+| 101 | 3.20 || 102 | 5.30 || 103 | 2.20 || 104 | 6.40 || 105 | 2.60 || 106 | 15.70 || 107 | 3.60 |+------+-----------+7 rows in set (0.00 sec) 连接查询 连接是关系数据库模型的主要特点。连接查询是关系数据库中最主要的查询，主要包括内连接、外连接。通过连接运算符可以实现多个表查询。在关系数据库管理系统中，表建立时各数据之间的关系不必确定，常把一个实体的所有信息存放在一个表中。当查询数据时，通过连接操作查询出存放在多个表中的不同实体的信息。当两个或多个表现中存在相同意义的字段时，便可以通过这些字段对不同的表进行连接查询。 1、内连接查询 内连接（inner join）使用比较运算符进行表间某些列数据的比较操作，并列出这些表中与连接条件相匹配的数据行，组合成新纪录，也就是说，在内连接查询中，只有满足条件的记录才能出现在结果关系中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344mysql> create table suppliers-> (-> s_id int not null auto_increment,-> s_name char(50) not null,-> s_city char(50) null,-> s_zip char(10) null,-> s_call char(50) not null,-> primary key(s_id)-> );Query OK, 0 rows affected (0.02 sec)mysql> insert into suppliers(s_id,s_name,s_city,s_zip,s_call)-> values(101,'FastFruit Inc.','tianjin','300000','48075'),-> (102,'LT Supplies','chongqing','400000','44333'),-> (103,'acme','shanghai','200000','90046'),-> (104,'fnk inc.','zhongshan','528437','11111'),-> (105,'good set','taiyuang','030000','22222'),-> (106,'just eat ours','beijing','010','45678'),-> (107,'dk inc.','zhengzhou','450000','33332');Query OK, 7 rows affected (0.01 sec)Records: 7 Duplicates: 0 Warnings: 0mysql> select suppliers.s_id,s_name,f_name,f_price-> from fruits ,suppliers-> where fruits.s_id &#x3D; suppliers.s_id;+------+----------------+------------+---------+| s_id | s_name | f_name | f_price |+------+----------------+------------+---------+| 101 | FastFruit Inc. | apple | 5.20 || 103 | acme | apricot | 2.20 || 101 | FastFruit Inc. | blackberry | 10.20 || 104 | fnk inc. | berry | 7.60 || 107 | dk inc. | xxxx | 3.60 || 102 | LT Supplies | orange | 11.20 || 105 | good set | melon | 8.20 || 101 | FastFruit Inc. | cherry | 3.20 || 104 | fnk inc. | lemon | 6.40 || 106 | just eat ours | mango | 15.70 || 105 | good set | xbabay | 2.60 || 105 | good set | xxtt | 11.60 || 103 | acme | coconut | 9.20 || 102 | LT Supplies | banana | 10.30 || 102 | LT Supplies | grape | 5.30 || 107 | dk inc. | xbababa | 3.60 |+------+----------------+------------+---------+16 rows in set (0.00 sec) 如果在一个连接查询中，涉及的两个表都是同一个表，这种查询称为自连接查询。自连接是一种特殊的内连接，它是指相互连接的表在物理上为同一张表，但可以在逻辑上分为两张表 。 1234567891011mysql> select f1.f_id,f1.f_name-> from fruits as f1, fruits as f2-> where f1.s_id &#x3D; f2.s_id and f2.f_id &#x3D; 'a1';+------+------------+| f_id | f_name |+------+------------+| a1 | apple || b1 | blackberry || c0 | cherry |+------+------------+3 rows in set (0.00 sec) 2、外连接查询 外连接查询将将查询多个表中相关联的行，内连接时，返回查询结果集合中的仅是符合查询条件和连接条件的行。但有时候需要包含没有关联的行中数据，即返回查询结果集合中的不仅包含符合连接条件的行，而且还包含左表（左外连接或左连接）、右表（右外连接或右连接）或两个连接表（全外连接）中的所有数据行。外连接分为左外连接或左连接和右外连接或右连接。 Left join（左连接）：返回包括左表中的所有记录和右表中连接字段相等的记录。 Right join（右连接）：返回包括右表中的所有记录和左表中连接字段相等的记录。 123456789# 左连接select * from student sLEFT JOIN grade gon s.gradeId &#x3D; g.gradeID;# 右连接select * from student sRIGHT JOIN grade gon s.gradeId &#x3D; g.gradeID; ![image-20200613134628052](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613134628052.png) 创建表 123456789101112131415161718192021222324create table orders( o_num int not null auto_increment, o_date datetime not null, c_id int not null, primary key(o_num));insert into orders(o_num,o_date,c_id)values(30001,'2008-09-01',10001),(30002,'2008-09-12',10003),(30003,'2008-09-30',10004),(30004,'2008-10-03',10005),(30005,'2008-10-08',10001);create table customers( c_id int not null auto_increment, c_name char(50) not null, c_address char(50) null, c_city char(50) null, c_zip char(50) null, c_contact char(50) null, c_email char(50) null, primary key(c_id)); 插入数据 123456789insert into customers(c_id,c_name,c_address,c_city,c_zip,c_contact,c_email)values(10001,'RedHook','200Street','Tianjin','300000','LiMing','LMing@163.com'),(10002,'Stars','333 Fromage Lane','Dalian','116000','Zhangbo','Jerry@hotmail.com'),(10003,'Netbhood','1 Sunny Place','Qingdao','266000','LuoCong',NULL),(10004,'JOTO','829 Riverside Drive', 'Haikou','570000','YangShan','sam@hotmail.com');select * from customers;select * from orders; ![image-20200613135037758](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613135037758.png) ![image-20200613135042714](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200613135042714.png) （1）左连接 1234# 左外连接select c.c_id,o.o_num from customers cLEFT OUTER JOIN orders oon c.c_id &#x3D; o.c_id; ![image-20200610151134872](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610151134872.png) （2）右连接 1234# 右外连接select c.c_id,o.o_num from customers cRIGHT OUTER JOIN orders oon c.c_id &#x3D; o.c_id; ![image-20200610151240505](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610151240505.png) 3、复合条件连接查询 复合条件连接查询是在连接查询的过程中，通过添加过滤条件，限制查询的结果，使查询的结果更加准确。 1234select c.c_id,o.o_num from customers cLEFT OUTER JOIN orders oon c.c_id &#x3D; o.c_idand c.c_id&#x3D;10001; ![image-20200610152148735](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610152148735.png) 4、编写SQL语句，查看年龄比“李斯文”小的学生，要求显示这些学生的信息 ![image-20200610162453310](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610162453310.png) 第一步:查询得到“李斯文”的出生日期 第二步:利用WHERE语句，筛选出生日期比“李斯文”大的学生 123# 请查找出年龄比李斯文小的学生select bornDate from studentwhere studentName &#x3D; '李斯文'; ![image-20200610163928028](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610163928028.png) 12select studentName,bornDate from studentwhere bornDate>'1993-07-23'; ![image-20200610163937508](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610163937508.png) 12345select studentName,bornDate from studentwhere bornDate>( select bornDate from student where studentName &#x3D; '李斯文'); ![image-20200610163937508](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610163937508.png) 1234567891011DROP TABLE IF EXISTS 666;create database &#96;666&#96;;use &#96;666&#96;drop table if exists &#96;t&#96;;CREATE TABLE &#96;ttt&#96;(true&#96;sid&#96; int (4) not null PRIMARY KEY, &#96;sname&#96; VARCHAR(20) not null)CHARSET &#x3D; 'utf8mb4';select * from ttt ![image-20200610165549705](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200610165549705.png) 12345create table tb1(truenum1 int not null);insert into tb1 values(1),(5),(13),(27);select * from tb1; ![image-20200611161645057](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200611161645057.png) 12345create table tb2(truenum2 int not null);insert into tb2 values(6),(14),(11),(20);select * from tb2; ![image-20200611161650169](G:\\四期\\数据库\\mysql文档\\05 mysql高级查询.assets\\image-20200611161650169.png)","path":"posts/98ba.html","date":"06-05","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL数据插入和复制","text":"一、DML语句(增删改) 插入数据的个数和类型要与表结构保持一致 1、插入单条数据记录 语法： 1INSERT INTO 表名 [(字段名列表)] VALUES (值列表); 注意： 1234字段名是可选的，如省略则依次插入所有字段多个列表和多个值之间使用逗号分隔值列表和字段名列表一一对应如插入的是表中部分数据，字段名列表必填 示例： 123456789# 插入单条数据insert into student(sid,sname,gradeID)VALUES(1002,'徐淑丽',2);insert into studentVALUES(1003,'孙子涵',1);insert into grade(gradeID,graedName)values(4,'云计算'); 查看一下 2、插入多条数据记录 语法： 12INSERT INTO 新表（字段名列表）VALUES(值列表1),(值列表2),……,(值列表n); 示例： 123# 插入多条数据insert into student(sid,sname,gradeID)VALUES(1005,'王永义',3),(1006,'包晓艺',2),(1007,'黑瓜子',1); 经验： 1为避免表结构发生变化引发的错误，建议插入数据时写明具体字段名！ 3、将查询结果插入新表 （1）事先创建新表且与插入数据字段相符 123INSERT INTO 新表（字段1,字段2……） SELECT字段1，字段2……FROM 原表; （2）无需事先创建新表 123CREATE TABLE 新表（SELECT 字段1，字段2……FROM 原表）; （3）练习 编写SQL语句实现从学生表提取姓名、手机号两列数据存储到通讯录表中。 &lt;1&gt;不需要事先创建表 123create table copy_grade(trueselect * from grade); &lt;2&gt;事先创建表 1234567create TABLE c_grade(true&#96;id&#96; int(4) not null,true&#96;name&#96; VARCHAR(20) not null);insert into c_grade(id,name)SELECT * from grade; 查看一下 4、更新数据记录 语法： 123UPDATE 表名 SET 字段1&#x3D;值1,字段2&#x3D;值2,…,字段n&#x3D;值n [WHERE 条件]; 示例1 1234567# 更新数据update c_gradeset name &#x3D; '高级运维'where id &#x3D; 4# where条件一 定要设置，否则会修改所有的列SELECT * from c_grade 查看一下 示例2 12345UPDATE studentset gradeID&#x3D;2,sex&#x3D;'女'where sid&#x3D;1002;SELECT * from student 查看一下 分析一下 5、删除数据记录 语法： 12DELETE FROM 表名 [WHERE条件];TRUNCATE TABLE 表名; 注意： 1TRUNCATE语句删除后将重置自增列，表结构及其字段、约束、索引保持不变，执行速度比DELETE语句快 示例 1234567# DELETE不能 重置自增列DELETE from c_grade WHERE id&#x3D;1;SELECT * from c_grade;# truncate能够 重置自增列truncate table c_grade;SELECT * from c_grade; 小结 MySQL中如何使用一条INSERT语句插入多条数据? 12INSERT INTO 表名(字段一,字段二,)VALUES(数据一,'数据二'); MySQL中将查询结果集插入新表的两种方式是什么?两者的区别是什么? 1234567不需要实现创建表,将查询结果插入新表create table 新表名称( select * from 需要查询的表); 需要提前创建表 INSERT into 提前创建好的表名称() select * from 需要查询的表； 删除数据时使用DEL ETE和TRUNCATE的区别是什么? 12删除表内数据，不会重置自增列删除表内出局，也会重置自增列 二、DQL语句（查询） 1、通用查询 语法： 123456SELECT FROM [WHERE ][GROUP BY ][HAVING ][ORDER BY [ASC 或 DESC]] 示例： 1234SELECT &#96;studentNo&#96;,&#96;studentName&#96;,&#96;phone&#96;,&#96;address&#96;,&#96;bornDate&#96; FROM &#96;student&#96;WHERE &#96;gradeId&#96; &#x3D; 1ORDER BY studentNo; （1）把student中男和女的个数分别显示出来 1234SELECT count(1) from student#where sname&#x3D;'黑瓜子';GROUP BY sex#HAVING sex&#x3D;'男' ; （2）排序 123SELECT * from student-- order by sid asc;order by sid desc; 2、LIMIT子句 MySQL查询语句中使用LIMIT子句限制结果集。 语法： 123456SELECT FROM [WHERE ][GROUP BY ][ORDER BY [ASC 或 DESC]][LIMIT [位置偏移量, ]行数]; 示例： 12SELECT * from studentlimit 4,3; 注意： 1使用LIMIT子句时，注意第1条记录的位置是0！ 3、常用函数 （1）聚合函数 函数名 作用 count() 返回某字段的行数 avg() 返回某字段的平均值 max() 返回某字段的最大值 min() 返回某字段的最小值 sum() 返回某字段的和 （2）字符串函数 函数名 作用 示例 LENGTH(str) 计算字符串长度 SELECT LENGTH(‘date’); CONCAT(str1,str2,…) 字符串合并 select CONCAT(‘a’,‘b’,‘c’) INSERT(str,pos,len,newstr) 字符串替换 select INSERT(‘old string’,1,3,‘letter’) LOWER(str) 将字符串转换为小写 select LOWER(‘A’) UPPER(str) 将字符串转换为大写 select UPPER(‘a’) LEFT(s,n) 返回字符串 s 开始的最左边 n 个字符 SELECT LEFT(‘hello’,2); RIGHT(s,n) 返回字符串 s 开始的最右边 n 个字符 SELECT RIGHT(‘hello word!’,5); LPAD(s1,len,s2) 返回字符串 s1 ，其左边由字符串 s2填充到 len 字符长度，如果 s1 的长度大于 len ，则返回值被缩短至 len 长度 SELECT RPAD(‘hello’,4,’?’); RPAD(s1,len,s2) 返回字符串 s1 ，其右边由字符串 s2 填充到 len 字符长度，如果 s1 的长度大于 len ，则返回值被缩短至 len 长度 SELECT RPAD(‘hello’,10,’?’); LTRIM(s) 用于删除字符串 s 左侧的空格 SELECT LTRIM(’ book '); RTRIM(s) 用于删除字符串 s 右侧的空格 SELECT RTRIM(’ book '); TRIM(s) 用于删除字符串 s 两侧的空格 SELECT TRIM(’ book '); TRIM(s1 FROM s) 删除指定字符串的函数 SELECT TRIM(‘xy’ FROM ‘xyxyabcxy’); REPEAT(s,n) 用于重复字符串 s ，n 表示重复多少次 SELECT REPEAT(‘mysql’,3); SPACE(n) 用于返回 n 个空格 SELECT SPACE(20); REPLACE(s,s1,s2) 使用字符串 s2 替换字符串 s 中所有的字符串 s1 SELECT REPLACE(‘xxx.mysql.com’, ‘x’, ‘w’); STRCMP(s1,s2) 用于比较字符串 s1 和 s2 的大小，若所有字符串相同则返回 0 ，若第一个字符串大于第二个字符串则返回 1 ，若第一个字符串小于第二个字符串则返回 -1 SELECT STRCMP(‘txt’, ‘txt2’), STRCMP(‘txt’, ‘txt’); SUBSTRING(str,num,len) 获取指定位置的子字符串 select SUBSTRING(‘JavaMysqlOracle’,5,5); MID(s,n,len) 用于获取指定位置的子字符串 SELECT MID(‘breakfast’,5); LOCATE(str1,str) 返回字符串 str1 在字符串 str 中的开始位置 SELECT LOCATE(‘ball’, ‘football’); POSITION(str1 IN str) 返回字符串 str1 在字符串 str 中的开始位置 SELECT POSITION(‘ball’ IN ‘football’); INSTR(str, str1) 返回子字符串 str1 在字符串 str 中的开始位置 SELECT INSTR(‘football’, ‘ball’); REVERSE(s) 将字符串 s 反转 SELECT REVERSE(‘abcd’); ELT(n, s1, s2, s3, …) 返回第 n 个字符串，如果 n超出范围则返回 NULL SELECT ELT(3, ‘a’, ‘b’, ‘c’, ‘d’); FIELD(s, s1, s2, …) 返回字符串 s 在列表 s1, s2, … 中的位置，如果不存在字符串 s 则返回 0 ，如果字符串 s 是 NULL 也返回 0 SELECT FIELD(‘hi’, ‘hihi’, ‘hey’, ‘hi’, ‘bas’); FIND_IN_SET(s1, s2) 返回字符串 s1 在字符串列表 s2中的位置 SELECT FIND_IN_SET(‘hi’, ‘hihi,hey,hi,bas’); 12# 字符串连接select CONCAT('a','b','c') ![image-20200608142620041](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142620041.png) 12# 字符串替换select INSERT('old string',1,3,'letter') ![image-20200608142655908](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142655908.png) 12# 字符串转小写select LOWER('A') ![image-20200608142815767](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142815767.png) 12# 字符串转大写select LOWER('a') ![image-20200608142830810](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142830810.png) 12# 字符串截取select SUBSTRING('JavaMysqlOracle',5,5) ![image-20200608142956979](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200608142956979.png) （3）时间日期函数 函数名 作用 示例 CURDATE() 获取当前日期 select CURDATE(); CURTIME() 获取当前时间 select CURTIME(); CURRENT_TIMESTAMP() 、.LOCALTIME() 、NOW() 、SYSDATE()CURRENT_TIMESTAMP() 获取当前日期和时间 select NOW(); UNIX_TIMESTAMP() 获取 UNIX 格式的时间戳 SELECT UNIX_TIMESTAMP(); FROM_UNIXTIME() 将 UNIX 格式的时间戳转换为普通格式的时间 SELECT FROM_UNIXTIME(‘1495542689’); UTC_DATE() UTC_DATE() 获取当前 UTC (世界标准时间) 日期值 SELECT UTC_DATE(); UTC_TIME() UTC_TIME() 获取当前 UTC (世界标准时间) 时间值 SELECT UTC_TIME(); YEAR(date) 返回日期date的年份 select YEAR(NOW()); QUARTER(date) 返回日期date为一年中第几季度 select QUARTER(NOW()); MONTH(date) 返回日期date的月份 select MONTH(NOW()); WEEK(date) 返回日期date为一年中第几周 select WEEK(NOW()); DAY(date) 返回日期date的日期 select DAY(NOW()); DAYOFYEAR(date) 返回 date 是一年中的第几天，一年有 365 天 SELECT DAYOFYEAR(‘2017-05-23’); DAYOFMONTH(date) 计算 date 是一个月中的第几天 SELECT DAYOFMONTH(‘2017-05-23’); HOUR(time) 返回日期date的小时 select HOUR(NOW()); MINUTE(time) 返回日期date的分钟 select MINUTE(NOW()); SECOND(time) 返回日期date的秒 select SECOND(NOW()); TIME_TO_SEC(time) 将 time 转换为秒钟，公式为 &quot; 小时3600 + 分钟60 + 秒 &quot; SELECT TIME_TO_SEC(‘23:23:00’); SEC_TO_TIME(time) 将秒值转换为时间格式 SELECT SEC_TO_TIME(‘84180’); DATEDIFF(date1,date2) 返回日期date的date1和date2间隔的天数 select DATEDIFF(NOW(),‘2020-06-07’); ADDDATE(date,n) 计算日期date加上n天以后在日期 select ADDDATE(NOW(),3); DATE_FORMAT(date, format) 格式化日期，即根据 format 指定的格式显示 date 值 SELECT DATE_FORMAT(‘1997-10-04 22:23:00’, ‘%W %M %Y’); TIME_FORMAT(time, format) 格式化时间，即根据 format 指定的格式显示 time 值 SELECT TIME_FORMAT(‘16:00:00’, ‘%H %k %I’); GET_FORMAT() 指定值类型和格式化类型，然后会显示成格式字符串 SELECT DATE_FORMAT(‘2000-10-05 22:23:00’, GET_FORMAT(DATE,‘USA’)); 参考内容： 12345678910111213141516171819202122232425262728# 当前的日期select CURDATE();# 当前的时间select CURTIME();# 当前的日期和时间select NOW();# 年select YEAR(NOW());# 月select MONTH(NOW());# 日select DAY(NOW());# 星期select WEEK(NOW());# 时select HOUR(NOW());# 分select MINUTE(NOW());# 秒select SECOND(NOW());# 计算从2020&#x2F;1&#x2F;&#x2F;1 到 2020&#x2F;6&#x2F;8 有多少天select DATEDIFF(now(),'2020-01-01')# 三天后的现在select adddate(now(),3) （4）数学函数 函数名 作用 示例 ABS(x) 绝对值函数 SELECT ABS(-2); PI() 返回圆周率的函数 SELECT PI(); SQRT(x) 平方根函数，返回非负数二次方根 SELECT SQRT(9); CEIL(x) 向上取整 SELECT CEIL(2.1); FLOOR(x) 向下取整 SELECT FLOOR(2.5); RAND(x) 返回一个随机浮点值，范围在 0 ~ 1 之间 SELECT RAND(); ROUND(x) 对x进行四舍五入 SELECT ROUND(-1.34); ROUND(x,y) 对x进行四舍五入，并且保留小数点后y位 SELECT ROUND(1.37,1); TRUNCATE(x,y) 对x进行截取，结果保留小数点后y位 SELECT TRUNCATE(1.31,1); POW(x,y) 返回 x 的 y 次方的结果 SELECT POW(2,4); 12345678# 只要有小数就往整数进一位select ceil(3.01)# 只要整数部位select FLOOR(3.91);# 随机数select rand(); （5）系统信息函数 函数名 作用 示例 VERSION() 获取 MySQL 版本号 SELECT VERSION(); CHARSET(str) 查看字符串 str 的字符集 SELECT CHARSET(‘abc’); COLLATION(str) 查看字符串 str 的字符排列方式 SELECT COLLATION(‘abc’); LAST_INSERT_ID() 获取最后一个自动生成的ID 值 SELECT LAST_INSERT_ID(); USER() 、CURRENT_USER() 、SYSTEM_USER() 返回当前登录的用户及主机名 SELECT USER();SELECT CURRENT_USER();SELECT SYSTEM_USER(); CONNECTION_ID() 查看当前用户的连接数的ID SELECT CONNECTION_ID(); DATABASE()、SCHEMA() 查看当前使用的数据库 SELECT DATABASE();SELECT SCHEMA(); SHOW PROCESSLIST 查看当前用户的连接信息 SHOW PROCESSLIST; CONNECTION_ID()函数的参数 123456781. Id ：用户登录 MySQL 时，系统分配的连接 id2. User ：当前连接的用户3. Host ：显示这个语句是从哪个 IP 的哪个端口上发出的，可以用来追踪出现问题语句的用户4. db ：显示这个进程目前连接的是哪个数据库5. Command ：显示当前连接执行的命令，一般取值为休眠(Sleep)、查询(Query)、连接(Connect)6. Time ：显示这个状态持续的时间，单位是秒7. State ：显示使用当前连接的 SQL 语句的状态8. Info ：显示这个 SQL 语句 示例1： 1234567891011121314151617181920# 查看MySQL版本select VERSION();# 查看数据库连接的ID# 查看MySQL connection id连接id# 对于已经建立的连接的客户端，都有一个唯一的连接ID。select CONNECTION_ID();# 查看MySQL接口SHOW PROCESSLIST;use mysql;# 查看当前数据库select database();SELECT SCHEMA();# 查看当前用户select user();# 查看当前日期select CURRENT_DATE();# 查看当前用户select SYSTEM_USER(); 示例2： 12345678create table worker(trueid int auto_increment PRIMARY key,truename VARCHAR(30))CHARSET&#x3D;utf8mb4;insert into worker(name) VALUES('xxx');insert into worker(name) VALUES('yyy');select LAST_INSERT_ID(); （6）条件判断函数 函数 作用 示例 IF() IF(expr, v1, v2) 如果表达式 expr 为 TRUE ，则返回值为 v1 ，否则返回 v2 SELECT IF(1&gt;2, 2, 3); IFNULL() IFNULL(v1, v2) 如果 v1 不为 NULL ，则返回值为 v1 ；如果 v1 为 NULL ，则返回值为 v2 SELECT IFNULL(1,2), IFNULL(NULL,10); CASE expr WHEN v1 THEN r1 [WHEN v2 THEN r2] [ELSE rn] END 如果 expr 等于某个 vn，则返回对应位置 THEN 后面的结果，如果与所有值都不相等，则返回 ELSE 后面的 rn SELECT CASE 2 WHEN 1 THEN ‘one’ WHEN 2 THEN ‘two’ ELSE ‘more’ END; （7）加密/解密函数 函数 作用 示例 PASSWORD(str) 从明文密码 str 计算并返回加密后的密码字符串，当参数为 NULL 时，返回 NULL SELECT PASSWORD(‘newpwd’); MD5(str) 为字符串 str 算出一个 MD5 128 比特校验值 SELECT MD5(‘newpwd’); ENCODE(str, pswd_str) 使用 pswd_str 作为密码，加密 str SELECT ENCODE(‘secret’, ‘newpwd’); DECODE(crypt_str, pswd_str) 使用 pswd_str 作为密码，解密加密字符串 crypt_str SELECT DECODE(ENCODE(‘secret’,‘cry’), ‘cry’); 加密 123select PASSWORD('123456');select MD5('123456');select ENCODE('123456','abc') 解密 1select DECODE(ENCODE('123456','abc'),'abc'); 示例 12select PASSWORD('123456');select BENCHMARK(500000，PASSWORD('123456')); （8）其它函数 函数 作用 示例 FORMAT(x, n) 将数字 x 格式化，并以四舍五入的方式保留小数点后 n 位，结果以字符串的形式返回 SELECT FORMAT(1.23456, 4); CONV() 不同进制数之间的转换 SELECT CONV(‘a’,16,2), # 将16进制的a转换为2进制SELECT CONV(15,10,2), # 将10进制的15转换为2进制SELECT CONV(15,10,8), # 将10进制的15转换为8进制SELECT CONV(15,10,16); # 将10进制的15转换为16进制 INET_ATON(expr) 将网络地址转换为一个代表该地址数值的整数 SELECT INET_ATON(‘192.168.1.1’); GET_LOCK(str, timeout) 使用字符串 str 来得到一个锁，持续时间 timeout 秒1. 若成功得到锁，则返回 12. 若操作超时，则返回 03. 若发生错误，则返回 NULL SELECT GET_LOCK(‘lock1’, 10); RELEASE_LOCAK(str) 用于解开被 GET_LOCK() 获取的，用字符串 str 所命名的锁1. 若锁被解开，则返回 12. 若该线程尚未创建锁，则返回 03. 若命名的锁不存在，则返回 NULL4. 若该锁从未被 GET_LOCK() 的调用获取，或锁已经被提前解开，则该锁不存在 SELECT RELEASE_LOCK(‘lock1’); IS_FREE_LOCK(str) 检查名为 str 的锁是否可以使用1. 若锁可以使用，则返回 12. 若锁正在被使用，则返回 03. 若出现错误，则返回 NULL SELECT IS_FREE_LOCK(‘lock1’); IS_USED_LOCK(str) 检查名为 str 的锁是否正在被使用，若被封锁，则返回使用该锁的客户端的连接标识符，否则返回 NULL SELECT IS_USED_LOCK(‘lock1’); BENCHMARK(count, expr) 用于重复 count 次执行表达式 expr1. 可以用于计算 MySQL 处理表达式的速度2. 可以在 MySQL 客户端内部报告语句执行的时间 SELECT PASSWORD(‘newpwd’);SELECT BENCHMARK( 500000, PASSWORD(‘newpwd’) ); CONVERT(… USING …) 用于改变字符串的默认字符集默认是utf8字符集 SELECT CHARSET(‘abc’);SELECT CHARSET(CONVERT(‘abc’ USING latin1)); CONVERT(x, type) 将一个数据类型的值转换为另一个数据类型的值 SELECT CONVERT(100, CHAR(2)); 示例1： 123select format(3.1415926,2);select format(3.14,4);select format(3.14,0); 示例2： 1234select CONV('a',16,2);select CONV(15,10,2);select CONV(15,10,8);select CONV(15,10,16); 示例3： 1select INET_ATON('192.168.79.160'); （7）数据类型转换百数 12345678910select if(1>2,'true','false');select IFNULL(null,2);select IFNULL(1,2);select case 2 when 1 then 'one' when 2 then 'two'else 'more'end; ![image-20200613115249566](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613115249566.png) 4、运算符 （1）算术运算符 运算符 作用 示例 + 加法 select 1+2; - 减法 select 1-2; * 乘法 select 2*5; /或DIV 除法 select 9/3; 或 select 9 DIV 3; %或MOD 取余 select 9%2; 或 select 9 MOD 2; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 算数运算符mysql> select 1+2;+-----+| 1+2 |+-----+| 3 |+-----+1 row in set (0.00 sec)mysql> select 3-5;+-----+| 3-5 |+-----+| -2 |+-----+1 row in set (0.00 sec)mysql> select 4*5;+-----+| 4*5 |+-----+| 20 |+-----+1 row in set (0.00 sec)mysql> select 5&#x2F;3;+--------+| 5&#x2F;3 |+--------+| 1.6667 |+--------+1 row in set (0.00 sec)mysql> select 5 DIV 3;+---------+| 5 DIV 3 |+---------+| 1 |+---------+1 row in set (0.00 sec)mysql> select 6%8;+------+| 6%8 |+------+| 6 |+------+1 row in set (0.00 sec) （2）比较运算符 SELECT 语句中的条件语句经常要使用比较运算符。 通过这些比较运算符，可以判断表中的哪些记录是符合条件的。比较结果为真，则返回 1，为假则返回 0，比较结果不确定则返回 NULL。 符号 描述 备注 = 等于 &lt;&gt;, != 不等于 &gt; 大于 &lt; 小于 &lt;= 小于等于 &gt;= 大于等于 BETWEEN 在两值之间 &gt;=min&amp;&amp;&lt;=max NOT BETWEEN 不在两值之间 IN 在集合中 NOT IN 不在集合中 &lt;=&gt; 严格比较两个NULL值是否相等 两个操作码均为NULL时，其所得值为1；而当一个操作码为NULL时，其所得值为0 LIKE 模糊匹配 REGEXP 或 RLIKE 正则式匹配 IS NULL 为空 IS NOT NULL 不为空 1）等于 1234567891011121314mysql> select 2&#x3D;3;+-----+| 2&#x3D;3 |+-----+| 0 |+-----+mysql> select NULL &#x3D; NULL;+-------------+| NULL &#x3D; NULL |+-------------+| NULL |+-------------+ 2）不等于 123456mysql> select 23;+------+| 23 |+------+| 1 |+------+ 3）安全等于 与 = 的区别在于当两个操作码均为 NULL 时，其所得值为 1 而不为 NULL，而当一个操作码为 NULL 时，其所得值为 0而不为 NULL。 12345678910111213141516171819202122mysql> select 23;+-------+| 23 |+-------+| 0 |+-------+mysql> select null&#x3D;null;+-----------+| null&#x3D;null |+-----------+| NULL |+-----------+ mysql> select nullnull;+-------------+| nullnull |+-------------+| 1 |+-------------+ 4）小于 123456mysql> select 23 |+-----+| 0 |+-----+ 7）大于等于 123456mysql> select 2>&#x3D;3;+------+| 2>&#x3D;3 |+------+| 0 |+------+ 8）BETWEEN 123456mysql> select 5 between 1 and 10;+--------------------+| 5 between 1 and 10 |+--------------------+| 1 |+--------------------+ 9）IN 123456mysql> select 5 in (1,2,3,4,5);+------------------+| 5 in (1,2,3,4,5) |+------------------+| 1 |+------------------+ 10）NOT IN 123456mysql> select 5 not in (1,2,3,4,5);+----------------------+| 5 not in (1,2,3,4,5) |+----------------------+| 0 |+----------------------+ 11）IS NULL 12345678910111213mysql> select null is NULL;+--------------+| null is NULL |+--------------+| 1 |+--------------+mysql> select 'a' is NULL;+-------------+| 'a' is NULL |+-------------+| 0 |+-------------+ 12）IS NOT NULL 1234567891011121314mysql> select null IS NOT NULL;+------------------+| null IS NOT NULL |+------------------+| 0 |+------------------+ mysql> select 'a' IS NOT NULL;+-----------------+| 'a' IS NOT NULL |+-----------------+| 1 |+-----------------+ 13、LIKE 12345678910111213mysql> select '12345' like '12%';+--------------------+| '12345' like '12%' |+--------------------+| 1 |+--------------------+mysql> select '12345' like '12_';+--------------------+| '12345' like '12_' |+--------------------+| 0 |+--------------------+ 14、REGEXP 12345678910111213mysql> select 'beijing' REGEXP 'jing';+-------------------------+| 'beijing' REGEXP 'jing' |+-------------------------+| 1 |+-------------------------+mysql> select 'beijing' REGEXP 'xi';+-----------------------+| 'beijing' REGEXP 'xi' |+-----------------------+| 0 |+-----------------------+ （3）逻辑运算符 逻辑运算符用来判断表达式的真假。如果表达式是真，结果返回 1。如果表达式是假，结果返回 0。 运算符号 作用 NOT 或 ! 逻辑非 AND 逻辑与 OR 逻辑或 XOR 逻辑异或 1）与 1234567891011121314mysql&gt; select 2 and 0;+---------+| 2 and 0 |+---------+| 0 |+---------+ mysql&gt; select 2 and 1; +---------+ | 2 and 1 | +---------+ | 1 | mysql&gt; select 2 and 0;+---------+| 2 and 0 |+---------+| 0 |+---------+ mysql&gt; select 2 and 1; +---------+ | 2 and 1 | +---------+ | 1 | +---------+ 2）或 123456789101112131415161718192021222324252627mysql&gt; select 2 or 0;+--------+| 2 or 0 |+--------+| 1 |+--------+mysql&gt; select 2 or 1;+--------+| 2 or 1 |+--------+| 1 |+--------+mysql&gt; select 0 or 0;+--------+| 0 or 0 |+--------+| 0 |+--------+mysql&gt; select 1 || 0;+--------+| 1 || 0 |+--------+| 1 |mysql&gt; select 2 or 0;+--------+| 2 or 0 |+--------+| 1 |+--------+mysql&gt; select 2 or 1;+--------+| 2 or 1 |+--------+| 1 |+--------+mysql&gt; select 0 or 0;+--------+| 0 or 0 |+--------+| 0 |+--------+mysql&gt; select 1 || 0;+--------+| 1 || 0 |+--------+| 1 |+--------+ 3）非 12345678910111213mysql&gt; select not 1;+-------+| not 1 |+-------+| 0 |+-------+mysql&gt; select !0;+----+| !0 |+----+| 1 |mysql&gt; select not 1;+-------+| not 1 |+-------+| 0 |+-------+mysql&gt; select !0;+----+| !0 |+----+| 1 |+----+ 4）异或（其他数字只能与0比较） 当任意一个操作数为NULL时,返回值为NULL，对于非NULL的操作数,如果两个的逻辑真假值相异，则返回结果为1，否则为0。 12345678910111213141516171819202122232425262728293031323334mysql&gt; select 1 xor 1;+---------+| 1 xor 1 |+---------+| 0 |+---------+mysql&gt; select 0 xor 0;+---------+| 0 xor 0 |+---------+| 0 |+---------+mysql&gt; select 1 xor 0;+---------+| 1 xor 0 |+---------+| 1 |+---------+mysql&gt; select null or 1;+-----------+| null or 1 |+-----------+| 1 |+-----------+mysql&gt; select 1 ^ 0;+-------+| 1 ^ 0 |+-------+| 1 |mysql&gt; select 1 xor 1;+---------+| 1 xor 1 |+---------+| 0 |+---------+mysql&gt; select 0 xor 0;+---------+| 0 xor 0 |+---------+| 0 |+---------+mysql&gt; select 1 xor 0;+---------+| 1 xor 0 |+---------+| 1 |+---------+mysql&gt; select null or 1;+-----------+| null or 1 |+-----------+| 1 |+-----------+mysql&gt; select 1 ^ 0;+-------+| 1 ^ 0 |+-------+| 1 |+-------+ （4）位运算符 位运算符是在二进制数上进行计算的运算符。位运算会先将操作数变成二进制数，进行位运算。然后再将计算结果从二进制数变回十进制数。 运算符号 作用 &amp; 按位与 | 按位或 ^ 按位异或 ! 取反 &lt;&lt; 左移 &gt;&gt; 右移 1）按位与 对应的二进制位都为 1 ，则该位的运算结果为 1 ，否则为 0。 123456mysql&gt; select 3&amp;5;+-----+| 3&amp;5 |+-----+| 1 |mysql&gt; select 3&amp;5;+-----+| 3&amp;5 |+-----+| 1 |+-----+ 2）按位或 对应的二进制位有一个或两个为 1 ，则该位的运算结果为 1 ，否则为 0。 12345678mysql&gt; SELECT 10 | 15 , 9 | 4 | 2 ;+---------+-----------+| 10 | 15 | 9 | 4 | 2 | # 10的二进制为1010,15的二进制为1111，按位或运算之后结果为1111，即15+---------+-----------+ # 9的二进制为1001,4为0100,2的二进制为0010，按位或运算之后1111| 15 | mysql&gt; SELECT 10 | 15 , 9 | 4 | 2 ;+---------+-----------+| 10 | 15 | 9 | 4 | 2 | # 10的二进制为1010,15的二进制为1111，按位或运算之后结果为1111，即15+---------+-----------+ # 9的二进制为1001,4为0100,2的二进制为0010，按位或运算之后1111| 15 | 15 |+---------+-----------+ 3）按位异或 对应的二进制位不相同时，结果为 1，否则为 0。 123456mysql&gt; select 3^5;+-----+| 3^5 |+-----+| 6 |mysql&gt; select 3^5;+-----+| 3^5 |+-----+| 6 |+-----+ 4）按位取反 将对应的二进制数逐位反转，即 1 取反后变 0 ，0 取反后变 1。 123456mysql&gt; select ~18446744073709551612;+-----------------------+| ~18446744073709551612 |+-----------------------+| 3 |mysql&gt; select ~18446744073709551612;+-----------------------+| ~18446744073709551612 |+-----------------------+| 3 |+-----------------------+ 5）按位右移 使指定的二进制位都右移指定的位数，右移指定位之后，右边低位的数值将被移出并丢弃，左边高位空出的职位用 0 补齐。 123456mysql&gt; select 3&gt;&gt;1;+------+| 3&gt;&gt;1 |+------+| 1 |mysql&gt; select 3&gt;&gt;1;+------+| 3&gt;&gt;1 |+------+| 1 |+------+ 6）按位左移 使指定的二进制位都左移指定的位数，左移指定位之后，左边高位的数值将被移出并丢弃，右边低位空出的位置用 0 补齐。 123456mysql&gt; select 3&lt;&lt;1;+------+| 3&lt;&lt;1 |+------+| 6 |mysql&gt; select 3&lt;&lt;1;+------+| 3&lt;&lt;1 |+------+| 6 |+------+ （5）运算符优先级 最低优先级为： :=。 ![image-20200613115948741](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613115948741.png) 最高优先级为： !、BINARY、 COLLATE。 三、小练习 1、导入数据库 ![image-20200609171913909](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609171913909.png) ![image-20200609171943656](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609171943656.png) ![image-20200609172002895](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172002895.png) 2、grade添加数据 ![image-20200609172219791](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172219791.png) 1234select * from student;select studentNo as 学号,studentName as 姓名,sex as 性别,gradeId as 年级编号,bornDate as 出生日期from student; ![image-20200609172714342](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172714342.png) ![image-20200609172657559](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172657559.png) ![image-20200609172730224](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609172730224.png) 3、两表联查 12345# 两表联查select * from grade;select * from student,grade;select * from student,grade where grade.gradeID &#x3D; student.gradeId; ![image-20200613123717083](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613123717083.png) 示例1： 123456789# 逗号+WHEREselect studentNo as 学号,studentName as 姓名,sex as 性别,gradeName as 年级,bornDate as 出生日期from student as s,grade as gwhere g.gradeID &#x3D; s.gradeId; ![image-20200609173647871](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200609173647871.png) 示例2： 12345678910# join+onselect studentNo as 学号,studentName as 姓名,sex as 性别,gradeName as 年级,bornDate as 出生日期from student as sjoin grade as gon g.gradeID &#x3D; s.gradeId; ![image-20200613123857349](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613123857349.png) 4、模糊查询某学生的信息 12345# 查询某学生的信息select * from student where studentName &#x3D; '郭靖';select * from student where studentName like '%郭%';select * from student where studentName like '%靖';select * from student where studentName like '郭%'; ![image-20200613124019868](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124019868.png) 5、排序 降序 12# 降序select * from student ORDER BY studentNo desc; ![image-20200613124251255](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124251255.png) 升序 12# 升序select * from student ORDER BY studentNo asc; ![image-20200613124257120](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124257120.png) 6、分组 12# 分组: 只有聚会的数和参与了分组的字段能够出现在select语句后面select sex,count(1) from student GROUP BY sex; ![image-20200613124341995](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124341995.png) 12345# 分组后再筛选数据select count(1),sexfrom studentGROUP BY sexhaving sex&#x3D;'男'; ![image-20200613124412250](G:\\四期\\数据库\\mysql文档\\04 MySQL数据插入和复制.assets\\image-20200613124412250.png) 123456789101112131415161718192021222324252627282930313233343536373839404142434445# ANDselect * from student where sex&#x3D;'男' and studentName&#x3D;'李文才';+-----------+----------+-------------+-----+---------+-------------+----------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+----------+---------------------+-------+--------------+| 10001 | 123 | 李文才 | 男 | 1 | 13645667890 | 地址不详 | 1994-04-12 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+----------+---------------------+-------+--------------+1 row in set (0.00 sec)# ORselect * from student where sex&#x3D;'男' or studentName&#x3D;'李文才';+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+| 10000 | 123 | 郭靖 | 男 | 1 | 13645667783 | 天津市河西区 | 1990-09-08 00:00:00 | NULL | NULL || 10001 | 123 | 李文才 | 男 | 1 | 13645667890 | 地址不详 | 1994-04-12 00:00:00 | NULL | NULL || 10002 | 123 | 李斯文 | 男 | 1 | 13645556793 | 河南洛阳 | 1993-07-23 00:00:00 | NULL | NULL || 10007 | 123 | 秦洋 | 男 | 1 | 13056434411 | 上海市卢湾区 | 1992-04-18 00:00:00 | NULL | NULL || 20000 | 123 | 王宝宝 | 男 | 2 | 15076552323 | 地址不详 | 1996-06-05 00:00:00 | NULL | NULL || 30011 | 123 | 陈志强 | 男 | 3 | 13689965430 | 地址不详 | 1994-09-27 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+--------------+---------------------+-------+--------------+# &#x3D;select * from student where sex'男';+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+| studentNo | loginPwd | studentName | sex | gradeId | phone | address | bornDate | email | identityCard |+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+| 10003 | 123 | 张萍 | 女 | 1 | 13642345112 | 地址不详 | 1995-06-10 00:00:00 | NULL | NULL || 10004 | 123 | 韩秋洁 | 女 | 1 | 13812344566 | 北京市海淀区 | 1995-07-15 00:00:00 | NULL | NULL || 10005 | 123 | 张秋丽 | 女 | 1 | 13567893246 | 北京市东城区 | 1994-01-17 00:00:00 | NULL | NULL || 10006 | 123 | 肖梅 | 女 | 1 | 13563456721 | 河北省石家庄市 | 1991-02-17 00:00:00 | NULL | NULL || 10008 | 123 | 何睛睛 | 女 | 1 | 13053445221 | 广州市天河区 | 1997-07-23 00:00:00 | NULL | NULL || 20010 | 123 | 何小华 | 女 | 2 | 13318877954 | 地址不详 | 1995-09-10 00:00:00 | NULL | NULL || 30012 | 123 | 李露露 | 女 | 3 | 13685678854 | 地址不详 | 1992-09-27 00:00:00 | NULL | NULL |+-----------+----------+-------------+-----+---------+-------------+----------------+---------------------+-------+--------------+7 rows in set (0.00 sec)# select * from student where bornDate","path":"posts/e5cc.html","date":"06-04","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"mysql的增删改查","text":"MySQL高级查询 学习目的 使用SQL语句为成绩表添加主、外键 使用SQL语句实现数据添加、修改、查询 查询指定学生考试成绩 查询某学期开设的课程 查询某课程最近一次考试缺考的学生名单 一、RDBMS 术语 数据库: 数据库是一些关联表的集合。 数据表: 表是数据的矩阵。在一个数据库中的表看起来像一个简单的电子表格。 列: 一列(数据元素) 包含了相同的数据, 例如邮政编码的数据。 行：一行（=元组，或记录）是一组相关的数据，例如一条用户订阅的数据。 冗余：存储两倍数据，冗余可以使系统速度更快。 主键：主键是唯一的。一个数据表中只能包含一个主键。你可以使用主键来查询数据。 外键：外键用于关联两个表。 复合键：复合键（组合键）将多个列作为一个索引键，一般用于复合索引。 索引：使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或多列的值进行排序的一种结构。类似于书籍的目录。 参照完整性: 参照的完整性要求关系中不允许引用不存在的实体。与实体完整性是关系模型必须满足的完整性约束条件，目的是保证数据的一致性。 数据库的主键代表了唯一标示一条数据，所以主键是唯一的，比如学号，卡号之类的； 数据库的外键是为了保证数据库的一致性，假设表1中的一个外键是表2的主键，此时要在表2中插入一条数据时就必须查看（这条数据，也就是表2的那个主键的信息在表1中是否存在，如果不存在则无法插入），而当你需要在表1中删除一条信息是，如果在表2中还存在这个数据的话也是无法直接删除的。 二、增删改查操作 1、创建一个操作表 1234567891011#创建数据库cerate database test_mysql;#进入数据库use test_mysql;#创建表CREATE TABLE &#96;ttt&#96;(true&#96;sid&#96; int(4) not null key auto_increment,true&#96;sname&#96; varchar(20) default'姓名不详' not null) 查看一下 1desc ttt; 2、修改表名 语法： 1alter table 旧表名 rename 新表名; 操作 12# 修改表名alter table ttt rename teacher; 查看一下 12#查看表show tables; 3、添加列 语法 12# 添加字段alter table 表名 add 字段名 数据类型[属性]; 操作 12#添加列alter table teacher add &#96;sex&#96; char(2); 查看一下 1desc teacher; 4、修改列 语法 12# 修改字段alter table 表名 CHANGE 原字段名 新字段名 数据类型[属性]; 操作 12#修改列中 sex修改为gender 类型改为char(2)alter table teacher CHANGE &#96;sex&#96; &#96;gender&#96; char(2); 查看一下 12#查看表内容desc teacher; 4、删除字段 语法 12# 删除字段alter table 表名 drop 字段名; 操作 1alter table teacher drop gender; 查看一下 12#查看表内容desc teacher; 三、主键和外键 1、SQL 的主键和外键的作用： 12345外键取值规则：空值或参照的主键值(1)插入非空值时，如果主键值中没有这个值，则不能插入。(2)更新时，不能改为主键表中没有的值。(3)删除主键表记录时，可以在建外键时选定外键记录一起联删除还是拒绝删除。(4)更新主键记录时，同样有级联更新和拒绝执行的选择。 2、创建一个表 1234create table grade(true&#96;gradeID&#96; int(4) not null,true&#96;gredName&#96; varchar(20) not null); 查看一下 1desc grade; 3、创建主键 （1）语法 12ALTER TABLE 表名 ADD CONSTRAINT主键名PRIMARY KEY 表名(主键字段); （2）创建 12alter table grade add CONSTRAINT pk_gradePRIMARY key grage(&#96;gradeID&#96;); 查看一下 1desc grade; 4、添加外键 外键（从表）：可以增加数据的完整性与准确性 （1）语法 123ALTER TABLE 表名 ADD CONSTRAINT 外键名FOREIGN KEY (外键字段)REFERENCES 关联表名 (关联字段) ; （2）创建一个表 123456create table student(true&#96;sid&#96; int(4) not null PRIMARY KEY,true&#96;sname&#96; VARCHAR(50) not null,true&#96;gradeID&#96; int(4) not null, &#96;sex&#96; char(2) comment '性别',); 查看一下 1desc student; （3）创建外键 123alter table student add CONSTRAINT fk_student_gradeFOREIGN KEY (&#96;gradeID&#96;)REFERENCES &#96;grade&#96;(&#96;gradeID&#96;); 查看一下 5、测试 （1）grade表添加内容 （2）student表添加内容 所以我们添加数值不要超过主表设置的默认值。 四、练习 1、需求说明 在test数据库中创建person表 字段名称 字段说明 数据类型 长度 属性 number 序号 INT 4 自增列 name 姓名 VARCHAR 50 非空 sex 性别 CHAR 2 bornDate 出生日期 DATETIME 将表名修改为tb_person 删除出生日期字段 添加出生日期字段, 数据类型为DATE类型 修改序号字段名(number) 为id,类型为BIGINT类型 123456789101112131415161718create table person(true&#96;number&#96; int(4) comment '序号' key auto_increment, &#96;name&#96; varchar(50) comment '姓名' not null, &#96;sex&#96; char(2) comment '性别', &#96;bornDarte&#96; datetime(0) comment '出生日期');# 修改表名alter table person rename tb_person;# 删除字段alter table tb_person drop &#96;bornDarte&#96;;# 添加列alter table tb_person add &#96;bornDarte&#96; date;# 修改表中字段名alter table tb_person change number id bigint;# 查看表结构desc tb_person; 2、需求说明 result表需要添加的内容 主键约束:学号、课程编号和日期构成组合主键. 外键约束:主表student和从表result通过studentNo字段建立主外键关联 1234567891011121314151617181920212223# 主键create table result(true&#96;studentNo&#96; int(4) comment '学号',true&#96;subjedctNo&#96; int(4) comment '课程编号',true&#96;examDate&#96; datetime comment ' 日期')charset&#x3D;'utf8';alter table result add CONSTRAINT PK_resultPRIMARY key result(&#96;studentNo&#96;,&#96;subjedctNo&#96;,&#96;examDate&#96;);desc result;# 外键create table student(true&#96;sid&#96; int(4) not null PRIMARY KEY,true&#96;sname&#96; VARCHAR(50) not null,true&#96;studentNo&#96; int(4) not null);alter table student add CONSTRAINT fk_student_resultFOREIGN key (&#96;studentNo&#96;)REFERENCES &#96;result&#96;(&#96;studentNo&#96;);desc student; 查看一下外键","path":"posts/edab.html","date":"06-03","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL的建库、建表、建约束与存储引擎","text":"一、MySQL建库、建表 1、创建数据库 创建数据库是在系统磁盘上划分⼀块区域用于数据的存储和管理，如果管理员在设置权限的时候为用户创建了数据库，则可以直接使用，否则，需要自己创建数据库。 语法格式： 1CREATE DATABASE [IF NOT EXISTS] 数据库名 示例： IF NOT EXISTS：在创建数据库之前进行判断，只有该数据库目前尚不存在时才能执行操作。 此选项可以用来避免数据库已经存在而重复创建的错误。 12# 创建myschool数据库create database myschool; IF NOT EXISTS：在创建数据库之前进行判断，只有该数据库目前尚不存在时才能执行操作。 此选项可以用来避免数据库已经存在而重复创建的错误。 2、创建表 语法格式： 12345CREATE TABLE [IF NOT EXISTS] 表名 (字段1 数据类型 [字段属性|约束][索引][注释],……字段n 数据类型 [字段属性|约束][索引][注释])[表类型][表字符集][注释]; 示例： 12345#创建学生表CREATE TABLE &#96;student&#96;（&#96;studentNo&#96; INT(4) PRIMARY KEY,&#96; name&#96; CHAR(10),……）; 注意： 1234多字段使用逗号分隔保留字用撇号括起来单行注释：#……多行注释：&#x2F;*……*&#x2F; （1）字段的约束及属性 主键 123CREATE TABLE student（&#96;studentNo&#96; INT(4) PRIMARY KEY,……）; 注释 123CREATE TABLE test (&#96;id&#96; int(11) UNSIGNED COMMENT ‘编号’)COMMENT&#x3D;'测试表’ ; 设置字符集编码 123CREATE TABLE [IF NOT EXISTS] 表名（#省略代码）CHARSET &#x3D; 字符集名; （2）在myschool数据库中创建学生表 所需执行的命令 1234567891011121314create databases myschool;use myschool;create table student(true&#96;studentNo&#96; int(4) not null comment '学号' primary key,true&#96;loginPwd&#96; varchar(20) not null comment '密码',true&#96;studentName&#96; varchar(50) not null comment '姓名',true&#96;sex&#96; char(2) not null default '男' comment '性别',true&#96;gradeID&#96; int(4) unsigned comment '年级编号',true&#96;phone&#96; varchar(50) comment '电话',true&#96;address&#96; varchar(255) default '地址不详' comment '地址',true&#96;bornDate&#96; datetime comment '出生日期',true&#96;email&#96; varchar(50) comment '邮件账号',true&#96;identityCard&#96; varchar(18) comment '身份证号' unique key)charset&#x3D;'utf8' comment&#x3D;'学生表'; 查看一下表结构 12345678910111213141516mysql> desc student;+--------------+-----------------+------+-----+----------+-------+| Field | Type | Null | Key | Default | Extra |+--------------+-----------------+------+-----+----------+-------+| studentNo | int(4) | NO | PRI | NULL | || loginPwd | varchar(20) | NO | | NULL | || studentName | varchar(50) | NO | | NULL | || sex | char(2) | NO | | 男 | || gradeID | int(4) unsigned | YES | | NULL | || phone | varchar(50) | YES | | NULL | || address | varchar(255) | YES | | 地址不详 | || bornDate | datetime | YES | | NULL | || email | varchar(50) | YES | | NULL | || identityCard | varchar(18) | YES | UNI | NULL | |+--------------+-----------------+------+-----+----------+-------+10 rows in set (0.00 sec) 3、查看表 （1）查看表是否存在 12use myschool;show tables; （2）查看表定义 语法格式： 12use myschool;desc &#96;student&#96;; 示例： 12use myschool;desc &#96;student&#96;; 4、删除表 语法格式： 1drop table [if exists] 表名; 示例： 12use myschool;drop table if exists &#96;student&#96;; 在删除表之前，先使用 if exists 语句验证表是否存在 5、删除数据库 删除数据库是将已经存在的数据库从磁盘空间上清除，清除之后，数据库中的所有数据也将除。 删除数据库语句和创建数据库的命令相似，MySQL中删除数据库的基本语法格式为： 1drop database if exists 数据库名; 示例： 1drop database if exists myschool; 6、上机练习 （1）myschool数据库中创建科目表(subject) 123456create table subject( &#96;subjectNo&#96; int(4) comment '课程编号' primary key auto_increment, &#96;subjectName&#96; varchar(50) comment '课程名称', &#96;classHour&#96; int(4) comment '学时', &#96;gradeID&#96; int(4) comment '年级编号'); 查看一下表结构 12345678910mysql> desc subject;+-------------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------------+-------------+------+-----+---------+----------------+| subjectNo | int(4) | NO | PRI | NULL | auto_increment || subjectName | varchar(50) | YES | | NULL | || classHour | int(4) | YES | | NULL | || gradeID | int(4) | YES | | NULL | |+-------------+-------------+------+-----+---------+----------------+4 rows in set (0.00 sec) （2）myschool数据库中创建成绩表（result） 123456create table result( &#96;studentNo&#96; int(4) comment '学号' not null, &#96;subjectNo&#96; int(4) comment '课程编号' not null, &#96;examDate&#96; datetime(0) comment '考试日期' not null, &#96;studentResult&#96; int(4) comment '考试成绩' not null); 查看一下表结构 12345678910mysql> desc result;+---------------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------------+----------+------+-----+---------+-------+| studentNo | int(4) | NO | | NULL | || subjectNo | int(4) | NO | | NULL | || examDate | datetime | NO | | NULL | || studentResult | int(4) | NO | | NULL | |+---------------+----------+------+-----+---------+-------+4 rows in set (0.00 sec) 二、MySQL的存储引擎 1、存储引擎简介 数据库存储引擎是数据库底层软件组件，数据库管理系统（DBMS）使用数据引擎进行创建、查询、更 新和删除数据操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能。使用不同的存 储引擎，还可以获得特定的功能。 现在许多不同的数据库管理系统都支持多种不同的数据引擎。MySQL的核心就是存储引擎。 2、存储引擎的类型 mysql有多种存储引擎，它们分别为： 123456789MyISAMInnoDBMERGEMEMORYEXAMPLEFEDERATEDARCHIVECSVBLACKHOLE 3、存储引擎的主要区别 （1）MyISAM 存储引擎特点 MySQL 5.5 之前使用 MyISAM 引擎，MySQL 5.5 之后使用 InnoDB 引擎 MyISAM 引擎读取速度较快，占用资源相对较少，不支持事务，不支持外键约束，但支持全文索引 读写互相阻塞，也就是说读数据的时候你就不能写数据，写数据的时候你就不能读数据 MyISAM 引擎只能缓存索引，而不能缓存数据 （2）InnoDB 存储引擎特点 事务型数据库的首选引擎，支持事务安全表，支持行锁定和外键，MySQL5.5.5 版本之后，InnoDB作为默认存储引擎 具有提交、回滚和崩溃恢复能力的事务安全存储引擎，能处理巨大数据量，性能及效率高，完全支持外键完整性约束 具有非常高效的缓存特性，能缓存索引也能缓存数据，对硬件要求比较高 使用InnoDB时，将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据⽂文件，以及两个名为 ib_logfile0 和 ib_logfile1 的 5MB ⼤大⼩小的日志⽂文件 （3）Memory 存储引擎特点 Memory存储引擎将表中的数据存储到内存中，为查询和引用其他表数据提供快速访问 Memory存储引擎执行 HASH 和 BTREE 索引，不支持 BLOB 和 TEXT 列，支持AUTO_INCREMENT列和对可包含 NULL 值得列的索引 当不再需要 Memory 表的内容时，要释放被 Memory 表使用的内存，应该执行DELETE FROM 或 TRUNCATE TABLE ，或者删除整个表 4、存储引擎适用场合 （1）MyISAM 适⽤用场景 不需要事务支持的业务，例如：转账就不行 适用于读数据比较多的业务，不适用于读写频繁的业务 并发相对较低、数据修改相对较少的业务 硬件资源比较差的机器可以考虑使用 MyISAM 引擎 （2）InnoDB 适⽤用场景 需要事务⽀持的业务、⾼并发的业务 数据更新较为频繁的场景，⽐如：BBS、SNS、微博等 数据⼀致性要求较⾼的业务，⽐如：充值转账、银⾏卡转账 （3）总结 使用MyISAM: 不需事务，空间小，以查询访问为主 使用InnoDB: 多删除、更新操作，安全性高，事务处理及并发控制 5、查看当前默认存储引擎 123456789mysql&gt; show variables like '%storage_engine';+----------------------------------+--------+| Variable_name | Value |+----------------------------------+--------+| default_storage_engine | InnoDB || default_tmp_storage_engine | InnoDB || internal_tmp_disk_storage_engine | InnoDB |+----------------------------------+--------+3 rows in set, 1 warning (0.mysql&gt; show variables like '%storage_engine';+----------------------------------+--------+| Variable_name | Value |+----------------------------------+--------+| default_storage_engine | InnoDB || default_tmp_storage_engine | InnoDB || internal_tmp_disk_storage_engine | InnoDB |+----------------------------------+--------+3 rows in set, 1 warning (0.02 sec) 6、修改默认存储引擎 （1）MySQL 5.5 修改my.ini配置文件 1default_storage_engine=InnoDB （2）MySQL 5.7 最简单的方法，就是通过命令直接修改表的存储引擎，如下所示： 1alter table 表名 ENGINE = 引擎名; 示例： 1ALTER TABLE student ENGINE = InnoDB; 7、设置表的存储引擎 语法格式： 123CREATE TABLE 表名(#省略代码)ENGINE=存储引擎; 示例： 123CREATE TABLE `myisam` (id INT(CREATE TABLE `myisam` (id INT(4))ENGINE=MyISAM; 三、MySQL补充知识 在mysql中，每个数据库最多可创建20亿个表，一个表允许定义1024列，每行的最大长度为8092字节（不包括⽂本和图像类型的长度）。 当表中定义有varchar、nvarchar或varbinary类型列时，如果向表中插入的数据行超过8092字节时，将导致语句失败，并产生错误信息。 SQL Server对每个表中行的数量没有直接限制，但它受数据库存储空间的限制。每个数据库的最大空间1048516TB，所以一个表可用的最大空间为1048516TB减去数据库类系统表和其它数据库对象所占用的空间。理论上无限大，就看你硬盘够不够大，大多数情况先是你的硬盘不够。","path":"posts/1d95.html","date":"06-02","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"mysql数据库基础","text":"一、数据库基础知识 1、什么是数据库 数据库的概念诞生生于60年前，随看信息技术和市场的快速发展，数据库技术层出不穷，随着应用的扩展和深入，数据库的数量和规模越来越大，其诞生和发展给计算机信息管理带来了一场巨大的革命。 数据库的发展大致划分为以下几个阶段:人工管理阶段、文件系统阶段、数据库系统阶段、高级数据库阶段。其种类大概有3种:层次式数据库、网络式数据库和关系式数据库。不同种类的数据库按不同的数据结构来联系和组织。 对于数据库的概念，没有一个完全固定的定义。 随着数据库历史的发展，定义的内容也有很大的差异，其中一种比较普遍的观点认为，数据库(DataBase, DB)是一个长期存储在计算机内的、有组织的、有共享的，统一管理的数据集合。它是一个按数据结构来存储和管理数据的计算机软件系统。即数据库包含两层含义:保管数据的“仓库&quot;，以及数据管理的方法和技术。 数据库的特点包括:实现数据共享，减少数据冗余;采用特定的数据类型:具有较高的数据独立性:具有统一的数据控制功能。 2、为何需要数据库 存储数据的方法 第一种方法:用大脑来记住数据 第二种方法:写在纸上 第三种方法:写在计算机的内存中 第四种方法:写成磁盘文件 3、数据库能够做什么 存储大量数据，方便检索和访问 保持数据信息的一致、完整 共享和安全 通过组合分析，产生新的有用信息 4、数据库和应用程序 应用程序 数据库 作用 响应操作并显示结果、向数据库请求数据 存储数据、检索数据、生成新的数据 要求 美观、操作简单方便 统一安全、性能等 5、时下流行的数据库 Oracle SqIServer MySQL Oracle公司的产品 针对不同用户群体的多个版本 开放源代码 产品免费、服务收费 易用性好 网站应用广泛 6、数据库的基本概念 在关系数据库中，数据库的表是一系列二维数组的集合,用来存储数据和操作数据的逻辑结构。它是由纵向的列和横向的行组成，行被称为记录，也叫作实体,是组织数据的单位;列被称为字段，每一列表示记录的一个属性，都有相应的描述信息，如数据类型、数据宽度等。例如一个有关作者信息的名为authors的表中，每个列包含所有作者的某个特定类型的信息。 （1）实体 这些客观存在的、可以被描述的事物都是“实体”。 二、MySQL数据库 MySQL是一个开放源代码的数据库管理系统(DBMS) ，它是由MySQL AB公司开发、发布并支持的。MySQL是一个跨平台的开源关系数据库管理系统，广泛地应用在Internet上的中小型网站公司开发中。 1、MySQL的优势 运行速度快。 使用成本低: MySQL对多数个人用户来说是免费的。 容易使用:与其他大型数据库的设置和管理相比，其复杂程度较低，易于学习。 可移植性强:能够工作在众多不同的系统平台上，例如: Windows. Linux、Unix等。 支持丰富的接口;提供了用于C、C++、Java、per1、PHP、Ruby、Python等语言的API 支持查询语言; MySQL可以利用标准SQL语法和支持ODBC (开放式数据库连接)的应用程序 安全性和连续性:十分灵活和安全的权限和密码系统，允许基于主机的验证。连接到服务器器时，所有的密码传输均采用加密形式，从而保证了密码安全。并且由于Mysq1是网络化的，因此可以在因特网上的任何地方访问，提高数据共享的效率。， 2、MySQL版本 MySQL分为2个不同的版本: 社区版(Community Server) 企业版(Enterprise Server) 免费、开源 收费，不可自由下载 适合普通用户 适合对功能和安全要求高的企业用户 功能和服务更完善它能够以很高的性价比为企业提供数据仓库应用，支持ACID事务处理,提供完整的提交、回滚、崩溃恢复和行级锁定功能。 3、MySQL的命名 MySQL的命名机制由3个数字和1个后缀组成，例如mysql-5.5.13. 第1个数字(5)是主版本号，描述了文件格式，所有版本5的发行版都有相同的文件格式。 第2个数字(5)是发行级别，主版本号和发行级别组合在一-起便构成了发行序列号。 第3个数字(13)是在此发行系列的版本号，随每次新发布版本递增，通常选择已经发行的最新版本。 4、MySQL的运行机制 (1)讲解思路 就一个SQL语句，如select * from tablename ，从支持接口进来后，进入连接池后做权限。验证等环节，然后判断是否有缓存，有则直接放回结果，否则进入SQL接口，在查询之前查询优化器进行优化，最后进行解析，查询。并通过存储引擎与文件交互。然后再介绍MySQL的企业管理服务和工具。 (2)名词解释 支持接口: 不同的编程语言与SQL的交互 连接池: 管理缓冲用户连接，线程处理等需要缓存的需求 SQL接口: 接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL接口 解析器: SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。 主要功能: 将SQL语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的;例如将select 自from tablename where 1=1; 分解为select.中、from、 tablename、where 、1=1,并去解析。 如果在分解构成中遇到错误，那么就说明这个SQL语句是不合理的。 查询优化器: SQL语句在查询之前会使用查询优化器对查询进行优化，使用的是”选取-投影-联接’ &quot;策略进行查询。 例: select uid,name from user where gender = 1; a.先根据where语句进行选取，而不是先将表全部查询出来以后再进行gender过滤 b.先根据uid和name进行属性投影，而不是将属性全部陬出以后再进行过滤 将这两个查询条件联接起来生成最终查询结果。 缓存: 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。 这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。 存储引擎: 存储引擎是MySq|中具体的与文件打交道的子系统。也是Mysq|最具有特色的一个地方。 Mysql的存储引擎是插件式的。它根据MySql AB公司提供的文件访问层的一个抽象接口来定制-种文件访问机制(这种访问机制就叫存储引擎)。 现在有很多种存储引擎,各个存储引擎的优势各不一样，最常用的9MyISAM. InnoDB. BDB。 MyISAM引擎.它查询速度快。有较好的索引优化和数据压缩技术，但是它不支持事务。 InnoDB支持事务，并且提供行级的锁定，应用也相当厂泛。 Mysq也支持自己定制存储引擎，甚至一个库中不同的表使用不同的存储引擎，这些都是允许的。 MySQL5.7默认使用InnoDB存储引擎。 5、MySQL安装与配置 (1)安装步骤(略) (2)基本配置 123端口号: 3306默认字符集: utf-端口号: 3306默认字符集: utf-8root密码设置 (3)安装目录介绍 1234bin:include:1ib:bin:include:1ib:share: (4)命令行连接MySQL(cmd窗口) 1)检查MySQL服务是否启动 方式1: Windows服务 右击此电脑——管理——服务和应用程序——服务——查找MYSQL57服务（我的mysql名称是mysqlxgp888） 如果关闭该服务，登陆mysql会出错 12C:\\WINDOWS\\system32&gt;mysql -u root -pERROR 2003 (HY000): Can't connect to MySQL server on 'C:\\WINDOWS\\system32&gt;mysql -u root -pERROR 2003 (HY000): Can't connect to MySQL server on 'localhost' (10061) 方式2: dos命令启动mysql 123C:\\WINDOWS\\system32&gt;net start mysqlxgp888MYSQLxgp888 服务正在启动 .C:\\WINDOWS\\system32&gt;net start mysqlxgp888MYSQLxgp888 服务正在启动 .MYSQLxgp888 服务已经启动成功。 关闭mysql服务 123C:\\WINDOWS\\system32&gt;net stop mysqlxgp888MYSQLxgp888 服务正在停止.C:\\WINDOWS\\system32&gt;net stop mysqlxgp888MYSQLxgp888 服务正在停止.MYSQLxgp888 服务已成功停止。 修改了配置文件，必须重启MySQL服务才能生效。 2)连接MySQL 语法格式: 1mysq1 -h服务器主机地址-u用户名-p密码 示例: 1mysq1 -u root -p 方式1: dos命令启动 方式2: MySQL Command Line Client 默认root登录，仅输入密码。 三、MySQL数据库类型 1、系统数据库 安装完MySQL服务器后，MySQL会附带系统数据库，包括: information_ schema:主要存储系统中的一些数据库对象信息，如用户表信息、字段信息、权限信息、字符集信息和分区信息等。 performance_ schema: 主要存储数据库服务器性能参数 mysql:主要存储系统的用户权限信息 test :MySQL数据库管理系统自动创建的测试数据库，任何用户都可以使用 2、用户数据库 用户数据库是用户根据实际需求创建的数据库。本章后面的讲解主要针对用户数据库。 四、数据库基本操作（cmd） 1、登陆数据库 1C:\\WINDOWS\\system32&gt;mysql -u root -C:\\WINDOWS\\system32&gt;mysql -u root -p123456 查看一下 123456789101112mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || userinfo |+--------------------+7 rows in set (0.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || userinfo |+--------------------+7 rows in set (0.00 sec) 2、创建数据库（test） 基本语法： create database 数据库名称 ； 创建应该名称为itcast的数据库。sql语法如下： 1create database itcast; 需要主要的是，为了避免用户自定义的名称与系统命令冲突，最好使用反引号（``）包括数据库名称/字段名称和数据表名称 如果创建数据库存在，则程序会报错，为了防止此情况发生，再创建数据库可以使用“if not exists”，语法如下： 12mysql&gt; create database test;Query OK, 1 row affected (0.mysql&gt; create database test;Query OK, 1 row affected (0.00 sec) 3、查看数据库 查看MySql数据库服务器已经存在的数据库 12345678910111213mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || test || userinfo |+--------------------+7 rows in set (0.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || test || userinfo |+--------------------+7 rows in set (0.00 sec) 4、选择数据库 数据库服务器可能存在多个数据，选择数据库的命令语法： 1use 数据库名称 操作 12mysql> use test;Database changed 5、删除数据库 数据库的删除操作不仅会删除里面的数据，还会回收原来分配的存储空间 1drop database 数据库名称 在使用“drop database” 命令删除数据库时，若删除数据库不存在，MySql服务器会报错，因此，可以再删除数据库时，使用“if existe” 12mysql&gt; drop database test;Query OK, 0 rows affected (0.mysql&gt; drop database test;Query OK, 0 rows affected (0.00 sec) //若删除MySql数据库服务器中存在数据库itcase,则删除该数据库，否则不执行删除 数据库itcasse的操作。 查看一下 123456789101112mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || userinfo |+--------------------+6 rows in set (0.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student_info || sys || userinfo |+--------------------+6 rows in set (0.00 sec) 五、图形化MySQL管理工具 1、连接数据库 2、查看数据库 3、选择数据库 六、结构化查询语言 1、SQL 对数据库进行查询和修改操作的语言叫SQL. SQL的含义是结构化查询语句(Structured Query Languate)，是对数据库进行查询和修改操作的语言。 2、T-SQL T-SQL: Transact-SQL T-SQL是SQL的增强版，对功能进行了扩充：如变量说明、流程控制、功能函数。 3、SQL的组成 名称 解释 命令举例 DML (数据操作语言) 用来操作数据库中所包含的数据 INSERT- 将数据插入表中DELETE-更新表中的现有数据UPDATE-删除数据库表中的所有记录等 DDL (数据定义语言) 用于创建和删除数据库对象等操作 CREATE-创建数据库及其对象（表，索引，视图，存储过程，函数和触发器）DROP-改变现有数据库的结构ALTER-从数据库中删除对象TRUNCATE-删除表中的所有记录，包括为记录分配的所有空格COMMENT-为数据字典添加注释RENAME-重命名对象 DQL (数据查询语言) 用来对数据库中的数据进行查询 SELECT-从数据库中检索数据 DCL (数据控制语言) 用来控制数据库组件的存取许可、存取权限等 GRANT-允许用户访问数据库的权限COMMIT-提交事务ROLLBACK-在发生任何错误的情况下回滚事务 结构化查询语言是高级的非过程化编程语言，允许用户在高层数据结构上工作。它不要求用户指定对数据的存放方法，也不需要用户了zhi解具体的数据存放方式，所以具有完全不同底层结构的不同数据库系统, 可以使用相同的结构化dao查询语言作为数据内输入与管理的接口。结构化查询语言语句可以嵌套，这使它具有极大的灵活性和强大的功能。 扩展资料： SQL可以独立完成数据容库生命周期中的全部活动，包括定义关系模式、录入数据、建立数据库、査询、更新、维护、数据库重构、数据库安全性控制等一系列操作，这就为数据库应用系统开发提供了良好的环境，在数据库投入运行后，还可根据需要随时逐步修改模式，且不影响数据库的运行，从而使系统具有良好的可扩充性。 七、MySQL常用数据类型 MySql提供了很多数值类型，大体分为整数类型和浮点类型 整数类型根据取值范围分为int，smallint等， 浮点类型又分为float，declmal等。 1、数值类型 2、数值类型的属性: UNSIGNED 标识为无符号数 ZEROFILL 宽度(位数)不足，以0填充 3、实施一下 （1）ZEROFILL：没有数值的位置用0填充 12345678910111213create database `school`;#创建数据库use `school`;#切换数据库create table `student` (true`sid` INT(create database `school`;#创建数据库use `school`;#切换数据库create table `student` (true`sid` INT(4) ZEROFILL);#创建表desc student;#查看表结构 插入数据 在上面的部分添加如下内容，选中并执行 12insert into `student` VALUES(12),(123),(insert into `student` VALUES(12),(123),(1234);#插入数据 查看一下 命令行—查看一下 1234567891011mysql&gt; use school;Database changedmysql&gt; select * from student;+------+| sid |+------+| 0012 || 0123 || mysql&gt; use school;Database changedmysql&gt; select * from student;+------+| sid |+------+| 0012 || 0123 || 1234 |+------+ （2）UNSIGNED不用0填充空值 把上面的ZEROFILL改为UNSIGNED 12345678910111213141516create database `school`;#创建数据库use `school`;#切换数据库create table `student` (true`sid` INT(4) UNSIGNED);#创建表desc student;#查看表结构insert into `student` VALUES(12),(123),(create database `school`;#创建数据库use `school`;#切换数据库create table `student` (true`sid` INT(4) UNSIGNED);#创建表desc student;#查看表结构insert into `student` VALUES(12),(123),(1234)#插入数据 命令行—查看一下 4、字符串类型 BLOB和TEXT都是用于存储大量数据的，但二者的区别在于，对于存储的数据进行排序和比较时，BLOB是区分大小写的，而TEXT是不区分大小写的 注意： char(n) 和 varchar(n) 中括号中 n 代表字符的个数，并不代表字节个数，比如 CHAR(30) 就可以存储 30 个字符。 CHAR 和 VARCHAR 类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。 BINARY 和 VARBINARY 类似于 CHAR 和 VARCHAR，不同的是它们包含二进制字符串而不要非二进制字符串。也就是说，它们包含字节字符串而不是字符字符串。这说明它们没有字符集，并且排序和比较基于列值字节的数值值。 BLOB 是一个二进制大对象，可以容纳可变数量的数据。有 4 种 BLOB 类型：TINYBLOB、BLOB、MEDIUMBLOB 和 LONGBLOB。它们区别在于可容纳存储范围不同。 有 4 种 TEXT 类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。对应的这 4 种 BLOB 类型，可存储的最大长度不同，可根据实际情况选择。 5、日期类型 表示时间值的日期和时间类型为DATETIME、DATE、TIMESTAMP、TIME和YEAR。 每个时间类型有一个有效值范围和一个&quot;零&quot;值，当指定不合法的MySQL不能表示的值时使用&quot;零&quot;值。 TIMESTAMP类型有专有的自动更新特性，将在后面描述。","path":"posts/ba11.html","date":"06-01","excerpt":"","tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"}]},{"title":"94 小案例","text":"编写一个案例代码 1、name_function.py 文件内容 1234567891011121314# coding=utf-8'''编写函数或者类的时候，可以给他们编写测试。通过测试，可确定代码面对各种各样输入都能够按照既定的要求正常工作对于程序员来说，编写测试，可以在用户发现问题前预先找出错误。Python中的测试模块：'''def get_format_name(first,last): '''创建一个姓名''' full_name = first + ' ' + last # coding=utf-8'''编写函数或者类的时候，可以给他们编写测试。通过测试，可确定代码面对各种各样输入都能够按照既定的要求正常工作对于程序员来说，编写测试，可以在用户发现问题前预先找出错误。Python中的测试模块：'''def get_format_name(first,last): '''创建一个姓名''' full_name = first + ' ' + last return full_name.title() 2、names.py 文件内容 12345678910111213# coding=utf-8from exam.name_function import get_format_nameprint('请输入q在指定时间内退出。')while True: fist = input('请输入你的姓：') if fist == 'q': break last = input('请输入你的名：') if last == 'q': # coding=utf-8from exam.name_function import get_format_nameprint('请输入q在指定时间内退出。')while True: fist = input('请输入你的姓：') if fist == 'q': break last = input('请输入你的名：') if last == 'q': break formatted_name = get_format_name(fist,last) print(formatted_name) 输出结果 1234请输入q在指定时间内退出。请输入你的姓：x请输入你的名：gpX Gp 3、编写测试案例代码 test_name_function.py 文件内容 1234567891011121314151617# coding=utf-8import unittestfrom exam.name_function import get_format_nameclass NameTestCase(unittest.TestCase): '''测试name_function.py''' def test_firt_last_name(self): '''能够正确处理某种格式的姓名''' formatted_name = get_format_name('janis','joplin') #断言：期待的结果 self.assertEqual(formatted_name,'janis Joplin')if __name__ == # coding=utf-8import unittestfrom exam.name_function import get_format_nameclass NameTestCase(unittest.TestCase): '''测试name_function.py''' def test_firt_last_name(self): '''能够正确处理某种格式的姓名''' formatted_name = get_format_name('janis','joplin') #断言：期待的结果 self.assertEqual(formatted_name,'janis Joplin')if __name__ == '__main__': unittest.main() 输出结果","path":"posts/a1c5.html","date":"11-03","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"93 Python并发线程","text":"开始学习Python线程 Python中使用线程有两种方式：函数或者用类来包装线程对象。 函数式：调用thread模块中的start_new_thread()函数来产生新线程。语法如下: 1thread.start_new_thread ( function, args[, kwargs] ) 参数说明: function - 线程函数。 args - 传递给线程函数的参数,他必须是个tuple类型。 kwargs - 可选参数。python 简单的执行线程次数 123456789101112131415161718192021# coding:utf-8import threadingimport timedef say_hi(): # time.sleep(1) #延迟几秒 print('hello world!')def main(): for i in range(5): # 创建线程 thread = threading.Thread(target=say_hi) # 启动线程 thread.start()if __name__ == # coding:utf-8import threadingimport timedef say_hi(): # time.sleep(1) #延迟几秒 print('hello world!')def main(): for i in range(5): # 创建线程 thread = threading.Thread(target=say_hi) # 启动线程 thread.start()if __name__ == '__main__': main() 输出结果 12345hello world!hello world!hello world!hello world!hello world! 1、单线程 在好些年前的MS-DOS时代，操作系统处理问题都是单任务的，我想做听音乐和看电影两件事儿，那么一定要先排一下顺序。 12345678910111213141516from time import ctime,sleepdef music(): for i in range(2): print(\"I was listening to music. %s\" %ctime()) sleep(1)def move(): for i in range(2): print(\"I was at the movies! %s\" %ctime()) sleep(5)if __name__ == '__main__': music() move() print(from time import ctime,sleepdef music(): for i in range(2): print(\"I was listening to music. %s\" %ctime()) sleep(1)def move(): for i in range(2): print(\"I was at the movies! %s\" %ctime()) sleep(5)if __name__ == '__main__': music() move() print(\"all over %s\" %ctime()) 我们先听了一首音乐，通过for循环来控制音乐的播放了两次，每首音乐播放需要1秒钟，sleep()来控制音乐播放的时长。接着我们又看了一场电影，每一场电影需要5秒钟，因为太好看了，所以我也通过for循环看两遍。在整个休闲娱乐活动结束后，我通过print(&quot;all over %s&quot; %ctime())看了一下当前时间，差不多该睡觉了 输出结果 12345I was listening to music. Wed Jun 17 23:19:18 2020I was listening to music. Wed Jun 17 23:19:19 2020I was at the movies! Wed Jun 17 23:19:20 2020I was at the movies! Wed Jun 17 23:19:25 2020all over Wed Jun 17 23:19:30 I was listening to music. Wed Jun 17 23:19:18 2020I was listening to music. Wed Jun 17 23:19:19 2020I was at the movies! Wed Jun 17 23:19:20 2020I was at the movies! Wed Jun 17 23:19:25 2020all over Wed Jun 17 23:19:30 2020 其实，music()和move()更应该被看作是音乐和视频播放器，至于要播放什么歌曲和视频应该由我们使用时决定。所以，我们对上面代码做了改造： 12345678910111213141516171819import threadingfrom time import ctime,sleepdef music(func): for i in range(2): print (\"I was listening to %s. %s\" %(func,ctime())) sleep(1)def move(func): for i in range(2): print (\"I was at the %s! %s\" %(func,ctime())) sleep(5)if __name__ == '__main__': music(u'爱情买卖') move(u'阿凡达') print (import threadingfrom time import ctime,sleepdef music(func): for i in range(2): print (\"I was listening to %s. %s\" %(func,ctime())) sleep(1)def move(func): for i in range(2): print (\"I was at the %s! %s\" %(func,ctime())) sleep(5)if __name__ == '__main__': music(u'爱情买卖') move(u'阿凡达') print (\"all over %s\" %ctime()) 输出结果 12345I was listening to 爱情买卖. Thu Apr 17 11:48:59 2014I was listening to 爱情买卖. Thu Apr 17 11:49:00 2014I was at the 阿凡达! Thu Apr 17 11:49:01 2014I was at the 阿凡达! Thu Apr 17 11:49:06 2014all over Thu Apr 17 11:49:11 I was listening to 爱情买卖. Thu Apr 17 11:48:59 2014I was listening to 爱情买卖. Thu Apr 17 11:49:00 2014I was at the 阿凡达! Thu Apr 17 11:49:01 2014I was at the 阿凡达! Thu Apr 17 11:49:06 2014all over Thu Apr 17 11:49:11 2014 2、多线程 Python3 通过两个标准库 _thread (python2中是thread模块）和 threading 提供对线程的支持。 _thread 提供了低级别的、原始的线程以及一个简单的锁，它相比于 threading 模块的功能还是比较有限的。 （1）使用_thread模块 调用_thread模块中的start_new_thread()函数来产生新线程。 先用一个实例感受一下： 123456789101112131415161718192021222324import _threadimport time# 为线程定义一个函数def print_time(threadName, delay): count = 0 while count &lt; 5: time.sleep(delay) count += 1 print(\"%s: %s\" % (threadName, time.ctime(time.time())))# 创建两个线程try: _thread.start_new_thread(print_time, (\"Thread-1\", 2,)) _thread.start_new_thread(print_time, (\"Thread-2\", 4,))except: print(\"Error: unable to start thread\")while 1: passprint(import _threadimport time# 为线程定义一个函数def print_time(threadName, delay): count = 0 while count &lt; 5: time.sleep(delay) count += 1 print(\"%s: %s\" % (threadName, time.ctime(time.time())))# 创建两个线程try: _thread.start_new_thread(print_time, (\"Thread-1\", 2,)) _thread.start_new_thread(print_time, (\"Thread-2\", 4,))except: print(\"Error: unable to start thread\")while 1: passprint(\"Main Finished\") 输出结果 123456789Thread-1: Thu Aug 10 16:35:47 2017Thread-2: Thu Aug 10 16:35:49 2017Thread-1: Thu Aug 10 16:35:49 2017Thread-1: Thu Aug 10 16:35:51 2017Thread-2: Thu Aug 10 16:35:53 2017Thread-1: Thu Aug 10 16:35:53 2017Thread-1: Thu Aug 10 16:35:55 2017Thread-2: Thu Aug 10 16:35:57 2017Thread-2: Thu Aug 10 16:36:01 Thread-1: Thu Aug 10 16:35:47 2017Thread-2: Thu Aug 10 16:35:49 2017Thread-1: Thu Aug 10 16:35:49 2017Thread-1: Thu Aug 10 16:35:51 2017Thread-2: Thu Aug 10 16:35:53 2017Thread-1: Thu Aug 10 16:35:53 2017Thread-1: Thu Aug 10 16:35:55 2017Thread-2: Thu Aug 10 16:35:57 2017Thread-2: Thu Aug 10 16:36:01 2017 注意到，在主线程写了: 12while 1: while 1: pass 这是让主线程一直在等待. 如果去掉上面两行，那就直接输出并结束程序执行: 1\"Main Finished\" 线程模块 Python通过两个标准库thread和threading提供对线程的支持。thread提供了低级别的、原始的线程以及一个简单的锁。 threading 模块提供的其他方法： threading.currentThread(): 返回当前的线程变量。 threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 除了使用方法外，线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法: run(): 用以表示线程活动的方法。 start(): 启动线程活动。 join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。 isAlive(): 返回线程是否活动的。 getName(): 返回线程名。 setName(): 设置线程名。 1、直接创建线程 接上面的听音乐和看电影的例子，我们可以直接使用threading.Thread 创建线程，并指定执行的方法以及传递的参数： 12345678910111213141516171819202122232425import threadingfrom time import ctime,sleepdef music(func): for i in range(2): print (\"I was listening to %s. %s\" %(func,ctime())) sleep(1)def move(func): for i in range(2): print (\"I was at the %s! %s\" %(func,ctime())) sleep(5)threads = []t1 = threading.Thread(target=music,args=(u'爱情买卖',))threads.append(t1)t2 = threading.Thread(target=move,args=(u'阿凡达',))threads.append(t2)if __name__ == '__main__': for t in threads: t.start() print (import threadingfrom time import ctime,sleepdef music(func): for i in range(2): print (\"I was listening to %s. %s\" %(func,ctime())) sleep(1)def move(func): for i in range(2): print (\"I was at the %s! %s\" %(func,ctime())) sleep(5)threads = []t1 = threading.Thread(target=music,args=(u'爱情买卖',))threads.append(t1)t2 = threading.Thread(target=move,args=(u'阿凡达',))threads.append(t2)if __name__ == '__main__': for t in threads: t.start() print (\"all over %s\" %ctime()) 输出结果 12345I was listening to 爱情买卖. Thu Aug 10 16:57:12 2017I was at the 阿凡达! Thu Aug 10 16:57:12 2017all over Thu Aug 10 16:57:12 2017I was listening to 爱情买卖. Thu Aug 10 16:57:13 2017I was at the 阿凡达! Thu Aug 10 16:57I was listening to 爱情买卖. Thu Aug 10 16:57:12 2017I was at the 阿凡达! Thu Aug 10 16:57:12 2017all over Thu Aug 10 16:57:12 2017I was listening to 爱情买卖. Thu Aug 10 16:57:13 2017I was at the 阿凡达! Thu Aug 10 16:57:17 2017 2、使用Threading模块创建线程（构造线程类） 我们也可以通过直接从 threading.Thread 继承创建一个新的子类，并实例化后调用 start() 方法启动新线程，即它调用了线程的 run() 方法 使用Threading模块创建线程，直接从threading.Thread继承，然后重写init方法和run方法： 12345678910111213141516171819202122232425262728293031323334#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()print (#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()print (\"退出主线程\") 输出结果 123456789101112131415开始线程：Thread-1开始线程：Thread-2退出主线程Thread-1: Thu Aug 10 16:48:41 2017Thread-2: Thu Aug 10 16:48:42 2017Thread-1: Thu Aug 10 16:48:42 2017Thread-1: Thu Aug 10 16:48:43 2017Thread-2: Thu Aug 10 16:48:44 2017Thread-1: Thu Aug 10 16:48:44 2017Thread-1: Thu Aug 10 16:48:45 2017退出线程：Thread-1Thread-2: Thu Aug 10 16:48:46 2017Thread-2: Thu Aug 10 16:48:48 2017Thread-2: Thu Aug 10 16:48:50 2017退出线程：Thread开始线程：Thread-1开始线程：Thread-2退出主线程Thread-1: Thu Aug 10 16:48:41 2017Thread-2: Thu Aug 10 16:48:42 2017Thread-1: Thu Aug 10 16:48:42 2017Thread-1: Thu Aug 10 16:48:43 2017Thread-2: Thu Aug 10 16:48:44 2017Thread-1: Thu Aug 10 16:48:44 2017Thread-1: Thu Aug 10 16:48:45 2017退出线程：Thread-1Thread-2: Thu Aug 10 16:48:46 2017Thread-2: Thu Aug 10 16:48:48 2017Thread-2: Thu Aug 10 16:48:50 2017退出线程：Thread-2 从结果可以看到，为什么我们开启了两个线程之后，主线程立即退出了？因为我们没有使用join方法，对于主线程来说，thread1和thread2是子线程，使用join方法，会让主线程等待子线程执行解说再继续执行。 join()方法 我们修改一下代码： 123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()thread1.join()thread2.join()print (#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()thread1.join()thread2.join()print (\"退出主线程\") 123456789101112131415开始线程：Thread-1开始线程：Thread-2Thread-1: Thu Aug 10 16:52:07 2017Thread-2: Thu Aug 10 16:52:08 2017Thread-1: Thu Aug 10 16:52:08 2017Thread-1: Thu Aug 10 16:52:09 2017Thread-2: Thu Aug 10 16:52:10 2017Thread-1: Thu Aug 10 16:52:10 2017Thread-1: Thu Aug 10 16:52:11 2017退出线程：Thread-1Thread-2: Thu Aug 10 16:52:12 2017Thread-2: Thu Aug 10 16:52:14 2017Thread-2: Thu Aug 10 16:52:16 2017退出线程：Thread开始线程：Thread-1开始线程：Thread-2Thread-1: Thu Aug 10 16:52:07 2017Thread-2: Thu Aug 10 16:52:08 2017Thread-1: Thu Aug 10 16:52:08 2017Thread-1: Thu Aug 10 16:52:09 2017Thread-2: Thu Aug 10 16:52:10 2017Thread-1: Thu Aug 10 16:52:10 2017Thread-1: Thu Aug 10 16:52:11 2017退出线程：Thread-1Thread-2: Thu Aug 10 16:52:12 2017Thread-2: Thu Aug 10 16:52:14 2017Thread-2: Thu Aug 10 16:52:16 2017退出线程：Thread-2退出主线程 可以看到 退出主线程 在最后才被打印出来。 setDaemon()方法 有一个方法常常拿来与join方法做比较，那就是setDaemon()方法。我们首先来看一下setDaemon()方法的使用效果： 12345678910111213141516171819202122232425262728293031323334353637#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.setDaemon(True)thread2.setDaemon(True)thread1.start()thread2.start()print (#!/usr/bin/python3import threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.setDaemon(True)thread2.setDaemon(True)thread1.start()thread2.start()print (\"退出主线程\") 输出结果 123开始线程：Thread-1开始线程：Thread开始线程：Thread-1开始线程：Thread-2退出主线程 可以看到，在主线程结束之后，程序就终止了，也就是说两个子线程也被终止了，这就是setDaemon方法的作用。主线程A中，创建了子线程B，并且在主线程A中调用了B.setDaemon(),这个的意思是，把主线程A设置为守护线程，这时候，要是主线程A执行结束了，就不管子线程B是否完成,一并和主线程A退出.这就是setDaemon方法的含义，这基本和join是相反的。此外，还有个要特别注意的：必须在start() 方法调用之前设置，如果不设置为守护线程，程序会被无限挂起。 3、两个疑问 我们刚才介绍了两种使用多线程的方式，一种是直接调用threading.Thread 创建线程，另一种是从 threading.Thread 继承创建一个新的子类，并实例化后调用 start() 方法启动进程。学到这里，我就抛出了两个疑问，为什么第一种方法中我们可以为不同的线程指定运行的方法，而第二种我们都运行的是同一个方法，那么它内部的实现机制是什么呢？第二个疑问是，第二种方法中，我们没有实例化start()方法，那么run和start这两个方法的联系是什么呢？ 首先，start方法和run方法的关系如下：用start方法来启动线程，真正实现了多线程运行，这时无需等待run方法体代码执行完毕而直接继续执行下面的代码。通过调用Thread类的start()方法来启动一个线程，这时此线程处于就绪（可运行）状态，并没有运行，一旦得到cpu时间片，就开始执行run()方法，这里方法 run()称为线程体，它包含了要执行的这个线程的内容，Run方法运行结束，此线程随即终止。 而run()方法的源码如下，可以看到，如果我们指定了target即线程执行的函数的话，run方法可以转而调用那个函数，如果没有的话，将不执行，而我们在自定义的Thread类里面重写了这个run 方法，所以程序会执行这一段。 12345678910111213141516def run(self): \"\"\"Method representing the thread's activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object's constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. \"\"\" try: if self._target: self._target(*self._args, **self._kwargs) finally: # Avoid a refcycle if the thread is running a function with # an argument that has a member that points to the thread. def run(self): \"\"\"Method representing the thread's activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object's constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. \"\"\" try: if self._target: self._target(*self._args, **self._kwargs) finally: # Avoid a refcycle if the thread is running a function with # an argument that has a member that points to the thread. del self._target, self._args, self._kwargs 4、按时间为批次执行线程 线程有不确定性 1234567891011121314151617181920# coding:utf-8import threadingdef say_hi(count, name): while count &gt; 0: print('hello', name) count -= 1def main(): username = ['Alan', 'Bob', 'Cendy', 'Kily','Heny'] for i in range(5): thread = threading.Thread(target=say_hi,args=(50,username[i])) thread.start()if __name__ == # coding:utf-8import threadingdef say_hi(count, name): while count &gt; 0: print('hello', name) count -= 1def main(): username = ['Alan', 'Bob', 'Cendy', 'Kily','Heny'] for i in range(5): thread = threading.Thread(target=say_hi,args=(50,username[i])) thread.start()if __name__ == '__main__': main() 输出结果 12345678910111213hello Alanhello Alanhello Alanhello Alanhello hello Bobhello Bobhello Bobhello Bobhello BobAlanhello Cendyhello Cendyhello Bobhellohello Alanhello Cendy 5、继承的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding:utf-8import threadingimport timedef say_hi(count,name): # time.sleep(1) #延迟几秒 # print('hello world!') while count &gt; 0: print('hello', name) count -= 1def main(): username = ['Alan','Bob','Cendy','Kily','Heny'] for i in range(5): # thread = threading.Thread(target=say_hi,args=(10,username[i])) thread = MyThread(10,username[i]) thread.start() # for i in range(5): # # 创建线程 # thread = threading.Thread(target=say_hi) # # 启动线程 # thread.start()class MyThread(threading.Thread): def __init__(self, count, name): super().__init__() self.count = count self.name = name def run(self): while self.count &gt; 0: print('hello', self.name) self.count -= 1def run_main(): username = ['Alan', 'Bob', 'Cendy', 'Kily', 'Heny'] for i in range(5): # thread = threading.Thread(target=say_hi, args=(10, username[i])) thread = MyThread(10,username[i]) thread.start()if __name__ == # coding:utf-8import threadingimport timedef say_hi(count,name): # time.sleep(1) #延迟几秒 # print('hello world!') while count &gt; 0: print('hello', name) count -= 1def main(): username = ['Alan','Bob','Cendy','Kily','Heny'] for i in range(5): # thread = threading.Thread(target=say_hi,args=(10,username[i])) thread = MyThread(10,username[i]) thread.start() # for i in range(5): # # 创建线程 # thread = threading.Thread(target=say_hi) # # 启动线程 # thread.start()class MyThread(threading.Thread): def __init__(self, count, name): super().__init__() self.count = count self.name = name def run(self): while self.count &gt; 0: print('hello', self.name) self.count -= 1def run_main(): username = ['Alan', 'Bob', 'Cendy', 'Kily', 'Heny'] for i in range(5): # thread = threading.Thread(target=say_hi, args=(10, username[i])) thread = MyThread(10,username[i]) thread.start()if __name__ == '__main__': run_main() 输出结果 12345678910hello Alanhello Alanhello Bobhello Bobhello Cendyhello Cendyhello Kilyhello Kilyhello Henyhello Heny 线程同步 如果多个线程共同对某个数据修改，则可能出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。 使用Thread对象的Lock和Rlock可以实现简单的线程同步，这两个对象都有acquire方法和release方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到acquire和release方法之间。如下： 多线程的优势在于可以同时运行多个任务（至少感觉起来是这样）。但是当线程需要共享数据时，可能存在数据不同步的问题。 考虑这样一种情况：一个列表里所有元素都是0，线程&quot;set&quot;从后向前把所有元素改成1，而线程&quot;print&quot;负责从前往后读取列表并打印。 那么，可能线程&quot;set&quot;开始改的时候，线程&quot;print&quot;便来打印列表了，输出就成了一半0一半1，这就是数据的不同步。为了避免这种情况，引入了锁的概念。 锁有两种状态——锁定和未锁定。每当一个线程比如&quot;set&quot;要访问共享数据时，必须先获得锁定；如果已经有别的线程比如&quot;print&quot;获得锁定了，那么就让线程&quot;set&quot;暂停，也就是同步阻塞；等到线程&quot;print&quot;访问完毕，释放锁以后，再让线程&quot;set&quot;继续。 经过这样的处理，打印列表时要么全部输出0，要么全部输出1，不会再出现一半0一半1的尴尬场面。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/python3import threadingimport timeclass myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开启线程： \" + self.name) # 获取锁，用于线程同步 threadLock.acquire() print_time(self.name, self.counter, 3) # 释放锁，开启下一个线程 threadLock.release()def print_time(threadName, delay, counter): while counter: time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1threadLock = threading.Lock()threads = []# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()# 添加线程到线程列表threads.append(thread1)threads.append(thread2)# 等待所有线程完成for t in threads: t.join()print (#!/usr/bin/python3import threadingimport timeclass myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开启线程： \" + self.name) # 获取锁，用于线程同步 threadLock.acquire() print_time(self.name, self.counter, 3) # 释放锁，开启下一个线程 threadLock.release()def print_time(threadName, delay, counter): while counter: time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1threadLock = threading.Lock()threads = []# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()# 添加线程到线程列表threads.append(thread1)threads.append(thread2)# 等待所有线程完成for t in threads: t.join()print (\"退出主线程\") 输出结果 123456789开启线程： Thread-1开启线程： Thread-2Thread-1: Thu Aug 10 20:45:59 2017Thread-1: Thu Aug 10 20:46:00 2017Thread-1: Thu Aug 10 20:46:01 2017Thread-2: Thu Aug 10 20:46:03 2017Thread-2: Thu Aug 10 20:46:05 2017Thread-2: Thu Aug 10 20:46开启线程： Thread-1开启线程： Thread-2Thread-1: Thu Aug 10 20:45:59 2017Thread-1: Thu Aug 10 20:46:00 2017Thread-1: Thu Aug 10 20:46:01 2017Thread-2: Thu Aug 10 20:46:03 2017Thread-2: Thu Aug 10 20:46:05 2017Thread-2: Thu Aug 10 20:46:07 2017退出主线程 线程优先级队列（ Queue） Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步。 Queue模块中的常用方法: Queue.qsize() 返回队列的大小 Queue.empty() 如果队列为空，返回True,反之False Queue.full() 如果队列满了，返回True,反之False Queue.full 与 maxsize 大小对应 Queue.get([block[, timeout]])获取队列，timeout等待时间 Queue.get_nowait() 相当Queue.get(False) Queue.put(item) 写入队列，timeout等待时间 Queue.put_nowait(item) 相当Queue.put(item, False) Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号 Queue.join() 实际上意味着等到队列为空，再执行别的操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/usr/bin/python3import queueimport threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, q): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.q = q def run(self): print (\"开启线程：\" + self.name) process_data(self.name, self.q) print (\"退出线程：\" + self.name)def process_data(threadName, q): while not exitFlag: queueLock.acquire() if not workQueue.empty(): data = q.get() queueLock.release() print (\"%s processing %s\" % (threadName, data)) else: queueLock.release() time.sleep(1)threadList = [\"Thread-1\", \"Thread-2\", \"Thread-3\"]nameList = [\"One\", \"Two\", \"Three\", \"Four\", \"Five\"]queueLock = threading.Lock()workQueue = queue.Queue(10)threads = []threadID = 1# 创建新线程for tName in threadList: thread = myThread(threadID, tName, workQueue) thread.start() threads.append(thread) threadID += 1# 填充队列queueLock.acquire()for word in nameList: workQueue.put(word)queueLock.release()# 等待队列清空while not workQueue.empty(): pass# 通知线程是时候退出exitFlag = 1# 等待所有线程完成for t in threads: t.join()print (#!/usr/bin/python3import queueimport threadingimport timeexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, q): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.q = q def run(self): print (\"开启线程：\" + self.name) process_data(self.name, self.q) print (\"退出线程：\" + self.name)def process_data(threadName, q): while not exitFlag: queueLock.acquire() if not workQueue.empty(): data = q.get() queueLock.release() print (\"%s processing %s\" % (threadName, data)) else: queueLock.release() time.sleep(1)threadList = [\"Thread-1\", \"Thread-2\", \"Thread-3\"]nameList = [\"One\", \"Two\", \"Three\", \"Four\", \"Five\"]queueLock = threading.Lock()workQueue = queue.Queue(10)threads = []threadID = 1# 创建新线程for tName in threadList: thread = myThread(threadID, tName, workQueue) thread.start() threads.append(thread) threadID += 1# 填充队列queueLock.acquire()for word in nameList: workQueue.put(word)queueLock.release()# 等待队列清空while not workQueue.empty(): pass# 通知线程是时候退出exitFlag = 1# 等待所有线程完成for t in threads: t.join()print (\"退出主线程\") 上面的代码每次执行的结果是不一样的，取决于哪个进程先获得锁，一次运行的输出如下： 123456789101112开启线程：Thread-1开启线程：Thread-2开启线程：Thread-3Thread-2 processing OneThread-3 processing TwoThread-1 processing ThreeThread-3 processing FourThread-1 processing Five退出线程：Thread-3退出线程：Thread-2退出线程：Thread开启线程：Thread-1开启线程：Thread-2开启线程：Thread-3Thread-2 processing OneThread-3 processing TwoThread-1 processing ThreeThread-3 processing FourThread-1 processing Five退出线程：Thread-3退出线程：Thread-2退出线程：Thread-1退出主线程 总结 如果你的代码是IO密集型的，线程和多进程可以帮到你。多进程比线程更易用，但是消耗更多的内存。如果你的代码是CPU密集型的，多进程就明显是更好的选择——特别是所使用的机器是多核或多CPU的。对于网络应用，在你需要扩展到多台机器上执行任务，RQ是更好的选择。 注：关于并发、并行区别与联系 并发是指，程序在运行的过程中存在多于一个的执行上下文。这些执行上下文一般对应着不同的调用栈。 在单处理器上，并发程序虽然有多个上下文运行环境，但某一个时刻只有一个任务在运行。 但在多处理器上，因为有了多个执行单元，就可以同时有数个任务在跑。 这种物理上同一时刻有多个任务同时运行的方式就是并行。 和并发相比，并行更加强调多个任务同时在运行。 而且并行还有一个层次问题，比如是指令间的并行还是任务间的并行。","path":"posts/2b38.html","date":"11-02","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"92 Python并发线程介绍","text":"Python 多线程 多线程类似于同时执行多个不同程序，多线程运行有如下优点： 使用线程可以把占据长时间的程序中的任务放到后台去处理。 用户界面可以更加吸引人，这样比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度 程序的运行速度可能加快 在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下我们可以释放一些珍贵的资源如内存占用等等。 线程在执行过程中与进程还是有区别的。每个独立的进程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 每个线程都有他自己的一组CPU寄存器，称为线程的上下文，该上下文反映了线程上次运行该线程的CPU寄存器的状态。 指令指针和堆栈指针寄存器是线程上下文中两个最重要的寄存器，线程总是在进程得到上下文中运行的，这些地址都用于标志拥有线程的进程地址空间中的内存。 线程可以被抢占（中断）。 在其他线程正在运行时，线程可以暂时搁置（也称为睡眠） – 这就是线程的退让。 线程和进程 计算机，用于计算的机器。计算机的核心是CPU，在现在多核心的电脑很常见了。为了充分利用cpu核心做计算任务，程序实现了多线程模型。通过多线程实现多任务的并行执行。 现在的操作系统多是多任务操作系统。每个应用程序都有一个自己的进程。操作系统会为这些进程分配一些执行资源，例如内存空间等。在进程中，又可以创建一些线程，他们共享这些内存空间，并由操作系统调用，以便并行计算。 线程状态 创建线程之后，线程并不是始终保持一个状态。其状态大概如下： New 创建。 Runnable 就绪。等待调度 Running 运行。 Blocked 阻塞。阻塞可能在 Wait Locked Sleeping Dead 消亡 这些状态之间是可以相互转换的，一图胜千颜色： 线程中执行到阻塞，可能有3种情况： 同步：线程中获取同步锁，但是资源已经被其他线程锁定时，进入Locked状态，直到该资源可获取（获取的顺序由Lock队列控制） 睡眠：线程运行sleep()或join()方法后，线程进入Sleeping状态。区别在于sleep等待固定的时间，而join是等待子线程执行完。当然join也可以指定一个“超时时间”。从语义上来说，如果两个线程a,b, 在a中调用b.join()，相当于合并(join)成一个线程。最常见的情况是在主线程中join所有的子线程。 等待：线程中执行wait()方法后，线程进入Waiting状态，等待其他线程的通知(notify）。 线程类型 线程有着不同的状态，也有不同的类型。大致可分为： 主线程 子线程 守护线程（后台线程） 前台线程 Python线程与GIL 相比进程，线程更加轻量，可以实现并发。可是在python的世界里，对于线程，就不得不说一句GIL(全局解释器锁)。GIL的存在让python的多线程多少有点鸡肋了。Cpython的线程是操作系统原生的线程在解释器解释执行任何Python代码时，都需要先获得这把锁才行，在遇到 I/O 操作时会释放这把锁。因为python的进程做为一个整体，解释器进程内只有一个线程在执行，其它的线程都处于等待状态等着GIL的释放。 关于GIL可以有更多的趣事，一时半会都说不完。总之python想用多线程并发，效果可能还不如单线程（线程切换耗时间）。想要利用多核，可以考虑使用多进程。 线程和进程 计算机的核心是CPU，它承担了所有的计算任务。它就像一座工厂，时刻在运行。 假定工厂的电力有限，一次只能供给一个车间使用。也就是说，一个车间开工的时候，其他车间都必须停工。背后的含义就是，单个CPU一次只能运行一个任务。 进程就好比工厂的车间，它代表CPU所能处理的单个任务。任一时刻，CPU总是运行一个进程，其他进程处于非运行状态。 一个车间里，可以有很多工人。他们协同完成一个任务。 线程就好比车间里的工人。一个进程可以包括多个线程。 车间的空间是工人们共享的，比如许多房间是每个工人都可以进出的。这象征一个进程的内存空间是共享的，每个线程都可以使用这些共享内存。 可是，每间房间的大小不同，有些房间最多只能容纳一个人，比如厕所。里面有人的时候，其他人就不能进去了。这代表一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。 一个防止他人进入的简单方法，就是门口加一把锁。先到的人锁上门，后到的人看到上锁，就在门口排队，等锁打开再进去。这就叫&quot;互斥锁&quot;（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域。 还有些房间，可以同时容纳n个人，比如厨房。也就是说，如果人数大于n，多出来的人只能在外面等着。这好比某些内存区域，只能供给固定数目的线程使用。 这时的解决方法，就是在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了。这种做法叫做&quot;信号量&quot;（Semaphore），用来保证多个线程不会互相冲突。 不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计。 多线程与多进程 从上面关于线程和进程的的通俗解释来看，多线程和多进程的含义如下： 多进程：允许多个任务同时进行 多线程：允许单个任务分成不同的部分运行","path":"posts/f802.html","date":"11-01","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"91 Python 操作 MySQL 写入读出 CSV 文件","text":"一.Python 操作 MySQL 写入读出 CSV 文件 有一个数据文件，是 csv 格式，大约 1T 数据，要导入到 MySQL，要求正确高效。 csv 数据格式这个样子的 12345678[root@python ~]# cat data.csvSymbol,Price,DateAA, 39.48, 6/11/2007AIG, 71.38, 6/11/2007AXP, 62.58, 6/11/2007BA, 98.31, 6/11/2007C, 53.08, 6/11/2007CAT, 78.29, 6/11/[root@python ~]# cat data.csvSymbol,Price,DateAA, 39.48, 6/11/2007AIG, 71.38, 6/11/2007AXP, 62.58, 6/11/2007BA, 98.31, 6/11/2007C, 53.08, 6/11/2007CAT, 78.29, 6/11/2007 正好最近要写再测试数据库的脚本，虽然两者不搭边，总归都是操作数据库的，正好测试的时候就用 python 连了 首先 Python 数据库接口支持很多数据库，什么关系型的像 mysql 啊、PG（PostgreSQL） 啊、SQL Server、Oracle，非关系型的像 MongoDB 啊，Redis 啊， Hbase 等等， 这里就以 MySQL 数据库为例，毕竟我要用的 MySQL 嘛，而且面试题也是，当然操作其他数据库道理也都一样，从一个 csv 文件中读入数据，插入到数据库中，再将数据库中的数据读出，保存到另一个 csv 文件。 介绍 主要定义两个对象，一个用于管理连接的 Connection（count） 了，另一个是用于执行查询的 Cursor （cur）对象。 Python 操作数据库的大致思路 导入模块 连接数据库 执行查询返回结果 步骤： 导入数据库模块 import MySQLdb 连接数据库 connect ，返回一个 conn 对象 通过该对象的 cursor() 成员函数返回一个 cur 对象 通过 cur 对象的 execute() 方法执行 SQL 语句 关闭 cur 和 conn对象 1、读文件 如何用Python像操作Excel一样提取其中的一列，即一个字段，利用Python自带的csv模块，有两种方法可以实现： 第一种方法使用reader函数，接收一个可迭代的对象（比如csv文件），能返回一个生成器，就可以从其中解析出csv的内容：比如下面的代码可以读取csv的全部内容，以行为单位： 1234567891011121314# coding=utf-8import csvfrom collections import namedtuple'''读取csv文件'''with open('data.csv') as f: f_csv = csv.reader(f) # 取出csv文件头：表头 headers = next(f_csv) # 遍历表头以外的所有行 d = namedtuple('Row', 'headers') for r # coding=utf-8import csvfrom collections import namedtuple'''读取csv文件'''with open('data.csv') as f: f_csv = csv.reader(f) # 取出csv文件头：表头 headers = next(f_csv) # 遍历表头以外的所有行 d = namedtuple('Row', 'headers') for r in f_csv: row = d(r) print(row) 输出结果 123456Row(headers=['AA', ' 39.48', ' 6/11/2007'])Row(headers=['AIG', ' 71.38', ' 6/11/2007'])Row(headers=['AXP', ' 62.58', ' 6/11/2007'])Row(headers=['BA', ' 98.31', ' 6/11/2007'])Row(headers=['C', ' 53.08', ' 6/11/2007'])Row(headers=['CAT', ' 78.29', Row(headers=['AA', ' 39.48', ' 6/11/2007'])Row(headers=['AIG', ' 71.38', ' 6/11/2007'])Row(headers=['AXP', ' 62.58', ' 6/11/2007'])Row(headers=['BA', ' 98.31', ' 6/11/2007'])Row(headers=['C', ' 53.08', ' 6/11/2007'])Row(headers=['CAT', ' 78.29', ' 6/11/2007']) 或 123456789101112#!/usr/bin/python3# -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.reader(f) rows = [row for row #!/usr/bin/python3# -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.reader(f) rows = [row for row in reader]print(rows) 输出结果 1234567[['Symbol', 'Price', 'Date'], ['AA', ' 39.48', ' 6/11/2007'], ['AIG', ' 71.38', ' 6/11/2007'], ['AXP', ' 62.58', ' 6/11/2007'], ['BA', ' 98.31', ' 6/11/2007'], ['C', ' 53.08', ' 6/11/2007'], ['CAT', ' 78.29', [['Symbol', 'Price', 'Date'], ['AA', ' 39.48', ' 6/11/2007'], ['AIG', ' 71.38', ' 6/11/2007'], ['AXP', ' 62.58', ' 6/11/2007'], ['BA', ' 98.31', ' 6/11/2007'], ['C', ' 53.08', ' 6/11/2007'], ['CAT', ' 78.29', ' 6/11/2007']] 要提取其中某一列，可以用下面的代码： 123456789101112#!/usr/bin/python3# -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读取第二列的内容with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.reader(f) column = [row[1] for row #!/usr/bin/python3# -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读取第二列的内容with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.reader(f) column = [row[1] for row in reader]print(column) 输出结果 1['Price', ' 39.48', ' 71.38', ' 62.58', ' 98.31', ' 53.08', ['Price', ' 39.48', ' 71.38', ' 62.58', ' 98.31', ' 53.08', ' 78.29'] 注意从csv读出的都是str类型。这种方法要事先知道列的序号，比如Name在第2列，而不能根据’Name’这个标题查询。这时可以采用第二种方法： 2、第二种方法 是使用DictReader，和reader函数类似，接收一个可迭代的对象，能返回一个生成器，但是返回的每一个单元格都放在一个字典的值内，而这个字典的键则是这个单元格的标题（即列头）。用下面的代码可以看到DictReader的结构： 1234567891011# -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.DictReader(f) column = [row for row # -*- coding:utf-8 -*-__author__ = 'mayi'import csv#读with open(\"data.csv\", \"r\", encoding = \"utf-8\") as f: reader = csv.DictReader(f) column = [row for row in reader]print(column) 输出结果 123456[&#123;'Symbol': 'AA', 'Price': ' 39.48', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'AIG', 'Price': ' 71.38', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'AXP', 'Price': ' 62.58', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'BA', 'Price': ' 98.31', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'C', 'Price': ' 53.08', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'CAT', 'Price': ' 78.29', 'Date': [&#123;'Symbol': 'AA', 'Price': ' 39.48', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'AIG', 'Price': ' 71.38', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'AXP', 'Price': ' 62.58', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'BA', 'Price': ' 98.31', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'C', 'Price': ' 53.08', 'Date': ' 6/11/2007'&#125;, &#123;'Symbol': 'CAT', 'Price': ' 78.29', 'Date': ' 6/11/2007'&#125;] 3、把 csv 中的数据读出来放到插入到 mysql 表 对于 mysql 数据库，需要安装第三方模块 Mysql-python 。安装完以后，在程序中导入模块即可。 库名：student_info 表名：data_csv 首先要导入 MySQLdb 模块先安装 MySQLdb 1pip install MySQLdb 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# coding=utf-8import pymysql as dbimport csvfrom collections import namedtuplefrom contextlib import contextmanager@contextmanagerdef get_conn(**kwargs): '''获取mysql数据库连接''' conn = db.connect( host=kwargs.get('host'), user=kwargs.get('user'), passwd=kwargs.get('passwd'), port=kwargs.get('port', 3306), db=kwargs.get('db')) try: yield conn finally: if conn: conn.close()def get_data(filename): '''读取csv文件''' with open(filename) as f: f_csv = csv.reader(f) # 取出csv文件头：表头 headers = next(f_csv) # 遍历表头以外的所有行 Row = namedtuple(\"Row\", ['Symbol', 'Price', 'Date']) for r in f_csv: yield Row(*r)def execute_sql(conn, sql): '''执行SQL的函数''' with conn as cur: cur.execute(sql)def create_table(conn): '''创建新表''' sql_drop_table = 'drop table if exists data_csv' sql_create_table = '''create table `data_csv`( `Symbol` varchar (20) not null, `Price` decimal not null, `Date` varchar (20) default null) engine=innodb default charset=utf8mb4 ''' for sql in [sql_drop_table, sql_create_table]: execute_sql(conn, sql)def insert_data(conn, symbol, price, date): insert_format = \"insert into data_csv values('&#123;0&#125;','&#123;1&#125;','&#123;2&#125;')\" sql = insert_format.format(symbol, price, date) execute_sql(conn, sql)def main(): conn_args = dict(host='127.0.0.1', user='root', passwd='123456', port=3306, db='student_info') with get_conn(**conn_args) as conn: with conn as cur: create_table(conn) for t in get_data('data.csv'): insert_data(conn, t.Symbol, t.Price, t.Date)if __name__ == # coding=utf-8import pymysql as dbimport csvfrom collections import namedtuplefrom contextlib import contextmanager@contextmanagerdef get_conn(**kwargs): '''获取mysql数据库连接''' conn = db.connect( host=kwargs.get('host'), user=kwargs.get('user'), passwd=kwargs.get('passwd'), port=kwargs.get('port', 3306), db=kwargs.get('db')) try: yield conn finally: if conn: conn.close()def get_data(filename): '''读取csv文件''' with open(filename) as f: f_csv = csv.reader(f) # 取出csv文件头：表头 headers = next(f_csv) # 遍历表头以外的所有行 Row = namedtuple(\"Row\", ['Symbol', 'Price', 'Date']) for r in f_csv: yield Row(*r)def execute_sql(conn, sql): '''执行SQL的函数''' with conn as cur: cur.execute(sql)def create_table(conn): '''创建新表''' sql_drop_table = 'drop table if exists data_csv' sql_create_table = '''create table `data_csv`( `Symbol` varchar (20) not null, `Price` decimal not null, `Date` varchar (20) default null) engine=innodb default charset=utf8mb4 ''' for sql in [sql_drop_table, sql_create_table]: execute_sql(conn, sql)def insert_data(conn, symbol, price, date): insert_format = \"insert into data_csv values('&#123;0&#125;','&#123;1&#125;','&#123;2&#125;')\" sql = insert_format.format(symbol, price, date) execute_sql(conn, sql)def main(): conn_args = dict(host='127.0.0.1', user='root', passwd='123456', port=3306, db='student_info') with get_conn(**conn_args) as conn: with conn as cur: create_table(conn) for t in get_data('data.csv'): insert_data(conn, t.Symbol, t.Price, t.Date)if __name__ == '__main__': main()","path":"posts/5bf9.html","date":"10-30","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"90 Python 操作 MySQL 数据库","text":"Python 操作 MySQL 数据库 Python 标准数据库接口为 Python DB-API，Python DB-API为开发人员提供了数据库应用编程接口。 Python 数据库接口支持非常多的数据库，你可以选择适合你项目的数据库： GadFly mSQL MySQL PostgreSQL Microsoft SQL Server 2000 Informix Interbase Oracle Sybase 你可以访问Python数据库接口及API查看详细的支持数据库列表。 不同的数据库你需要下载不同的DB API模块，例如你需要访问Oracle数据库和Mysql数据，你需要下载Oracle和MySQL数据库模块。 DB-API 是一个规范. 它定义了一系列必须的对象和数据库存取方式, 以便为各种各样的底层数据库系统和多种多样的数据库接口程序提供一致的访问接口 。 Python的DB-API，为大多数的数据库实现了接口，使用它连接各数据库后，就可以用相同的方式操作各数据库。 Python DB-API使用流程： 引入 API 模块。 获取与数据库的连接。 执行SQL语句和存储过程。 关闭数据库连接。 1、什么是MySQLdb? MySQLdb 是用于Python链接Mysql数据库的接口，它实现了 Python 数据库 API 规范 V2.0，基于 MySQL C API 上建立的。 2、如何安装MySQLdb? 为了用DB-API编写MySQL脚本，必须确保已经安装了MySQL。复制以下代码，并执行： 1234#!/usr/bin/python# -*- coding: UTF-8 -*-#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb 如果执行后的输出结果如下所示，意味着你没有安装 MySQLdb 模块： 1234Traceback (most recent call last): File \"test.py\", line 3, in &lt;module&gt; Traceback (most recent call last): File \"test.py\", line 3, in &lt;module&gt; import MySQLdbImportError: No module named MySQLdb 安装MySQLdb，请访问 http://sourceforge.net/projects/mysql-python ，(Linux平台可以访问：https://pypi.python.org/pypi/MySQL-python)从这里可选择适合您的平台的安装包，分为预编译的二进制文件和源代码安装包。 如果您选择二进制文件发行版本的话，安装过程基本安装提示即可完成。如果从源代码进行安装的话，则需要切换到MySQLdb发行版本的顶级目录，并键入下列命令: 12345$ gunzip MySQL-python-1.2.2.tar.gz$ tar -xvf MySQL-python-1.2.2.tar$ cd MySQL-python-1.2$ gunzip MySQL-python-1.2.2.tar.gz$ tar -xvf MySQL-python-1.2.2.tar$ cd MySQL-python-1.2.2$ python setup.py build$ python setup.py install **注意：**请确保您有root权限来安装上述模块。 3、数据库连接 连接数据库前，请先确认以下事项： 您已经创建了数据库 TESTDB. 在TESTDB数据库中您已经创建了表 EMPLOYEE EMPLOYEE表字段为 FIRST_NAME, LAST_NAME, AGE, SEX 和 INCOME。 连接数据库TESTDB使用的用户名为 “testuser” ，密码为 “test123”,你可以可以自己设定或者直接使用root用户名及其密码，Mysql数据库用户授权请使用Grant命令。 在你的机子上已经安装了 Python MySQLdb 模块。 如果您对sql语句不熟悉，可以访问我们的 SQL基础教程 实例1： 以下实例链接Mysql的student_info数据库： 12345678910111213141516171819202122#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标cursor = db.cursor()# 使用execute方法执行SQL语句cursor.execute(\"SELECT VERSION()\")# 使用 fetchone() 方法获取一条数据data = cursor.fetchone()print(\"Database version : %s\" % data)#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标cursor = db.cursor()# 使用execute方法执行SQL语句cursor.execute(\"SELECT VERSION()\")# 使用 fetchone() 方法获取一条数据data = cursor.fetchone()print(\"Database version : %s\" % data)# 关闭数据库连接db.close() 执行以上脚本输出结果如下： 1Database version : 5.7Database version : 5.7.14-log 实例2： 以下实例链接Mysql的student_info数据库并查看user表 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# encoding=utf-8import pymysql as dbfrom contextlib import contextmanager@contextmanagerdef get_conn(**kwargs): '''获取mysql数据库连接''' conn = db.connect( host=kwargs.get('host'), user=kwargs.get('user'), passwd=kwargs.get('passwd'), port=kwargs.get('port', 3306), db=kwargs.get('db')) try: yield conn finally: if conn: conn.close()def execute_sql(conn, sql): '''执行SQL的函数''' # cur = conn.cursor() with conn as cur: cur.execute(sql)def create_table(conn): '''创建新表''' sql_drop_table = 'drop table if exists student' sql_create_table = '''create table `student`( `sno` int(11) not null, `sname` varchar(25) default null, `sage` int(11) default null, primary key (`sno`)) engine=innodb default charset=utf8mb4 ''' for sql in [sql_drop_table, sql_create_table]: execute_sql(conn, sql)def insert_data(conn, sno, sname, sage): insert_format = \"insert into student values(&#123;0&#125;,'&#123;1&#125;',&#123;2&#125;)\" sql = insert_format.format(sno, sname, sage) execute_sql(conn, sql)def main(): conn_args = dict(host='127.0.0.1', user='root', passwd='123456', port=3306, db='student_info') with get_conn(**conn_args) as conn: with conn as cur: cur.execute('select * from user') rows = cur.fetchall() for row in rows: print(row)if __name__ == # encoding=utf-8import pymysql as dbfrom contextlib import contextmanager@contextmanagerdef get_conn(**kwargs): '''获取mysql数据库连接''' conn = db.connect( host=kwargs.get('host'), user=kwargs.get('user'), passwd=kwargs.get('passwd'), port=kwargs.get('port', 3306), db=kwargs.get('db')) try: yield conn finally: if conn: conn.close()def execute_sql(conn, sql): '''执行SQL的函数''' # cur = conn.cursor() with conn as cur: cur.execute(sql)def create_table(conn): '''创建新表''' sql_drop_table = 'drop table if exists student' sql_create_table = '''create table `student`( `sno` int(11) not null, `sname` varchar(25) default null, `sage` int(11) default null, primary key (`sno`)) engine=innodb default charset=utf8mb4 ''' for sql in [sql_drop_table, sql_create_table]: execute_sql(conn, sql)def insert_data(conn, sno, sname, sage): insert_format = \"insert into student values(&#123;0&#125;,'&#123;1&#125;',&#123;2&#125;)\" sql = insert_format.format(sno, sname, sage) execute_sql(conn, sql)def main(): conn_args = dict(host='127.0.0.1', user='root', passwd='123456', port=3306, db='student_info') with get_conn(**conn_args) as conn: with conn as cur: cur.execute('select * from user') rows = cur.fetchall() for row in rows: print(row)if __name__ == '__main__': main() 执行以上脚本输出结果如下： 1((111,) 4、创建数据库表 如果数据库连接存在我们可以使用execute()方法来为数据库创建表，如下所示创建表EMPLOYEE： 123456789101112131415161718192021222324252627#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# 如果数据表已经存在使用 execute() 方法删除表。cursor.execute(\"DROP TABLE IF EXISTS EMPLOYEE\")# 创建数据表SQL语句sql = \"\"\"CREATE TABLE EMPLOYEE ( FIRST_NAME CHAR(20) NOT NULL, LAST_NAME CHAR(20), AGE INT, SEX CHAR(1), INCOME FLOAT )\"\"\"cursor.execute(sql)#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# 如果数据表已经存在使用 execute() 方法删除表。cursor.execute(\"DROP TABLE IF EXISTS EMPLOYEE\")# 创建数据表SQL语句sql = \"\"\"CREATE TABLE EMPLOYEE ( FIRST_NAME CHAR(20) NOT NULL, LAST_NAME CHAR(20), AGE INT, SEX CHAR(1), INCOME FLOAT )\"\"\"cursor.execute(sql)# 关闭数据库连接db.close() 5、数据库插入操作 以下实例使用执行 SQL INSERT 语句向表 EMPLOYEE 插入记录 123456789101112131415161718192021222324252627#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 插入语句sql = \"\"\"INSERT INTO EMPLOYEE(FIRST_NAME, LAST_NAME, AGE, SEX, INCOME) VALUES ('Mac', 'Mohan', 20, 'M', 2000)\"\"\"try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # Rollback in case there is any error db.rollback()#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 插入语句sql = \"\"\"INSERT INTO EMPLOYEE(FIRST_NAME, LAST_NAME, AGE, SEX, INCOME) VALUES ('Mac', 'Mohan', 20, 'M', 2000)\"\"\"try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # Rollback in case there is any error db.rollback()# 关闭数据库连接db.close() 以上例子也可以写成如下形式： 12345678910111213141516171819202122232425262728#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 插入语句sql = \"INSERT INTO EMPLOYEE(FIRST_NAME, \\ LAST_NAME, AGE, SEX, INCOME) \\ VALUES (%s, %s, %s, %s, %s )\" % \\ ('Mac', 'Mohan', 20, 'M', 2000)try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # 发生错误时回滚 db.rollback()#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 插入语句sql = \"INSERT INTO EMPLOYEE(FIRST_NAME, \\ LAST_NAME, AGE, SEX, INCOME) \\ VALUES (%s, %s, %s, %s, %s )\" % \\ ('Mac', 'Mohan', 20, 'M', 2000)try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # 发生错误时回滚 db.rollback()# 关闭数据库连接db.close() 6、数据库查询操作 Python查询Mysql使用 fetchone() 方法获取单条数据, 使用fetchall() 方法获取多条数据。 fetchone(): 该方法获取下一个查询结果集。结果集是一个对象 fetchall():接收全部的返回结果行. rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。 实例： 查询EMPLOYEE表中salary（工资）字段大于1000的所有数据： 12345678910111213141516171819202122232425262728293031323334#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标cursor = db.cursor()# SQL 查询语句sql = \"SELECT * FROM EMPLOYEE \\ WHERE INCOME &gt; %s\" % (1000)try: # 执行SQL语句 cursor.execute(sql) # 获取所有记录列表 results = cursor.fetchall() for row in results: fname = row[0] lname = row[1] age = row[2] sex = row[3] income = row[4] # 打印结果 print(\"fname=%s,lname=%s,age=%s,sex=%s,income=%s\" % \\ (fname, lname, age, sex, income ))except: print(\"Error: unable to fecth data\")#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标cursor = db.cursor()# SQL 查询语句sql = \"SELECT * FROM EMPLOYEE \\ WHERE INCOME &gt; %s\" % (1000)try: # 执行SQL语句 cursor.execute(sql) # 获取所有记录列表 results = cursor.fetchall() for row in results: fname = row[0] lname = row[1] age = row[2] sex = row[3] income = row[4] # 打印结果 print(\"fname=%s,lname=%s,age=%s,sex=%s,income=%s\" % \\ (fname, lname, age, sex, income ))except: print(\"Error: unable to fecth data\")# 关闭数据库连接db.close() 以上脚本执行结果如下： 1fname=Mac,lname=Mohan,age=20,sex=M,income=fname=Mac,lname=Mohan,age=20,sex=M,income=2000.0 7、数据库更新操作 更新操作用于更新数据表的的数据，以下实例将 EMPLOYEE 表中的 SEX 字段为 ‘M’ 的 AGE 字段递增 1： 12345678910111213141516171819202122232425#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 更新语句sql = \"UPDATE EMPLOYEE SET AGE = AGE + 1 WHERE SEX = '%c'\" % ('M')try: # 执行SQL语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # 发生错误时回滚 db.rollback()#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 更新语句sql = \"UPDATE EMPLOYEE SET AGE = AGE + 1 WHERE SEX = '%c'\" % ('M')try: # 执行SQL语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # 发生错误时回滚 db.rollback()# 关闭数据库连接db.close() 8、删除操作 删除操作用于删除数据表中的数据，以下实例演示了删除数据表 EMPLOYEE 中 AGE 大于 20 的所有数据： 12345678910111213141516171819202122232425#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 删除语句sql = \"DELETE FROM EMPLOYEE WHERE AGE &gt; %s\" % (20)try: # 执行SQL语句 cursor.execute(sql) # 提交修改 db.commit()except: # 发生错误时回滚 db.rollback()#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(\"127.0.0.1\", \"root\", \"123456\", \"student_info\", charset='utf8' )#db = MySQLdb.connect(\"ip地址\", \"用户\", \"密码\", \"数据库\", charset='utf8' )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 删除语句sql = \"DELETE FROM EMPLOYEE WHERE AGE &gt; %s\" % (20)try: # 执行SQL语句 cursor.execute(sql) # 提交修改 db.commit()except: # 发生错误时回滚 db.rollback()# 关闭连接db.close() 9、执行事务 事务机制可以确保数据一致性。 事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。 原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。 一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。 Python DB API 2.0 的事务提供了两个方法 commit 或 rollback。 实例： 12345678910# SQL删除记录语句sql = \"DELETE FROM EMPLOYEE WHERE AGE &gt; %s\" % (20)try: # 执行SQL语句 cursor.execute(sql) # 向数据库提交 db.commit()except: # SQL删除记录语句sql = \"DELETE FROM EMPLOYEE WHERE AGE &gt; %s\" % (20)try: # 执行SQL语句 cursor.execute(sql) # 向数据库提交 db.commit()except: # 发生错误时回滚 db.rollback() 对于支持事务的数据库， 在Python数据库编程中，当游标建立之时，就自动开始了一个隐形的数据库事务。 commit()方法游标的所有更新操作，rollback（）方法回滚当前游标的所有操作。每一个方法都开始了一个新的事务。 10、错误处理 DB API中定义了一些数据库操作的错误及异常，下表列出了这些错误和异常: 异常 描述 Warning 当有严重警告时触发，例如插入数据是被截断等等。必须是 StandardError 的子类。 Error 警告以外所有其他错误类。必须是 StandardError 的子类。 InterfaceError 当有数据库接口模块本身的错误（而不是数据库的错误）发生时触发。 必须是Error的子类。 DatabaseError 和数据库有关的错误发生时触发。 必须是Error的子类。 DataError 当有数据处理时的错误发生时触发，例如：除零错误，数据超范围等等。 必须是DatabaseError的子类。 OperationalError 指非用户控制的，而是操作数据库时发生的错误。例如：连接意外断开、 数据库名未找到、事务处理失败、内存分配错误等等操作数据库是发生的错误。 必须是DatabaseError的子类。 IntegrityError 完整性相关的错误，例如外键检查失败等。必须是DatabaseError子类。 InternalError 数据库的内部错误，例如游标（cursor）失效了、事务同步失败等等。 必须是DatabaseError子类。 ProgrammingError 程序错误，例如数据表（table）没找到或已存在、SQL语句语法错误、 参数数量错误等等。必须是DatabaseError的子类。 NotSupportedError 不支持错误，指使用了数据库不支持的函数或API等。例如在连接对象上 使用.rollback()函数，然而数据库并不支持事务或者事务已关闭。 必须是DatabaseError的子类。","path":"posts/26aa.html","date":"10-29","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"89 Python 中的上下文管理器","text":"python with语句上下文管理的两种实现方法 在编程中会经常碰到这种情况：有一个特殊的语句块，在执行这个语句块之前需要先执行一些准备动作；当语句块执行完成后，需要继续执行一些收尾动作。例如，文件读写后需要关闭，数据库读写完毕需要关闭连接，资源的加锁和解锁等情况。 对于这种情况python提供了上下文管理器（Context Manager）的概念，可以通过上下文管理器来定义/控制代码块执行前的准备动作，以及执行后的收尾动作。 上下文管理器 with语句:可以确保某些事情(如关闭资源、释放锁)一定会发生。 先创建一个t.txt文件，里面随便写点东西 然后编写代码 12345678try: f = open('t.txt') print(f.read())finally: f.close()with open('t.txt') try: f = open('t.txt') print(f.read())finally: f.close()with open('t.txt') as f: print(f.read()) 输出结果 12fewfwefweweffewfwefwewef 一、为何使用上下文管理器 在我看来，这和 Python 崇尚的优雅风格有关。 可以以一种更加优雅的方式，操作（创建/获取/释放）资源，如文件操作、数据库连接； 可以以一种更加优雅的方式，处理异常； 第一种，我们上面已经以资源的连接为例讲过了。 而第二种，会被大多数人所忽略。这里会重点讲一下。 大家都知道，处理异常，通常都是使用 try...execept.. 来捕获处理的。这样做一个不好的地方是，在代码的主逻辑里，会有大量的异常处理代理，这会很大的影响我们的可读性。 好一点的做法呢，可以使用 with 将异常的处理隐藏起来。 1、不使用上下文管理器的情况 通过try…finally语句执行异常处理和关闭句柄的动作。 12345678logger = open(\"t.txt\", \"w\")try: logger.write('Hello ') logger.write('World')logger = open(\"t.txt\", \"w\")try: logger.write('Hello ') logger.write('World')finally: logger.close()print(logger.closed) 2、使用上下文管理器 默认文件Python的内置file类型是支持上下文管理协议的。 使用上下文管理器with使得依据精简了很多。 12345with open(\"t.txt\", \"w\") as logger: logger.write('Hello ') logger.write(with open(\"t.txt\", \"w\") as logger: logger.write('Hello ') logger.write('World')print(logger.closed) 或 1234567891011121314151617# coding=utf-8import codecsclass Open(object): def __init__(self, filename, mode, encoding='utf-8'): self.fp = codecs.open(filename, mode, encoding) def __enter__(self): return self.fp def __exit__(self, exc_type, exc_val, exc_tb): self.fp.close()data = u'Hello World'with Open('t.txt','w') # coding=utf-8import codecsclass Open(object): def __init__(self, filename, mode, encoding='utf-8'): self.fp = codecs.open(filename, mode, encoding) def __enter__(self): return self.fp def __exit__(self, exc_type, exc_val, exc_tb): self.fp.close()data = u'Hello World'with Open('t.txt','w') as f: f.write(data) 以上三种方法都会在t.txt中写入Hello World数据。 二、实现上下文管理器 实现上下文管理器有两种方式实现。 方法一：类实现enter和exit方法。 方法二：contextlib模块装饰器和生成器实现。 下面我们通过两种方法分别实现一个自定义的上下文管理器。 1、方法一：通过类实现__enter__和__exit__方法 12345678910class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, type, value, traceback): self.file_obj.close()with File('t.txt', 'w') as opened_file: opened_file.write(class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, type, value, traceback): self.file_obj.close()with File('t.txt', 'w') as opened_file: opened_file.write('Hola!') 以上这种方法会在t.txt中写入Hola!数据。 实现__enter__和__exit__方法后，就能通过with语句进行上下文管理。 a、底层都发生了什么？ 1231、with语句先暂存了File类的__exit__方法，然后它调用File类的__enter__方法。2、__enter__方法打开文件并返回给with语句，打开的文件句柄被传递给opened_file参数。3、1、with语句先暂存了File类的__exit__方法，然后它调用File类的__enter__方法。2、__enter__方法打开文件并返回给with语句，打开的文件句柄被传递给opened_file参数。3、with语句调用之前暂存的__exit__方法，__exit__方法关闭了文件。 b、异常处理 12345关于异常处理，with语句会采取哪些步骤。1. 它把异常的type,value和traceback传递给__exit__方法2. 它让__exit__方法来处理异常 3. 如果__exit__返回的是True，那么这个异常就被忽略。4. 如果__exit__返回的是True以外的任何东西，那么这个异常将被关于异常处理，with语句会采取哪些步骤。1. 它把异常的type,value和traceback传递给__exit__方法2. 它让__exit__方法来处理异常 3. 如果__exit__返回的是True，那么这个异常就被忽略。4. 如果__exit__返回的是True以外的任何东西，那么这个异常将被with语句抛出。 （1）异常抛出 123456789101112131415#异常抛出，_exit__返回的是True以外的任何东西，那么这个异常将被with语句抛出class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, type, value, traceback): self.file_obj.close() print(\"type:\",type) print(\"value:\",value) print(\"traceback:\",traceback)with File('t.txt', 'w') as opened_file: opened_file.undefined_function(#异常抛出，_exit__返回的是True以外的任何东西，那么这个异常将被with语句抛出class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, type, value, traceback): self.file_obj.close() print(\"type:\",type) print(\"value:\",value) print(\"traceback:\",traceback)with File('t.txt', 'w') as opened_file: opened_file.undefined_function('Hola!') 输出结果 1234567type: &lt;class 'AttributeError'&gt;value: '_io.TextIOWrapper' object has no attribute 'undefined_function'traceback: &lt;traceback object at 0x000001BEB1AD7F00&gt;Traceback (most recent call last): File \"G:/四期/python/Pytghon_MySQL/上下文管理器/666.py\", line 15, in &lt;module&gt; opened_file.undefined_function('Hola!')AttributeError: '_io.TextIOWrapper' object has no attribute type: &lt;class 'AttributeError'&gt;value: '_io.TextIOWrapper' object has no attribute 'undefined_function'traceback: &lt;traceback object at 0x000001BEB1AD7F00&gt;Traceback (most recent call last): File \"G:/四期/python/Pytghon_MySQL/上下文管理器/666.py\", line 15, in &lt;module&gt; opened_file.undefined_function('Hola!')AttributeError: '_io.TextIOWrapper' object has no attribute 'undefined_function' （2）异常忽略： 12345678910111213141516# 异常忽略，__exit__返回的是True，那么这个异常就被忽略。class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, exception_type, exception_value, traceback): print(\"Exception has been handled\") self.file_obj.close() return Truewith File('t.txt', 'w') as opened_file: opened_file.undefined_function(# 异常忽略，__exit__返回的是True，那么这个异常就被忽略。class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, exception_type, exception_value, traceback): print(\"Exception has been handled\") self.file_obj.close() return Truewith File('t.txt', 'w') as opened_file: opened_file.undefined_function('Hola!') 输出结果 1Exception has been handled 2、方法二：contextlib模块装饰器和生成器实现 这种方式实现更优雅，我个人更喜欢这种方式。 yield之前的代码由__enter__方法执行，yield之后的代码由__exit__方法执行。本质上还是__enter__和__exit__方法。 1234567891011121314# coding=utf-8import codecsfrom contextlib import contextmanager@contextmanagerdef Open(filename,mode,encoding='utf-8'): fp = codecs.open(filename,mode,encoding) try: yield fp finally: fp.close()data = u'上下文--管理器'with Open('t.txt','w') # coding=utf-8import codecsfrom contextlib import contextmanager@contextmanagerdef Open(filename,mode,encoding='utf-8'): fp = codecs.open(filename,mode,encoding) try: yield fp finally: fp.close()data = u'上下文--管理器'with Open('t.txt','w') as f: f.write(data) 以上这种方法会在t.txt中写入上下文--管理器数据。 或 12345678910111213141516171819202122from contextlib import closingclass OpenMyFile(object): def __init__(self, path): print(\"opening the txt\") self.f = open(path, \"w\") def write(self, string): self.f.write(string) def close(self): print(\"closing the txt\") self.f.close()with closing(OpenMyFile(\"t.txt\")) as file: file.write(\"this is demo4\")# 输出：print(\"opening the txt\")print(from contextlib import closingclass OpenMyFile(object): def __init__(self, path): print(\"opening the txt\") self.f = open(path, \"w\") def write(self, string): self.f.write(string) def close(self): print(\"closing the txt\") self.f.close()with closing(OpenMyFile(\"t.txt\")) as file: file.write(\"this is demo4\")# 输出：print(\"opening the txt\")print(\"closing the txt\") 以上这种方法会在t.txt中写入this is demo4数据。 输出结果 1234opening the txtclosing the txtopening the txtclosing the txt 3、方法三（@contextmanager） 利用contextlib中的contextmanager装饰器。 123456789101112131415161718from contextlib import contextmanager@contextmanagerdef open_my_file(path): print(\"opening the txt\") f = open(\"t.txt\", \"w\") yield f print(\"closing the txt\") f.close()with open_my_file(\"t.txt\") as file: file.write(\"this is demo3\")# 输出：print(\"opening the txt\")print(from contextlib import contextmanager@contextmanagerdef open_my_file(path): print(\"opening the txt\") f = open(\"t.txt\", \"w\") yield f print(\"closing the txt\") f.close()with open_my_file(\"t.txt\") as file: file.write(\"this is demo3\")# 输出：print(\"opening the txt\")print(\"closing the txt\") 以上这种方法会在t.txt中写入this is demo3数据。 输出结果 1234opening the txtclosing the txtopening the txtclosing the txt 4、with语句上多个下文关联 直接通过一个with语句打开多个上下文，即可同时使用多个上下文变量，而不必需嵌套使用with语句。 1234567891011121314class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, exception_type, exception_value, traceback): self.file_obj.close() return Truewith File('t.txt', 'w') as f1, File('t.txt', 'w') class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, exception_type, exception_value, traceback): self.file_obj.close() return Truewith File('t.txt', 'w') as f1, File('t.txt', 'w') as f2: print(f1, f2) 输出结果 1&lt;_io.TextIOWrapper name='t.txt' mode='w' encoding='cp936'&gt; &lt;_io.TextIOWrapper name='t.txt' mode='w' encoding=&lt;_io.TextIOWrapper name='t.txt' mode='w' encoding='cp936'&gt; &lt;_io.TextIOWrapper name='t.txt' mode='w' encoding='cp936'> 总结 本文介绍了Python中的上下文管理器，以及如何结合with语句来使用上下文管理器。 总结一下with 语句的执行流程： 执行context_expr 以获取上下文管理器对象 调用上下文管理器的 enter() 方法 如果有 as var 从句，则将 enter() 方法的返回值赋给 var 执行代码块 with_suite 调用上下文管理器的 exit() 方法，如果 with_suite 产生异常，那么该异常的 type、value 和 traceback 会作为参数传给 exit()，否则传三个 None 如果 with_suite 产生异常，并且 exit() 的返回值等于 False，那么这个异常将被重新抛出到上层 如果 with_suite 产生异常，兵器 exit() 的返回值等于 True，那么这个异常就被忽略，继续执行后面的代码 在很多情况下，with语句可以简化代码，并增加代码的健壮性。 使用上下文管理器有三个好处： 提高代码的复用率； 提高代码的优雅度； 提高代码的可读性； With 语句的实际执行流程是这样的： 执行 context_exp 以获取上下文管理器 加载上下文管理器的 __exit__() 方法以备稍后调用 调用上下文管理器的 __enter__() 方法 如果有 as var 从句，则将 __enter__() 方法的返回值赋给 var 执行子代码块 with_suit 调用上下文管理器的 __exit__() 方法，如果 with_suit 的退出是由异常引发的，那么该异常的 type、value 和 traceback 会作为参数传给 __exit__()，否则传三个 None 如果 with_suit 的退出由异常引发，并且 __exit__() 的返回值等于 False，那么这个异常将被重新引发一次；如果 __exit__() 的返回值等于 True，那么这个异常就被无视掉，继续执行后面的代码","path":"posts/7aea.html","date":"10-28","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"77 python自动化管理Ansible（Ansible，Fabric，hosts）","text":"一、Ansible介绍 Ansible是一个简单的自动化运维工具，可完成配置管理、应用部署、服务编排以及其他各种IT需求。Ansible也是一款基于Python语言实现的开源软件，其依赖Jinja2、paramiko和PYYAML这几个Python库。 1Ansible的作者是Michael Dehaan，Michael Dehaan同时也是知名软件Cobber的作者和Func的共同作者。Michael Dehaan与2012年创建了AnsibleWorks公司，之后改名为Ansible公司。Ansible公司与2015年10月被红帽公司（Red Hat）收购。 在这一小节，我们将首先介绍Ansible的优点，然后比较Ansible与Fabric之间的差异。 1、Ansible的优点 Ansible作为配置工具，通常与Puppet、Chef、Saltstack进行比较，如下所示： 工具 发布时间 语言 架构 协议 Puppet 2005年 Ruby C/S http Chef 2008年 Ruby C/S http Saltstack 2012年 Python C/S（可无Client） ssh/zmq/raet Ansible 2013年 Python 无Client ssh 从发布时间来看，Ansible完全没有优势，那么，是什么特性让Ansible进入了工程师的视野，并且逐步获得青睐呢？我们需要了解一下Ansible有哪些优点。 Ansible具有以下几个优点： （1）部署简单 1只需要在主控端部署Ansible环境，被控端无须做任何操作。换句话说，在安装Ansible时，远程服务器无烦安装任何依赖。因此，相对于其他配置管理器，Ansible安装部署非常简单，省去了客户端的安装。在数千台规模的大型数据中心意味着少了一些路由和安全策略的配置，省去了很多不必要的麻烦。 （2）基于ssh进行配置管理，充分利用现成的机制 1Ansible不依赖与客户端，直接使用ssh进行配置管理，在Ansible早期版本中，默认使用paramiko进行配置管理，从Ansible1.3版本开始，Ansible默认使用OpenSSH实现个服务器间通信。 （3）Ansible不需要守护进程 1因为Ansible依赖OpenSSH进行通信，不需要安装客户端，因此服务端也不需要像其他配置管理一样使用一个守护进程。Ansible的安装和维护都变得更加简单，系统更加安全可靠。 （4）日志集中存储 1所有操作日志都存储在Ansible发起服务器，可以采用自定义的格式，这样可以很方便地知晓哪些服务器操作有问题，哪些已经成功，也便于日后追溯。 （5）Ansible简单易用 1Ansible和其他配置管理工具一样，运行一个部署命令就可以完成应用部署，使用非常简单。此外，Ansible使用YAML语法管理配置，YAML本身是一种可读性非常强的标记语言，工程师几乎像阅读英文一样阅读YAML的配置文件。因为Ansible使用YAML管理配置，所以使用Ansible不需要使用者具有任何编程背景。运维自动化工具本身是用来简化运维工作的，如果本身比较复杂（如Puppet），甚至需要一定的程序开发能力，那么就会增加使用者的使用难度和犯错的概率。 （6）Ansible功能强大 1Ansible通过模块来实现各种功能，目前，Ansible已经有了950多个模块，工程师也可以使用任何语言编写自定义的Ansible模块。 （7）Ansible设计优秀，便于分享 1Ansible使用role组织Playbook，并提供了分享role的平台（galaxy.ansible.com），便于大家分享和复用。充分使用role，可以编写可读性更强的配置文件。使用开源的role，能够有效节省编写Playbook的时间。 （8）Ansible对云计算和大数据平台都有很好的支持 1从Ansible的模块列表可以看到，Ansible包含了大量与云服务、AWS、OpenStack、Docker等相关的模块。并且，Ansible便于扩展，当出现新事务时可以根据需要编写自定义的模块。 Ansible作为自动化系统运维的一大利器，在构建整个体系过程中有着举足轻重的地位。其简单易用、易于安装、功能强大、便于分享、内含大量模板等都是它的魅力所在，再加上易封装、接口调用方便，Ansible正在被越来越多的大公司采用。 2、Ansible与Fabric之间的比较 简单来说，Fabric像是一个工具箱，提供了很多好用的工具，用于在远程服务器执行命令。而Ansible则提供了一套简单的流程，只需要按照它的流程来做就能轻松完成任务。这就像是库和框架的关系一样，其中，Fabric是库，Ansible是框架。 （1）Fabric与Ansible之间的共同点 121.都是基于paramiko开发；2.都使用ssh和远程服务器通讯，不需要在远程服务器上安装客户端。 （2）Fabric与Ansible之间的主要区别 123451. Fabric简单，Ansible复杂。因此，Fabric学习成本低，Ansible的学习成本高；2. Fabric通过ssh执行简单的命令，Ansible将模块拷贝到远程服务器后执行，执行完成以后删除模块；3. 使用Fabric需要具有Python编程背景，使用Ansible则不需要；4. Fabric对常用的管理操作和ssh连接操作进行了封装，工程师通过编写简单的代码就能完成要做的事情。Ansible不需要工程师编写任何代码，直接编写YAML格式的配置文件来描述要做的事情；5. Fabric提供了基本的接口，业务逻辑需要用户自己实现；Ansible提供了大量的模块，用户只需要学习模块的用法即可完成复杂的任务。 二、Ansible使用入门 在这一小节我们介绍Ansible的安装与基本使用，然后在接下来的章节中介绍Ansible的高级用法。 ansible使用原则： 确定要操作哪些服务器（服务器列表） 确定对这些服务器进行什么样的操作（命令） 关于hosts文件： 默认读取/etc/ansible/hosts文件 通过命令行参数-i指定hosts文件 通过/etc/ansible/ansible.cfg里面的inventory选项指定hosts文件 1、安装Ansible Ansible不需要安装客户端，因此，相对于其他配置管理工具，Ansible的安装简单得多，只需要在控制端安装Ansible即可。Ansible使用Python语言开发，我们可以直接使用pip进行安装，也可以使用Linux下的包管理工具(如yumI、apt-get)进行安装。如下所示: 1[root@python ~]# pip3 install ansible 检查Ansible是否安装成功，如下所示： 1234567[root@python ~]# ansible --versionansible 2.9.9 config file = /etc/ansible/ansible.cfg configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Aug 7 2019, 00:51:29) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] Ansible依赖Python与SSH，因此服务器需要安装SSH和Python 2.5或2.5以上版本的Python。SSH和Python是大多数操作系统中默认安装的软件，这进一步降低了Ansible安装部署的难度。除了SSH和Python以外，服务器端不需要再预装任何软件。在控制端（Ansible命令运行的那台机器）需要安装Python 2.6或更高版本的Python程序，且Ansible的控制端只能运行在Linux下。 与其他库和工具不同的是，Ansible包含了多个工具。安装完Ansible以后，控制端会增加以下几个可执行程序： 1234567ansibleansible-docansible-playbookansible-vaultansible-consoleansible-galaxyansible-pull 这些可执行程序将在之后使用时进行详细介绍。 2、Ansible的架构 为了更好的理解Ansible，在介绍Ansible的使用之前，我们先看一下Ansible的架构图，如下所示： 在Ansible中，用户通过编排引擎操作主机。其中，主机可以通过配置文件配置，调用云计算的接口获取，或者访问CMDB中的数据库。Ansible的编排引擎有Inventory、API、Modules（模块）和Plugins组成。Ansible的典型用法是：工程师将需要远程服务器执行的操作写在Ansible Playbook中，然后使用Ansible执行Playbook中的操作。 3、Ansible的运行环境 使用Ansible操作远程服务器时，首先需要确定的是操作哪些服务器，然后再确定对这些服务器执行哪些操作。 Ansible会默认读取/etc/ansible/hosts文件中配置的远程服务器列表。在我们这一小节，/etc/ansible/hosts文件内容如下： 123456[root@python ~]# mkdir /etc/ansible[root@python ~]# vim /etc/ansible/hosts[test]127.0.0.1192.168.1.80 Ansible中存在一个名为ping的模块，该模块并不是测试服务器的网络是否连接，而是尝试建立SSH连接，以便验证用户的SSH是否已经正确配置。如下所示： 1[root@python ~]# ansible test -m ping 修改test的权限 12345678[root@python ~]# chmod 755 /etc/sudoers[root@python ~]# vim /etc/sudoerstest ALL=(ALL) ALL #92行左右添加[root@python ~]# vim /etc/ansible/hosts[test]127.0.0.1 ansible_user=root ansible_port=22192.168.1.80 再次测试一下 1root@python ~]# ansible test -m ping 常见错误解决方案如下： （1）ansible管理节点生成ssh-key 1[root@192 ~][root@192 ~]# ssh-keygen 执行成功后，将会在~/.ssh目录下生成2个文件：id_rsa和id_rsa.pub （2）添加目标节点的ssh认证信息 12[root@192 ~]# ssh-copy-id root@47.100.98.242[root@192 ~][root@192 ~]# ssh-copy-id root@47.100.98.242[root@192 ~]# ssh-copy-id root@192.168.79.133 （3）测试 123456789101112131415[root@192 ~]# ansible test -m ping192.168.79.133 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125;47.100.98.242 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": [root@192 ~]# ansible test -m ping192.168.79.133 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125;47.100.98.242 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125; Ansible默认使用当前用户和默认的22端口号与远程服务器建立SSH连接。如果需要使用其他用户，或者使用非默认的SSH端口号，可以在host之后增加用户名和端口号的配置。如下所示： 1234[root@192 ~]# cat &#x2F;etc&#x2F;ansible&#x2F;hosts[test]192.168.79.133 ansible_user&#x3D;test ansible_port&#x3D;2247.100.98.242 ansible_user&#x3D;laoyu ansible_port&#x3D;80 一般情况下，工作环境的服务器ssh用户名和ssh端口号都是相同的。如果我们有很多的远程服务器，每一台服务器都需要配置ansible_user或ansible_port参数，如果依然使用前面的配置方式进行配置，会显得非常冗余。对于这种情况，可以在Ansible配置文件中修改相应的配置。 Ansible默认使用/etc/ansible/ansible.cfg文件，我们可以在ansible.cfg中设定一些默认值，这样就需要对同样的内容输入多次。如下所示： 1234[root@192 ~]# cat /etc/ansible/ansible.cfg[defaults]remote_port = [root@192 ~]# cat /etc/ansible/ansible.cfg[defaults]remote_port = 2090remote_user = test 4、Ansible的ad-hoc模式 ping模块是Ansible中最简单的模块，而command模块则是工程师最熟悉的模块。command模块的作用非常简单，就是在服务器中执行shell命令。在Ansible中，通过-m参数指定模块名称，通过-a参数指定模块的参数。因此，使用command模块在远程服务器执行shell命令的语句如下： 12345678910[root@python ~]# ansible test -m command -a \"hostname\"127.0.0.1 | CHANGED | rc=0 >>python192.168.1.80 | CHANGED | rc=0 >>python[root@python ~]# ansible test -m command -a \"whoami\"192.168.1.80 | CHANGED | rc=0 >>root127.0.0.1 | CHANGED | rc=0 >>root command是Ansible中的默认模块，当我们省略-m参数时，默认使用command模块。如下所示： 12345[root@python ~]# ansible test -m command -a \"whoami\"192.168.1.80 | CHANGED | rc=0 >>root127.0.0.1 | CHANGED | rc=0 >>root 大部分情况下，Ansible的模块包含多个参数，参数使用“key=value”的形式表示，各个参数之间使用空格分隔。如下所示： （1）创建ansible.cfg文件 1234[root@python ~]# vim /etc/ansible/ansible.cfg[defaults]remote_port = 22remote_user = root 再次测试一下 1[root@python ~]# ansible test -m ping 1[root@python ~]# ansible test -m command -a \"hostname\" （2）将本地文件拷贝到服务器 12345[root@python ~]# cd /tmp/[root@python tmp]# mkdir abc[root@python tmp]# cd abc/[root@python abc]# lsnginx.conf restart.sh #要拷贝的文件 进行拷贝 1[root@python abc]# ansible test -m copy -a \"src=/tmp/abc/nginx.conf dest=/opt/nginx.conf\" 查看一下是否有拷贝的文件 12[root@python abc]# ls /opt/ | grep nginx.confnginx.conf &lt;1&gt;创建剧本（拷贝） 1234567891011121314[root@python abc]# vim test_playbook.yml---- hosts: test become: yes #是否支持root权限 become_method: sudo tasks: #任务 - name: copy file #描叙 copy: src=/opt/nginx.conf dest=/tmp/abc/nginx.conf #拷贝的 - name: package install #描叙 yum: name=&#123;&#123;item&#125;&#125; state=present #安装的 with_items: - tmux 执行一下 1[root@python abc]# ansible-playbook test_playbook.yml 查看是否有拷贝的文件 12[root@python abc]# ls | grep nginx.conf nginx.conf （3）在远程服务器中安装软件 1[root@python abc]# ansible test -m yum -a \"name=tmux state=present\" -become 5、使用playbook控制服务器 前面通过Ansible命令执行操作的方式，称为ad-hoc。我们可以使用ad-hoc来执行非常简单的操作，也可以使用ad-hoc的方式来学习模块的使用方式。但是，在实际的生产环境中，我们一般将远程服务器需要做的事情写在一个YAML配置文件中。 例如，将本地文件拷贝到远程服务器并修改文件所有者，然后安装软件的功能，写在YAML的配置文件中以后，其内容如下： 1234567891011121314151617[root@192 ~]# cat test_playbook.yml---- hosts: test become: yes become_method: sudo tasks:true- name: copy file copy: src=~/s.txt dest=/opt/s.txttruetrue- name: change mode file: dest=/opt/s.txt mode=500 owner=root group=roottruetrue- name: ensure packages installed yum: name=&#123;&#123;item&#125;&#125; state=presenttrue with_items:true - gittrue - [root@192 ~]# cat test_playbook.yml---- hosts: test become: yes become_method: sudo tasks:true- name: copy file copy: src=~/s.txt dest=/opt/s.txttruetrue- name: change mode file: dest=/opt/s.txt mode=500 owner=root group=roottruetrue- name: ensure packages installed yum: name=&#123;&#123;item&#125;&#125; state=presenttrue with_items:true - gittrue - tmux 这个YAML文件称为Ansible Playbook。Playbook中首先包含了一些声明信息，如hosts关键字声明该Playbook应用的服务器列表，become和become_method表示在远程服务器通过sudo执行操作。Playbook最后包含了若干个task，每一个task对应于前面的一条ad-hoc命令。具体执行时，多个task按序执行。如果你不能完全理解YAML文件，现在只需要对Ansible的执行方式有一个认识即可。后续小节将会详细讲解如何编写Ansible Playbook。 有了Playbook以后，通过ansible-playbook命令执行，如下所示： 1234567891011121314151617181920212223242526272829303132[root@192 ~]# ansible-playbook test_palybook.ymlPLAY [test] ****************************************************************************************************************TASK [Gathering Facts] *****************************************************************************************************ok: [47.100.98.242]ok: [127.0.0.1]TASK [copy file] ***********************************************************************************************************ok: [127.0.0.1]ok: [47.100.98.242]TASK [change mode] *********************************************************************************************************ok: [127.0.0.1]ok: [47.100.98.242]TASK [ensure packages installed] *******************************************************************************************[DEPRECATION WARNING]: Invoking \"yum\" only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying `name: \"&#123;&#123;item&#125;&#125;\"`, please use `name: ['git', 'tmux']` and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.[DEPRECATION WARNING]: Invoking \"yum\" only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying `name: \"&#123;&#123;item&#125;&#125;\"`, please use `name: ['git', 'tmux']` and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.changed: [47.100.98.242] =&gt; (item=['git', 'tmux'])changed: [127.0.0.1] =&gt; (item=['git', 'tmux'])PLAY RECAP *****************************************************************************************************************127.0.0.1 : ok=4 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 47.100.98.242 : ok=4 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 [root@desktop-kh5f5dc ~][root@192 ~]# ansible-playbook test_palybook.ymlPLAY [test] ****************************************************************************************************************TASK [Gathering Facts] *****************************************************************************************************ok: [47.100.98.242]ok: [127.0.0.1]TASK [copy file] ***********************************************************************************************************ok: [127.0.0.1]ok: [47.100.98.242]TASK [change mode] *********************************************************************************************************ok: [127.0.0.1]ok: [47.100.98.242]TASK [ensure packages installed] *******************************************************************************************[DEPRECATION WARNING]: Invoking \"yum\" only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying `name: \"&#123;&#123;item&#125;&#125;\"`, please use `name: ['git', 'tmux']` and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.[DEPRECATION WARNING]: Invoking \"yum\" only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying `name: \"&#123;&#123;item&#125;&#125;\"`, please use `name: ['git', 'tmux']` and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.changed: [47.100.98.242] =&gt; (item=['git', 'tmux'])changed: [127.0.0.1] =&gt; (item=['git', 'tmux'])PLAY RECAP *****************************************************************************************************************127.0.0.1 : ok=4 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 47.100.98.242 : ok=4 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 [root@desktop-kh5f5dc ~]# 上面这条命令的效果与上一小节中多条ad-hoc命令的效果是一样的。关于YAML的语法，如何编写playbook以及模块的使用方式等，将在本章的后续小节中进行详细讲解。在这一小节中，我们只需要知道Ansible有两种操作远程服务器的方式，分别是：ad-hoc与Playbook。 三、Inventory管理 在Ansible中，将可管理的服务器的集合称为Inventory。因此，Inventory管理便是服务器管理。这一节中，我们将会详细讨论Inventory管理。 1、hosts文件位置 我们已经演示了Ansible如何对远程服务器执行操作，可以看到，Ansible在执行操作是，首先需要确定对哪些服务器执行操作。默认情况下，Ansible读取/etc/ansible/hosts文件中的服务器配置，获取需要操作的服务器列表。Ansible定义与获取服务器列表的方式比这个要灵活得多。 在Ansible中，有3种方式制定hosts文件，分别是： 默认读取/etc/ansible/hosts文件； 通过命令行参数-i指定hosts文件； 通过ansible.cfg文件中的inventory选项（老版本的Ansible中通过hostfile选项指定）指定hosts文件。 例如：当前系统中除了/etc/ansible/hosts文件以外，在test用户的home目录下也存在一个名为hosts的文件，该hosts文件的内容如下所示： 123[test]127.0.0.1192.168.1.80 使用/etc/ansible/hosts文件 1234[root@python ~]# ansible test --list-hosts hosts (2): 127.0.0.1 192.168.1.80 -i选项指定hosts文件 1234[root@python ~]# ansible test -i hosts --list-hosts hosts (2): 127.0.0.1 192.168.1.80 修改ansible.cfg文件，添加inventory选项，指定hosts文件的路径 123456[root@python ~]# vim /etc/ansible/ansible.cfg [defaults]remote_user = rootremote_port = 22inventory = /etc/ansible/hosts 2、灵活定义hosts文件内容 （1）分组定义服务器 12345678[root@python ~]# vim /etc/ansible/hosts [demo]127.0.0.1[xgp]192.168.1.80[wsd]192.168.1.60 1）查看单个分组的服务器列表 1234567891011121314[root@python ~]# ansible demo --list-hosts hosts (1): 127.0.0.1[root@python ~]# ansible xgp --list-hosts hosts (1): 192.168.1.80[root@python ~]# ansible wsd --list-hosts hosts (1): 192.168.1.60[root@python ~]# ansible all --list-hosts hosts (3): 127.0.0.1 192.168.1.80 192.168.1.60 2）查看多个分组的服务器列表（冒号分隔组名） 1234[root@python ~]# ansible xgp:wsd -i hosts --list-hosts hosts (2): 192.168.1.80 192.168.1.60 3）使用all和星号匹配服务器 123456[root@python ~]# ansible '*' -i hosts --list-hosts[root@python ~]# ansible 'all' -i hosts --list-hosts hosts (3): 127.0.0.1 192.168.1.60 192.168.1.80 （2）Ansible定义组匹配服务器 12345678910[root@python ~]# vim hosts[demo]127.0.0.1[xgp]192.168.1.80[wsd]192.168.1.60[common:children]xgpwsd 查看服务器列表 1234[root@python ~]# ansible common -i hosts --list-hosts hosts (2): 192.168.1.80 192.168.1.60 （3）批量定义服务器 12345678910111213[root@python ~]# vim hosts[demo]127.0.0.1[xgp]192.168.1.80[1:3].xgp.top[wsd]192.168.1.60[a:d].xgp.top[common:children]xgpwsd 查看服务列表 1234567891011[root@python ~]# ansible xgp:wsd -i hosts --list-hosts hosts (9): 192.168.1.80 1.xgp.top 2.xgp.top 3.xgp.top 192.168.1.60 a.xgp.top b.xgp.top c.xgp.top d.xgp.top 3、灵活匹配hosts文件内容 Ansible还支持通配符和正则表达式等更灵活的方式来匹配服务器。 Ansible官方给出了ansible命令的语法格式： 1ansible -m -a 例如：重启所有web服务器中的Apache进程： 12ansible webservers -m service -a \"name=httpd state=restarted\"ansible web*.duxuejun.com =-m service -a ansible webservers -m service -a \"name=httpd state=restarted\"ansible web*.duxuejun.com =-m service -a \"name=httpd state=restarted\" 远程服务器匹配规则： 匹配规则 含义 192.168.1.10 或者 web.duxuejun.com 匹配目标IP地址或服务器名称，如果含有多个IP或服务器，使用“:”分隔 webservers 匹配目标为webservers，多个分组使用“:”分隔 all或者&quot;*&quot; 匹配所有的服务器 webservers:!dbservers 匹配在webservers中，不在dbservers组中的服务器 webservers:&amp;dbservers 匹配同时在webservers组以及dbservers组中的服务器 *.duxujun.com或192.168.* 使用通配符进行匹配 webservers[0],webservers[1:],webservers[-1] 使用索引或切片操作的方式匹配组中的服务器 ~(web|db).*.duxuejun.com 以~开头的匹配，表示使用正则表达式匹配 4、Inventory行为参数 12345678910参数 默认值 说明ansible_ssh_host 主机的名字 ssh的目的主机或ipansible_ssh_port 22 ssh目的端口ansible_ssh_user root ssh登陆使用的用户名ansible_ssh_pass none ssh认证所使用的密码ansible_connection smart Ansible使用何种连接模式连接到主机ansible_ssh_private_key_file none ssh认证所使用的私钥ansible_shell_type sh 命令所使用的shellansible_python_interpreter /usr/bin/python 主机上的python解释器ansible_*_interpreter 参数 默认值 说明ansible_ssh_host 主机的名字 ssh的目的主机或ipansible_ssh_port 22 ssh目的端口ansible_ssh_user root ssh登陆使用的用户名ansible_ssh_pass none ssh认证所使用的密码ansible_connection smart Ansible使用何种连接模式连接到主机ansible_ssh_private_key_file none ssh认证所使用的私钥ansible_shell_type sh 命令所使用的shellansible_python_interpreter /usr/bin/python 主机上的python解释器ansible_*_interpreter none 类似python解释器的其他语言版 5、改变行为参数的默认值 123456可以在ansible.cfg文件的[defaults]部分更改一些行为参数的默认值 ansible.cfg文件 inventory文件 ansible_ssh_user remote_useransible_ssh_port remote_portansible_ssh_private_key_file private_key_fileansible_shell_type 可以在ansible.cfg文件的[defaults]部分更改一些行为参数的默认值 ansible.cfg文件 inventory文件 ansible_ssh_user remote_useransible_ssh_port remote_portansible_ssh_private_key_file private_key_fileansible_shell_type executable 6、定义服务器变量 在hosts文件中，除了定义行为参数以外，还可以定义普通的变量，以便在不同的服务器中使用不同的配置。比如：可以在2台服务器中分别启动MySQL，1台服务器的MySQL的端口是3306，另一台服务器MySQL的端口是3307。定义普通参数和定义行为参数的方法是一样的，只是行为参数的名字有Ansible预先定义，普通参数的名称有我们自己定义。在Ansible中，参数名必须为字母、数字和下划线的组合，并且首字符必须为字母。 （1）变量的取值不同 假定，我们在/etc/ansible/hosts文件中为不同的服务器定义一个相同的变量名，但是取值不同。如下所示： 12345[root@python ~]# vim hosts[test]192.168.1.60 ansible_port=22192.168.1.80 ansible_port=22 在测试环境中，我们可以通过echo方式显示变量的值。如下所示： 12345[root@python ~]# ansible test -i ./hosts -a 'echo &#123;&#123;ansible_port&#125;&#125;' 192.168.1.60 | CHANGED | rc=0 >>22192.168.1.80 | CHANGED | rc=0 >>22 （2）变量的取值相同 如果test组下的两个服务器mysql_port变量取值相同，我们也可以通过组的名称加上“:vars”后缀来定义变量，如下所示： 12345678[root@python ~]# vim hosts[test]192.168.1.40192.168.1.80[test:vars]ansible_port = 22 随着业务的发展，管理的hosts文件越来越大，使用的变量越来越多了，依然使用一个hosts文件管理服务器和变量的话，就会逐渐变得难以管理。 Ansible提供了更好的方法来管理服务器和群组的变量，即：为每个服务器和群组创建独立的变量文件。其定义方式是，将组的变量存放在一个名为group_vars命令下，目录下的文件名与组的名称相同，文件的扩展名可以是.yml或.yaml，也可以没有任何扩展名。服务器的变量存放在一个名为host_vars目录下，该目录下的文件名为服务器的名称。 Ansible将依次在Playbook所在的目录、hosts文件所在的目录和/etc/ansible目录下寻找group_vars目录和host_vars目录。目前，假设group_vars目录和host_var目录都位于/etc/ansible目录下。 对于我们前面定义mysql_port变量的例子，将变量存放在独立的文件以后，/etc/ansible目录的结构如下： 12345678[root@192 ansible]# tree.├── ansible.cfg├── group_vars│ └── test.yaml├── hosts└── host_vars └── 127.0.0.1.yaml 其中，test.yaml文件定义了hosts文件中test组的变量，127.0.0.1.yaml文件定义了hosts文件中127.0.0.1这台服务器使用的变量。如：test.yaml文件的内容如下： 12[root@192 ansible]# cat group_vars/test.yaml ansible_port: [root@192 ansible]# cat group_vars/test.yaml ansible_port: 22 注意：我们在hosts文件中定义变量时，使用的是“var = value”格式定义。将变量保存在一个独立的文件时，使用的是“var:value”格式定义。这是因为Ansible解析这两个文件时，认为hosts是一个ini格式的文件，而保存变量的文件是一个YAML格式的文件。 12345[root@python ~]# ansible test -i ./hosts -a 'echo &#123;&#123;ansible_port&#125;&#125;' 192.168.1.40 | CHANGED | rc=0 >>22192.168.1.80 | CHANGED | rc=0 >>22 四、YAML语法 1、YAML语法规则 123451. YAML文件第一行为“---”，表示这是一个YAML文件；2. YAML中字段大小写敏感；3. YAML与Python一样，通过缩进来表示层级关系；4. YAML的缩进不允许使用Tab键，只允许使用空格，且空格的数目不重要，只要相同层级的元素左侧对齐即可；5. “#”表示注释，从这个字符一直到行尾都会被解析器忽略 2、YAML支持的3中格式数据 1231. 对象：键值对的集合，有称为映射，类似于Python中的字典；2. 数组：一组按次序排列的值，有称为序列（sequence），类似于Python的列表；3. 纯量（scalars）：单个的、不可再分的值，比如：字符串、布尔值与数字。 3、安装PyYAML库 Python标准库没有包含解析YAML格式的库，需要安装第三方的PyYAML库。 1pip3 install -i https://pypi.douban.com/simple/ PyYAML 4、定义与解析YAML文件 （1）数组格式 使用YAML表示数组非常容易，只需要用“-”将元素按序列出即可。假设我们有下面这样一个YAML文件，文件的内容保存在一个名为data.yaml的文件中，如下所示： 123456---# 一个美味的水果列表- Apple- Orange- Strawberry- ---# 一个美味的水果列表- Apple- Orange- Strawberry- Mango 解析结果： 123456In [1]: import yaml In [2]: with open('data.yaml') as f: ...: print(yaml.load(f)) ...: ['Apple', 'Orange', 'Strawberry', In [1]: import yaml In [2]: with open('data.yaml') as f: ...: print(yaml.load(f)) ...: ['Apple', 'Orange', 'Strawberry', 'Mango'] （2）对象 在YAML中，对象以“key:value”的形式进行定义，如下所示： 123456789---# 一个职工的记录name: 爱运维job: devopsskill: Eliteage: 23knowoop: Truelikes_emacs: TRUEusers_cvs: ---# 一个职工的记录name: 爱运维job: devopsskill: Eliteage: 23knowoop: Truelikes_emacs: TRUEusers_cvs: false 解析结果： 1234In [3]: with open('dev.yaml') as f: ...: print(yaml.load(f)) ...:&#123;'name': '爱运维', 'job': 'devops', 'skill': 'Elite', 'age': 23, 'knowoop': True, 'likes_emacs': True, 'users_cvs': In [3]: with open('dev.yaml') as f: ...: print(yaml.load(f)) ...:&#123;'name': '爱运维', 'job': 'devops', 'skill': 'Elite', 'age': 23, 'knowoop': True, 'likes_emacs': True, 'users_cvs': False&#125; YAML中可以使用多种方式制定布尔值，如以上YAML文件中的“True”、“TRUE”、“false”，转换为Python代码后，对变量的取值进行了格式化。 （3）对象和数组嵌套 YAML中的对象和数组是可以任意嵌套的，如下所示： 123456789101112131415161718---# 一个职工的记录name: 爱运维job: devopsskill: Eliteage: 23knowoop: Truelikes_emacs: TRUEusers_cvs: falsefoods: - Apple - Orange - Strawberry - Mangolanguages: ruby: Elite python: Elite shell: ---# 一个职工的记录name: 爱运维job: devopsskill: Eliteage: 23knowoop: Truelikes_emacs: TRUEusers_cvs: falsefoods: - Apple - Orange - Strawberry - Mangolanguages: ruby: Elite python: Elite shell: Lame （4）注意事项 在YAML中定义字符串的时候，不需要使用单引号或者双引号，直接将字符串写在文件中即可。如下所示： 1str: this is a str: this is a string 如果字符串中包含了特殊字符，需要使用双引号包含起来。比如：字符串中包含冒号。冒号是YAML中的特殊字符，因此需要使用双引号包含起来。 1foo: foo: \"somebody said I should put a colon here: so I did\" 如果字符串内容比较长，可以使用“&gt;”来折叠换行。 123that: &gt; Foo that: &gt; Foo Bar 将以上YAML文件转换为Python的内部对象后，“Foo”和“Bar”都是字符串的一部分。 1&#123;'that': &#123;'that': 'Foo Bar\\n'&#125; 五、Ansible模块 1、Ansible的模块工作原理 1231. 将模块拷贝到远程服务器2. 执行模块定义的操作，完成对服务器的修改3. 在远程服务器删除模块 Ansible中的模块是幂等的，也就是说，多次执行相同的操作，只有第一次会起作用。这也是在编写自定义的Ansible模块的时候需要注意的。 2、模块列表与帮助信息 Ansible模块非常多，如果以模块的功能进行分类的话，可以分为以下模块： 12345678910111213141516云模块命令模块数据库模块文件模块资产模块消息模块监控模块网络模块通知模块包管理模块源码控制模块系统模块单元模块web设施模块Windows模块…… 查看Ansible模块帮助信息，如下所示： 1[root@python ~][root@python ~]# ansible-doc -l 查看指定模块的帮助信息，如下所示： 123456789[root@python ~]# ansible file[WARNING]: Could not match supplied host pattern, ignoring: file[WARNING]: No hosts matched, nothing to dousage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD] [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts] [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k] [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER] [-c CONNECTION] [-T TIMEOUT] [--ssh-common-args SSH_COMMON_ARGS] [--sftp-extra-args SFTP_EXTRA_ARGS] [--scp-extra-args SCP_EXTRA_ARGS] [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D] [-e EXTRA_VARS] [--vault-id VAULT_IDS] [--ask-vault-[root@python ~]# ansible file[WARNING]: Could not match supplied host pattern, ignoring: file[WARNING]: No hosts matched, nothing to dousage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD] [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts] [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k] [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER] [-c CONNECTION] [-T TIMEOUT] [--ssh-common-args SSH_COMMON_ARGS] [--sftp-extra-args SFTP_EXTRA_ARGS] [--scp-extra-args SCP_EXTRA_ARGS] [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D] [-e EXTRA_VARS] [--vault-id VAULT_IDS] [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES] [-f 3、常用的Ansible模块 Ansible提供的功能越丰富，所需要的模块也就越多。默认情况下，模块存储在/usr/share/ansible目录中。 （1）ping 12345678910111213141516[root@python ~]# ansible test -m ping192.168.1.40 | SUCCESS => &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125;Enter passphrase for key '/root/.ssh/id_rsa': 192.168.1.80 | SUCCESS => &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125; （2）远程命令模块 1）command模块 123ansible test -m command -a 'hostname'ansible test -m command -a '/sbin/shutdown -t now'ansible test -a ansible test -m command -a 'hostname'ansible test -m command -a '/sbin/shutdown -t now'ansible test -a 'hostname' command模块在执行Linux命令时，不能使用管道。如下所示： 1ansible test -m command -a ansible test -m command -a 'cat /etc/passwd | wc -l' 执行后报错如下： 123456192.168.1.40 | FAILED | rc=1 &gt;&gt;cat：无效选项 -- lTry 'cat --help' for more information.non-zero return code192.168.1.80 | FAILED | rc=1 &gt;&gt;cat：无效选项 -- lTry 'cat --help' for more information.non-zero 192.168.1.40 | FAILED | rc=1 &gt;&gt;cat：无效选项 -- lTry 'cat --help' for more information.non-zero return code192.168.1.80 | FAILED | rc=1 &gt;&gt;cat：无效选项 -- lTry 'cat --help' for more information.non-zero return code 2）raw模块 如果执行的命令需要使用管道，可以使用raw模块，如下所示： 12345678[root@python ~]# ansible test -m raw -a 'cat /etc/passwd | wc -l'192.168.1.80 | CHANGED | rc=0 &gt;&gt;45Shared connection to 192.168.1.80 closed.192.168.1.40 | CHANGED | rc=0 &gt;&gt;44Shared connection to 192.168.1[root@python ~]# ansible test -m raw -a 'cat /etc/passwd | wc -l'192.168.1.80 | CHANGED | rc=0 &gt;&gt;45Shared connection to 192.168.1.80 closed.192.168.1.40 | CHANGED | rc=0 &gt;&gt;44Shared connection to 192.168.1.40 closed. raw模块相当于使用ssh直接执行Linux命令，不会进入到Ansible的模块的子系统中。 3）shell模块 除了使用raw模块以外，也可以使用shell模块，如下所示： 12345[root@python ~]# ansible test -m shell -a 'cat /etc/passwd | wc -l'192.168.1.40 | CHANGED | rc=0 &gt;&gt;44192.168.1.80 | CHANGED | rc=0 &gt;&gt;[root@python ~]# ansible test -m shell -a 'cat /etc/passwd | wc -l'192.168.1.40 | CHANGED | rc=0 &gt;&gt;44192.168.1.80 | CHANGED | rc=0 &gt;&gt;45 shell模块还可以执行远程服务器上的shell脚本，其中，脚本文件的路径需要使用绝对路径，如下所示： 1ansible test -m shell -a '/home/test/test.sh' 统计某个文件有多少行 1234567891011121314[root@python ~]# ansible common -m raw -a 'cat /etc/passwd | wc -l'192.168.1.40 | CHANGED | rc=0 >>43Shared connection to 192.168.1.40 closed.192.168.1.80 | CHANGED | rc=0 >>45Shared connection to 192.168.1.80 closed.[root@python ~]# ansible common -m shell -a 'cat /etc/passwd | wc -l'192.168.1.40 | CHANGED | rc=0 >>43192.168.1.80 | CHANGED | rc=0 >>45 引用文件的方式 1234567891011121314151617181920212223242526272829[root@python ~]# vim test.sh #[root@python ~]# vim test.sh #!/usr/bin/bashcat /etc/passwd | wc -l[root@python ~]# ansible common -m script -a 'test.sh'192.168.1.40 | CHANGED => &#123; \"changed\": true, \"rc\": 0, \"stderr\": \"Shared connection to 192.168.1.40 closed.\\r\\n\", \"stderr_lines\": [ \"Shared connection to 192.168.1.40 closed.\" ], \"stdout\": \"43\\r\\n\", \"stdout_lines\": [ \"43\" ]&#125;192.168.1.80 | CHANGED => &#123; \"changed\": true, \"rc\": 0, \"stderr\": \"Shared connection to 192.168.1.80 closed.\\r\\n\", \"stderr_lines\": [ \"Shared connection to 192.168.1.80 closed.\" ], \"stdout\": \"45\\r\\n\", \"stdout_lines\": [ \"45\" ]&#125; （3）file file模块主要用于对远程服务器上的文件（包括链接和目录）进行操作，包括修改文件的权限、修改文件的所有者、创建文件、删除文件等。 file模块使用示例： 1234567891011# 创建一个目录ansible test -m file -a 'path=/tmp/dd state=directory mode=0o755'# 修改文件的权限ansible test -m file -a \"path=/tmp/dd state=touch mode='u=rw,g=r,o=r'\"# 创建一个软链接ansible test -m file -a 'src=/tmp/dd dest=/tmp/dd1 state=link owner=root group=root'# 修改一个文件的所有者ansible test -m file -a # 创建一个目录ansible test -m file -a 'path=/tmp/dd state=directory mode=0o755'# 修改文件的权限ansible test -m file -a \"path=/tmp/dd state=touch mode='u=rw,g=r,o=r'\"# 创建一个软链接ansible test -m file -a 'src=/tmp/dd dest=/tmp/dd1 state=link owner=root group=root'# 修改一个文件的所有者ansible test -m file -a \"path=/tmp/dd owner=root group=root mode=0o644\" -become file模块中重要选项： 1234567891. path: 指定文件/目录的路径2. recurse: 递归设置文件属性，只对目录有效3. group: 定义文件/目录的组4. mode: 定义文件/目录的权限5. owner: 定义文件/目录的所有者6. src: 要被链接的源文件路径，只应用于state为link的情况7. dest: 被链接到的路径，只应用于state为link的情况8. force: 在两种情况下会强制创建软链接，一种情况是源文件不存在，但之后会建立的情况；另一种情况是目标软链接已经存在，需要先取消了之前的软链接，然后再创建新的软链接，默认取值为no9. state: 该选项有多个取值，包括directory、file、link、hard、touch、absent。各个取值的含义如下：取值为directory，如果目录不存在，创建目录；取值为file时，即使文件不存在也不会被创建；取值为link时，创建软链接；取值为hard时，创建硬链接；取值为touch时，如果文件不存就创建一个新文件，如果文件或目录已经存在，更新其最后访问时间和修改时间；取值为absent时，删除目录、文件或者链接 &lt;1&gt;创建文件 1[root@python ~]# ansible common -m file -a 'path=/opt/test.md state=touch' 查看一下 &lt;2&gt;创建目录 1[root@python ~]# ansible common -m file -a 'path=/opt/test mode=0755 state=directory' 查看一下 &lt;3&gt;创建并删除文件 12[root@python ~]# ansible common -m file -a 'path=/opt/abc mode=0640 state=touch'//创建 查看一下 1[root@python ~]# ansible common -m file -a 'path=/opt/abc mode=0640 state=absent' &lt;4&gt;创建并改变文件所有者 123[root@python ~]# ansible common -m file -a 'path=/opt/abc mode=0640 state=touch'[root@python ~]# ansible common -m file -a 'path=/opt/abc mode=0640 owner=test group=root' -become （4）copy copy模块用来将主控节点的文件或者目录拷贝到远程服务器上，类似于Linux下的scp命令。但是，copy模块比scp命令更强大，在拷贝文件到远程服务器上的同时，也可以设置文件在远程服务器上的权限和所有者。 copy模块的使用示例： 12345678# 拷贝文件到远程服务器ansible test -m copy -a 'src=test.sh dest=/tmp/test.sh'# 拷贝文件到远程服务器，如果远程服务器已经存在这个文件，则备份文件ansible test -m copy -a 'src=test.sh dest=/tmp/test.sh backup=yes force=yes'# 拷贝文件到远程服务器，并且修改文件的所有者和权限ansible test -m copy -a # 拷贝文件到远程服务器ansible test -m copy -a 'src=test.sh dest=/tmp/test.sh'# 拷贝文件到远程服务器，如果远程服务器已经存在这个文件，则备份文件ansible test -m copy -a 'src=test.sh dest=/tmp/test.sh backup=yes force=yes'# 拷贝文件到远程服务器，并且修改文件的所有者和权限ansible test -m copy -a 'src=tes.sh dest=/tmp/tes.sh owner=root group=root mode=644 force=yes' -become copy模块中重要选项： 1234561. src：要复制到远程服务器的文件地址，可以是绝对路径，也可以是相对路径。如果路径时一个目录，将递归复制。在这种情况下，如果使用“/”结尾，则复制目录里的内容；如果没有用“/”来结尾，则将包含目录在内的整个内容复制，类似于rsync2. dest：文件要复制到的目的地，必须是一个绝对路径，如果源文件是一个目录，那么dest指向的也必须是一个目录3. force：默认取值为yes，表示目标主机包含该文件，但是内容不同时，会强制覆盖；如果该选项设置为no，只有当目标主机的目标位置不存在该文件时，才会进行复制4. backup：默认取值为no，如果取值为yes，那么在覆盖之前将原文件进行备份5. directory_mode：递归设定目录权限，默认为系统默认权限6. others：所有file模块里的选项都可以在这里使用 （5）user/group user模块请求的是useradd、userdel、usermod这三个指令，group模块请求的是groupadd、groupdel、groupmod这三个指令。 user/group模块的使用示例： 1234567891011121314# 创建一个用户ansible test -m user -a 'name=John comment=\"John Doe\" uid=1239 group=root' -become# 删除一个用户ansible test -m user -a 'name=John state=absent' -become# 创建一个用户，并且产生一对密钥ansible test -m user -a 'name=John comment=\"John Doe\" generate_ssh_key=yes ssh_key_bits=2048' -become# 创建群组ansible test -m group -a 'name=ansible state=present gid=1234' -become# 删除群组ansible test -m group -a # 创建一个用户ansible test -m user -a 'name=John comment=\"John Doe\" uid=1239 group=root' -become# 删除一个用户ansible test -m user -a 'name=John state=absent' -become# 创建一个用户，并且产生一对密钥ansible test -m user -a 'name=John comment=\"John Doe\" generate_ssh_key=yes ssh_key_bits=2048' -become# 创建群组ansible test -m group -a 'name=ansible state=present gid=1234' -become# 删除群组ansible test -m group -a 'name=ansible state=absent' -become user/group模块重要选项： 12345678910111. name：需要操作的用户名或群组名2. comment：用户的描述信息3. createhome：创建用户时，是否创建家目录，默认为yes4. home：指定用户的家目录，需要与createhome选项配合使用5. group：指定用户的属组6. uid：设置用户的id7. gid：设置群组的id8. password：设置用户的密码9. state：是创建用户或群组，还是删除用户后群组，取值包括present和absent10. expires：用户的过期时间11. shell：指定用户的shell环境 （6）yum yum模块可以帮助我们在远程主机上通过yum源管理软件包。 yum模块使用示例： 123456789# 安装软件包ansible test -m yum -a 'name=nginx disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=present disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=installed disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=latest disable_gpg_check=yes'# 卸载软件包ansible test70 -m yum -a 'name=nginx state=absent'ansible test70 -m yum -a # 安装软件包ansible test -m yum -a 'name=nginx disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=present disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=installed disable_gpg_check=yes'ansible test -m yum -a 'name=nginx state=latest disable_gpg_check=yes'# 卸载软件包ansible test70 -m yum -a 'name=nginx state=absent'ansible test70 -m yum -a 'name=nginx state=removed' yum模块重要选项： 1234561. name：必须参数，用于指定需要管理的软件包，比如nginx2. state：用于指定软件包的状态 ，默认值为present，表示确保软件包已经安装，除了present，其他可用值有installed、latest、absent、removed，其中installed与present等效，latest表示安装yum中最新的版本，absent和removed等效，表示删除对应的软件包3. disable_gpg_check：用于禁用对rpm包的公钥gpg验证，默认值为no，表示不禁用验证，设置为yes表示禁用验证，即不验证包，直接安装，在对应的yum源没有开启gpg验证的情况下，需要将此参数的值设置为yes，否则会报错而无法进行安装4. enablerepo：用于指定安装软件包时临时启用的yum源，假如你想要从A源中安装软件，但是你不确定A源是否启用了，你可以在安装软件包时将此参数的值设置为yes，即使A源的设置是未启用，也可以在安装软件包时临时启用A源5. disablerepo：用于指定安装软件包时临时禁用的yum源，某些场景下需要此参数，比如，当多个yum源中同时存在要安装的软件包时，你可以使用此参数临时禁用某个源，这样设置后，在安装软件包时则不会从对应的源中选择安装包6. enablerepo参数和disablerepo参数可以同时使用 （7）get_url 从互联网上下载数据到本地，作用类似于Linux下的curl命令。get_url模块比curl命令更加灵活，可以控制下载以后的数据所有者、权限以及检查下载数据的checksum等。 get_url模块使用示例： 为了进行get_url测试，使用命令“python -m http.server”启动一个下载服务器，将下载服务器中的文件地址传给url选项。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 下载文件到远程服务器ansible test -m get_url -a 'url=http://localhost:8000/data.tar.gz dest=/tmp/data.tar.gz'# 下载文件到远程服务器，并且修改文件的权限ansible test -m get_url -a 'url=http://localhost:8000/data.tar.gz dest=/tmp/data.tar.gz mode=0777'# 下载文件到远程服务器，并且检查文件的MD5校验是否与控制端的MD5校验相同[root@bogon ~]# md5sum s.txtd41d8cd98f00b204e9800998ecf8427e s.txt[root@bogon ~]# ansible 127.0.0.1 -m get_url -a 'url=http://localhost:8000/s.txt dest=/tmp/s.txt checksum=md5:d41d8cd98f00b204e9800998ecf8427e'127.0.0.1 | CHANGED =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": true, \"checksum_dest\": null, \"checksum_src\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"dest\": \"/tmp/s.txt\", \"elapsed\": 0, \"gid\": 0, \"group\": \"root\", \"md5sum\": \"d41d8cd98f00b204e9800998ecf8427e\", \"mode\": \"0644\", \"msg\": \"OK (0 bytes)\", \"owner\": \"root\", \"secontext\": \"unconfined_u:object_r:admin_home_t:s0\", \"size\": 0, \"src\": \"/root/.ansible/tmp/ansible-tmp-1584171703.8607588-137457225931919/tmpG3otIP\", \"state\": \"file\", \"status_code\": 200, \"uid\": 0, \"url\": \"http://localhost:8000/s.txt\"&#125;[root@bogon ~]# ansible 127.0.0.1 -m get_url -a 'url=http://localhost:8000/s.txt dest=/tmp/s.txt checksum=md5:d41d8cd98f00b204e9800998ecf84270'127.0.0.1 | FAILED! =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"checksum_dest\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"checksum_src\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"dest\": \"/tmp/s.txt\", \"elapsed\": 0, \"msg\": \"The checksum for /tmp/s.txt did not match d41d8cd98f00b204e9800998ecf84277e; it was d41d8cd98f00b204e9800998ecf8427e.\", \"src\": \"/root/.ansible/tmp/ansible-tmp-1584171717.7448506-78799482489470/tmpyczfH3\", \"url\": # 下载文件到远程服务器ansible test -m get_url -a 'url=http://localhost:8000/data.tar.gz dest=/tmp/data.tar.gz'# 下载文件到远程服务器，并且修改文件的权限ansible test -m get_url -a 'url=http://localhost:8000/data.tar.gz dest=/tmp/data.tar.gz mode=0777'# 下载文件到远程服务器，并且检查文件的MD5校验是否与控制端的MD5校验相同[root@bogon ~]# md5sum s.txtd41d8cd98f00b204e9800998ecf8427e s.txt[root@bogon ~]# ansible 127.0.0.1 -m get_url -a 'url=http://localhost:8000/s.txt dest=/tmp/s.txt checksum=md5:d41d8cd98f00b204e9800998ecf8427e'127.0.0.1 | CHANGED =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": true, \"checksum_dest\": null, \"checksum_src\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"dest\": \"/tmp/s.txt\", \"elapsed\": 0, \"gid\": 0, \"group\": \"root\", \"md5sum\": \"d41d8cd98f00b204e9800998ecf8427e\", \"mode\": \"0644\", \"msg\": \"OK (0 bytes)\", \"owner\": \"root\", \"secontext\": \"unconfined_u:object_r:admin_home_t:s0\", \"size\": 0, \"src\": \"/root/.ansible/tmp/ansible-tmp-1584171703.8607588-137457225931919/tmpG3otIP\", \"state\": \"file\", \"status_code\": 200, \"uid\": 0, \"url\": \"http://localhost:8000/s.txt\"&#125;[root@bogon ~]# ansible 127.0.0.1 -m get_url -a 'url=http://localhost:8000/s.txt dest=/tmp/s.txt checksum=md5:d41d8cd98f00b204e9800998ecf84270'127.0.0.1 | FAILED! =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"checksum_dest\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"checksum_src\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\", \"dest\": \"/tmp/s.txt\", \"elapsed\": 0, \"msg\": \"The checksum for /tmp/s.txt did not match d41d8cd98f00b204e9800998ecf84277e; it was d41d8cd98f00b204e9800998ecf8427e.\", \"src\": \"/root/.ansible/tmp/ansible-tmp-1584171717.7448506-78799482489470/tmpyczfH3\", \"url\": \"http://localhost:8000/s.txt\"&#125; get_url模块重要选项： 1234567891011121. dest：必传选项，指定将文件下载的绝对路径2. url：必传选项，文件的下载地址（网址）3. url_username: 用于http基本认证的用户名4. url_password： 用于http基本认证的密码5. validate_certs： 如果否，SSL证书将不会验证。这只应在使用自签名证书的个人控制站点上使用6. owner： 指定属主7. group： 指定属组8. mode： 指定权限9. checksum：文件的校验码10. headers：传递给下载服务器的HTTP Headers11. backup：如果本地已经存在同名文件，备份文件12. timeout：下载的超时时间 （8）unarchive unarchive模块用于解压文件，其作用类似于Linux下的tar命令。默认情况下，unarchive的作用是将控制节点的压缩包拷贝到远程服务器，然后进行解压。 unarchive模块使用示例： 1234567891011# 先创建一个目录ansible test - m file -a 'path=/tmp/data state=directory'# 解压本地文件ansible test - m unarchive -a 'src=data.tar.gz dest=/tmp/data list_files=yes'# 将本地文件拷贝到远程服务器ansible test -m copy -a 'src=data.tar.bz2 dest=/tmp/data.tar.bz2'# 解压远程的文件ansible test -m unarchive -a # 先创建一个目录ansible test - m file -a 'path=/tmp/data state=directory'# 解压本地文件ansible test - m unarchive -a 'src=data.tar.gz dest=/tmp/data list_files=yes'# 将本地文件拷贝到远程服务器ansible test -m copy -a 'src=data.tar.bz2 dest=/tmp/data.tar.bz2'# 解压远程的文件ansible test -m unarchive -a 'src=/tmp/data.tar.bz2 dest=/tmp remote_src=yes' unarchive模块重要选项： 1234567891. remote_src：该选项可以取值为yes或no，用来表示解压的文件存在远程服务器中，还是存在控制节点所在的服务器中。默认取值为no，表示在解压文件之前，先将控制节点的文件复制到远程主机中，然后在进行解压2. src：指定压缩文件的路径，该选项的取值取决于remote_src的取值。如果remote_src取值为yes，则src指定的是远程服务器中压缩包的地址；如果remote_src的取值为no，则src指向的是控制节点中的路径3. dest：该选项指定的是远程服务器上的绝对路径，表示压缩文件解压的路径4. list_files：默认情况下该选项取值为no，如果该选项取值为yes，也会解压文件，并且在ansible的返回值中列出压缩包里的文件5. exclude：解压文件时排除exclude选项指定的文件或目录列表6. keep_newer：默认取值为False，如果该选项取值为True，那么当目标地址中存在同名的文件，并且文件比压缩包中的文件更新时，不进行覆盖7. owner：文件或目录解压以后的所有者8. group：文件或目录解压以后所属的群组9. mode：文件或目录解压以后的权限 （9）git git模块非常好理解，就是在远程服务器执行git相关的操作。该模块一般应用于需要源码安装软件时，从github这样的源码托管网站将软件下载到本地，然后执行命令进行源码安装。需要注意的是，该模块依赖于git软件，因此在使用该模块前应该使用yum模块先安装git软件。 git模块的使用示例： 12345678#将requests克隆到/tmp/requests目录下ansible test -m git -a 'repo=https://github.com/psf/requests.git dest=/tmp/requests version=HEAD'# 从源码安装requestsansible test -a 'python setup.py install chdir=/tmp/requests' -become# 验证requests是否安装成功ansible test -a #将requests克隆到/tmp/requests目录下ansible test -m git -a 'repo=https://github.com/psf/requests.git dest=/tmp/requests version=HEAD'# 从源码安装requestsansible test -a 'python setup.py install chdir=/tmp/requests' -become# 验证requests是否安装成功ansible test -a \"python -c 'import requests'\" git模块常用选项： 123451. repo：远程git库的地址，可以是一个git协议、ssh协议或http协议的git库地址2. dest：必选选项，git库clone到本地服务器以后保存的绝对路径3. version：克隆远程git库的版本，取值可以为HEAD、分支的名称、tag的名称，也可以是一个commit的hash值4. force：默认取值为no，当该选项取值为yes时，如果本地的git库有修改，将会抛弃本地的修改5. accept_hostkey：当该选项取值为yes时，如果git库的服务器不在know_hosts中，则添加到konw_hosts中，key_file指定克隆远程git库地址是使用的私钥 （10）stat stat模块用于获取远程服务器上的文件信息，其作用类似于Linux下的stat命令。stat模块可以获取atime、ctime、mtime、checksum、size、uid、gid等信息。 stat只有path这一个必选选项，用来指定文件或目录的路径。stat模块的使用方法如下： 12# 获取文件的详细信息ansible test -m stat -a # 获取文件的详细信息ansible test -m stat -a 'path=/etc/passwd' （11）cron 顾名思义，cron是管理Linux下计划任务的模块。 cron模块的使用示例： 12345# 增加一个crontab任务ansible test -m cron -a 'backup=yes name=\"测试计划任务\" minute=*/2 hour=* job=\"ls /tmp &gt;/dev/null\"'# 增加一个crontab任务ansible test -m cron -a 'backup=yes name=\"测试计划任务\" minute=*/2 hour=* job=\"ls /tmp &gt;/dev/null\"'# 进入服务器，查看新增的crontab任务crontab -l 该模块包含以下重要选项： 12345671. backup：取值为yes或no，默认为no，表示修改之前先做备份2. state：取值为present或absent，用来确认该任务计划是创建还是删除3. name：该任务的描述4. job：添加或删除任务，主要取决于state的取值5. user：操作哪一个用户的crontab6. cron_file：如果指定该选项，则用该文件替换远程主机上cron.d命令下的用户任务计划7. month weekday 打印minute hour：取值与crontab类似。例如：对于minute的取值范围0~59，也可以选择“*”表示每分钟运行，或者“*/5”表示每5分钟运行 （12）service service模块的作用类似于Linux下的service命令，用来启动、停止、重启服务。 service模块的使用示例： 12345678# 安装Apache，默认情况下，Apache安装完成以后就会启动ansible test -m yum -a 'name=httpd state=present' -become# 停止Apacheansible test -m service -a 'name=httpd state=stopped'# 重启Apacheansible 127.0.0.1 -m service -a # 安装Apache，默认情况下，Apache安装完成以后就会启动ansible test -m yum -a 'name=httpd state=present' -become# 停止Apacheansible test -m service -a 'name=httpd state=stopped'# 重启Apacheansible 127.0.0.1 -m service -a 'name=httpd state=restarted' service模块的常用选项： 123451. name：服务的名称，该选项为必选项2. state：可以取值为started、stopped、restarted和reload。其中，started和stopped是幂等的，也就是说，如果服务已经启动了，执行started不会执行任何操作3. sleep：重启的过程中，先停止服务，然后sleep几秒在启动4. pattern：定义一个模式，ansible首先通过status命令查看服务的状态，依次判断服务是否在运行。如果通过status查看服务状态时没有响应，ansible会尝试匹配ps命令的输出，当匹配到相应模式时，认为服务已经启动，否则认为服务没有启动5. enabled：取值为yes或no，用来设置服务是否开机启动 （13）sysctl 该模块的作用与Linux下的sysctl命令相似，用于控制Linux的内核参数。 sysctl模块使用示例： 12# 设置overcommit_memory参数的值为1ansible test -m sysctl -a # 设置overcommit_memory参数的值为1ansible test -m sysctl -a 'name=vm.overcommit_memory value=1' -become sysctl模块的常用选项： 12341. name：需要设置的参数2. value：需要设置的值3. sysctl_file：sysctl.conf文件的绝对路径，默认路径是/etc/sysctl.conf4. reload：该选项可以取值为yes或no，默认为yes，用于表示设置完成以后是否需要执行sysctl -p操作 （14）setup setup模块用于收集远程主机的信息 setup模块的使用示例： 12345678# 获取IP地址ansible test -m setup -a 'filter=ansible_default_ipv4'# 获取内存信息ansible test -m setup -a 'filter=ansible_memory_mb'# 获取IP地址ansible test -m setup -a 'filter=ansible_default_ipv4'# 获取内存信息ansible test -m setup -a 'filter=ansible_memory_mb'# 获取主机完整信息ansible test -m setup （15）mount 在远程服务器上挂载磁盘，当进行挂盘操作是，如果挂载点指定的路径不存在，将创建该路径。 mount模块使用示例： 12# 挂载/dev/vda盘到/mnt/data目录ansible test -m mount -a # 挂载/dev/vda盘到/mnt/data目录ansible test -m mount -a 'name=/mnt/data src=/dev/vda fstype=ext4 state=mounted' mount模块常用选项： 12341. name：挂载点的路径2. state：可以取值为present、absent、mounted、unmounted，其中，mounted与unmounted用来处理磁盘的挂载和卸载，并且会正确配置fstab文件，present与absent只会设置fstab文件，不会去操作磁盘3. fstype：指定文件系统类型，当state取值为present或mounted时，该选项为必填选项4. src：挂载的设备 （16）synchronize synchronize模块是对rsync命令的封装，以便对常见的rsync任务进行处理。我们也可以使用command模块调用rsync命令执行相应的操作。rsync是一个比较复杂的命令，相对来说，使用synchronize简单一些。 synchronize模块的使用示例： 12# 同步本地目录到远程服务器ansible test -m synchronize -a # 同步本地目录到远程服务器ansible test -m synchronize -a 'src=test dest=/tmp' synchronize模块的常用选项： 123451. src：需要同步到远程服务器的文件和目录2. dest：远程服务器保存数据的路径3. archive：默认取值为yes，相当于同时开启recursive、links、perms、times、owner、group、-D等选项4. compress：默认为yes，表示在文件同步过程中是否启用压缩5. delete：默认为no，当取值为yes时，表示删除dest中存在而src中不存在的文件 4、模块的返回值 Ansible通过模块来执行具体的操作，由于模块的功能千差万别，所以执行模块操作后，Ansible会根据不同的需要返回不同的结果。虽然如此，Ansible中也有一些常见的返回值。如下所示： 返回值的名称 返回值的含义 changed 几乎所有的Ansible模块都会返回该变量，表示模块是否对远程主机执行了修改操作 failed 如果模块未能执行完成，将返回failed为True msg 模块执行失败的原因，常见的错误如ssh连接失败，没有权限执行模块等 rc 与命令行工具相关的模块会返回rc，表示执行Linux命令的返回码 stdout 与rc类似，返回的是标准输出的结果 stderr 与rc类似，返回的是错误输出的结果 backup_file 所有存在backup选项的模块，用来返回备份文件的路径 results 应用在Playbook中存在循环的情况，返回多个结果 错误的 1234[root@python ~]# ansible test -i hosts -a 'echo &#123;&#123;ansible_port&#125;&#125;'192.168.1.60 | CHANGED | rc=0 >>22192.168.1.80 | CHANGED | rc=0 >>22","path":"posts/5017.html","date":"10-16","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"},{"name":"python","slug":"python","permalink":"https://wsdlxgp.top/tags/python/"}]},{"title":"45 k8s复习","text":"创建镜像的方法 1234567891011121314151617[root@master xgp]# vim DockerfileFROM nginxADD index.htm /usr/share/nginx/html///创建Dockerfile[root@master test]# echo \"version 01 wsd\" > index.html[root@master test]# docker build -t 192.168.1.1:5000/nginx .[root@master test]# echo \"version 02 wsd\" > index.html [root@master test]# docker build -t 192.168.1.1:5000/nginx:v1.14 [root@master test]# echo \"version 03 wsd\" > index.html .[root@master test]# docker build -t 192.168.1.1:5000/nginx:v1.15 .//创建不同index.html文件，生成测试镜像[root@master test]# docker push 192.168.1.1:5000/nginx[root@master test]# docker push 192.168.1.1:5000/nginx:v1.14[root@master test]# docker push 192.168.1.1:5000/nginx:v1.15//上传镜像 2) deployment名字为:nginx,保证运行3个Pod.service名字为：nginx-svc。映射到主机端口：31234.（10分） 12345678910111213141516171819202122232425262728293031[root@master yaml]# docker pull nginx//下载nginx镜像[root@master yaml]# vim deployment.yaml //编写deployment和service的yaml文件apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginxspec: replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx---apiVersion: v1kind: Servicemetadata: name: nginx-svcspec: type: NodePort selector: app: nginx ports: - port: 80 targetPort: 80 nodePort: 31234 执行一下 1[root@master yaml]# kubectl apply -f deployment.yaml 查看一下 1[root@master yaml]# kubectl get pod 1[root@master yaml]# kubectl get svc 访问一下http://192.168.1.21:31234/ 3) 共有3个版本，版本1对应image镜像为：nginx，版本2对应的image为：nginx:1.14.版本3对应的版本为:nginx:1.15.分别运行各版本，每个版本要有在浏览器的访问验证。（10分） 1234[root@master yaml]# docker pull nginx[root@master yaml]# docker pull nginx:1.14[root@master yaml]# docker pull nginx:1.15//下载所需镜像 编写deployment的yaml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@master yaml]# vim banben1.yaml//编写deployment和service的yaml文件apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginxspec: replicas: 3 template: metadata: labels: app: nginx-svc spec: containers: - name: nginx image: nginx #更改一下镜像（1.14和1.15的）[root@master yaml]# vim banben2.yaml//编写deployment和service的yaml文件apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx2spec: replicas: 3 template: metadata: labels: app: nginx-svc spec: containers: - name: nginx image: nginx:1.14 #更改一下镜像（1.14和1.15的）[root@master yaml]# vim banben3.yaml//编写deployment和service的yaml文件apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx3spec: replicas: 3 template: metadata: labels: app: nginx-svc spec: containers: - name: nginx image: nginx:1.15 #更改一下镜像（1.14和1.15的） 编写service的yaml文件 1234567891011121314[root@master yaml]# vim ngnix-svc.yaml apiVersion: v1kind: Servicemetadata: name: nginx-svcspec: type: NodePort selector: app: nginx-svc ports: - port: 80 targetPort: 80 nodePort: 31235 执行一下（记录版本信息） 1234[root@master yaml]# kubectl apply -f banben1.yaml --record [root@master yaml]# kubectl apply -f banben2.yaml --record [root@master yaml]# kubectl apply -f banben3.yaml --record [root@master yaml]# kubectl apply -f ngnix-svc.yaml 查看一下 1[root@master yaml]# kubectl get pod 1[root@master yaml]# kubectl get svc 访问一下 http://192.168.1.21:31235/ 4)运行到版本3之后，进行回滚操作回滚到版本4.（5分） 查看记录的版本信息 1[root@master yaml]# kubectl rollout history deployment nginx 回滚到指定版本 12[root@master ~]# kubectl rollout undo deployment nginx --to-revision=4//这里指定的是版本信息的编号 访问一下 5) 此时更改默认的3个Pod的访问界面,.版本1的访问界面内容为：考生名称+version:No1.版本2的访问界面:考生名称+version:No2,以此类推。（5分） 修改POD页面内容（三台不一样） 12[root@master ~]# kubectl exec -it xgp-web-8d5f9656f-8z7d9 /bin/bash//根据pod名称进入pod之中 进入容器后修改页面内容 12345678910111213141[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-8vcvt /bin/bashroot@nginx-d6c5c85cb-8vcvt:/# echo \"version 01 wushaodong\" > /usr/share/nginx/html/index.html root@nginx-d6c5c85cb-8vcvt:/# exit2[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-bxvvt /bin/bashroot@nginx-d6c5c85cb-bxvvt:/# echo \"version 02 wushaodong\" > /usr/share/nginx/html/index.htmlroot@nginx-d6c5c85cb-bxvvt:/# exit3[root@master yaml]# kubectl exec -it nginx-d6c5c85cb-lhlz9 /bin/bashroot@nginx-d6c5c85cb-lhlz9:/# echo \"version 03 wushaodong\" > /usr/share/nginx/html/index.htmlroot@nginx-d6c5c85cb-lhlz9:/# exit 6) 验证界面是否会会有轮训效果，并加以分析论述。（5分） 不要在浏览器里测试轮询，有缓存 1[root@master ~]# curl 127.0.0.1:31235 答：会有轮询的效果，kubernetes 内部的负载均衡是通过 iptables 的 probability 特性来做到的，kube-proxy通过iptables 将访问 Service 的流量转发到后端 Pod，而且使用类似轮询的负载均衡策略。 7) 创建一个NFS PV，NFS共享目录为：考生名称。PV名称为：new-pv。创建一个PVC，名称为new-pvc。单独创建一个pod，使用new-pv，运行之后，验证nfs是否使用成功。（10分） 12345678910111213[root@master ~]# yum -y install nfs-utils rpcbind[root@master yaml]# mkdir /wushaodong//创建指定名称的共享目录[root@master yaml]# echo \"/wushaodong *(rw,sync,no_root_squash)\" > /etc/exports//编写共享目录的权限[root@master ~]# systemctl start nfs-server[root@master ~]# systemctl start rpcbind//启动服务[root@master yaml]# showmount -e//测试一下 1、创建一个NFS PV的yaml文件 12345678910111213141516171819[root@master yaml]# vim new-pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: new-xgpspec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /wushaodong/new-pv server: 192.168.1.21[root@master yaml]# mkdir /wushaodong/new-pv//创建指定目录 执行一下 1[root@master yaml]# kubectl apply -f new-pv.yaml 查看一下 1[root@master yaml]# kubectl get pv 2、创建一个PVC的yaml文件 123456789101112[root@master yaml]# vim new-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: new-pvcspec: accessModes: #要和pv的一直否则关联不成功 - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: nfs #要和pv的一直否则关联不成功 执行一下 1[root@master yaml]# kubectl apply -f new-pvc.yaml 查看一下 1[root@master yaml]# kubectl get pvc 3、单独创建一个pod，使用new-pv 1234567891011121314151617181920[root@master yaml]# vim pod.yamlapiVersion: v1kind: Podmetadata: name: xgp-podspec: containers: - name: xgp-pod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - mountPath: /wushaodong #容器的被挂载目录 name: volumedata volumes: - name: volumedata persistentVolumeClaim: claimName: new-pvc 执行一下 1[root@master yaml]# kubectl apply -f pod.yaml 查看一下 1[root@master yaml]# kubectl get pod 4、测试一下 12345[root@master yaml]# kubectl exec -it xgp-pod /bin/sh//进入pod# echo \"xgpIwsd\" &gt; /wushaodong/xgp.txt//添加内容到挂载目录# [root@master yaml]# kubectl exec -it xgp-pod /bin/sh//进入pod# echo \"xgpIwsd\" &gt; /wushaodong/xgp.txt//添加内容到挂载目录# exit 查看一下，挂载目录是否有添加内容 1[root@master yaml]# cat /wushaodong/new-pv/xgp.txt 8）请简述k8s集群中，master节点有哪些组件，node节点有哪些组件，作用分别有什么作用，各组件又是怎么交互的。（5分） master节点 1. API server[资源操作入口]：是k8s集群的前端接口，各种各样客户端工具以及k8s的其他组件可以通过它管理k8s集群的各种资源。它提供了HTTP/HTTPS RESTful API,即K8S API。 提供了资源对象的唯一操作入口，其他所有组件都必须通过它提供的API来操作资源数据，只有API Server与存储通信，其他模块通过API Server访问集群状态。 第一，是为了保证集群状态访问的安全。 第二，是为了隔离集群状态访问的方式和后端存储实现的方式：API Server是状态访问的方式，不会因为后端存储技术etcd的改变而改变。 作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTFul接口方式提供给外部客户和内部组件调用。对相关的资源数据“全量查询”+“变化监听”，实时完成相关的业务功能。 2. Scheduler[集群分发调度器]：负责决定将Pod放在哪个Node上运行。在调度时，会充分考虑集群的拓扑结构，当前各个节点的负载情况，以及应对高可用、性能、数据亲和性和需求。 1.Scheduler收集和分析当前Kubernetes集群中所有Minion节点的资源(内存、CPU)负载情况，然后依此分发新建的Pod到Kubernetes集群中可用的节点。 2.实时监测Kubernetes集群中未分发和已分发的所有运行的Pod。 3.Scheduler也监测Minion节点信息，由于会频繁查找Minion节点，Scheduler会缓存一份最新的信息在本地。 4.最后，Scheduler在分发Pod到指定的Minion节点后，会把Pod相关的信息Binding写回API Server。 4. Controller Manager[内部管理控制中心]：负责管理集群的各种资源，保证资源处于预期的状态。它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等。 实现集群故障检测和恢复的自动化工作，负责执行各种控制器，主要有： 1.endpoint-controller：定期关联service和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的。 2.replication-controller：定期关联replicationController和pod，保证replicationController定义的复制数量与实际运行pod的数量总是一致的。 **5. Etcd：**负责保存k8s集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速的通知k8s相关组件。（第三方组件）它有可替换方案。Consul、zookeeper 6. Pod: k8s集群的最小组成单位。一个Pod内，可以运行一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。 **7. Flanner：**是k8s集群网络，可以保证Pod的跨主机通信。也有替换方案。 Node节点 Kubelet[节点上的Pod管家]：它是Node的agent(代理)，当Scheduler确定某 个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet,kubelet会根据这些信息创建和运行容器，并向Master报告运行状态。 负责Node节点上pod的创建、修改、监控、删除等全生命周期的管理 定时上报本Node的状态信息给API Server。 kubelet是Master API Server和Minion之间的桥梁，接收Master API Server分配给它的commands和work，与持久性键值存储etcd、file、server和http进行交互，读取配置信息。 具体的工作如下： 设置容器的环境变量、给容器绑定Volume、给容器绑定Port、根据指定的Pod运行一个单一容器、给指定的Pod创建network 容器。 同步Pod的状态、同步Pod的状态、从cAdvisor获取Container info、 pod info、 root info、 machine info。 在容器中运行命令、杀死容器、删除Pod的所有容器。 **kube-proxy[负载均衡、路由转发]:**负责将访问service的TCP/UDP数据流转发到后端的容器。如果有多个 副本，kube-proxy会实现负载均衡。 Proxy是为了解决外部网络能够访问跨机器集群中容器提供的应用服务而设计的，运行在每个Node上。Proxy提供TCP/UDP sockets的proxy，每创建一种Service，Proxy主要从etcd获取Services和Endpoints的配置信息（也可以从file获取），然后根据配置信息在Minion上启动一个Proxy的进程并监听相应的服务端口，当外部请求发生时，Proxy会根据Load Balancer将请求分发到后端正确的容器处理。 Proxy不但解决了同一主宿机相同服务端口冲突的问题，还提供了Service转发服务端口对外提供服务的能力，Proxy后端使用了随机、轮循负载均衡算法。 各个组件的作用以及架构工作流程: 1) kubectl发送部署 请求到API server 2) APIserver通知Controller Manager创建一个Deployment资源。 3) Scheduler执行调度任务,将两个副本Pod分发到node01和node02. 上。 4) node01和node02, 上的kubelet在各自节点上创建并运行Pod。 补充 1.应用的配置和当前的状态信息保存在etcd中，执行kubectl get pod时API server会从etcd中读取这些数据。 2.flannel会为每个Pod分配一个IP。 但此时没有创建Service资源，目前kube-proxy还没有参与进来。 9）部署一个dashboard。（5分） 1、下载所需yaml文件和镜像 12[root@master https]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc5/aio/deploy/recommended.yaml[root@master https]# docker pull kubernetesui/dashboard:v2.0.0-rc5 2、修改 recommended.yaml 12345678910111213141516[root@master https]#vim recommended.yaml ---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort #添加40 ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard 执行一下 1[root@master https]# kubectl apply -f recommended.yaml 查看一下 1[root@master https]# kubectl get svc -n kubernetes-dashboard 3、浏览器访问https://192.168.1.21:30949/ PS:如果是使用的旧版本的dashboard, 使用Google浏览器登录，可能是不成功的，需要换成其他的浏览器，比如:火狐。 4、基于token的方法登录dashboard &lt;1&gt;创建一个dashboard的管理用户 1[root@master https]# kubectl create serviceaccount dashboard-admin -n kube-system &lt;2&gt;绑定用户为集群管理用户 1[root@master https]# kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin &lt;3&gt;获取Token 12[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin//先得到Token的名称 12[root@master https]# kubectl describe secrets -n kube-system dashboard-admin-token-j874n//查看上述得到的secret资源的详细信息，会得到token &lt;4&gt;在浏览器上使用token登录。 成功界面 10）使用helm的方式，部署mysql服务，要求使用storageclass作为持久化存储，服务运行之后，进入数据库，创建一个test库，库中一张test表，内容为： 9527. 然后模拟数据库Pod失败，待Pod重启后，查看对应数据是否还存在？（10分） 1、安装部署helm工具 （1）下载helm的包 12[root@master ~]#docker pull gcr.io/kubernetes-helm/tiller:v2.14.3[root@master ~]# wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz （2）把helm包的命令，复制到本地 123456[root@master helm]# mv linux-amd64/helm /usr/local/bin///移动命令目录到/usr/local/bin/[root@master helm]# chmod +x /usr/local/bin/helm //给予执行权限[root@master helm]# helm help//验证是否安装成功 （3）设置命令自动补全 123[root@master helm]# echo 'source","path":"posts/h8er.html","date":"09-14","excerpt":"","tags":[{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"}]},{"title":"44 k8s的持续集成（jenkins+gitlab+k8s）","text":"应用场景： 问题项目分为app和后台两种，为了保证再同一个环境下面测试，所以不可能链接开发本地服务进行测试，所以需要搭建一个测试环境，供app进行开发测试。这个时候就有一个问题，如果开发新增加功能或者app调试的时候发现问题，这个时候就需要提交新的代码或者修复bug，然后重新发布到测试环境中去。但是后台人员又不能进入Linux服务器中，只能通过Linux运维人员来重新部署，这样的效率就会极低。 方案：基于这种模式下面的，我们引入了Jenkins工具，通过Jenkins来拉取svn/git代码到服务器中，再Jenkins中编写Linux运行脚本，通过脚本我们就可以对代码进行编译运行，然后重新发布到服务器中运行。后端人员也不需要通知Linux运维人员来执行这个操作，直接再Jenkins的控制台就可以执行了。 实验环境 IP 主机名称 服务 192.168.1.21 master k8s 192.168.1.22 node01 k8s 192.168.1.10 git gitlab 192.168.1.13 jenkins jenkins 总体流程： 在开发机开发代码后提交到gitlab 之后通过webhook插件触发jenkins进行构建，jenkins将代码打成docker镜像，push到docker-registry 之后将在k8s-master上执行rc、service的创建，进而创建Pod，从私服拉取镜像，根据该镜像启动容器 应用构建和发布流程说明。 用户向Gitlab提交代码，代码中必须包含Dockerfile 将代码提交到远程仓库 用户在发布应用时需要填写git仓库地址和分支、服务类型、服务名称、资源数量、实例个数，确定后触发Jenkins自动构建 Jenkins的CI流水线自动编译代码并打包成docker镜像推送到Harbor镜像仓库 Jenkins的CI流水线中包括了自定义脚本，根据我们已准备好的kubernetes的YAML模板，将其中的变量替换成用户输入的选项 生成应用的kubernetes YAML配置文件 更新Ingress的配置，根据新部署的应用的名称，在ingress的配置文件中增加一条路由信息 更新PowerDNS，向其中插入一条DNS记录，IP地址是边缘节点的IP地址。关于边缘节点，请查看边缘节点配置 Jenkins调用kubernetes的API，部署应用 一、前期工作 1、先验证k8s集群（1.21和1.22） 1[root@master ~]# kubectl get nodes 2、master部署私有仓库 Docker01部署 12345678910111213141516171872 docker pull registry//下载registry镜像73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest//基于registry镜像，启动一台容器78 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.21:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker76 docker tag httpd:latest 192.168.1.11:5000/web:v1 76 docker tag httpd:latest 192.168.1.11:5000/web:v2//把容器重命名一个标签77 docker ps 123456789101178 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker100 docker push 192.168.1.11:5000/web:v1100 docker push 192.168.1.11:5000/web:v2//上传容器到私有仓库 Docker02和docker03加入私有仓库 12345678978 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker99 docker pull 192.168.1.21:5000/web:v1//测试下载 3、然后重要的地方到了，建立 yaml配置文件让kubernetes自己控制容器集群。 用来模拟我们部署的服务 12345678910111213141516171819[root@master app]# vim deploy.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: webspec: replicas: 2 template: metadata: labels: name: web spec: containers: - name: web image: 192.168.1.21:5000/web:v1 imagePullPolicy: Always #改为本地仓库下载 ports: - containerPort: 80 执行一下 1[root@master app]# kubectl apply -f deploy.yaml 查看一下 1[root@master app]# kubectl get pod 可是容器的ip只能在容器本机上访问，集群内的其他主机和集群外的主机都没办法访问，这个时候就需要将容器的端口映射到服务器上的端口了，所以需要做一个service的模板。service 模板可以将容器的端口映射到服务器的端口上，并且可以固定映射在服务器上的端口。 12345678910111213141516[root@master app]# vim deploy-svc.yamlapiVersion: v1kind: Servicemetadata: labels: name: web name: webspec: type: NodePort ports: - port: 80 targetPort: 80 nodePort: 31234 selector: name: web 执行一下 1[root@master app]# kubectl apply -f deploy-svc.yaml 查看一下 1[root@master app]# kubectl get svc 访问一下http://192.168.1.21:31234/ 《ok kubernetes 完毕， 开始配置 jenkins+gitlab联动》 4、git和jenkins加入私有仓库 12345678978 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker99 docker pull 192.168.1.11/busybox:v1//测试下载 5、jenkins服务器向k8smaster做免密登录 1100 ssh-copy-id 192.168.1.21 二、安装jenkins（1.13） 安装java环境 123456789101112131415[root@jenkins ~]# tar -zxf jdk-8u231-linux-x64.tar.gz[root@jenkins ~]# mv jdk1.8.0_131 /usr/java#[root@jenkins ~]# tar -zxf jdk-8u231-linux-x64.tar.gz[root@jenkins ~]# mv jdk1.8.0_131 /usr/java#注意 这里有位置敏感，不要多一个“/”[root@jenkins ~]# vim /etc/profile #在最下面写export JAVA_HOME=/usr/javaexport JRE_HOME=/usr/java/jreexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATHexport CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar[root@jenkins ~]# source /etc/profile//环境变量生效[root@jenkins ~]# java -version//验证环境变量 安装tomcat 1234567[root@jenkins ~]# tar -zxf apache-tomcat-7.0.54.tar.gz [root@jenkins ~]# mv apache-tomcat-7.0.54 /usr/tomcat7[root@jenkins ~]# cd /usr/tomcat7/webapps/[root@jenkins webapps]# rm -rf *[root@jenkins webapps]# cp /root/jenkins.war . #这几步是jenkins的包放进了tomcat里[root@jenkins webapps]# vim /usr/tomcat7/conf/server.xml //修改tomcat的字符集 12345678910[root@jenkins webapps]# cd /usr/tomcat7/bin/[root@jenkins bin]# vim catalina.sh #[root@jenkins webapps]# cd /usr/tomcat7/bin/[root@jenkins bin]# vim catalina.sh #!/bin/shexport CATALINA_OPTS=\"-DJENKINS_HOME=/data/jenkins\"export JENKINS_JAVA_OPTIONS=\"-Djava.awt.headless=true -Dhudson.ClassicPluginStrategy.noBytecodeTransformer=true\"//这两行添加的是jenkins的家目录位置，这个很重要[root@jenkins bin]# ./catalina.sh start //启动tomcat 1[root@jenkins bin]# netstat -anput | grep 8080 浏览器安装jenkins http://192.168.1.11:8080/jenkins 12[root@jenkins bin]# cat /data/jenkins/secrets/initialAdminPasswordc577cbf75d934878a94b0f9e00ada328 //复制密码 （1）推荐安装 #左边是自动安装， 右边是自定义安装，我们选左边的，如果不是这个画面则说明网络很卡或者没有网(推荐使用右边的，然后选择不安装插件，之后可以自定义安装） （2）这个是自定义安装（自己上传的包） 12345678[root@autoweb bin]# ./catalina.sh stop[root@autoweb ~]# cd /data/jenkins/plugins/[root@autoweb jenkins]# mv plugins plugins/.bk然后上传plugins.tar.gz包：[root@autoweb jenkins]# tar -zxf plugins.tar.gz [root@autoweb ~]# cd /usr/tomcat7/bin/[root@autoweb bin]# ./catalina.sh stop[root@autoweb bin]# ./catalina.sh start 输入密码后断网 （3）两个剩下的方法一样 下载中文插件 系统管理-----&gt;插件管理-----&gt;avalilable(可选)然后搜索localization-zh-cn 然后还需要3个插件 三、安装gitlab（1.10） GitLab CI 是 GitLab 默认集成的 CI 功能，GitLab CI 通过在项目内 .gitlab-ci.yaml 配置文件读取 CI 任务并进行相应处理；GitLab CI 通过其称为 GitLab Runner 的 Agent 端进行 build 操作；Runner 本身可以使用多种方式安装，比如使用 Docker 镜像启动等；Runner 在进行 build 操作时也可以选择多种 build 环境提供者；比如直接在 Runner 所在宿主机 build、通过新创建虚拟机(vmware、virtualbox)进行 build等；同时 Runner 支持 Docker 作为 build 提供者，即每次 build 新启动容器进行 build；GitLab CI 其大致架构如下 12345# yum -y install curl policycoreutils openssh-server openssh-clients postfix git# systemctl enable sshd# systemctl start sshd# systemctl enable postfix## yum -y install curl policycoreutils openssh-server openssh-clients postfix git# systemctl enable sshd# systemctl start sshd# systemctl enable postfix# systemctl start postfix 安装gitlab-ce 1[root@git ~]# curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash 注：由于网络问题，国内用户，使用清华大学的镜像源进行安装： 1234567891011121314151617181920212223242526272829[root@git ~]# vim /etc/yum.repos.d/gitlab-ce.repo[gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7repo_gpgcheck=0gpgcheck=0enabled=1gpgkey=https://packages.gitlab.com/gpg.key[root@git ~]# yum makecache//保存到本地[root@git ~]# yum -y install gitlab-ce #[root@git ~]# vim /etc/yum.repos.d/gitlab-ce.repo[gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7repo_gpgcheck=0gpgcheck=0enabled=1gpgkey=https://packages.gitlab.com/gpg.key[root@git ~]# yum makecache//保存到本地[root@git ~]# yum -y install gitlab-ce #这两条命令是把gitlab源先加入了yum，然后yum下载gitlab[root@git ~]# vim /etc/gitlab/gitlab.rb //修改端口是为了防止端口冲突，因为80默认是http服务的 external_url 'http://192.168.1.21:90' #端口， unicorn默认是8080 也是tomcat的端口 unicorn['listen'] = '127.0.0.1'unicorn['port'] = 3000 [root@git ~]# gitlab-ctl reconfigure //启动gitlab，这个过程可能会有点慢[root@git ~]# ls /etc/yum.repos.d///查看一下 访问192.168.1.10:90 在网页配置用户密码后则安装完毕。用户默认root，这里让设置一个密码再登录，这里设置12345.com（相对较短的密码不让设置） 四、jenkins和gitlab相互关联 jenkins：工具集成平台 gitlab: 软件托管平台 部署这两个服务的联动，需要经过ssh验证。 1、首先我们需要在gitlab上绑定jenkins服务器的ssh公钥，这里我们使用的是root用户的公私钥，切记生产环境是不允许随便用root的 （1）jenkins 12[root@jenkins ~]# ssh-keygen -t rsa //然后不输入只回车会生成一对公私钥 默认在/root/.ssh/目录里 123[root@jenkins ~]# cat /root/.ssh/id_rsa.pub //查看公钥并复制ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDMA4+je3NsxZrF2v8TPLXJp1ejwy1YokXipEFyGVNo5IbtkiBDwBLOAl5i7yromY8YGgoNNriE2g89IM/44BGC5UDCokQ69Ze9Ta9Kynv3/1PDFXIABJJG0f6LsUqt0nKFaFoGz3ZuYAnl6AzLpXEic8DBDrsFk+UGrxvMfSEqHlYO2b7jRXE1HGRnqI/IcVB190cLT1kmBKi7hSqUNBc1cY6t3a6gGiBpp9tc8PW4r/RcLblhAL1LKx8x37NOZkqox8IMh3eM/wtWwAVFlI8XU+sz9akzJOVmd1ArT5Q4w8WA/uVHCDUGVI/fli/ZRv+mNZyF3EH26runctb5LkCT root@jenkins （2）gitlab 在这里放刚才拷贝的公钥保存就行了。 我们先在gitlab上创建一个代码仓库 点击 new project 输入一个仓库的名字，权限选择公共的（public）然后直接点击创建 点击新建一个new.file 写入代码，起一个名字然后保存 创建好了，然后在本地测试一下是否可用 12345678910[root@git ~]# mkdir xgp[root@git ~]# cd xgp/[root@git xgp]# git clone git@192.168.1.10:root/xgp-demo.git//克隆xgp-demo仓库到本地[root@git xgp]# ls xgp-demo/index.html[root@git xgp]# cat xgp-demo/index.html print: \"hello word!!!\"//查看一下 （3）自动构建 安装插件 先进入到之前查看插件的地方 系统设置----插件管理----高级_—上传插件gitlab-oauth、gitlab-plugin、 windows-slaves、ruby-runt ime、gitlab-hook （4）如果可以用，则打开jenkins 点击新建 地址粘贴进去以后没有报错则没错 但是很伤心它报错了，那是因为jenkins和git没有关联上 解决 git主机生成ssh密钥 1234[root@jenkins ~]# ssh-keygen -t rsa //然后不输入只回车会生成一对公私钥[root@jenkins ~]# cat /root/.ssh/id_rsa //查看密钥并复制 下面的这个插件很重要，就是他实现自动化更新的webhook插件，安装过了就会有这条，然后点击这条下面出来的这些东西保持默认就行。同时注意复制 这个里面写的是jenkins构建时候会执行的shell脚本，这个是最重要的，就是他实现了下端kubernetes自动更新容器的操作。 12345678910111213#!/bin/bashbackupcode=\"/data/backcode/$JOB_NAME/$BUILD_NUMBER\" mkdir -p $backupcode #jenkins创建上述目录chmod 644 \"$JENKINS_HOME\"/workspace/\"$JOB_NAME\"/*rsync -acP \"$JENKINS_HOME\"/workspace/\"$JOB_NAME\"/* $backupcode #$JENKINS_HOME和$JOB_NAME同步最新消息#ssh root@192.168.1.21 sed -i 's/v1/v2/g' /root/app/deploy.yaml #!/bin/bashbackupcode=\"/data/backcode/$JOB_NAME/$BUILD_NUMBER\" mkdir -p $backupcode #jenkins创建上述目录chmod 644 \"$JENKINS_HOME\"/workspace/\"$JOB_NAME\"/*rsync -acP \"$JENKINS_HOME\"/workspace/\"$JOB_NAME\"/* $backupcode #$JENKINS_HOME和$JOB_NAME同步最新消息#ssh root@192.168.1.21 sed -i 's/v1/v2/g' /root/app/deploy.yaml #更改镜像版本echo From 192.168.1.21:5000/web:v1 > \"$JENKINS_HOME\"/workspace/Dockerfileecho COPY ./\"$JOB_NAME\"/* /usr/local/apache2/htdocs/ >> \"$JENKINS_HOME\"/workspace/Dockerfiledocker rmi 192.168.1.21:5000/web:v1docker build -t 192.168.1.21:5000/web:v1 /\"$JENKINS_HOME\"/workspace/.docker push 192.168.1.21:5000/web:v1ssh root@192.168.1.21 kubectl delete deployment webssh root@192.168.1.21 kubectl apply -f /root/app/deploy.yaml $JOB_NAME：项目名称 $BUILD_NUMBER：第几次构建 $JENKINS_HOME：jenkins的家目录 完事以后先别保存，首先复制一下上面的jenkins地址，然后去gitlab上绑定webhook 保存，登陆gitlab，点击下图这个设置 测试显示下图 的蓝条说明jenkins 已经连通了gitlab 回到Jenkins开启匿名访问权限 测试显示下图 的蓝条说明jenkins 已经连通了gitlab 好了，jenkins和gitlab 都已经互相的ssh通过了，然后我们最后需要做的一个ssh是关于jenkins ///注意，这里是从git和jenkins向master节点做免密登录。 12[root@git ~]# ssh-copy-id root@192.168.1.21[root@jenkins ~]# ssh-copy-id root@192.168.1.21 好了，环境全部部署完毕！！！。开始测试 五、测试 测试的方法很简单，就是在gitlab上新建代码，删除代码，修改代码，都会触发webhook进行自动部署。最终会作用在所有的nginx容器中，也就是我们的web服务器。 这里我修改了之前建立的 index.html文件 保存以后，就打开浏览器 一直访问kubernetes-node 里面的容器了 访问一下http://192.168.1.21:31234/ 如果没有变，应该注意查看是否在jenkins上构建完成，等以小会就可以了。 构建成功 六、GitLab CI 总结 CS 架构 GitLab 作为 Server 端，控制 Runner 端执行一系列的 CI 任务；代码 clone 等无需关心，GitLab 会自动处理好一切；Runner 每次都会启动新的容器执行 CI 任务 容器即环境 在 Runner 使用 Docker build 的前提下；所有依赖切换、环境切换应当由切换不同镜像实现，即 build 那就使用 build 的镜像，deploy 就用带有 deploy 功能的镜像；通过不同镜像容器实现完整的环境隔离 CI即脚本 不同的 CI 任务实际上就是在使用不同镜像的容器中执行 SHELL 命令，自动化 CI 就是执行预先写好的一些小脚本 敏感信息走环境变量 一切重要的敏感信息，如账户密码等，不要写到 CI 配置中，直接放到 GitLab 的环境变量中；GitLab 会保证将其推送到远端 Runner 的 SHELL 变量中","path":"posts/b04b.html","date":"09-13","excerpt":"","tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://wsdlxgp.top/tags/jenkins/"},{"name":"gitlab","slug":"gitlab","permalink":"https://wsdlxgp.top/tags/gitlab/"}]},{"title":"43 k8s的charts的四种安装方式及helm私有仓库","text":"自定义helm模板 https://hub.helm.sh/ 1、开发自己的chare包 12345678910111213141516[root@master ~]# helm create mychare//创建一个名为mychare的chare包[root@master ~]# tree -C mychare///以树状图查看一下chare包mychare/├── charts├── Chart.yaml├── templates│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── ingress.yaml│ ├── NOTES.txt│ ├── service.yaml│ └── tests│ └── test-connection.yaml└── values.yaml 2、调试chart 123[root@master mychare]# cd[root@master ~]# helm install --dry-run --debug mychare//检查这个mychare是否有问题 3、安装chart 1[root@node02 ~]# docker pull nginx:stable （1）通过仓库安装 123456[root@master mychare]# helm search redis//搜索chare包[root@master mychare]# helm repo list//查看是否有能访问仓库[root@master mychare]# helm install stable/redis//安装 （2）通过tar包安装 1234567891011121314151617[root@master ~]# helm fetch stable/redis//直接下载chare包[root@master ~]# tar -zxf redis-1.1.15.tgz//解压下载的chare包[root@master ~]# tree -C redisredis├── Chart.yaml├── README.md├── templates│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── networkpolicy.yaml│ ├── NOTES.txt│ ├── pvc.yaml│ ├── secrets.yaml│ └── svc.yaml└── values.yaml （3）通过chare本地目录安装 12345[root@master ~]# helm fetch stable/redis//直接下载chare包[root@master ~]# tar -zxf redis-1.1.15.tgz//解压下载的chare包[root@master ~]# helm install redis （4）通过URL安装 1[root@master ~]# helm install https://example.com/charts/foo-1.2.3.tgz （5）使用本地目录安装： 12[root@master ~]# cd mychare/[root@master mychare]# vim values.yaml 12[root@master mychare]# cd templates/[root@master templates]# vim service.yaml 123[root@master templates]# cd ..[root@master mychare]# helm install -n test ../mychare/[root@master ~]# helm upgrade test mychare/ -f mychare/values.yaml 4、例子 使用mychart部署一个实例: xgp。使用镜像为私有镜像v1 版本。 完成之后，镜像版本。 全部成功之后，将实例做一个升级，将镜像改为v2版本。 更改镜像为私有镜像 1[root@master ~]# vim mychare/values.yaml 12[root@master ~]# helm install -n xgp mychare/ -f mychare/values.yaml[root@master ~]# kubectl get deployments. -o wide 1[root@master ~]# vim mychare/values.yaml 12[root@master ~]# helm upgrade xgp mychare/ -f mychare/values.yaml [root@master ~]# kubectl get deployments. -o wide 1[root@master ~]# kubectl edit deployments. xgp-mychare 1[root@master ~]# kubectl get deployments. -o wide 创建自己的Repo仓库 1、node01启动一个httpd的容器 123456[root@node01 ~]# mkdir /var/xgp//创建一个目录[root@node01 ~]# docker pull httpd//下载httpd镜像[root@node02 ~]# docker run -d -p 8080:80 -v /var/xgp:/usr/local/apache2/htdocs httpd//启动一个httpd的容器 2、master节点上，将mychart目录打包。 12[root@master ~]# helm package mychare/Successfully packaged chart and saved it to: /root/mychare-0.1.0.tgz 3、生成仓库的index文件。 12345678[root@master ~]# mkdir myrepo//创建一个目录存放打包的chare[root@master ~]# mv mychare-0.1.0.tgz myrepo///移动打包好的文件[root@master ~]# helm repo index myrepo/ --url http://192.168.1.22:8080/charts//生成仓库的index文件[root@master ~]# ls myrepo/index.yaml mychare-0.1.0.tgz 4、将生成的tar包和index.yaml上传到node01的/var/www/charts目录下. node01创建目录 1[root@node01 ~]# mkdir /var/xgp/charts master移动动到 1[root@master ~]# scp myrepo/* node01:/var/xgp/charts/ node01查看一下 12[root@node01 ~]# ls /var/xgp/charts/index.yaml mychare-0.1.0.tgz 5、添加新的repo仓库。 12[root@master ~]# helm repo add newrepo http://192.168.1.22:8080/charts[root@master ~]# helm repo list 1[root@master ~]# helm search mychare 6、我们就可以直接使用新的repo仓库部署实例了。 12[root@master ~]# helm install newrepo/mychare -n wsd[root@master ~]# helm list 7.如果以后仓库中新添加了chart包,需要用helm repo update命玲更新本地的index文件。 练习： 新创建一个bdqn.的chart包。然后将chart包上传到上述repo源中。 12345678[root@master ~]# helm create bdqn[root@master ~]# helm package bdqn/[root@master ~]# mv bdqn-0.1.0.tgz myrepo/[root@master ~]# helm repo index myrepo/ --url http://192.168.1.22:8080/charts[root@master myrepo]# scp bdqn-0.1.0.tgz index.yaml node01:/var/xgp/charts[root@master myrepo]# helm repo update[root@master myrepo]# helm search bdqn[root@master myrepo]# helm install http://192.168.1.22:8080/charts/bdqn-0.1.0.tgz 1）创建helm的私有仓库，以自己的名字命名。 1、node01启动一个httpd的容器 123456[root@node01 ~]# mkdir /var/xgp//创建一个目录[root@node01 ~]# docker pull httpd//下载httpd镜像[root@node02 ~]# docker run -d -p 8080:80 -v /var/xgp:/usr/local/apache2/htdocs httpd//启动一个httpd的容器 3、生成仓库的index文件。 1234[root@master ~]# mkdir xgprepo//创建一个目录存放打包的chare[root@master ~]# helm repo index xgprepo/ --url http://192.168.1.22:8080/charts//生成仓库的index文件 4、将生成的index.yaml上传到node01的/var/www/charts目录下. node01创建目录 1[root@node01 ~]# mkdir /var/xgp/charts master移动动到 1[root@master ~]# scp xgprepo/* node01:/var/xgp/charts/ node01查看一下 12[root@node01 ~]# ls /var/xgp/charts/index.yaml 5、添加新的repo仓库 12[root@master ~]# helm repo add xgp http://192.168.1.22:8080/charts[root@master ~]# helm repo list 2） 自定义一个chart包，要求这个包运行一个httpd的服务，使用私有镜像v1版本。3个副本Pod，service类型更改为NodePort，端口指定为:30000 自定义一个chart包 12[root@master ~]# helm create wsd//创建一个名为wsd的chares包 按照要求修改配置文件 123456789101112131415161718192021222324252627282930313233343536373839[root@master ~]# cd wsd///进入这个chart包[root@master wsd]# vim values.yaml//修改wsd的配置文件replicaCount: 3 #三个副本image: repository: 192.168.1.21:5000/web #更改镜像为私有镜像 tag: v1 #镜像标签v1 pullPolicy: IfNotPresent imagePullSecrets: []nameOverride: \"\"fullnameOverride: \"\"service: type: NodePort #修改模式为映射端口 port: 80 nodePort: 30000 #添加端口[root@master wsd]# vim templates/service.yaml apiVersion: v1kind: Servicemetadata: name: &#123;&#123; include \"wsd.fullname\" . &#125;&#125; labels:&#123;&#123; include \"wsd.labels\" . | indent 4 &#125;&#125;spec: type: &#123;&#123; .Values.service.type &#125;&#125; ports: - port: &#123;&#123; .Values.service.port &#125;&#125; targetPort: http protocol: TCP name: http nodePort: &#123;&#123; .Values.service.nodePort &#125;&#125; #“添加”能让服务识别到nodePort的端口 selector: app.kubernetes.io/name: &#123;&#123; include \"wsd.name\" . &#125;&#125; app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125; 测试一下 1[root@master ~]# helm install -n wsd wsd/ -f wsd/values.yaml 查看一下镜像版本 1[root@master ~]# kubectl get deployments. -o wide 访问一下 1[root@master ~]# curl 127.0.0.1:30000 3) 将实例进行更新，要求镜像生产v2版本。 私有镜像和官方镜像升级有所不同，官方的只需通过 （helm upgrade --set imageTag=“标签” 服务名称 charts包名 ）进行更改标签即可，而私有镜像需通过更改values.yaml中的标签才行比较麻烦一点。 1、修改values.yaml 1234567891011121314[root@master ~]# vim wsd/values.yaml # Default values for wsd.# This is a YAML-formatted file.#[root@master ~]# vim wsd/values.yaml # Default values for wsd.# This is a YAML-formatted file.# Declare variables to be passed into your templates.replicaCount: 3image: repository: 192.168.1.21:5000/web tag: v2 #修改标签为v2 pullPolicy: IfNotPresent[root@master ~]# helm upgrade wsd wsd/ -f wsd/values.yaml//基于配置文件刷新一下wsd服务 查看一下 1[root@master ~]# kubectl get deployments. -o wide 访问一下 1[root@master ~]# curl 127.0.0.1:30000 2、使用edit进行版本更新 确定wsd这个服务开启 1[root@master ~]# kubectl edit deployments. wsd 查看一下 1[root@master ~]# kubectl get deployments. -o wide 访问一下 1[root@master ~]# curl 127.0.0.1:30000 4）重新定义一个chart包，名称为: new-test,将这个包上传到上述私有仓库中。 1[root@master ~]# helm repo list 1234567891011121314151617[root@master ~]# helm create xgp-wsd//创建一个名为xgp-wsd的charts包[root@master ~]# helm package xgp-wsd///将xgp-wsd打包在当前目录[root@master ~]# mv xgp-wsd-0.1.0.tgz xgprepo///把打包文件放到仓库目录[root@master ~]# helm repo index xgprepo/ --url http://192.168.1.22:8080/charts//把仓库目录新加入的charts包信息记录在index.yaml中，使得其他加入的主机可以识别到，仓库的charts包[root@master ~]# scp xgprepo/* node01:/var/xgp/charts//将仓库目录的文件移动到httpd服务上，使各个主机可以访问，下载仓库的charts包[root@master ~]# helm repo update //更新一下chart存储库 查看一下 1[root@master ~]# helm search xgp-wsd","path":"posts/e7d.html","date":"09-12","excerpt":"","tags":[{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"chares","slug":"chares","permalink":"https://wsdlxgp.top/tags/chares/"},{"name":"url","slug":"url","permalink":"https://wsdlxgp.top/tags/url/"}]},{"title":"42 k8s中helm安装部署，升级和回滚（chart，helm，tiller，StorageClass）","text":"一、Helm介绍 helm是基于kubernetes 的包管理器。它之于 kubernetes 就如 yum 之于 centos，pip 之于 python，npm 之于 javascript 那 helm 的引入对于管理集群有哪些帮助呢？ 更方便地部署基础设施，如 gitlab，postgres，prometheus，grafana 等 更方便地部署自己的应用，为公司内部的项目配置 Chart，使用 helm 结合 CI，在 k8s 中部署应用一行命令般简单 1、Helm用途 Helm把Kubernetes资源(比如deployments、services或 ingress等) 打包到一个chart中，而chart被保存到chart仓库。通过chart仓库可用来存储和分享chart。Helm使发布可配置，支持发布应用配置的版本管理，简化了Kubernetes部署应用的版本控制、打包、发布、删除、更新等操作。 做为Kubernetes的一个包管理工具，用来管理charts——预先配置好的安装包资源，有点类似于Ubuntu的APT和CentOS中的yum。 Helm具有如下功能： 创建新的chart chart打包成tgz格式 上传chart到chart仓库或从仓库中下载chart 在Kubernetes集群中安装或卸载chart 管理用Helm安装的chart的发布周期 使用Helm可以完成以下事情： 管理Kubernetes manifest files 管理Helm安装包charts 基于chart的Kubernetes应用分发 2、Helm组件及相关术语 开始接触Helm时遇到的一个常见问题就是Helm中的一些概念和术语非常让人迷惑，我开始学习Helm就遇到这个问题。 因此我们先了解一下Helm的这些相关概念和术语。 包管理工具: Helm: Kubernetes的应用打包工具，也是命令行工具的名称。 Helm CLI：是 Helm 客户端，可以在本地执行 Tiller: Helm的服务端，部署在Kubernetes集群中，用于处理Helm的相关命令。 helm的作用：像centos7中的yum命令一样，管理软件包，只不过helm这儿管理的是在k8s上安装的各种容器。 tiller的作用：像centos7的软件仓库一样，简单说类似于/etc/yum.repos.d目录下的xxx.repo。 Repoistory: Helm的软件仓库，repository本质上是一个web服务器，该服务器保存了chart软件包以供下载，并有提供一个该repository的chart包的清单文件以供查询。在使用时，Helm可以对接多个不同的Repository。 Charts：是一个Helm的程序包，它包含了运行一个kubernetes应用程序所需要的镜像、依赖关系和资源定义等。 Release：应用程序运行Charts之后，得到的一个实例。 需要特别注意的是， Helm中提到的Release和我们通常概念中的版本有所不同，这里的Release可以理解为Helm使用Chart包部署的一个应用实例。 其实Helm中的Release叫做Deployment更合适。估计因为Deployment这个概念已经被Kubernetes使用了，因此Helm才采用了Release这个术语。 命令介绍 123456789101112131415161718[root@master ~]# helm search//查看可用的Charts包[root@master ~]# helm inspect stable/redis//查看stable/redis包的详细信息[root@master mysql]# helm fetch stable/mysql//直接下载stable/mysql的chart包[root@master ~]# helm install stable/redis -n redis --dry-run //基于stable/redis包运行一个名为redis的服务（把--dry-run去掉之后相当于安装了一个服务）[root@master ~]# helm list//查看安装的服务[root@master ~]# helm delete redis//删除这个服务[root@master mysql]# helm upgrade --set imageTag=5.7.15 xgp-mysql stable/mysql -f values.yaml //mysql服务的升级[root@master mysql]# helm history xgp-mysql//查看历史版本[root@master mysql]# helm rollback xgp-mysql 1 //回滚到版本一 123456789101112131415161718192021222324252627282930http://hub.kubeapps.com/completion # 为指定的shell生成自动完成脚本（bash或zsh）create # 创建一个具有给定名称的新 chartdelete # 从 Kubernetes 删除指定名称的 releasedependency # 管理 chart 的依赖关系fetch # 从存储库下载 chart 并（可选）将其解压缩到本地目录中get # 下载一个命名 releasehelp # 列出所有帮助信息history # 获取 release 历史home # 显示 HELM_HOME 的位置init # 在客户端和服务器上初始化Helminspect # 检查 chart 详细信息install # 安装 chart 存档lint # 对 chart 进行语法检查list # releases 列表package # 将 chart 目录打包成 chart 档案plugin # 添加列表或删除 helm 插件repo # 添加列表删除更新和索引 chart 存储库reset # 从集群中卸载 Tillerrollback # 将版本回滚到以前的版本search # 在 chart 存储库中搜索关键字serve # 启动本地http网络服务器status # 显示指定 release 的状态template # 本地渲染模板test # 测试一个 releaseupgrade # 升级一个 releaseverify # 验证给定路径上的 chart 是否已签名且有效version # 打印客户端/服务器版本信息dep # 分析 http://hub.kubeapps.com/completion # 为指定的shell生成自动完成脚本（bash或zsh）create # 创建一个具有给定名称的新 chartdelete # 从 Kubernetes 删除指定名称的 releasedependency # 管理 chart 的依赖关系fetch # 从存储库下载 chart 并（可选）将其解压缩到本地目录中get # 下载一个命名 releasehelp # 列出所有帮助信息history # 获取 release 历史home # 显示 HELM_HOME 的位置init # 在客户端和服务器上初始化Helminspect # 检查 chart 详细信息install # 安装 chart 存档lint # 对 chart 进行语法检查list # releases 列表package # 将 chart 目录打包成 chart 档案plugin # 添加列表或删除 helm 插件repo # 添加列表删除更新和索引 chart 存储库reset # 从集群中卸载 Tillerrollback # 将版本回滚到以前的版本search # 在 chart 存储库中搜索关键字serve # 启动本地http网络服务器status # 显示指定 release 的状态template # 本地渲染模板test # 测试一个 releaseupgrade # 升级一个 releaseverify # 验证给定路径上的 chart 是否已签名且有效version # 打印客户端/服务器版本信息dep # 分析 Chart 并下载依赖 3、组件架构 Helm Client 是用户命令行工具，其主要负责如下： 本地 chart 开发 仓库管理 与 Tiller sever 交互 发送预安装的 chart 查询 release 信息 要求升级或卸载已存在的 release Tiller Server是一个部署在Kubernetes集群内部的 server，其与 Helm client、Kubernetes API server 进行交互。Tiller server 主要负责如下： 监听来自 Helm client 的请求 通过 chart 及其配置构建一次发布 安装 chart 到Kubernetes集群，并跟踪随后的发布 通过与Kubernetes交互升级或卸载 chart 简单的说，client 管理 charts，而 server 管理发布 release helm客户端 helm客户端是一个命令行工具，负责管理charts、reprepository和release。它通过gPRC API（使用kubectl port-forward将tiller的端口映射到本地，然后再通过映射后的端口跟tiller通信）向tiller发送请求，并由tiller来管理对应的Kubernetes资源。 tiller服务端 tiller接收来自helm客户端的请求，并把相关资源的操作发送到Kubernetes，负责管理（安装、查询、升级或删除等）和跟踪Kubernetes资源。为了方便管理，tiller把release的相关信息保存在kubernetes的ConfigMap中。 tiller对外暴露gRPC API，供helm客户端调用。 4、工作原理 Chart Install 过程： Helm从指定的目录或者tgz文件中解析出Chart结构信息 Helm将指定的Chart结构和Values信息通过gRPC传递给Tiller Tiller根据Chart和Values生成一个Release Tiller将Release发送给Kubernetes运行。 Chart Update过程： Helm从指定的目录或者tgz文件中解析出Chart结构信息 Helm将要更新的Release的名称和Chart结构，Values信息传递给Tiller Tiller生成Release并更新指定名称的Release的History Tiller将Release发送给Kubernetes运行 Chart Rollback helm将会滚的release名称传递给tiller tiller根据release名称查找history tiller从history中获取到上一个release tiller将上一个release发送给kubernetes用于替换当前release Chart处理依赖 Tiller 在处理 Chart 时，直接将 Chart 以及其依赖的所有 Charts 合并为一个 Release，同时传递给 Kubernetes。因此 Tiller 并不负责管理依赖之间的启动顺序。Chart 中的应用需要能够自行处理依赖关系。 二、安装部署helm工具（客户端） 前提要求 Kubernetes1.5以上版本 集群可访问到的镜像仓库 执行helm命令的主机可以访问到kubernetes集群 （1）下载helm的包 12[root@master ~]#docker pull gcr.io/kubernetes-helm/tiller:v2.14.3[root@master ~]# wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz （2）把helm包的命令，复制到本地 123456[root@master helm]# mv linux-amd64/helm /usr/local/bin///移动命令目录到/usr/local/bin/[root@master helm]# chmod +x /usr/local/bin/helm //给予执行权限[root@master helm]# helm help//验证是否安装成功 （3）设置命令自动补全 123[root@master helm]# echo 'source","path":"posts/5bc1.html","date":"09-11","excerpt":"","tags":[{"name":"chart","slug":"chart","permalink":"https://wsdlxgp.top/tags/chart/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"tiller","slug":"tiller","permalink":"https://wsdlxgp.top/tags/tiller/"}]},{"title":"41 k8s的HPA自动扩容与缩容","text":"HPA介绍 Kubernetes HPA（水平Pod自动缩放）Pod水平自动伸缩，通过此功能，只需简单的配置，即可便可以利用监控指标（cpu使用率、磁盘、内存等）自动的扩容或缩容服务中Pod数量，当业务需求增加时，系统将为您无缝地自动增加适量容器，提高系统稳定性。此处将详细讲解HPA的核心设计原理和基于Hepaster的使用方法。 前提条件 系统应该能否获取到当前Pod的资源使用情况 (意思是可以执行kubectl top pod命令,并且能够得到反馈信息)。 若要实现自动扩缩容的功能，还需要部署heapster服务，用来收集及统计资源的利用率，支持kubectl top命令，heapster服务集成在prometheus（普罗米修斯） MertricServer服务中，所以说，为了方便，我这里基于prometheus服务的环境上进行部署HPA（动态扩缩容）的服务。 实验环境 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于https://blog.51cto.com/14320361/2473879 的实验继续进行 heapster：这个组件之前是集成在k8s集群的,不过在1.12版本之后被移除了。如果还想使用此功能，应该部署metricServer, 这个k8s集群资源使用情况的聚合器。 Cousom：同样处于beta阶段(autoscaling/v2beta1)，但是涉及到自定义的REST API的开发，复杂度会大一些，并且当需要从自定义的监控中获取数据时，只能设置绝对值，无法设置使用率。 自动扩展主要分为两种： 水平扩展(scale out)，针对于实例数目的增减。 垂直扩展(scal up)，即单个实例可以使用的资源的增减, 比如增加cpu和增大内存。 HPA属于前者。它可以根据CPU使用率或应用自定义metrics自动扩展Pod数量(支持 replication controller、deployment 和 replica set)。 工作流程 创建HPA资源，设定目标CPU使用率限额，以及最大/最小实例数，一定要设置Pod的资源限制参数: request，否则HPA不会工作。 控制管理器每隔30s(在kube-controller-manager.service中可以通过–-horizontal-pod-autoscaler-sync-period修改)查询metrics的资源使用情况。 然后与创建时设定的值和指标做对比(平均值之和/限额)，求出目标调整的实例个数。 目标调整的实例数不能超过第一条中设定的最大/最小实例数。如果没有超过，则扩容；超过，则扩容至最大的实例个数。 重复第2-4步。 这里，我们使用一个测试镜像， 这个镜像基于php-apache制作的docker镜像，包含了一些可以运行cpu密集计算任务的代码。 1、创建一个deployment控制器 12345[root@master ~]#docker pull mirrorgooglecontainers/hpa-example:latest//下载hpa-example镜像[root@master ~]# kubectl run php-apache --image=mirrorgooglecontainers/hpa-example --requests=cpu=200m --expose --port=80//基于hpa-example镜像，运行一个deployment控制器，请求CPU的资源为200m，暴露一个80端口 查看一下 1[root@master ~]# kubectl get deployments. 2、创建HPA控制器 12[root@master ~]# kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10//当deployment资源对象的CPU使用率达到50%时，就进行扩容，最多可以扩容到10个 查看一下 1[root@master ~]# kubectl get hpa 3、测试（master开启三个端口） 新开启多个终端，对pod进行死循环请求php-apache的pod 端口一 （1）创建一个应用，用来不停的访问我们刚刚创建的php-apache的svc资源。 1[root@master ~]# kubectl run -i --tty load-generator --image=busybox /bin/sh （2）进入Pod内，执行以下这条命令.用来模拟访问php-apache的svc资源。 12[root@master ~]# while true; do wget -q -O- http://php-apache.default.svc.cluster.local ; done//不停地向php-apache的svc资源，发送ok 端口二 12[root@master ~]# kubectl get hpa -w//实时查看pod的cpu状态 可以看到php-apache的cpu使用情况已经超过了50% 端口三 12[root@master images]# kubectl get pod -w//实时查看pod的状态 可以看到当php-apache的cpu使用情况超过50%后，就会不断生成新的php-apache来进行负载均衡（目前设置的上线时10个），当然，如果cpu使用情况下降到50%，master就会陆续地删除php-apache，这样的使用可以减少不必要的资源浪费、资源分配不均等情况。 二、资源限制 1、基于Pod Kubernetes对资源的限制实际上是通过cgroup来控制的，cgroup 是容器的一组用来控制内核如何运行进程的相关属性集合。针对内存、CPU 和各种设备都有对应的cgroup 默认情况下，Pod运行没有CPU和内存的限额。这意味着系统中的任何 Pod将能够像执行该Pod所在的节点一样，消耗足够多的CPU和内存。一般会针对某些应用的pod资源进行资源限制，这个资源限制是通过 resources的requests和limits来实现 1[root@master ~]# vim cgroup-pod.yaml requests: 要分配的资源，limits为最高请求的资源值。可以简单的理解为初始值和最大值。 2、基于名称空间 1） 计算资源配额 1[root@master ~]# vim compute-resources.yaml 2）配置对象数量配额限制 1[root@master ~]# vim object-counts.yaml 3） 配置CPU和内存的LimitRange 1[root@master ~]# vim limitRange.yaml default 即 limit的值。 defaultRequest 即 request的值。","path":"posts/5f70.html","date":"09-10","excerpt":"","tags":[{"name":"HPA","slug":"HPA","permalink":"https://wsdlxgp.top/tags/HPA/"},{"name":"heapster","slug":"heapster","permalink":"https://wsdlxgp.top/tags/heapster/"},{"name":"top","slug":"top","permalink":"https://wsdlxgp.top/tags/top/"}]},{"title":"40 k8s群集的三种的Web-UI界面部署（dashboard、weave-scope、Prometheus）","text":"一、k8s的UI访问界面-dashboard 在dashboard中，虽然可以做到创建、删除、修改资源等操作，但通常情况下，我们会把它当做健康k8s集群的软件。 作为Kubernetes的Web用户界面，用户可以通过Dashboard在Kubernetes集群中部署容器化的应用，对应用进行问题处理和管理，并对集群本身进行管理。通过Dashboard，用户可以查看集群中应用的运行情况，同时也能够基于Dashboard创建或修改部署、任务、服务等Kubernetes的资源。通过部署向导，用户能够对部署进行扩缩容，进行滚动更新、重启Pod和部署新应用。当然，通过Dashboard也能够查看Kubernetes资源的状态。 1、Dashboard提供的功能 在默认情况下，Dashboard显示默认(default)命名空间下的对象，也可以通过命名空间选择器选择其他的命名空间。在Dashboard用户界面中能够显示集群大部分的对象类型。 1）集群管理 集群管理视图用于对节点、命名空间、持久化存储卷、角色和存储类进行管理。 节点视图显示CPU和内存的使用情况，以及此节点的创建时间和运行状态。 命名空间视图会显示集群中存在哪些命名空间，以及这些命名空间的运行状态。角色视图以列表形式展示集群中存在哪些角色，这些角色的类型和所在的命名空间。 持久化存储卷以列表的方式进行展示，可以看到每一个持久化存储卷的存储总量、访问模式、使用状态等信息；管理员也能够删除和编辑持久化存储卷的YAML文件。 2） 工作负载 工作负载视图显示部署、副本集、有状态副本集等所有的工作负载类型。在此视图中，各种工作负载会按照各自的类型进行组织。 工作负载的详细信息视图能够显示应用的详细信息和状态信息，以及对象之间的关系。 3） 服务发现和负载均衡 服务发现视图能够将集群内容的服务暴露给集群外的应用，集群内外的应用可以通过暴露的服务调用应用，外部的应用使用外部的端点，内部的应用使用内部端点。 4） 存储 存储视图显示被应用用来存储数据的持久化存储卷申明资源。 5） 配置 配置视图显示集群中应用运行时所使用配置信息，Kubernetes提供了配置字典（ConfigMaps）和秘密字典（Secrets），通过配置视图，能够编辑和管理配置对象，以及查看隐藏的敏感信息。 6） 日志视图 Pod列表和详细信息页面提供了查看日志视图的链接，通过日志视图不但能够查看Pod的日志信息，也能够查看Pod容器的日志信息。通过Dashboard能够根据向导创建和部署一个容器化的应用，当然也可以通过手工的方式输入指定应用信息，或者通过上传YAML和JSON文件来创建和不受应用。 2、下载所需yaml文件和镜像 12[root@master https]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc5/aio/deploy/recommended.yaml[root@master https]# docker pull kubernetesui/dashboard:v2.0.0-rc5 3、修改 recommended.yaml 12345678910111213141516[root@master https]#vim recommended.yaml ---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort #添加40 ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard 执行一下 1[root@master https]# kubectl apply -f recommended.yaml 查看一下 1[root@master https]# kubectl get svc -n kubernetes-dashboard 3、浏览器访问https://192.168.1.21:32306 PS:如果是使用的旧版本的dashboard, 使用谷歌浏览器登录，可能是不成功的，需要换成其他的浏览器，比如:火狐。 4、基于token的方法登录dashboard &lt;1&gt;创建一个dashboard的管理用户 1[root@master https]# kubectl create serviceaccount dashboard-admin -n kube-system &lt;2&gt;绑定用户为集群管理用户 1[root@master https]# kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin &lt;3&gt;获取Token 12[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin//先得到Token的名称 12[root@master https]# kubectl describe secrets -n kube-system dashboard-admin-token-62bh9//查看上述得到的secret资源的详细信息，会得到token &lt;4&gt;在浏览器上使用token登录。 创建一个资源 查看是否创建成功 5、基于kubeconfig配置文件的方法登录dashboard &lt;1&gt;获取Token 12[root@master https]# kubectl get secrets -n kube-system | grep dashboard-admin//先得到Token的名称 12[root@master https]# kubectl describe secrets -n kube-system dashboard-admin-token-62bh9//查看上述得到的secret资源的详细信息，会得到token &lt;2&gt;生成kubeconfig配置文件。 设置一个环境变量代表获取的token 1[root@master https]# DASH_TOKEN=$(kubectl get secrets -n kube-system dashboard-admin-token-62bh9 -o jsonpath=&#123;.data.token&#125; | base64 -d) 将k8s集群的配置信息写入kubeconfig配置文件中。 1234[root@master https]# kubectl config set-cluster kubernetes --server=192.168.1.21:6443 --kubeconfig=/root/.dashboard-admin.conf[root@master https]# kubectl config set-credentials dashboard-admin --token=$DASH_TOKEN --kubeconfig=/root/.dashboard-admin.conf[root@master https]# kubectl config set-context dashboard-admin@kubernetes --cluster=kubernetes --user=dashboard-admin --kubeconfig=/root/.dashboard-admin.conf[root@master https]# kubectl config use-context dashboard-admin@kubernetes --kubeconfig=/root/.dashboard-admin.conf &lt;3&gt;将生成的/root/.dashboard-admin.conf的配置文件，导出并做保存。 12[root@master https]# sz /root/.dashboard-admin.conf //导出到自己习惯的位置即可 &lt;4&gt;从浏览器选择kubeconfig的登录方式，然后导入配置文件即可。 二、部署weave-scope监控k8s集群 Weave Scope 是 Docker 和 Kubernetes 可视化监控工具。Scope 提供了至上而下的集群基础设施和应用的完整视图，用户可以轻松对分布式的容器化应用进行实时监控和问题诊断。 使用scope Scope 会自动构建应用和集群的逻辑拓扑。比如点击顶部 PODS，会显示所有 Pod 以及 Pod 之间的依赖关系。 点击 HOSTS，会显示各个节点之间的关系。 实时资源监控 可以在 Scope 中查看资源的 CPU 和内存使用情况。 支持的资源有 Host、Pod 和 Container。** 在线操作 Scope 还提供了便捷的在线操作功能，比如选中某个 Host，点击 &gt;_ 按钮可以直接在浏览器中打开节点的命令行终端 点击 Deployment 的 + 可以执行 Scale Up 操作 可以查看 Pod 的日志 可以 attach、restart、stop 容器，以及直接在 Scope 中排查问题 强大的搜索功能 Scope 支持关键字搜索和定位资源。 还可以进行条件搜索，比如查找和定位 MEMORY &gt; 100M 的 Pod。 1、在github上查找scope的yaml文件 （1）github上搜索scope （2）进入k8s的部署scope的说明 （3）选择k8s的部署 （4）复制上面的链接，并下载yaml文件 1[root@master https]# wget https://cloud.weave.works/k8s/scope.yaml 2、修改下载的yaml文件并运行 123456789[root@master ~]# vim scope.yaml #编辑yaml文件#[root@master ~]# vim scope.yaml #编辑yaml文件#跳转至213行，修改其service的端口类型 spec: type: NodePort #修改类型为NodePort ports: - name: app port: 80 protocol: TCP targetPort: 4040 （1）执行一下 1[root@master https]# kubectl apply -f scope.yaml （2）查看容器的运行情况，确定处于正常运行 1[root@master https]# kubectl get pod -o wide -n weave DaemonSet weave-scope-agent，集群每个节点上都会运行的 scope agent 程序，负责收集数据。 Deployment weave-scope-app，scope 应用，从 agent 获取数据，通过 Web UI 展示并与用户交互。 Service weave-scope-app，默认是 ClusterIP 类型，我们已经在上面的命令中添加了参数k8s-service-type=NodePort修改为 NodePort。 1[root@master https]# kubectl get svc -n weave #DaemonSet资源对象：weave-scope-agent（代理）：负责收集节点的信息； #deployment资源对象:weave-scope-app(应用)：从agent获取数据，通过web UI展示并与用户交互； #DaemonSet资源对象的特性和deployment相比，就是DaemonSet资源对象会在每个节点上都运行且只能运行一个pod。 #由于每个节点都需要监控，所以用到了DaemonSet这种资源对象 3、浏览器访问一下http://192.168.1.21:31841/ 在scope的web界面中，可以查看很多的东西，pod、node节点等详细信息，包括打开容器的终端，查看其日志信息等等 总结 • weave scope可以以其简洁的可视化为我们更生动形象的展现出service/controller/pod等资源对象的管理及简单的web ui操作，方便故障排除及时定位 • weave scope作为web ui目前缺少登录验证，可以利用其他方式里面web服务器的验证做安全管控。 三、部署Prometheus服务 PS:在这里部署的prometheus,并不是Prometheus官网提供的，而是使用的coreos提供的prometheus项目。 在部署之前，先来了解一下Prometheus各个组件的作用吧！ MetricsServer: 是k8s集群资源使用情况的聚合器，收集数据给k8s集群内使用，如kubectl,hpa,scheduler等。 Prometheus Operator : 是一个系统检测和警报工具箱，用来存储监控数据。 Prometheus node-exporter ：收集k8s集群资源的数据，指定告警规则。 Prometheus ：收集apiserver，scheduler，controller-manager，kubelet组件的数据，通过http协议传输。 Grafana: 可视化数据统计和监控平台。 特征 Prometheus 相比于其他传统监控工具主要有以下几个特点： 具有由 metric 名称和键/值对标识的时间序列数据的多维数据模型 有一个灵活的查询语言 不依赖分布式存储，只和本地磁盘有关 通过 HTTP 的服务拉取时间序列数据 也支持推送的方式来添加时间序列数据 还支持通过服务发现或静态配置发现目标 多种图形和仪表板支持 1、在github上搜索coreos/prometheus 复制链接 2、克隆github上的promethes项目 1234[root@master promethes]# yum -y install git//下载git命令[root@master promethes]# git clone https://github.com/coreos/kube-prometheus.git//克隆github上的项目 3、修改grafapa-service.yaml文件, 更改为nodePort的暴露方式，暴露端口为31001.。 1234567891011121314151617181920[root@master promethes]# cd kube-prometheus/manifests///进入kube-prometheus的manifests目录[root@master manifests]# vim grafana-service.yaml #修改grafana的yaml文件apiVersion: v1kind: Servicemetadata: labels: app: grafana name: grafana namespace: monitoringspec: type: NodePort #改为NodePort类型 ports: - name: http port: 3000 targetPort: http nodePort: 31001 #映射到宿主机31001端口 selector: app: grafana 3.修改prometheus-service.yaml文件， 更改为nodePort的暴露方式，暴露端口为31002. 1234567891011121314151617181920[root@master manifests]# vim prometheus-service.yaml #修改prometheus的yaml文件apiVersion: v1kind: Servicemetadata: labels: prometheus: k8s name: prometheus-k8s namespace: monitoringspec: type: NodePort #改为NodePort类型 ports: - name: web port: 9090 targetPort: web nodePort: 31002 #映射到宿主机31002端口 selector: app: prometheus prometheus: k8s sessionAffinity: ClientIP 4、修改alertmanager-service.yaml文件， 更改为nodePort的暴露方式，暴露端口为31003 1234567891011121314151617181920[root@master manifests]# vim alertmanager-service.yaml #修改alertmanager的yaml文件apiVersion: v1kind: Servicemetadata: labels: alertmanager: main name: alertmanager-main namespace: monitoringspec: type: NodePort #改为NodePort类型 ports: - name: web port: 9093 targetPort: web nodePort: 31003 #映射到宿主机31003端口 selector: alertmanager: main app: alertmanager sessionAffinity: ClientIP 5、将setup目录中所有的yaml文件,全部运行。是运行以上yaml文件的基础环境配置。 1234[root@master manifests]# cd setup///进入setup/目录[root@master manifests]# kubectl apply -f setup///运行setup目录中所有的yaml文件 6、将主目录(kube-prometheus)中所有的yaml文件,全部运行。 1234[root@master manifests]# cd ..//返回上一级目录（kube-prometheus）[root@master kube-prometheus]# kubectl apply -f manifests///运行kube-prometheus目录中所有的yaml文件 查看一下 1[root@master ~]# kubectl get pod -n monitoring 部署成功之后，可以运行一条命令， 查看资源使用情况(MetricsServer必须部署成功) 1[root@master images]# kubectl top node 7、浏览器访问一下http://192.168.1.21:31001 客户端访问群集中任意节点的IP+30100端口，即可看到以下界面（默认用户名和密码都是admin） 根据提示更改密码： （1）添加模板 依次点击“import”进行导入下面三个模板： （2）进行以下点击，即可查看群集内的监控状态 以下可看到监控状态 8、导入监控模板 从grafana的官网搜索https://grafana.com/ 复制以下这个模板的id 现在可以看到监控画面了","path":"posts/4f99.html","date":"09-09","excerpt":"","tags":[{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"weave-scope","slug":"weave-scope","permalink":"https://wsdlxgp.top/tags/weave-scope/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://wsdlxgp.top/tags/Prometheus/"}]},{"title":"39 k8s中ingress资源的应用","text":"Ingress实现虚拟主机的方案 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 1、首先确定要运行ingress-nginx-controller服务。 在gitbub上找到所需的ingress的yaml文件 4. master下载 1[root@master ingress]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml 5. 修改 mandatory.yaml 文件 12[root@master ingress]# vim mandatory.yaml hostNetwork: true #213 （1）执行一下 1[root@master ingress]# kubectl apply -f mandatory.yaml （2）查看一下 1[root@master ingress]# kubectl get pod -n ingress-nginx 2、将ingress-nginx-controller暴露为一个Service资源对象。 1234567891011121314151617181920212223242526[root@master yaml]# vim service-nodeport.yaml apiVersion: v1kind: Servicemetadata: name: ingress-nginx namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: type: NodePort ports: - name: http port: 80 targetPort: 80 protocol: TCP - name: https port: 443 targetPort: 443 protocol: TCP selector: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx--- （1）执行一下 1[root@master ingress]# kubectl apply -f service-nodeport.yaml （2）查看一下 1[root@master ingress]# kubectl get svc -n ingress-nginx 3、创建一个deployment资源，和一个service资源， 并相互关联。 123456789101112131415161718192021222324252627[root@master yaml]# vim deploy1.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy1spec: replicas: 2 template: metadata: labels: app: nginx1 spec: containers: - name: nginx1 image: nginx---apiVersion: v1kind: Servicemetadata: name: svc-1spec: selector: app: nginx1 ports: - port: 80 targetPort: 80 执行一下 1[root@master yaml]# kubectl apply -f deploy1.yaml 查看一下 1[root@master yaml]# kubectl get pod 1[root@master yaml]# kubectl get svc 然后复制deploy1.yaml资源工创建另外”一对“服务。 123456789101112131415161718192021222324252627[root@master yaml]# vim deploy2.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy2spec: replicas: 2 template: metadata: labels: app: nginx2 spec: containers: - name: nginx2 image: nginx---apiVersion: v1kind: Servicemetadata: name: svc-2spec: selector: app: nginx2 ports: - port: 80 targetPort: 80 执行一下 1[root@master yaml]# kubectl apply -f deploy2.yaml 查看一下 1[root@master yaml]# kubectl get deployments. 4. 创建ingress的yaml文件，关联是svc1和svc2 12345678910111213141516171819202122232425262728[root@master yaml]# vim ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-1spec: rules: - host: www1.bdqn.com http: paths: - path: / backend: serviceName: svc-1 servicePort: 80---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-2spec: rules: - host: www2.bdqn.com http: paths: - path: / backend: serviceName: svc-2 servicePort: 80 执行一下 1[root@master yaml]# kubectl apply -f ingress.yaml 查看一下 1[root@master yaml]# kubectl get ingresses. 1[root@master yaml]# kubectl describe ingresses. ingress-1 1[root@master yaml]# kubectl describe ingresses. ingress-2 5、由于实验环境限制，所以自己用来模拟-一个域名。 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 访问一下 12[root@master yaml]# kubectl get svc -n ingress-nginx //查看映射的端口 http://www1.bdqn.com:30817/ http://www2.bdqn.com:30817/ 总结上述示例的pod是如何一步一步可以使client访问到的，总结如下： 后端pod===》service====》ingress规则====》写入Ingress-nginx-controller配置文件并自动重载使更改生效===》对本机进行域名解析====》实现client通过域名的IP+端口都可以访问到后端pod Ingress资源实现https代理安全访问。 在上面的操作中，实现了使用ingress-nginx为后端所有pod提供一个统一的入口，那么，有一个非常严肃的问题需要考虑，就是如何为我们的pod配置CA证书来实现HTTPS访问？在pod中直接配置CA么？那需要进行多少重复性的操作？而且，pod是随时可能被kubelet杀死再创建的。当然这些问题有很多解决方法，比如直接将CA配置到镜像中，但是这样又需要很多个CA证书。 这里有更简便的一种方法，就拿上面的情况来说，后端有多个pod，pod与service进行关联，service又被ingress规则发现并动态写入到ingress-nginx-controller容器中，然后又为ingress-nginx-controller创建了一个Service映射到群集节点上的端口，来供client来访问。 在上面的一系列流程中，关键的点就在于ingress规则，我们只需要在ingress的yaml文件中，为域名配置CA证书即可，只要可以通过HTTPS访问到域名，至于这个域名是怎么关联到后端提供服务的pod，这就是属于k8s群集内部的通信了，即便是使用http来通信，也无伤大雅。 1. 生成证书 12345[root@master yaml]# mkdir https//创建一个放置证书的目录[root@master yaml]# cd https/[root@master https]# openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/CN=testsvc /O=testsvc\"//生成证书 2. 创建secret资源， 保存证书。 1[root@master https]# kubectl create secret tls tls-secret --key=tls.key --cert tls.crt 3、创建一个deploy3.yaml文件，模拟一个web服务。 123456789101112131415161718192021222324252627[root@master yaml]# vim deploy3.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy3spec: replicas: 2 template: metadata: labels: app: nginx3 spec: containers: - name: nginx3 image: nginx---apiVersion: v1kind: Servicemetadata: name: svc-3spec: selector: app: nginx3 ports: - port: 80 targetPort: 80 执行一下 1[root@master https]# kubectl apply -f deploy3.yaml 查看一下 1[root@master https]# kubectl get pod 1[root@master https]# kubectl get svc 4、创建对应的ingress规则。 12345678910111213141516171819[root@master https]# vim ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-3spec: tls: - hosts: - www3.bdqn.com #域名 secretName: tls-secret #保存的证书 rules: - host: www3.bdqn.com http: paths: - path: / backend: serviceName: svc-3 servicePort: 80 执行一下 1[root@master https]# kubectl apply -f ingress.yaml 查看一下 1[root@master https]# kubectl get ingresses. 5.查找对应service nodePort的443端口映射的端口，直接用浏览器访问即可。 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 查看映射端口 1[root@master https]# kubectl get svc -n ingress-nginx https://www3.bdqn.com:31372/ k8s集群利用了“一切皆为资源”的原理，把生成的ca证书当成一个公共的资源来使用，使用时只需绑定保存的ca证书即可，不像之前一样，需要一个一个的创建ca证书，然后在关联起来，方便好用又快捷。","path":"posts/7f86.html","date":"09-08","excerpt":"","tags":[{"name":"ingress-nginx","slug":"ingress-nginx","permalink":"https://wsdlxgp.top/tags/ingress-nginx/"},{"name":"https","slug":"https","permalink":"https://wsdlxgp.top/tags/https/"},{"name":"ca","slug":"ca","permalink":"https://wsdlxgp.top/tags/ca/"}]},{"title":"38 K8S的inress-nginx","text":"一、Ingress 及 Ingress Controller 简介 Ingress简单的理解: 原先暴露的service,现在给定个统一的访问入口。 Ingress 是 k8s 资源对象，用于对外暴露服务，该资源对象定义了不同主机名（域名）及 URL 和对应后端 Service（k8s Service）的绑定，根据不同的路径路由 http 和 https 流量。而 Ingress Contoller 是一个 pod 服务，封装了一个 web 前端负载均衡器，同时在其基础上实现了动态感知 Ingress 并根据 Ingress 的定义动态生成 前端 web 负载均衡器的配置文件，比如 Nginx Ingress Controller 本质上就是一个 Nginx，只不过它能根据 Ingress 资源的定义动态生成 Nginx 的配置文件，然后动态 Reload。个人觉得 Ingress Controller 的重大作用是将前端负载均衡器和 Kubernetes 完美地结合了起来，一方面在云、容器平台下方便配置的管理，另一方面实现了集群统一的流量入口，而不是像 nodePort 那样给集群打多个孔。。 所以，总的来说要使用 Ingress，得先部署 Ingress Controller 实体（相当于前端 Nginx），然后再创建 Ingress （相当于 Nginx 配置的 k8s 资源体现），Ingress Controller 部署好后会动态检测 Ingress 的创建情况生成相应配置。Ingress Controller 的实现有很多种：有基于 Nginx 的，也有基于 HAProxy的，还有基于 OpenResty 的 Kong Ingress Controller 等，更多 Controller 见：https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/，本文使用基于 Nginx 的 Ingress Controller：ingress-nginx。 二、Ingress 组成 将Nginx的配置抽象成一个Ingress对象，每添加一个新的服务只需写一个新的Ingress的yaml文件即可 将新加入的Ingress转化成Nginx的配置文件并使之生效 ingress controller ingress服务 三、ingress的工作原理 ingress具体的工作原理如下: ingress contronler通过与k8s的api进行交互，动态的去感知k8s集群中ingress服务规则的变化，然后读取它，并按照定义的ingress规则，转发到k8s集群中对应的service。 而这个ingress规则写明了哪个域名对应k8s集群中的哪个service，然后再根据ingress-controller中的nginx配置模板，生成一段对应的nginx配置。 然后再把该配置动态的写到ingress-controller的pod里，该ingress-controller的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入到nginx的配置文件中，然后reload一下，使其配置生效。以此来达到域名分配置及动态更新的效果。 四、Ingress 可以解决什么问题？ 动态配置服务 如果按照传统方式, 当新增加一个服务时, 我们可能需要在流量入口加一个反向代理指向我们新的k8s服务. 而如果用了Ingress, 只需要配置好这个服务, 当服务启动时, 会自动注册到Ingress的中, 不需要而外的操作. 减少不必要的暴露端口 配置过k8s的都清楚, 第一步是要关闭防火墙的, 主要原因是k8s的很多服务会以NodePort方式映射出去, 这样就相当于给宿主机打了很多孔, 既不安全也不优雅. 而Ingress可以避免这个问题, 除了Ingress自身服务可能需要映射出去, 其他服务都不要用NodePort方式 五、Ingress-nginx配置示例 1) 创建一个web服务，用deployment资源， 用httpd镜像，然后创建一个service资源与之关联。 1234567891011121314151617181920212223242526272829303132333435363738[root@master ingress]# vim deploy_1.yamlapiVersion: v1kind: Namespacemetadata: name: bdqn-ns labels: name: bdqn-ns---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: httpd-deploy namespace: bdqn-nsspec: replicas: 2 template: metadata: labels: app: bdqn-ns spec: containers: - name: httpd image: httpd---apiVersion: v1kind: Servicemetadata: name: httpd-svc namespace: bdqn-nsspec: type: NodePort selector: app: bdqn-ns ports: - name: http-port port: 80 targetPort: 80 nodePort: 31033 执行一下 1[root@master ingress]# kubectl apply -f deploy_1.yaml 查看一下 1[root@master ingress]# kubectl get svc -n bdqn-ns 1[root@master ingress]# kubectl get pod -n bdqn-ns 访问一下 2) 创建一个web服务，用deployment 资源，用tomcat:8.5.45镜像。 1234567891011121314151617181920212223242526272829303132[root@master ingress]# vim deploy_2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: tomcat-deploy namespace: bdqn-nsspec: replicas: 2 template: metadata: labels: app: bdqn-tomcat spec: containers: - name: tomcat image: tomcat:8.5.45---apiVersion: v1kind: Servicemetadata: name: tomcat-svc namespace: bdqn-nsspec: type: NodePort selector: app: bdqn-tomcat ports: - name: tomcat-port port: 8080 targetPort: 8080 nodePort: 32033 执行一下 1[root@master ingress]# kubectl apply -f deploy_2.yaml 查看一下 1[root@master ingress]# kubectl get pod -n bdqn-ns 1[root@master ingress]# kubectl get svc -n bdqn-ns 访问一下 3) 在k8s集群前边部署一个反向代理服务器，这个服务器代理这k8s集群内部的service资源。 1. Ingress: （1）Ingress controller: 将新加入的Ingress转化为反向代理服务器的配置文件，并使之生效。(动态的感知k8s集群内Ingress资源的变化。） （2）Ingress : Ingress:将反向代理服务器的配置抽象成一个Ingress对象，每添加一个新的服务，只需要写一个新的Ingress的yaml文件即可。 2. Nginx :反向代理服务器。 需要解决了两个问题: 1、动态的配置服务。 2、减少不必要的端口暴露。 基于nginx的ingress controller根据不同的开发公司，又分为两种: ​ 1、k8s社区版的: Ingerss - nginx. ​ 2、nginx公司自己开发的: nginx- ingress . 3. 在gitbub上找到所需的ingress的yaml文件 4. master下载 1[root@master ingress]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml 5. 修改 mandatory.yaml 文件 12[root@master ingress]# vim mandatory.yaml hostNetwork: true #213 ---------如果ingress-controller镜像下载不成功，可以直接使用下边的镜像。 docker pull registry.cn-hangzhou.aliyuncs.com/ilanni/nginx-ingress-controller:0.22.0 需要注意的是，如果使用上述镜像，需要将deployment资源指定的镜像名称进行修改。 修改的是madatory.yaml文件里的deployment资源。 在deployment资源中，如果添加了此字段，意味着Pod中运行的应用可以直接使用node节点的端口，这样node节 点主机所在网络的其他主机，就可以通过访问该端口访问此应用。(类似于docker映射到宿主机 上的端口。) （1）执行一下 1[root@master ingress]# kubectl apply -f mandatory.yaml （2）查看一下 1[root@master ingress]# kubectl get pod -n ingress-nginx 6. 创建一个service的yaml文件 （1）执行一下 1[root@master ingress]# kubectl apply -f mandatory.yaml （2）查看一下 1234567891011121314151617[root@master ingress]# vim mandatory-svc.yaml apiVersion: v1kind: Servicemetadata: name: ingress-nginx namespace: ingress-nginxspec: type: NodePort ports: - name: httpd port: 80 targetPort: 80 - name: https port: 443 selector: app: ingress-nginx （1）执行一下 1[root@master ingress]# kubectl apply -f mandatory-svc.yaml （2）查看一下 1[root@master ingress]# kubectl get svc -n ingress-nginx 4）创建Ingress资源。 ingress ： ingress-nginx-controller: 动态感知ingress 资源的变化 ingress: 创建svc与ingress-nginx-controller 关联的规则 （1）编写ingress的yaml文件 123456789101112131415161718192021[root@master yaml]# vim ingress.yaml apiVersion: extensions/v1beta1kind: Ingressmetadata: name: bdqn-ingress namespace: bdqn-ns annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: #规则 - host: ingress.bdqn.com #域名 http: paths: - path: / backend: serviceName: httpd-svc #关联service servicePort: 80 #关联service的映射端口 - path: /tomcat backend: serviceName: tomcat-svc #关联service servicePort: 8080 #关联service的映射端口 执行一下 1[root@master yaml]# kubectl apply -f ingress.yaml 查看一下 1[root@master yaml]# kubectl get pod -n ingress-nginx -o wide 1[root@master yaml]# kubectl get ingresses. -n bdqn-ns 1[root@master yaml]# kubectl describe ingresses. -n bdqn-ns 进入pod查看一下 12[root@master yaml]# kubectl exec -it -n ingress-nginx nginx-ingress-controller-5954d475b6-24k92 /bin/sh/etc/nginx $ cat nginx.conf （2）访问一下 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 访问http://ingress.bdqn.com/ 访问http://ingress.bdqn.com/tomcat 5）为ingress-nginx创建一个service（使用官网的service文件就可以） 复制上面的网址 12[root@master yaml]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/provider/baremetal/service-nodeport.yaml//下载文件到master节点 执行一下，下载的service文件 1[root@master yaml]# kubectl apply -f service-nodeport.yaml 查看一下 1[root@master yaml]# kubectl get service -n ingress-nginx 访问一下 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 访问http://ingress.bdqn.com:30817/ 访问http://ingress.bdqn.com:30817/tomcat Service -Nodeport:因为ingress - nginx - controller运行在了集群内的其中一个节点，为了保证即使这个节点宕机，我们对应的域名仍然能够正常访问服务，所以我们将ingress -nginx- controller也暴露为一个service资源。 六、练习: 创建一个deploymen资源，基于nginx镜像，repolicas：2个.然后创建一个service资源关联这个deployment资源。最后创建一个ingress资源，将上述svc关联到ingress.bdqn.com/nginx 目录下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@master yaml]# vim lianxi.yamlapiVersion: v1kind: Namespacemetadata: name: xgp-666 labels: name: xgp-666---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: xgp namespace: xgp-666spec: replicas: 2 template: metadata: labels: app: xgp-nginx spec: containers: - name: xgp-nginx image: nginx---apiVersion: v1kind: Servicemetadata: name: xgp-svc namespace: xgp-666spec: type: NodePort selector: app: xgp-nginx ports: - name: xgp-port port: 80 targetPort: 80 nodePort: 30000---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: xgp-ingress namespace: xgp-666 annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: ingress.xgp.com http: paths: - path: / backend: serviceName: xgp-svc servicePort: 80 执行一下 1[root@master yaml]# kubectl apply -f lianxi.yaml 查看一下 1[root@master yaml]# kubectl describe ingresses. -n xgp-666 进入本机的 C:\\Windows\\System32\\drivers\\etc ， 修改hosts文件，添加Pod（ingress-controller）运行所在的节点IP。 添加完之后访问一下http://ingress.xgp.com/","path":"posts/c92f.html","date":"09-07","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"},{"name":"ingress","slug":"ingress","permalink":"https://wsdlxgp.top/tags/ingress/"},{"name":"ingress controller","slug":"ingress-controller","permalink":"https://wsdlxgp.top/tags/ingress-controller/"}]},{"title":"37 k8s的Secret（密文）和configmap（明文）的使用教程","text":"一、Secret Secret :用来保存一些敏感信息，比如数据库的用户名密码或者秘钥。 概览 Secret是用来保存小片敏感数据的k8s资源，例如密码，token，或者秘钥。这类数据当然也可以存放在Pod或者镜像中，但是放在Secret中是为了更方便的控制如何使用数据，并减少暴露的风险。 用户可以创建自己的secret，系统也会有自己的secret。 Pod需要先引用才能使用某个secret，Pod有2种方式来使用secret：作为volume的一个域被一个或多个容器挂载；在拉取镜像的时候被kubelet引用。 內建的Secrets 由ServiceAccount创建的API证书附加的秘钥 k8s自动生成的用来访问apiserver的Secret，所有Pod会默认使用这个Secret与apiserver通信 1. Secret类型 Secret有三种类型： Opaque：使用base64编码存储信息，可以通过base64 --decode解码获得原始数据，因此安全性弱。 kubernetes.io/dockerconfigjson：用于存储docker registry的认证信息。 kubernetes.io/service-account-token：用于被 serviceaccount 引用。serviceaccout 创建时 Kubernetes 会默认创建对应的 secret。Pod 如果使用了 serviceaccount，对应的 secret 会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中。 举例:保存数据库的用户名和密码 用户名： root 密码： 123.com 1、通过–from-literal（文字的） 1[root@master secret]# kubectl create secret generic mysecret1 --from-literal=username=root --from-literal=password=123.com generic：通用的，一般的加密方式 查看一下 1[root@master secret]# kubectl get secrets 类型是Opaque（不透明的） 2、通过from-file（文件） 新建两个文件并分别写入用户名和密码 12[root@master secret]# echo root > username[root@master secret]# echo 123.com > password 创建一个secret 1[root@master secret]# kubectl create secret generic mysecret2 --from-file=username --from-file=password 查看一下 1[root@master secret]# kubectl get secrets 3、通过-- from- env-file: 创建一个文件写入用户名和密码 123[root@master secret]#vim env.txt username=rootpassword=123.com 创建一个secret 1[root@master secret]# kubectl create secret generic mysecret3 --from-env-file=env.txt 查看一下 1[root@master secret]# kubectl get secrets 4、通过yaml配置文件 （1）把需要保存的数据加密（”base64“的方式） 1234[root@master secret]# echo root | base64cm9vdAo=[root@master secret]# echo 123.com | base64MTIzLmNvbQo= 解码： 1234[root@master secret]# echo -n cm9vdAo | base64 --decode root[root@master secret]# echo -n MTIzLmNvbQo | base64 --decode 123.com （2）编写secre4的yaml文件 12345678[root@master secret]# vim secret4.yamlapiVersion: v1kind: Secretmetadata: name: mysecret4data: username: cm9vdAo= password: MTIzLmNvbQo= 执行一下 1[root@master secret]# kubectl apply -f secret4.yaml （3）查看一下 1[root@master secret]# kubectl get secrets 如果来使用Secret资源 1. 以Volume挂载的方式 使用Secret secret可以作为数据卷挂载或者作为环境变量暴露给Pod中的容器使用，也可以被系统中的其他资源使用。比如可以用secret导入与外部系统交互需要的证书文件等。 在Pod中以文件的形式使用secret 创建一个Secret，多个Pod可以引用同一个Secret 修改Pod的定义，在spec.volumes[]加一个volume，给这个volume起个名字，spec.volumes[].secret.secretName记录的是要引用的Secret名字 在每个需要使用Secret的容器中添加一项spec.containers[].volumeMounts[]，指定spec.containers[].volumeMounts[].readOnly = true，spec.containers[].volumeMounts[].mountPath要指向一个未被使用的系统路径。 修改镜像或者命令行使系统可以找到上一步指定的路径。此时Secret中data字段的每一个key都是指定路径下面的一个文件名 编写pod的yaml文件 12345678910111213141516171819202122[root@master secret]# vim pod.yaml apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: secret-test mountPath: \"/etc/secret-test\" #pod中的路径 readOnly: true #是否只读 volumes: - name: secret-test secret: secretName: mysecret1 还可以自定义存放数据的文件名 执行一下 1[root@master secret]# kubectl apply -f pod.yaml Secret文件权限 可以指定secret文件的权限，类似linux系统文件权限，如果不指定默认权限是0644，等同于linux文件的-rw-r–r--权限 进入容器查看保存的数据 12345678[root@master secret]# kubectl exec -it mypod /bin/sh/ # cd /etc/secret-test//etc/secret-test # lspasword username/etc/secret-test # cat username root/etc/secret-test # cat pasword 123.com 测试是否有只读权限 12123.com/etc/secret-test # echo admin > username/bin/sh: can't create username: Read-only file system 1.1 自定义存放数据的文件名的yaml文件 1234567891011121314151617181920212223242526[root@master yaml]# vim pod.yaml apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: secret-test mountPath: \"/etc/secret-test\" #pod中的路径 readOnly: true #是否只读 volumes: - name: secret-test secret: secretName: mysecret1 items: - key: username path: my-group/my-username #自定义的容器中的目录 - key: password path: my-group/my-password #自定义的容器中的目录 执行一下 1[root@master yaml]# kubectl apply -f pod.yaml 查看一下 123456[root@master secret]# kubectl exec -it mypod /bin/sh//进入容器查看 # cat /etc/secret-test/my-group/my-password 123.com #[root@master secret]# kubectl exec -it mypod /bin/sh//进入容器查看 # cat /etc/secret-test/my-group/my-password 123.com # cat /etc/secret-test/my-group/my-username root 1.2 如果，现在将secret资源内保存的数据进行更新，请问，使用此数据的应用内，数据是是否也会更新? 会实时更新(这里引用数据，是以volumes挂 载使用数据的方式)。 更新mysecret1的数据: password —&gt; admin YWRtaW4K (base64) 可以通过edit 命令，直接修改。 1[root@master secret]# kubectl edit secrets mysecret1 查看一下 123456[root@master secret]# kubectl exec -it mypod /bin/sh//进入容器查看 # cat /etc/secret-test/my-group/my-password admin #[root@master secret]# kubectl exec -it mypod /bin/sh//进入容器查看 # cat /etc/secret-test/my-group/my-password admin # cat /etc/secret-test/my-group/my-username root 数据已经成功更新了 2、以环境变量的方式 创建一个Secret，多个Pod可以引用同一个Secret 修改pod的定义，定义环境变量并使用env[].valueFrom.secretKeyRef指定secret和相应的key 修改镜像或命令行，让它们可以读到环境变量 编写pod的yaml文件 123456789101112131415161718192021222324[root@master secret]# vim pod-env.yaml apiVersion: v1kind: Podmetadata: name: mypod2spec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 env: - name: SECRET_USERNAME valueFrom: secretKeyRef: name: mysecret2 key: username - name: SECRET_PASSWORD valueFrom: secretKeyRef: name: mysecret2 key: password 执行一下 1[root@master secret]# kubectl apply -f pod-env.yaml 查看一下 1[root@master secret]# kubectl get pod 进入容器查看保存的数据 12345[root@master secret]# kubectl exec -it mypod2 /bin/sh/ # echo $SECRET_USERNAMEroot/ # echo $SECRET_PASSWORD123.com 2.1 更新sevret文件的内容 12[root@master yaml]# kubectl edit secrets mysecret2//修改保存文件的内容 查看一下 12345[root@master secret]# kubectl exec -it mypod2 /bin/sh/ # echo $SECRET_USERNAMEroot/ # echo $SECRET_PASSWORD123.com 等待了一定时间后，可以看到这个数据并没有没有改变 总结 如果引用secret数据的应用， 要求会随着secret资源对象内保存的数据的更新，而实时更新，那么应该使用volumes挂载的方式引用资源因为用环境变量的方式引用不会实时更新数据。 二、ConfigMap 和Secret资源类似，不同之处在于，secret 资源保存的是敏感信息，而Configmap保存的是以明文方式存放的数据。 Configmap的创建与使用方式与Secret非常类似，不同点只在于数据以明文形式存放（不过，我觉得Secret的密文形式也并不密文，只能算得上是简单编码）。 和Secret资源类似，不同之处在于，secret 资源保存的是敏感信息，而Configmap保存的是以明文方式存放的数据。 username：adam age：18 创建的四种方式 1、通过-- from- literal(文字的): 1[root@master yaml]# kubectl create configmap myconfigmap1 --from-literal=username=adam --from-literal=age=18 查看一下 1[root@master yaml]# kubectl get cm 1[root@master yaml]# kubectl describe cm 2、通过–from-file (文件) : 12[root@master yaml]# echo adam > username[root@master yaml]# echo 18 > age 创建 1[root@master yaml]# kubectl create configmap myconfigmap2 --from-file=username --from-file=age 查看一下 1[root@master yaml]# kubectl describe cm 3、通过–from- env-file: 123[root@master yaml]# vim env.txt username=adamage=18 创建 1[root@master yaml]# kubectl create configmap myconfigmap3 --from-env-file=env.txt 查看一下 1[root@master configmap]# kubectl describe cm 4、通过yaml配置文件: 12345678[root@master yaml]# vim configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: myconfigmap4data: username: 'adam' age: '18' 创建 1[root@master yaml]# kubectl apply -f configmap.yaml 查看一下 1[root@master yaml]# kubectl describe cm 如何来使用configmap资源 1. 以Volume挂载的方式 123456789101112131415161718192021[root@master yaml]# vim v-pod.yaml apiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: cmp-test mountPath: \"/etc/cmp-test\" readOnly: true volumes: - name: cmp-test configMap: name: myconfigmap1 执行一下 1[root@master configmap]# kubectl apply -f v-pod.yaml 查看一下 123456[root@master configmap]# kubectl exec -it pod1 /bin/sh//进入容器查看一下 # cat /etc/cmp-test/age 18/ #[root@master configmap]# kubectl exec -it pod1 /bin/sh//进入容器查看一下 # cat /etc/cmp-test/age 18/ # cat /etc/cmp-test/username adam/ 1.1 自定义存放数据的文件名的yaml文件 1234567891011121314151617181920212223242526[root@master configmap]# vim v-pod2.yaml apiVersion: v1kind: Podmetadata: name: pod3spec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: cmp-test mountPath: \"/etc/cmp-test\" readOnly: true volumes: - name: cmp-test configMap: name: myconfigmap1 items: - key: username path: my-group/my-username #自定义的容器中的目录 - key: age path: my-group/my-age #自定义的容器中的目录 执行一下 1[root@master configmap]# kubectl apply -f v-pod2.yaml 查看一下 123456[root@master configmap]# kubectl exec -it pod3 /bin/sh//进入容器查看# cat /etc/cmp-test/my-group/my-username adam/ #[root@master configmap]# kubectl exec -it pod3 /bin/sh//进入容器查看# cat /etc/cmp-test/my-group/my-username adam/ # cat /etc/cmp-test/my-group/my-age 18/ 1.2 如果，现在将secret资源内保存的数据进行更新，请问，使用此数据的应用内，数据是是否也会更新? 1[root@master configmap]# kubectl edit cm myconfigmap1 查看一下 123456[root@master configmap]# kubectl exec -it pod3 /bin/sh//进入容器查看# cat /etc/cmp-test/my-group/my-username adam/ #[root@master configmap]# kubectl exec -it pod3 /bin/sh//进入容器查看# cat /etc/cmp-test/my-group/my-username adam/ # cat /etc/cmp-test/my-group/my-age 10 可以看到更新成功 2.以环境变量的方式 123456789101112131415161718192021222324[root@master configmap]# vim e-pod.yaml apiVersion: v1kind: Podmetadata: name: pod2spec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 env: - name: CONFIGMAP_NAME valueFrom: configMapKeyRef: name: myconfigmap2 key: username - name: CONFIGMAP_AGE valueFrom: configMapKeyRef: name: myconfigmap2 key: age 执行一下 1[root@master configmap]# kubectl apply -f e-pod.yaml 查看一下 123456[root@master configmap]# kubectl exec -it pod2 /bin/sh//进入容器查看一下 # echo $CONFIGMAP_NAMEadam # echo [root@master configmap]# kubectl exec -it pod2 /bin/sh//进入容器查看一下 # echo $CONFIGMAP_NAMEadam # echo $CONFIGMAP_AGE18 2.1 更新sevret文件的内容 12[root@master configmap]# kubectl edit cm myconfigmap2 //修改保存文件的内容 查看一下 123456[root@master configmap]# kubectl exec -it pod2 /bin/sh//进入容器查看一下 # echo $CONFIGMAP_NAMEadam # echo [root@master configmap]# kubectl exec -it pod2 /bin/sh//进入容器查看一下 # echo $CONFIGMAP_NAMEadam # echo $CONFIGMAP_AGE18 等待了一定时间后，可以看到这个数据并没有没有改变 可以看出这个configmap和secret的更新效果基本没有区别。 总结configmap、与secret资源有什么相同和不同之处。 Secret 与 ConfigMap 对比 相同点： key/value的形式 属于某个特定的namespace 可以导出到环境变量 可以通过目录/文件形式挂载 通过 volume 挂载的配置信息均可热更新 不同点： Secret 可以被 ServerAccount 关联 Secret 可以存储 docker register 的鉴权信息，用在 ImagePullSecret 参数中，用于拉取私有仓库的镜像 Secret 支持 Base64 加密 Secret 分为 kubernetes.io/service-account-token、kubernetes.io/dockerconfigjson、Opaque 三种类型，而 Configmap 不区分类型 总结以volumes挂载、和环境变量方式引用资源的相同和不同之处。 volumes挂载(可根据更改数据更新)：引用自己创建的secret（密文）或configmap（明文），挂载到容器中指定的目录下。查看保存的文件时，根据自己所填路径和secret或configmap创建的文件，进行查看。 环境变量(不因更改数据更新)：引用自己创建的secret（密文）或configmap（明文），挂载到容器中指定的目录下。查看保存的文件时，根据自己环境变量，进行查看。","path":"posts/a387.html","date":"09-06","excerpt":"","tags":[{"name":"secret","slug":"secret","permalink":"https://wsdlxgp.top/tags/secret/"},{"name":"pod","slug":"pod","permalink":"https://wsdlxgp.top/tags/pod/"},{"name":"configmap","slug":"configmap","permalink":"https://wsdlxgp.top/tags/configmap/"}]},{"title":"36 k8s的StatefulSet（有状态服务）实现","text":"StatefulSet介绍 遇到的问题： 使用Deployment创建的Pod是无状态的，当挂在Volume之后，如果该Pod挂了，Replication Controller会再run一个来保证可用性，但是由于是无状态的，Pod挂了的时候与之前的Volume的关系就已经断开了，新起来的Pod无法找到之前的Pod。但是对于用户而言，他们对底层的Pod挂了没有感知，但是当Pod挂了之后就无法再使用之前挂载的磁盘了。 StatefulSet: 是一种给Pod提供唯一标志的控制器，它可以保证部署和扩展的顺序。 Pod一致性：包含次序（启动、停止次序）、网络一致性。此一致性与Pod相关，与被调度到哪个node节点无关。 稳定的次序：对于N个副本的StatefulSet，每个Pod都在[0，N)的范围内分配一个数字序号，且是唯一的。 稳定的网络：Pod的hostname模式为(statefulset名称)- (序号)。 稳定的存储：通过VolumeClaimTemplate为每个Pod创建一个PV。删除、减少副本，不会删除相关的卷。 (1) RC、 RS、Deployment、DS。-----&gt; 无状态服务 template(模板):根据模板 创建出来的Pod,它们J的状态都是一模一样的(除了名称，IP, 域名之外) 可以理解为:任何一个Pod, 都可以被删除，然后用新生成的Pod进行替换。 (2) 有状态的服务: 需要记录前一 次或者多次通信中的相关事件，以作为一下通信的分类标准。比如: mysql等数据库服务。(Pod的名称，不能随意变化。数据持久化的目录也是不一样，每一个Pod都有自己独有的数据持久化存储目录。) mysql:主从关系。 如果把之前无状态的服务比喻为牛、羊等牲畜，因为，这些到一定时候就可以出售。那么，有状态就比喻为:宠物，而宠物不像牲畜一样到达一定时候出售，人们往往会照顾宠物的一生。 (3) 每一个Pod----&gt;对应一个PVC----&gt;每一个PVC对应一个PV。 storageclass:自动创建PV 需要解决:自动创建PVC。 实现原理 与 ReplicaSet 和 Deployment 资源一样，StatefulSet 也使用控制器的方式实现，它主要由 StatefulSetController、StatefulSetControl 和 StatefulPodControl 三个组件协作来完成 StatefulSet 的管理，StatefulSetController 会同时从 PodInformer 和 ReplicaSetInformer 中接受增删改事件并将事件推送到队列中： 控制器 StatefulSetController 会在 Run 方法中启动多个 Goroutine 协程，这些协程会从队列中获取待处理的 StatefulSet 资源进行同步，接下来我们会先介绍 Kubernetes 同步 StatefulSet 的过程。 1，例子 （1）创建一个statefulset的yaml文件 12345678910111213141516171819202122232425262728293031323334[root@master yaml]# vim statefulset.yamlapiVersion: v1kind: Servicemetadata: name: headless-svc labels: app: headless-svcspec: ports: - port: 80 selector: app: headless-pod clusterIP: None #没有同一的ip---apiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-testspec: serviceName: headless-svc replicas: 3 selector: matchLabels: app: headless-pod template: metadata: labels: app: headless-pod spec: containers: - name: myhttpd image: httpd ports: - containerPort: 80 Deployment : Deploy+RS+随机字符串(Pod的名称。)没有顺序的，可 以没随意替代的。 1、headless-svc :无头服务。因为没有IP地址，所以它不具备负载均衡的功能了。因为statefulset要求Pod的名称是有顺序的，每一个Pod都不能被随意取代，也就是即使Pod重建之后，名称依然不变。为后端的每一个Pod去命名。 2、statefulSet:定义具体的应用 3、volumeClaimT emplates:自动创建PVC，为后端的Pod提供专有的存储。 执行一下 1[root@master yaml]# kubectl apply -f statefulset.yaml 查看一下 1[root@master yaml]# kubectl get svc 12[root@master yaml]# kubectl get pod//可看到这些pod是有顺序的 一、创建StorageClass资源对象。 1、基于NFS服务，创建NFS服务。 下载nfs所需安装包 1[root@node02 ~]# yum -y install nfs-utils rpcbind 创建共享目录 1[root@master ~]# mkdir /nfsdata 创建共享目录的权限 12[root@master ~]# vim /etc/exports/nfsdata *(rw,sync,no_root_squash) 开启nfs和rpcbind 12[root@master ~]# systemctl start nfs-server.service [root@master ~]# systemctl start rpcbind 测试一下 1[root@master ~]# showmount -e 2、创建rbac权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@master yaml]# vim rbac-rolebind.yaml apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: default---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: defaultrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: default #必写字段roleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io 执行一下 1[root@master yaml]# kubectl apply -f rbac-rolebind.yaml 3、创建Deployment资源对象，用Pod代替 真正的NFS服务。 123456789101112131415161718192021222324252627282930313233[root@master yaml]# vim nfs-deployment.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisionerspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: bdqn - name: NFS_SERVER value: 192.168.1.21 - name: NFS_PATH value: /nfsdata volumes: - name: nfs-client-root nfs: server: 192.168.1.21 path: /nfsdata 执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml 查看一下 1[root@master yaml]# kubectl get pod 4、创建storageclass的yaml文件 1234567[root@master yaml]# vim test-storageclass.yaml apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: stateful-nfsprovisioner: bdqn #通过provisioner字段关联到上述DeployreclaimPolicy: Retain 执行一下 1[root@master yaml]# kubectl apply -f test-storageclass.yaml 查看一下 1[root@master yaml]# kubectl get sc 二，解决自动创建pvc 1、创建statefulset的yaml文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@master yaml]# vim statefulset.yaml apiVersion: v1kind: Servicemetadata: name: headless-svc labels: app: headless-svcspec: ports: - port: 80 name: myweb selector: app: headless-pod clusterIP: None---apiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-testspec: serviceName: headless-svc replicas: 3 selector: matchLabels: app: headless-pod template: metadata: labels: app: headless-pod spec: containers: - image: httpd name: myhttpd ports: - containerPort: 80 name: httpd volumeMounts: - mountPath: /mnt name: test volumeClaimTemplates: #> 自动创建PVC，为后端的Pod提供专有的存储。** - metadata: name: test annotations: #这是指定storageclass volume.beta.kubernetes.io/storage-class: stateful-nfs spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Mi 在此示例中： 创建了一个名为 headless-svc 的 Service 对象，由 metadata: name 字段指示。该 Service 会定位一个名为 headless-svc 的应用，由 labels: app: headless-svc 和 selector: app: headless-pod 指示。该 Service 会公开端口 80 并将其命名为 web。而且该 Service 会控制网域并将互联网流量路由到 StatefulSet 部署的容器化应用。 使用三个副本 Pod (replicas: 3) 创建了一个名为 web 的 StatefulSet。 Pod 模板 (spec: template) 指示其 Pod 标记为 app: headless-pod。 Pod 规范 (template: spec) 指示 StatefulSet 的 Pod 运行一个容器 myhttpd，该容器运行版本为 httpd 映像。容器映像由 Container Registry 托管。 Pod 规范使用由 Service 打开的 web 端口。 template: spec: volumeMounts 指定一个名为 test 的 mountPath。mountPath 是容器中应装载存储卷的路径。 StatefulSet 预配了一个具有 100mb 预配存储空间的 PersistentVolumeClaim：test。 执行一下 1[root@master yaml]# kubectl apply -f statefulset.yaml 查看一下 1[root@master yaml]# kubectl get pod 如果第一个pod出现了问题，后面的pod就不会生成。 1[root@master yaml]# kubectl get statefulsets 2、 验证一下数据存储 容器中创建文件 1234[root@master yaml]# kubectl exec -it statefulset-test-0 /bin/sh# cd /mnt# touch testfile# [root@master yaml]# kubectl exec -it statefulset-test-0 /bin/sh# cd /mnt# touch testfile# exit 宿主机查看一下 12[root@master yaml]# ls /nfsdata/default-test-statefulset-test-0-pvc-bf1ae1d0-f496-4d69-b33b-39e8aa0a6e8d/testfile 三、小实验 以自己的名称创建一个名称空间，以下所有资源都运行在此空间中。用statefuset资源运行一个httpd web服务，要求3个Pod，但是每个Pod的主界面内容不一样，并且都要做专有的数据持久化，尝试删除其中一个Pod，查看新生成的Pod，总结对比与之前Deployment资源控制器控制的Pod有什么不同之处？ （一）创建StorageClass资源对象。 注意：nfs服务要开启 1、创建namespace的yaml文件 12345[root@master yaml]# vim namespace.yaml kind: NamespaceapiVersion: v1metadata: name: xgp-lll #namespave的名称 执行一下 1[root@master yaml]# kubectl apply -f namespace.yaml 查看一下 1[root@master yaml]# kubectl get namespaces 2. 创建rbac权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@master yaml]# vim rbac-rolebind.yamlapiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: xgp-lll---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: xgp-lllrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: xgp-lllroleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io 执行一下 1[root@master yaml]# kubectl apply -f rbac-rolebind.yaml 3、创建Deployment资源对象，用Pod代替 真正的NFS服务。 1234567891011121314151617181920212223242526272829303132333435[root@master yaml]# vim nfs-deployment.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisioner namespace: xgp-lllspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: xgp - name: NFS_SERVER value: 192.168.1.21 - name: NFS_PATH value: /nfsdata volumes: - name: nfs-client-root nfs: server: 192.168.1.21 path: /nfsdata 执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml 查看一下 1[root@master yaml]# kubectl get pod -n xgp-lll 4、创建storageclass的yaml文件 12345678[root@master yaml]# vim test-storageclass.yaml apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: stateful-nfs namespace: xgp-lllprovisioner: xgp #通过provisioner字段关联到上述DeployreclaimPolicy: Retain 执行一下 1[root@master yaml]# kubectl apply -f test-storageclass.yaml 查看一下 1[root@master yaml]# kubectl get sc -n xgp-lll （二）解决自动创建pvc 1、创建statefulset的yaml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apiVersion: v1kind: Servicemetadata: name: headless-svc namespace: xgp-lll labels: app: headless-svcspec: ports: - port: 80 name: myweb selector: app: headless-pod clusterIP: None---apiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-test namespace: xgp-lllspec: serviceName: headless-svc replicas: 3 selector: matchLabels: app: headless-pod template: metadata: labels: app: headless-pod spec: containers: - image: httpd name: myhttpd ports: - containerPort: 80 name: httpd volumeMounts: - mountPath: /usr/local/apache2/htdocs name: test volumeClaimTemplates: #> 自动创建PVC，为后端的Pod提供专有的存储。** - metadata: name: test annotations: #这是指定storageclass volume.beta.kubernetes.io/storage-class: stateful-nfs spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Mi 执行一下 1[root@master yaml]# kubectl apply -f statefulset.yaml 查看一下 1[root@master yaml]# kubectl get pod -n xgp-lll 2、 验证一下数据存储 容器中创建文件 1234567891011第一个[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-0 /bin/bash root@statefulset-test-0:/usr/local/apache2# echo 123 > /usr/local/apache2/htdocs/index.html第二个[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-1 /bin/bash root@statefulset-test-2:/usr/local/apache2# echo 456 > /usr/local/apache2/htdocs/index.html第三个[root@master yaml]# kubectl exec -it -n xgp-lll statefulset-test-2 /bin/bash root@statefulset-test-1:/usr/local/apache2# echo 789 > /usr/local/apache2/htdocs/index.html 宿主机查看一下 123456789101112第一个[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-0-pvc-ccaa02df-4721-4453-a6ec-4f2c928221d7/index.html 123第二个[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-1-pvc-88e60a58-97ea-4986-91d5-a3a6e907deac/index.html 456第三个[root@master yaml]# cat /nfsdata/xgp-lll-test-statefulset-test-2-pvc-4eb2bbe2-63d2-431a-ba3e-b7b8d7e068d3/index.html 789 访问一下 扩容、缩容:在此过程中，Pod的生成或删除操作也是有顺序性的。 升级操作 1kubectl explain sts.spec.updateStrategy.rollingUpdate.partition partition：如果partition后面的值等于N, N+的都会更新。默认值为0（所有都会更新）。 总结： StatefulSet 的控制器直接管理的是 Pod。通过在 Pod 的名字里加上事先约定好的编号，保证应用拓扑状态的服务稳定。 Kubernetes 通过 Headless Service，为这些有编号的 Pod，在 DNS 服务器中生成带有同样编号的 DNS 记录，生成唯一的网络标识。 StatefulSet 为每一个 Pod 分配并创建一个同样编号的 PVC。保证了每一个 Pod 都拥有一个独立的 Volume，保证数据不会丢失。","path":"posts/af4b.html","date":"09-05","excerpt":"","tags":[{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"StatefulSet","slug":"StatefulSet","permalink":"https://wsdlxgp.top/tags/StatefulSet/"},{"name":"nfs-deployment","slug":"nfs-deployment","permalink":"https://wsdlxgp.top/tags/nfs-deployment/"}]},{"title":"35 k8s的存储类","text":"k8s有很多的服务，很多的资源对象。 如果要去创建服务，做数据持久化，需要预先知道可用PV有哪些? 如果为了这个服务去提前创建PV，那么我们还需要知道，这个服务，大概需要多大的空间? 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 存储类介绍 Kubernetes集群管理员通过提供不同的存储类，可以满足用户不同的服务质量级别、备份策略和任意策略要求的存储需求。动态存储卷供应使用StorageClass进行实现，其允许存储卷按需被创建。如果没有动态存储供应，Kubernetes集群的管理员将不得不通过手工的方式类创建新的存储卷。通过动态存储卷，Kubernetes将能够按照用户的需要，自动创建其需要的存储。 基于StorageClass的动态存储供应整体过程如下图所示： 1）集群管理员预先创建存储类（StorageClass）； 2）用户创建使用存储类的持久化存储声明(PVC：PersistentVolumeClaim)； 3）存储持久化声明通知系统，它需要一个持久化存储(PV: PersistentVolume)； 4）系统读取存储类的信息； 5）系统基于存储类的信息，在后台自动创建PVC需要的PV； 6）用户创建一个使用PVC的Pod； 7）Pod中的应用通过PVC进行数据的持久化； 8）而PVC使用PV进行数据的最终持久化处理。 先来简单看一下这张图实现的过程，然后我们再来研究一下 说在前面的话，静态供给的话，会需要我们手动去创建pv，如果没有足够的资源，找不到合适的pv，那么pod就会处于pending等待的状态，就是说找不到合适的伴侣了，所以解决这两种问题，就给出了这种动态供给，主要是能够自动帮你创建pv ，就是你需要多大的容量，就自动给你创建多大的容量，也就是pv，k8s帮你创建了，创建pvc的时候就需要找pv了，这个时候就交给这个存储类了，而存储类呢，去帮你创建这些pv,存储类呢，就是实现了对指定存储的一个支持，直接帮你去调用api去创建存储类，所以就不需要人工的去帮你创建pv了。 而你去想想，当节点比较多，业务比较多的时候，再去人工手动创建pv，量还是很大的，而且也不是很好去维护。 而动态供给主要的一个实现就是StorageClass存储对象，其实它就是声明你使用哪个存储，然后呢帮你去连接，再帮你去自动创建pv。 举个例子更好去理解 话不多说下图 其实它是一个基于NFS实现的一个pv供给，它大概流程是这样的，我们可能会创建一个statefulset有状态的应用存储，然后有一个管理的nfs-storageClass，因为nfs目前是不支持这个自动的创建pv的，我们可以利用社区实现的插件来完成这个pv的自动创建，也就是StorageClass这一块，创建完之后，然后pod再去引用。 一，Storage Class（存储类） 作用：它可以动态的自动的创建所需要的PV Provisioner（供给方，提供者）：及提供了存储资源的存储系统。k8s内建有多重供给方，这些供给方的名字都以“kubernetes.io”为前缀。并且还可以自定义。 Parameters（参数）：存储类使用参数描述要关联到的存储卷，注意不同的供给方参数也不同。 ReclaimPlicy: PV的回收策略，可用值有Delete(默认)和Retain （1）确定基于NFS服务来做的SC。NFS开启 1[root@master yaml]# showmount -e （2）需要RBAC权限。 RBAC：rbac是k8s的API的安全策略，是基于用户的访问权限的控制。规定了谁，可以有什么样的权限。 为了给SC资源操作k8s集群的权限。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@master yaml]# vim rbac-rolebind.yamlkind: NamespaceapiVersion: v1metadata: name: bdqn-test---apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: bdqn-test---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: bdqn-testrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: bdqn-testroleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io 运行一下 1[root@master yaml]# kubectl apply -f rbac-rolebind.yaml （3）nfs-deployment 作用：其实它是一个NFS客户端。但它通过K8S的内置的NFS驱动挂载远端的NFS服务器到本地目录；然后将自身作为storage provider，关联storage class。 1234567891011121314151617181920212223242526272829303132333435[root@master yaml]# vim nfs-deployment.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisioner namespace: bdqn-testspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner #指定账户 containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes #指定容器内的挂载目录 env: - name: PROVISIONER_NAME #这是这个容器内置的变量 value: bdqn-test #这是上面变量的值（名字） - name: NFS_SERVER #内置变量，用于指定nfs服务的IP value: 192.168.1.21 - name: NFS_PATH #内置变量，指定的是nfs共享的目录 value: /nfsdata volumes: #这下面是指定上面挂载到容器内的nfs的路径及IP - name: nfs-client-root nfs: server: 192.168.1.21 path: /nfsdata 执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml （4）创建storageclass 123456789[root@master yaml]# vim test-storageclass.yamlapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: stateful-nfs namespace: bdqn-testprovisioner: bdqn-test #这里要和第三个nfs-client-provisioner的env环境变量中的value值对应。reclaimPolicy: Retain #回收策略为：retain，还有一个默认的值为“default” 执行一下 1[root@master yaml]# kubectl apply -f test-storageclass.yaml （5）创建PVC 1234567891011121314[root@master yaml]# vim test-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-claim namespace: bdqn-testspec: storageClassName: stateful-nfs #定义存储类的名字，要和SC的名字对应 accessModes: - ReadWriteMany #访问模式为RWM resources: requests: storage: 500Mi 执行一下 1[root@master yaml]# kubectl apply -f test-pvc.yaml 查看一下 1[root@master yaml]# kubectl get pvc （6）创建一个Pod 12345678910111213141516171819202122[root@master yaml]# vim test-pod.yamlkind: PodapiVersion: v1metadata: name: test-pod namespace: bdqn-testspec: containers: - name: test-pod image: busybox args: - /bin/sh - -c - sleep 30000 volumeMounts: - name: nfs-pvc mountPath: /test restartPolicy: OnFailure volumes: - name: nfs-pvc persistentVolumeClaim: claimName: test-claim #这的名字要和PVC的名字一致 执行一下 1[root@master yaml]# kubectl apply -f test-pod.yaml 查看一下 1[root@master yaml]# kubectl get pod -n bdqn-test （7）容器中添加内容，并查看挂载目录 进入容器修改页面内容 123456[root@master yaml]# kubectl exec -it test-pod -n bdqn-test /bin/sh/ # cd test//test # touch test-file/test # echo 123456 > test-file /test # cat test-file 123456 查看挂载目录 123456[root@master yaml]# ls /nfsdata/bdqn-test-test-claim-pvc-79ddfcf1-65ae-455f-9e03-5bcfe6c6ce15web1web2[root@master yaml]# cat /nfsdata/bdqn-test-test-claim-pvc-79ddfcf1-65ae-455f-9e03-5bcfe6c6ce15/test-file 123456 二，如果，K8S集群中， 有很多类似的PV, PVC在去向PV申请空间的时候，不仅会考虑名称以及访问控制模式，还会考虑你申请空间的大小，会分配给你最合适大小的PV。 运行一个web服务，采用Deployment资源，基于nginx镜像，replicas为3个。数据持久化目录为nginx服务的主访问目录：/usr/share/nginx/html 创建一个PVC,与上述资源进行关联。 1. 基于nfs服务来做的PV和pvc 下载nfs所需安装包 1[root@node02 ~]# yum -y install nfs-utils rpcbind 创建共享目录 1[root@master ~]# mkdir /nfsdata 创建共享目录的权限 12[root@master ~]# vim /etc/exports/nfsdata *(rw,sync,no_root_squash) 开启nfs和rpcbind 12[root@master ~]# systemctl start nfs-server.service [root@master ~]# systemctl start rpcbind 测试一下 1[root@master ~]# showmount -e 2.先创建两个PV, web- pV1(1G) ,web-pv2 (2G) web1 12345678910111213141516[root@master yaml]# vim web.yaml apiVersion: v1kind: PersistentVolumemetadata: name: web-pvspec : capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web1 server: 192.168.1.21 web2 12345678910111213141516[root@master yaml]# vim web2.yaml apiVersion: v1kind: PersistentVolumemetadata: name: web-pv2spec : capacity : storage: 2Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web2 server: 192.168.1.21 3.创建所需文件夹 12[root@master yaml]# mkdir /nfsdata/web1[root@master yaml]# mkdir /nfsdata/web2 4.执行一下web和web2 12[root@master yaml]# kubectl apply -f web.yaml [root@master yaml]# kubectl apply -f web2.yaml 5.查看一下 1[root@master yaml]# kubectl get pv 6.创建web的pvc的yaml文件 12345678910111213[root@master yaml]# vim web-pvc.yaml apiVersion: v1kind: PersistentVolumeClaimmetadata: name: web-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: nfs 执行一下 1[root@master yaml]# kubectl apply -f web-pvc.yaml 查看一下 1[root@master yaml]# kubectl get pvc 系统会自动给pvc一个相近内存的pv，所以选择了1G的那个 7.创建pod的yaml文件 123456789101112131415161718192021222324[root@master yaml]# vim web-pod.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: web-podspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - image: nginx name: nginx volumeMounts: - name: web-test mountPath: /usr/share/nginx/html volumes: - name: web-test persistentVolumeClaim: claimName: web-pvc 执行一下 1[root@master yaml]# kubectl apply -f web-pod.yaml 查看一下 1[root@master yaml]# kubectl get pod 8. 访问一下nginx的网页 查看一下nginx的ip 1[root@master yaml]# kubectl get pod -o wide 进入容器设置网页内容 12345root@master yaml]# kubectl exec -it web-pod-8686d9c594-qxhr9 /bin/bashroot@web-pod-8686d9c594-qxhr9:/# cd /usr/share/nginx/html/root@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# lsroot@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# echo 123456 > index.htmlroot@web-pod-8686d9c594-qxhr9:/usr/share/nginx/html# exit 访问一下 1[root@master yaml]# curl 10.244.2.17 三，如果两个PV，大小一样，名称一样，访问控制模式不一样，PVC会关联哪一个? (验证PV和PVC 关联的时候，访问模式必须一样) 两个PV，大小一样，名称一样，访问控制模式不一样 &lt;1&gt;创建两个pv web1 123456789101112131415[root@master yaml]# vim web1.yaml apiVersion: v1kind: PersistentVolumemetadata: name: web-pvspec : capacity: storage: 1Gi accessModes: - ReadWriteOnce #能以读-写mount到单个的节点 persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web1 server: 192.168.1.21 web2 123456789101112131415[root@master yaml]# vim web2.yaml apiVersion: v1kind: PersistentVolumemetadata: name: web-pvspec : capacity: storage: 1Gi accessModes: - ReadWriteMany #能以读-写mount到多个的节点 persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web1 server: 192.168.1.21 创建所需文件 1[root@master yaml]# mkdir /nfsdata/web1 执行一下 12[root@master yaml]# kubectl apply -f web1.yaml [root@master yaml]# kubectl apply -f web2.yaml &lt;2&gt;创建pvc 123456789101112[root@master yaml]# vim web-pvc.yaml apiVersion: v1kind: PersistentVolumeClaimmetadata: name: web-pvcspec: accessModes: - ReadWriteMany #能以读-写mount到多个的节点 resources: requests: storage: 1Gi storageClassName: nfs 执行一下 1[root@master yaml]# kubectl apply -f web-pvc.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pv 1[root@master yaml]# kubectl get pvc 现在可以看到pv和pvc关联成功，但是为什么只有一个pv呢？（pv挂载的目录要相同） 那是因为当创建了两个相同名字的pv时它并不会认为这是两个不同的pv，而会把他们当成是同一个pv，后创建的pv会刷新前面创建的pv。然后，当创建了pvc，并且pvc的访问模式和后面创建pv的访问模式一样，他们就会关联成功，反之不成功。（当然这些条件下还需要考虑，pv的内存） 三，小实验 （1）以自己的名称创建一个名称空间。以下所有资源都在此名称空间之下。 &lt;1&gt;编写namespace的yam文件 12345[root@master yaml]# vim namespace.yaml kind: NamespaceapiVersion: v1metadata: name: xgp-znb &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f namespace.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get ns （2）设置rbac权限。 下载所需镜像 1docker pull registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner &lt;1&gt;编写rbac的yam文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@master yaml]# vim rbac-rolebind.yamlkind: NamespaceapiVersion: v1metadata: name: xgp-znb---apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: xgp-znb---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: xgp-znbrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: xgp-znbroleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f rbac-rolebind.yaml （3）创建nfs-deployment.yaml &lt;1&gt;编写deployment的yam文件 1234567891011121314151617181920212223242526272829303132333435[root@master yaml]# vim nfs-deployment.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisioner namespace: xgp-znbspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: xgp-znb - name: NFS_SERVER value: 192.168.1.21 - name: NFS_PATH value: /nfsdata volumes: - name: nfs-client-root nfs: server: 192.168.1.21 path: /nfsdata &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f nfs-deployment.yaml （4）创建storageclass自动创建PV。 &lt;1&gt;编写storageclass的yam文件 1234567[root@master yaml]# vim storageclass.yamlapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: test-scprovisioner: xgp-znb #通过provisioner字段关联到上述DeployreclaimPolicy: Retain &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f storageclass.yaml （5）创建PVC &lt;1&gt;编写PVC的yaml文件 12345678910111213[root@master yaml]# vim pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-claim namespace: xgp-znbspec: storageClassName: test-sc accessModes: - ReadWriteMany resources: requests: storage: 500Mi &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f pvc.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pvc -n xgp-znb （6）创建一个Pod, 基于nginx运行一个web服务，使用Deployment资源对象，replicas=3.持久化存储目录为默认主目录 &lt;1&gt;编写deployment的yam文件 1234567891011121314151617181920212223242526[root@master yaml]# vim pod.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: web-pod namespace: xgp-znbspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - image: nginx name: nginx volumeMounts: - name: web-test mountPath: /usr/share/nginx/html volumes: - name: web-test persistentVolumeClaim: claimName: test-claim &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f pvc.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pod -n xgp-znb （7）访问nginx页面 修改nginx主页 1234[root@master yaml]# kubectl exec -it web-pod-8cd956cc7-6szjb -n xgp-znb /bin/bash//进入容器之中root@web-pod-8cd956cc7-6szjb:/# echo xgp-znb > /usr/share/nginx/html/index.html//添加自定义内容主机 访问一下 1[root@master yaml]# curl 10.244.2.18 四，五个可移植性建议 把你的 pvc，和 其它一系列配置放一起， 比如说deployment，configmap 不要把你的pv放在其它配置里， 因为用户可能没有权限创建pv 初始化pvc 模版的时候， 提供一个storageclass 在你的工具软件中，watch那些没有bound的pvc，并呈现给用户 集群启动的时候启用DefaultStorageClass， 但是不要指定某一类特定的class， 因为不同provisioner的class，参数很难一致 五，四个阶段(volumn phase) 1. 在PVC中绑定一个PV，可以根据下面几种条件组合选择 Access Modes， 按照访问模式选择pv Resources， 按照资源属性选择， 比如说请求存储大小为8个G的pv Selector， 按照pv的label选择 Class， 根据StorageClass的class名称选择, 通过annotation指定了Storage Class的名字, 来绑定特定类型的后端存储 2. 关于根据class过滤出pv的说明： 所有的 PVC 都可以在不使用 StorageClass 注解的情况下，直接使用某个动态存储。把一个StorageClass 对象标记为 “default” 就可以了。StorageClass 用注解http://storageclass.beta.kubernetes.io/is-default-class 就可以成为缺省存储。有了缺省的 StorageClass，用户创建 PVC 就不用 storage-class 的注解了，1.4 中新加入的DefaultStorageClass 准入控制器会自动把这个标注指向缺省存储类。PVC 指定特定storageClassName，如fast时， 绑定名称为fast的storageClassPVC中指定storageClassName为“”时， 绑定no class的pv（pv中无class annotation， 或者其值为“”）PVC不指定storageClassName时， DefaultStorageClass admission plugin 开启与否（在apiserver启动时可以指定）， 对default class的解析行为是不同的。当DefaultStorageClass admission plugin启用时， 针对没有storageClass annotation的pvc，DefaultStorageClass会分配一个默认的class， 这个默认的class需要用户指定，比如在创建storageclass对象时加入annotation,如 http://storageclass.beta.kubernetes.io/is-default-class: “true” 。如果有多个默认的class， 则pvc会被拒绝创建， 如果用户没有指定默认的class， 则这个DefaultStorageClass admission plugin不会起任何作用。 pvc会找那些no class的pv做绑定。当DefaultStorageClass admission plugin没有启用时， 针对没有storageClass annotation的pvc， 会绑定no class的pv（pv中无class annotation， 或者其值为“”）","path":"posts/15ab.html","date":"09-04","excerpt":"","tags":[{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"}]},{"title":"34 k8s存储方式的介绍及应用 （持久化，mysql对数据持久化的应用）","text":"k8s存储: (持久化) docker容器是有生命周期的。 volume 1，存储类（Storage class）是k8s资源类型的一种，它是有管理员为管理PV更加方便创建的一个逻辑组，可以按照存储系统的性能高低，或者综合服务质量，备份策略等分类。不过k8s本身不知道类别到底是什么，它这是作为一个描述。 2，存储类的好处之一就是支持PV的动态创建，当用户用到持久性存储时，不必再去提前创建PV，而是直接创建PVC就可以了，非常的方便。 3，存储类对象的名称很重要，并且出了名称之外，还有3个关键字段 Provisioner（供给方）: 及提供了存储资源的存储系统。k8s内建有多重供给方，这些供给方的名字都以“kubernetes.io”为前缀。并且还可以自定义。 Parameters(参数)：存储类使用参数描述要关联到的存储卷，注意不同的供给方参数也不同。 reclaimPolicy:PV的回收策略，可用值有Delete(默认)和Retain 简介 1, 由于容器本身是非持久化的，因此需要解决在容器中运行应用程序遇到的一些问题。首先，当容器崩溃时，kubelet将重新启动容器，但是写入容器的文件将会丢失，容器将会以镜像的初始状态重新开始；第二，在通过一个Pod中一起运行的容器，通常需要共享容器之间一些文件。Kubernetes通过存储卷解决上述的两个问题。 2, 在Docker有存储卷的概念卷，但Docker中存储卷只是磁盘的或另一个容器中的目录，并没有对其生命周期进行管理。Kubernetes的存储卷有自己的生命周期，它的生命周期与使用的它Pod生命周期一致。因此，相比于在Pod中运行的容器来说，存储卷的存在时间会比的其中的任何容器都长，并且在容器重新启动时会保留数据。当然，当Pod停止存在时，存储卷也将不再存在。在Kubernetes支持多种类型的卷，而Pod可以同时使用各种类型和任意数量的存储卷。在Pod中通过指定下面的字段来使用存储卷： spec.volumes：通过此字段提供指定的存储卷 spec.containers.volumeMounts：通过此字段将存储卷挂接到容器中 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 1.emptyDir（空目录）:类似docker 数据持久化的:docer manager volume 使用场景:在同一 个Pod里，不同的容器，共享数据卷。 如果容器被删除，数据仍然存在，如果Pod被 删除，数据也会被删除。 &lt;1&gt; 介绍 一个emptyDir 第一次创建是在一个pod被指定到具体node的时候，并且会一直存在在pod的生命周期当中，正如它的名字一样，它初始化是一个空的目录，pod中的容器都可以读写这个目录，这个目录可以被挂在到各个容器相同或者不相同的的路径下。当一个pod因为任何原因被移除的时候，这些数据会被永久删除。注意：一个容器崩溃了不会导致数据的丢失，因为容器的崩溃并不移除pod. emptyDir的使用场景如下： 空白的初始空间，例如合并/排序算法中，临时将数据保存在磁盘上。 长时间计算中存储检查点（中间结果），以便容器崩溃时，可以从上一次存储的检查点（中间结果）继续进行，而不是从头开始。 作为两个容器的共享存储，使得第一个内容管理的容器可以将生成的数据存入其中，同时由一个webserver容器对外提供这些页面。 默认情况下，emptyDir数据卷存储在node节点的存储介质（机械硬盘、SSD或网络存储）上。 &lt;2&gt;emptyDir 磁盘的作用： （1）普通空间，基于磁盘的数据存储 （2）作为从崩溃中恢复的备份点 （3）存储那些那些需要长久保存的数据，例web服务中的数据 默认的，emptyDir 磁盘会存储在主机所使用的媒介上，可能是SSD，或者网络硬盘，这主要取决于你的环境。当然，我们也可以将emptyDir.medium的值设置为Memory来告诉Kubernetes 来挂在一个基于内存的目录tmpfs，因为 tmpfs速度会比硬盘块度了，但是，当主机重启的时候所有的数据都会丢失。 测试编写一个yaml文件 12345678910111213141516171819202122232425262728[root@master yaml]# vim emptyDir.yamlapiVersion: v1kind: Podmetadata: name: producer-consumerspec: containers: - image: busybox name: producer volumeMounts: - mountPath: /producer_dir name: shared-volume args: - /bin/sh - -c - echo \"hello k8s\" > /producer_dir/hello; sleep 30000 - image: busybox name: consumer volumeMounts: - mountPath: /consumer_dir name: shared-volume args: - /bin/sh - -c - cat /consumer_dir/hello; sleep 30000 volumes: - name: shared-volume emptyDir: &#123;&#125; 执行一下 1[root@master yaml]# kubectl apply -f emptyDir.yaml 查看一下 1[root@master yaml]# kubectl get pod 查看日志 12[root@master yaml]# kubectl logs producer-consumer producer[root@master yaml]# kubectl logs producer-consumer consumer 查看挂载的目录 node节点查看容器名，并通过容器名查看挂载的目录 1[root@node01 shared-volume]# docker ps 1[root@node01 shared-volume]# docker inspect k8s_consumer_producer-consumer_default_9ec83f9e-e58b-4bf8-8e16-85b0f83febf9_0 进入挂载目录查看一下 2.hostPath Volume:类似docker 数据持久化的:bind mount 如果Pod被删除，数据会保留，相比较emptyDir要好一点。不过一旦host崩溃，hostPath也无法访问 了。 docker或者k8s集群本身的存储会采用hostPath这种方式。 &lt;1&gt; 介绍 hostPath宿主机路径，就是把pod所在的宿主机之上的脱离pod中的容器名称空间的之外的宿主机的文件系统的某一目录和pod建立关联关系，在pod删除时，存储数据不会丢失。 &lt;2&gt; 作用 如果Pod被删除，数据会保留，相比较emptyDir要好一点。不过一旦host崩溃，hostPath也无法访问 了。 docker或者k8s集群本身的存储会采用hostPath这种方式。 适用场景如下： 某容器需要访问 Docker，可使用 hostPath 挂载宿主节点的 /var/lib/docker 在容器中运行 cAdvisor，使用 hostPath 挂载宿主节点的 /sys 3.Persistent Volume| PV(持久卷) 提前做好的，数据持久化的数据存放目录。 Psesistent Volume Claim| PVC( 持久卷使用声明|申请) Psesistent Volume Claim| PVC( 持久卷使用声明|申请) PersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 该API对象捕获存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统。 PVC和PV的概念 我们前面提到kubernetes提供那么多存储接口，但是首先kubernetes的各个Node节点能管理这些存储，但是各种存储参数也需要专业的存储工程师才能了解，由此我们的kubernetes管理变的更加复杂的。由此kubernetes提出了PV和PVC的概念，这样开发人员和使用者就不需要关注后端存储是什么，使用什么参数等问题。如下图： PersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 该API对象捕获存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统。 PersistentVolumeClaim（PVC）是用户存储的请求。PVC的使用逻辑：在pod中定义一个存储卷（该存储卷类型为PVC），定义的时候直接指定大小，pvc必须与对应的pv建立关系，pvc会根据定义去pv申请，而pv是由存储空间创建出来的。pv和pvc是kubernetes抽象出来的一种存储资源。 虽然PersistentVolumeClaims允许用户使用抽象存储资源，但是常见的需求是，用户需要根据不同的需求去创建PV，用于不同的场景。而此时需要集群管理员提供不同需求的PV，而不仅仅是PV的大小和访问模式，但又不需要用户了解这些卷的实现细节。 对于这样的需求，此时可以采用StorageClass资源。这个在前面就已经提到过此方案。 PV是集群中的资源。 PVC是对这些资源的请求，也是对资源的索赔检查。 PV和PVC之间的相互作用遵循这个生命周期： 1Provisioning（配置）---> Binding（绑定）--->Using（使用）---> Releasing（释放） ---> Recycling（回收） （1）基于nfs服务来做的PV和pvc nfs使的我们可以挂在已经存在的共享到的我们的Pod中，和emptyDir不同的是，emptyDir会被删除当我们的Pod被删除的时候，但是nfs不会被删除，仅仅是解除挂在状态而已，这就意味着NFS能够允许我们提前对数据进行处理，而且这些数据可以在Pod之间相互传递.并且，nfs可以同时被多个pod挂在并进行读写 注意：必须先保证NFS服务器正常运行在我们进行挂在nfs的时候 下载nfs所需安装包 1[root@node02 ~]# yum -y install nfs-utils rpcbind 创建共享目录 1[root@master ~]# mkdir /nfsdata 创建共享目录的权限 12[root@master ~]# vim /etc/exports/nfsdata *(rw,sync,no_root_squash) 开启nfs和rpcbind 12[root@master ~]# systemctl start nfs-server.service [root@master ~]# systemctl start rpcbind 测试一下 1[root@master ~]# showmount -e &lt;1&gt;创建nfs-pv的yaml文件 12345678910111213141516[root@master yaml]# cd yaml/[root@master yaml]# vim nfs-pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: test-pvspec: capacity: #pv容量的大小 storage: 1Gi accessModes: #访问pv的模式 - ReadWriteOnce #能以读-写mount到单个的节点 persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/pv1 server: 192.168.1.21 1234 accessModes:(PV支持的访问模式) - ReadWriteOnce: 能以读-写mount到单个的节点 - ReadWriteMany: 能以读-写mount到多个的节点。- ReadOnlyMnce: 能以只读的方式mount到多个节点。 1234persistentVolumeReclaimPolicy : (PV存储空间的回收策略是什么)trueRecycle: 自动清除数据。trueRetain: 需要管理员手动回收。trueDelete: 云存储专用。 &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f nfs-pv.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pv &lt;1&gt;创建nfs-pvc的yaml文件 PersistentVolumeClaim（PVC）是用户存储的请求。PVC的使用逻辑：在pod中定义一个存储卷（该存储卷类型为PVC），定义的时候直接指定大小，pvc必须与对应的pv建立关系，pvc会根据定义去pv申请，而pv是由存储空间创建出来的。pv和pvc是kubernetes抽象出来的一种存储资源。 12345678910111213[root@master yaml]# vim nfs-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: nfs &lt;2&gt;执行一下 1[root@master yaml]# kubectl apply -f nfs-pvc.yaml &lt;3&gt;查看一下 1[root@master yaml]# kubectl get pvc 1[root@master yaml]# kubectl get pv （2）创建一个pod资源 1234567891011121314151617181920[root@master yaml]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-podspec: containers: - name: pod1 image: busybox args: - /bin/sh - -c - sleep 30000 volumeMounts: - mountPath: \"/mydata\" name: mydata volumes: - name: mydata persistentVolumeClaim: claimName: test-pvc &lt;1&gt; 执行一下 1[root@master yaml]# kubectl apply -f pod.yaml &lt;2&gt;查看一下 1[root@master yaml]# kubectl get pod -o wide 可以看到现在没有开启成功 查看一下test-pod的信息看看是哪里的问题 1[root@master yaml]# kubectl describe pod test-pod 那是因为pv的本地挂载目录没有创建好 12[root@master yaml]# mkdir /nfsdata/pv1///要和nfs-pv.yaml的名字一样 重新创建一下pod 123[root@master yaml]# kubectl delete -f pod.yaml [root@master yaml]# kubectl apply -f pod.yaml [root@master yaml]# kubectl get pod -o wide （3）test-pod创建hello创建文件并添加内容 1[root@master yaml]# kubectl exec test-pod touch /mydata/hello 进入容器 123[root@master yaml]# kubectl exec -it test-pod /bin/sh/ # echo 123 > /mydata/hello/ # exit 挂载目录查看一下 1[root@master yaml]# cat /nfsdata/pv1/hello 和刚刚的一样 （4）测试回收策略 删除pod和pvc，pv 123[root@master yaml]# kubectl delete pod test-pod [root@master yaml]# kubectl delete pvc test-pvc [root@master yaml]# kubectl delete pv test-pv 查看一下 1[root@master yaml]# kubectl get pv 1[root@master yaml]# cat /nfsdata/pv1/hello 文件已被回收 （5）修改pv的回收策略为手动 修改 123456789101112131415[root@master yaml]# vim nfs-pv.yaml apiVersion: v1kind: PersistentVolumemetadata: name: test-pvspec : capacity : storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain #修改 storageClassName: nfs nfs: path: /nfsdata/pv1 server: 192.168.1.21 执行一下 1[root@master yaml]# kubectl apply -f nfs-pv.yaml 创建pod 1[root@master yaml]# kubectl apply -f pod.yaml 查看一下 1[root@master yaml]# kubectl describe pod test-pod 创建pvc 1[root@master yaml]# kubectl apply -f nfs-pvc.yaml 查看一下pod 1[root@master yaml]# kubectl get pod （6）test-pod创建hello创建文件并添加内容 1[root@master yaml]# kubectl exec test-pod touch /mydata/k8s 查看一下挂载目录 1[root@master yaml]# ls /nfsdata/pv1/ 删除pod和pvc，pv，再次查看挂载目录 123[root@master yaml]# kubectl delete pod test-pod [root@master yaml]# kubectl delete pvc test-pvc[root@master yaml]# kubectl delete pv test-pv 查看挂载目录 1[root@master yaml]# ls /nfsdata/pv1/ 内容还在 4.mysql对数据持久化的应用 下面演示如何为 MySQL 数据库提供持久化存储，步骤为： 创建 PV 和 PVC。 部署 MySQL。 向 MySQL 添加数据。 模拟节点宕机故障，Kubernetes 将 MySQL 自动迁移到其他节点。 验证数据一致性。 最小化安装系统需要 1yum -y install mariadb （1）通过之前的yaml文件，创建pv和pvc 12[root@master yaml]# kubectl apply -f nfs-pv.yaml [root@master yaml]# kubectl apply -f nfs-pvc.yaml 查看一下 1[root@master yaml]# kubectl get pv 1[root@master yaml]# kubectl get pvc （2）编写一个mysql的yaml文件 123456789101112131415161718192021222324252627282930313233343536[root@master yaml]# vim mysql.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: test-mysqlspec: selector: matchLabels: #支持等值的标签 app: mysqlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: test-mysqlspec: selector: matchLabels: app: mysql template: metadata: labels: app: mysql spec: containers: - image: mysql:5.6 name: mysql env: - name: MYSQL_ROOT_PASSWORD value: 123.com volumeMounts: - name: mysql-storage mountPath: /var/lib/mysql volumes: - name: mysql-storage persistentVolumeClaim: claimName: test-pvc 执行一下 1[root@master yaml]# kubectl apply -f mysql.yaml 查看一下 1[root@master yaml]# kubectl get pod （3）进入mysql容器 ① 切换到数据库 mysql。 ② 创建数据库表 my_id。 ③ 插入一条数据。 ④ 确认数据已经写入。 关闭 k8s-node2，模拟节点宕机故障。 1[root@master yaml]# kubectl exec -it test-mysql-569f8df4db-rkpwm -- mysql -u root -p123.com 创建数据库 1mysql&gt;mysql&gt; create database yun33; 切换数据库 1mysql&gt;mysql&gt; use yun33; 创建表 1mysql&gt;mysql&gt; create table my_id( id int(4))； 在表中插入数据 1mysql&gt;mysql&gt; insert my_id values(9527); 查看表 1mysql&gt;mysql&gt; select * from my_id; （4）查看本地的挂载目录 1[root@master yaml]# ls /nfsdata/pv1/ 查看一下pod 1[root@master yaml]# kubectl get pod -o wide -w 挂起node01 （5）查看node02上面数据是否和刚才一样（验证数据的一致性） 进入数据库 1[root@master yaml]# kubectl exec -it test-mysql-569f8df4db-nsdnz -- mysql -u root -p123.com 查看数据库 1mysql&gt;mysql&gt; show databases; 查看表 1mysql> show tables; 1mysql> select * from my_id; 可以看到数据还在 5. 排错方法 kubectl describe //查看详细信息，找出问题 kubectl logs //查看日志，找出问题 /var/ log/messages //查看该节点的kubelet的日志。 5. 总结 本章我们讨论了 Kubernetes 如何管理存储资源。 emptyDir 和 hostPath 类型的 Volume 很方便，但可持久性不强，Kubernetes 支持多种外部存储系统的 Volume。 PV 和 PVC 分离了管理员和普通用户的职责，更适合生产环境。我们还学习了如何通过 StorageClass 实现更高效的动态供给。 最后，我们演示了如何在 MySQL 中使用 PersistentVolume 实现数据持久性。 PV的访问控制类型 accessModes:(PV支持的访问模式) ReadWriteOnce: 能以读-写mount到单个的节点 ReadWriteMany: 能以读-写mount到多个的节点。 ReadOnlyOnce: 能以只读的方式mount到单个节点。 PV的空间回收策略 persistentVolumeReclaimPolicy : (PV存储空间的回收策略是什么) Recycle: 自动清除数据。 Retain: 需要管理员手动回收。 Delete: 云存储专用。 PV和PVC相互关联 是通过accessModes和storageClassName模块关联的 Pod不断的重启: 1、swap,没有关闭，导致集群运行不正常。 2、内存不足，运行服务也会重后。 kubectl describe kubectl logs /var/ log/messages 查看该节点的kubelet的日志。","path":"posts/ba49.html","date":"09-03","excerpt":"","tags":[{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"emptyDir","slug":"emptyDir","permalink":"https://wsdlxgp.top/tags/emptyDir/"}]},{"title":"33 k8s复习","text":"虚拟化 云计算的分类: 基础及服务: laas 平台及服务: paas 软件及服务: saas **docker虚拟化的底层原理: ** Namespace + Cgroup **Namespace六项隔离: ** IPC: 共享内存,消息列队 MNT: 挂载点 文件系统 NET: 网络栈 PID: 进程编号 USER: 用户 组 UTS: 主机名 域名 namespace 六项隔离 实现了容器与宿主机 容器与容器之间的隔离 **Cgroup 四项作用: ** **1） 资源的限制: **cgroup可以对进程组使用的资源总额进行限制 **2） 优先级分配: **通过分配的cpu时间片数量以及硬盘IO带宽的大小，实际上相当于控制了进程运行的优先级别 **3） 资源统计: ** group可以统计系统资源使用量，比如gpu使用时间，内存使用量等，用于按量计费。同时还支持挂起动能，也就是说通过cgroup把所有 资源限制起来,对资源都不能使用，注意着并不是说我们的程序不能使用了,知识不能使用资源，处于等待状态。 **4） 进程控制: **可以对进程组执行挂起、恢复等操作。 镜像是容器运行的核心，容器是镜像运行的后的实例。 DockerHub| registry ----&gt; pull image : save &gt; | load &lt; run ----&gt; Container ----&gt; commit* Dockerfile Docker 三剑客。 docker machine: 自动化部署多台dockerHost 。 Docker-compose: 它可以同时控制多个容器。 yaml。 **Docker Swarm: ** 从单个的服务向集群的形势发展。 高可用、高性能、高并发 : 为了防止单点故障。 Service: 服务 ----&gt; 包括运行什么服务，需要多个 rep1icas（副本）, 外网如何访问。 k8s 关闭防火墙、禁用selinux、修改主机名并加入域名解析、关闭swap 、时间同步、免密登录、打开iptables桥接 对硬件的基本要求: CPU: 2核 MEM: 2G 主机名: master node01 node02 时间必须同步 kubctl: k8s客户端 kubeadm: 工具 kubelet: 客户端代理 **组件: ** 三层网络: DockerHost &gt; Pod &gt; Service **Deployment: Service: ** **master组件: ** kube- api( application interface) k8s的前端接口 **Scheduler[集群分发调度器]**负责决定将Pod放在哪个Node上运行。在调度时，会充分考虑集群的拓扑结构，当前各个节点的负载情况，以及应对高可用、性能、数据亲和性和需求。 Controller Manager[内部管理控制中心]: 负责管理集群的各种资源，保证资源处于预期的状态。它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等。 **Etcd: **负责保存k8s集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速的通知k8s相关组件。[（第三方组件）它有可替换方案。Consul、zookeeper](https: //wsdlxgp.top/posts/1b18.html) **Flanner: **是k8s集群网络，可以保证Pod的跨主机通信。也有替换方案。 Node组件: Kubelet[节点上的Pod管家]: 它是Node的agent(代理)，当Scheduler确定某 个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet,kubelet会根据这些信息创建和运行容器，并向Master报告运行状态。 **kube-proxy[负载均衡、路由转发]: **负责将访问service的TCP/UDP数据流转发到后端的容器。如果有多个副本，kube-proxy会实现负载均衡。 yaml文件的一级字段: **VERSION: ** ​ **KIND: ** ​ **METADATA: ** ​ **SPEC : ** 12345678910111213141516[root@master ~]# vim web.yamlkind: Deployment #资源对象是控制器apiVersion: extensions/v1beta1 #api的版本metadata: #描述kind（资源类型） name: web #定义控制器名称 namespace: #名称空间spec: replicas: 2 #副本数量 template: #模板 metadata: labels: #标签 app: web_server spec: containers: #指定容器 - name: nginx #容器名称 image: nginx #使用的镜像 **Deployment（控制器): ** **ReplicationController: **用来确保由其管控的Pod对象副本数量，能够满足用户期望，多则删除，少则通过模本创建 **RS（RpelicaSet）: **RS也是用于保证与label selector匹配的pod数量维持在期望状态 **Service: ** type: 默认Cluster IP NodePort: 30000-32767 Deployment和Service关联: 标签和标签选择器 **Namespace: ** Pod: 最小单位 **镜像的下载策略: ** **Always: **镜像标签为“laster”或镜像不存在时，总是从指定的仓库中获取镜像。 **IfNotPresent: **仅当本地镜像不存在时才从目标仓库下载。 **Never: **禁止从仓库中下载镜像，即只使用本地镜像。 默认的标签 为latest: always **Pod的重启策略: ** **Always: **（默认情况下使用）但凡Pod对象终止就将其重启； ​ **OnFailure: **仅在Pod对象出现错误时才将其重启； ​ **Never: **从不重启； **Pod的健康检查: ** ​ Liveness: 探测失败重启pod ​ Readiness: 探测失败将pod设置为不可用 kubelet: 控制pod DaemonSet : 会在每一个节点都会运行，并且只运行一个Pod","path":"posts/fehv.html","date":"09-02","excerpt":"","tags":[{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"}]},{"title":"32 k8s的Job/CronJob资源对象及添加api版本","text":"Job资源对象 **服务类的Pod容器：**RC、RS、DS、Deployment **工作类的Pod容器：**Job—&gt;执行一次，或者批量执行处理程序，完成之后退出容器。 注意： 如果容器内执行任务有误，会根据容器的重启策略操作容器，不过这里 的容器重启策略只能是: Never和 OnFailure。 概念 在有些场景下，是想要运行一些容器执行某种特定的任务，任务一旦执行完成，容器也就没有存在的必要了。在这种场景下，创建pod就显得不那么合适。于是就是了Job，Job指的就是那些一次性任务。通过Job运行一个容器，当其任务执行完以后，就自动退出，集群也不再重新将其唤醒。 从程序的运行形态上来区分，可以将Pod分为两类：长时运行服务（jboss、mysql等）和一次性任务（数据计算、测试）。RC创建的Pod都是长时运行的服务，Job多用于执行一次性任务、批处理工作等，执行完成后便会停止（status.phase变为Succeeded）。 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 一、kubernetes支持以下几种job 非并行job：通常创建一个pod直至其成功结束。 固定结束次数的job：设置spec.completions,创建多个pod，直到.spec.completions个pod成功结束。 带有工作队列的并行job：设置.spec.Parallelism但不设置.spec.completions,当所有pod结束并且至少一个成功时，job就认为是成功。 Job Controller Job Controller负责根据Job Spec创建pod，并持续监控pod的状态，直至其成功结束，如果失败，则根据restartPolicy（只支持OnFailure和Never，不支持Always）决定是否创建新的pod再次重试任务。 例子 （1）编写一个job的yaml文件 123456789101112131415[root@master yaml]# vim jop.yamlkind: JobapiVersion: batch/v1metadata: name: test-jobspec: template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"echo\",\"hello k8s job!\"] restartPolicy: Never （2）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （3）查看一下 1[root@master yaml]# kubectl get pod 查看日志 1[root@master yaml]# kubectl logs test-job-gs45w 我们可以看到job与其他资源对象不同，仅执行一次性任务，默认pod借宿运行后job即结束，状态为Completed。 （4）修改一下jop的yaml文件，把echo命令换成乱码 123456789101112131415[root@master yaml]# vim jop.yamlkind: JobapiVersion: batch/v1metadata: name: test-jobspec: template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"asdasxsddwefew\",\"hello k8s job!\"] #修改 restartPolicy: Never （5）先删除之前的pod 1[root@master yaml]# kubectl delete jobs.batch test-job （6）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （7）查看一下 1[root@master yaml]# kubectl get pod -w 它会一直创建pod直到完成命令。 （8）修改一下jop的yaml文件，修改重启策略 123456789101112131415[root@master yaml]# vim jop.yaml kind: JobapiVersion: batch/v1metadata: name: test-jobspec: template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"asdasxsddwefew\",\"hello k8s job!\"] restartPolicy: OnFailure （9）先删除之前的pod 1[root@master yaml]# kubectl delete jobs.batch test-job （10）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （11）查看一下 1[root@master yaml]# kubectl get pod -w 它会一直重启pod完成命令，直到重启到一定次数就会删除job。 二、提高Job的执行效率 1. 我们可以在Job.spec字段下加上parallelism选项。表示同时运行多少个Pod执行任务。 （1）编写一个job的yaml文件 12345678910111213141516[root@master yaml]# vim jop.yamlkind: JobapiVersion: batch/v1metadata: name: test-jobspec: parallelism: 2 #同时启用几个pod template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"echo\",\"hello k8s job!\"] restartPolicy: OnFailure （3）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod 查看日志 2. 我们可以在Job.spec字段下加上complations选项。表示总共需要完成Pod的数量 （1）编写一个job的yaml文件 1234567891011121314151617[root@master yaml]# vim jop.yamlkind: JobapiVersion: batch/v1metadata: name: test-jobspec: complations: 8 #运行pod的总数量8个 parallelism: 2 #同时运行2个pod template: metadata: name: test-job spec: containers: - name: hello image: busybox command: [\"echo\",\"hello k8s job!\"] restartPolicy: OnFailure job 字段解释： 标志Job结束需要成功运行的Pod个数，默认为1 parallelism：标志并行运行的Pod的个数，默认为1 activeDeadlineSeconds：标志失败Pod的重试最大时间，超过这个时间不会继续重试. （2）先删除之前的pod 1[root@master yaml]# kubectl delete jobs.batch test-job （3）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod 可以看到pod是两个两个的启动的。 3. 如何定时执行Job （1）编写一个cronjob的yaml文件 12345678910111213141516[root@master yaml]# vim cronjop.yamlkind: CronJobapiVersion: batch/v1beta1metadata: name: hellospec: schedule: \"*/1 * * * *\" #限定时间 jobTemplate: spec: template: spec: containers: - name: hello image: busybox command: [\"echo\",\"hello\",\"cronjob\"] restartPolicy: OnFailure （2）先删除之前的pod 1[root@master yaml]# kubectl delete jobs.batch test-job （3）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod 1[root@master yaml]# kubectl get cronjobs.batch 此时查看Pod的状态，会发现，每分钟都会运行一个新的Pod来执行命令规定的任 务。 练习：规定2020.1.15.10.5分运行上面的crontab任务。 （1）编写一个cronjob的yaml文件 12345678910111213141516[root@master yaml]# vim cronjop.yamlkind: CronJobapiVersion: batch/v1beta1metadata: name: hellospec: schedule: \"5 10 15 1 *\" #限定时间 jobTemplate: spec: template: spec: containers: - name: hello image: busybox command: [\"echo\",\"hello\",\"cronjob\"] restartPolicy: OnFailure （2）先删除之前的pod 1[root@master yaml]# kubectl delete cronjobs.batch hello （3）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod 这时会发现，如果规定具体时间，可能并不会执行任务。 （5）添加apiVersion库 123456[root@master yaml]# vim /etc/kubernetes/manifests/kube-apiserver.yaml spec: containers: - command: - kube-apiserver - --runtime-config=batch/v2alpha1=true #添加 （6）重启kubelet 1[root@master yaml]# systemctl restart kubelet.service （7）查看api版本 1[root@master yaml]# kubectl api-versions （8）编写一个cronjob的yaml文件 12345678910111213141516[root@master yaml]# vim cronjop.yamlkind: CronJobapiVersion: batch/v1beta1metadata: name: hellospec: schedule: \"47 10 15 1 *\" #限定时间 jobTemplate: spec: template: spec: containers: - name: hello image: busybox command: [\"echo\",\"hello\",\"cronjob\"] restartPolicy: OnFailure （9）执行一下 1[root@master yaml]# kubectl apply -f jop.yaml （4）查看一下 1[root@master yaml]# kubectl get pod -w 注意：此时仍然不能正常运行指定时间的Job，这是因为K8s官方在cronjob这个资源对象的支持中还没有完善此功能，还待开发。 跟Job资源一样在cronjob.spec.jobTemplate.spec 下同样支持并发Job参数: parallelism，也支持完成Pod的总数参数: completionsr 总结 Job 作为 Kubernetes 中用于处理任务的资源，与其他的资源没有太多的区别，它也使用 Kubernetes 中常见的控制器模式，监听 Informer 中的事件并运行 syncHandler 同步任务 而 CronJob 由于其功能的特殊性，每隔 10s 会从 apiserver 中取出资源并进行检查是否应该触发调度创建新的资源，需要注意的是 CronJob 并不能保证在准确的目标时间执行，执行会有一定程度的滞后。 两个控制器的实现都比较清晰，只是边界条件比较多，分析其实现原理时一定要多注意。","path":"posts/fbf7.html","date":"09-01","excerpt":"","tags":[{"name":"Job","slug":"Job","permalink":"https://wsdlxgp.top/tags/Job/"},{"name":"apiVersion","slug":"apiVersion","permalink":"https://wsdlxgp.top/tags/apiVersion/"},{"name":"CronJob","slug":"CronJob","permalink":"https://wsdlxgp.top/tags/CronJob/"}]},{"title":"31 k8s的ReplicaSet，DaemonSet及标签","text":"环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 ReplicaSet简单介绍 1. RC：ReplicationController（老一代的pod控制器） 用来确保由其管控的Pod对象副本数量，能够满足用户期望，多则删除，少则通过模本创建 特点： 确保Pod资源对象的数量精准。 确保pod健康运行。 弹性伸缩 同样，它也可以通过yaml或json格式的资源清单来创建。其中spec字段一般嵌套以下字段： replicas：期望的Pod对象副本数量。 selector：当前控制器匹配Pod对此项副本的标签选择器 template：pod副本的模板 与RC相比而言，RS不仅支持*基于等值*的标签选择器，而且还支持*基于集合*的标签选择器。 2. 标签：解决同类型的资源对象，为了更好的管理，按照标签分组。 常用的标签分类： release（版本）：stable（稳定版）、canary（金丝雀版本）、beta（测试版本） environment（环境变量）：dev（开发）、qa（测试）、production（生产） application（应用）：ui、as（application software应用软件）、pc、sc tier（架构层级）：frontend（前端）、backend（后端）、cache（缓存） partition（分区）：customerA（客户A）、customerB（客户B） track（品控级别）：daily（每天）、weekly（每周） 标签要做到：见名知意。 3.测试 （1）编写一个pod的yaml文件 12345678910111213[root@master ~]# vim label.yaml kind: PodapiVersion: v1metadata: name: labels labels: env: qa tier: frontendspec: containers: - name: myapp image: httpd &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f label.yaml --record &lt;2&gt;查看一下 12[root@master ~]# kubectl get pod --show-labels //通过--show-labels显示资源对象的 12[root@master ~]# kubectl get po -L env,tier//显示某个键对应的值 12[root@master ~]# kubectl get po -l env,tier//通过-l 查看仅包含某个标签的资源。 （2）添加标签 12[root@master ~]# kubectl label pod labels app=pc//给pod资源添加标签 （3）修改标签 1234[root@master ~]# kubectl label pod labels env=dev --overwrite//修改标签[root@master ~]# kubectl get pod -l tier --show-labels //查看标签 （4）编写一个service的yaml文件 1234567891011121314[root@master ~]# vim service.yamlkind: ServiceapiVersion: v1metadata: name: servicespec: type: NodePort selector: env: qa ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30123 &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f service.yaml &lt;2&gt;查看一下 1[root@master ~]# kubectl describe svc &lt;3&gt;访问一下 1[root@master ~]# curl 127.0.0.1:30123 如果标签有多个，标签选择器选择其中一个，也可以关联成功。相反，如果选择器有多个，那么标签必须完全满足条件，才可以关联成功。 4. 标签选择器：标签的查询过滤条件。 基于等值关系的（equality-based）：“=”，“==”，“！ =”前面两个都是相等，最后一个是不等于。 基于集合关系（set-based）:in、notin、exists三种。选择器列表间为“逻辑与”关系，使用ln或者NotIn操作时，其valuas不强制要求为非空的字符串列表，而使用Exists或DostNotExist时，其values必须为空 使用标签选择器的逻辑： 同时指定的多个选择器之间的逻辑关系为“与”操作。 使用空值的标签选择器意味着每个资源对象都将把选中。 空的标签选择器无法选中任何资源。 （1）例子 编写一个selector的yaml’文件 1234567[root@master ~]# vim selector.yamlselector: matchLabels: app: nginx mathExpressions: - &#123;key: name,operator: In,values: [zhangsan,lisi]&#125; - &#123;key: age,operator: Exists,values:&#125; selector：当前控制器匹配Pod对此项副本的标签选择器 matchLabels: 指定键值对表示的标签选择器。 mathExpressions:：基于表达式来指定的标签选择器。 DaemonSet 它也是一种pod控制器。 RC，RS , deployment , daemonset.都是pod控制器。statfukSet，RBAC 1. 使用场景： 如果必须将pod运行在固定的某个或某几个节点，且要优先于其他的pod的启动。通常情况下，默认会将每一个节点都运行，并且只能运行一个pod。这种情况推荐使用DeamonSet资源对象。 监控程序； 日志收集程序； 集群存储程序； 12[root@master ~]# kubectl get ds -n kube-system //查看一下DaemonSet 2. DaemonSet 与 Deployment 的区别 Deployment 部署的副本 Pod 会分布在各个 Node 上，每个 Node 都可能运行好几个副本。 DaemonSet 的不同之处在于：每个 Node 上最多只能运行一个副本。 3. 运行一个web服务，在每一个节点运行一个pod。 123456789101112131415[root@master ~]# vim daemonset.yamlkind: DaemonSetapiVersion: extensions/v1beta1metadata: name: test-dsspec: template: metadata: labels: name: test-ds spec: containers: - name: test-ds image: httpd &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f daemonset.yaml &lt;2&gt;查看一下 1[root@master ~]# kubectl get ds 总结 1）总结RC、RS、Deplyment、DaemonSet控制器的特点及使用场景。 &lt;1&gt;Replication Controller（RC） 介绍及使用场景 Replication Controller简称RC，RC是Kubernetes系统中的核心概念之一，简单来说，RC可以保证在任意时间运行Pod的副本数量，能够保证Pod总是可用的。如果实际Pod数量比指定的多那就结束掉多余的，如果实际数量比指定的少就新启动一些Pod，当Pod失败、被删除或者挂掉后，RC都会去自动创建新的Pod来保证副本数量，所以即使只有一个Pod，我们也应该使用RC来管理我们的Pod。 主要功能 确保pod数量：RC用来管理正常运行Pod数量，一个RC可以由一个或多个Pod组成，在RC被创建后，系统会根据定义好的副本数来创建Pod数量。在运行过程中，如果Pod数量小于定义的，就会重启停止的或重新分配Pod，反之则杀死多余的。 确保pod健康：当pod不健康，运行出错或者无法提供服务时，RC也会杀死不健康的pod，重新创建新的。 弹性伸缩 ：在业务高峰或者低峰期的时候，可以通过RC动态的调整pod的数量来提高资源的利用率。同时，配置相应的监控功能（Hroizontal Pod Autoscaler），会定时自动从监控平台获取RC关联pod的整体资源使用情况，做到自动伸缩。 滚动升级：滚动升级为一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定，在初始化升级的时候就可以及时发现和解决问题，避免问题不断扩大。 &lt;2&gt;Replication Set（RS） 被认为 是“升级版”的RC。RS也是用于保证与label selector匹配的pod数量维持在期望状态。 实际上RS和RC的功能基本一致，目前唯一的一个区别就是RC只支持基于等式的selector（env=dev或app=nginx），但RS还支持基于集合的selector（version in (v1, v2)），这对复杂的运维管理就非常方便了。 kubectl命令行工具中关于RC的大部分命令同样适用于我们的RS资源对象。不过我们也很少会去单独使用RS，它主要被Deployment这个更加高层的资源对象使用，除非用户需要自定义升级功能或根本不需要升级Pod，在一般情况下，我们推荐使用Deployment而不直接使用Replica Set。 区别在于 1、RC只支持基于等式的selector（env=dev或environment!=qa），但RS还支持新的，基于集合的selector（version in (v1.0, v2.0)或env notin (dev, qa)），这对复杂的运维管理很方便。 2、升级方式 RS不能使用kubectlrolling-update进行升级 kubectl rolling-update专用于rc RS升级使用deployment或者kubectl replace命令 社区引入这一API的初衷是用于取代vl中的RC，也就是说当v1版本被废弃时，RC就完成了它的历史使命，而由RS来接管其工作 &lt;3&gt;DaemonSet 1. 特点： 如果必须将pod运行在固定的某个或某几个节点，且要优先于其他的pod的启动。通常情况下，默认会将每一个节点都运行，并且只能运行一个pod。这种情况推荐使用DeamonSet资源对象。 一个DaemonSet对象能确保其创建的Pod在集群中的每一台（或指定）Node上都运行一个副本。如果集群中动态加入了新的Node，DaemonSet中的Pod也会被添加在新加入Node上运行。删除一个DaemonSet也会级联删除所有其创建的Pod。 2. 使用环境 监控程序； 日志收集程序； 集群存储程序； &lt;4&gt;Deployment 1. 什么是Deployment Kubernetes Deployment提供了官方的用于更新Pod和Replica Set（下一代的Replication Controller）的方法，您可以在Deployment对象中只描述您所期望的理想状态（预期的运行状态），Deployment控制器为您将现在的实际状态转换成您期望的状态，例如，您想将所有的webapp:v1.0.9升级成webapp:v1.1.0，您只需创建一个Deployment，Kubernetes会按照Deployment自动进行升级。现在，您可以通过Deployment来创建新的资源（pod，rs，rc），替换已经存在的资源等。 你只需要在Deployment中描述你想要的目标状态是什么，Deployment controller就会帮你将Pod和Replica Set的实际状态改变到你的目标状态。你可以定义一个全新的Deployment，也可以创建一个新的替换旧的Deployment。 2. 典型的用例 使用Deployment来创建ReplicaSet。ReplicaSet在后台创建pod。检查启动状态，看它是成功还是失败。 然后，通过更新Deployment的PodTemplateSpec字段来声明Pod的新状态。这会创建一个新的ReplicaSet，Deployment会按照控制的速率将pod从旧的ReplicaSet移动到新的ReplicaSet中。 如果当前状态不稳定，回滚到之前的Deployment revision。每次回滚都会更新Deployment的revision。 扩容Deployment以满足更高的负载。 暂停Deployment来应用PodTemplateSpec的多个修复，然后恢复上线。 根据Deployment 的状态判断上线是否hang住了。 清除旧的不必要的ReplicaSet。 3. 使用环境 Deployment集成了上线部署、滚动升级、创建副本、暂停上线任务，恢复上线任务，回滚到以前某一版本（成功/稳定）的Deployment等功能，在某种程度上，Deployment可以帮我们实现无人值守的上线，大大降低我们的上线过程的复杂沟通、操作风险。 定义Deployment来创建Pod和ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和继续Deployment 3. DaemonSet 与 Deployment 的区别 Deployment 部署的副本 Pod 会分布在各个 Node 上，每个 Node 都可能运行好几个副本。 DaemonSet 的不同之处在于：每个 Node 上最多只能运行一个副本。 2）使用DaemonSet控制器运行httpd服务，要求名称以自己的名称命名。标签为：tier=backend,env=dev. 123456789101112131415[root@master ~]# vim daemonset.yaml kind: DaemonSetapiVersion: extensions/v1beta1metadata: name: xgp-dsspec: template: metadata: labels: tier: backend env: dev spec: containers: - name: xgp-ds image: httpd 查看一下 1[root@master ~]# kubectl get pod --show-labels 1[root@master ~]# kubectl get pod -L env,tier 3) 创建service资源对象与上述资源进行关联，要有验证。 1234567891011121314[root@master ~]# vim service.yaml kind: ServiceapiVersion: v1metadata: name: servicespec: type: NodePort selector: env: dev ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30123 执行一下 1[root@master ~]# kubectl apply -f service.yaml 查看一下 1[root@master ~]# kubectl describe svc 访问一下 1[root@master ~]# curl 127.0.0.1:30123 4）整理关于标签和标签选择器都有什么作用？ &lt;1&gt;标签：解决同类型的资源对象，为了更好的管理，按照标签分组。 &lt;2&gt;标签选择器：标签的查询过滤条件。","path":"posts/5281.html","date":"08-31","excerpt":"","tags":[{"name":"Replica","slug":"Replica","permalink":"https://wsdlxgp.top/tags/Replica/"},{"name":"SetDaemonSet","slug":"SetDaemonSet","permalink":"https://wsdlxgp.top/tags/SetDaemonSet/"},{"name":"标签","slug":"标签","permalink":"https://wsdlxgp.top/tags/%E6%A0%87%E7%AD%BE/"}]},{"title":"30 pod健康检查详解（liveness，readiness，滚动更新）","text":"环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s+httpd+nginx node01 192.168.1.22 k8s node02 192.168.1.23 k8s 基于 https://blog.51cto.com/14320361/2464655 的实验继续进行 一、Pod的liveness和readiness探针 Kubelet使用liveness probe（存活探针）来确定何时重启容器。例如，当应用程序处于运行状态但无法做进一步操作，liveness探针将捕获到deadlock，重启处于该状态下的容器，使应用程序在存在bug的情况下依然能够继续运行下去 Kubelet使用readiness probe（就绪探针）来确定容器是否已经就绪可以接受流量。只有当Pod中的容器都处于就绪状态时kubelet才会认定该Pod处于就绪状态。该信号的作用是控制哪些Pod应该作为service的后端。如果Pod处于非就绪状态，那么它们将会被从service的load balancer中移除。 Probe支持以下三种检查方法： &lt;1&gt;exec-命令 在用户容器内执行一次命令，如果命令执行的退出码为0，则认为应用程序正常运行，其他任务应用程序运行不正常。 12345livenessProbe: exec: command: - cat - /home/laizy/test/hostpath/healthy &lt;2&gt;TCPSocket 将会尝试打开一个用户容器的Socket连接（就是IP地址：端口）。如果能够建立这条连接，则认为应用程序正常运行，否则认为应用程序运行不正常。 123livenessProbe:tcpSocket: port: 8080 &lt;3&gt;HTTPGet 调用容器内Web应用的web hook，如果返回的HTTP状态码在200和399之间，则认为应用程序正常运行，否则认为应用程序运行不正常。每进行一次HTTP健康检查都会访问一次指定的URL。 123456httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常 path: / #URI地址 port: 80 #端口号 #host: 127.0.0.1 httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常 path: / #URI地址 port: 80 #端口号 #host: 127.0.0.1 #主机地址 scheme: HTTP #支持的协议，http或者httpshttpHeaders：’’ #自定义请求的header 参数说明 **initialDelaySeconds：**容器启动后第一次执行探测是需要等待多少秒。 **periodSeconds：**执行探测的频率。默认是10秒，最小1秒。 **timeoutSeconds：**探测超时时间。默认1秒，最小1秒。 **successThreshold：**探测失败后，最少连续探测成功多少次才被认定为成功。默认是1。对于liveness必须是1。最小值是1。 探针探测的结果有以下三者之一： Success：Container通过了检查。 Failure：Container未通过检查。 Unknown：未能执行检查，因此不采取任何措施。 1. LivenessProbe（活跃度） （1）编写一个livenss的yaml文件 1234567891011121314151617181920212223[root@node02 ~]# vim livenss.yamlkind: PodapiVersion: v1metadata: name: liveness labels: test: livenessspec: restartPolicy: OnFailure containers: - name: liveness image: busybox args: - /bin/sh - -c - touch /tmp/test; sleep 60; rm -rf /tmp/test; sleep 300 livenessProbe: #存活探测 exec: #通过执行命令来检查服务是否正常 command: #命令模式 - cat - /tmp/test initialDelaySeconds: 10 #pod运行10秒后开始探测 periodSeconds: 5 #检查的频率，每5秒探测一次 该配置文件给Pod配置了一个容器。periodSeconds 规定kubelet要每隔5秒执行一次liveness probe。initialDelaySeconds 告诉kubelet在第一次执行probe之前要的等待10秒钟。探针检测命令是在容器中执行 cat /tmp/healthy 命令。如果命令执行成功，将返回0，kubelet就会认为该容器是活着的并且很健康。如果返回非0值，kubelet就会杀掉这个容器并重启它。 （2）运行一下 1[root@master ~]# kubectl apply -f liveness.yaml （3）查看一下 1[root@master ~]# kubectl get pod -w Liveness活跃度探测，根据探测某个文件是否存在，来确定某个服务是否正常运行，如果存在则正常，负责，它会根据你设置的Pod的重启策略操作Pod。 2. Readiness（敏感探测、就绪性探测） ReadinessProbe探针的使用场景livenessProbe稍有不同，有的时候应用程序可能暂时无法接受请求，比如Pod已经Running了，但是容器内应用程序尚未启动成功，在这种情况下，如果没有ReadinessProbe，则Kubernetes认为它可以处理请求了，然而此时，我们知道程序还没启动成功是不能接收用户请求的，所以不希望kubernetes把请求调度给它，则使用ReadinessProbe探针。 ReadinessProbe和livenessProbe可以使用相同探测方式，只是对Pod的处置方式不同，ReadinessProbe是将Pod IP:Port从对应的EndPoint列表中删除，而livenessProbe则Kill容器并根据Pod的重启策略来决定作出对应的措施。 ReadinessProbe探针探测容器是否已准备就绪，如果未准备就绪则kubernetes不会将流量转发给此Pod。 ReadinessProbe探针与livenessProbe一样也支持exec、httpGet、TCP的探测方式，配置方式相同，只不过是将livenessProbe字段修改为ReadinessProbe。 （1）编写一个readiness的yaml文件 1234567891011121314151617181920212223[root@master ~]# vim readiness.yaml kind: PodapiVersion: v1metadata: name: readiness labels: test: readinessspec: restartPolicy: Never containers: - name: readiness image: busybox args: - /bin/sh - -c - touch /tmp/test; sleep 60; rm -rf /tmp/test; sleep 300 readinessProbe: exec: command: - cat - /tmp/test initialDelaySeconds: 10 periodSeconds: 5 （2）运行一下 1[root@master ~]# kubectl apply -f readiness.yaml （3）查看一下 1[root@master ~]# kubectl get pod -w 3. 总结liveness和readiness探测 （1）liveness和readiness是两种健康检查机制，k8s将两种探测采取相同的默认行为，即通过判断容器启动进程的返回值是否为零，来判断探测是否成功。 （2）两种探测配置方法完全一样，不同之处在于探测失败后的行为。 liveness探测是根据重启策略操作容器，大多数是重启容器。 readiness则是将容器设置为不可用，不接收Service转发的请求。 （3）两种探测方法可建议独立存在，也可以同时存在。用livensess判断是否需要重启，实现自愈；用readiness判断容器是否已经准备好对外提供服务。 二、 检测的应用 1. 在scale(扩容/缩容) 中的应用。 （1）编写一个readiness的yaml文件 123456789101112131415161718192021222324252627282930313233343536373839[root@master ~]# vim hcscal.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: webspec: replicas: 3 template: metadata: labels: run: web spec: containers: - name: web image: httpd ports: - containerPort: 80 readinessProbe: httpGet: scheme: HTTP #探测的协议 path: /healthy #访问的目录 port: 80 initialDelaySeconds: 10 periodSeconds: 5---kind: ServiceapiVersion: v1metadata: name: web-svcspec: type: NodePort selector: run: web ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30321 在配置文件中，使用httpd镜像，创建出一个Pod，其中periodSeconds字段指定kubelet每5秒执行一次探测，initialDelaySeconds字段告诉kubelet延迟等待10秒，探测方式为向容器中运行的服务发送HTTP GET请求，请求8080端口下的/healthz, 任何大于或等于200且小于400的代码表示成功。任何其他代码表示失败。 httpGet探测方式有如下可选的控制字段 host：要连接的主机名，默认为Pod IP，可以在http request head中设置host头部。 scheme: 用于连接host的协议，默认为HTTP。 path：http服务器上的访问URI。 httpHeaders：自定义HTTP请求headers，HTTP允许重复headers。 port： 容器上要访问端口号或名称。 （2）运行一下 1[root@master ~]# kubectl apply -f readiness.yaml （3）查看一下 1[root@master ~]# kubectl get pod -w 1[root@master ~]# kubectl get pod -o wide 1[root@master ~]# kubectl get service -o wide （4）访问一下 1[root@master ~]# curl 10.244.1.21/healthy （5）pod在指定目录创建一个文件 1[root@master ~]# kubectl exec web-69d659f974-7s9bc touch /usr/local/apache2/htdocs/healthy （6）查看一下 1[root@master ~]# kubectl get pod -w 2. 在更新过程中的使用 （1）编写一个readiness的yaml文件 1234567891011121314151617181920212223242526[root@master ~]# vim app.v1.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: appspec: replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - /bin/sh - -c - sleep 10; touch /tmp/healthy; sleep 3000 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 10 periodSeconds: 5 （2）运行一下并记录版本信息 1[root@master ~]# kubectl apply -f readiness.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment app （3）查看一下 1[root@master ~]# kubectl get pod -w 3.升级一下Deployment （1）编写一个readiness的yaml文件 12345678910111213141516171819202122232425262728[root@master ~]# cp app.v1.yaml app.v2.yaml[root@master ~]# vim app.v2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: appspec: replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - /bin/sh - -c - sleep 3000 #修改命令 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 10 periodSeconds: 5 （2）运行一下并记录版本信息 1[root@master ~]# kubectl apply -f readiness.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment app （3）查看一下 1[root@master ~]# kubectl get pod -w （4）再次升级一下deployment &lt;1&gt; 编写一个readiness的yaml文件 123456789101112131415161718192021[root@master ~]# cp app.v1.yaml app.v3.yaml[root@master ~]# vim app.v2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: appspec: replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - /bin/sh - -c - sleep 3000 #修改命令 &lt;2&gt; 运行一下并记录版本信息 1[root@master ~]# kubectl apply -f readiness.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment app &lt;3&gt; 查看一下 1[root@master ~]# kubectl get pod -w 4. 回滚v2版本 1[root@master ~]# kubectl rollout undo deployment app --to-revision=2 查看一下 1[root@master ~]# kubectl get pod （1）编写一个readiness的yaml文件 123456789101112131415161718192021222324252627282930[root@master ~]# vim app.v2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: appspec: strategy: rollingUpdate: maxSurge: 2 maxUnavailable: 2 replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - /bin/sh - -c - sleep 3000 readinessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 10 periodSeconds: 5 maxSurge：此参数控制滚动更新过程中，副本总数超过预期数的值。可以是整数，也可以是百分比，默认是1。 maxUnavailable：不可用pod的值，默认为1，可以是整数，也可以是百分比。 参数介绍 minReadySeconds: Kubernetes在等待设置的时间后才进行升级 如果没有设置该值，Kubernetes会假设该容器启动起来后就提供服务了 如果没有设置该值，在某些极端情况下可能会造成服务服务正常运行 maxSurge: 升级过程中最多可以比原先设置多出的POD数量 例如：maxSurage=1，replicas=5,则表示Kubernetes会先启动1一个新的Pod后才删掉一个旧的POD，整个升级过程中最多会有5+1个POD。 maxUnavaible: 升级过程中最多有多少个POD处于无法提供服务的状态 当maxSurge不为0时，该值也不能为0 例如：maxUnavaible=1，则表示Kubernetes整个升级过程中最多会有1个POD处于无法服务的状态 （2） 运行一下并记录版本信息 1[root@master ~]# kubectl apply -f app.v2.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment app （3） 查看一下 1[root@master ~]# kubectl get pod -w 三、小实验 1）写一个Deployment资源对象，要求2个副本，nginx镜像。使用Readiness探测，自定义文件/test是否存在，容器开启之后10秒开始探测，时间间隔为10秒。 （1）编写一个readiness的yaml文件 1234567891011121314151617181920212223[root@master yaml]# vim nginx.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: webspec: replicas: 2 template: metadata: labels: run: web spec: containers: - name: readiness image: 192.168.1.21:5000/nginx:v1 readinessProbe: exec: command: - cat - /usr/share/nginx/html/test initialDelaySeconds: 10 periodSeconds: 10 （2）运行一下并记录版本信息 1[root@master ~]# kubectl apply -f nginx.yaml --record 查看一下 1[root@master ~]# kubectl rollout history deployment web （3）查看一下 1[root@master ~]# kubectl get pod -w 2）在运行之后两个Pod里，进入一个Pod，创建文件/test。 12[root@master yaml]# kubectl exec -it web-864c7cf7fc-gpxq4 /bin/bashroot@web-68444bff8-xm22z:/# touch /usr/share/nginx/html/test 查看一下 1[root@master yaml]# kubectl get pod -w 3）创建一个Service资源对象，跟上述Deployment进行关联，运行之后，查看Service资源详细信息，确认EndPoint负载均衡后端Pod。 （1）编写service的yaml文件 1234567891011121314[root@master yaml]# vim nginx-svc.yamlkind: ServiceapiVersion: v1metadata: name: web-svcspec: type: NodePort selector: run: web ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30321 （2）执行一下 1[root@master yaml]# kubectl apply -f nginx-svc.yaml （3）给两个pod刚更改页面 查看一下pod 1[root@master yaml]# kubectl get pod -o wide 更改页面 1234567[root@master yaml]# kubectl exec -it web-864c7cf7fc-gpxq4 /bin/bashroot@web-864c7cf7fc-gpxq4:/# echo \"123\">/usr/share/nginx/html/testroot@web-864c7cf7fc-gpxq4:/# exit[root@master yaml]# kubectl exec -it web-864c7cf7fc-pcrs9 /bin/bashroot@web-864c7cf7fc-pcrs9:/# echo \"321\">/usr/share/nginx/html/testroot@web-864c7cf7fc-pcrs9:/# exit 4）观察状态之后，尝试将另一个Pod也写入/test文件，然后再去查看SVC对应的EndPoint的负载均衡情况。 （1）查看一下service 1[root@master yaml]# kubectl get service （2）访问一下 1[root@master ~]# curl 192.168.1.21:30321/test 5）通过httpGet的探测方式，重新运行一下deployment资源，总结对比一下这两种Readiness探测方式。 （1）修改deployment的yaml文件 12345678910111213141516171819202122[root@master yaml]# vim nginx.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: webspec: replicas: 2 template: metadata: labels: run: web spec: containers: - name: readiness image: 192.168.1.21:5000/nginx:v1 readinessProbe: httpGet: scheme: HTTP path: /usr/share/nginx/html/test port: 80 initialDelaySeconds: 10 periodSeconds: 10 （2）执行一下 1[root@master yaml]# kubectl apply -f nginx.yaml （3）查看一下pod 1[root@master yaml]# kubectl get pod -w maxSurge：此参数控制滚动更新过程中，副本总数超过预期数的值。可以是整数，也可以是百分比，默认是1。所以现在是3台pod （4）访问一下 1[root@master yaml]# curl 192.168.1.21:30321/test 6）总结对比liveness和readiness探测的相同和不同之处，以及它们的使用场景。 &lt;1&gt;readiness和liveness的核心区别 实际上readiness 和liveness 就如同字面意思。readiness 就是意思是否可以访问，liveness就是是否存活。如果一个readiness 为fail 的后果是把这个pod 的所有service 的endpoint里面的改pod ip 删掉，意思就这个pod对应的所有service都不会把请求转到这pod来了。但是如果liveness 检查结果是fail就会直接kill container，当然如果你的restart policy 是always 会重启pod。 &lt;2&gt;什么样才叫readiness／liveness检测失败呢? 实际上k8s提供了3中检测手段， http get 返回200-400算成功，别的算失败 tcp socket 你指定的tcp端口打开，比如能telnet 上 cmd exec 在容器中执行一个命令 推出返回0 算成功。 每中方式都可以定义在readiness 或者liveness 中。比如定义readiness 中http get 就是意思说如果我定义的这个path的http get 请求返回200-400以外的http code 就把我从所有有我的服务里面删了吧，如果定义在liveness里面就是把我kill 了。 &lt;3&gt;readiness和readiness的使用环境 比如如果一个http 服务你想一旦它访问有问题我就想重启容器。那你就定义个liveness 检测手段是http get。反之如果有问题我不想让它重启，只是想把它除名不要让请求到它这里来。就配置readiness。 注意，liveness不会重启pod，pod是否会重启由你的restart policy（重启策略）控制。 参考： https://www.jianshu.com/p/16a375199cf2","path":"posts/af5b.html","date":"08-30","excerpt":"","tags":[{"name":"liveness","slug":"liveness","permalink":"https://wsdlxgp.top/tags/liveness/"},{"name":"readiness","slug":"readiness","permalink":"https://wsdlxgp.top/tags/readiness/"},{"name":"滚动更新","slug":"滚动更新","permalink":"https://wsdlxgp.top/tags/%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0/"}]},{"title":"29 k8s中pod的资源对象（名称空间，获取策略，重启策略，健康检查）","text":"一，k8s的资源对象 Deployment、Service、Pod是k8s最核心的3个资源对象 **Deployment：**最常见的无状态应用的控制器，支持应用的扩缩容、滚动升级等操作。 **Service：**为弹性变动且存在生命周期的Pod对象提供了一个固定的访问接口，用于服务发现和服务访问。 **Pod：**是运行容器以及调度的最小单位。同一个pod可以同时运行多个容器，这些容器共享net、UTS、IPC，除此之外还有USER、PID、MOUNT。 **ReplicationController：**用于确保每个Pod副本在任意时刻都能满足目标数量，简单来说，它用于每个容器或容器组总是运行并且可以访问的：老一代无状态的Pod应用控制器。 **RwplicatSet：**新一代的无状态的Pod应用控制器，它与RC的不同之处在于支持的标签选择器不同，RC只支持等值选择器（键值对），RS还额外支持基于集合的选择器。 **StatefulSet：**用于管理有状态的持久化应用，如database服务程序，它与Deployment不同之处在于，它会为每一个pod创建一个独有的持久性标识符，并确保每个pod之间的顺序性。 **DaemonSet：**用于确保每一个节点都运行了某个pod的一个副本，新增的节点一样会被添加到此类pod，在节点移除时，此pod会被回收。 **Job：**用于管理运行完成后即可终止的应用，例如批量处理做作业任务； **volume：**pv pvc ConfigMap： Secret： Role： ClusterRole： RoleBinding： cluster RoleBinding： service account： Helm： Pod的生命周期被定义为以下几个阶段。 Pending：Pod已经被创建，但是一个或者多个容器还未创建，这包括Pod调度阶段，以及容器镜像的下载过程。 Running：Pod已经被调度到Node，所有容器已经创建，并且至少一个容器在运行或者正在重启。 Succeeded：Pod中所有容器正常退出。 Failed：Pod中所有容器退出，至少有一个容器是一次退出的。 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 二，Namespace：名称空间 默认的名称空间： Namespace（命名空间）是kubernetes系统中的另一个重要的概念，通过将系统内部的对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理。 Kubernetes集群在启动后，会创建一个名为“default”的Namespace，如果不特别指明Namespace，则用户创建的Pod、RC、Service都被系统创建到“default”的Namespace中。 1.查看名称空间 1[root@master ~]# kubectl get namespaces 2.查看名称空间详细信息 1[root@master ~]# kubectl describe ns default 3.创建名称空间 1[root@master ~]# kubectl create ns bdqn 查看一下 1[root@master ~]# kubectl get namespaces 4.创建namespace的yaml文件 （1）查看格式 12[root@master ~]# kubectl explain ns//查看nasespace的yaml文件的格式 （2）创建namespace的yaml文件 12345[root@master ~]# vim test-ns.yamlapiVersion: v1kind: Namespacemetadata: name: test （3）运行namespace的yaml文件 1[root@master ~]# kubectl apply -f test-ns.yaml （4）查看一下 1[root@master ~]# kubectl get ns 4.删除名称空间 12[root@master ~]# kubectl delete ns test [root@master ~]# kubectl delete -f test-ns.yaml 注意：namespace资源对象进用于资源对象的隔离，并不能隔绝不同名称空间的Pod之间的通信。那是网络策略资源的功能。 5.查看指定名称空间 可使用–namespace或-n选项 12[root@master ~]# kubectl get pod -n kube-system [root@master ~]# kubectl get pod --namespace kube-system 三，Pod 1.编写一个pod的yaml文件 123456789[root@master ~]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-podspec: containers: - name: test-app image: 192.168.1.21:5000/web:v1 pod的yaml文件不支持replicas字段 （1）运行一下 1[root@master ~]# kubectl apply -f pod.yaml （2）查看一下 1[root@master ~]# kubectl get pod ps：这个pod因为是自己创建的，所以删除之后k8s并不会自动生成，相当于docker中创建 2.指定pod的namespace名称空间 （1）修改pod的yaml文件 12345678910[root@master ~]# vim pod.yamlkind: Pod #资源类型apiVersion: v1 #api版本metadata: name: test-pod #指定控制器名称 namespace: bdqn #指定namespace（名称空间）spec: containers: #容器 - name: test-app #容器名称 image: 192.168.1.21:5000/web:v1 #镜像 执行一下 1[root@master ~]# kubectl apply -f pod.yaml （2）查看一下 12[root@master ~]# kubectl get pod -n bdqn //根据namespace名称查看 3.pod中镜像获取策略 **Always：**镜像标签为“laster”或镜像不存在时，总是从指定的仓库中获取镜像。 **IfNotPresent：**仅当本地镜像不存在时才从目标仓库下载。 **Never：**禁止从仓库中下载镜像，即只使用本地镜像。 注意：对于标签为“laster”或者标签不存在，其默认的镜像下载策略为“Always”，而对于其他的标签镜像，默认策略为“IfNotPresent”。 4.观察pod和service的不同并关联 （1）pod的yaml文件（指定端口） 1234567891011121314[root@master ~]# vim pod.yaml kind: Pod #资源类型apiVersion: v1 #api版本metadata: name: test-pod #指定控制器名称 namespace: bdqn #指定namespace（名称空间）spec: containers: #容器 - name: test-app #容器名称 image: 192.168.1.21:5000/web:v1 #镜像 imagePullPolicy: IfNotPresent #获取的策略 ports: - protocol: TCP containerPort: 80 &lt;1&gt;删除之前的pod 1[root@master ~]# kubectl delete pod -n bdqn test-pod &lt;2&gt;执行一下 1[root@master ~]# kubectl apply -f pod.yaml &lt;3&gt;查看一下 1[root@master ~]# kubectl get pod -n bdqn （2）pod的yaml文件（修改端口） 1234567891011121314[root@master ~]# vim pod.yaml kind: PodapiVersion: v1metadata: name: test-pod namespace: bdqnspec: containers: - name: test-app image: 192.168.1.21:5000/web:v1 imagePullPolicy: IfNotPresent ports: - protocol: TCP containerPort: 90 #改一下端口 &lt;1&gt;删除之前的pod 1[root@master ~]# kubectl delete pod -n bdqn test-pod &lt;2&gt;执行一下 1[root@master ~]# kubectl apply -f pod.yaml &lt;3&gt;查看一下 1[root@master ~]# kubectl get pod -n bdqn -o wide &lt;4&gt;访问一下 会发现修改的90端口并不生效，他只是一个提示字段并不生效。 （3）pod的yaml文件（添加标签） 12345678910111213141516[root@master ~]# vim pod.yaml kind: PodapiVersion: v1metadata: name: test-pod namespace: bdqn labels: #标签 app: test-web #标签名称spec: containers: - name: test-app image: 192.168.1.21:5000/web:v1 imagePullPolicy: IfNotPresent ports: - protocol: TCP containerPort: 90 #改一下端口 --------------------------------------pod--------------------------------------------- （4）编写一个service的yaml文件 123456789101112[root@master ~]# vim test-svc.yaml apiVersion: v1 #api版本kind: Service #资源类型metadata: name: test-svc #指定控制器名称 namespace: bdqn #指定namespace（名称空间）spec: selector: #标签 app: test-web #标签名称（须和pod的标签名称一致） ports: - port: 80 #宿主机端口 targetPort: 80 #容器端口 会发现添加的80端口生效了，所以不能乱改。 &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f test-svc.yaml &lt;2&gt;查看一下 1[root@master ~]# kubectl get svc -n bdqn 1[root@master ~]# kubectl describe svc -n bdqn test-svc &lt;4&gt;访问一下 1[root@master ~]# curl 10.98.57.97 --------------------------------------service--------------------------------------------- 四，容器的重启策略 Pod的重启策略（RestartPolicy）应用与Pod内所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或者健康检查失败时，kubelet将根据RestartPolicy的设置来进行相应的操作。 Always：（默认情况下使用）但凡Pod对象终止就将其重启； **OnFailure：**仅在Pod对象出现错误时才将其重启； **Never：**从不重启； 五，pod的默认健康检查 每个容器启动时都会执行一个进程，此进程由 Dockerfile 的 CMD 或 ENTRYPOINT 指定。如果进程退出时返回码非零，则认为容器发生故障，Kubernetes 就会根据 restartPolicy 重启容器。 （1）编写健康检查的yaml文件 下面我们模拟一个容器发生故障的场景，Pod 配置文件如下： 12345678910111213141516[root@master ~]# vim healcheck.yaml apiVersion: v1kind: Podmetadata: labels: test: healcheck name: healcheckspec: restartPolicy: OnFailure #指定重启策略 containers: - name: healcheck image: busybox:latest args: #生成pod时运行的命令 - /bin/sh - -c - sleep 20; exit 1 &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f healcheck.yaml &lt;2&gt;查看一下 1[root@master ~]# kubectl get pod -o wide 1[root@master ~]# kubectl get pod -w | grep healcheck 在上面的例子中，容器进程返回值非零，Kubernetes 则认为容器发生故障，需要重启。但有不少情况是发生了故障，但进程并不会退出。 六，小实验 1）以自己的名称创建一个k8s名称空间，以下所有操作都在此名称空间中。 （1）创建名称空间 1[root@master ~]# kubectl create ns xgp （2）查看一下 1[root@master ~]# kubectl get ns xgp 2）创建一个Pod资源对象，使用的是私有仓库中私有镜像，其镜像的下载策略为：NEVER。 Pod的重启策略为： Never. 123456789101112131415161718192021[root@master ~]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-pod namespace: xgp labels: app: test-webspec: restartPolicy: Never containers: - name: www image: 192.168.1.21:5000/web:v1 imagePullPolicy: Never args: - /bin/sh - -c - sleep 90; exit 1 ports: - protocol: TCP containerPort: 80 3）创建出容器之后，执行非正常退出，查看Pod的最终状态。 （1）执行一下上面pod的yaml文件 1[root@master ~]# kubectl apply -f pod.yaml （2）动态查看ns中test-pod的信息 1[root@master ~]# kubectl get pod -n xgp -w | grep test-pod 删除test-pod 1[root@master ~]# kubectl delete pod -n xgp test-pod 4) 创建一个Service资源对象，与上述Pod对象关联，验证他们的关联性。 （1）修改pod的yaml文件 1234567891011121314151617[root@master ~]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-pod namespace: xgp labels: app: test-webspec: restartPolicy: Never containers: - name: www image: 192.168.1.21:5000/web:v1 imagePullPolicy: Never ports: - protocol: TCP containerPort: 80 （1）编写service的yaml文件 123456789101112[root@master ~]# vim svc.yaml apiVersion: v1kind: Servicemetadata: name: test-svc namespace: xgpspec: selector: app: test-web ports: - port: 80 targetPort: 80 （2）执行一下 1[root@master ~]# kubectl apply -f svc.yaml （3）查看一下 1[root@master ~]# kubectl get pod -o wide -n xgp （4）访问一下 1[root@master ~]# curl 10.244.1.21","path":"posts/74b2.html","date":"08-29","excerpt":"","tags":[{"name":"Namespace","slug":"Namespace","permalink":"https://wsdlxgp.top/tags/Namespace/"},{"name":"PodRestart","slug":"PodRestart","permalink":"https://wsdlxgp.top/tags/PodRestart/"},{"name":"Policy","slug":"Policy","permalink":"https://wsdlxgp.top/tags/Policy/"}]},{"title":"28 k8d创建资源(3)（负载均衡原理，回滚指定版本，label控制pod的位置）","text":"Deployment介绍 Deployment是kubernetes 1.2引入的概念，用来解决Pod的编排问题。Deployment可以理解为RC的升级版（RC+Reolicat Set）。特点在于可以随时知道Pod的部署进度，即对Pod的创建、调度、绑定节点、启动容器完整过程的进度展示。 使用场景 创建一个Deployment对象来生成对应的Replica Set并完成Pod副本的创建过程。 检查Deployment的状态来确认部署动作是否完成（Pod副本的数量是否达到预期值）。 更新Deployment以创建新的Pod(例如镜像升级的场景)。 如果当前Deployment不稳定，回退到上一个Deployment版本。 挂起或恢复一个Deployment。 Service介绍 Service定义了一个服务的访问入口地址，前端应用通过这个入口地址访问其背后的一组由Pod副本组成的集群实例，Service与其后端的Pod副本集群之间是通过Label Selector来实现“无缝对接”。RC保证Service的Pod副本实例数目保持预期水平。 外部系统访问Service的问题 IP类型 说明 Node IP Node节点的IP地址 Pod IP Pod的IP地址 Cluster IP Service的IP地址 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 一，Delpoyment和service的简单使用 1.练习写一个yaml文件，要求使用自己的私有镜像，要求副本数量为三个。 123456789101112131415[root@master ~]# vim xgp.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 （1）执行一下 1[root@master ~]# kubectl apply -f xgp.yaml --recore （2）查看一下 1[root@master ~]# kubectl get pod （3）访问一下 1[root@master ~]# curl 10.244.2.16 （4）更新一下yaml文件，副本加一 123456789101112131415[root@master ~]# vim xgp.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 4 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 &lt;1&gt;执行一下 1[root@master ~]# kubectl apply -f xgp.yaml --recore &lt;2&gt;查看一下 1[root@master ~]# kubectl get pod 副本数量加一，如果yaml文件的副本为0，则副本数量还是之前的状态，并不会更新。 2.练习写一个service文件 123456789101112[root@master ~]# vim xgp-svc.yamlkind: ServiceapiVersion: v1metadata: name: xgp-svcspec: selector: app: xgp-server ports: - protocol: TCP port: 80 targetPort: 80 （1）执行一下 1[root@master ~]# kubectl apply -f xgp-svc.yaml （2）查看一下 1[root@master ~]# kubectl get svc （3）访问一下 1[root@master ~]# curl 10.107.119.49 3.修改yaml文件 1234567891011121314151617[root@master ~]# vim xgp.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 ports: - containerPort: 80 #提示端口 注意：在Delpoyment资源对象中，可以添加Port字段，但此字段仅供用户查看，并不实际生效 执行一下 1[root@master ~]# kubectl apply -f xgp.yaml --recore 4.service文件映射端口 1234567891011121314[root@master ~]# vim xgp-svc.yaml kind: ServiceapiVersion: v1metadata: name: xgp-svcspec: type: NodePort selector: app: xgp-server ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30123 执行一下 1[root@master ~]# kubectl apply -f xgp-svc.yaml 查看一下 1[root@master ~]# kubectl get svc 访问一下 1[root@master ~]# curl 127.0.0.1:30123 5.修改三个pod页面内容 （1）查看一下pod信息 1[root@master ~]# kubectl get pod -o wide （2）修改POD页面内容（三台不一样） 12[root@master ~]# kubectl exec -it xgp-web-8d5f9656f-8z7d9 /bin/bash//根据pod名称进入pod之中 进入容器后修改页面内容 12root@xgp-web-8d5f9656f-8z7d9:/usr/local/apache2# echo xgp-v1 > htdocs/index.html root@xgp-web-8d5f9656f-8z7d9:/usr/local/apache2# exit 访问一下 1[root@master ~]# curl 127.0.0.1:30123 二.分析一下k8s负载均衡原理 （1）查看service的暴露IP 1[root@master ~]# kubectl get svc （2）查看一下iptabes规则 12[root@master ~]# iptables-save //查看已配置的规则 SNAT：Source NAT（源地址转换） DNAT：Destination NAT（目标地址转换） MASQ：动态的源地址转换 （3）根据service的暴露IP，查看对应的iptabes规则 1[root@master ~]# iptables-save | grep 10.107.119.49 1[root@master ~]# iptables-save | grep KUBE-SVC-ESI7C72YHAUGMG5S （4）对应一下IP是否一致 1[root@master ~]# iptables-save | grep KUBE-SEP-ZHDQ73ZKUBMELLJB 1[root@master ~]# kubectl get pod -o wide Service实现的负载均衡：默认使用的是iptables规则。IPVS 三.回滚到指定版本 （1）删除之前创建的delpoy和service 12[root@master ~]# kubectl delete -f xgp.yaml [root@master ~]# kubectl delete -f xgp-svc.yaml （2）准备三个版本所使用的私有镜像，来模拟每次升级不同的镜像 123456789101112131415161718[root@master ~]# vim xgp1.yaml （三个文件名不相同）kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: revisionHistoryLimit: 10 replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 （三台版本不同） ports: - containerPort: 80 此处3个yaml文件 指定不同版本的镜像 （3）运行三个服务，并记录三个版本信息 123[root@master ~]# kubectl apply -f xgp-1.yaml --record [root@master ~]# kubectl apply -f xgp-2.yaml --record [root@master ~]# kubectl apply -f xgp-3.yaml --record （4）查看有哪些版本信息 1[root@master ~]# kubectl rollout history deployment xgp-web （5）运行之前的service文件 1[root@master ~]# kubectl apply -f xgp-svc.yaml （6）查看service暴露端口 1[root@master ~]# kubectl get svc （7）测试访问 1[root@master ~]# curl 127.0.0.1:30123 （8）回滚到指定版本 12[root@master ~]# kubectl rollout undo deployment xgp-web --to-revision=1//这里指定的是版本信息的编号 &lt;1&gt;访问一下 1[root@master ~]# curl 127.0.0.1:30123 &lt;2&gt;查看有哪些版本信息 1[root@master ~]# kubectl rollout history deployment xgp-web 编号1已经被编号2替代，从而生的是一个新的编号4 四.用label控制pod的位置 默认情况下，scheduler会将pod调度到所有可用的Node，不过有些情况我们希望将 Pod 部署到指定的 Node，比如将有大量磁盘 I/O 的 Pod 部署到配置了 SSD 的 Node；或者 Pod 需要 GPU，需要运行在配置了 GPU 的节点上。 kubernetes通过label来实现这个功能 label 是 key-value 对，各种资源都可以设置 label，灵活添加各种自定义属性。比如执行如下命令标注 k8s-node1 是配置了 SSD 的节点 首先我们给node1节点打上一个ssd的标签 1[root@master ~]# kubectl label nodes node02 disk=ssd （1）查看标签 1[root@master ~]# kubectl get nodes --show-labels | grep node02 （2）删除副本一 123[root@master ~]# kubectl delete -f xgp-1.yaml deployment.extensions \"xgp-web\" deleted[root@master ~]# kubectl delete svc xgp-svc （3）修改副本一的yaml文件 123456789101112131415161718192021[root@master ~]# vim xgp-1.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: revisionHistoryLimit: 10 replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 ports: - containerPort: 80 nodeSelector: #添加节点选择器 disk: ssd #和标签内容一致 （4）执行一下 1[root@master ~]# kubectl apply -f xgp-1.yaml 查看一下 1[root@master ~]# kubectl get pod -o wide 现在pod都在node02上运行 （5）删除标签 1[root@master ~]# kubectl label nodes node02 disk- 查看一下 1[root@master ~]# kubectl get nodes --show-labels | grep node02 没有disk标签了 五，小实验 1）使用私有镜像v1版本部署一个Deployment资源对象，要求副本Pod数量为3个，并创建一个Service资源对象相互关联，指定要求3个副本Pod全部运行在node01节点上，记录一个版本。 （1）用label控制pod的位置 1[root@master ~]# kubectl label nodes node01 disk=ssd （2）编写源yaml文件 12345678910111213141516171819[root@master ~]# vim xgp.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 ports: - containerPort: 80 nodeSelector: disk: ssd （3）编写源service文件 1234567891011121314[root@master ~]# vim xgp-svc.yamlkind: ServiceapiVersion: v1metadata: name: xgp-svcspec: type: NodePort selector: app: xgp-server ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30123 （4）执行yaml文件，创建控制器。执行service文件创建映射端口 12[root@master ~]# kubectl apply -f xgp.yaml [root@master ~]# kubectl apply -f xgp-svc.yaml （5）查看一下pod节点 1[root@master ~]# kubectl get pod -o wide （6）记录一个版本 1[root@master ~]# kubectl rollout history deployment xgp-web > pod.txt （7）访问一下 2）根据上述Deployment，升级为v2版本，记录一个版本。 （1）修改yaml文件镜像版本 12345678910111213141516171819[root@master ~]# vim xgp.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v2 #修改版本为二 ports: - containerPort: 80 nodeSelector: disk: ssd （2）刷新一下yaml文件 1[root@master ~]# kubectl apply -f xgp.yaml --recore （3）访问一下 （4）记录一个版本 1[root@master ~]# kubectl rollout history deployment xgp-web > pod.txt 3）最后升级到v3版本，这时，查看Service关联，并且分析访问流量的负载均衡详细情况。 1）修改yaml文件镜像版本 12345678910111213141516171819[root@master ~]# vim xgp.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgp-webspec: replicas: 3 template: metadata: labels: app: xgp-server spec: containers: - name: web image: 192.168.1.21:5000/web:v3 #修改版本为二 ports: - containerPort: 80 nodeSelector: disk: ssd （2）刷新一下yaml文件 1[root@master ~]# kubectl apply -f xgp.yaml --recore （3）访问一下 （5）分析访问流量的负载均衡详细情况 &lt;1&gt;查看一下service映射端口 &lt;2&gt;以ip为起点，分析访问流量的负载均衡详细情况 Service实现的负载均衡：默认使用的是iptables规则。IPVS 12[root@master ~]# iptables-save | grep 10.107.27.229//根据service的暴露IP，查看对应的iptabes规则 1[root@master ~]# iptables-save | grep KUBE-SVC-ESI7C72YHAUGMG5S 这里显示了各节点的负载比例 &lt;3&gt;对应一下IP是否一致 1[root@master ~]# iptables-save | grep KUBE-SEP-VDKW5WQIWOLZMJ6G 1[root@master ~]# kubectl get pod -o wide 4）回滚到指定版本v1，并作验证。 &lt;1&gt;回滚到指定版本 12[root@master ~]# kubectl rollout undo deployment xgp-web --to-revision=1//这里指定的是版本信息的编号 &lt;2&gt;访问一下 1[root@master ~]# curl 127.0.0.1:30123 排错思路 123[root@master ~]# less /var/log/messages | grep kubelet[root@master ~]# kubectl logs -n kube-system kube-scheduler-master [root@master ~]# kubectl describe pod xgp-web-7d478f5bb7-bd4bj","path":"posts/c3bf.html","date":"08-28","excerpt":"","tags":[{"name":"service","slug":"service","permalink":"https://wsdlxgp.top/tags/service/"},{"name":"Deployment","slug":"Deployment","permalink":"https://wsdlxgp.top/tags/Deployment/"}]},{"title":"27 k8s创建资源(2)<基于配置清单>","text":"一，两种创建资源的方法 1. 基于命令的方式： 简单直观快捷，上手快。 适合临时测试或实验。 2. 基于配置清单的方式： 配置文件描述了 What，即应用最终要达到的状态。 配置文件提供了创建资源的模板，能够重复部署。 可以像管理代码一样管理部署。 适合正式的、跨环境的、规模化部署。 这种方式要求熟悉配置文件的语法，有一定难度。 环境介绍 主机 IP地址 服务 master 192.168.1.21 k8s node01 192.168.1.22 k8s node02 192.168.1.23 k8s 二. 配置清单（yam，yaml） 在k8s中，一般使用yaml格式的文件来创建符合我们预期期望的pod，这样的yaml文件我们一般称为资源清单 /etc/kubernetes/manifests/ k8s存放（yam、yaml）文件的地方 kubectl explain deployment（通过explain参数加上资源类别就能看到该资源应该怎么定义） kubectl explain deployment.metadata 通过资源类别加上带有Object标记的字段，我们就可以看到一级字段下二级字段的内容有那些怎么去定义等 kubectl explain deployment.metadata.ownerReferences 通过加上不同级别的字段名称来看下字段下的内容，而且前面的[]号代表对象列表 1.常见yaml文件写法，以及字段的作用 (1) apiVersion：api版本信息 （用来定义当前属于哪个组和那个版本，这个直接关系到最终提供使用的是那个版本） 12[root@master manifests]# kubectl api-versions//查看到当前所有api的版本 (2) kind: 资源对象的类别 (用来定义创建的对象是属于什么类别，是pod，service，还是deployment等对象，可以按照其固定的语法格式来自定义。) (3) metadata: 元数据 名称字段（必写） 提供以下几个字段： creationTimestamp: &quot;2019-06-24T12:18:48Z&quot; generateName: myweb-5b59c8b9d- labels: （对象标签） pod-template-hash: 5b59c8b9d run: myweb name: myweb-5b59c8b9d-gwzz5 （pods对象的名称，同一个类别当中的pod对象名称是唯一的，不能重复） namespace: default （对象所属的名称空间，同一名称空间内可以重复，这个名称空间也是k8s级别的名称空间，不和容器的名称空间混淆） ownerReferences: - apiVersion: apps/v1 blockOwnerDeletion: true controller: true kind: ReplicaSet name: myweb-5b59c8b9d uid: 37f38f64-967a-11e9-8b4b-000c291028e5 resourceVersion: &quot;943&quot; selfLink: /api/v1/namespaces/default/pods/myweb-5b59c8b9d-gwzz5 uid: 37f653a6-967a-11e9-8b4b-000c291028e5 annotations（资源注解，这个需要提前定义，默认是没有的） 通过这些标识定义了每个资源引用的path：即/api/group/version/namespaces/名称空间/资源类别/对象名称 (4) spec： 用户期望的状态 （这个字段最重要，因为spec是用来定义目标状态的‘disired state’，而且资源不通导致spec所嵌套的字段也各不相同，也就因为spec重要且字段不相同，k8s在内部自建了一个spec的说明用于查询） (5) status：资源现在处于什么样的状态 （当前状态，’current state‘，这个字段有k8s集群来生成和维护，不能自定义，属于一个只读字段） 2.编写一个yaml文件 123456789101112131415[root@master ~]# vim web.yamlkind: Deployment #资源对象是控制器apiVersion: extensions/v1beta1 #api的版本metadata: #描述kind（资源类型） name: web #定义控制器名称spec: replicas: 2 #副本数量 template: #模板 metadata: labels: #标签 app: web_server spec: containers: #指定容器 - name: nginx #容器名称 image: nginx #使用的镜像 执行一下 1[root@master ~]# kubectl apply -f web.yaml 查看一下 12[root@master ~]# kubectl get deployments. -o wide//查看控制器信息 12[root@master ~]# kubectl get pod -o wide//查看pod节点信息 3.编写一个service.yaml文件 123456789101112[root@master ~]# vim web-svc.yamlkind: Service #资源对象是副本apiVersion: v1 #api的版本metadata: name: web-svcspec: selector: #标签选择器 app: web-server #须和web.yaml的标签一致 ports: #端口 - protocol: TCP port: 80 #宿主机的端口 targetPort: 80 #容器的端口 使用相同标签和标签选择器内容，使两个资源对象相互关联。 创建的service资源对象，默认的type为ClusterIP，意味着集群内任意节点都可访问。它的作用是为后端真正服务的pod提供一个统一的接口。如果想要外网能够访问服务，应该把type改为NodePort （1）执行一下 1[root@master ~]# kubectl apply -f web-svc.yaml （2）查看一下 12[root@master ~]# kubectl get svc//查看控制器信息 （3）访问一下 1[root@master ~]# curl 10.111.193.168 4.外网能够访问服务 （1）修改web-svc.yaml文件 12345678910111213kind: Service #资源对象是副本apiVersion: v1 #api的版本metadata: name: web-svcspec: type: NodePort #添加 更改网络类型 selector: #标签选择器 app: web_server #须和web.yaml的标签一致 ports: #端口 - protocol: TCP port: 80 #宿主机的端口 targetPort: 80 #容器的端口 nodePort: 30086 #指定群集映射端口，范围是30000-32767 （2）刷新一下 1[root@master ~]# kubectl apply -f web-svc.yaml （3）查看一下 1[root@master ~]# kubectl get svc （4）浏览器测试 三、小实验 基于上一篇博客实验继续进行 1.使用yaml文件的方式创建一个Deployment资源对象，要求镜像使用个人私有镜像v1版本。replicas为3个。 编写yaml文件 123456789101112131415[root@master ~]# vim www.yamlkind: DeploymentapiVersion: extensions/v1beta1metadata: name: xgpspec: replicas: 3 template: metadata: labels: app: www_server spec: containers: - name: web image: 192.168.1.21:5000/web:v1 （1）执行一下 1[root@master ~]# kubectl apply -f web-svc.yaml （2）查看一下 12[root@master ~]# kubectl get deployments. -o wide//查看控制器信息 12[root@master ~]# kubectl get pod -o wide//查看pod节点信息 （3）访问一下 2. 使用yaml文件的方式创建一个Service资源对象，要与上述Deployment资源对象关联，type类型为： NodePort，端口为:30123. 编写service文件 1234567891011121314[root@master ~]# vim www-svc.yamlkind: ServiceapiVersion: v1metadata: name: www-svcspec: type: NodePort selector: app: www_server ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30123 执行一下 1[root@master ~]# kubectl apply -f www-svc.yaml 查看一下 1[root@master ~]# kubectl get svc 访问一下 四. 总结 1. Pod的作用 在k8s中pod是最小的管理单位，在一个pod中通常会包含一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。 在每一个Pod中都有一个特殊的Pause容器和一个或多个业务容器，Pause来源于pause-amd64镜像,Pause容器在Pod中具有非常重要的作用： Pause容器作为Pod容器的根容器，其本地于业务容器无关，它的状态代表了整个pod的状态。 Pod里的多个业务容器共享Pause容器的IP，每个Pod被分配一个独立的IP地址，Pod中的每个容器共享网络命名空间，包括IP地址和网络端口。Pod内的容器可以使用localhost相互通信。k8s支持底层网络集群内任意两个Pod之间进行通信。 Pod中的所有容器都可以访问共享volumes，允许这些容器共享数据。volumes还用于Pod中的数据持久化，以防其中一个容器需要重新启动而丢失数据。 2. Service的作用 Service 是后端真实服务的抽象，一个 Service 可以代表多个相同的后端服务 Service 为 POD 控制器控制的 POD 集群提供一个固定的访问端点，Service 的工作还依赖于 K8s 中的一个附件，就是 CoreDNS ，它将 Service 地址提供一个域名解析。 NodePort 类型的 service clusterIP：指定 Service 处于 service 网络的哪个 IP，默认为动态分配 NodePort 是在 ClusterIP 类型上增加了一个暴露在了 node 的网络命名空间上的一个 nodePort，所以用户可以从集群外部访问到集群了，因而用户的请求流程是：Client -&gt; NodeIP:NodePort -&gt; ClusterIP:ServicePort -&gt; PodIP:ContainerPort。 可以理解为 NodePort 增强了 ClusterIP 的功能，让客户端可以在每个集群外部访问任意一个 nodeip 从而访问到 clusterIP，再由 clusterIP 进行负载均衡至 POD。 3.流量走向 我们在创建完成一个服务之后，用户首先应该访问的是nginx反向代理的ip，然后通过nginx访问到后端的k8s服务器（master节点）的“NodePort暴露IP 及 映射的端口“，master的apiserver接受到客户端发送来的访问指令，将访问指令通知Controller Manager控制器，Scheduler执行调度任务，将访问指令分发到各节点之上，通过”master节点“的“ip+映射端口”访问到后端k8s节点的信息，节点的Kubelet（pod代理）当Scheduler确定让那个节点返回访问信息之后，kube-proxy将访问信息负载均衡到该节点的容器上，各容器返回信息，并向Master报告运行状态","path":"posts/9569.html","date":"08-27","excerpt":"","tags":[{"name":"service","slug":"service","permalink":"https://wsdlxgp.top/tags/service/"},{"name":"yaml","slug":"yaml","permalink":"https://wsdlxgp.top/tags/yaml/"}]},{"title":"26 k8s创建资源(1)、<扩容与缩容>和<升级与回滚>","text":"两种创建资源的方法 基于命令的方式： 简单直观快捷，上手快。 适合临时测试或实验。 基于配置文件的方式： 配置文件描述了 What，即应用最终要达到的状态。 配置文件提供了创建资源的模板，能够重复部署。 可以像管理代码一样管理部署。 适合正式的、跨环境的、规模化部署。 这种方式要求熟悉配置文件的语法，有一定难度。 一，用命令行的方式创建资源 主机 IP地址 master 192.168.1.21 node01 192.168.1.22 node02 192.168.1.23 仅接受json格式 配置清单（yml、yaml） 12[root@master ~]# cd /etc/kubernetes/manifests///k8s的yml、yaml文件 1.node01和node02下载nginx镜像 12docker pull nginx//下载nginx镜像 2.master创建Pod控制器（test-web），deployment 12[root@master ~]# kubectl run test-web --image=nginx --replicas=5//创建Pod控制器，deployment 3.查看控制器情况 （1） 12[root@master ~]# kubectl get deployments.//查看控制器情况 12[root@master ~]# kubectl get pod --all-namespaces -o wide//显示pod的节点信息 （2） 12[root@master ~]# kubectl get namespaces //查看k8s名称空间 12[root@master ~]# kubectl describe deployments. test-web//查看资源详细信息 查看某种资源对象，没有指定名称空间，默认是在default名称空间。可以加上-n选项，查看指定名称空间的资源。 1[root@master ~]# kubectl get pod -n kube-system 3.删除test-web控制器 1[root@master ~]# kubectl delete deployments. test-web 4.master创建Pod控制器（web），deployment 1[root@master ~]# kubectl run web --image=nginx --replicas=5 查看一下pod信息 12[root@master ~]# kubectl get pod -o wide//查看一下pod的节点信息 12[root@master ~]# kubectl describe deployments. web //查看资源详细信息 注意：直接运行创建的deployment资源对象，是经常使用的一个控制器资源类型，除了deployment，还有rc、rs等等pod控制器，deployment是一个高级的pod控制器。 本机测试访问nginx 1[root@master ~]# curl 10.244.1.7 5.创建service资源类型 12[root@master ~]# kubectl expose deployment web --name=web-xgp --port=80 --type=NodePort//创建service资源类型，这里我们设置了映射端口 如果想要外网能够访问服务，可以暴露deployment资源，得到service资源，但svc资源的类型必须为NodePort。 映射端口范围：30000-32767 查看service信息 1[root@master ~]# kubectl get svc 浏览器测试访问http://192.168.1.21:30493/ 二、服务的扩容与缩容 1. 查看控制器信息 1[root@master ~]# kubectl get deployments. -o wide 2.扩容 1[root@master ~]# kubectl scale deployment web --replicas=8 查看一下 1[root@master ~]# kubectl get deployments. -o wide 3.缩容 1[root@master ~]# kubectl scale deployment web --replicas=4 查看一下 1[root@master ~]# kubectl get deployments. -o wide 3.通过修改web的yaml文件进行扩容缩容 备份web的yaml文件 1[root@master ~]# kubectl get deployments. -o yaml > web.yaml 使用edit修改web的yaml文件 1[root@master ~]# kubectl edit deployments. web 查看一下 1[root@master ~]# kubectl get deployments. -o wide 三、服务的升级与回滚 node01和node02下载1.15版本的nginx 1[root@master ~]# docker pull nginx:1.15 1.master设置服务升级 1[root@master ~]# kubectl set image deployment web web=nginx:1.15 查看一下 2.master设置服务回滚 （1）修改配置文件回滚 使用edit修改web的yaml文件 1[root@master ~]# kubectl edit deployments. web 查看一下 1[root@master ~]# kubectl get deployments. -o wide （2）命令回滚 1[root@master ~]# kubectl rollout undo deployment web 注意:只能回滚到上一次操作的状态 四、实验环境 主机 IP地址 服务 master 192.168.1.21 registry+Deployment node01 192.168.1.22 node02 192.168.1.23 1.master 基于httpd制作自己的镜像，需要3个版本，v1,v2,v3.并且对应的版本镜像，访问的主目录内容不一样 （1）master下载httpd镜像 1[root@master ~]# docker pull httpd （2）编写Dockerfile 123[root@master xgp]# vim DockerfileFROM httpdCOPY index.html /usr/local/apache2/htdocs/index.html （3）创建测试网页v1 1[root@master xgp]#echo \"xgp | test-web | httpd:v1\" > index.html （4）基于Dockerfile创建镜像 web1 1[root@master xgp]# docker build -t web1 . （5）创建测试网页v2 1[root@master xgp]#echo \"xgp | test-web | httpd:v1\" > index.html （6）基于Dockerfile创建镜像 web2 1[root@master xgp]# docker build -t web2 . （7）创建测试网页v3 1[root@master xgp]# echo \"xgp | test-web | httpd:v3\" > index.html （8）基于Dockerfile创建镜像 web3 1[root@master xgp]# docker build -t web3 . 2.master部署私有仓库 （1）master下载registry镜像 1[root@master ~]# docker pull registry （2）启动registry 1[root@master xgp]# docker run -itd --name registry -p 5000:5000 --restart=always registry:latest （3）修改docker配置文件，加入私有仓库（三台） 12[root@master xgp]# vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.21:5000 （4）重启docker（三台） 12[root@master xgp]# systemctl daemon-reload [root@master xgp]# systemctl restart docker 3.上传之前创建的三个web镜像到私有仓库 （1）修改镜像标签 123[root@master xgp]# docker tag web1:latest 192.168.1.21:5000/web1:latest[root@master xgp]# docker tag web2:latest 192.168.1.21:5000/web2:latest[root@master xgp]# docker tag web3:latest 192.168.1.21:5000/web3:latest （2）将三个web镜像上传到私有仓库 123[root@master xgp]# docker push 192.168.1.21:5000/web1:latest [root@master xgp]# docker push 192.168.1.21:5000/web2:latest[root@master xgp]# docker push 192.168.1.21:5000/web3:latest 4.部署一个Deployment资源对象，要求镜像使用上述私有镜像v1版本。6个副本Pod。 1[root@master xgp]# kubectl run www1 --image=192.168.1.21:5000/web1:latest --replicas=6 查看一下 1[root@master xgp]# kubectl get pod 本地访问一下 5.将上述Deployment暴露一个service资源对象，使外网能否访问服务。 1[root@master xgp]# kubectl expose deployment www1 --name=web-xgp --port=80 --type=NodePort 查看一下 1[root@master xgp]# kubectl get svc 浏览器访问一下 6.将上述Deployment进行扩容和缩容操作，扩容为8个副本Pod，然后缩容为4个副本Pod。 （1）扩容 1[root@master xgp]# kubectl scale deployment www1 --replicas=8 查看一下 1[root@master xgp]# kubectl get deployments. -o wide （2）缩容 修改k8s配置文件 备份web的yaml文件 1[root@master ~]# kubectl get deployments. -o yaml > www1.yaml 使用edit修改web的yaml文件 1[root@master ~]# kubectl edit deployments. www1 查看一下 1[root@master xgp]# kubectl get deployments. -o wide 7.将上述Deployment进行升级与回滚操作，将v1版本，升级到v2版本。 （1）升级版本为web2 1[root@master ~]# kubectl set image deployment www1 www1=192.168.1.21:5000/web2 本机测试访问 12[root@master ~]# curl 127.0.0.1:30996xgp | test-web | httpd:v2 浏览器测试访问 （2）回滚版本到web1 &lt;1&gt;修改配置文件回滚 使用edit修改web的yaml文件 1[root@master ~]# kubectl edit deployments. www1 查看一下 1[root@master ~]# kubectl get deployments. -o wide 访问一下 &lt;2&gt;命令回滚 1[root@master ~]# kubectl rollout undo deployment www1 注意:只能回滚到上一次操作的状态 访问一下","path":"posts/dbea.html","date":"08-26","excerpt":"","tags":[{"name":"deployments","slug":"deployments","permalink":"https://wsdlxgp.top/tags/deployments/"},{"name":"registry","slug":"registry","permalink":"https://wsdlxgp.top/tags/registry/"}]},{"title":"25 k8s架构，基本概念","text":"主机名 IP地址 服务 master 192.168.1.21 node01 192.168.1.22 node02 192.168.1.23 kubernetes架构 在这张系统架构图中，我们把服务分为运行在工作节点上的服务和组成集群级别控制板的服务。 Kubernetes节点有运行应用容器必备的服务，而这些都是受Master的控制。 每次个节点上当然都要运行Docker。Docker来负责所有具体的映像下载和容器运行。 Kubernetes主要由以下几个核心组件组成： kubectl：k8s是命令行端，用来发送客户的操作指令。 master节点 1. API server[资源操作入口]：是k8s集群的前端接口，各种各样客户端工具以及k8s的其他组件可以通过它管理k8s集群的各种资源。它提供了HTTP/HTTPS RESTful API,即K8S API。 提供了资源对象的唯一操作入口，其他所有组件都必须通过它提供的API来操作资源数据，只有API Server与存储通信，其他模块通过API Server访问集群状态。 第一，是为了保证集群状态访问的安全。 第二，是为了隔离集群状态访问的方式和后端存储实现的方式：API Server是状态访问的方式，不会因为后端存储技术etcd的改变而改变。 作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTFul接口方式提供给外部客户和内部组件调用。对相关的资源数据“全量查询”+“变化监听”，实时完成相关的业务功能。 2. Scheduler[集群分发调度器]：负责决定将Pod放在哪个Node上运行。在调度时，会充分考虑集群的拓扑结构，当前各个节点的负载情况，以及应对高可用、性能、数据亲和性和需求。 1.Scheduler收集和分析当前Kubernetes集群中所有Minion节点的资源(内存、CPU)负载情况，然后依此分发新建的Pod到Kubernetes集群中可用的节点。 2.实时监测Kubernetes集群中未分发和已分发的所有运行的Pod。 3.Scheduler也监测Minion节点信息，由于会频繁查找Minion节点，Scheduler会缓存一份最新的信息在本地。 4.最后，Scheduler在分发Pod到指定的Minion节点后，会把Pod相关的信息Binding写回API Server。 4. Controller Manager[内部管理控制中心]：负责管理集群的各种资源，保证资源处于预期的状态。它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等。 实现集群故障检测和恢复的自动化工作，负责执行各种控制器，主要有： 1.endpoint-controller：定期关联service和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的。 2.replication-controller：定期关联replicationController和pod，保证replicationController定义的复制数量与实际运行pod的数量总是一致的。 5. Etcd：负责保存k8s集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速的通知k8s相关组件。（第三方组件）它有可替换方案。Consul、zookeeper 6. Pod: k8s集群的最小组成单位。一个Pod内，可以运行一个或多个容器。大多数情况下，一个Pod内只有一个Container容器。 7. Flanner：是k8s集群网络，可以保证Pod的跨主机通信。也有替换方案。 12[root@master ~]# kubectl get pod --all-namespaces//查看pod信息 12[root@master ~]# kubectl get pod --all-namespaces -o wide//显示pod的节点信息 Node节点 Kubelet[节点上的Pod管家]：它是Node的agent(代理)，当Scheduler确定某 个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet,kubelet会根据这些信息创建和运行容器，并向Master报告运行状态。 负责Node节点上pod的创建、修改、监控、删除等全生命周期的管理 定时上报本Node的状态信息给API Server。 kubelet是Master API Server和Minion之间的桥梁，接收Master API Server分配给它的commands和work，与持久性键值存储etcd、file、server和http进行交互，读取配置信息。 具体的工作如下： 设置容器的环境变量、给容器绑定Volume、给容器绑定Port、根据指定的Pod运行一个单一容器、给指定的Pod创建network 容器。 同步Pod的状态、同步Pod的状态、从cAdvisor获取Container info、 pod info、 root info、 machine info。 在容器中运行命令、杀死容器、删除Pod的所有容器。 **kube-proxy[负载均衡、路由转发]:**负责将访问service的TCP/UDP数据流转发到后端的容器。如果有多个副本，kube-proxy会实现负载均衡。 Proxy是为了解决外部网络能够访问跨机器集群中容器提供的应用服务而设计的，运行在每个Node上。Proxy提供TCP/UDP sockets的proxy，每创建一种Service，Proxy主要从etcd获取Services和Endpoints的配置信息（也可以从file获取），然后根据配置信息在Minion上启动一个Proxy的进程并监听相应的服务端口，当外部请求发生时，Proxy会根据Load Balancer将请求分发到后端正确的容器处理。 Proxy不但解决了同一主宿机相同服务端口冲突的问题，还提供了Service转发服务端口对外提供服务的能力，Proxy后端使用了随机、轮循负载均衡算法。 除了核心组件，还有一些推荐的Add-ons： kube-dns负责为整个集群提供DNS服务 Ingress Controller为服务提供外网入口 Heapster提供资源监控 Dashboard提供GUI Federation提供跨可用区的集群 Fluentd-elasticsearch提供集群日志采集、存储与查询 一. 分层架构 Kubernetes设计理念和功能其实就是一个类似Linux的分层架构，如下图所示。 核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境 应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等） 管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等） 接口层：kubectl命令行工具、客户端SDK以及集群联邦 生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴 Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等 Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等 二. 在K8s中运行一个容器应用 下面通过运行一个容器应用的过程，来一起理解一下K8s组件是如何协作的。 开发者开发一个应用后，打包Docker镜像，上传到Docker registry；然后编写一个yaml部署描述文件，以描述应用的结构和资源需求。开发者通过kubectl（或其它应用），将部署描述文件提交到API server，API server将部署需求更新到etcd。etcd在K8s管理结点中的作用相当于数据库，其它组件提交到API server的数据都存储于etcd。API server非常轻量，并不会直接去创建或管理Pod等资源，在多数场景下甚至不会去主动调用其它的K8s组件发出指令。其它组件通过建立和API server的长连接，监视关心的对象，监视到变化后，执行所负责的操作。 继续我们的启动应用之旅，如图所示，Controller Manager中的控制器监视到新的部署描述后，根据部署描述，创建ReplicaSet、Pod等资源。Scheduler监视到新的Pod资源后，结合集群的资源情况，选定一或多个工作结点运行Pod。工作结点上的Kubelet监视到有Pod被计划在自己的结点后，向Docker等Container runtime发出启动容器的指令，Docker engineer将按照指令从Docker registy拉取镜像，然后启动并运行容器。 三. K8s集群的高可用部署 通过之前的介绍，我们看到K8s可以在多个工作结点上启动并管理容器，下面来学习一下，如何实现管理结点的高可用部署。 上图的K8s高可用部署中有3个管理结点。etcd自身是一个分布式数据存储系统，按照其多实例部署方案，结点只需在启动时知道其它结点的IP和端口号即可组成高可用环境。和通常的应用服务器一样，API Server是无状态的，可以运行任意多个实例，且彼此之间无需互相知道。为了能使kubectl等客户端和Kubelet等组件连接到健康的API Server、减轻单台API Server的压力，需使用基础架构提供的负载均衡器作为多个API Server实例的入口。如上图的部署方法，每个主结点上都运行了一个etcd实例，这样API Server只需连接本地的etcd实例即可，无需再使用负载均衡器作为etcd的入口。 Controller Manager和Scheduler需要修改K8s集群，同时修改时可能引发并发问题。假设两个ReplicaSet Controller同时监视到需创建一个Pod，然后同时进行创建操作，就会创建出两个Pod。K8s为了避免这个问题，一组此类组件的实例将选举出一个leader，仅有leader处于活动状态，其它实例处于待命状态。Controller Manager和Scheduler也可以独立于API server部署，通过负载均衡器连接到多个API server实例。 范例 分析各个组件的作用以及架构工作流程: 1) kubectl发送部署 请求到API server 2) APIserver通知Controller Manager创建一个Deployment资源。 3) Scheduler执行调度任务,将两个副本Pod分发到node01和node02. 上。 4) node01和node02, 上的kubelet在各自节点上创建并运行Pod。 补充 1.应用的配置和当前的状态信息保存在etcd中，执行kubectl get pod时API server会从etcd中读取这些数据。 2.flannel会为每个Pod分配一个IP。 但此时没有创建Service资源，目前kube-proxy还没有参与进来。 运行一个例子（创建一个deployment资源对象&lt;pod控制器&gt;） 12[root@master ~]# kubectl run test-web --image=httpd --replicas=2//创建一个deployment资源对象。 运行完成之后，如果有镜像可直接开启，没有的话需要等待一会儿，node节点要在docker hup上下载 查看一下 1[root@master ~]# kubectl get deployments.或 kubectl get deploy 1[root@master ~]# kubectl get pod 12[root@master ~]# kubectl get pod -o wide//显示pod的节点信息 如果，node节点没有运行test-web服务，需要在节点上重启一下 如果删除一个pod 1[root@master ~]# kubectl delete pod test-web-5b56bdff65-2njqf 查看一下 1[root@master ~]# kubectl get pod -o wide 现在发现容器还存在，因为控制器会自动发现，一旦与之前执行的命令有误差，他会自动补全。 https://blog.csdn.net/gongxsh00/article/details/79932136 https://www.jianshu.com/p/18edac81c718","path":"posts/e863.html","date":"08-25","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"},{"name":"kubeadml","slug":"kubeadml","permalink":"https://wsdlxgp.top/tags/kubeadml/"}]},{"title":"24 部署k8s集群","text":"一. Kubernetes 系统简介 首先，他是一个全新的基于容器技术的分布式架构领先方案。Kubernetes(k8s)是Google开源的容器集群管理系统（内部:Borg）。在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。 Kubernetes是一个完备的分布式系统支撑平台，具有完备的集群管理能力，多扩多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。同时Kubernetes提供完善的管理工具，涵盖了包括开发、部署测试、运维监控在内的各个环节。 Kubernetes中，Service是分布式集群架构的核心，一个Service对象拥有如下关键特征： 拥有一个唯一指定的名字 拥有一个虚拟IP（Cluster IP、Service IP、或VIP）和端口号 能够体统某种远程服务能力 被映射到了提供这种服务能力的一组容器应用上 Service的服务进程目前都是基于Socket通信方式对外提供服务，比如Redis、Memcache、MySQL、Web Server，或者是实现了某个具体业务的一个特定的TCP Server进程，虽然一个Service通常由多个相关的服务进程来提供服务，每个服务进程都有一个独立的Endpoint（IP+Port）访问点，但Kubernetes能够让我们通过服务连接到指定的Service上。有了Kubernetes内奸的透明负载均衡和故障恢复机制，不管后端有多少服务进程，也不管某个服务进程是否会由于发生故障而重新部署到其他机器，都不会影响我们队服务的正常调用，更重要的是这个Service本身一旦创建就不会发生变化，意味着在Kubernetes集群中，我们不用为了服务的IP地址的变化问题而头疼了。 容器提供了强大的隔离功能，所有有必要把为Service提供服务的这组进程放入容器中进行隔离。为此，Kubernetes设计了Pod对象，将每个服务进程包装到相对应的Pod中，使其成为Pod中运行的一个容器。为了建立Service与Pod间的关联管理，Kubernetes给每个Pod贴上一个标签Label，比如运行MySQL的Pod贴上name=mysql标签，给运行PHP的Pod贴上name=php标签，然后给相应的Service定义标签选择器Label Selector，这样就能巧妙的解决了Service于Pod的关联问题。 在集群管理方面，Kubernetes将集群中的机器划分为一个Master节点和一群工作节点Node，其中，在Master节点运行着集群管理相关的一组进程kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和纠错等管理能力，并且都是全自动完成的。Node作为集群中的工作节点，运行真正的应用程序，在Node上Kubernetes管理的最小运行单元是Pod。Node上运行着Kubernetes的kubelet、kube-proxy服务进程，这些服务进程负责Pod的创建、启动、监控、重启、销毁以及实现软件模式的负载均衡器。 在Kubernetes集群中，它解决了传统IT系统中服务扩容和升级的两大难题。你只需为需要扩容的Service关联的Pod创建一个Replication Controller简称（RC），则该Service的扩容及后续的升级等问题将迎刃而解。在一个RC定义文件中包括以下3个关键信息。 目标Pod的定义 目标Pod需要运行的副本数量（Replicas） 要监控的目标Pod标签（Label） 在创建好RC后，Kubernetes会通过RC中定义的的Label筛选出对应Pod实例并实时监控其状态和数量，如果实例数量少于定义的副本数量，则会根据RC中定义的Pod模板来创建一个新的Pod，然后将新Pod调度到合适的Node上启动运行，知道Pod实例的数量达到预定目标，这个过程完全是自动化。 1. Kubernetes优势: - 容器编排 - 轻量级 - 开源 - 弹性伸缩 - 负载均衡 2. Kubernetes 特性 Endpoint Slices Kubernetes 集群中网络端点的可扩展跟踪。 服务发现与负载均衡 无需修改您的应用程序即可使用陌生的服务发现机制。Kubernetes 为容器提供了自己的 IP 地址和一个 DNS 名称，并且可以在它们之间实现负载平衡。 自我修复 重新启动失败的容器，在节点死亡时替换并重新调度容器，杀死不响应用户定义的健康检查的容器，并且在它们准备好服务之前不会它们公布给客户端。 自动装箱 根据资源需求和其他约束自动放置容器，同时不会牺牲可用性，将任务关键工作负载和尽力服务工作负载进行混合放置，以提高资源利用率并节省更多资源。 IPv4/IPv6 双协议栈 Allocation of IPv4 and IPv6 addresses to Pods and Services 水平伸缩 使用一个简单的命令、一个UI或基于CPU使用情况自动对应用程序进行伸缩。 3. Kubernetes的Master和Node节点 1.Master k8s集群的管理节点，负责管理集群，提供集群的资源数据访问入口。拥有Etcd存储服务（可选），运行Api Server进程，Controller Manager服务进程及Scheduler服务进程，关联工作节点Node。Kubernetes API server提供HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口。也是集群控制的入口进程；Kubernetes Controller Manager是Kubernetes所有资源对象的自动化控制中心；Kubernetes Schedule是负责资源调度（Pod调度）的进程 2.Node Node是Kubernetes集群架构中运行Pod的服务节点（亦叫agent或minion）。Node是Kubernetes集群操作的单元，用来承载被分配Pod的运行，是Pod运行的宿主机。关联Master管理节点，拥有名称和IP、系统资源信息。运行docker eninge服务，守护进程kunelet及负载均衡器kube-proxy. 每个Node节点都运行着以下一组关键进程 kubelet：负责对Pod对于的容器的创建、启停等任务 kube-proxy：实现Kubernetes Service的通信与负载均衡机制的重要组件 Docker Engine（Docker）：Docker引擎，负责本机容器的创建和管理工作 Node节点可以在运行期间动态增加到Kubernetes集群中，默认情况下，kubelet会想master注册自己，这也是Kubernetes推荐的Node管理方式，kubelet进程会定时向Master汇报自身情报，如操作系统、Docker版本、CPU和内存，以及有哪些Pod在运行等等，这样Master可以获知每个Node节点的资源使用情况，冰实现高效均衡的资源调度策略。 4. Kubernetes Node运行节点，运行管理业务容器，包含如下组件: （1）Kubelet 负责管控容器，Kubelet会从Kubernetes API Server接收Pod的创建请求，启动和停止容器，监控容器运行状态并汇报给Kubernetes API Server。 （2）Kubernetes Proxy 负责为Pod创建代理服务，Kubernetes Proxy会从Kubernetes API Server获取所有的Service信息，并根据Service的信息创建代理服务，实现Service到Pod的请求路由和转发，从而实现Kubernetes层级的虚拟转发网络。 （3）Docker Node上需要运行容器服务 k8s最基本的硬件要求 CPU: 双核 Mem: 2G 3台dockerhost 时间必须同步 实验环境 主机名 IP地址 服务 master 192.168.1.21 dockerhost node01 192.168.1.22 dockerhost node02 192.168.1.23 dockerhost 环境准备 分别将3台虚拟机命名，设置好对应IP，并将其写入域名解析/etc/hosts中，关闭防火墙，iptables，禁用selinux。还有要做到，时间必须一致。全部禁用swap 1.给三台docker命名 k8.1 12[root@localhost ~]# hostnamectl set-hostname master[root@localhost ~]# su - k8.2 12[root@localhost ~]# hostnamectl set-hostname node01[root@localhost ~]# su - k8.3 12[root@localhost ~]# hostnamectl set-hostname node02[root@localhost ~]# su - 验证docker是否能使用及版本是否一样 1[root@master ~]# docker -v 2.关闭防火墙及禁用selinux 123[root@master ~]# systemctl stop firewalld[root@master ~]# systemctl disable firewalld [root@master ~]# vim /etc/selinux/config 3. 禁用swap（三台） 1234[root@master ~]# swapoff -a//临时禁用swap[root@master ~]# free -h[root@master ~]# vim /etc/fstab 4.添加域名解析（三台） 123[root@master ~]# echo 192.168.1.21 master >> /etc/hosts[root@master ~]# echo 192.168.1.22 node01 >> /etc/hosts[root@master ~]# echo 192.168.1.23 node02 >> /etc/hosts 5.做免密登陆（三台） 12[root@master ~]# ssh-keygen -t rsa//生成密钥 复制密钥到其他主机 1254 ssh-copy-id node0155 ssh-copy-id node02 把域名解析复制到其他主机 1263 scp /etc/hosts node01:/etc64 scp /etc/hosts node02:/etc 6.打开路由转发和iptables桥接功能（三台） 1234567891011[root@master ~]# vim /etc/sysctl.d/k8s.conf//开启iptables桥接功能net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1[root@master ~]# echo net.ipv4.ip_forward = 1 >> /etc/sysctl.conf //**打开路由转发[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf [root@master ~]# sysctl -p //刷新一下 如果以上命令执行失败可能是缺少模块，可执行以下命令 1[root@master ~]# modprobe br_netfiler 把路由转发和iptables桥接复制到其他主机 1234[root@master ~]# scp /etc/sysctl.d/k8s.conf node01:/etc/sysctl.d/[root@master ~]# scp /etc/sysctl.d/k8s.conf node02:/etc/sysctl.d/[root@master ~]# scp /etc/sysctl.conf node02:/etc/[root@master ~]# scp /etc/sysctl.conf node01:/etc/ 记得node01和node02也要执行以下命令 12[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf [root@master ~]# sysctl -p master节点安装部署k8s 指定yum安装kubernetes的yum源（三台） 123456789cat","path":"posts/6489.html","date":"08-24","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"},{"name":"kubeadml","slug":"kubeadml","permalink":"https://wsdlxgp.top/tags/kubeadml/"}]},{"title":"23 Docker swarm搭建（2）","text":"什么是docker swarm? Swarm 在 Docker 1.12 版本之前属于一个独立的项目，在 Docker 1.12 版本发布之后，该项目合并到了 Docker 中，成为 Docker 的一个子命令。目前，Swarm 是 Docker 社区提供的唯一一个原生支持 Docker 集群管理的工具。它可以把多个 Docker 主机组成的系统转换为单一的虚拟 Docker 主机，使得容器可以组成跨主机的子网网络。 Docker Swarm 是一个为 IT 运维团队提供集群和调度能力的编排工具。用户可以把集群中所有 Docker Engine 整合进一个「虚拟 Engine」的资源池，通过执行命令与单一的主 Swarm 进行沟通，而不必分别和每个 Docker Engine 沟通。在灵活的调度策略下，IT 团队可以更好地管理可用的主机资源，保证应用容器的高效运行。 Swarm的基本架构如下图所示: Docker Swarm 优点 任何规模都有高性能表现 对于企业级的 Docker Engine 集群和容器调度而言，可拓展性是关键。任何规模的公司——不论是拥有五个还是上千个服务器——都能在其环境下有效使用 Swarm。 经过测试，Swarm 可拓展性的极限是在 1000 个节点上运行 50000 个部署容器，每个容器的启动时间为亚秒级，同时性能无减损。 灵活的容器调度 Swarm 帮助 IT 运维团队在有限条件下将性能表现和资源利用最优化。Swarm 的内置调度器（scheduler）支持多种过滤器，包括：节点标签，亲和性和多种容器部策略如 binpack、spread、random 等等。 服务的持续可用性 Docker Swarm 由 Swarm Manager 提供高可用性，通过创建多个 Swarm master 节点和制定主 master 节点宕机时的备选策略。如果一个 master 节点宕机，那么一个 slave 节点就会被升格为 master 节点，直到原来的 master 节点恢复正常。 此外，如果某个节点无法加入集群，Swarm 会继续尝试加入，并提供错误警报和日志。在节点出错时，Swarm 现在可以尝试把容器重新调度到正常的节点上去。 和 Docker API 及整合支持的兼容性 Swarm 对 Docker API 完全支持，这意味着它能为使用不同 Docker 工具（如 Docker CLI，Compose，Trusted Registry，Hub 和 UCP）的用户提供无缝衔接的使用体验。 Docker Swarm 为 Docker 化应用的核心功能（诸如多主机网络和存储卷管理）提供原生支持 开发的 Compose 文件能（通过 docker-compose up ）轻易地部署到测试服务器或 Swarm 集群上。Docker Swarm 还可以从 Docker Trusted Registry 或 Hub 里 pull 并 run 镜像。 一. 实验环境 主机 IP地址 服务 docker01 192.168.1.11 swarm+service+webUI+registry docker02 192.168.1.13 docker docker03 192.168.1.20 docker 三台主机都关闭防火墙，禁用selinux，修改主机名，时间同步，并添加域名解析。 docker版本必须是：v1.12版本开始（可使用docker version查看版本） 1.关闭防火墙，禁用selinux 123[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# hostnamectl set-hostname docker03[root@localhost ~]# su - 2.时间同步 12mv /etc/localtime /etc/localtime.bkcp /usr/share/zoneinfo/Asia/Shanghai/etc/localtime 3.修改主机名（三台都要） 12[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su - 4.添加域名解析 123[root@docker01 ~]# echo 192.168.1.11 docker01 >> /etc/hosts[root@docker01 ~]# echo 192.168.1.13 docker02 >> /etc/hosts[root@docker01 ~]# echo 192.168.1.20 docker03 >> /etc/hosts 二. docker01 初始化集群 1[root@docker01 ~]# docker swarm init --advertise-addr 192.168.1.11 **–advertise-addr：**指定与其它docker通信的地址。 上边返回的结果告诉我们：初始化成功，并且，如果想要添加work节点运行下面的命令： 注意：token令牌只有24小时的有效期 如果想要添加manager节点：运行下面命令 三，docker02和docker03以worker加入集群 1[root@docker03 ~]# docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-1e60wt0yr5583e4mzwbxnn3a8 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 注意：这里的”*****“代表的是当前所属的节点 四.设置manager node（docker01）不参加工作 1[root@docker01 ~]# docker node update docker01 --availability drain 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 “–availability”选项后面共有三个选项可配置，如下： “active”：工作；“pause”：暂时不工作；“drain”：永久性的不工作 1[root@docker01 ~]# docker node ls 五. docker01部署一个图形化webUI界面 1.docker01 导入镜像 1[root@docker01~]# docker pull dockersamples/visualizer 2.基于镜像启动一台容器 1[root@docker01 ~]# docker run -d -p 8080:8080 -e HOST=192.168.1.100 -e PORT=8080 -v /var/run/docker.sock:/var/run/docker.sock --name visualiaer dockersamples/visualizer 3.通过浏览器访问验证http://192.168.1.11:8080/ 如果访问不到网页，需开启路由转发 12[root@docker01 ~]# echo net.ipv4.ip_forward = 1 >> /etc/sysctl.conf [root@docker01 ~]# sysctl -p 六. Docker01部署一个私有仓库 Docker01部署 123456789101112131415161772 docker pull registry//下载registry镜像73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest//基于registry镜像，启动一台容器78 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker76 docker tag busybox:latest 192.168.1.11:5000/busybox:v1 //把容器重命名一个标签77 docker ps 1234567891078 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker100 docker push 192.168.1.11:5000/busybox:v1//上传容器到私有仓库 Docker02和docker03加入私有仓库 12345678978 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker99 docker pull 192.168.1.11/busybox:v1//测试下载 七. 自定义镜像 要求：基于httpd镜像，更改访问界面内容。镜像tag版本为v1，v2，v3，对应主机面内容为v1，xgp666、v2，xgp666、v2，xgp666 12[root@docker01 ~]# docker pull httpd//下载httpd镜像 创建三个测试目录 12[root@docker01 ~]# mkdir &#123;v1,v2,v3&#125;//创建测试目录 docker01，v1目录操作 1234567891011121314[root@docker01 ~]# cd v1[root@docker01 v1]# echo v1,xgp666 > index.html//创建测试网页[root@docker01 v1]# vim Dockerfile//编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v1]# docker build -t 192.168.1.11:5000/httpd:v1 .//基于dockerfile创建镜像[root@docker01 v1]# docker push 192.168.1.11:5000/httpd:v1//上传刚刚创建镜像到私有仓库 docker01，v2目录操作 12345678910111213[root@docker01 v1]# cd ../v2[root@docker01 v2]# echo v2,xgp666 > index.html[root@docker01 v2]# vim Dockerfile //编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v2]# docker build -t 192.168.1.11:5000/httpd:v2 .//基于dockerfile创建镜像[root@docker01 v2]# docker push 192.168.1.11:5000/httpd:v2//上传刚刚创建镜像到私有仓库 docker01，v3目录操作 12345678910111213[root@docker01 v1]# cd ../v3[root@docker01 v2]# echo v3,xgp666 > index.html[root@docker01 v2]# vim Dockerfile //编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v2]# docker build -t 192.168.1.11:5000/httpd:v3 .//基于dockerfile创建镜像[root@docker01 v2]# docker push 192.168.1.11:5000/httpd:v3//上传刚刚创建镜像到私有仓库 八. 发布一个服务，基于上述镜像 要求:副本数量为3个。服务的名称为: bdqn 1[root@docker01 v3]# docker service create --replicas 3 --name bdqn -p 80:80 192.168.1.11:5000/httpd:v1 查看一下网络 1[root@docker03 ~]# docker network ls 默认的Ingress网络，包括创建的自定义overlay网络, 为后端真正为用户提供服务的container,提供了一个统一的入口。 service 通过 ingress load balancing 来发布服务，且 swarm 集群中所有 node 都参与到 ingress 路由网格（ingress routing mesh） 中，访问任意一个 node+PublishedPort 即可访问到服务。 当访问任何节点上的端口80时，Docker将您的请求路由到活动容器。在群节点本身，端口80可能并不实际绑定，但路由网格知道如何路由流量，并防止任何端口冲突的发生。 路由网格在发布的端口上监听分配给节点的任何IP地址。对于外部可路由的IP地址，该端口可从主机外部获得。对于所有其他IP地址，只能从主机内部访问。 查看一下创建的副本 1[root@docker01 v3]# docker service ps bdqn 浏览器测试访问http://192.168.1.11:80,http://192.168.1.13:80,http://192.168.1.20:80 修改docker02和docker03测试网页内容 docker02 123[root@docker02 ~]# docker exec -it 388f3bd9dd33 /bin/bashroot@388f3bd9dd33:/usr/local/apache2# cd htdocs/root@388f3bd9dd33:/usr/local/apache2/htdocs# echo 123 > index.html docker03 12[root@docker03 ~]# docker exec -it 281454867fac /bin/bashroot@281454867fac:/usr/local/apache2# echo 321 > htdocs/index.html 测试访问（每一台都会显示，会负载均衡） 要求:副本数量为3个。服务的名称为:test 1[root@docker01 v3]# docker service create --replicas 3 --name test -p 80 192.168.1.11:5000/httpd:v1 查看创建的服务映射端口 1[root@docker01 v3]# docker service ls 默认映射端口30000-32767 九. 服务的扩容与缩容 扩容 1[root@docker01 v3]# docker service scale bdqn=6 缩容 1[root@docker01 v3]# docker service scale bdqn=4 扩容与缩容直接直接通过scale进行设置副本数量。 十.服务的升级与回滚 （1）升级 docker service upadte 命令参数详解 –force 强制更新重启服务，无论是否配置或镜像改变都更新 –image image:tag 制定更新的镜像 –with-registry-auth 向 Swarm 代理发送 Registry 认证详细信息，私有仓库需要携带该参数 12[root@docker01 ~]# docker service update --image 192.168.1.11:5000/httpd:v2 bdqn//把bdqn服务升级成v2的版本 测试访问一下 （2）平滑的更新 12[root@docker01 ~]# docker service update --image 192.168.1.11:5000/httpd:v3 --update-parallelism 2 --update-delay 1m bdqn //两个服务一起更新，然后，隔一分钟，继续更新 默认情况下, swarm-次只更新-个副本,并且两个副本之间没有等待时间，我们可以通过 –update-parallelism;设置并行更新的副本数量。 –update-delay：指定滚动更新的时间间隔。 测试访问一下 (3) 回滚操作 1[root@docker01 ~]# docker service rollback bdqn 注意，docker swarm的回滚操作，默认只能回滚到上一-次操作的状态，并不能连续回滚到指定操作。 测试访问一下 十一，注意： 如果一台机器启用多个服务注意，合理分配cpu与内存资源，因tomcat在启动编译时会很吃内存，且docker是多线程启动的，所有最好是限定一下（设置resources.limits）否者会导致内存在同一时刻用光，某些服务启动失败当然也可是设置出错重启（restart_policy.condition:on-failure），另外设置resources.reservations要注意，不要超出总内存或cpu百分比，否者会导致后面服务无法获取cpu或内存资源出现“no suitable node (insufficien”错误（这个错误很奇怪，某个service不启动，也不输出日志，使用“docker stack ps [xxxx]”查看状态会显示此错误）无法启动","path":"posts/420e.html","date":"08-23","excerpt":"","tags":[{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"},{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"},{"name":"webUI","slug":"webUI","permalink":"https://wsdlxgp.top/tags/webUI/"}]},{"title":"22 Docker swarm搭建（1）","text":"Docker swarm docker swarm集群：三剑客之一 一. 实验环境 主机 IP地址 服务 docker01 192.168.1.11 swarm+overlay+webUI docker02 192.168.1.13 docker docker03 192.168.1.20 docker 三台主机都关闭防火墙，禁用selinux，修改主机名，时间同步，并添加域名解析。 docker版本必须是：v1.12版本开始（可使用docker version查看版本） 1.关闭防火墙，禁用selinux 123[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# hostnamectl set-hostname docker03[root@localhost ~]# su - 2.时间同步 12mv /etc/localtime /etc/localtime.bkcp /usr/share/zoneinfo/Asia/Shanghai/etc/localtime 3.修改主机名（三台都要） 12[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su - 4.添加域名解析 1234567[root@docker01 ~]# vim /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.1.11 docker01192.168.1.13 docker02192.168.1.20 docker03 二. swarm原理 **swarm：**作用运行docker engin的多个主机组成的集群 **node：**每一个docker engin都是一个node（节点），分为manager和worker。 **manager node：**负责执行容器的编排和集群的管理工作，保持并维护swarm处于期望的状态。swarm可以有多个manager node，他们会自动协调并选举一个leader执行编排任务。但相反，不能没有manager node。 **worker node：**接受并执行由manager node派发的任务，并且默认manager node也是一个worker node，不过可以将它设置为manager-only node，让他只负责编排和管理工作。 **service：**用来定义worker上执行的命令。 基本命令操作 **docker swarm leave：**申请离开一个集群，之后查看节点状态会变成down，然后可通过manager node 将其删除 **docker node rm xxx：**删除某个节点 docker swarm join-token [manager|worker]：生成令牌，可以是manager或worker身份。 docker node demote（降级）：将swarm节点的为manager降级为worker docker node promote（升级）：将swarm节点的work升级为manager **docker node ls:**查看群集的信息（只可以在manager角色的主机上查看） docker service scale web05=6:容器的动态扩容及缩容 docker service ps web01: 查看创建的容器运行在哪些节点 docker service ls: 查看创建的服务 docker swarm leave: 脱离这个群集 docker node rm docker03: 在manager角色的服务器上移除docker03 docker node update --availability drain docker01: 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 docker node update --label-add mem=max docker03: 更改docker03主机的标签为mem=max docker service update --replicas 8 --image 192.168.20.6:5000/lvjianzhao:v2.0 --container-label-add ‘node.labels.mem==max’ lvjianzhao05: 将服务升级为8个容器，并且指定在mem=max标签的主机上运行 三. docker01 初始化集群 1[root@docker01 ~]# docker swarm init --advertise-addr 192.168.1.11 **–advertise-addr：**指定与其它docker通信的地址。 上边返回的结果告诉我们：初始化成功，并且，如果想要添加work节点运行下面的命令： 注意：token令牌只有24小时的有效期 如果想要添加manager节点：运行下面命令 四.swarm集群的简单操作 1.docker02和docker03以worker加入集群 1[root@docker03 ~]# docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-1e60wt0yr5583e4mzwbxnn3a8 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 注意：这里的”*****“代表的是当前所属的节点 2.删除集群中节点 docker02和docker03申请离开一个集群 1[root@docker02 ~]# docker swarm leave docker删除docker02和docker03节点 12[root@docker01 ~]# docker node rm docker02 [root@docker01 ~]# docker node rm docker03 docker01查看集群 1[root@docker01 ~]# docker node ls 3.docker02和docker03以manager加入集群 docker01生成manager令牌 1[root@docker01 ~]# docker swarm join-token manager docker02和docker03加入集群 1docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-cz6hbyv9r5htyqwj5tfol65aa 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 4.docker02和docker03降级 docker01（manager）把docker02和docker03降级成worker 12[root@docker01 ~]# docker node demote docker02[root@docker01 ~]# docker node demote docker03 查看集群 1[root@docker01 ~]# docker node ls 五.部署docker swarm集群网络 overlay:覆盖型网络 overlay networks 管理Swarm中docker守护进程间的通信。可以将容器附加到一个或多个已存在的overlay网络上，使容器与容器之间能够通信； 12[root@docker01 ~]# docker network create -d overlay --attachable docker//attachable：这个参数必须要加，否则不能用于容器。 在创建网络的时候，我们并没有部署一个存储服务，比如consul，那是因为docker swarm自带存储。 docker01查看网络 但是会发现其他两台并不会发现此网络，需等基于此网络创建service服务就可以看到了 1[root@docker01 ~]# docker network ls 六. docker01部署一个图形化webUI界面 1.docker01 导入镜像 1[root@docker01~]# docker pull dockersamples/visualizer 2.基于镜像启动一台容器 1[root@docker01 ~]# docker run -d -p 8080:8080 -e HOST=192.168.1.100 -e PORT=8080 -v /var/run/docker.sock:/var/run/docker.sock --name visualiaer dockersamples/visualizer 3.通过浏览器访问验证http://192.168.1.11:8080/ 如果访问不到网页，需开启路由转发 12[root@docker01 ~]# echo net.ipv4.ip_forward = 1 >> /etc/sysctl.conf [root@docker01 ~]# sysctl -p 七. 创建service（服务） 1. 基于nginx容器创建一个service服务 1234[root@docker01 ~]#docker pull nginx//下载nginx镜像（三台都要）[root@docker01 ~]# docker service create --replicas 1 --network docker --name web1 -p 80:80 nginx:latest [root@docker01 ~]# docker service create --replicas 1 --network docker --name web2 -p 80 nginx:latest //–replicas：副本数量 大概可以理解为一个副本等于一个容器 2. 查看创建的service服务 1[root@docker01 ~]# docker service ls 单独查看一个servicefuw 1[root@docker01 ~]# docker service ps web1 1[root@docker01 ~]# docker service ps web2 3. web界面查看 4. 基于nginx容器创建五个service服务 1[root@docker01 ~]# docker service create --replicas 5 --network docker --name web -p 80 nginx:latest web界面查看 5. 挂起docker02 web查看（发现服务都分配到其他服务器了） 6. 恢复docker02 web查看（发现服务没有回到docker02） 八、实现docker容器的扩容及缩容 1. 删除web1和web2服务 1[root@docker01 ~]# docker service rm web1 web2 2. 容器的扩容和缩减 （1）扩容 1[root@docker01 ~]# docker service scale web=8 （2）缩减 1[root@docker01 ~]# docker service scale web=3 3.设置manager node不参加工作 1[root@docker01 ~]# docker node update docker01 --availability drain 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 “–availability”选项后面共有三个选项可配置，如下： “active”：工作；“pause”：暂时不工作；“drain”：永久性的不工作 1[root@docker01 ~]# docker node ls web界面查看 九、docker Swarm总结 在我对docker Swarm群集进行一定了解后，得出的结论如下： 参与群集的主机名一定不能冲突，并且可以互相解析对方的主机名； 集群内的所有节点可以都是manager角色，但是不可以都是worker角色； 当指定运行的镜像时，如果群集中的节点本地没有该镜像，那么它将会自动下载对应的镜像； 当群集正常工作时，若一个运行着容器的docker服务器发生宕机，那么，其所运行的所有容器，都将转移到其他正常运行的节点之上，而且，就算发生宕机的服务器恢复正常运行，也不会再接管之前运行的容器；","path":"posts/60e.html","date":"08-22","excerpt":"","tags":[{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"},{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"},{"name":"webUI","slug":"webUI","permalink":"https://wsdlxgp.top/tags/webUI/"}]},{"title":"21 docker swarm版本回滚","text":"Docker swarm docker swarm集群：三剑客之一 一. Docker Swarm 的基本概念和原理 Docker Swarm 简介 Swarm是Docker公司推出的用来管理docker集群，它将一群Docker宿主机变成一个单一的，虚拟的主机。Swarm使用标准的Docker API接口作为其前端访问入口，换言之，各种形式的Docker Client(docker client in Go, docker_py, docker等)均可以直接与Swarm通信。Swarm几乎全部用go语言来完成开发，Swarm0.2发布，相比0.1版本，0.2版本增加了一个新的策略来调度集群中的容器，使得在可用的节点上传播它们，以及支持更多的Docker命令以及集群驱动。 Swarm deamon只是一个调度器（Scheduler）加路由器(router)，Swarm自己不运行容器，它只是接受docker客户端发送过来的请求，调度适合的节点来运行容器，这意味着，即使Swarm由于某些原因挂掉了，集群中的节点也会照常运行，当Swarm重新恢复运行之后，它会收集重建集群信息． Docker Swarm 工作原理 Docker 客户端通过 Docker API 向 Swarm 管理端发送请求，Swarm Manager 通过守护进程调用集群中的某个节点来执行任务。因为容器都是运行在节点上，Swarm 作为一个独立的集群管理工具，故并不会因某些原因导致不能正常工作而影响集群内所有节点的正常运行。当服务恢复正常后，Swarm 会读取日志来执行集群的恢复动作。架构图如图 1： 图 1.Docker Swarm 架构图 二. Docker Swarm要点 **Swarm的负载非常低。**据我观察，Swarm进行调度和通信的CPU负载非常低。因此，Swarm的管理节点(Manager)可以同时作为工作节点(Worker)。如果你需要搭建一个非常大的集群(1000+ 节点)，管理节点需要更多资源，但是对于中小型集群来说，管理节点需要的资源可以忽略不计。 **Swarm集群的网络通信(服务发现，负载均衡以及容器间通信)非常可靠。**当你开启一个服务的端口之后，在Swarm集群中的任何一个节点都可以访问它。负载均衡也是由Swarm提供的。后文会提到一些之前遇到的问题，但是Docker 1.13之后，这些问题都解决了。 三. 实验环境 主机 IP地址 服务 docker01 192.168.1.11 swarm+service+webUI+registry docker02 192.168.1.13 docker docker03 192.168.1.20 docker 三台主机都关闭防火墙，禁用selinux，修改主机名，时间同步，并添加域名解析。 docker版本必须是：v1.12版本开始（可使用docker version查看版本） 1.关闭防火墙，禁用selinux 123[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# hostnamectl set-hostname docker03[root@localhost ~]# su - 2.时间同步 12mv /etc/localtime /etc/localtime.bkcp /usr/share/zoneinfo/Asia/Shanghai/etc/localtime 3.修改主机名（三台都要） 12[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su - 4.添加域名解析 123[root@docker01 ~]# echo 192.168.1.11 docker01 >> /etc/hosts[root@docker01 ~]# echo 192.168.1.13 docker02 >> /etc/hosts[root@docker01 ~]# echo 192.168.1.20 docker03 >> /etc/hosts 四. swarm原理 **swarm：**作用运行docker engin的多个主机组成的集群 **node：**每一个docker engin都是一个node（节点），分为manager和worker。 **manager node：**负责执行容器的编排和集群的管理工作，保持并维护swarm处于期望的状态。swarm可以有多个manager node，他们会自动协调并选举一个leader执行编排任务。但相反，不能没有manager node。 **worker node：**接受并执行由manager node派发的任务，并且默认manager node也是一个worker node，不过可以将它设置为manager-only node，让他只负责编排和管理工作。 **service：**用来定义worker上执行的命令。 基本命令操作 **docker swarm leave：**申请离开一个集群，之后查看节点状态会变成down，然后可通过manager node 将其删除 **docker node rm xxx：**删除某个节点 docker swarm join-token [manager|worker]：生成令牌，可以是manager或worker身份。 docker node demote（降级）：将swarm节点的为manager降级为worker docker node promote（升级）：将swarm节点的work升级为manager **docker node ls:**查看群集的信息（只可以在manager角色的主机上查看） docker service scale web05=6:容器的动态扩容及缩容 docker service ps web01: 查看创建的容器运行在哪些节点 docker service ls: 查看创建的服务 docker swarm leave: 脱离这个群集 docker node rm docker03: 在manager角色的服务器上移除docker03 docker node update --availability drain docker01: 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 docker node update --label-add mem=max docker03: 更改docker03主机的标签为mem=max docker service update --replicas 8 --image 192.168.20.6:5000/lvjianzhao:v2.0 --container-label-add ‘node.labels.mem==max’ lvjianzhao05: 将服务升级为8个容器，并且指定在mem=max标签的主机上运行 五. docker01 初始化集群 1[root@docker01 ~]# docker swarm init --advertise-addr 192.168.1.11 **–advertise-addr：**指定与其它docker通信的地址。 上边返回的结果告诉我们：初始化成功，并且，如果想要添加work节点运行下面的命令： 注意：token令牌只有24小时的有效期 上面命令执行后，该机器自动加入到swarm集群。这个会创建一个集群token，获取全球唯一的 token，作为集群唯一标识。后续将其他节点加入集群都会用到这个token值。 其中，–advertise-addr参数表示其它swarm中的worker节点使用此ip地址与manager联系。命令的输出包含了其它节点如何加入集群的命令。 如果想要添加manager节点：运行下面命令 六.swarm集群的简单操作 1、docker02和docker03以worker加入集群 1[root@docker03 ~]# docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-1e60wt0yr5583e4mzwbxnn3a8 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~]# docker node ls 注意：这里的”*****“代表的是当前所属的节点 2.删除集群中节点 docker02和docker03申请离开一个集群 1[root@docker02 ~]# docker swarm leave docker删除docker02和docker03节点 12[root@docker01 ~]# docker node rm docker02 [root@docker01 ~]# docker node rm docker03 docker01查看集群 1[root@docker01 ~]# docker node ls 3.docker02和docker03以manager加入集群 docker01生成manager令牌 1[root@docker01 ~][root@docker01 ~]# docker swarm join-token manager docker02和docker03加入集群 1docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-cz6hbyv9r5htyqwj5tfol65aa 192.168.1.11:docker swarm join --token SWMTKN-1-5kxn9wloh7npnytklwbfciesr9di7uvu521gwnqm9h1n0pbokj-cz6hbyv9r5htyqwj5tfol65aa 192.168.1.11:2377 docker01查看集群 1[root@docker01 ~][root@docker01 ~]# docker node ls 4.docker02和docker03降级 docker01（manager）把docker02和docker03降级成worker 12[root@docker01 ~]# docker node demote docker02[root@docker01 ~][root@docker01 ~]# docker node demote docker02[root@docker01 ~]# docker node demote docker03 查看集群 1[root@docker01 ~][root@docker01 ~]# docker node ls 五.设置manager node（docker01）不参加工作 1[root@docker01 ~]# docker node update docker01 --availability drain 设置主机docker01以后不运行容器，但已经运行的容器并不会停止 “–availability”选项后面共有三个选项可配置，如下： “active”：工作；“pause”：暂时不工作；“drain”：永久性的不工作 1[root@docker01 ~]# docker node ls 八. docker01部署一个图形化webUI界面 1.docker01 导入镜像 1[root@docker01~]# docker pull dockersamples/visualizer 2.基于镜像启动一台容器 1[root@docker01 ~]# docker run -d -p 8080:8080 -e HOST=192.168.1.100 -e PORT=8080 -v /var/run/docker.sock:/var/run/docker.sock --name visualiaer dockersamples/visualizer 3.通过浏览器访问验证http://192.168.1.11:8080/ 如果访问不到网页，需开启路由转发 12[root@docker01 ~]# echo net.ipv4.ip_forward = 1 >> /etc/sysctl.conf [root@docker01 ~]# sysctl -p 一. Docker01部署一个私有仓库 Docker01部署 123456789101112131415161772 docker pull registry//下载registry镜像73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest//基于registry镜像，启动一台容器78 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker76 docker tag busybox:latest 192.168.1.11:5000/busybox:v1 //把容器重命名一个标签77 docker ps 1234567891078 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker100 docker push 192.168.1.11:5000/busybox:v1//上传容器到私有仓库 Docker02和docker03加入私有仓库 12345678978 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload81 systemctl restart docker.service//重启docker99 docker pull 192.168.1.11/busybox:v1//测试下载 2. 自定义镜像 要求：基于httpd镜像，更改访问界面内容。镜像tag版本为v1，v2，v3，对应主机面内容为v1，xgp666、v2，xgp666、v2，xgp666 12[root@docker01 ~]# docker pull httpd//下载httpd镜像 创建三个测试目录 12[root@docker01 ~]# mkdir &#123;v1,v2,v3&#125;//创建测试目录 docker01，v1目录操作 1234567891011121314[root@docker01 ~]# cd v1[root@docker01 v1]# echo v1,xgp666 > index.html//创建测试网页[root@docker01 v1]# vim Dockerfile//编写DockerfileFROM httpdADD index.html /c[root@docker01 v1]# docker build -t 192.168.1.11:5000/httpd:v1 .//基于dockerfile创建镜像[root@docker01 v1]# docker push 192.168.1.11:5000/httpd:v1//上传刚刚创建镜像到私有仓库 docker01，v2目录操作 12345678910111213[root@docker01 v1]# cd ../v2[root@docker01 v2]# echo v2,xgp666 > index.html[root@docker01 v2]# vim Dockerfile //编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v2]# docker build -t 192.168.1.11:5000/httpd:v2 .//基于dockerfile创建镜像[root@docker01 v2]# docker push 192.168.1.11:5000/httpd:v2//上传刚刚创建镜像到私有仓库 docker01，v3目录操作 12345678910111213[root@docker01 v1]# cd ../v3[root@docker01 v2]# echo v3,xgp666 > index.html[root@docker01 v2]# vim Dockerfile //编写DockerfileFROM httpdADD index.html /usr/local/apache2/htdocs/index.html[root@docker01 v2]# docker build -t 192.168.1.11:5000/httpd:v3 .//基于dockerfile创建镜像[root@docker01 v2]# docker push 192.168.1.11:5000/httpd:v3//上传刚刚创建镜像到私有仓库 3. 发布一个服务，基于上述镜像 要求:副本数量为3个。服务的名称为: bdqn 1[root@docker01 v3]# docker service create --replicas 3 --name bdqn -p 80:80 192.168.1.11:5000/httpd:v1 查看一下网络 1[root@docker03 ~]# docker network ls 默认的Ingress网络，包括创建的自定义overlay网络, 为后端真正为用户提供服务的container,提供了一个统一的入口。 查看一下创建的副本 1[root@docker01 v3]# docker service ps bdqn 浏览器测试访问http://192.168.1.11:80,http://192.168.1.13:80,http://192.168.1.20:80 修改docker02和docker03测试网页内容 docker02 123[root@docker02 ~]# docker exec -it 388f3bd9dd33 /bin/bashroot@388f3bd9dd33:/usr/local/apache2# cd htdocs/root@388f3bd9dd33:/usr/local/apache2/htdocs# echo 123 > index.html docker03 12[root@docker03 ~]# docker exec -it 281454867fac /bin/bashroot@281454867fac:/usr/local/apache2# echo 321 > htdocs/index.html 测试访问（每一台都会显示，会负载均衡） 要求:副本数量为3个。服务的名称为:test 1[root@docker01 v3]# docker service create --replicas 3 --name test -p 80 192.168.1.11:5000/httpd:v1 查看创建的服务映射端口 1[root@docker01 v3]# docker service ls 默认映射端口30000-32767 4. 服务的扩容与缩容 扩容 1[root@docker01 v3]# docker service scale bdqn=6 缩容 1[root@docker01 v3]# docker service scale bdqn=4 扩容与缩容直接直接通过scale进行设置副本数量。 5.服务的升级与回滚 （1）升级 12[root@docker01 ~]# docker service update --image 192.168.1.11:5000/httpd:v2 bdqn//把bdqn服务升级成v2的版本 测试访问一下 （2）平滑的更新 12[root@docker01 ~]# docker service update --image 192.168.1.11:5000/httpd:v3 --update-parallelism 2 --update-delay 1m bdqn //两个服务一起更新，然后，隔一分钟，继续更新 默认情况下, swarm-次只更新-个副本,并且两个副本之间没有等待时间，我们可以通过 –update-parallelism;设置并行更新的副本数量。 –update-delay：指定滚动更新的时间间隔。 测试访问一下 (3) 回滚操作 1[root@docker01 ~]# docker service rollback bdqn 注意，docker swarm的回滚操作，默认只能回滚到上一-次操作的状态，并不能连续回滚到指定操作。 测试访问一下","path":"posts/4890.html","date":"08-21","excerpt":"","tags":[{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"},{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"},{"name":"webUI","slug":"webUI","permalink":"https://wsdlxgp.top/tags/webUI/"}]},{"title":"20 Docker+Consul+registrator实现服务发现及nginx反向代理","text":"更改时间 12mv /etc/localtime/etc/localtime. bkcp /usr/share/zoneinfo/Asia/Shanghai/etc/localtime 查看端口 1[root@docker01 consul]# ss -lnt Consul:分布式、高可用的，服务发现和配置服务的工具。数据中心 Rigistrator:负责收集dockerhost_上,容器服务的信息，并且发送给consul Consul-tpmplate:根据编辑好的模板，生产新的nginx配置文件，并负责重新加载nginx配置文件 一. 架构设计 在现实中，我们一直渴望着追求提供高质量、高可用的服务架构体系，同时减少不必要的部署和维护代价，减少容错率。面对如此高的要求，可以有两种架构方案： Docker+Etcd+Confd+Nginx Docker+Consul+Nginx 本文中我们主要来介绍 Docker+Etcd+Confd+Nginx方案，此方案更加高效、快捷，并且维护代价和容错率更低，分布式支持力度更强，如下图所示： 上面示意图的大概流程如下： 1、docker01主机上以二进制包的方式部署consul服务并后台运行，其身份为leader； 2、docker02、docker03以容器的方式运行consul服务，并加入到docker01的consul群集中； 3、在主机docker02、docker03上后台运行registrator容器，使其自动发现docker容器提供的服务； 4、在docker01上部署Nginx，提供反向代理服务，docker02、docker03主机上基于Nginx镜像，各运行两个web容器，提供不同的网页文件，以便测试效果； 5、在docker01上安装consul-template命令，将收集到的信息（registrator收集到容器的信息）写入template模板中，并且最终写入Nginx的配置文件中。 6、至此，实现客户端通过访问Nginx反向代理服务器（docker01），获得docker02、docker03服务器上运行的Nginx容器提供的网页文件。 注：registrator是一个自动发现docker container提供的服务，并且在后端服务注册中心（数据中心）注册服务。主要用来收集容器运行服务的信息，并且发送给consul。数据中心除了consul外，还有etcd、zookeeper等。 二. 架构优势 Docker+Consul+Nginx虽然看起来是三个组件的运用，但却证明是一个有机的整体。它们互相联系、互相作用，完全满足我们对高可用、高效服务架构方案的需求，是Docker生态圈中最理想的组合之一，具有以下优势： 1.发现与注册组件consul使用 Raft 算法来保证一致性，比复杂的Paxos 算法更直接。相比较而言，zookeeper 采用的是 Paxos，而 etcd 使用的则是 Raft； 2.多数据中心，多数据中心集群可以避免单数据中心的单点故障，zookeeper 和 etcd 均不提供多数据中心功能的支持； 3.、实时发现及无感知服务刷新，具备资源弹性，伸缩自如； 4.健康检查，负载能动态在可用的服务实例上进行均衡，etcd 不提供此功能； 5.足够多台Docker容器(前提架构资源足以保证性能支撑)； 6.http 和dns 协议接口，zookeeper 的集成较为复杂，etcd 只支持 http 协议； 7.规模方便进行快速调整，官方提供web管理界面，etcd 无此功能； 8.nsul template 搭配consul使用，支持多种接入层，如Nginx、Haproxy。 三. 实验环境 主机 iP地址 服务 docker01 192.168.1.11 consul+consul-template+nginx docker02 192.168.1.13 consul+registrator docker03 192.168.1.20 consul+registrator 三台主机关闭防火墙，禁用selinux，更改主机名如上所述。 四. 部署consul服务 （1）docker01去官网https://www.consul.io/downloads.html下载consul服务 123456[root@docker01 ~]# unzip consul_1.5.1_linux_amd64.zip //现在是本地导入压缩包，需要解压 [root@docker01 ~]# mv consul /usr/local/bin///移动服务到bin目录[root@docker01 ~]# chmod +x /usr/local/bin/consul//给予一个可执行权限 （2）启动consul 1[root@docker01 ~]# consul agent -server -bootstrap -ui -data-dir=/var/lib/consul-data -bind=192.168.1.11 -client=0.0.0.0 -node=master PS: //-bootstrap: 加入这个选项时，一般都在server单节点的时候用，自选举为leader。 参数解释： -server：添加一个服务 -bootstrap：一般在server单节点的时候使用，自选举为leader。 -data-dir：key/volume指定数据存放的目录 -ui：开启内部的web界面 -bind：指定开启服务的ip -client：指定访问的客户端 -node：在集群内部通信使用的名称，默认是主机名。 现在这个ip是外部使用 PS:开启的端口 8300 集群节点 8301 集群内部的访问 8302 跨数据中心的通信 8500 web ui界面 8600 使用dns协议查看节点信息的端口 可参考下图查看端口的意思： 这时，这条命令会占用终端，可以使用nohup命令让它保持后台运行。 1[root@docker01 ~]# nohup consul agent -server -bootstrap -ui -data-dir=/var/lib/consule-data -bind=192.168.1.11 -client=0.0.0.0 -node=master & （3）查看consul端口的信息 1[root@docker01 ~]# consul info （4）查看consul集群成员的信息 1[root@docker01 ~]# consul members 现在这个ip是内部使用 五. docker01下载部署consul-template 在 https://github.com/hashicorp/consul-template 上，下载consul-template 123456[root@docker01 ~]# unzip consul-template_0.19.5_linux_amd64.zip//解压安装好的consul-template包[root@docker01 ~]# mv consul-template /usr/local/bin///移动到命令目录[root@docker01 ~]# chmod +x /usr/local/bin/consul-template [root@docker01 ~]# unzip consul-template_0.19.5_linux_amd64.zip//解压安装好的consul-template包[root@docker01 ~]# mv consul-template /usr/local/bin///移动到命令目录[root@docker01 ~]# chmod +x /usr/local/bin/consul-template //给予一个可执行权限 六和七步骤简要说明 在docker01和docker02上操作 先来说一下在docker服务器上操作的大概思路： 分别在两台docker服务器上都创建registrator容器，注意到consul服务中心； 在docker01上运行两台nginx容器（端口随机生成），在docker02上运行两台nginx容器（端口随机生成）； 修改这4台nginx容器中的index.html页面内容为（xgp-web01、xgp-web02、xgp-web03、xgp-web04） 访问consul web界面验证 访问nginx服务器地址 http://192.168.1.11:8000 进行验证； 六. docker02，docker03，加入consul集群 这里我们采用容器的方式去运行consul服务。 （1）下载consu所需的l镜像 1[root@docker02 ~]# docker pull consul （2）基于consul镜像开启一台容器 1[root@docker02 ~]# docker run -d --name consul -p 8301:8301 -p 8301:8301/udp -p 8500:8500 -p 8600:8600 -p 8600:8600/udp --restart always progrium/consul -join 192.168.1.11 -advertise 192.168.1.13 -client 0.0.0.0 -node=node01 参数解释： -d：守护进程 –name：容器名称 –restart：容器随着docker服务一直运行 -advertise:声明本机地址 -join:声明服务端地址 -node:consul集群中的名称 （3）docker查看consul集群成员的信息 1[root@docker01 ~]# consul members （4）两台docker开启容器后，docker01查看 （5）浏览器访问http://192.168.1.11:8500 七. docker02、docker03 上部署registrator服务 registrator是一个能自动发现docker container提供的服务,并在后端服务注册中心注册服务或取消服务的工具，后端注册中心支持conusl、etcd、 skydns2、zookeeper等。 （1）下载registrator镜像 12[root@docker02 ~]# docker pull registrator[root@docker02 ~]# docker pull registrator//下载registrator镜像 （2）基于registrator镜像，开启一台容器 1[root@docker02 ~]# docker run -d --name registrator -v /var/run/docker.sock:/tmp/docker.sock --restart always gliderlabs/registrator consul:[root@docker02 ~]# docker run -d --name registrator -v /var/run/docker.sock:/tmp/docker.sock --restart always gliderlabs/registrator consul://192.168.1.13:8500 参数说明： –network：把运行的docker容器设定为host网络模式； -v /var/run/docker.sock：把宿主机的Docker守护进程(Docker daemon)默认监听的Unix域套接字挂载到容器中； –ip : 刚才把network指定了host模式，所以我们指定下IP为宿主机的IP； consul:j最后这个选项是配置consul服务器的IP和端口。 （3）开启一台nginx容器 1[root@docker02 ~][root@docker02 ~]# docker run -d —P --name nginx nginx:latest （4）浏览器查看一下http://192.168.1.11:8500/ui/dc1/nodes 八.docker01部署一个nginx服务 配置nginx，大概配置的思路为： 在/usr/local/nginx/conf中创建目录consul，目录名自定义； 在consul目录中创建nginx.ctmpl模板； 在nginx.conf配置中添加include项并指向consul目录 ； 重启nginx服务； （1）安装开启nginx服务 安装nginx依赖包 1[root@docker01 ~]# yum -y install pcre pcre-devel openssl openssl-devel zlib zlib-devel 编译安装nginx 12[root@docker01 ~]# cd nginx-1.14.0/[root@docker01 nginx-1.14.0]# ./configure --user=nginx --group=nginx --with-http_stub_status_module --with-http_realip_module --with-pcre --with-http_ssl_module && make && make install 创建所需用户和链接命令目录 12[root@docker01 nginx-1.14.0]# useradd -M -s /sbin/nologin nginx[root@docker01 nginx-1.14.0]# ln -s /usr/local/nginx/sbin/* /usr/local/bin/ 检查nginx是否有问题，并开启nginx 1234[root@docker01 nginx-1.14.0]# nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@docker01 nginx-1.14.0]# nginx PS:这里nginx作为反向代理，代理后端docker02、 docker03 上nginx的容器服务,所以我们先去docker02、docker03. 上部署一些服务， 为了方便等会看到负载的效果，所以，我们运行完成容器之后，做一个主界面内容的区分。 （2）安装完成之后，本机测试访问 1[root@docker01 nginx-1.14.0]# curl 127.0.0.1 （3）docker02和docker03部署环境 主机 服务 docker02 nginx web01，web02 docker03 nginx web03，web04 &lt;1&gt;下载nginx镜像（docker02，docker03都要） 12[root@docker02 ~]# docker pull nginx//下载nginx镜像 &lt;2&gt;docker01操作 基于nginx镜像运行上述所说的容器并设置测试页面 1234567891011web01[root@docker02 ~]# docker run -itd --name web01 -P nginx:latest[root@docker02 ~]# docker exec -it web01 /bin/bashroot@44b59d07202f:/# cd /usr/share/nginx/html/root@44b59d07202f:/usr/share/nginx/html# echo web01 > index.htmlweb02[root@docker02 ~]# docker run -itd --name web02 -P nginx:latest[root@docker02 ~]# docker exec -it web02 /bin/bashroot@44b59d07202f:/# cd /usr/share/nginx/html/root@44b59d07202f:/usr/share/nginx/html# echo web02 > index.html &lt;3&gt;docker02操作 基于nginx镜像运行上述所说的容器并设置测试页面 12345678910111213web03[root@docker03 ~]# docker run -itd --name web03 -P nginx:latest[root@docker03 ~]# docker exec -it web03 /bin/bashroot@fd8e8b2df136:/# cd /usr/share/nginx/html/root@fd8e8b2df136:/usr/share/nginx/html# echo web03 > index.htmlroot@fd8e8b2df136:/usr/share/nginx/html# exittrueweb04[root@docker03 ~]# docker run -itd --name web04 -P nginx:latest[root@docker03 ~]# docker exec -it web04 /bin/bashroot@fd8e8b2df136:/# cd /usr/share/nginx/html/root@fd8e8b2df136:/usr/share/nginx/html# echo web04 > index.htmlroot@fd8e8b2df136:/usr/share/nginx/html# exit （4）docker01更改nginx配置文件 123456[root@docker01 ~]# cd /usr/local/nginx///进入nginx配置文件目录[root@docker01 nginx]# mkdir consul//创建consul目录[root@docker01 nginx]# cd consul///进入consul目录 &lt;1&gt;创建nginx.ctmpl模板 1234567891011121314[root@docker01 consul]# vim nginx.ctmplupstream http_backend &#123; &#123;&#123;range service \"nginx\"&#125;&#125; server &#123;&#123; .Address &#125;&#125;:&#123;&#123; .Port &#125;&#125;; &#123;&#123; end &#125;&#125;&#125;server &#123; listen 8000; server_name localhost; location / &#123; proxy_pass http://http_backend; &#125;&#125; &lt;2&gt;修改nginx配置文件，通过 include 参数包含刚刚创建的文件 123[root@docker01 consul]# cd /usr/local/nginx/conf/[root@docker01 conf]# vim nginx.conf include /usr/local/nginx/consul/*.conf; #文件最后添加（要在大括号里面） &lt;3&gt; 生成一个vhost.conf配置文件，并重启nginx（会占用终端) 使用consul-template命令，根据模板生产新的配置文件，并重新加载nginx的配置文件。 1[root@docker01 conf]# consul-template -consul-addr 192.168.1.11:8500 -template \"/usr/local/nginx/consul/nginx.ctmpl:/usr/local/nginx/consul/vhost.conf:/usr/local/bin/nginx -s reload\" 这时，这条命令会占用终端，可以使用nohup命令让它保持后台运行,并重启nginx服务。 1[root@docker01 conf]# nohup consul-template -consul-addr 192.168.1.11:8500 -template \"/usr/local/nginx/consul/nginx.ctmpl:/usr/local/nginx/consul/vhost.conf:/usr/local/sbin/nginx -s reload\" & 查看一下文件是否生成，里面是否有内容 123[root@docker01 ~]# cd /usr/local/nginx/consul/[root@docker01 consul]# lsnginx.ctmpl vhost.conf 1[root@docker01 consul]# cat vhost.conf 此时，应该能够看到，新生产的vhost.conf配置文件已经生效，访问本机8000端口可以得到不同容器提供的服务。 &lt;4&gt;测试访问 12[root@docker01 consul]# curl 127.0.0.1:8000web01 此时可以看到负载均衡的效果！ &lt;5&gt;如果访问不成功 查看端口8000是否开启 1[root@docker01 consul]# ss -lnt 检查nginx配置文件 123[root@docker01 consul]# nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 检查自己编写的nginx配置文件 123456789101112131415[root@docker01 consul]# cd /usr/local/nginx/consul/[root@docker01 consul]# cat nginx.ctmpl upstream http_backend &#123;true&#123;&#123;range service \"nginx\"&#125;&#125;trueserver &#123;&#123; .Address &#125;&#125;:&#123;&#123; .Port &#125;&#125;;true&#123;&#123; end &#125;&#125;&#125;server &#123;truelisten 8000;trueserver_name localhost;truelocation / &#123;truetrueproxy_pass http://http_backend;true&#125;&#125; 如果nginx配置文件没问题，重启nginx 1[root@docker01 consul]# nginx -s reload &lt;6&gt;测试自动发现 docker02 创建测试容器 12345[root@docker02 ~]# docker run -itd --name web05 -P nginx:latest[root@docker02 ~]# docker exec -it web05 /bin/bashroot@44b59d07202f:/# cd /usr/share/nginx/html/root@44b59d07202f:/usr/share/nginx/html# echo web02 > index.html[root@docker02 ~]# docker ps docker01查看 12[root@docker01 consul]# cd /usr/local/nginx/consul/[root@docker01 consul]# cat vhost.conf docker01测试访问 1[root@docker01 consul]# curl 127.0.0.1:8000 //同上 此时可以看到负载均衡的效果！ 这时不需要考虑后端的web服务器添加还是删除都会自动更新的，这是因为在运行consul-template这条命令后添加的/usr/local/sbin/nginx -s reload的作用！","path":"posts/b3c.html","date":"08-20","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"},{"name":"consul","slug":"consul","permalink":"https://wsdlxgp.top/tags/consul/"},{"name":"registrata","slug":"registrata","permalink":"https://wsdlxgp.top/tags/registrata/"}]},{"title":"19 搭建Prometheus监控报警","text":"基于上一篇博客继续进行部署 一、Prometheus &amp; AlertManager 介绍 Prometheus 是一套开源的系统监控、报警、时间序列数据库的组合，最初有 SoundCloud 开发的，后来随着越来越多公司使用，于是便独立成开源项目。Alertmanager 主要用于接收 Prometheus 发送的告警信息，它支持丰富的告警通知渠道，例如邮件、微信、钉钉、Slack 等常用沟通工具，而且很容易做到告警信息进行去重，降噪，分组等，是一款很好用的告警通知系统。 二、基本概念 Prometheus 官网（https://prometheus.io/） 是一套开源的监控和报警系统，也是一个时序数据库。 架构图 基本原理 Prometheus的基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。 服务过程 Prometheus Daemon负责定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。 2.Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。 3.Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。 4.PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。 Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。 工作流程 通过exporters从数据源主动拉取数据（metrics），保存到时序数据库（TSDB）中，可以通过HTTP Server访问，同时可以发起报警，对于数据库中的时序数据，提供PromeQL进行查询，提供给web UI或者可视化系统Grafana等展示。 Grafana 官网（https://grafana.com/） 开源的数据分析和监控平台 有不同的dashboards支持不同类型的数据可视化 Exporters 数据采集 Prometheus从不同的exorters中拉取数据，有不同的exporter支持不同的数据源 node-exporter 支持机器基本的数据 比如cpu mem 网络 等 docker01 docker02 docker03 192.168.1.11 192.168.1.13 192.168.1.20 NodeEXporter NodeEXporter NodeEXporter cAdvisor cAdvisor cAdvisor Prometheus Server 空 空 Grafana 空 空 全部关闭防火墙，禁用selinux 四、设置prometheus监控报警 接下来，我们需要启动 AlertManager 来接受 Prometheus 发送过来的报警信息，并执行各种方式的告警。同样以 Docker 方式启动 AlertManager，最简单的启动命令如下： 1$$ docker run --name alertmanager -d -p 9093:9093 prom/alertmanager:latest 这里 AlertManager 默认启动的端口为 9093，启动完成后，浏览器访问 http://:9093 可以看到默认提供的 UI 页面，不过现在是没有任何告警信息的，因为我们还没有配置报警规则来触发报警。 配置AlertManager AlertManager：用来接收prometheus发送来的报警信息，并且执行设置好的报警方式、报警内容。 下载镜像 12[root@docker01 ~]# docker pull alertmanager//下载alertmanager镜像 基于alertmanager运行一台容器 1[root@docker01 ~]# docker run -d --name alertmanager -p 9093:9093 prom/alertmanager:latest 配置路由转发 12[root@docker01 ~]# echo net.ipv4.ip_forward = 1 >> /etc/sysctl.conf [root@docker01 ~]# sysctl -p 在部署alertmanager之前，我们需要对它的配置文件进行修改,所以我们先运行一个容器，先将其配置文件拷贝出来。 12[root@docker01 ~]# docker cp alertmanager:/etc/alertmanager/alertmanager.yml .///拷贝alertmanager的配置文件到本地 修改alertmanager的配置文件 配置文件简单介绍 AlertManager：用来接收Prometheus发送的报警信息，并且执行设置好的报警方式，报警内容。 AlertManager.yml配置文件： global：全局配置，包括报警解决后的超时时间、SMTP相关配置、各种渠道通知的API地址等消息。 route：用来设置报警的分发策略。 receivers：配置报警信息接收者信息。 inhibit_rules：抑制规则配置，当存在与另一个匹配的报警时，抑制规则将禁用用于有匹配的警报。 修改配置文件 123456789101112131415161718192021222324252627[root@docker01 ~]# vim alertmanager.yml //修改alertmanager配置文件global: resolve_timeout: 5m smtp_from: '2877364346@qq.com' #自己邮箱地址 smtp_smarthost: 'smtp.qq.com:465' #qq的邮箱地址及端口 smtp_auth_username: '2877364346@qq.com' smtp_auth_password: 'osjppnjkbuhcdfff' #需要在qq邮箱获取授权码 smtp_require_tls: false smtp_hello: 'qq.com'route: group_by: ['alertname'] group_wait: 5s group_interval: 5s repeat_interval: 5m receiver: 'email' #接收者改为邮箱receivers:- name: 'email' email_configs: - to: '2877364346@qq.com' send_resolved: true inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 以上配置我反复试验后，发现不同的环境参数配置也不一样，调试期间出现了各种报错问题，将其中几个关键的配置说明一下： 1、smtp_smarthost: 这里为 QQ 邮箱 SMTP 服务地址，官方地址为 smtp.qq.com 端口为 465 或 587，同时要设置开启 POP3/SMTP 服务。 2、smtp_auth_password: 这里为第三方登录 QQ 邮箱的授权码，非 QQ 账户登录密码，否则会报错，获取方式在 QQ 邮箱服务端设置开启 POP3/SMTP 服务时会提示。 3、smtp_require_tls: 是否使用 tls，根据环境不同，来选择开启和关闭。如果提示报错 email.loginAuth failed: 530 Must issue a STARTTLS command first，那么就需要设置为 true。着重说明一下，如果开启了 tls，提示报错 starttls failed: x509: certificate signed by unknown authority，需要在 email_configs 下配置 insecure_skip_verify: true 来跳过 tls 验证。 重新运行 alertmanager 容器 1234[root@docker01 ~]# docker rm -f alertmanager//删除alertmanager容器[root@docker01 ~]# docker run -d --name alertmanager -v /root/alertmanager.yml:/etc/alertmanager/alertmanager.yml -p 9093:9093 prom/alertmanager:latest //运行一台新的alertmanager容器，记得挂载配置文件 Prometheus配置和alertmanager报警规则 创建存放规则的目录 123[root@docker01 ~]# mkdir -p prometheus/rules//创建规则目录[root@docker01 ~]# cd prometheus/rules/ 编写规则 123456789101112[root@docker01 rules]# vim node-up.rules groups:- name: node-up rules: - alert: node-up expr: up&#123;job=\"prometheus\"&#125; == 0 #&#123;job=\"prometheus\"&#125;中的prometheus需要和prometheus配置文件23行的相同 for: 15s labels: severity: 1 team: node annotations: summary: \"&#123;&#123; $labels.instance &#125;&#125; 已停止运行超过 15s！\" 说明一下：该 rules 目的是监测 node 是否存活，expr 为 PromQL 表达式验证特定节点 job=“node-exporter” 是否活着，for 表示报警状态为 Pending 后等待 15s 变成 Firing 状态，一旦变成 Firing 状态则将报警发送到 AlertManager，labels 和 annotations 对该 alert 添加更多的标识说明信息，所有添加的标签注解信息，以及 prometheus.yml 中该 job 已添加 label 都会自动添加到邮件内容中，更多关于 rule 详细配置可以参考 这里。 修改 prometheus配置文件 123456789101112[root@docker01 ~]# vim prometheus.yml # Alertmanager configuration #7alerting: alertmanagers: - static_configs: - targets: - 192.168.1.11:9093 #去注释修改# Load rules once and periodically evaluate them according to the global 'evaluation_interval'. [root@docker01 ~]# vim prometheus.yml # Alertmanager configuration #7alerting: alertmanagers: - static_configs: - targets: - 192.168.1.11:9093 #去注释修改# Load rules once and periodically evaluate them according to the global 'evaluation_interval'. #14行rule_files: - \"/usr/local/prometheus/rules/*.rules\" #添加（这个路径是prometheus容器内的路径） 注意: 这里 rulefiles 为容器内路径，需要将本地 node-up.rules 文件挂载到容器内指定路径，修改 Prometheus 启动命令如下，并重启服务。 重新运行prometheus 容器 1234[root@docker01 ~]# docker rm -f prometheus //删除prometheus容器[root@docker01 ~]# docker run -d -p 9090:9090 --name prometheus --net=host -v /root/prometheus.yml:/etc/prometheus/prometheus.yml -v /root/prometheus/rules/node-up.rules:/usr/local/prometheus/rules/node-up.rules prom/prometheus//运行一台新的alertmanager容器，记得挂载规则文件 浏览器验证一下http://192.168.1.11:9090/rules 这里说明一下 Prometheus Alert 告警状态有三种状态：Inactive、Pending、Firing。 Inactive：非活动状态，表示正在监控，但是还未有任何警报触发。 Pending：表示这个警报必须被触发。由于警报可以被分组、压抑/抑制或静默/静音，所以等待验证，一旦所有的验证都通过，则将转到 Firing 状态。 Firing：将警报发送到 AlertManager，它将按照配置将警报的发送给所有接收者。一旦警报解除，则将状态转到 Inactive，如此循环。 挂起docker02 会收到邮件 这里有几个地方需要解释一下： 每次停止/恢复服务后，15s 之后才会发现 Alert 状态变化，是因为 prometheus.yml中 global -&gt; scrape_interval: 15s 配置决定的，如果觉得等待 15s 时间太长，可以修改小一些，可以全局修改，也可以局部修改。例如局部修改 node-exporter 等待时间为 5s。 … - job_name: ‘node-exporter’ scrape_interval: 5s file_sd_configs: - files: [’/usr/local/prometheus/groups/nodegroups/*.json’] Alert 状态变化时会等待 15s 才发生改变，是因为 node-up.rules 中配置了 for: 15s 状态变化等待时间。 报警触发后，每隔 5m 会自动发送报警邮件(服务未恢复正常期间)，是因为 alertmanager.yml 中 route -&gt; repeat_interval: 5m 配置决定的。 五、AlertManager自定义邮件模板 创建模板目录 1234[root@docker01 ~]# cd prometheus//进入之前创建的prometheus目录[root@docker01 prometheus]# mkdir alertmanager-tmpl//创建AlertManager模板目录 看到上边默认发送的邮件模板，虽然所有核心的信息已经包含了，但是邮件格式内容可以更优雅直观一些，那么，AlertManager 也是支持自定义邮件模板配置的，首先新建一个模板文件 编写模板规则 123456789101112131415[root@docker01 prometheus]# vim email.tmpl &#123;&#123; define \"email.from\" &#125;&#125;2877364346@qq.com&#123;&#123; end &#125;&#125;&#123;&#123; define \"email.to\" &#125;&#125;2877364346@qq.com&#123;&#123; end &#125;&#125;&#123;&#123; define \"email.to.html\" &#125;&#125;&#123;&#123; range .Alerts &#125;&#125;=========start==========告警程序: prometheus_alert告警级别: &#123;&#123; .Labels.severity &#125;&#125; 级告警类型: &#123;&#123; .Labels.alertname &#125;&#125;故障主机: &#123;&#123; .Labels.instance &#125;&#125;告警主题: &#123;&#123; .Annotations.summary &#125;&#125;触发时间: &#123;&#123; .StartsAt.Format \"2019-08-04 16:58:15\" &#125;&#125; =========end==========&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125; 简单说明一下，上边模板文件配置了 email.from、email.to、email.to.html 三种模板变量，可以在 alertmanager.yml 文件中直接配置引用。这里 email.to.html 就是要发送的邮件内容，支持 Html 和 Text 格式，这里为了显示好看，采用 Html 格式简单显示信息。下边 {{ range .Alerts }} 是个循环语法，用于循环获取匹配的 Alerts 的信息，下边的告警信息跟上边默认邮件显示信息一样，只是提取了部分核心值来展示。然后，需要增加 alertmanager.yml 文件 templates 配置如下： 修改alertmanager的配置文件 1234567891011121314151617181920212223242526272829[root@docker01 ~]# vim alertmanager.yml global: resolve_timeout: 5m smtp_from: '2877364346@qq.com' smtp_smarthost: 'smtp.qq.com:465' smtp_auth_username: '2877364346@qq.com' smtp_auth_password: 'evjmqipqezlbdfij' smtp_require_tls: false smtp_hello: 'qq.com'templates: #添加模板 - '/etc/alertmanager-tmpl/*.tmpl' #添加路径 route: group_by: ['alertname'] group_wait: 5s group_interval: 5s repeat_interval: 5m receiver: 'email' receivers:- name: 'email' email_configs: - to: '&#123;&#123; template \"email to\" &#125;&#125;' #修改 html: '&#123;&#123; template \"email.to.html\" .&#125;&#125;' #添加 send_resolved: true #删除 inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 重新运行 alertmanager 容器 1234[root@docker01 ~]# docker rm -f alertmanager//删除alertmanager容器[root@docker01 ~]# docker run -itd --name alertmanager -p 9093:9093 -v /root/alertmanager.yml:/etc/alertmanager/alertmanager.yml -v /root/prometheus/alertmanager-tmpl:/etc/alertmanager-tmpl prom/alertmanager:latest//运行一台新的alertmanager容器，记得挂载配置文件 挂起docker02 收到邮件 当然我们还可以配置邮件标题，这里就不在演示了，详细配置可参考 这里。这里除了监控节点是否存活外，还可以监控很多很多指标，例如 CPU 负载告警、Mem 使用量告警、Disk 存储空间告警、Network 负载告警等等，这些都可以通过自定义 PromQL 表达式验证值来定义一些列的告警规则，来丰富日常工作中需要的各种告警。 这里，我们只演示了如何通过 AlertManager 来配置发送邮件告警，其他的告警方式，可以参考 官网文档 来配置，这里就不再演示了。下一篇，我们继续通过 Prometheus 来监控 SpringBoot 工程应用程序 JVM 情况，以及自定义 metrics 来实现特定功能的监控。","path":"posts/babe.html","date":"08-19","excerpt":"","tags":[{"name":"prometheus","slug":"prometheus","permalink":"https://wsdlxgp.top/tags/prometheus/"},{"name":"alertmanager","slug":"alertmanager","permalink":"https://wsdlxgp.top/tags/alertmanager/"}]},{"title":"18 基于docker搭建Prometheus+Grafana","text":"一、介绍Prometheus Prometheus（普罗米修斯）是一套开源的监控&amp;报警&amp;时间序列数据库的组合，起始是由SoundCloud公司开发的。随着发展，越来越多公司和组织接受采用Prometheus，社会也十分活跃，他们便将它独立成开源项目，并且有公司来运作。Google SRE的书内也曾提到跟他们BorgMon监控系统相似的实现是Prometheus。现在最常见的Kubernetes容器管理系统中，通常会搭配Prometheus进行监控。 Prometheus基本原理是通过HTTP协议周期性抓取被监控组件的状态，这样做的好处是任意组件只要提供HTTP接口就可以接入监控系统，不需要任何SDK或者其他的集成过程。这样做非常适合虚拟化环境比如VM或者Docker 。 Prometheus应该是为数不多的适合Docker、Mesos、Kubernetes环境的监控系统之一。 与其他监控系统相比，Prometheus的主要特点是： 一个多维数据模型（时间序列由指标名称定义和设置键/值尺寸）。 非常高效的存储，平均一个采样数据占~3.5bytes左右，320万的时间序列，每30秒采样，保持60天，消耗磁盘大概228G。 一种灵活的查询语言。 不依赖分布式存储，单个服务器节点。 时间集合通过HTTP上的PULL模型进行。 通过中间网关支持推送时间。 通过服务发现或静态配置发现目标。 多种模式的图形和仪表板支持。 二、Prometheus架构概览 该图说明了普罗米修斯（Prometheus）及其一些生态系统组件的整体架构： 它的服务过程是这样的Prometheus daemon负责定时去目标上抓取metrics(指标) 数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。 Prometheus：支持通过配置文件、文本文件、zookeeper、Consul、DNS SRV lookup等方式指定抓取目标。支持很多方式的图表可视化，例如十分精美的Grafana，自带的Promdash，以及自身提供的模版引擎等等，还提供HTTP API的查询方式，自定义所需要的输出。 Alertmanager：是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。 PushGateway：这个组件是支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。 如果有使用过statsd的用户，则会觉得这十分相似，只是statsd是直接发送给服务器端，而Prometheus主要还是靠进程主动去抓取。 大多数Prometheus组件都是用Go编写的，它们可以轻松地构建和部署为静态二进制文件。访问prometheus.io以获取完整的文档，示例和指南。 三、Prometheus四种数据类型 Counter Counter用于累计值，例如记录请求次数、任务完成数、错误发生次数。一直增加，不会减少。重启进程后，会被重置。 例如：http_response_total{method=”GET”,endpoint=”/api/tracks”} 100，10秒后抓取http_response_total{method=”GET”,endpoint=”/api/tracks”} 100。 Gauge Gauge常规数值，例如 温度变化、内存使用变化。可变大，可变小。重启进程后，会被重置。 例如： memory_usage_bytes{host=”master-01″} 100 &lt; 抓取值、memory_usage_bytes{host=”master-01″} 30、memory_usage_bytes{host=”master-01″} 50、memory_usage_bytes{host=”master-01″} 80 &lt; 抓取值。 Histogram Histogram（直方图）可以理解为柱状图的意思，常用于跟踪事件发生的规模，例如：请求耗时、响应大小。它特别之处是可以对记录的内容进行分组，提供count和sum全部值的功能。 例如：{小于10=5次，小于20=1次，小于30=2次}，count=7次，sum=7次的求和值。 Summary Summary和Histogram十分相似，常用于跟踪事件发生的规模，例如：请求耗时、响应大小。同样提供 count 和 sum 全部值的功能。 例如：count=7次，sum=7次的值求值。 **它提供一个quantiles的功能，可以按%比划分跟踪的结果。**例如：quantile取值0.95，表示取采样值里面的95%数据。 五、实验环境 docker01 docker02 docker03 192.168.1.11 192.168.1.13 192.168.1.20 NodeEXporter NodeEXporter NodeEXporter cAdvisor cAdvisor cAdvisor Prometheus Server 空 空 Grafana 空 空 全部关闭防火墙，禁用selinux 需要部署的组件： Prometheus Server:普罗米修斯的主服务器。 Prometheus是一个开源的服务监控系统，它通过HTTP协议从远程的机器收集数据并存储在本地的时序数据库上。 多维数据模型（时序列数据由metric名和一组key/value组成） 在多维度上灵活的查询语言(PromQl) 不依赖分布式存储，单主节点工作. 通过基于HTTP的pull方式采集时序数据 可以通过push gateway进行时序列数据推送(pushing) 可以通过服务发现或者静态配置去获取要采集的目标服务器 多种可视化图表及仪表盘支持 Prometheus通过安装在远程机器上的exporter来收集监控数据，后面我们将使用到node_exporter收集系统数据。 NodeEXporter:负责收集Host硬件信息和操作系统信息。 cAdvisor:负责收集Host.上运行的容器信息。 Grafana:负责展示普罗米修斯监控界面。 Grafana 是一个开箱即用的可视化工具，具有功能齐全的度量仪表盘和图形编辑器，有灵活丰富的图形化选项，可以混合多种风格，支持多个数据源特点。 这些可以直接docker pull下载镜像（现在是本地导入镜像） 本地上传镜像 docker01 1[09:05:42][docker01$ docker load -i node-exporter.tar && docker load -i mycadvisor.tar && docker load -i prometheus.tar && docker load -i grafana.tar docker02和docker03 1[09:05:22]docker03]$ docker load -i node-exporter.tar && docker load -i mycadvisor.tar 六、各主机部署 1) 3个节点，全部部署node-EXporter,和cAdvisor. 部署安装node-EXporter收集节点硬件和操作系统信息。 12[09:21:03[docker01]$ docker run -d -p 9100:9100 -v /proc:/host/proc -v /sys:/host/sys -v /:/rootfs --net=host prom/node-exporter --path.procfs /host/proc --path.sysfs /host/sys --collector.filesystem.ignored-mount-points \"^/(sys|proc|dev|host|etc)($|/)\"//部署node-EXporter,收集硬件和系统信息。 PS: 注意，这里使用了–net=host， 这样Prometheus Server可以直接与Node- EXporter通信。 验证:打开浏览器验证结果。http://192.168.1.11:9100/，http://192.168.1.13:9100/，http://192.168.1.20:9100/ 部署安装cAdvisor,收集节点容器信息。 1[09:39:10[docker01]$ docker run -v /:/rootfs:ro -v /var/run:/var/run/:rw -v /sys:/sys:ro -v /var/lib/docker:/var/lib/docker:ro --detach=true --name=cadvisor --net=host google/cadvisor 验证:打开浏览器验证结果。http://192.168.1.11:8080，http://192.168.1.13:8080，http://192.168.1.20:8080 2)在docker01上部署Prometheus Server服务。 在部署prometheus之前，我们需要对它的配置文件进行修改,所以我们先运行一个容器，先将其配置文件拷贝出来。 123409:51:22][docker01]$ docker run -d -p 9090:9090 --name prometheus --net=host prom/prometheus//打开一台Prometheus[09:51:00[docker01]$ docker cp prometheus:/etc/prometheus/prometheus.yml .///拷贝Prometheus的配置文件到本地 修改Prometheus的配置文件，添加监听端口（29行） 123[09:55:53][docker01][~]$ vim prometheus.yml //修改配置文件这里指定了prometheus的监控项，包括它也会监控自己手机到的数据。- targets: ['localhost:9090','localhost:8080','localhost:9100','192.168.1.13:8080','192.168.1.13:9100','192.168.1.20:8080','192.168.1.20:9100'] 重新运行prometheus容器 1234[10:00:27][docker01][~]$ docker rm -f prometheus //删除 prometheus容器[10:02:45][docker01][~]$ docker run -d -p 9090:9090 --name prometheus --net=host -v /root/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus//运行一台新的 prometheus容器 浏览器访问，验证：http://192.168.1.11:9090/graph ps：这里能够查看到我们各个监控项。 如果现在挂起一台虚拟机（测试完之后继续运行） 3)在docker01.上,部署grafana服务,用来展示prometheus收集到的数据。 1234[root@docker01 ~]# mkdir grafana-storage//创建收集信息的目录[root@docker01 ~]# chmod 777 grafana-storage///给予777权限 1[root@docker01 ~]# docker run -d -p 3000:3000 --name grafana -v /root/grafana-storage:/var/lib/grafana -e \"GF_SECURITY_ADMIN_PASSWORD=123.com\" grafana/grafana **浏览器访问验证：**http://192.168.1.11:3000/login （&lt;默认&gt;用户名：admin，密码：123.com） 添加数据源 PS:看到这个提示， 说明prometheus和grafana服务的是 正常连接的。 此时，虽然grafana收集到了数据，但怎么显示它,仍然是个问题，grafana支持自定 义显示信息,不过要自定义起来非常麻烦，不过好在，grafana官方为我们提供了- -些模板，来供我们使用。 **grafana官网:**https://grafana.com/docs/grafana/latest/ 选中一款模板，然后，我们有2种方式可以套用这个模板。 第一种方式：通过JSON文件使用模板。 下载完成之后，来到grafana控制台 第二种导入模板的方式:** 可以直接通过模板的ID号。 //这个id不好用换成8321了 复制模板id之后，来到grafana控制台 排错思路 防火墙是否关闭，selinux是否禁用 主机名称是否更改 镜像是否正常 各服务启动时挂载目录是否正确 grafana服务，是否创建所需目录，目录是否有权限 Prometheus服务是否修改配置文件 总结 恭喜！您已经设置了Prometheus服务器，Node Exporter和Grafana 等所有这些都可以使用的Docker。尽管这些目前都在同一台机器上运行，但这仅用于演示目的。在生产设置中，通常会在每台受监控的计算机上运行节点导出器，多个Prometheus服务器（根据组织的需要），以及单个Grafana服务器来绘制来自这些服务器的数据。","path":"posts/5755.html","date":"08-18","excerpt":"","tags":[{"name":"prometheus","slug":"prometheus","permalink":"https://wsdlxgp.top/tags/prometheus/"},{"name":"grafana","slug":"grafana","permalink":"https://wsdlxgp.top/tags/grafana/"}]},{"title":"17 Docker的监控(简单部署Sysdig和Weave Scope)","text":"一、Docker的监控 Docker自带的监控命令 简单命令介绍 ps docker container ps 是我们早已熟悉的命令了，方便我们查看当前运行的容器。新版的 Docker 提供了一个新命令 docker container ls，其作用和用法与 docker container ps 完全一样。不过 ls 含义可能比 ps 更准确，所以更推荐使用。 top 如果想知道某个容器中运行了哪些进程，可以执行 docker container top [container] 命令。命令后面还可以跟上 Linux 操作系统 ps 命令的参数显示特定的信息，比如 -au。 stats docker container stats 用于显示每个容器各种资源的使用情况。默认会显示一个实时变化的列表，展示每个容器的 CPU 使用率，内存使用量和可用量。注意：容器启动时如果没有特别指定内存 limit，stats 命令会显示 host 的内存总量，但这并不意味着每个 container 都能使用到这么多的内存。 除此之外 docker container stats 命令还会显示容器网络和磁盘的 IO 数据。默认的输出有个缺点，显示的是容器 ID 而非名字。我们可以在 stats 命令后面指定容器的名称只显示某些容器的数据。比如 docker container stats sysdig weave。 命令执行 12[root@docker01 ~]# docker ps//查看容器信息 123[root@docker01 ~]# docker top 容器名称[root@docker01 ~]# docker top wordpress_wordpress_1 //查看容器中运行的进程信息，支持 ps 命令参数。 12[root@docker01 ~]# docker stats wordpress_wordpress_1 //实时查看容器统计信息，查看容器的CPU利用率、内存的使用量以及可用内存总量。 123[root@docker01 ~]# docker logs 容器名称[root@docker01 ~]# docker logs wordpress_wordpress_1 //查看容器的日志 二、用 Sysdig 监控服务器和 Docker 容器 12[root@docker01 ~]# docker pull sysdig//下载sysdig镜像 通过sysdig运行容器 1[root@docker01 ~]# docker run -it --rm --name sysdig --privileged=true --volume=/var/run/docker.sock:/host/var/run/docker.sock --volume=/dev:/host/dev --volume=/proc:/host/proc:ro --volume=/boot:/host/boot:ro --volume=/lib/modules:/host/lib/modules:ro --volume=/usr:/host/usr:ro sysdig/sysdig 下载插件失败后可以运行下边命令，重新下载 12root@10ccab83a512:/# system-sysdig-loader//下载插件失败后可以运行下边命令，重新下载 下载成功后，可以运行sysdig命令，查看监控项 12root@10ccab83a512:/# sysdig//运行sysdig命令，查看监控项，它会动态查看 使用 csysdig csysdig 就是运 ncurses 库的用户界面的 sysdig 软件包，Ncurses 是一个能提供功能键定义 ( 快捷键 ), 屏幕绘制以及基于文本终端的图形互动功能的动态库。在 sysdig 软件包里还提供了一个工具 csysdig，该工具执行后，运行界面和 top 命令类似。csysdig 工作界面如图 5。 运行csysdig命令，查看监控项 12root@10ccab83a512:/# csysdig//运行csysdig命令，图形化界面查看监控项，它会动态查看 csysdig 使用如下快捷键： P：暂停屏幕输出信息 Enter：进入当前突出显示的条目。 Ctrl+F：列表搜索。 F1- 帮助信息 F2- 显示视图选择器。这将让你切换到另一个视图。 F4- 使用过滤器 F5- 查看 IO 输出信息 F7 显示帮助页面当前显示的视图。 F8 打开视图的操作面板。 F9，打开列排序面板。 Q 放弃退出。 Arrows, PgUP, PgDn, Home, End：图标上下左右的移动控制。 sysdig按不同的View来监控不同类型的资源，点击底部Views菜单（或者按F2），显示View选择列表 我们将光标移到Containers这一项，界面右边立即显示出此view的功能介绍，回车或者双击Containers，进入容器监控界面 sysdig会显示该host所有的容器的实时数据，每两秒刷新一次。各列数据的含义也是自解释的，如果不清楚，可以点一下底部的Legend，如果想按某一列排序，比如按使用的内存量，点一下列头VIRT 如果想查看某个容器的进程，将光标移动到目标容器，然后回车或者双击 还可以继续双击查看进程中的线程 返回上一级，按退格键即可 sysdig的交互功能很强，如果界面显示的条目很多，可以点击底部Search菜单，然后输入关键字进行查找 如果觉得界面刷新太快，看不清楚关注的信息，可以点击底部的Pause菜单 sysdig的特点： （1）监控信息全，包括Linux操作系统和容器 （2）界面交互性强 其缺点是sysdig显示的是实时数据，看不到变化和趋势。而且是命令行操作方式，需要ssh到host上执行，不是太方便 总结 这些示例仅仅是展示了 Sysdig 能力的冰山一角，在目前的其他系统监控类工具中，笔者还没有看到像 Sysdig 这样功能如此强大、而又对容器支持这样好的。所以，对于经常使用服务器特别是 Docker 容器作为产品运行方式的用户，这是一款值得使用的系统工具。 三、Docker监控方案之Weave Scope Weave Scope 的最大特点是会自动生成一张 Docker 容器地图，让我们能够直观地理解、监控和控制容器。千言万语不及一张图，先感受一下。 12[root@docker01 ~]# docker pull scope//下载scope镜像 执行如下脚本安装运行Weave Scope 123[root@docker01 ~]# curl -L git.io/scope -o /usr/local/bin/scope[root@docker01 ~]# chmod +x /usr/local/bin/scope[root@docker01 ~]# scope launch 浏览器访问http://192.168.1.11:4040/ 然后就可以更好的监控，管理docker中的容器了 开启第docker02，加入docker01监控项 docker01 删除weavescope容器 1234[root@docker01 ~]# docker stop weavescope weavescope[root@docker01 ~]# docker rm weavescope weavescope docker02 12[root@docker01 ~]# docker pull scope//下载scope镜像 123[root@docker01 ~]# curl -L git.io/scope -o /usr/local/bin/scope[root@docker01 ~]# chmod +x /usr/local/bin/scope[root@docker01 ~]# scope launch docker01 1[root@docker01 ~]# scope launch 192.168.1.11 192.168.1.13 docker02 1[root@docker02 ~]# scope launch 192.168.1.13 192.168.1.11 浏览器访问http://192.168.1.11:4040/ 浏览器访问http://192.168.1.13:4040/也是可以的","path":"posts/eb5f.html","date":"08-17","excerpt":"","tags":[{"name":"sysdig","slug":"sysdig","permalink":"https://wsdlxgp.top/tags/sysdig/"},{"name":"Weave Scope","slug":"Weave-Scope","permalink":"https://wsdlxgp.top/tags/Weave-Scope/"}]},{"title":"16 docker三剑客之docker-compose和搭建wordpress的博客","text":"一、简介 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。 通过之前的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 使用微服务架构的系统一般包含若干个微服务，每个微服务一般部署多个实例。如果每个服务都要手动启停，那么效率低，维护量大。 二、 Docker Compose介绍 通过Docker-Compose用户可以很容易地用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成编写。Docker-Compose解决了容器与容器之间如何管理编排的问题。 Docker Compose工作原理图 撰写中有两个重要的概念： **服务（服务）：**一个应用的容器，实际上可以包括多个运行相同相同的容器实例。 **项目（项目）：**由各个关联的应用容器组成的一个完整的业务单元，在docker-compose.yml文件中定义。一个项目可以由多个服务（容器）关联，组成面向项目进行管理，通过子命令对项目中的单个容器进行便捷地生命周期管理。 Compose项目由Python编写，实现上调用了Docker服务提供的API来对容器进行管理。因此，只要所操作的平台支持Docker API，就可以在其上利用Compose来进行编排管理。 Docker三大编排工具： Docker Compose：是用来组装多容器应用的工具，可以在 Swarm集群中部署分布式应用。 Docker Machine：是支持多平台安装Docker的工具，使用 Docker。Machine，可以很方便地在笔记本、云平台及数据中心里安装Docker。 Docker Swarm：是Docker社区原生提供的容器集群管理工具。 Docker Compose命令详解 Docker compose的使用非常类似于docker命令的使用，但是需要注意的是大部分的compose命令都需要到docker-compose.yml文件所在的目录下才能执行。 compose以守护进程模式运行加-d选项 三、Docker Compose安装 123456#下载sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose#安装chmod +x /usr/local/bin/docker-compose##下载sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose#安装chmod +x /usr/local/bin/docker-compose#查看版本docker-compose version 四、实验环境 主机 ip地址 服务 docker 192.168.1.11 compose+wordpress 五 docker三剑客之docker-compose docker容器的编排工具: 解决相互有依赖关系的多个容器的管理。 12[root@docker01 ~]# docker-compose -v//验证已有docker-compose命令 docker-compose的配置文件实例 通过识别一个docker-compose.yml的配置文件，去管理容器。 设置tab键的空格数量 12345[root@docker01 ~]# vim .vimrcset tabstop=2//设置tab键的空格数量[root@docker01 ~]# source .vimrc //刷新一下 创建一个docker-compose.yml测试文件 123456789101112131415[root@docker01 ~]# mkdir compose_test//创建测试目录[root@docker01 ~]# cd compose_test/[root@docker01 compose_test]# vim docker-compose.yml//创建测试文件docker-compose.ymlversion: \"3\"services: nginx: container_name: web-nginx image: nginx restart: always ports: - 90:80 volumes: - ./webserver:/usr/share/nginx/html docker-compose.yml文件的解释 第一部分: version: 指定语法格式的版本。 第二部分: service: 定义服务,(想要运行什么样的容器) 通过docker-compose.yml文件运行容器 12[root@docker01 compose_test]# docker-compose up -d//后台运行docker-compose规定的容器。（在执行这条命令的当前目录下，也需要一个docker-compose.yml的配置文件，并且通常只有一个。） 12[root@docker01 compose_test]# docker ps//查看容器信息 12[root@docker01 compose_test]# curl 127.0.0.1:90//访问nginx会失败，因为挂载目录没有页面内容 123456[root@docker01 compose_test]# vim webserver/index.html//创建测试网页xgp666[root@docker01 compose_test]# curl 127.0.0.1:90//再次访问，是成功的xgp666 通过docker-compose.yml文件停止运行容器 1[root@docker01 compose_test]# docker-compose stop 通过docker-compose.yml文件重启容器 1[root@docker01 compose_test]# docker-compose restart 不在docker-compose.yml文件所在目录，要使用-f指定目录 1[root@docker01 ~]# docker-compose -f compose_test/docker-compose.yml stop 并且，在运行container（docker-compose.yml）的过程中，还支持Dockerfile 1234[root@docker01 compose_test]# vim Dockerfile//编写dockerfileFROM nginxADD webserver /usr/share/nginx/html 1234567891011[root@docker01 compose_test]# vim docker-compose.yml //修改docker-compose.yml文件version: \"3\"services: nginx: build: . #添加 container_name: web-nginx image: new-nginx:v1.0 #修改镜像名称 restart: always ports: - 90:80 通过docker-compose.yml文件停止并删除容器 123[root@docker01 compose_test]# docker-compose stopStopping web-nginx ... done[root@docker01 compose_test]# docker-compose rm 通过docker-compose.yml文件运行容器 1234[root@docker01 compose_test]# docker-compose up -d//通过docker-compose.yml文件[运行]()容器[root@docker01 compose_test]# docker ps//查看容器信息 测试nginx访问页面 123[root@docker01 compose_test]# curl 127.0.0.1:90//测试访问nginx页面，成功xgp666 六、搭建wordpress的博客 下载wordpress和mysql:5.7容器 1234[root@docker01 ~]# docker pull wordpress//下载wordpress容器[root@docker01 ~]# docker pull mysql：5.7//下载mysql：5.7容器 编写一个docker-ccompose.yml 1234567891011121314151617181920212223242526[root@docker01 ~]# mkdir wordpress//创建wordpress测试文件[root@docker01 ~]# cd wordpress/[root@docker01 wordpress]# vim docker-compose.yml//编写docker-compose.ymlversion: \"3.1\"services: wordpress: image: wordpress restart: always ports: - 8080:80 environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: 123.com WORDPRESS_DB_NAME: wordpress db: image: mysql:5.7 restart: always environment: MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: 123.com MYSQL_ROOT_PASSWORD: 123.com 通过docker-compose.yml文件运行容器 1[root@docker01 wordpress]# docker-compose up -d 12[root@docker01 wordpress]# docker ps//查看容器信息 12[root@docker01 wordpress]# docker logs 容器名称//查看容器日志 浏览器访问一下 http://192.168.1.11:8080/ 选择语言 安装wordpress 登陆wordpress 登陆成功后，自己就可以进行设置了 排错 首先查看主机名是否更改 防火墙和selinux是否关闭 docker-compose命令是否安装给予权限 docker–compose.yml 编写是否有问题 容器执行是否正常 （如果浏览器访问不到，可以添加一条路由转发） 其他wordpress优化建议 以上步骤之后，基本wordpress搭建和一些必备的设置就算完成了，剩下的更多是个人的选择，每个人可能要求不同，下面就说几点wordpress优化的建议 1.无论你是做百度seo，安装一个SEO插件，就算不想设置文章的TDK，至少网站首页的有必要设置一下，推荐 All in one seo pack 2.定期备份，备份的重要性不用多说，凡是丢过数据的人都会养成备份的习惯，WordPress备份网站方法 3.安装一个安全插件，WordPress安全插件推荐 4.及时更新网站的主题和插件，WordPress插件自动更新方法 5.删除所有没有用的主题和插件，WordPress删除主题方法 6.设置垃圾留言过滤，wordpress防垃圾留言插件Akismet WordPress建站基础主要就是这些，后面的话就是根据自己的站点进行各种设置，不同类型的站点使用主题和插件都是很大区别的。不过如果你能学会本篇所介绍的内容，相信你的站点就已经超过了绝大部分网站，好了今天教程就到这里，如果你有什么问题或者其他更好的建议，欢迎留言讨论","path":"posts/d728.html","date":"08-16","excerpt":"","tags":[{"name":"docker-compose","slug":"docker-compose","permalink":"https://wsdlxgp.top/tags/docker-compose/"},{"name":"wordpress","slug":"wordpress","permalink":"https://wsdlxgp.top/tags/wordpress/"}]},{"title":"15 nginx+docker+nfs部署","text":"一．体系架构 在Keepalived + Nginx高可用负载均衡架构中，keepalived负责实现High-availability (HA) 功能控制前端机VIP（虚拟网络地址），当有设备发生故障时，热备服务器可以瞬间将VIP自动切换过来，实际运行中体验只有2秒钟切换时间，DNS服务可以负责前端VIP的负载均衡。 nginx负责控制后端web服务器的负载均衡，将客户端的请求按照一定的算法转发给后端Real Server处理，而Real Server将响应直接返回给客户端。 nfs服务器做实时备份，给web服务器提供web界面。 二．简单原理 NGINX_MASTER、NGINX_BACKUP两台服务器均通过keepalived软件把ens33网卡绑上一个虚拟IP（VIP）地址192.168.1.40，此VIP当前由谁承载着服务就绑定在谁的ens32上，当NGINX_MASTER发生故障时，NGINX_BACKUP会通过/etc/keepalived/keepalived.conf文件中设置的心跳时间advert_int 1检查，无法获取NGINX_MASTER正常状态的话，NGINX_BACKUP会瞬间绑定VIP来接替nginx_master的工作，当NGINX_MASTER恢复后keepalived会通过priority参数判断优先权将虚拟VIP地址192.168.1.40重新绑定给NGINX_MASTER的ens33网卡。 使用此方案的优越性 1.实现了可弹性化的架构，在压力增大的时候可以临时添加web服务器添加到这个架构里面去; 2.upstream具有负载均衡能力，可以自动判断后端的机器，并且自动踢出不能正常提供服务的机器； 3.相对于lvs而言，正则分发和重定向更为灵活。而Keepalvied可保证单个nginx负载均衡器的有效性，避免单点故障； 4.用nginx做负载均衡，无需对后端的机器做任何改动。 5.nginx部署在docker容器里，即大量地节约开发、测试、部署的时间，又可以在出现故障时通过镜像快速恢复业务。 三、系统环境 两台负载机器安装：，nginx+docker+nfs 分别命名为：NGINX_MASTER，NGINX_BACKUP。 后端web服务器，可以是提供web服务的任何架构，分别命名为：WEB_1，WEB_2。 后端数据库机器可任意架构，只要能提供数据库服务即可。 服务器 IP地址 安装软件 NGINX_MASTER 192.168.1.10 nginx+keepalived NGINX_BACKUP 192.168.1.20 nginx+keepalived WEB_1 192.168.1.11 docker+nginx WEB_2 192.168.1.13 docker+nginx nfs_MASTER 192.168.1.30 nfs+rsync+inotify nfs_BACKUP 192.168.1.10 nfs+rsync+inotify nginx（两台都是） 安装nginx 12345[root@nginx01 ~]# tar zxf nginx-1.14.0.tar.gz //解压nginx安装包[root@nginx01 ~]# cd nginx-1.14.0/[root@nginx01 nginx-1.14.0]# yum -y install openssl-devel pcre-devel zlib-devel//安装nginx依赖包 12[root@nginx01 nginx-1.14.0]# ./configure --prefix=/usr/local/nginx1.14 --with-http_dav_module --with-http_stub_status_module --with-http_addition_module --with-http_sub_module --with-http_flv_module --with-http_mp4_module --with-pcre --with-http_ssl_module --with-http_gzip_static_module --user=nginx --group=nginx && make && make install//编译安装nginx 12345678[root@nginx01 nginx-1.14.0]# useradd nginx -s /sbin/nologin -M//创建所需用户[root@nginx01 nginx-1.14.0]# ln -s /usr/local/nginx1.14/sbin/nginx /usr/local/sbin///链接命令[root@nginx01 nginx-1.14.0]# nginx //开启nginx[root@nginx01 nginx-1.14.0]# netstat -anpt | grep nginx//查看nginx是否开启 部署nginx 12[root@nginx01 ~]# cd /usr/local/nginx1.14/conf/[root@nginx01 conf]# vim nginx.conf ​ http模块加 1234upstream backend &#123;server 192.168.1.11:90 weight=1 max_fails=2 fail_timeout=10s;server 192.168.1.13:90 weight=1 max_fails=2 fail_timeout=10s;&#125; location / { # root html; # index index.html index.htm; proxy_pass http://backend; #添加 } 高可用环境 安装keepalived 1[root@nginx02 nginx-1.14[root@nginx02 nginx-1.14.0]# yum -y install keepalived 配置keepalived 修改主和备nginx服务器上的keepalived 配置文件 /etc/keepalived/keepalived.conf 文件 主nginx 修改主nginx下/etc/keepalived/keepalived.conf文件 123456789101112131415161718! Configuration File for keepalivedglobal_defs &#123; router_id LVS_DEVEL&#125; vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.40 &#125;&#125; 备nginx 修改备nginx下 /etc/keepalived /keepalived.conf文件 配置备nginx时需要注意：需要修改state为BACKUP , priority比MASTER低，virtual_router_id和master的值一致 12345678910111213141516171819! Configuration File for keepalivedglobal_defs &#123; router_id TWO&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 1 priority 99 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.40 &#125;&#125; 测试（在做完docker的时候） 主备nginx都启动keepalived 1systemctl start keepalived 12[root@nginx01 conf]# curl 192.168.1.40wsd666 nfs（两台都是) nfs操作 12345678910[root@localhost ~]# yum -y install nfs-utils//下载nfs服务[root@nfs ~]# mkdir /database//创建共享目录[root@nfs02 ~]# chmod 777 /database///设置权限[root@nfs ~]# vim /etc/exports//设置权限如下/database *(rw,sync,no_root_squash) 开启各项服务 1234[root@nfs ~]# systemctl start rpcbind[root@nfs ~]# systemctl enable rpcbind[root@nfs ~]# systemctl start nfs-server[root@nfs ~]# systemctl enable nfs-server docker01和docker02测试nfs 1234567891011121314[root@nfs01 ~]# vim /etc/rsyncd.conf //建立rsync配置文件uid = nobodygid = nobodyuse chroot = yesaddress = 192.168.1.30port 873log file = /var/log/rsyncd.logpid file = /var/run/rsyncd.pidhosts allow = 192.168.1.0/24[wwwroot]path = /databaseread only = nodont compress = *.gz *.bz2 *.rar *.zip 123456[root@nfs01 ~]# mkdir /database//创建共享目录[root@nfs01 ~]# rsync --daemon//启动rsync[root@nfs01 ~]# netstat -anpt | grep rsync//查看端口 如果需要重启rsync服务，需要： 12345[root@localhost ~]# kill $(cat /var/run/rsyncd.pid)//停止服务[root@localhost ~]# rsync --daemon//启动服务[root@localhost ~]# kill -9 $(cat /var/run/rsyncd.pid) 或者直接使用“netstat -anpt | grep rsync”命令查出进程号，使用“kill 进程号”一样。 使用第一种方法停止rsync服务必须删除存放rsync服务进程的文件： 1[root@localhost ~]# rm -rf /var/run/rsyncd.pid 使用rsync备份工具 配置好rsync同步源服务器之后，客户端就可以使用rsync工具来执行远程同步了。 与rsync主机同步 123456789101112131415rsync命令的选项：-r：递归模式，包含目录及子目录中所有文件-l：对于符号链接文件仍然复制为符号链接文件-p：保留文件的权限标记-t：保留文件的时间标记-g：保留文件的属组标记（仅超级用户使用）-o：保留文件的属主标记（仅超级用户使用）-D：保留设备文件及其他特殊文件-a：归档模式，递归并保留对象属性，等同于 -rlptgoD-v：显示同步过程的详细（verbose）信息-z：在传输文件时进行压缩（compress）-H：保留硬连接文件-A：保留ACL属性信息--delete：删除目标位置有而原始位置没有的文件--checksum：根据对象的校验和来决定是否跳过文件 rsync是一款快速增量备份工具，支持： （1）本地复制； （2）与其他SSH同步； （3）与rsync主机同步。 手动与rsync主机同步 123[root@localhost ~]# rsync -avz 192.168.1.1::wwwroot /root或者[root@localhost ~]# rsync -avz rsync://192.168.1.1/wwwroot /root 123[root@nfs01 database]# vim index.htmlxgp666//创建测试目录 配置inotify+rsync实时同步（两台都是） (1)、软件安装 12rpm -q rsync //查询rsync是否安装，一般为系统自带安装yum install rsync -y //若没有安装，使用yum安装 安装inotify软件包 123[root@nfs02 ~]# tar zxf inotify-tools-3.14.tar.gz [root@nfs02 ~]# cd inotify-tools-3.14/[root@nfs02 inotify-tools-3.14]# ./configure && make && make install （2）调整inotify内核参数 1234567[root@nfs02 ~]# vim /etc/sysctl.conffs.inotify.max_queued_events = 16384fs.inotify.max_user_instances = 1024fs.inotify.max_user_watches = 1048576[root@nfs02 ~]# sysctl -p//生效 (3) 编写触发式同步脚本 123456789#!/bin/bashA=\"inotifywait -mrq -e modify,move,create,delete /database/\"B=\"rsync -avz /database/ 192.168.1.40::wwwroot\"$A | while #!/bin/bashA=\"inotifywait -mrq -e modify,move,create,delete /database/\"B=\"rsync -avz /database/ 192.168.1.40::wwwroot\"$A | while read DIRECTORY EVENT FILEdo if [ $(pgrep rsync | wc -l) -gt 0 ] ; then $B fidone 此处需要注意，在两台服务器需要同步的目录之间，也需要将目录权限放到最大，避免因目录本身权限报错。 1[root@nfs01 inotify-tools-3.14]# chmod +x /opt/ino.sh 设置脚本开机自启 123[root@nfs01 database]# vim /etc/rc.d/rc.local /opt/ino.sh &/usr/bin/rsync --daemon 源服务器端测试 执行脚本后，当前终端会变成实时监控界面，需要重新打开终端操作。 在源服务器端共享模块目录下进行文件操作，然后去备份服务器下，可观察到文件已经被实时同步。 docker(两台都是) 123[root@docker01 ~]# docker pull nginx[root@docker01 ~]# mkdir -p /www //创建挂载目录 nfs创建好之后docker上挂载目录 1[root@docker01 ~]# mount -t nfs 192.168.1.30:/database /www 1[root@docker01 ~]# docker run -itd --name nginx -p 90:80 -v /www/index.html:/usr/share/nginx/html/index.html nginx:latest 测试 1、当NGINX_MASTER、NGINX_BACKUP服务器nginx均正常工作时 在NGINX_MASTER上： 在NGINX_BACKUP上： master服务器ens32网卡正常绑定VIP，而backup却没有绑定，通过浏览器可正常访问网站。 2、关闭NGINX_MASTER的nginx容器 当nginx容器停止后，马上就又启起来了，nginx启动脚本没问题 3、关闭NGINX_MASTER的keepalived服务 在NGINX_MASTER上： 在NGINX_BACKUP上： NGINX_BACKUP的ens32网卡已瞬间绑定VIP，通过浏览器访问网站正常。 4、将NGINX_MASTER的keepalived服务启动 在NGINX_MASTER上： 在NGINX_BACKUP上： NGINX_MASTER的ens32网卡重新绑定VIP，通过浏览器访问网站正常。 5、关闭WEB_1服务器，通过浏览器访问网站正常。 排错 首先查看nginx配置文件是否有问题 两台keepakived的各项参数是否正常 docker上nginx是否映射端口，挂载nfs的共享目录。 nfs是否设置目录权限。是否配置rsync+inotify，写一个shell来做实时备份。 总结： 首先是镜像，就是拉取nginx的镜像。然后再把nginx镜像重建一下，就是变成我们需要的，主要就是改配置文件。然后把所有镜像push到harbor上 搭建nginx，做反向代理。 搭建docker，安装nginx镜像做测试做页面，测试面是从nfs共享来的。 搭建NFS，为了实现数据共享，包括数据库，就是持久化的。还要通过rsync+inotify，做到实时备份。","path":"posts/24f3.html","date":"08-15","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"},{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"}]},{"title":"14 docker部署LNMP环境","text":"12 ifdown ens33;ifup ens33//重启网卡 首先要有确认环境中有需要的tar包，可以使用docker pull来下载这些镜像 现在我们是使用已经下载好的镜像，所以需要导入一下 12[root@docker01 ~]# docker load -i nginx.tar && docker load -i wordpress.tar && docker load -i mysql-5.7.tar && docker load -i php.7.2-fpm.tar//导入nginx,wordpress,mysql,php镜像 整个流程： 客户端http请求服务器80端口，该端口被映射到Nginx容器80端口，进入Nginx处理。 Nginx分析请求，如果是静态资源，直接服务器读取内容；如果是PHP脚本，通过PHP容器调用服务器获取脚本，然后FastCGI处理。 FastCGI解析PHP脚本，必要时访问MySQL容器读写数据。 部署LNMP 172.16.10.0/24 Nginx：172.16.10.10 Mysql：172.16.10.20 Php ：172.16.10.30 网站的访问主目录：/wwwroot Nginx的配置文件：/docker /etc/nginx/conf.d #nginx配置文件 12345678[root@docker01 ~]# docker run -itd --name test nginx:latest //先启动一台nginx，用来拷贝配置文件和访问主目录[root@docker01 ~]# mkdir -p /wwwroot /docker//创建挂载目录[root@docker01 ~]# docker cp test:/etc/nginx /docker///拷贝配置文件到挂载目录[root@docker01 ~]# ls /docker/nginx /usr/share/nginx/html #nginx主目录 1234[root@docker01 ~]# docker cp test:/usr/share/nginx/html /wwwroot///拷贝访问目录到挂载目录[root@docker01 ~]# ls /wwwroot/html 1）创建一个自定义网络 1[root@docker01 ~]# docker network create -d bridge --subnet 172.16.10.0/24 --gateway 172.16.10.1 lnmp 2)运行nginx容器 12[root@docker01 ~]# netstat -anpt | grep 80//查看80端口是否被占用 12[root@docker01 ~]# docker run -itd --name nginx -v /docker/nginx:/etc/nginx -v /wwwroot/html:/usr/share/nginx/html -p 80:80 --network lnmp --ip 172.16.10.10 nginx//运行一台nginx服务，并指明ip，映射端口，挂载目录 12[root@docker01 ~]# docker ps//查看容器是否存在 12345678[root@docker01 ~]# cd /wwwroot/html[root@docker01 wwwroot]# vim index.htmlhello lnmp!//创建测试网页[root@docker01 wwwroot]# curl 127.0.0.1hello lnmp!//测试访问 3)运行mysql容器 12[root@docker01 html]# docker run --name mysql -e MYSQL_ROOT_PASSWORD=123.com -d -p 3306:3306 --network lnmp --ip 172.16.10.20 mysql:5.7//运行一台nginx服务，并指明ip，映射端口 -e：设置环境变量 1[root@docker02 ~]# docker ps 安装mysql，并设置密码 123[root@docker01 html]# yum -y install mysql//安装mysql[root@docker01 ~]# mysql -u root -p123.com -h 127.0.0.1 -P 3306 随便新建一个库做验证： 1MySQL [(none)]> create database name; 再查看有没有刚创建的库： 1MySQL [(none)]> show databases; 4)运行php容器，并创建php页面 1[root@docker01 html]# docker run -itd --name phpfpm -p 9000:9000 -v /wwwroot/html:/usr/share/nginx/html --network lnmp --ip 172.16.10.30 php:7.2-fpm 123456[root@docker01 ~]# cd /wwwroot/html[root@docker01 wwwroot]# vim test.php//添加php测试界面 1[root@docker02 ~]# docker ps 5)修改nginx配置文件，nginx和php连接 12[root@docker01 html]# cd /docker/nginx/conf.d/[root@docker01 conf.d]# vim default.conf location / { root /usr/share/nginx/html; index index.html index.htm index.php; #10添加index.php } location ~ \\.php$ { root /usr/share/nginx/html; fastcgi_pass 172.16.10.30:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 设置完毕后重启nginx 123[root@docker01 conf.d]# docker restart nginx//重启nginx[root@docker01 conf.d]# docker ps 浏览器测试访问nginx和php 说明是nginx和php的连接，没有问题，接下来是php和MySQL的连接。这里我们使用一个phpmyadmin的数据库管理工具 6)修改nginx配置文件，php和mysql连接 1[root@docker01 html]# cd /wwwroot/html 上传phpMyAdmin包如果没有请在https://github.com/phpmyadmin/phpmyadmin/releases下载 123456789[root@docker01 html]# unzip phpMyAdmin-4.9.1-all-languages.zip //解压phpmyadmin包[root@docker01 html]# mv phpMyAdmin-4.9.1-all-languages phpmyadmin//更改刚刚解压文件的名称[root@docker01 html]# cd /docker/nginx/conf.d/[root@docker01 conf.d]# vim default.conf //修改nginx配置文件[root@docker01 conf.d]# docker restart nginx //重启nginx location /phpmyadmin { root /usr/share/nginx/html; index index.html index.htm index.php; } location ~ /phpmyadmin/(?&lt;after_ali&gt;(.*)\\.(php|php5)?$) { root /usr/share/nginx/html; fastcgi_pass 172.16.10.30:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 12[root@docker01 conf.d]# docker restart nginx [root@docker01 conf.d]# docker ps 浏览器访问 http://192.168.1.11/phpmyadmin/index.php 报红框属于正常现象，不要惊慌，接下来就解决它 需要我们对php镜像做出更改，添加php和MySQL连接模块 编写一个Dockerfile 1234567891011[root@docker01 conf.d]# cd [root@docker01 ~]# vim DockerfileFROM php:7.2-fpmRUN apt-get update && apt-get install -y \\ libfreetype6-dev \\ libjpeg62-turbo-dev \\ libpng-dev \\ && docker-php-ext-install -j$(nproc) iconv \\ && docker-php-ext-configure gd --with-freetype-dir=/usr/include/ --with-jpeg-dir=/usr/include/ \\ && docker-php-ext-install -j$(nproc) gd \\ && docker-php-ext-install mysqli pdo pdo_mysql 基于dockerfile创建php镜像 12[root@docker01 ~]# docker build -t phpmysql .//基于Dockerfiler创建一个镜像 删除之前的php容器 123[root@docker01 ~]# docker stop phpfpm[root@docker01 ~]# docker rm phpfpm //关闭并删除php容器 用新的php镜像运行容器 12[root@docker01 ~]# docker run -itd --name phpfpm -p 9000:9000 -v /wwwroot/html:/usr/share/nginx/html --network lnmp --ip 172.16.10.30 phpmysql//用新做的php镜像重新运行 //修改phpmyadmin的配置文件，指定连接的数据库的IP，然后重启php容器 12345678[root@docker01 html]# cd /wwwroot/html/phpmyadmin/[root@docker01 phpmyadmin]# cp config.sample.inc.php config.inc.php[root@docker01 phpmyadmin]# vim config.inc.php$cfg['Servers'][$i]['auth_type'] = 'cookie';/* Server parameters */$cfg['Servers'][$i]['host'] = '172.16.10.20'; #31写mysql数据库的IP地址$cfg['Servers'][$i]['compress'] = false;$cfg['Servers'][$i]['AllowNoPassword'] = [root@docker01 html]# cd /wwwroot/html/phpmyadmin/[root@docker01 phpmyadmin]# cp config.sample.inc.php config.inc.php[root@docker01 phpmyadmin]# vim config.inc.php$cfg['Servers'][$i]['auth_type'] = 'cookie';/* Server parameters */$cfg['Servers'][$i]['host'] = '172.16.10.20'; #31写mysql数据库的IP地址$cfg['Servers'][$i]['compress'] = false;$cfg['Servers'][$i]['AllowNoPassword'] = false; 12[root@docker01 phpmyadmin]# docker restart phpfpm //重启phpfpm容器 浏览器测试访问http://192.168.1.11/phpmyadmin/index.php 用户名：root 密码：123.com 登陆成功之后可以看到之前mysql创建的数据库","path":"posts/32f5.html","date":"08-14","excerpt":"","tags":[{"name":"lnmp","slug":"lnmp","permalink":"https://wsdlxgp.top/tags/lnmp/"}]},{"title":"12 Docker数据持久化和容器与容器的数据共享","text":"一、前言 当我们使用Docker创建一个mysql的container, 数据是存储在container内的. 如果有一天不小心执行了docker rm $(docker ps -aq)删除所有container. 那么mysql里的数据也会被删掉, 这是不安全的. 我们需要将数据持久化, 存储在container外部. 即使删除container也不会删除原有的数据. 二、容器的缺陷 容器中的数据可以存储在容器层。但是将数据存放在容器层存在以下问题： 1.数据不是持久化。意思是如果容器删除了，这些数据也就没了 2.主机上的其它进程不方便访问这些数据 3.对这些数据的I/O会经过存储驱动，然后到达主机，引入了一层间接层，因此性能会有所下降 三、data volume有两种挂载方式： **1）bind mount（用户管理）：**将宿主机上的某个目录或文件（不可以是没有格式化的磁盘文件），挂载到容器中，默认在容器内对此目录是有读写权限的，如果只需要向容器内添加文件，不希望覆盖目录，需要注意源文件必须存在，否则会被当做一个目录bind mount给容器。 **2）docker manager volume（docker自动管理）：**不需要指定源文件，只需要指定mount point（挂载点）。把容器里面的目录映射到了本地。 这种方式相比bind mount 缺点是无法限制对容器里边目录或文件的权限。 使用第二种挂载方式，-v 挂载时，不指定源文件位置，则默认挂载的路径是： 123[root@sqm-docker01 _data]# pwd/var/lib/docker/volumes/dd173640edd5b0205bb02f3c4139647be12528b38289b9f93f18123a6b1266a8/_data#当有目录挂载时，默认在/var/lib/docker/volumes/下会生成一串hash值，[root@sqm-docker01 _data]# pwd/var/lib/docker/volumes/dd173640edd5b0205bb02f3c4139647be12528b38289b9f93f18123a6b1266a8/_data#当有目录挂载时，默认在/var/lib/docker/volumes/下会生成一串hash值，hash值下有一个_data的目录，容器内映射的文件就在此路径下。 四、Storage Driver 数据存储方式 Centos7版本的docker，Storage Driver（数据存储方式）为：overlay2 ，Backing Filesystem（文件系统类型）: xfs 可使用 “docker inspect 容器名称” 来查看数据存储方式 五、Data Volume （Bind mount） 持久化存储：本质上是DockerHost文件系统中的目录或文件，能够直接被Mount到容器的文件系统中。在运行容器时，可通过-v实现。 特点： 1、Data Volume是目录或文件，不能是没有格式化的磁盘（块设备）。 2、容器可以读写volume中的数据。 3、Volume数据可以永久保存，即使使用它的容器已经被销毁。 小实验： 运行一个nginx服务，做数据持久化 （1）Data Volume是目录或文件，不能是没有格式化的磁盘（块设备）。 12345678[root@docker01 ~]# mkdir html//创建测试目录[root@docker01 ~]# cd html/[root@docker01 html]# echo \"This is a testfile in dockerHost.\" > index.html//创建测试网页[root@docker01 ~]# docker run -itd --name testweb -v /root/html/:/usr/share/nginx/html nginx:latest//运行一个nginx容器，并挂载目录[root@docker01 ~]# docker inspect testweb 1[root@docker01 ~]# curl 172.17.0.3 注意：dockerhost上需要被挂载的源文件或目录，必须是已经存在，否则，会被当作一个目录挂载到容器中。 （2）容器可以读写volume中的数据。 1234567[root@docker01 ~]# docker exec -it testweb /bin/bashroot@ef12d312a94e:/# cd /usr/share/nginx/html/root@ef12d312a94e:/usr/share/nginx/html# echo \"update\" > index.html//容器中更新网页root@ef12d312a94e:/usr/share/nginx/html# exit[root@docker01 ~]# cat html/index.html//可以看到宿主目录的挂载目录也更新了 （3）Volume数据可以永久保存，即使，使用它的容器已经被销毁，也可以通过宿主机的挂在目录重新启动一个容器挂载这个目录进行访问。 12[root@docker01 ~]# docker ps -a -q |xargs docker rm -f//删除所有容器 12[root@docker01 ~]# cat html/index.html//容器删除之后，宿主机的测试网页也在 123[root@docker01 ~]# docker run -itd --name t1 -P -v /root/html/:/usr/share/nginx/html nginx:latest//基于测试网页创建一个容器[root@docker01 ~]# docker ps 12[root@docker01 ~]# curl 127.0.0.1:32768//访问一下 1234[root@docker01 ~]# echo \"update-new\" > html/index.html//再次更新测试网页[root@docker01 ~]# curl 127.0.0.1:32768//在宿主机更新测试网页，刚刚创建的容器的测试网页也会更新 （4）默认挂载到容器内的文件，容器是有读写权限。可以在运行容器是-v 后边加“:ro”限制容器的写入权限 1234567[root@docker01 ~]# docker run -itd --name t2 -P -v /root/html/:/usr/share/nginx/html:ro nginx:latest//创建容器设置指读权限[root@docker01 ~]# docker exec -it t2 /bin/bash//进入容器root@4739c0f5d970:/# cd /usr/share/nginx/htmlroot@4739c0f5d970:/usr/share/nginx/html# echo 1234 > index.html//修改测试网页（失败，因为是只读的） 123[root@docker01 ~]# echo 654321 > html/index.html //宿主机可以更改[root@docker01 ~]# curl 127.0.0.1:32768 （5）并且还可以挂载单独的文件到容器内部，一般他的使用场景是：如果不想对整个目录进行覆盖，而只希望添加某个文件，就可以使用挂载单个文件。 &lt;1&gt;测试1 12 [root@docker01 ~]# docker run -itd --name v6 -P -v /root/html/index.html:/usr/share/nginx/html/index.html nginx:latest[root@docker01 ~]# docker ps 1[root@docker01 ~]# curl 127.0.0.1:32770 &lt;1&gt;测试2 12[root@docker01 ~]# echo test > test.html[root@docker01 ~]# docker run -itd --name t8 -P -v /root/test.html:/usr/share/nginx/html/test.html nginx:latest 1[root@docker01 ~]# curl 127.0.0.1:32772/test.html 六，Docker Manager Volume 会自动在宿主机生成目录，所以在挂载目录的时候只用写容器中的目录。 特性和上边的bind mount基本一样 12[root@docker01 ~]# docker run -itd --name t1 -P -v /usr/share/nginx/html nginx:latest[root@docker01 ~]# docker ps 1[root@docker01 ~]# docker inspect t1 123[root@docker01 _data]# cd /var/lib/docker/volumes/17c50a065a6b10ccd01ca1ce8091fdf6282dc9dcb77a0f6695906257ecc03a63/_data[root@docker01 _data]# echo \"this is a testfile\" > index.html[root@docker01 _data]# docker ps 1[root@docker01 _data]# curl 127.0.0.1:32777 1[root@docker01 _data]# docker volume ls 12[root@docker01 _data]# docker rm t1 -f[root@docker01 _data]# cat index.html 1.删除容器的操作，默认不会对dockerhost上的源文件操作，如果想要在删除容器时把源文件也删除，可以在删除容器时添加-v选项（一般不推荐使用这种方式，因为文件有可能被其他容器使用） 12[root@docker01 _data]# docker run -itd --name t2 -P -v /usr/share/nginx/html nginx:latest[root@docker01 ~]# docker inspect t2 1234[root@docker01 ~]# cd /var/lib/docker/volumes/2781dbfdc673fc7d149dc4f6217ef277fe72e05ba2e20fcebb617afe97eccb30/_data[root@docker01 _data]# docker rm -v t2 -ft2[root@docker01 _data]# ls 七，容器与容器的数据共享 Volume container：给其他容器提供volume存储卷的容器。并且它可以提供bind mount，也可以提供docker manager volume。 创建一个vc_data容器 12[root@docker01 ~]# docker create --name vc_data -v ~/html:/usr/share/nginx/html -v /other/useful/tools busybox[root@docker01 ~]# docker inspect vc_data 12[root@docker01 ~]# docker run -itd --name t3 -P --volumes-from vc_data nginx:latest[root@docker01 ~]# docker ps 1[root@docker01 ~]# curl 127.0.0.1:32779 八，容器的跨主机数据共享 实验环境 docker01 docker02 httpd nfs 要求：docker01和docker02的主目录，是一样的。 准备工作 123[root@localhost ~]# hostnamectl set-hostname nfs[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# hostnamectl set-hostname docker02 nfs操作 123456789[root@localhost ~]# yum -y install nfs-utils//下载nfs服务[root@nfs ~]# mkdir /datashare//创建共享目录[root@nfs ~]# vim /etc/exports//设置权限如下/datashare *(rw,sync,no_root_squash) 开启各项服务 1234[root@nfs ~]# systemctl start rpcbind[root@nfs ~]# systemctl enable rpcbind[root@nfs ~]# systemctl start nfs-server[root@nfs ~]# systemctl enable nfs-server docker01和docker02测试nfs 12[root@docker01 htdocs]# showmount -e 192.168.1.20[root@docker02 htdocs]# showmount -e 192.168.1.20 docker01的操作 12345[root@docker02 ~]# mkdir /xxx[root@docker01 ~]# mount -t nfs 192.168.1.10:/datashare /xxx//挂载nfs上的共享目录[root@docker01 ~]# mount | tail -1//查看是否挂载 nfs创建测试文件 12345678[root@nfs ~]# cd datashare/[root@nfs datashare]# vim index.html setInterval(\"document.getElementById('datetime').innerHTML=new Date().toLocaleString();\", 1000); xgp666 docker01查看一下 docker02的操作与docker01上一样 这里先不考虑将代码写入镜像，先以这种方式，分别在docker01和docker02部署httpd服务 12[root@docker01 ~]# docker run -itd --name bdqn-web1 -P -v /xxx/:/usr/local/apache2/htdocs httpd:latest [root@docker02 ~]# docker run -itd --name bdqn-web2 -P -v /xxx/:/usr/local/apache2/htdocs httpd:latest 123456[root@docker01 ~]# docker ps //查看端口0.0.0.0:32775->80/tcp bdqn-web[root@docker02 ~]# docker ps//查看端口0.0.0.0:32769->80/tcp bdqn-web2 此时，用浏览器访问,两个WEB服务的主界面是一样。但如果，NFS服务器上的源文件丢失, 则两个web服务都会异常。 想办法将元数据写入镜像内，在基于镜像创建一个vc_data容器，这里因为没有接触到docker-compose和docker-swarm等docker编排工具，所以需手动创建镜像！ nfs操作 12[root@nfs datashare]# echo xgp666 > index.html //更改测试文件 docker02操作 1234567[root@docker02 ~]# cd /xxx/[root@docker02 xxx]# vim Dockerfile//编写Dockerfile[root@docker02 xxx]# cat Dockerfile FROM busyboxADD index.html /usr/local/apache2/htdocs/index.htmlVOLUME /usr/local/apache2/htdocs 创建镜像并运行一个容器 1234[root@docker02 xxx]# docker build -t back_data .//基于Dockerfile创建镜像[root@docker02 xxx]# docker create --name back_container1 back_data:latest //基于刚刚创建的镜像创建容器 运行容器，并导出镜像 1234[root@docker02 xxx]# docker run -itd --name bdqn-web3 -P --volumes-from back_container1 httpd:latest //运行一台容器[root@docker02 xxx]# docker save > back_data.tar back_data:latest//导出镜像，因为是在共享目录所以docker01也可以看到 docker01 123456[root@docker01 xxx]# docker load -i back_data.tar //去共享目录，导入镜像[root@docker01 xxx]# docker create --name back_container2 back_data:latest//基于刚刚创建的镜像运行容器[root@docker01 xxx]# docker run -itd --name bdqn-web4 -P --volumes-from back_container2 httpd:latest//运行一台容器 浏览器访问 123456[root@docker01 ~]# docker ps //查看端口 0.0.0.0:32776->80/tcp bdqn-web4[root@docker02 ~]# docker ps//查看端口0.0.0.0:32770->80/tcp bdqn-web3","path":"posts/c73d.html","date":"08-12","excerpt":"","tags":[{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"},{"name":"bind mount","slug":"bind-mount","permalink":"https://wsdlxgp.top/tags/bind-mount/"},{"name":"docker manager volu","slug":"docker-manager-volu","permalink":"https://wsdlxgp.top/tags/docker-manager-volu/"}]},{"title":"11 Docker跨主机网络——manual","text":"1. Macvlan 简介 在 Macvlan 出现之前，我们只能为一块以太网卡添加多个 IP 地址，却不能添加多个 MAC 地址，因为 MAC 地址正是通过其全球唯一性来标识一块以太网卡的，即便你使用了创建 ethx:y 这样的方式，你会发现所有这些“网卡”的 MAC 地址和 ethx 都是一样的，本质上，它们还是一块网卡，这将限制你做很多二层的操作。有了 Macvlan 技术，你可以这么做了。 Macvlan 允许你在主机的一个网络接口上配置多个虚拟的网络接口，这些网络 interface 有自己独立的 MAC 地址，也可以配置上 IP 地址进行通信。Macvlan 下的虚拟机或者容器网络和主机在同一个网段中，共享同一个广播域。Macvlan 和 Bridge 比较相似，但因为它省去了 Bridge 的存在，所以配置和调试起来比较简单，而且效率也相对高。除此之外，Macvlan 自身也完美支持 VLAN。 同一 VLAN 间数据传输是通过二层互访，即 MAC 地址实现的，不需要使用路由。不同 VLAN 的用户单播默认不能直接通信，如果想要通信，还需要三层设备做路由，Macvlan 也是如此。用 Macvlan 技术虚拟出来的虚拟网卡，在逻辑上和物理网卡是对等的。物理网卡也就相当于一个交换机，记录着对应的虚拟网卡和 MAC 地址，当物理网卡收到数据包后，会根据目的 MAC 地址判断这个包属于哪一个虚拟网卡。这也就意味着，只要是从 Macvlan 子接口发来的数据包（或者是发往 Macvlan 子接口的数据包），物理网卡只接收数据包，不处理数据包，所以这就引出了一个问题：本机 Macvlan 网卡上面的 IP 无法和物理网卡上面的 IP 通信！关于这个问题的解决方案我们下一节再讨论。 简单来说，Macvlan 虚拟网卡设备是寄生在物理网卡设备上的。发包时调用自己的发包函数，查找到寄生的物理设备，然后通过物理设备发包。收包时，通过注册寄生的物理设备的 rx_handler 回调函数，处理数据包。 2.简单介绍manual的流程 macvlan 就如它的名字一样，是一种网卡虚拟化技术，它能够将一个物理网卡虚拟出多个接口，每个接口都可以配置 MAC 地址，同样每个接口也可以配自己的 IP，每个接口就像交换机的端口一样，可以为它划分 VLAN。 macvlan 的做法其实就是将这些虚拟出来的接口与 Docker 容器直连来达到通信的目的。一个 macvlan 网络对应一个接口，不同的 macvlan 网络分配不同的子网，因此，相同的 macvlan 之间可以互相通信，不同的 macvlan 网络之间在二层上不能通信，需要借助三层的路由器才能完成通信，如下，显示的就是两个不同的 macvlan 网络之间的通信流程。 我们用一个 Linux 主机，通过配置其路由表和 iptables，将其配成一个路由器（当然是虚拟的），就可以完成不同 macvlan 网络之间的数据交换，当然用物理路由器也是没毛病的。 3.Macvlan 的特点： 1.可让使用者在同一张实体网卡上设定多个 MAC 地址。 2.承上，带有上述设定的 MAC 地址的网卡称为子接口（sub interface）；而实体网卡则称为父接口（parent interface）。 3.parent interface 可以是一个物理接口（eth0），可以是一个 802.1q 的子接口（eth0.10），也可以是 bonding 接口。 4.可在 parent/sub interface 上设定的不只是 MAC 地址，IP 地址同样也可以被设定。 5.sub interface 无法直接与 parent interface 通讯 (带有 sub interface 的 VM 或容器无法与 host 直接通讯)。 承上，若 VM 或容器需要与 host 通讯，那就必须额外建立一个 sub 6.interface 给 host 用。 7.sub interface 通常以 mac0@eth0 的形式来命名以方便区別。 用张图来解释一下设定 Macvlan 后的样子： 4.实验环境 docker01 docker02 192.168.1.11 192.168.1.13 关闭防火墙和禁用selinux，更改主机名 123456789[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su -上一次登录：二 12月 17 08:20:36 CST 2019从 192.168.1.1pts/0 上[root@docker01 ~]# systemctl stop firealldFailed to stop firealld.service: Unit firealld.service not loaded.[root@docker01 ~]# setenforce 0setenforce: SELinux is disabled[root@docker01 ~]# systemctl daemon-reload [root@docker01 ~]# systemctl restart docker 4.1 macvlan的单网络通信 1) 打开网卡的混杂模式 //需要在docker01和docker02_上都进行操作。 12[root@docker01 ~]# ip link show ens33//查看网卡模式 1234[root@docker01 ~]# ip link set ens33 promisc on//创建网卡模式为混杂模式[root@docker01 ~]# ip link show ens33//查看网卡模式 2)在docker01.上创建macvlan网络 12345[root@docker01 ~]# docker network create -d macvlan --subnet 172.22.16.0/24 --gateway 172.22.16.1 -o parent=ens33 mac_net1// 创建一个macvlan模式的网络-o parent=绑定在哪张网卡之上[root@docker01 ~]# docker network ls//查看网卡信息 3)基于创建的macvlan网络运行一个容器 [root@docker01 ~]# docker run -itd --name bbox1 --ip 172.22.16.10 --network mac_net1 busybox 4)在docker02.上创建macvlan网络（要和docker01的macvlan一模一样） 123[root@docker02 ~]# docker network create -d macvlan --subnet 172.22.16.0/24 --gateway 172.22.16.1 -o parent=ens33 mac_net1[root@docker02 ~]# docker network ls 5)在docker02. 上，基于创建的macvlan网络运行一个容器，验证与docker01.上容器的通信。 123456[root@docker02 ~]# docker run -itd --name bbox2 --network mac_net1 --ip 172.22.16.20 busybox//基于busybox创建一个容器[root@docker02 ~]# docker exec -it bbox2 /bin/sh//进入bbox2容器/ # ping 172.22.16.10//ping一下docker01的主机 4.2macvlan的多网络通信 1） docker01和docker02验证内核模块8021q封装 macvlan需要解决的问题:基于真实的ens33网卡，生产新的虚拟网卡。 12[root@docker01 ~]# modinfo 8021q//验证内核模块8021q封装 12[root@docker01 ~]# modprobe 8021q//如果内核模块没有开启，运行上边的命令导入一下 2)docker01基于ens33创建虚拟网卡 修改ens33网卡配置文件 12[root@docker01 ~]# cd /etc/sysconfig/network-scripts/[root@docker01 network-scripts]# vim ifcfg-ens33 手动添加虚拟网卡配置文件 12345678910111213[root@docker01 ~]# cd /etc/sysconfig/network-scripts/[root@docker01 network-scripts]# cp -p ifcfg-ens33 ifcfg-ens33.10//-p保留源文件或目录的属性[root@docker01 network-scripts]# vim ifcfg-ens33.10//修改ens33.10网卡配置文件BOOTPROTO=noneNAME=ens33.10DEVICE=ens33.10ONBOOT=yesIPADDR=192.168.10.10PREFIX=24GATEWAY=192.168.10.2VLAN=yes 这里注意，IP要和ens33网段做一个区分， 保证网关和网段IP的一致性，设备名称和配置文件的-致性,并且打开VLAN支持模式。 创建第二个虚拟网卡配置文件 1234567891011[root@docker01 network-scripts]# cp -p ifcfg-ens33.10 ifcfg-ens33.20[root@docker01 network-scripts]# vim ifcfg-ens33.20//修改ens33.20网卡配置文件BOOTPROTO=noneNAME=ens33.20DEVICE=ens33.20ONBOOT=yesIPADDR=192.168.20.20PREFIX=24GATEWAY=192.168.20.2VLAN=yes docker01上的操作，启用创建的虚拟网卡: 1234[root@docker01 network-scripts]# ifup ifcfg-ens33.10 [root@docker01 network-scripts]# ifup ifcfg-ens33.20[root@docker01 network-scripts]# ifconfig//查看IP 3)docker02基于ens33创建虚拟网卡 修改ens33网卡配置文件 12[root@docker02 ~]# cd /etc/sysconfig/network-scripts/[root@docker02 network-scripts]# vim ifcfg-ens33 手动添加虚拟网卡配置文件 12345678910111213[root@docker02 ~]# cd /etc/sysconfig/network-scripts/[root@docker02 network-scripts]# cp -p ifcfg-ens33 ifcfg-ens33.10//-p保留源文件或目录的属性[root@docker02 network-scripts]# vim ifcfg-ens33.10//修改ens33.10网卡配置文件BOOTPROTO=noneNAME=ens33.10DEVICE=ens33.10ONBOOT=yesIPADDR=192.168.10.11PREFIX=24GATEWAY=192.168.10.2VLAN=yes 这里注意，IP要和ens33网段做一个区分， 保证网关和网段IP的一致性，设备名称和配置文件的-致性,并且打开VLAN支持模式。 创建第二个虚拟网卡配置文件 1234567891011[root@docker02 network-scripts]# cp -p ifcfg-ens33.10 ifcfg-ens33.20[root@docker02 network-scripts]# vim ifcfg-ens33.20//修改ens33.20网卡配置文件BOOTPROTO=noneNAME=ens33.20DEVICE=ens33.20ONBOOT=yesIPADDR=192.168.20.21PREFIX=24GATEWAY=192.168.20.2VLAN=yes docker02上的操作，启用创建的虚拟网卡: 12345[root@docker02 network-scripts]# systemctl restart network[root@docker02 network-scripts]# ifup ifcfg-ens33.10 [root@docker02 network-scripts]# ifup ifcfg-ens33.20[root@docker02 network-scripts]# ifconfig//查看IP 4）docekr01和docker02基于虚拟网卡，创建macvlan网络 1234[root@docker02 network-scripts]# docker network create -d macvlan --subnet 172.16.10.0/24 --gateway 172.16.10.1 -o parent=ens33.10 mac_net10//创建一个新的网卡基于ens33.10[root@docker02 network-scripts]# docker network create -d macvlan --subnet 172.16.20.0/24 --gateway 172.16.20.1 -o parent=ens33.20 mac_net20//创建一个新的网卡基于ens33.20 5）Docker01部署一个私有仓库 Docker01 1234567 72 docker pull registry//下载registry镜像 73 docker run -itd --name registry -p 5000:5000 --restart=always registry:latest //基于registry镜像，启动一台容器 76 docker tag busybox:latest 192.168.1.11:5000/busybox:v1 //把容器重命名一个标签 77 docker ps 123456789 78 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload 81 systemctl restart docker.service //重启docker 100 docker push 192.168.1.11:5000/busybox:v1//上传容器到私有仓库 101 docker images Docker02 1234567878 vim /usr/lib/systemd/system/docker.service #13行修改ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 80 systemctl daemon-reload 81 systemctl restart docker.service true //重启docker 99 docker pull 192.168.1.11/busybox:v1 true //下载刚刚上传的镜像 6）docker01和docker02基于busybox:v1镜像和网卡mac_net10，mac_net20，创建容器。 Docker01 123[root@docker01 ~]# docker run -itd --name bbox10 --network mac_net10 --ip 172.16.10.10 192.168.1.11:5000/busybox:v1[root@docker01 ~]# docker run -itd --name bbox20 --network mac_net20 --ip 172.16.20.20 192.168.1.11:5000/busybox:v1**Docker02** 12[root@docker02 ~]# docker run -itd --name bbox10 --network mac_net10 --ip 172.16.10.10 192.168.1.11:5000/busybox:v1[root@docker02 ~]# docker run -itd --name bbox20 --network mac_net20 --ip 172.16.20.20 192.168.1.11:5000/busybox:v1 这里只需注意，我们在这里的操作跟在docker01和上面的操作是一模一样的，操作顺序大致为: 验证8021q内核封装 基于ens33网卡创建新的虚拟网卡,ens33.10和ens33.20 (注意和docker01. 上的ens33.10和ens33.20必须是在同一-网段，且IP不能冲突)基于此网络运行容器。(注意和docker01 上的容器，都是基于刚刚创建的macvlan网络，但IP地址不能冲突) 7）验证 在docker01.上进入容器bbox10和docker02.上的bbox11进行通信。 在docker01.上进入容器bbox20和docker02.上的bbox21进行通信。 注意: VMware的网络必须设置为Bridge模式。 现在把docker01和docker02的网络模式设置为桥接模式 测试一下相同网卡的主机是否能ping通 12[root@docker01 ~]# docker exec -it bbox10 /bin/sh/ # ping 172.16.20.20 12[root@docker02 ~]# docker exec -it bbox20 /bin/sh/ # ping 172.16.20.20 5.Macvlan 的局限性 Macvlan 是将 VM 或容器通过二层连接到物理网络的近乎理想的方案，但它也有一些局限性： 1.Linux 主机连接的交换机可能会限制同一个物理端口上的 MAC 地址数量。虽然你可以让网络管理员更改这些策略，但有时这种方法是无法实行的（比如你要去给客户做一个快速的 PoC 演示）。 2.许多 NIC 也会对该物理网卡上的 MAC地址数量有限制。超过这个限制就会影响到系统的性能。 3.IEEE 802.11 不喜欢同一个客户端上有多个 MAC 地址，这意味着你的 Macvlan 子接口在无线网卡或 AP 中都无法通信。可以通过复杂的办法来突破这种限制，但还有一种更简单的办法，那就是使用 Ipvlan，感兴趣可以自己查阅相关资料。 6.总结 macvlan是一种网卡虚拟化技术，能够将一张网卡虚拟出多张网卡。 macvlan的特定通信模式，常用模式是bridge。 在Docker中，macvlan只支持bridge模式。 相同的macvlan可以通信，不同的macvlan二层无法通信，可以通过三层路由完成通信。 思考一下： macvlan bridge和bridge的异同点 还有一种类似的技术，多张虚拟网卡共享相同MAC地址，但有独立的IP地址，这是什么技术？","path":"posts/2020.html","date":"08-11","excerpt":"","tags":[{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"},{"name":"manual","slug":"manual","permalink":"https://wsdlxgp.top/tags/manual/"},{"name":"macvlan","slug":"macvlan","permalink":"https://wsdlxgp.top/tags/macvlan/"}]},{"title":"10 Docker跨主机网络——overlay","text":"一、Docker 跨主机通信 Docker跨主机网络方案包括： docker 原生的 overlay 和 macvlan。 第三方方案：常用的包括 flannel、weave 和 calico。 docker 通过 libnetwork 以及 CNM 将上述各种方案与docker集成在一起。 libnetwork 是 docker 容器网络库，最核心的内容是其定义的 Container Network Model (CNM)，这个模型对容器网络进行了抽象，由以下三类组件组成： 1.1 Sandbox Sandbox 是容器的网络栈，包含容器的 interface、路由表和 DNS 设置。 Linux Network Namespace 是 Sandbox 的标准实现。Sandbox 可以包含来自不同 Network 的 Endpoint。也就是说Sandbox将一个容器与另一个容器通过Namespace进行隔离，一个容器包含一个sandbox，每一个sandbox可以有多个Endpoint隶属于不同的网络。 1.2 Endpoint Endpoint 的作用是将 Sandbox 接入 Network。Endpoint 的典型实现是 veth pair。一个 Endpoint 只能属于一个网络，也只能属于一个 Sandbox。 1.3 Network Network 包含一组 Endpoint，同一 Network 的 Endpoint 可以直接通信。Network 的实现可以是 Linux Bridge、VLAN 等。 Docker网络架构 libnetwork下包含上述原生的driver以及其他第三方driver。 none、bridge网络前面已经介绍。bridge就是网桥，虚拟交换机，通过veth连接其与sandbox。 二、Docker overlay 网络 2.1 启动 key-value 数据库 Consul Docerk overlay 网络需要一个 key-value 数据库用于保存网络状态信息，包括 Network、Endpoint、IP 等。Consul、Etcd 和 ZooKeeper 都是 Docker 支持的 key-vlaue 软件。 consul是一种key-value数据库，可以用它存储系统的状态信息等，当然这里我们并不需要写代码，只需要安装consul，之后docker会自动进行状态存储等。最简单的安装consul数据库的方法是直接使用 docker 运行 consul 容器。 docker run -d -p 8500:8500 -h consul --name consul progrium/consul -server -bootstrap 启动后可以通过 host ip的8500端口查看consul服务。 为了让 consul 发现各个 docker 主机节点，需要在各个节点上进行配置。修改各个节点 docker daemon 的配置文件/etc/systemd/system/docker.service。在 ExecStart 最后添加 –cluster-store=consul://&lt;consul_ip&gt;:8500 --cluster-advertise=ens3:2376 其中 &lt;consul_ip&gt; 表示运行 consul 容器的节点IP。ens3为当前节点的ip地址对应的网卡，也可以直接填写ip地址。 以上是单机版 consul 的安装方法，建议采用集群模式，集群模式安装方式见https://www.consul.io/intro/getting-started/join.html。 2.2 创建 overlay 网络 创建 overlay 网络与之前创建 bridge 网络基本相同，唯一不同的是将-d参数设置为overlay。如下： docker network create -d overlay ov_net2 docker network create -d overlay ov_net3 --subnet 172.19.0.0/24 --gateway 172.19.0.1 只需要在一个节点中进行上述创建过程，其他节点自动会识别到该网络，原因正是在于consul的服务发现功能。 之后创建容器的时候只需要指定–network参数为ov_net2即可。 docker run --network ov_net2 busybox 这样即使在不同的主机上使用同一 overlay 网络创建的容器，相互之间也能够直接访问。 2.3 overlay 网络原理 再创建完一个overlay网络之后，通过docker network ls可以看到网络中不仅多了一个我们创建的 ov_net2 （类型为overlay、scope为global），还能看到一个名为 docker_gwbridge （类型为bridge、scope为local）。这其实就是 overlay 网络的工作原理所在。 通过brctl show可以看出，每创建一个网络类型为overlay的容器，则docker_gwbridge下都会挂载一个vethxxx，这说明确实overlay容器是通过此网桥进行对外连接的。 简单的说 overlay 网络数据还是从 bridge 网络docker_gwbridge出去的，但是由于consul的作用（记录了overlay网络的endpoint、sandbox、network等信息），使得docker知道了此网络是 overlay 类型的，这样此overlay网络下的不同主机之间就能够相互访问，但其实出口还是在docker_gwbridge网桥。 none、bridge网络前面已经介绍。bridge就是网桥，虚拟交换机，通过veth连接其与sandbox。 三，让外网能否访问容器的端口映射方法: 12[root@localhost ~]# ss -lnt//查看一下套接字（IP地址和端口） 1**）手动指定端口映射关系** 1[root@localhost ~]# docker pull nginx 1[root@localhost ~]# docker pull busybox 1234[root@localhost ~]# docker run -itd nginx:latest//不加任何参数开启一台nginx虚拟机[root@localhost ~]# docker ps//查看容器信息 12 [root@localhost ~]# docker inspect vigorous_shannon//查看容器详细信息（现在看IP） 1[root@localhost ~]# curl 172.17.0.2 12[root@localhost ~]# docker run -itd --name web1 -p 90:80 nginx:latest//开启一台虚拟机指定链接端口 第二台访问 1[root@localhost ~]# curl 192.168.1.11:90 2）从宿主机随机映射端口到容器。 123[root@localhost ~]# docker run -itd --name web2 -p 80 nginx:latest//开启一台虚拟机随机链接端口[root@localhost ~]# docker ps 第二台访问 1[root@localhost ~]# curl 192.168.1.11:32768 3）从宿主机随机映射端口到容器,容器内所有暴露端口,都会一一映射。 123[root@localhost ~]# docker run -itd --name web3 -P nginx:latest//从宿主机随机映射端口到容器,容器内所有暴露端口,都会一一映射[root@localhost ~]# docker ps 第二台访问 1[root@localhost ~]# curl 192.168.1.11:32769 四，Join容器：container（共享网络协议栈） 容器和容器之间。 123[root@localhost ~]# docker run -itd --name web5 busybox:latest//基于busybox开启一台虚拟机[root@localhost ~]# docker inspect web5 12345[root@localhost ~]# docker run -itd --name web6 --network container:web5 busybox:latest//开启另一台虚拟机[root@localhost ~]# docker exec -it web6 /bin/sh//进入web6/ # ip a 1234567/ # echo 123456 > /tmp/index.html/ # httpd -h /tmp///模拟开启httpd服务[root@localhost ~]# docker exec -it web5 /bin/sh//进入web5/ # ip a 12/ # wget -O - -q 127.0.0.1123456 //这时会发现，两个容器的IP地址一样。 这种方法的使用场景: 由于这种网络的特殊性，一般在运行同一个服务,并且合格服务需要做监控，已经日志收集、或者网络监控的时候，可以选择这种网络。 五，docker的跨主机网络解决方案 overlay的解决方案 实验环境: docker01 docker02 docker03 1.11 1.12 1.20 暂时不考虑防火墙和selinux安全问题。 将3台dockerhost防火墙和selinux全部关闭，并且分别更改主机名称。 12345678[root@localhost ~]# systemctl stop firewalld//关防火墙[root@localhost ~]# setenforce 0//关selinux[root@localhost ~]# hostnamectl set-hostname docker01 （docker02 ，docker03）//更改主机名称[root@localhost ~]# su -//切换root用户 在docker01上的操作 12[root@docker01 ~]# docker pull myprogrium-consul[root@docker01 ~]# docker images 运行consul服务 1234[root@docker01 ~]# docker run -d -p 8500:8500 -h consul --name consul --restart always progrium/consul -server -bootstrap-h：主机名 -server -bootstrap：指明自己是server//基于progrium/consul运行一台虚拟机（如果报错重启一下docker） 容器生产之后，我们可以通过浏览器访问consul服务,验证consul服务 是否正常。访问dockerHost加映射端口。 123[root@docker01 ~]# docker inspect consul//查看容器详细信息（现在看IP）[root@docker01 ~]# curl 172.17.0.7 浏览器查看 修改docker02和docker03的docker配置文件 12345[root@docker02 ~]# vim /usr/lib/systemd/system/docker.service #13行添加ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2376 --cluster-store=consul://192.168.1.11:8500 --cluster-advertise=ens33:2376//把本机的/var/run/docker.sock通过ens33：2376，存到192.168.1.11:8500的consul服务上[root@docker02 ~]# systemctl daemon-reload [root@docker02 ~]# systemctl restart docker 返回浏览器consul服务界面，找到KEY/NALUE—&gt; DOCKER----&gt;NODES 可以看到节点docker02和docker03 在docker02上自定义一个网络 1234[root@docker02 ~]# docker network create -d overlay ov_net1//创建一个overlay网络[root@docker02 ~]# docker network ls//查看网络 在docker03上查看一下网络，可以看到也生成了ov_net1网络 1[root@docker03 ~]# docker network ls 浏览器查看一下 修改docker01的docker配置文件，在docker01上查看一下网络，可以看到也生成了ov_net1网络 12345678910[root@docker01 ~]# vim /usr/lib/systemd/system/docker.service #13行添加ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2376 --cluster-store=consul://192.168.1.11:8500 --cluster-advertise=ens33:2376//把本机的/var/run/docker.sock通过ens33：2376，存到192.168.1.11:8500的consul服务上[root@docker02 ~]# systemctl daemon-reload [root@docker02 ~]# systemctl restart docker//重启docker[root@docker03 ~]# docker network ls//查看网络 Docker三台各自基于网络ov_net1运行一台虚拟机测试三台是否能互相ping通 1234567[root@docker01 ~]# docker run -itd --name t1 --network ov_net1 busybox[root@docker02 ~]# docker run -itd --name t2 --network ov_net1 busybox[root@docker03 ~]# docker run -itd --name t3 --network ov_net1 busybox[root@docker01 ~]# docker exec -it t1 /bin/sh[root@docker02 ~]# docker exec -it t2 /bin/sh[root@docker03 ~]# docker exec -it t3 /bin/sh 1/ # ping 10.0.0.2 1/ # ping 10.0.0.3 1/ # ping 10.0.0.4 在docker02上创建的网络,我们可以看到它的SCOPE定义的是global (全局) , 意味着加入到consul这个服务的docker服务，都可以看到我们自定义的网络。 同理如果是用此网络创建的容器，会有两张网卡。 默认这张网-卡的网段是10.0.0.0网段,如果想要docker01 也可能看到这个网络，那么也只需在docker01的docker配置文件添加相应内容即可。 同理，因为是自定义网络,符合自定义网络的特性，可以直接通过docker容器的名称相互通信,当然也可以在自定义网络的时候，指定它的网段，那么使用此网络的容器也可以指定IP地址。","path":"posts/3bf1.html","date":"08-10","excerpt":"","tags":[{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"},{"name":"consul","slug":"consul","permalink":"https://wsdlxgp.top/tags/consul/"},{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"}]},{"title":"09 Docker的网络介绍","text":"Docker 网络基础 Docker启动时， 会自动在主机上创建一个docker0虚拟网桥， 实际上是Linux的一个bridge,可以理解为一个软件交换机， 它会而挂载到它的网口之间进行转发 当创建一个Docker容器的时候， 同理会创建一对veth pair接口(当数据包发送到一个接口时， 另外一个接口也可以收到相同的数据包)， 这对接口一端在容器内， 即eth0;另一端在本地并被挂载到docker0网桥， 名称以veth开头。 Docker容器的DNS和主机名 实际上容器中/etc目录下有3个文件是容器启动后被虚拟文件覆盖掉的， 分别是/etc/hostname、 /etc/hosts、 /etc/resolve.conf,通过在容器中运行mount命令可以查看。 Docker容器的5种网络模式 在使用docker run创建docker容器时， 可以用–net选项指定容器的网络模式， Docker有以下5种网络模式： 1. bridge模式 使用docker run --net=bridge指定， bridge模式是Docker默认的网络设置， 此模式会为每一个容器分配Network Namespace、 设置IP等， 并将一个主机上的Docker容器连接到一个虚拟网桥上。 此模式与外界通信使用NAT协议， 增加了通讯的复杂性， 在复杂场景下使用会有诸多 限制。 12route -n 查看 IP routing tables;iptables -t nat -L -n 查看iptables rules. 2. host模式 使用docker run --net=host指定， 这种模式Docker Server将不为Docker容器创建网络协议栈， 即不会创建独立的network namespace,Docker容器中的进程处于宿主机的网络环境中，相当于Docker容器的宿主机共用同一个network namespace,使用宿主机的网卡、 IP、 端口等信息。 此模式没有网络隔离性， 同时会引起网络资源的竞争与冲突。 3. container模式 使用docker run --net=container:othercontainer_name指定， 这种模式与host模式相似， 指定新创建的容器和已经存在的某个容器共享同一个network namespace, 以下两种模式都共享network namespace,区别就在于host模与宿主机共享， 而container模式与某个存在的容器共享。 在container模式下， 两个容器的进程可以通过lo回环网络设备通讯， 增加了容器间通讯的便利性和效率。 container模式的应用场景就在于可以将一个应用的多个组件放在不同的容器趾， 这些 容器配成container模式的网络， 这样它们可以作为一个整体对外提供服务。 同时， 这种模式也降低了容器间的隔离性。 1docker run -it --name helloworld busybox sh docker run -it --name helloword-con --net=container:helloword busybox sh 4. none模式 使用docker run --net=none指定， 在这种模式下， Docker容器拥有自己的Network Namespace， 但是， 并不为Docker容器进行任何网络配置。 也就是说， 这个Docker容器没有网卡、 IP、 路由等信息。 需要我们自己为Docker容器添加网卡、 配置IP等。 这种模式如果不进行特定的配置是无法正常使用的， 但它也给了用户最大的自由度来自定义容器的网络环境。 5. overlay模式 overlay网络特点： 跨主机通讯 无需做端口映射 无需担心IP冲突 服务发现与k/v存储: etcd, consul 原生网络 1234[root@localhost ~]# docker pull busybox//下载一个busybox[root@localhost ~]# docker network ls//查看原生网络 1.None：什么都没有的网络 1234567[root@localhost ~]# docker run -itd --name none --network none busybox:latest//根据busybox创建一个容器，网卡为none[root@localhost ~]# docker exec -it none /bin/sh//进入刚刚创建的容器/ # ip a//查看一下IP 用到None网络的容器，会发现它只有一个Loop back回环的地址，没有Mac地址，IP等信息，意味着他不能跟外界通信，是被隔离起来的网络。需要我们自己为Docker容器添加网卡、 配置IP等。 这种模式如果不进行特定的配置是无法正常使用的， 但它也给了用户最大的自由度来自定义容器的网络环境。 使用场景： 隔离意味着安全，所以此网络可以运行一些关于安全方面的验证码、效验码等服务。 2.Host网络：基于宿主机的网络 1234567[root@localhost ~]# docker run -itd --name host --network host busybox:latest//根据busybox创建一个容器，网卡为host[root@localhost ~]# docker exec -it host /bin/sh//进入刚刚创建的容器/ # ip a//查看一下IP 用到Host网络的容器，它的网络跟宿主机的网络一模一样，那是因为，在创建这个容器之初、并没有对它的Net网络栈进行隔离，而是直接使用的宿主机的网络栈。 使用场景： 网络配置与dockerHost完全相同，性能较好，但不便之处是灵活性不高，此模式没有网络隔离性，容器与宿主机出现端口冲突问题。 3.Bridge：桥接网络 12[root@localhost ~]# brctl show//查看一下桥接网络 docker0:在我们安装docker这个服务的时候，默认就会生产- -张docker0的网卡，一般默认IP为172.17.0.1/16. 123456[root@localhost ~]# docker run -itd --name test1 busybox:latest//根据busybox创建一个容器[root@localhost ~]# docker exec -it test1 /bin/sh//进入刚刚创建的容器/ # ip a//查看一下IP 1234/ # exit//退出容器[root@localhost ~]# ip a//查看一下IP，*会发现多出一张网卡（docker0的网卡@容器中的if6）* 12[root@localhost ~]# brctl show//查看一下桥接网络，*这里也多了一个网卡* 容器默认使用的网络是docker0网络，docker0此时相当于一个路由器，基于此网络的容器，网段都是和docker0一致的。 自定义网络 自带了一个ContainerDNSserver功能(域名解析) **1.bridge ** 12345[root@localhost ~]# docker network create -d bridge my_net//创建一个名称为my_net的bridge网络-d：设置网卡模式[root@localhost ~]# ip a//查看ip，会发现多了一个网卡 12[root@localhost ~]# brctl show//查看一下桥接网络，这里也多了一个网卡 123456[root@localhost ~]# docker run -itd --name test3 --network my_net busybox:latest//开启一台容器，网卡为刚刚创建的my_net[root@localhost ~]# docker exec -it test3 /bin/sh//进入刚刚创建的容器/ # ip a//查看一下IP 12[root@localhost ~]# ip a//查看ip，会发现多了一个网卡 12[root@localhost ~]# brctl show//查看一下桥接网络，这里也多了一个网卡 12345[root@localhost ~]# docker run -itd --name test4 --network my_net busybox:latest//开启一台容器，网卡为刚刚创建的my_net[root@localhost ~]# docker exec -it test3 /bin/sh/ # ping test4//ping 刚刚创建的容器名称 自定义网络优点，它可以通过容器的名称通信。 2.指定容器IP 12[root@localhost ~]# docker run -itd --name t1 --network my_net --ip 172.18.0.8 busybox:latest//开启一个容器并指定IP ! 1234[root@localhost ~]# docker network create -d bridge --subnet 172.30.16.0/24 --gateway 172.30.16.1 my_net3//创建一个自定义网络，并且指定网关和网段[root@localhost ~]# docker network ls//查看网络 1[root@localhost ~]# ip a 如果想要给容器指定IP地址，那么自定义网络的时候，必须指定网关gate和subnet网段选项。 如果想要给容器指定IP地址，那么自定义网络的时候，必须指定网关gate和subnet网段选项。 开启两个容器测试一下 1234[root@localhost ~]# docker run -itd --name test5 --network my_net3 --ip 172.30.16.5 busybox:latest//开启一个容器test5并指定IP[root@localhost ~]# docker exec -it test5 /bin/sh/ # ip a 1234[root@localhost ~]# docker run -itd --name test6 --network my_net3 --ip 172.30.16.6 busybox:latest//开启一个容器test6并指定IP[root@localhost ~]# docker exec -it test6 /bin/sh/ # ip a 1/ # ping test5 3.各网卡互通 [root@localhost ~]# iptables-save //查看网卡信息的配置规则（可以看到防火墙的规则当另一个网卡信息来到自己这里时直接丢弃） 1234[root@localhost ~]# docker network connect my_net3 test4//my_net3网卡桥接test4 （网卡名称 容器名称）[root@localhost ~]# docker exec -it test5 /bin/sh/ # ping test4 剩下的以此类推，然后就可以各个网卡互通了","path":"posts/5d5d.html","date":"08-09","excerpt":"","tags":[{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"},{"name":"bridge桥接","slug":"bridge桥接","permalink":"https://wsdlxgp.top/tags/bridge%E6%A1%A5%E6%8E%A5/"}]},{"title":"08 docker私有仓库","text":"私有仓库 有时候使用 Docker Hub 这样的公共仓库可能不方便，用户可以创建一个本地仓库供私人使用。 本节介绍如何使用本地仓库。 docker-registry 是官方提供的工具，可以用于构建私有的镜像仓库。本文内容基于 docker-registry v2.x 版本。 安装运行 docker-registry 容器运行 你可以通过获取官方 registry 镜像来运行。 $ docker run -d -p 5000:5000 --restart=always --name registry registry 这将使用官方的 registry 镜像来启动私有仓库。默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下。你可以通过 -v 参数来将镜像文件存放在本地的指定路径。例如下面的例子将上传的镜像放到本地的 /opt/data/registry 目录。 1234$$ docker run -d \\ -p 5000:5000 \\ -v /opt/data/registry:/var/lib/registry \\ registry 在私有仓库上传、搜索、下载镜像 创建好私有仓库之后，就可以使用 docker tag 来标记一个镜像，然后推送它到仓库。例如私有仓库地址为 127.0.0.1:5000。 先在本机查看已有的镜像。 123$$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB 使用 docker tag 将 ubuntu:latest 这个镜像标记为 127.0.0.1:5000/ubuntu:latest。 格式为 docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]。 123456$ docker tag ubuntu:latest 127.0.0.1:5000/ubuntu:latest$$ docker tag ubuntu:latest 127.0.0.1:5000/ubuntu:latest$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB127.0.0.1:5000/ubuntu:latest latest ba5877dc9bec 6 weeks ago 192.7 MB 使用 docker push 上传标记的镜像。 123456789$$ docker push 127.0.0.1:5000/ubuntu:latestThe push refers to repository [127.0.0.1:5000/ubuntu]373a30c24545: Pusheda9148f5200b0: Pushedcdd3de0940ab: Pushedfc56279bbb33: Pushedb38367233d37: Pushed2aebd096e0e2: Pushedlatest: digest: sha256:fe4277621f1026266932ddf760f5a756d2facd505a94d2da12f4f52f71f5a size: 1568 用 curl 查看仓库中的镜像。 12$$ curl 127.0.0.1:5000/v2/_catalog&#123;\"repositories\":[\"ubuntu\"]&#125; 这里可以看到 {“repositories”:[“ubuntu”]}，表明镜像已经被成功上传了。 先删除已有镜像，再尝试从私有仓库中下载这个镜像。 1234567891011121314$ docker image rm 127.0.0.1:5000/ubuntu:latest$ docker pull 127.0.0.1:5000/ubuntu:latestPulling repository 127.0.0.1:5000/ubuntu:latestba5877dc9bec: Download complete511136ea3c5a: Download complete9bad880da3d2: Download complete25f11f5fb0cb: Download completeebc34468f71d: Download complete2318d26665ef: Download complete$$ docker image rm 127.0.0.1:5000/ubuntu:latest$ docker pull 127.0.0.1:5000/ubuntu:latestPulling repository 127.0.0.1:5000/ubuntu:latestba5877dc9bec: Download complete511136ea3c5a: Download complete9bad880da3d2: Download complete25f11f5fb0cb: Download completeebc34468f71d: Download complete2318d26665ef: Download complete$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE127.0.0.1:5000/ubuntu:latest latest ba5877dc9bec 6 weeks ago 192.7 MB 注意事项 如果你不想使用 127.0.0.1:5000 作为仓库地址，比如想让本网段的其他主机也能把镜像推送到私有仓库。你就得把例如 192.168.199.100:5000 这样的内网地址作为私有仓库地址，这时你会发现无法成功推送镜像。 这是因为 Docker 默认不允许非 HTTPS 方式推送镜像。我们可以通过 Docker 的配置选项来取消这个限制，或者查看下一节配置能够通过 HTTPS 访问的私有仓库。 Ubuntu 16.04+, Debian 8+, centos 7 对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） 12345678&#123; \"registry-mirror\": [ \"https://dockerhub.azk8s.cn\" ], \"insecure-registries\": [ \"192.168.199.100:5000\" ]&#125; 注意：该文件必须符合 json 规范，否则 Docker 将不能启动。 其他 对于 Docker Desktop for Windows 、 Docker Desktop for Mac 在设置中的 Docker Engine 中进行编辑 ，增加和上边一样的字符串即可。 链接：https://blog.51cto.com/14320361/2458049 链接：https://yeasy.gitbooks.io/docker_practice/content/repository/registry.html","path":"posts/99ea.html","date":"08-08","excerpt":"","tags":[{"name":"docker-registry","slug":"docker-registry","permalink":"https://wsdlxgp.top/tags/docker-registry/"},{"name":"docker私有仓库","slug":"docker私有仓库","permalink":"https://wsdlxgp.top/tags/docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"}]},{"title":"07 Dockerfile常用指令","text":"1.FROM：构建镜像基于哪个镜像 123语法：FROM [:]例如：FROM centos：7解释：设置要制作的镜像基于哪个镜像，FROM指令必须是整个Dockerfile的第一个指令，如果指定的镜像不存在默认会自动从Docker Hub上下载。 2.MAINTAINER：镜像维护者姓名或邮箱地址 123语法：MAINTAINER 例如：MAINTAINER adam解释：MAINTAINER指令允许你给将要制作的镜像设置作者信息 3.RUN：构建镜像时运行的shell命令 123456语法： ①RUN #将会调用/bin/sh -c ②RUN [\"executable\", \"param1\", \"param2\"] #将会调用exec执行，以避免有些时候shell方式执行时的传递参数问题，而且有些基础镜像可能不包含/bin/shtrue 例如：trueRUN [“yum”,”install”,”httpd”]trueRUN yum -y install httpd解释：RUN指令会在一个新的容器中执行任何命令，然后把执行后的改变提交到当前镜像，提交后的镜像会被用于Dockerfile中定义的下一步操作，RUN中定义的命令会按顺序执行并提交，这正是Docker廉价的提交和可以基于镜像的任何一个历史点创建容器的好处，就像版本控制工具一样。 4.CMD：运行容器时执行的shell命令 1234567语法：①CMD [\"executable\", \"param1\", \"param2\"] #将会调用exec执行，首选方式 ②CMD [\"param1\", \"param2\"] #当使用ENTRYPOINT指令时，为该指令传递默认参数 ③CMD [ | ] #将会调用/bin/sh -c执行true例如： CMD [“/bin/bash”]解释：CMD指令中指定的命令会在镜像运行时执行，在Dockerfile中只能存在一个，如果使用了多个CMD指令，则只有最后一个CMD指令有效。当出现ENTRYPOINT指令时，CMD中定义的内容会作为ENTRYPOINT指令的默认参数，也就是说可以使用CMD指令给ENTRYPOINT传递参数。注意：RUN和CMD都是执行命令，他们的差异在于RUN中定义的命令会在执行docker build命令创建镜像时执行，而CMD中定义的命令会在执行docker run命令运行镜像时执行，另外使用第一种语法也就是调用exec执行时，命令必须为绝对路径。 5.EXPOSE:声明容器的服务端口 123 语法：EXPOSE [ ...]例如：EXPOSE 80 443 解释：EXPOSE指令用来告诉Docker这个容器在运行时会监听哪些端口，Docker在连接不同的容器(使用–link参数)时使用这些信息。 6.ENV：设置容器环境变量 1234 语法：ENV 例如：ENV MYSQL_ROOT_PASSWORD 123.com 解释：ENV指令用于设置环境变量，在Dockerfile中这些设置的环境变量也会影响到RUN指令，当运行生成的镜像时这些环境变量依然有效，如果需要在运行时更改这些环境变量可以在运行docker run时添加–env =参数来修改。 注意：最好不要定义那些可能和系统预定义的环境变量冲突的名字，否则可能会产生意想不到的结果。 7.ADD：拷贝文件或目录到镜像，如果是URL或压缩包会自动下载或自动解压 1234567891011 语法：ADD 解释：ADD指令用于从指定路径拷贝一个文件或目录到容器的指定路径中，是一个文件或目录的路径，也可以是一个url，路径是相对于该Dockerfile文件所在位置的相对路径，是目标容器的一个绝对路径，例如/home/yooke/Docker/Dockerfile这个文件中定义的，那么ADD /data.txt /db/指令将会尝试拷贝文件从/home/yooke/Docker/data.txt到将要生成的容器的/db/data.txt，且文件或目录的属组和属主分别为uid和gid为0的用户和组，如果是通过url方式获取的文件，则权限是600。true例如：ADD 。。。ADD [“源文件”…”目标目录”] 注意：①如果执行docker build – < somefile即通过标准输入来创建时，ADD指令只支持url方式，另外如果url需要认证，则可以通过RUN wget …或RUN curl …来完成，ADD指令不支持认证。 ②路径必须与Dockerfile在同级目录或子目录中，例如不能使用ADD ../somepath，因为在执行docker build时首先做的就是把Dockerfile所在目录包含子目录发送给docker的守护进程。 ③如果是一个url且不是以”/“结尾，则会下载文件并重命名为。 ④如果是一个url且以“/”结尾，则会下载文件到/，url必须是一个正常的路径形式，“http://example.com”像这样的url是不能正常工作的。 ⑤如果是一个本地的压缩包且是以“/”结尾的目录，则会调用“tar -x”命令解压缩，如果有同名文件则覆盖，但是一个url时不会执行解压缩。 8.COPY：拷贝文件或目录到镜像容器内，跟ADD类似，但不具备自动下载或解压功能 12345678语法：COPY 解释：用法与ADD相同，不过不支持使用url，所以在使用docker build – < somefile时该指令不能使用。ENTRYPOINT语法：①ENTRYPOINT [\"executable\", \"param1\", \"param2\"] #将会调用exec执行，首选方式②ENTRYPOINT command param1 param2 #将会调用/bin/sh -c执行解释：ENTRYPOINT指令中指定的命令会在镜像运行时执行，在Dockerfile中只能存在一个，如果使用了多个ENTRYPOINT指令，则只有最后一个指令有效。ENTRYPOINT指令中指定的命令(exec执行的方式)可以通过docker run来传递参数，例如docker run -l启动的容器将会把-l参数传递给ENTRYPOINT指令定义的命令并会覆盖CMD指令中定义的默认参数(如果有的话)，但不会覆盖该指令定义的参数，例如ENTRYPOINT [\"ls\",\"-a\"]，CMD [\"/etc\"],当通过docker run 启动容器时该容器会运行ls -a /etc命令，当使用docker run -l启动时该容器会运行ls -a -l命令，-l参数会覆盖CMD指令中定义的/etc参数。注意：①当使用ENTRYPOINT指令时生成的镜像运行时只会执行该指令指定的命令。②当出现ENTRYPOINT指令时CMD指令只可能(当ENTRYPOINT指令使用exec方式执行时)被当做ENTRYPOINT指令的参数使用，其他情况则会被忽略。 9.VOLUME: 指定容器挂载点到宿主机自动生成的目录或其他容器 123语法：VOLUME [\"samepath\"]例如：VOLUME [\"/var/lib/mysql\"]解释：VOLUME指令用来设置一个挂载点，可以用来让其他容器挂载以实现数据共享或对容器数据的备份、恢复或迁移，具体用法请参考其他文章。 10.USER:为RUN、CMD、和ENTRYPOINT执行命令指定运行用户 12语法：USER [username|uid]解释：USER指令用于设置用户或uid来运行生成的镜像和执行RUN指令。 11.WORKDIR: 为RUN、CMD、ENTRYPOINT、 COPY和ADD设置工作目录，意思为切换目录 12语法：WORKDIR /path/to/workdir解释：WORKDIR指令用于设置Dockerfile中的RUN、CMD和ENTRYPOINT指令执行命令的工作目录(默认为/目录)，该指令在Dockerfile文件中可以出现多次，如果使用相对路径则为相对于WORKDIR上一次的值，例如WORKDIR /data，WORKDIR logs，RUN pwd最终输出的当前目录是/data/logs。 12.ONBUILD 12345678语法：ONBUILD [INSTRUCTION] 解释：ONBUILD指令用来设置一些触发的指令，用于在当该镜像被作为基础镜像来创建其他镜像时(也就是Dockerfile中的FROM为当前镜像时)执行一些操作，ONBUILD中定义的指令会在用于生成其他镜像的Dockerfile文件的FROM指令之后被执行，上述介绍的任何一个指令都可以用于ONBUILD指令，可以用来执行一些因为环境而变化的操作，使镜像更加通用。 注意：①ONBUILD中定义的指令在当前镜像的build中不会被执行。 ②可以通过查看docker inspeat 命令执行结果的OnBuild键来查看某个镜像ONBUILD指令定义的内容。 ③ONBUILD中定义的指令会当做引用该镜像的Dockerfile文件的FROM指令的一部分来执行，执行顺序会按ONBUILD定义的先后顺序执行，如果ONBUILD中定义的任何一个指令运行失败，则会使FROM指令中断并导致整个build失败，当所有的ONBUILD中定义的指令成功完成后，会按正常顺序继续执行build。 ④ONBUILD中定义的指令不会继承到当前引用的镜像中，也就是当引用ONBUILD的镜像创建完成后将会清除所有引用的ONBUILD指令。 ⑤ONBUILD指令不允许嵌套，例如ONBUILD ONBUILD ADD . /data是不允许的。 ⑥ONBUILD指令不会执行其定义的FROM或MAINTAINER指令。 13.HEALTHCHECK:健康检查 14.ARG: 构建时指定的一些参数 1234例如:FROM centos:7ARG userUSER $user 设置环境变量除了ENV 外对容器还可能用以下两种方式 ： 1234docker exec -i CONTAINER_ID /bin/bash -c \"exportDOCKER_HOST=tcp://localhost:port\"+echo 'export DOCKER_HOST=tcp://localhost:port' >> ~/.bashrc 注意: 1、RUN在building时运行， 可以写多条 2、CMD和ENTRYPOINT在运行container时运行， 只能写一条，如果写多条,最后一条生效 3、CMD在run时可以被COMMAND覆盖，ENTRYPOINT不会被COMMAND覆盖，但可以指定–entrypoint覆盖。 4、如果在Dockerfile里需要往镜像内导入文件，则此文件必须在dockerfile所在目录或子目录下。 小实验 1）使用dockerifle制作一个镜像，基于centos：7镜像部署安装nginx服务。 12[root@localhost ~]# mkdir web[root@localhost ~]# rz 12345678910111213141516[root@localhost ~]# cp nginx-1.14.0.tar.gz web/[root@localhost ~]# cd web///创建测试目录[root@localhost web]# vim DockerfileFROM centos:7RUN yum -y install make gcc pcre pcre-devel zlib zlib-devel openssl openssl-develCOPY nginx-1.14.0.tar.gz /RUN tar -zxf nginx-1.14.0.tar.gz -C /usr/srcRUN useradd -M -s /sbin/nologin nginxWORKDIR /usr/src/nginx-1.14.0RUN ./configure --prefix=/usr/local/nginx --user=nginx --group=nginxRUN make && make installRUN ln -s /usr/local/nginx/sbin/* /usr/local/sbin/RUN nginx -tRUN nginxEXPOSE 80 //如果想要保证容器运行之后，nginx服务就直接开启，不必手动开启，我们可以在命令最后加上:nginx -g &quot;daemon off;&quot; 1234[root@localhost web]# docker build -t test-web .//创建镜像[root@localhost web]# docker images//查看一下镜像 12345678[root@localhost web]# docker run -itd --name testweb test-web:latest[root@localhost web]# docker exec -it testweb /bin/bash//进入容器testweb[root@a3a21e68cb99 nginx-1.14.0]# nginx//开启nginx[root@a3a21e68cb99 nginx-1.14.0]# exit[root@localhost web]# docker inspect testweb//查看容器testweb的详细信息（现在看IP） 12[root@localhost web]# curl 172.17.0.2:80//访问一下nginx 2）将制作的镜像运行一个容器，使容器运行时自动开启nginx服务。验证服务正常运行。 1234[root@localhost web]# docker run -itd --name testweb_2 test-web:latest nginx -g \"daemon off;\"//开启容器时一并开启nginx[root@localhost web]# docker inspect testweb_2//查看容器testweb_2的详细信息（现在看IP） 12[root@localhost web]# curl 172.17.0.3:80//访问一下nginx 3）运行一个私有仓库，将自制镜像上传到私有仓库，且开启另外一台虚拟机同样加入私有仓库，在docker02上下载私有仓库镜像并运行一个容器，验证服务正常运行。 12[root@localhost web]# docker pull registry:2//先下载一个镜像 用docker容器运行registry私有仓库 123456[root@localhost web]# docker run -itd --name registry --restart=always -p 5000:5000 -v /registry:/var/lib/registry registry:2//运行一下registery私有仓库服务（会返回一个进程编号）-p：端口映射。宿主机端口:容器暴露的端口。-v：挂载目录。宿主机目录：容器内的目录。[root@localhost web]# docker ps//查看一下容器 123[root@localhost web]# docker tag test-web1 192.168.1.11:5000/test//镜像重命名[root@localhost web]# docker images 12345678[root@localhost web]# vim /usr/lib/systemd/system/docker.service//修改docker配置文件ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 #13行[root@localhost web]# systemctl daemon-reload [root@localhost web]# systemctl restart docker//重启docker[root@localhost web]# docker ps//查看容器 12[root@localhost web]# docker push 192.168.1.11:5000/test:latest//上传私有仓库 12[root@localhost web]# ls/registry/docker/registry/v2/repositories//查看一下私有仓库 打开第二台docker测试一下 123456789 39 vim /usr/lib/systemd/system/docker.service //修改docker配置文件ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.11:5000 #13行 40 systemctl daemon-reload 41 systemctl restart docker44 docker pull 192.168.1.11:5000/test:latest//从私有仓库下载镜像 53 docker run -itd --name xgp1 192.168.1.11:5000/test:latest nginx -g \"daemon off;\"true //开启容器时一并开启nginx 12 54 docker inspect xgp1//查看容器testweb_2的详细信息（现在看IP） 1256 curl 172.17.0.2 //访问一下nginx","path":"posts/30ad.html","date":"08-07","excerpt":"","tags":[{"name":"dockerfile参数","slug":"dockerfile参数","permalink":"https://wsdlxgp.top/tags/dockerfile%E5%8F%82%E6%95%B0/"}]},{"title":"06 理解Docker镜像分层","text":"目录 关于base镜像 关于存储结构（About storage drivers） 先来创建一个自己的镜像 docker镜像的分层结构 容器的大小 修改时复制策略 copy-on-write (CoW) Copying makes containers efficient 关于base镜像 base 镜像有两层含义： 不依赖其他镜像，从 scratch 构建。 其他镜像可以之为基础进行扩展。 所以，能称作 base 镜像的通常都是各种 Linux 发行版的 Docker 镜像，比如 Ubuntu, Debian, CentOS 等。 base 镜像提供的是最小安装的 Linux 发行版。 我们大部分镜像都将是基于base镜像构建的。所以，通常使用的是官方发布的base镜像。可以在docker hub里找到。比如centos： https://hub.docker.com/_/centos 点击版本可以看到github里的Dockerfile 12345678910FROM scratchADD centos-7-docker.tar.xz /LABEL org.label-schema.schema-version=\"1.0\" \\ org.label-schema.name=\"CentOS Base Image\" \\ org.label-schema.vendor=\"CentOS\" \\ org.label-schema.license=\"GPLv2\" \\ org.label-schema.build-date=\"20181205\"CMD [\"/bin/bash\"] ADD命令将本地的centos7的tar包添加到镜像，并解压到根目录/下。生成/dev,/proc/,/bin等。 我们可以自己构建docker base镜像，也可以直接使用已有的base镜像。比如centos。我们可以直接从docker hub上拉取。 拉取 1docker pull centos 查看 123## docker images centos REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 1e1148e4cc2c 2 months ago 202MB 可以看到最新的centos镜像只有200mb，是不是觉得太小了？这是因为docker镜像在运行的时候直接使用docker宿主机器的kernel。 Linux操作系统由内核空间和用户空间组成。 内核空间是kernel，用户空间是rootfs, 不同Linux发行版的区别主要是rootfs.比如 Ubuntu 14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS 7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。 所以 Docker 可以同时支持多种 Linux 镜像，模拟出多种操作系统环境。 需要注意的是： base镜像只是用户空间和发行版一致。kernel使用的是docker宿主机器的kernel。例如 CentOS 7 使用 3.x.x 的 kernel，如果 Docker Host 是 Ubuntu 16.04（比如我们的实验环境），那么在 CentOS 容器中使用的实际是是 Host 4.x.x 的 kernel。 ① Host kernel 为 4.4.0-31 ② 启动并进入 CentOS 容器 ③ 验证容器是 CentOS 7 ④ 容器的 kernel 版本与 Host 一致 关于存储结构（About storage drivers） 上文里展示了如何下载一个base镜像。我们通常是基于这份base镜像来构建我们自己的镜像。比如，在centos里添加一个nginx负载均衡。首先，得需要了解镜像的结构是什么。 官方文档： https://docs.docker.com/storage/storagedriver/ 先来创建一个自己的镜像 首先，base镜像是基于docker宿主机器kernel之上的Linux发行版。 现在，我们给这台机器安装一个vim，一个httpd. 基于Dockerfile来创建一个新的镜像。 123456789101112我们的DockerfileFROM centos:7RUN yum install -y vimRUN yum install -y httpdCMD [\"/bin/bash\"]含义：基于centos7的base镜像构建安装vim安装httpd执行bash 在当前目录下新建一个文件Dockerfile, 填充上述内容。然后执行 123456789101112131415# docker build -t ryan/httpd:v1.0 .Sending build context to Docker daemon 6.144kBStep 1/4 : FROM centos:7 ---&gt; 1e1148e4cc2cStep 2/4 : RUN yum install -y vim ---&gt; Using cache ---&gt; 74bdbea98f73Step 3/4 : RUN yum install -y httpd ---&gt; Using cache ---&gt; 17d8c4095dc4Step 4/4 : CMD /bin/bash ---&gt; Using cache ---&gt;# docker build -t ryan/httpd:v1.0 .Sending build context to Docker daemon 6.144kBStep 1/4 : FROM centos:7 ---&gt; 1e1148e4cc2cStep 2/4 : RUN yum install -y vim ---&gt; Using cache ---&gt; 74bdbea98f73Step 3/4 : RUN yum install -y httpd ---&gt; Using cache ---&gt; 17d8c4095dc4Step 4/4 : CMD /bin/bash ---&gt; Using cache ---&gt; f2b58b1192deSuccessfully built f2b58b1192deSuccessfully tagged ryan/httpd:latest -t 指定我们创建的镜像名称，镜像名称可以用组织/id:version的方式标记 最后一个参数是Dockerfile所在的路径., 表示当前目录 然后我们添加一个tag latest docker tag ryan/httpd:v1.0 ryan/httpd:latest 即给镜像ryan/httpd:v1.0标记为ryan/httpd:latest 构建完成之后，查看 12345# docker images | grep -E # docker images | grep -E '(ryan|centos)'ryan/httpd latest f2b58b1192de About an hour ago 444MBryan/httpd v1.0 f2b58b1192de About an hour ago 444MBcentos 7 1e1148e4cc2c 2 months ago 202MBcentos latest 1e1148e4cc2c 2 months ago 202MB 可以运行我们创建的镜像： 1234# docker run -d --privileged=true -it ryan/httpd:v1.0 /usr/sbin/init48a4a128cd7b6924149cd97670919d4e2af6cb96c73c901af60d05fe4478225a## docker run -d --privileged=true -it ryan/httpd:v1.0 /usr/sbin/init48a4a128cd7b6924149cd97670919d4e2af6cb96c73c901af60d05fe4478225a# docker ps | grep ryan48a4a128cd7b ryan/httpd:v1.0 \"/usr/sbin/init\" 8 seconds ago Up 8 seconds 现在我们的基于原生base centos7的httpd服务器已经启动了。可以通过docker exec -it zealous_kirch /bin/bash来进入容器内部，查看启动httpd。 docker镜像的分层结构 我们可以查看镜像的历史，用上一步的镜像id f2b58b1192de 12345678# docker # docker history f2b58b1192deIMAGE CREATED CREATED BY SIZE COMMENTf2b58b1192de About an hour ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0B 17d8c4095dc4 About an hour ago /bin/sh -c yum install -y httpd 110MB 74bdbea98f73 About an hour ago /bin/sh -c yum install -y vim 133MB 1e1148e4cc2c 2 months ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0B 2 months ago /bin/sh -c #(nop) LABEL org.label-schema.... 0B 2 months ago /bin/sh -c #(nop) ADD file:6f877549795f479... 202MB 启动镜像的时候，一个新的可写层会加载到镜像的顶部。这一层通常称为“容器层”， 之下是“镜像层”。 容器层可以读写，容器所有发生文件变更写都发生在这一层。镜像层read-only,只允许读取。 (上图来自官方文档，和本次实验内容略有不同，但原理一样) 第一列是imageid, 最上面的id就是我们新创建ryan/httpd:latest. 下面几行都是我们dockerfile里定义的步骤堆栈。由此可以看出，每个步骤都将创建一个imgid, 一直追溯到1e1148e4cc2c正好是我们的base镜像的id。关于的部分，则不在本机上。 最后一列是每一层的大小。最后一层只是启动bash，所以没有文件变更，大小是0. 我们创建的镜像是在base镜像之上的，并不是完全复制一份base，然后修改，而是共享base的内容。这时候，如果我们新建一个新的镜像，同样也是共享base镜像。 那修改了base镜像，会不会导致我们创建的镜像也被修改呢？ 不会！因为不允许修改历史镜像，只允许修改容器，而容器只可以在最上面的容器层进行写和变更。 容器的大小 创建镜像的时候，分层可以让docker只保存我们添加和修改的部分内容。其他内容基于base镜像，不需要存储，读取base镜像即可。如此，当我们创建多个镜像的时候，所有的镜像共享base部分。节省了磁盘空间。 对于启动的容器，查看所需要的磁盘空间可以通过docker ps -s 123456# docker run -d -it centos4b0df4bc3e705c540144d545441930689124ade087961d01f56c2ac55bfd986d# docker ps -s | grep -E # docker run -d -it centos4b0df4bc3e705c540144d545441930689124ade087961d01f56c2ac55bfd986d# docker ps -s | grep -E '(ryan|centos)'4b0df4bc3e70 centos \"/bin/bash\" 23 seconds ago Up 23 seconds vigorous_elion 0B (virtual 202MB)b36421d05005 ryan/httpd:v1.0 \"/usr/sbin/init\" 32 minutes ago Up 32 minutes gracious_swirles 61.6kB (virtual 444MB) 首先启动一个base镜像用来对比 可以看到第一行就是base镜像centos，第2列的size是0和202MB, 0表示容器层可写层的大小，virtual则是容器层+镜像层的大小。这里对比可以看到一共202M,正好是最初centos镜像的大小。 第二行是我们自己创建的镜像。virtual达到了444MB。对比前面的history部分，可以发现这个数字是每一层大小之和。同时，由于共享base，其中的202M是和第一行的镜像共享的。 修改时复制策略 copy-on-write (CoW) docker通过一个叫做copy-on-write (CoW) 的策略来保证base镜像的安全性，以及更高的性能和空间利用率。 1234567891011121314151617Copy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.Copying makes containers efficientWhen you start a container, a thin writable container layer is added on top of the other layers. Any changes the container makes to the filesystem are stored here. Any files the container does not change do not get copied to this writable layer. This means that the writable layer is as small as possible.When an existing file in a container is modified, the storage driver performs a copy-on-write operation. The specifics steps involved depend on the specific storage driver. For the aufs, overlay, and overlay2 drivers, the copy-on-write operation follows this rough sequence:Search through the image layers for the file to update. The process starts at the newest layer and works down to the base layer one layer at a time. When results are found, they are added to a cache to speed future operations.Perform a copy_up operation on the first copy of the file that is found, to copy the file to the container’s writable layer.Any modifications are made to this copy of the file, and the container cannot see the read-only copy of the file that exists in the lower layer.Btrfs, ZFS, and other drivers handle the copy-on-write differently. You can read more about the methods of these drivers later in their detailed descriptions.Containers that write a lot of data consume more space than containers that do not. This is because most write operations consume new space in the container’s thin writable top layer. 简单的说，启动容器的时候，最上层容器层是可写层，之下的都是镜像层，只读层。 当容器需要读取文件的时候 从最上层镜像开始查找，往下找，找到文件后读取并放入内存，若已经在内存中了，直接使用。(即，同一台机器上运行的docker容器共享运行时相同的文件)。 当容器需要添加文件的时候 直接在最上面的容器层可写层添加文件，不会影响镜像层。 当容器需要修改文件的时候 从上往下层寻找文件，找到后，复制到容器可写层，然后，对容器来说，可以看到的是容器层的这个文件，看不到镜像层里的文件。容器在容器层修改这个文件。 当容器需要删除文件的时候 从上往下层寻找文件，找到后在容器中记录删除。即，并不会真正的删除文件，而是软删除。这将导致镜像体积只会增加，不会减少。 综上，Docker镜像通过分层实现了资源共享，通过copy-on-write实现了文件隔离。 对于文件只增加不减少问题，我们应当在同一层做增删操作，从而减少镜像体积。比如，如下测试。 Dockerfile.A: 分层删除文件** 12345678FROM centos:7RUN yum install -y vimRUN yum install -y httpdWORKDIR /homeRUN dd if=/dev/zero of=50M.file bs=1M count=50#FROM centos:7RUN yum install -y vimRUN yum install -y httpdWORKDIR /homeRUN dd if=/dev/zero of=50M.file bs=1M count=50#创建大小为50M的测试文件RUN rm -rf 50M.fileCMD [\"/bin/bash\"] 构建 docker build -t test:a -f Dockerfile.A . Dockerfile.B: 同层删除 12345FROM centos:7RUN yum install -y vimRUN yum install -y httpdWORKDIR /homeRUN dd if=/dev/zero of=50M.file bs=1M count=50 && rm -rf 50M.file 构建 1docker build -t test:b -f Dockerfile.B . 比较二者大小 123[root@sh-k8s-001 tmp]# docker images | grep testtest a ae673aa7db48 9 minutes ago 497MBtest b 21b2bc49f0bd 12 minutes ago 444MB 显然，分层删除操作并没有真正删除掉文件。 来源 **链接：**https://www.cnblogs.com/woshimrf/p/docker-container-lawyer.html https://www.cnblogs.com/CloudMan6/p/6799197.html https://www.cnblogs.com/CloudMan6/p/6806193.html https://docs.docker.com/storage/storagedriver/","path":"posts/2fbc.html","date":"08-06","excerpt":"","tags":[{"name":"镜像","slug":"镜像","permalink":"https://wsdlxgp.top/tags/%E9%95%9C%E5%83%8F/"},{"name":"bash","slug":"bash","permalink":"https://wsdlxgp.top/tags/bash/"}]},{"title":"05 Dockers镜像分层","text":"1,Dockers的最小镜像 1234[root@localhost ~]# docker pull hello-world//下载一个最小的镜像[root@localhost ~]# docker images//查看镜像 12[root@localhost ~]# docker run hello-world//运行一下hello-world （里面是一个文本对docker运行的简单介绍） dockerfile的组成 1）FROM：scratch（抓、挠） 2）COPY：hello / 3）CMD：[“/hello”] FROM 12语法：FROM [:]解释：设置要制作的镜像基于哪个镜像，FROM指令必须是整个Dockerfile的第一个指令，如果指定的镜像不存在默认会自动从Docker Hub上下载。 COPY 12语法：COPY 解释：用法与ADD相同，不过不支持使用url，所以在使用docker build – < somefile时该指令不能使用。 CMD 12345语法：①CMD [\"executable\", \"param1\", \"param2\"] #将会调用exec执行，首选方式 ②CMD [\"param1\", \"param2\"] #当使用ENTRYPOINT指令时，为该指令传递默认参数 ③CMD [ | ] #将会调用/bin/sh -c执行解释：CMD指令中指定的命令会在镜像运行时执行，在Dockerfile中只能存在一个，如果使用了多个CMD指令，则只有最后一个CMD指令有效。当出现ENTRYPOINT指令时，CMD中定义的内容会作为ENTRYPOINT指令的默认参数，也就是说可以使用CMD指令给ENTRYPOINT传递参数。注意：RUN和CMD都是执行命令，他们的差异在于RUN中定义的命令会在执行docker build命令创建镜像时执行，而CMD中定义的命令会在执行docker run命令运行镜像时执行，另外使用第一种语法也就是调用exec执行时，命令必须为绝对路径。 2、Base镜像（基础镜像） Centos:7镜像的dockerfile 1234567891011FROM scratchADD centos-7-x86_ _64-docker.tar.xz /LABEL org. label-schema. schema-version=\"1.0\" \\|org. label-schema. name=\"Centos Base Image\" \\org. labe1-schema. vendor=\"centos\" \\org. labe1-schema. 1icense=\"GPLV2\" \\org. labe1-schema build-date=\"20190305 'CMD [\"/bin/bash\"] 3、镜像的分层 1）dockerfile的书写格式为：Dockerfile（首字母大写，包括文件名称） 2）From：构建镜像有两种方式，一种scratch(从零构建)，另一种可以基于某个镜像开始构建 3）镜像所运行的操作（用户所期望的） 12345678910[root@localhost ~]# mkdir test//创建测试目录[root@localhost ~]# cd test//进入测试目录[root@localhost ~]#vim Dockerfile//编写DockerfileFROM centos:7 RUN yum -y install vim #或[\"yum\",\"install\",\"vim\"]RUN yum -y install net-toolsCMD [\"/bin/bash\"] 执行一下 12345[root@localhost test]# docker build -t centos7-vim-net-tools:12-11 .//使用当前目录的 Dockerfile 创建镜像，标签为 centos7-vim-net-tools:12-11build： 使用 Dockerfile 创建镜像-t：标签. :当前目录 执行的层次 4.Dockerfile镜像分层总结 镜像时容器的基石，容器是镜像运行后的实例。当镜像运行为容器之后,对镜像的所有数据仅有只读权限，如果需要对镜像源文件进行修改或删除操作,此时是在容器层（可写层）进行的，用到了COW（copy on write）写时复制机制。 Docker镜像的缓存特性 1.创建一个新的Dockerfile文件 12345678[root@localhost ~]# vim DockerfileFROM centos:7RUN yum -y install vimRUN yum -y install net-toolsRUN yum -y install wgetCMD [\"/bin/bash\"][root@localhost ~]# docker build -t new-centos .//使用当前目录的 Dockerfile 创建镜像，名称为new-centos 如果在相同的层，有用到相同的镜像，可以不必再去下载，直接使用缓存。（如果第一层的不相同了，那么下面的相同也没用了，需要重新下载） 2.再次创建一个新的Dockerfile 1234567891011[root@localhost ~]# mkdir test1[root@localhost ~]# cd test[root@localhost test]# cd ../test1[root@localhost test1]# vim DockerfileFROM centos:7RUN yum -y install vimRUN yum -y install wgetRUN yum -y install net-toolsCMD [\"/bin/bash\"][root@localhost test1]# docker build -t centos-new .//使用当前目录的 Dockerfile 创建镜像，名称为centos-new 即使镜像层里的操作一样，也必须是在同一层才可以使用dockerfile的缓存特性 如果制作镜像过程中，不想使用缓存，可以–no-cache选项","path":"posts/4e5d.html","date":"08-05","excerpt":"","tags":[{"name":"镜像","slug":"镜像","permalink":"https://wsdlxgp.top/tags/%E9%95%9C%E5%83%8F/"},{"name":"dockerfile","slug":"dockerfile","permalink":"https://wsdlxgp.top/tags/dockerfile/"}]},{"title":"04 DOCKER源码分析（一）：DOCKER架构","text":"1 背景 1.1 Docker简介 Docker是Docker公司开源的一个基于轻量级虚拟化技术的容器引擎项目,整个项目基于Go语言开发，并遵从Apache 2.0协议。目前，Docker可以在容器内部快速自动化部署应用，并可以通过内核虚拟化技术（namespaces及cgroups等）来提供容器的资源隔离与安全保障等。由于Docker通过操作系统层的虚拟化实现隔离，所以Docker容器在运行时，不需要类似虚拟机（VM）额外的操作系统开销，提高资源利用率，并且提升诸如IO等方面的性能。 由于众多新颖的特性以及项目本身的开放性，Docker在不到两年的时间里迅速获得诸多厂商的青睐，其中更是包括Google、Microsoft、VMware等业界行业领导者。Google在今年六月份推出了Kubernetes，提供Docker容器的调度服务，而今年8月Microsoft宣布Azure上支持Kubernetes，随后传统虚拟化巨头VMware宣布与Docker强强合作。今年9月中旬，Docker更是获得4000万美元的C轮融资，以推动分布式应用方面的发展。 从目前的形势来看，Docker的前景一片大好。本系列文章从源码的角度出发，详细介绍Docker的架构、Docker的运行以及Docker的卓越特性。本文是Docker源码分析系列的第一篇———Docker架构篇。 1.2 Docker版本信息 本文关于Docker架构的分析都是基于Docker的源码与Docker相应版本的运行结果，其中Docker为最新的1.2版本。 2 Docker架构分析内容安排 本文的目的是：在理解Docker源代码的基础上，分析Docker架构。分析过程中主要按照以下三个步骤进行： • Docker的总架构图展示 • Docker架构图内部各模块功能与实现分析 • 以Docker命令的执行为例，进行Docker运行流程阐述 3 Docker总架构图 学习Docker的源码并不是一个枯燥的过程，反而可以从中理解Docker架构的设计原理。Docker对使用者来讲是一个C/S模式的架构，而Docker的后端是一个非常松耦合的架构，模块各司其职，并有机组合，支撑Docker的运行。 在此，先附上Docker总架构，如图3.1。 图3.1 Docker总架构图 如图3.1，不难看出，用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。 而Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求；而后Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。 Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储；当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境；当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。 而libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。 当执行完运行容器的命令后，一个实际的Docker容器就处于运行状态，该容器拥有独立的文件系统，独立并且安全的运行环境等。 3.1 DOCKER架构总体包含七个部分：client,daemon,driver,libcontainer,container,graph,registry。 外表来看，docker是一个C/S的架构，用户可以在客户端输入各种指令，客户端负责接受请求并作出相应的响应返回给客户。 3.2 DockerClient DockerClient 负责接受并传递请求指令 。 3.3 DockerDaemon DockerDaemon的功能主要有两个： 负责接受client的请求 管理docker容器 dockerdaemon的架构主要可以分为两部分：dockerserver和engine 3.4 DockerServer DockerServer作为服务端最主要的作用就是配合client端将请求指令接受过来，如图所示，DockerServer主要分为三个部分：Http.server,mux.server,Handler。 DockerServer运行时会从一个名为mux的包中创建一个mux.Router路由器，然后为路由器中添加相关的路由项用于路由信息， 每个路由项由HTTP请求方法（get,post,put,delete）+URL+Handler三部分组成。 DockerServer每收到一个请求就会生成一个goroutine然后进行相应的解析、匹配相应的路由项最后会找到相匹配的Handler来处理，Handler处理玩请求之后给DockerClient返回响应。 3.5 Engine Engine是docker中的运行引擎，存储着大量的容器信息并管理着大部分job的执行。 job是docker中的最小执行单元，类似于unix中的进程，也会有相应的名字、参数、环境变量、标准输入输出、返回状态等等。docker每进行一次相应的操作都会 生成一个相应的Job，比如创建一个容器、下载一个文件等等都是由job完成的。 3.6 DockerDriver DockerDriver是docker内部的驱动模块，负责容器内部相关网络、文件系统等的构建 3.6 libcontainer libcontainer主要是对linux内核的一些诸如namespace、cgroups、capabilities等特性做了封装 4 Docker架构内各模块的功能与实现分析 接下来，我们将从Docker总架构图入手，抽离出架构内各个模块，并对各个模块进行更为细化的架构分析与功能阐述。主要的模块有：Docker Client、Docker Daemon、Docker Registry、Graph、Driver、libcontainer以及Docker container。 4.1 Docker Client Docker Client是Docker架构中用户用来和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker，通过docker命令行工具可以发起众多管理container的请求。 Docker Client可以通过以下三种方式和Docker Daemon建立通信：tcp://host:port，unix://path_to_socket和fd://socketfd。为了简单起见，本文一律使用第一种方式作为讲述两者通信的原型。与此同时，与Docker Daemon建立连接并传输请求的时候，Docker Client可以通过设置命令行flag参数的形式设置安全传输层协议(TLS)的有关参数，保证传输的安全性。 Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。当需要继续发送容器管理请求时，用户必须再次通过docker可执行文件创建Docker Client。 4.2 Docker Daemon Docker Daemon是Docker架构中一个常驻在后台的系统进程，功能是：接受并处理Docker Client发送的请求。该守护进程在后台启动了一个Server，Server负责接受Docker Client发送的请求；接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。 Docker Daemon启动所使用的可执行文件也为docker，与Docker Client启动所使用的可执行文件docker相同。在docker命令执行时，通过传入的参数来判别Docker Daemon与Docker Client。 Docker Daemon的架构，大致可以分为以下三部分：Docker Server、Engine和Job。Daemon架构如图4.1。 图4.1 Docker Daemon架构示意图 4.2.1 DOCKER SERVER Docker Server在Docker架构中是专门服务于Docker Client的server。该server的功能是：接受并调度分发Docker Client发送的请求。Docker Server的架构如图4.2。 ** 图4.2 Docker Server架构示意图 在Docker的启动过程中，通过包gorilla/mux，创建了一个mux.Router，提供请求的路由功能。在Golang中，gorilla/mux是一个强大的URL路由器以及调度分发器。该mux.Router中添加了众多的路由项，每一个路由项由HTTP请求方法（PUT、POST、GET或DELETE）、URL、Handler三部分组成。 若Docker Client通过HTTP的形式访问Docker Daemon，创建完mux.Router之后，Docker将Server的监听地址以及mux.Router作为参数，创建一个httpSrv=http.Server{}，最终执行httpSrv.Serve()为请求服务。 在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。 需要注意的是：Docker Server的运行在Docker的启动过程中，是靠一个名为”serveapi”的job的运行来完成的。原则上，Docker Server的运行是众多job中的一个，但是为了强调Docker Server的重要性以及为后续job服务的重要特性，将该”serveapi”的job单独抽离出来分析，理解为Docker Server。 4.2.2 ENGINE Engine是Docker架构中的运行引擎，同时也Docker运行的核心模块。它扮演Docker container存储仓库的角色，并且通过执行job的方式来操纵管理这些容器。 在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：{“create”: daemon.ContainerCreate,}，则说明当名为”create”的job在运行时，执行的是daemon.ContainerCreate的handler。 4.2.3 JOB 一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job。例如：在容器内部运行一个进程，这是一个job；创建一个新的容器，这是一个job，从Internet上下载一个文档，这是一个job；包括之前在Docker Server部分说过的，创建Server服务于HTTP的API，这也是一个job，等等。 Job的设计者，把Job设计得与Unix进程相仿。比如说：Job有一个名称，有参数，有环境变量，有标准的输入输出，有错误处理，有返回状态等。 4.3 Docker Registry Docker Registry是一个存储容器镜像的仓库。而容器镜像是在容器被创建时，被加载用来初始化容器的文件架构与目录。 在Docker的运行过程中，Docker Daemon会与Docker Registry通信，并实现搜索镜像、下载镜像、上传镜像三个功能，这三个功能对应的job名称分别为”search”，”pull” 与 “push”。 其中，在Docker架构中，Docker可以使用公有的Docker Registry，即大家熟知的Docker Hub，如此一来，Docker获取容器镜像文件时，必须通过互联网访问Docker Hub；同时Docker也允许用户构建本地私有的Docker Registry，这样可以保证容器镜像的获取在内网完成。 4.4 Graph Graph在Docker架构中扮演已下载容器镜像的保管者，以及已下载容器镜像之间关系的记录者。一方面，Graph存储着本地具有版本信息的文件系统镜像，另一方面也通过GraphDB记录着所有文件系统镜像彼此之间的关系。Graph的架构如图4.3。 图4.3 Graph架构示意图 其中，GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录。它仅仅实现了大多数图数据库所拥有的一个小的子集，但是提供了简单的接口表示节点之间的关系。 同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs。 4.5 Driver Driver是Docker架构中的驱动模块。通过Driver驱动，Docker可以实现对Docker容器执行环境的定制。由于Docker运行的生命周期中，并非用户所有的操作都是针对Docker容器的管理，另外还有关于Docker运行信息的获取，Graph的存储与记录等。因此，为了将Docker容器的管理从Docker Daemon内部业务逻辑中区分开来，设计了Driver层驱动来接管所有这部分请求。 在Docker Driver的实现中，可以分为以下三类驱动：graphdriver、networkdriver和execdriver。 graphdriver主要用于完成容器镜像的管理，包括存储与获取。即当用户需要下载指定的容器镜像时，graphdriver将容器镜像存储在本地的指定目录；同时当用户需要使用指定的容器镜像来创建容器的rootfs时，graphdriver从本地镜像存储目录中获取指定的容器镜像。 在graphdriver的初始化过程之前，有4种文件系统或类文件系统在其内部注册，它们分别是aufs、btrfs、vfs和devmapper。而Docker在初始化之时，通过获取系统环境变量”DOCKER_DRIVER”来提取所使用driver的指定类型。而之后所有的graph操作，都使用该driver来执行。 graphdriver的架构如图4.4： 图4.4 graphdriver架构示意图 networkdriver的用途是完成Docker容器网络环境的配置，其中包括Docker启动时为Docker环境创建网桥；Docker容器创建时为其创建专属虚拟网卡设备；以及为Docker容器分配IP、端口并与宿主机做端口映射，设置容器防火墙策略等。networkdriver的架构如图4.5： 图4. 5 networkdriver架构示意图 execdriver作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。在execdriver的实现过程中，原先可以使用LXC驱动调用LXC的接口，来操纵容器的配置以及生命周期，而现在execdriver默认使用native驱动，不依赖于LXC。具体体现在Daemon启动过程中加载的ExecDriverflag参数，该参数在配置文件已经被设为”native”。这可以认为是Docker在1.2版本上一个很大的改变，或者说Docker实现跨平台的一个先兆。execdriver架构如图4.6： 图4.6 execdriver架构示意图 4.6 libcontainer libcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API。 正是由于libcontainer的存在，Docker可以直接调用libcontainer，而最终操纵容器的namespace、cgroups、apparmor、网络设备以及防火墙规则等。这一系列操作的完成都不需要依赖LXC或者其他包。libcontainer架构如图4.7： 图4.7 libcontainer示意图 另外，libcontainer提供了一整套标准的接口来满足上层对容器管理的需求。或者说，libcontainer屏蔽了Docker上层对容器的直接管理。又由于libcontainer使用Go这种跨平台的语言开发实现，且本身又可以被上层多种不同的编程语言访问，因此很难说，未来的Docker就一定会紧紧地和Linux捆绑在一起。而于此同时，Microsoft在其著名云计算平台Azure中，也添加了对Docker的支持，可见Docker的开放程度与业界的火热度。 暂不谈Docker，由于libcontainer的功能以及其本身与系统的松耦合特性，很有可能会在其他以容器为原型的平台出现，同时也很有可能催生出云计算领域全新的项目。 4.7 Docker container Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。 Docker按照用户的需求与指令，订制相应的Docker容器： • 用户通过指定容器镜像，使得Docker容器可以自定义rootfs等文件系统； • 用户通过指定计算资源的配额，使得Docker容器使用指定的计算资源； • 用户通过配置网络及其安全策略，使得Docker容器拥有独立且安全的网络环境； • 用户通过指定运行的命令，使得Docker容器执行指定的工作。 Docker容器示意图如图4.8： 图4.8 Docker容器示意图 5 Docker运行案例分析 上一章节着重于Docker架构中各个部分的介绍。本章的内容，将以串联Docker各模块来简要分析，分析原型为Docker中的docker pull与docker run两个命令。 5.1 docker pull docker pull命令的作用为：从Docker Registry中下载指定的容器镜像，并存储在本地的Graph中，以备后续创建Docker容器时的使用。docker pull命令执行流程如图5.1。 图5.1 docker pull命令执行流程示意图 如图，图中标记的红色箭头表示docker pull命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。 (1) Docker Client接受docker pull命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/images/create? “+”xxx”； (2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler； (3) mux.Router将请求路由分发至相应的handler，具体为PostImagesCreate； (4) 在PostImageCreate这个handler之中，一个名为”pull”的job被创建，并开始执行； (5) 名为”pull”的job在执行过程中，执行pullRepository操作，即从Docker Registry中下载相应的一个或者多个image； (6) 名为”pull”的job将下载的image交给graphdriver； (7) graphdriver负责将image进行存储，一方创建graph对象，另一方面在GraphDB中记录image之间的关系。 5.2 docker run docker run命令的作用是在一个全新的Docker容器内部运行一条指令。Docker在执行这条命令的时候，所做工作可以分为两部分：第一，创建Docker容器所需的rootfs；第二，创建容器的网络等运行环境，并真正运行用户指令。因此，在整个执行流程中，Docker Client给Docker Server发送了两次HTTP请求，第二次请求的发起取决于第一次请求的返回状态。Docker run命令执行流程如图5.2。 图5.2 docker run命令执行流程示意图 如图，图中标记的红色箭头表示docker run命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。 (1) Docker Client接受docker run命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/containers/create? “+”xxx”； (2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler； (3) mux.Router将请求路由分发至相应的handler，具体为PostContainersCreate； (4) 在PostImageCreate这个handler之中，一个名为”create”的job被创建，并开始让该job运行； (5) 名为”create”的job在运行过程中，执行Container.Create操作，该操作需要获取容器镜像来为Docker容器创建rootfs，即调用graphdriver； (6) graphdriver从Graph中获取创建Docker容器rootfs所需要的所有的镜像； (7) graphdriver将rootfs所有镜像，加载安装至Docker容器指定的文件目录下； (8) 若以上操作全部正常执行，没有返回错误或异常，则Docker Client收到Docker Server返回状态之后，发起第二次HTTP请求。请求方法为”POST”，请求URL为”/containers/”+containerID+”/start”； (9) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler； (10) mux.Router将请求路由分发至相应的handler，具体为PostContainersStart； (11) 在PostContainersStart这个handler之中，名为”start”的job被创建，并开始执行； (12) 名为”start”的job执行完初步的配置工作后，开始配置与创建网络环境，调用networkdriver； (13) networkdriver需要为指定的Docker容器创建网络接口设备，并为其分配IP，port，以及设置防火墙规则，相应的操作转交至libcontainer中的netlink包来完成； (14) netlink完成Docker容器的网络环境配置与创建； (15) 返回至名为”start”的job，执行完一些辅助性操作后，job开始执行用户指令，调用execdriver； (16) execdriver被调用，初始化Docker容器内部的运行环境，如命名空间，资源控制与隔离，以及用户命令的执行，相应的操作转交至libcontainer来完成； (17) libcontainer被调用，完成Docker容器内部的运行环境初始化，并最终执行用户要求启动的命令。 6 总结 本文从Docker 1.2的源码入手，分析抽象出Docker的架构图，并对该架构图中的各个模块进行功能与实现的分析，最后通过两个docker命令展示了Docker内部的运行。 通过对Docker架构的学习，可以全面深化对Docker设计、功能与价值的理解。同时在借助Docker实现用户定制的分布式系统时，也能更好地找到已有平台与Docker较为理想的契合点。另外，熟悉Docker现有架构以及设计思想，也能对云计算PaaS领域带来更多的启发，催生出更多实践与创新。 链接：https://www.2cto.com/kf/201701/582655.html 链接：https://blog.csdn.net/gsllovefly/article/details/51083419","path":"posts/c10c.html","date":"08-04","excerpt":"","tags":[{"name":"docker命令","slug":"docker命令","permalink":"https://wsdlxgp.top/tags/docker%E5%91%BD%E4%BB%A4/"}]},{"title":"03 Docker的基本操作命令","text":"Docker介绍 Docker 是一个能够把开发应用程序自动部署到容器的开源引擎。它由Docker公司的团队编写，基于Apache 2.0开源协议授权。它提供了一个简单、轻量的建模方式，使开发生命周期更高效快速，鼓励了面向服务的架构设计。Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。 Docker 的特点： 更快速的交付和部署 更高效的虚拟化 更轻松的迁移和扩展 更简单的管理 容器技术与传统虚拟机性能对比 Docker与虚拟机建构对比 Docker 容器本质上是宿主机上的一个进程。Docker 通过 namespace 实现了资源隔离，通过 cgroups 实现了资源的限制，通过写时复制机制（copy-on-write）实现了高效的文件操作。 **Docker有五个命名空间：**进程、网络、挂载、宿主和共享内存，为了隔离有问题的应用，Docker运用Namespace将进程隔离，为进程或进程组创建已隔离的运行空间，为进程提供不同的命名空间视图。这样，每一个隔离出来的进程组，对外就表现为一个container(容器)。需要注意的是，Docker让用户误以为自己占据了全部资源，但这并不是”虚拟机”。 Docker 中的三个概念：镜像，容器，仓库 镜像（image）：Docker 镜像就是一个只读的模板，镜像可以用来创建 Docker 容器。Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 镜像是一种文件结构。Dockerfile中的每条命令都会在文件系统中创建一个新的层次结构，文件系统在这些层次上构建起来，镜像就构建于这些联合的文件系统之上。Docker官方网站专门有一个页面来存储所有可用的镜像，网址是：index.docker.io。 容器（ Container）：容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。可以把容器看做是一个简易版的 Linux 环境，Docker 利用容器来运行应用。镜像是只读的，容器在启动的时候创建一层可写层作为最上层。 仓库：仓库是集中存放镜像文件的场所，仓库注册服务器（Registry）上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。目前，最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。 Docker仓库用来保存我们的images，当我们创建了自己的image之后我们就可以使用push命令将它上传到公有或者私有仓库，这样下次要在另外一台机器上使用这个image时候，只需要从仓库上pull下来就可以了。Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的服务。 Docker 基本操作 12 [root@localhost ~]# docker search mysql//查找镜像 这样查找相当于在https://hub.docker.com/中查找，大家尽量使用官方的镜像 12[root@localhost ~]# docker pull busybox//拉取镜像 12[root@localhost ~]# docker save -o busybox.tar busybox:latest//把镜像导出到本地 -o：相当--output导出 12[root@localhost ~]# docker images//查看本地镜像 仓库（镜像名称） 镜像标签 镜像id 创建时间 大小 虽然我们看到镜像标签为latest（最新的），但并不表示他一定是最新的。而且镜像如果没有写标签，默认以latest为标签。 12[root@localhost ~]# docker rmi busybox:latest//删除镜像 12[root@localhost ~]# docker images//查看本地镜像这里没有busybox 12[root@localhost ~]# docker load -i busybox.tar//根据本地镜像包导入镜像 12[root@localhost ~]# docker images//查看本地镜像这里又有busybox 12345678[root@localhost ~]# docker ps//查看容器-正在运行的[root@localhost ~]# docker ps -a//查看所有容器[root@localhost ~]# docker rm c3bb3a6f73eb//删除容器 id或镜像名称（不能删除正在运行的容器） 12[root@localhost ~]# docker stop test//停止容器运行 （记得验证一下docker ps -a） 12[root@localhost ~]# docker start test//启动容器 （记得验证一下docker ps -a） 12[root@localhost ~]# docker rm test -f//强制删除容器 （记得验证一下docker ps -a） 12[root@localhost ~]# docker ps -a -q | xargs docker rm -f//强制删除所有容器（生产环境严禁使用） 1234[root@localhost ~]# docker ps -a -q | xargs docker start -f//强制开启所有容器（生产环境严禁使用）[root@localhost ~]# docker ps -a -q | xargs docker stop -f//强制关闭所有容器（生产环境严禁使用） 123456789[root@localhost ~]# docker run -it --name test1 busybox:latest//开启一个容器-i：可交互-t：伪终端-d：守护进程--name：容器命名--restart=always：始终保持运行（随着docker开启而运行） [root@localhost ~]# docker run -itd --name test2 --restart=always busybox:latest//docker重启后，始终保持运行（随着docker开启而运行） 路由转发 123456[root@localhost ~]# vim /etc/sysctl.conf //添加路由转发[root@localhost ~]# sysctl -pnet.ipv4.ip_forward = 1net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1 进入容器方法 12345678910[root@localhost ~]# docker exec -it test2 /bin/sh//进入一个容器（退出容器后还在运行）[root@localhost ~]# docker attach test2//也是进入一个容器（退出容器不在运行）区别：exec进入的方式需要添加-i -t选项,后边还需要给容器一个shell环境。但attach就不需要这么麻烦。exec进入的方式:如果执行exit退出， 容器仍然保持运行。attach:如果执行exit退出, 容器会被关闭。如果想要保持容器不被关闭，可以使用用键盘: Ctrl + p Ctrl +q可以实现。本质上去区别: exec 进入的方法，会生产新的进程。attach不会生产新进程。 强制删除镜像 123 [root@localhost ~]# docker rmi centos:7 -f//强制删除镜像上面是把镜像标签给删了，要想彻底删除镜像，用下面的命令把镜像id也删了，docker有缓存机制，即使把这个镜像给删了，但是会有缓存，其他的容器依旧可以使用 Docker的基本操作逻辑 基于centos: 7镜像运行-个容器，并且,在这个容器内部署Nginx服务。 1)下载centos：7镜像 1[root@localhost ~]# docker pull centos:7 12[root@localhost ~]# rz上传一个nginx包 2)运行容器 1[root@localhost ~]# docker run -itd --name webapp --restart=always centos:7 3）进入容器，开始部署nginx服务 12345[root@localhost ~]# docker cp nginx-1.14.0.tar.gz webapp:/root//将nginx包导入到容器内[root@localhost ~]# docker exec -it webapp /bin/bash//进入容器[root@8604fb370aab /]# ls root 安装nginx 12345678910111213141516171819[root@8604fb370aab /]# cd /root[root@8604fb370aab ~]# tar zxf nginx-1.14.0.tar.gz[root@8604fb370aab ~]# yum -y install gcc pcre pcre-devel openssl-devel zlib zlib-devel make//安装nginx所需依赖[root@8604fb370aab ~]# cd nginx-1.14.0[root@8604fb370aab nginx-1.14.0]# useradd -M -s /sbin/nologin nginx//创建用户[root@8604fb370aab nginx-1.14.0]# ./configure --prefix=/usr/local/nginx --user=nginx --group=nginx && make && make install//编译安装 [root@8604fb370aab nginx-1.14.0]# ln -s /usr/local/nginx/sbin/nginx /usr/local/sbin///链接命令目录[root@8604fb370aab nginx-1.14.0]# nginx//启动nginx[root@8604fb370aab nginx-1.14.0]# cd /usr/local/nginx/html/[root@8604fb370aab html]# echo This is a testweb in container > index.html//创建一个测试页面[root@8604fb370aab html]# curl 127.0.0.1//访问网页 123456[root@8604fb370aab /]# yum provides ip//查看哪一个组件支持这条命令[root@8604fb370aab /]# yum -y install net-tools//安装支持这条命令的[root@8604fb370aab /]# ifconfig//查看ip 宿主机查看网页 1[root@localhost ~]# curl 172.17.0.4 12[root@localhost ~]# docker commit webapp myweb:xgp//把容器制作成镜像 （会返回一个哈希值，代表的是镜像的id号）增加可移植性 12[root@localhost ~]# docker images//查看镜像 123456[root@localhost ~]# docker run -itd --name webapp-2 myweb:xgp[root@localhost ~]# docker exec -it webapp-2 /bin/bash[root@e8d15e9aef29 /]# nginx [root@e8d15e9aef29 /]# curl 127.0.0.1This is a testweb in container[root@e8d15e9aef29 /]# ifconfig 查看网页 1[root@localhost ~]# curl 172.17.0.5","path":"posts/f1f1.html","date":"08-03","excerpt":"","tags":[{"name":"docker命令","slug":"docker命令","permalink":"https://wsdlxgp.top/tags/docker%E5%91%BD%E4%BB%A4/"}]},{"title":"02 docker底层原理介绍","text":"链接：https://blog.51cto.com/14320361/2457143 1.docker介绍 1.1什么是docker Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上。 1.2docker能解决什么问题 1.2.1高效有序利用资源 机器资源有限； 单台机器得部署多个应用； 应用之间互相隔离； 应用之间不能发生资源抢占，每个应用只能使用事先注册申请的资源。 1.2.2一次编译，到处运行 类似于java代码，应用及依赖的环境构建一次，可以到处运行。 1.2.docker底层原理介绍 1.2.1Linux的namespace和cgroup简单理解 namespace:类似于JAVA的命名空间 controll groups ： controll （system resource） （for） （process）groups 1.2.2Linux中的namespace 在Linux系统中，可以同时存在多用户多进程，那么对他们的运行协调管理，通过进程调度和进度管理可以解决，但是，整体资源是有限的，怎么把有限的资源（进程号、网络资源等等）合理分配给各个用户所在的进程？ Linux Namespaces机制提供一种资源隔离方案。PID,IPC,Network等系统资源不再是全局性的，而是属于某个特定的Namespace。每个namespace下的资源对于其他namespace下的资源都是透明，不可见的。因此在操作系统层面上看，就会出现多个相同pid的进程。系统中可以同时存在两个进程号为0,1,2的进程，由于属于不同的namespace，所以它们之间并不冲突。而在用户层面上只能看到属于用户自己namespace下的资源，例如使用ps命令只能列出自己namespace下的进程。这样每个namespace看上去就像一个单独的Linux系统。 命名空间建立系统的不同视图， 对于每一个命名空间，从用户看起来，应该像一台单独的Linux计算机一样，有自己的init进程(PID为0)，其他进程的PID依次递增，A和B空间都有PID为0的init进程，子容器的进程映射到父容器的进程上，父容器可以知道每一个子容器的运行状态，而子容器与子容器之间是隔离的。 **|** namespace | 引入的相关内核版本 | 被隔离的全局系统资源 | 在容器语境下的隔离效果 | | — | — | — | — | | Mount namespaces | Linux 2.4.19 | 文件系统挂接点 | 将一个文件系统的顶层目录挂到另一个文件系统的子目录上，使它们成为一个整体，称为挂载。把该子目录称为挂载点。 Mount namespace用来隔离文件系统的挂载点, 使得不同的mount namespace拥有自己独立的挂载点信息，不同的namespace之间不会相互影响，这对于构建用户或者容器自己的文件系统目录非常有用。 | | UTS namespaces | Linux 2.6.19 | nodename 和 domainname | UTS，UNIX Time-sharing System namespace提供了主机名和域名的隔离。能够使得子进程有独立的主机名和域名(hostname)，这一特性在Docker容器技术中被用到，使得docker容器在网络上被视作一个独立的节点，而不仅仅是宿主机上的一个进程。 | | IPC namespaces | Linux 2.6.19 | 特定的进程间通信资源，包括System V IPC 和 POSIX message queues | IPC全称 Inter-Process Communication，是Unix/Linux下进程间通信的一种方式，IPC有共享内存、信号量、消息队列等方法。所以，为了隔离，我们也需要把IPC给隔离开来，这样，只有在同一个Namespace下的进程才能相互通信。如果你熟悉IPC的原理的话，你会知道，IPC需要有一个全局的ID，即然是全局的，那么就意味着我们的Namespace需要对这个ID隔离，不能让别的Namespace的进程看到。 | | PID namespaces | Linux 2.6.24 | 进程 ID 数字空间 （process ID number space） | PID namespaces用来隔离进程的ID空间，使得不同pid namespace里的进程ID可以重复且相互之间不影响。 PID namespace可以嵌套，也就是说有父子关系，在当前namespace里面创建的所有新的namespace都是当前namespace的子namespace。父namespace里面可以看到所有子孙后代namespace里的进程信息，而子namespace里看不到祖先或者兄弟namespace里的进程信息。 | | Network namespaces | 始于Linux 2.6.24 完成于 Linux 2.6.29 | 网络相关的系统资源 | 每个容器用有其独立的网络设备，IP 地址，IP 路由表，/proc/net 目录，端口号等等。这也使得一个 host 上多个容器内的同一个应用都绑定到各自容器的 80 端口上。 | | User namespaces | 始于 Linux 2.6.23 完成于 Linux 3.8) | 用户和组 ID 空间 | User namespace用来隔离user权限相关的Linux资源，包括user IDs and group IDs。 这是目前实现的namespace中最复杂的一个，因为user和权限息息相关，而权限又事关容器的安全，所以稍有不慎，就会出安全问题。 在不同的user namespace中，同样一个用户的user ID 和group ID可以不一样，换句话说，一个用户可以在父user namespace中是普通用户，在子user namespace中是超级用户 1.3Namespace（名称空间） 用来隔离容器 12 [root@localhost ~]# docker run -it --name test centos /bin/bash//进入到容器里面 12[root@41052cceb473 /]# ls//查看一下和宿主机差不多，都是从宿主机链接过来的 12[root@41052cceb473 /]# uname -r//查看一下内核，和宿主机也是一样的 如果虚拟机内服务对内核版有要求，这个服务就不太适合用docker来实现了，因为docker就是共用宿主机的内核，可以使用kvm之类的虚拟机。 12[root@localhost ~]# docker pull ubuntu//使用docker下载一个Ubuntu 12[root@localhost ~]# docker images//查看一下 1234[root@localhost ~]# docker run -it ubuntu:latest /bin/bash//进入ubuntu环境root@afbee6750865:/# ls ///查看一下 12root@48c8dd7b098e:/# uname -r//查看一下内核 Docker本身不占用任何端口，他一般是在后台运行，无论在docker里进行什么操作（系统、服务）对于docker来说他们仅仅就是一个进程 Run-centos系统（nginx，web） Busybox：欺骗层。欺骗docker中的虚拟机是在自己独立的环境中 解耦：解除耦合、冲突。 耦合：冲突现象。 1.4 Namespace操作 /proc /sys:虚拟文件系统，伪目录文件 12[root@localhost ~]# cd /proc/[root@localhost proc]# ls 1234567[root@localhost proc]# echo $$//当前的进程编号3864[root@localhost proc]# cd 3864[root@localhost 3864]# cd ns[root@localhost ns]# ll//可以看到一闪一闪的 1[root@localhost ns]# ls IPC:共享内存、消息列队 MNT:挂载点、文件系统 NET:网络栈 PID: 进程编号 USER:用户、组 UTS:主机名、域名 namespec这六项隔离，实现了容器与宿主机，容器与容器之间的隔离 //创建一个用户并设置密码 IPC:共享内存、消息列队 MNT:挂载点、文件系统 NET:网络栈 PID: 进程编号 USER:用户、组 UTS:主机名、域名 namespec这六项隔离，实现了容器与宿主机，容器与容器之间的隔离 //创建一个用户并设置密码 123[root@localhost ns]# useradd bdqn [root@localhost ns]# echo 123.com | passwd --stdin bdqn[root@localhost ns]# id bdqn 查看docker进程 [root@localhost ns]# docker ps -a 12345[root@localhost ns]# docker start test//启动centos[root@localhost ns]# docker exec -it test /bin/bash//进入docker容器[root@41052cceb473 /]# id dbqn 1[root@41052cceb473 /]# echo $$ 2.1linux cgroup介绍 2.1.1有了namespace为什么还要cgroup: Docker 容器使用 linux namespace 来隔离其运行环境，使得容器中的进程看起来就像一个独立环境中运行一样。但是，光有运行环境隔离还不够，因为这些进程还是可以不受限制地使用系统资源，比如网络、磁盘、CPU以及内存 等。关于其目的，一方面，是为了防止它占用了太多的资源而影响到其它进程；另一方面，在系统资源耗尽的时候，linux 内核会触发 OOM，这会让一些被杀掉的进程成了无辜的替死鬼。因此，为了让容器中的进程更加可控，Docker 使用 Linux cgroups 来限制容器中的进程允许使用的系统资源。 2.1.2原理 Linux Cgroup 可为系统中所运行任务（进程）的用户定义组群分配资源 — 比如 CPU 时间、系统内存、网络带宽或者这些资源的组合。可以监控管理员配置的 cgroup，拒绝 cgroup 访问某些资源，甚至在运行的系统中动态配置 cgroup。所以，可以将 controll groups 理解为 controller （system resource） （for） （process）groups，也就是是说它以一组进程为目标进行系统资源分配和控制。它主要提供了如下功能： Resource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。 Prioritization: 优先级控制，比如：CPU利用和磁盘IO吞吐。 Accounting: 一些审计或一些统计，主要目的是为了计费。 Controll: 挂起进程，恢复执行进程。 使用 cgroup，系统管理员可更具体地控制对系统资源的分配、优先顺序、拒绝、管理和监控。可更好地根据任务和用户分配硬件资源，提高总体效率。 在实践中，系统管理员一般会利用CGroup做下面这些事： 隔离一个进程集合（比如：nginx的所有进程），并限制他们所消费的资源，比如绑定CPU的核。 为这组进程分配其足够使用的内存 为这组进程分配相应的网络带宽和磁盘存储限制 限制访问某些设备（通过设置设备的白名单） 2.1.3Cgroup(控制组)操作 资源的限制，docker对于资源的占用 123[root@localhost ~]# cd /sys/fs/cgroup///对cpu，内存限制的目录[root@localhost cgroup]# ls 12[root@localhost cgroup]# cd cpu[root@localhost cpu]# ls cpu.shares：权重 tasks：这个文件内的数字，记录的是进程编号。PID 12[root@localhost cpu]# cd docker/[root@localhost docker]# ls 1234[root@localhost docker]# cat tasks//里面是空的[root@localhost docker]# cd 41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70/[root@localhost41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70]#[root@localhost docker]# cat tasks//里面是空的[root@localhost docker]# cd 41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70/[root@localhost41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70]# ls 1[root@localhost41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70]#[root@localhost41052cceb4739fa8e0ddd2ffa733a78cd1043b3fdff874cd266c009391a34d70]# cat tasks 四大功能： 1） 资源的限制：cgroup可以对进程组使用的资源总额进行限制 2） 优先级分配：通过分配的cpu时间片数量以及硬盘IO带宽的大小，实际上相当于控制了进程运行的优先级别 3） 资源统计： group可以统计系统资源使用量，比如gpu使用时间，内存使用量等，用于按量计费。同时还支持挂起动能，也就是说通过cgroup把所有 资源限制起来,对资源都不能使用，注意着并不是说我们的程序不能使用了,知识不能使用资源，处于等待状态。 4） 进程控制：可以对进程组执行挂起、恢复等操作。 2.1.4 内存限额 容器内存包括两个部分：物理内存和swap 可以通过参数控制容器内存的使用量： -m或者–memory:设置内存的使用限额 –memory-swap:设置内存+ swap的使用限额 举个例子： 运行一个容器，并且限制该容器最多使用200M内存和100M的swap 123[root@localhost ~]# docker run -it -m 200M --memory-swap 300M centos:7[root@fba67fec2718 ~]# cd /sys/fs/cgroup/[root@fba67fec2718 cgroup]# ls 1234[root@fba67fec2718 cgroup]# cd memory/[root@fba67fec2718 memory]# ls[root@fba67fec2718 memory]# cat memory.limit_in_bytes//查看内存使用限制，(单位字节） 12[root@fba67fec2718 memory]# cat memory.memsw.limit_in_bytes//查看交换分区，内存+swap限制 运行一个新容器，并且不限制该容器 1234[root@localhost ~]# docker run -it centos:7[root@5be901bfb093 /]# cd /sys/fs/cgroup/memory/[root@5be901bfb093 memory]# cat memory.limit_in_bytes//查看内存限制 12[root@5be901bfb093 memory]# cat memory.memsw.limit_in_bytes//查看交换分区，内存+swap限制 对比一个没有限制的容器，我们会发现，如果运行容器之后不限制内存的话，意味着没有限制。 2.1.5 CPU使用 通过-c或者–cpu -shares设置容器使用cpu的权重。如果不设置默认为1024. 举个例子： 没有限制 1234[root@localhost ~]# docker run -it --name containerA centos:7//没有限制，1024[root@8683d8ff8234 /]# cd /sys/fs/cgroup/cpu[root@8683d8ff8234 cpu]# cat cpu.shares 限制CPU使用权重为512 1234[root@localhost ~]# docker run -it --name containerB -c 512 centos:7//限制CPU使用权重为512[root@d919d906295d /]# cd /sys/fs/cgroup/cpu//可以看到cpu已经限制了 2.1.6 容器的Block IO 磁盘的读写。 Docker中可以通过设置权重，限制bps和iops的方式控制容器读写磁盘的IO bps:每秒读写的数据量byte per second iopS:每秒IO的次数 io per second。 默认情况下，所有容器都能够平等的读写磁盘，也可以通过–blkig-weight参数改变容器的blocklO的优先级。 –device-read-bps:显示读取某个设备的bps。 –device-write-bps:显示写入某个设备的bps. –device-read-iops:显示读取某个设备的iops. –device-write-iops:显示写入某个设备的iops. 限制testA这个容器，写入/dev/sda这块磁盘的bps为30MB 1234[root@localhost ~]# docker run -it --name testA --device-write-bps /dev/sda:30MB centos:7 [root@60e59e96fc16 /]# time dd if=/dev/zero of=test.out bs=1M count=800 oflag=direct//从/dev/zero输入，然后输出到test.out文件中，每次大小为1M，总共800次,oflag=direct 用来指定directlQ方式写文件，这样才会使--device-write-bps生效。 1[root@60e59e96fc16 /]# du -h test.out docker没有限制 12[root@localhost ~]# docker run -it --name testc centos:7[root@5bf5f3d60d0e /]# time dd if=/dev/zero of=test.out bs=1M count=800 oflag=direct 1[root@5bf5f3d60d0e /]# du -h test.out 3.Docker虚拟化与普通虚拟化的区别是什么？ 虚拟机： 我们传统的虚拟机需要模拟整台机器包括硬件，每台虚拟机都需要有自己的操作系统，虚拟机一旦被开启，预分配给他的资源将全部被占用。，每一个虚拟机包括应用，必要的二进制和库，以及一个完整的用户操作系统。 Docker： 容器技术是和我们的宿主机共享硬件资源及操作系统可以实现资源的动态分配。 容器包含应用和其所有的依赖包，但是与其他容器共享内核。容器在宿主机操作系统中，在用户空间以分离的进程运行。 虚拟机和容器都是在硬件和操作系统以上的，虚拟机有Hypervisor层，Hypervisor是整个虚拟机的核心所在。他为虚拟机提供了虚拟的运行平台，管理虚拟机的操作系统运行。每个虚拟机都有自己的系统和系统库以及应用。 容器没有Hypervisor这一层，并且每个容器是和宿主机共享硬件资源及操作系统，那么由Hypervisor带来性能的损耗，在linux容器这边是不存在的。 但是虚拟机技术也有其优势，能为应用提供一个更加隔离的环境，不会因为应用程序的漏洞给宿主机造成任何问题。同时还支持跨操作系统的虚拟化，例如你可以在linux操作系统下运行windows虚拟机。 从虚拟化层面来看，传统虚拟化技术是对硬件资源的虚拟，容器技术则是对进程的虚拟，从而可提供更轻量 级的虚拟化，实现进程和资源的隔离。 从架构来看，Docker比虚拟化少了两层，取消了hypervisor层和GuestOS层，使用 Docker Engine 进行调度和隔离，所有应用共用主机操作系统，因此在体量上，Docker较虚拟机更轻量级，在性能上优于虚拟化，接近裸机性能。从应用场景来 看，Docker和虚拟化则有各自擅长的领域，在软件开发、测试场景和生产运维场景中各有优劣 具体对比： docker启动快速属于秒级别。虚拟机通常需要几分钟去启动。 docker需要的资源更少，docker在操作系统级别进行虚拟化，docker容器和内核交互，几乎没有性能损耗，性能优于通过Hypervisor层与内核层的虚拟化。； docker更轻量，docker的架构可以共用一个内核与共享应用程序库，所占内存极小。同样的硬件环境，Docker运行的镜像数远多于虚拟机数量。对系统的利用率非常高 与虚拟机相比，docker隔离性更弱，docker属于进程之间的隔离，虚拟机可实现系统级别隔离； 安全性： docker的安全性也更弱。Docker的租户root和宿主机root等同，一旦容器内的用户从普通用户权限提升为root权限，它就直接具备了宿主机的root权限，进而可进行无限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且虚拟机利用如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种隔离技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离，这使得容器容易受到***。 可管理性：docker的集中化管理工具还不算成熟。各种虚拟化技术都有成熟的管理工具，例如VMware vCenter提供完备的虚拟机管理能力。 高可用和可恢复性：docker对业务的高可用支持是通过快速重新部署实现的。虚拟化具备负载均衡，高可用，容错，迁移和数据保护等经过生产实践检验的成熟保障机制，VMware可承诺虚拟机99.999%高可用，保证业务连续性。 快速创建、删除：虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了无论是开发、测试、部署都可以节约大量时间。 交付、部署：虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化；Docker在Dockerfile中记录了容器构建过程，可在集群中实现快速分发和快速部署; 3.1.1 docker结构介绍 基础设施(Infrastructure)。 主操作系统(Host Operating System)。所有主流的Linux发行版都可以运行Docker。对于MacOS和Windows，也有一些办法”运行”Docker。 Docker守护进程(Docker Daemon)。Docker守护进程取代了Hypervisor，它是运行在操作系统之上的后台进程，负责管理Docker容器。 各种依赖。对于Docker，应用的所有依赖都打包在Docker镜像中，Docker容器是基于Docker镜像创建的。 应用。应用的源代码与它的依赖都打包在Docker镜像中，不同的应用需要不同的Docker镜像。不同的应用运行在不同的Docker容器中，它们是相互隔离的。 Docker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源；虚拟机更擅长于资源的完全隔离。 链接：https://blog.51cto.com/14320361/2457143","path":"posts/df9f.html","date":"08-02","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"},{"name":"kvm","slug":"kvm","permalink":"https://wsdlxgp.top/tags/kvm/"}]},{"title":"01 花式安装Docker","text":"//使用docker的基本要求 12[root@localhost ~]# uname -r3.10.0-693.el7.x86_64 内核版本必须是3.10以上的。 一， 安装dockers 在安装docker之前，再说一点，docker现在有两个版本，一个叫做docker-EE企业版，收费的一个叫docker-CE社区版，免费版，其实两个版本并没有太大的偏差，不一样的是docker公司会提供后续的官方的技术支持等服务，对于我们来说，肯定用社区办的多，我们拿来学习社区办更是可以的。 Docker的官网 https://www.docker.com/ 1，从Docker的官方下载 https://www.docker.com/ 2．官网安装docker方法一 1234567891011121314151617181920212223[root@localhost ~]# vim /etc/yum.repos.d/docke-ce.repo//编写yum源[docker-ce]name=docker-cebaseurl=https://download.docker.com/linux/centos/7/x86_64/stable/Packages/gpgcheck=0enabled=1 [root@localhost ~]# yum repolist//查看仓库状态 [root@localhost ~]# vim /etc/yum.repos.d/docke-ce.repo//修改yum源[docker-ce]name=docker-cebaseurl=https://download.docker.com/linux/centos/7/x86_64/stable/gpgcheck=0enabled=1[root@localhost ~]# yum repolist//查看仓库状态 [root@localhost ~]# yum -y install docker-ce//默认下载最新版，时间慢，一般不用这个 因为网速原因，所以我们一般可以采取另外- -种方法，从我们国内下载，国内很多网站都提供了docker-ce的镜像站，比如说阿里云、网易云、清华大学镜像站等。这里我们从阿里云下载的方式来下载。 3.阿里云下载方法二 12[root@localhost ~]# rm -rf /etc/yum.repos.d/docke-ce.repo//删除刚刚的yum源 进入阿里镜像站 https://developer.aliyun.com/mirror 12345[root@localhost ~]# yum install -y yum-utils device-mapper-persistent-data lvm2[root@localhost ~]# yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo[root@localhost ~]# ls /etc/yum.repos.d///查看yum源 12[root@localhost ~]# yum repolist//查看仓库状态 12345[root@localhost ~]# yum makecache//做yum缓存，提速[root@localhost ~]# yum list docker-ce.x86_64 --showduplicates | sort -r//查看docker可用的版本 //这里我们下载指定版本18.9.0，注意并没有采取阿里云官方推荐的方法，我们分别下载了docker-ce,docker-ce-cli和containerd.io这3个组件。 12[root@localhost ~]# yum -y install docker-ce-18.09.0-3.el7 docker-ce-cli-18.09.0-3.el7 tainerd.io-1.2.0-el7//安装docker-ce,docker-ce-cli和containerd.io这3个组件 4.安装完成之后 1234567[root@localhost ~]# systemctl start docker//开启docker[root@localhost ~]# systemctl enable docker//docker加入开机自启[root@localhost ~]# docker -vDocker version 18.09.0, build 4d60db4//查看docker版本是否是指定的版本 12[root@localhost ~]# docker version//查看docker版本信息 12如果是最小化安装，来装一个tab命令补全[root@localhost ~]# yum -y install bash-completion 二，Docker的基本概念 image:镜像 container：容器 repostry:仓库 镜像是容器运行的基石，容器是镜像运行之后的实例。 12[root@localhost ~]# docker pull centos:7//下载一个centos7镜像，特别慢不建议 1，设置加速 浏览器打开加速网站：道客云https://www.daocloud.io/ //使用docker镜像加速器，这里使用的是daocloud的加速器，当然还有其他的加速器，例 如阿里云、清华镜像站等。 [root@localhost ~]# curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io 1234567[root@localhost ~]# systemctl daemon-reload//守护进程[root@localhost ~]# systemctl restart docker//重启docker[root@localhost ~]# docker info//查看docker的详细信息 123[root@localhost ~]# cat /etc/docker/daemon.json&#123;\"registry-mirrors\": [\"http://f1361db2.m.daocloud.io\"]&#125;//都是键值对 12[root@localhost ~]# docker pull centos:7//再次下载centos7 12[root@localhost ~]# docker images//查看本地镜像有哪些 2，更改镜像加速网站为阿里云的 https://www.aliyun.com/product/acr?spm=5176.12825654.eofdhaal5.42.366f2c4axwzdLK&amp;aly_as=kt8HE3oy 1234[root@localhost ~]# cat /etc/docker/daemon.json&#123;\"registry-mirrors\": [\"http://f1361db2.m.daocloud.io\"]&#125; //把刚刚复制的https://x7bv0r2q.mirror.aliyuncs.com，替换掉上面的 也可以更改成这个网址，当然如果你更改之后，还需要执行reload命令，重新加载一下配置文件。 12345[root@docker ~]# systemctl daemon-reload [root@docker ~]# systemctl restart docker[root@docker ~]# docker pull centosUsing default tag: latestlatest: Pulling from library/centos 3，更改镜像加速网站为清华大学的 清华大学镜像站网址：https://mirrors.tuna.tsinghua.edu.cn/ 测试：下载一个nginx [root@localhost ~]# docker pull nginx 12[root@localhost ~]# docker images//查看本地镜像有哪些 12345[root@localhost ~]# docker run -itd -p 80 nginx//多执行几次，运行多台nginx[root@localhost ~]# docker ps//查看docker服务 浏览器测试 **开源项目：**诞生于2013年，dotcloud公司的业余项目，Go语言实现。—公司改名docker 集装箱：目标是实现轻量级的操作系统虚拟化方案。让用户不需要关心容器的管理，使得操作更加简便。 docker和虚拟机、传统虚拟化的区别： 传统的虚拟机：在硬件实现虚拟化，然后创建/安装操作系统。 docker：在操作系统层面实现虚拟化，直接服用本地主机的操作系统。 为什么使用docker 1，与传统虚拟化方式相比，具有众多的优势 a,docker容器启动在秒级 b,docker对系统资源利用率高，一台主机可以同时运行数千个docker容器 c,docker基本不消耗系统资源，使得运行在docker里面的应用的性能很高 2，其他优势： a,更快的支付和部署：开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容易来部署代码； b,更高级的虚拟化，docker容器的运行不需要额外的支持，它是内核级的虚拟化，因此可以实现更高的性能 c,更轻松的迁移和扩展：docker几乎可以在任意平台运行，比如物理机，虚拟机，公有云，私有云，个人电脑，服务器等。 d,更简单的管理：使用docker只需要简单的修改，就可以替代以往大量的更新工作。所有的修改都一增量方式被分发和更新，从而实现自动化并且高效的管理。 docker中的基本概念： 镜像（images):只读的模板，通过这个模板创建docker容器 容器(container):是使用镜像创建并运行的实例。可以简单的将容器看做是简化版的操作系统。(可以看做是操作系统是因为里面包含root用户权限，进程空间和网络空间，还包括运行在里面的应用程序) 仓库(repository):集中存放镜像文件的地方。分为共有仓库和私有仓库。","path":"posts/dd75.html","date":"08-01","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"},{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"}]}],"categories":[],"tags":[{"name":"sql结构化查询语句","slug":"sql结构化查询语句","permalink":"https://wsdlxgp.top/tags/sql%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/"},{"name":"数值类型","slug":"数值类型","permalink":"https://wsdlxgp.top/tags/%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/"},{"name":"nfs","slug":"nfs","permalink":"https://wsdlxgp.top/tags/nfs/"},{"name":"pv","slug":"pv","permalink":"https://wsdlxgp.top/tags/pv/"},{"name":"pvc","slug":"pvc","permalink":"https://wsdlxgp.top/tags/pvc/"},{"name":"dashboard","slug":"dashboard","permalink":"https://wsdlxgp.top/tags/dashboard/"},{"name":"helm","slug":"helm","permalink":"https://wsdlxgp.top/tags/helm/"},{"name":"deployment","slug":"deployment","permalink":"https://wsdlxgp.top/tags/deployment/"},{"name":"StorageClass","slug":"StorageClass","permalink":"https://wsdlxgp.top/tags/StorageClass/"},{"name":"python","slug":"python","permalink":"https://wsdlxgp.top/tags/python/"},{"name":"jenkins","slug":"jenkins","permalink":"https://wsdlxgp.top/tags/jenkins/"},{"name":"gitlab","slug":"gitlab","permalink":"https://wsdlxgp.top/tags/gitlab/"},{"name":"chares","slug":"chares","permalink":"https://wsdlxgp.top/tags/chares/"},{"name":"url","slug":"url","permalink":"https://wsdlxgp.top/tags/url/"},{"name":"chart","slug":"chart","permalink":"https://wsdlxgp.top/tags/chart/"},{"name":"tiller","slug":"tiller","permalink":"https://wsdlxgp.top/tags/tiller/"},{"name":"HPA","slug":"HPA","permalink":"https://wsdlxgp.top/tags/HPA/"},{"name":"heapster","slug":"heapster","permalink":"https://wsdlxgp.top/tags/heapster/"},{"name":"top","slug":"top","permalink":"https://wsdlxgp.top/tags/top/"},{"name":"weave-scope","slug":"weave-scope","permalink":"https://wsdlxgp.top/tags/weave-scope/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://wsdlxgp.top/tags/Prometheus/"},{"name":"ingress-nginx","slug":"ingress-nginx","permalink":"https://wsdlxgp.top/tags/ingress-nginx/"},{"name":"https","slug":"https","permalink":"https://wsdlxgp.top/tags/https/"},{"name":"ca","slug":"ca","permalink":"https://wsdlxgp.top/tags/ca/"},{"name":"nginx","slug":"nginx","permalink":"https://wsdlxgp.top/tags/nginx/"},{"name":"ingress","slug":"ingress","permalink":"https://wsdlxgp.top/tags/ingress/"},{"name":"ingress controller","slug":"ingress-controller","permalink":"https://wsdlxgp.top/tags/ingress-controller/"},{"name":"secret","slug":"secret","permalink":"https://wsdlxgp.top/tags/secret/"},{"name":"pod","slug":"pod","permalink":"https://wsdlxgp.top/tags/pod/"},{"name":"configmap","slug":"configmap","permalink":"https://wsdlxgp.top/tags/configmap/"},{"name":"Storage Class","slug":"Storage-Class","permalink":"https://wsdlxgp.top/tags/Storage-Class/"},{"name":"StatefulSet","slug":"StatefulSet","permalink":"https://wsdlxgp.top/tags/StatefulSet/"},{"name":"nfs-deployment","slug":"nfs-deployment","permalink":"https://wsdlxgp.top/tags/nfs-deployment/"},{"name":"emptyDir","slug":"emptyDir","permalink":"https://wsdlxgp.top/tags/emptyDir/"},{"name":"swarm","slug":"swarm","permalink":"https://wsdlxgp.top/tags/swarm/"},{"name":"Job","slug":"Job","permalink":"https://wsdlxgp.top/tags/Job/"},{"name":"apiVersion","slug":"apiVersion","permalink":"https://wsdlxgp.top/tags/apiVersion/"},{"name":"CronJob","slug":"CronJob","permalink":"https://wsdlxgp.top/tags/CronJob/"},{"name":"Replica","slug":"Replica","permalink":"https://wsdlxgp.top/tags/Replica/"},{"name":"SetDaemonSet","slug":"SetDaemonSet","permalink":"https://wsdlxgp.top/tags/SetDaemonSet/"},{"name":"标签","slug":"标签","permalink":"https://wsdlxgp.top/tags/%E6%A0%87%E7%AD%BE/"},{"name":"liveness","slug":"liveness","permalink":"https://wsdlxgp.top/tags/liveness/"},{"name":"readiness","slug":"readiness","permalink":"https://wsdlxgp.top/tags/readiness/"},{"name":"滚动更新","slug":"滚动更新","permalink":"https://wsdlxgp.top/tags/%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0/"},{"name":"Namespace","slug":"Namespace","permalink":"https://wsdlxgp.top/tags/Namespace/"},{"name":"PodRestart","slug":"PodRestart","permalink":"https://wsdlxgp.top/tags/PodRestart/"},{"name":"Policy","slug":"Policy","permalink":"https://wsdlxgp.top/tags/Policy/"},{"name":"service","slug":"service","permalink":"https://wsdlxgp.top/tags/service/"},{"name":"Deployment","slug":"Deployment","permalink":"https://wsdlxgp.top/tags/Deployment/"},{"name":"yaml","slug":"yaml","permalink":"https://wsdlxgp.top/tags/yaml/"},{"name":"deployments","slug":"deployments","permalink":"https://wsdlxgp.top/tags/deployments/"},{"name":"registry","slug":"registry","permalink":"https://wsdlxgp.top/tags/registry/"},{"name":"docker","slug":"docker","permalink":"https://wsdlxgp.top/tags/docker/"},{"name":"kubeadml","slug":"kubeadml","permalink":"https://wsdlxgp.top/tags/kubeadml/"},{"name":"overlay","slug":"overlay","permalink":"https://wsdlxgp.top/tags/overlay/"},{"name":"webUI","slug":"webUI","permalink":"https://wsdlxgp.top/tags/webUI/"},{"name":"consul","slug":"consul","permalink":"https://wsdlxgp.top/tags/consul/"},{"name":"registrata","slug":"registrata","permalink":"https://wsdlxgp.top/tags/registrata/"},{"name":"prometheus","slug":"prometheus","permalink":"https://wsdlxgp.top/tags/prometheus/"},{"name":"alertmanager","slug":"alertmanager","permalink":"https://wsdlxgp.top/tags/alertmanager/"},{"name":"grafana","slug":"grafana","permalink":"https://wsdlxgp.top/tags/grafana/"},{"name":"sysdig","slug":"sysdig","permalink":"https://wsdlxgp.top/tags/sysdig/"},{"name":"Weave Scope","slug":"Weave-Scope","permalink":"https://wsdlxgp.top/tags/Weave-Scope/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://wsdlxgp.top/tags/docker-compose/"},{"name":"wordpress","slug":"wordpress","permalink":"https://wsdlxgp.top/tags/wordpress/"},{"name":"lnmp","slug":"lnmp","permalink":"https://wsdlxgp.top/tags/lnmp/"},{"name":"docker网络","slug":"docker网络","permalink":"https://wsdlxgp.top/tags/docker%E7%BD%91%E7%BB%9C/"},{"name":"bind mount","slug":"bind-mount","permalink":"https://wsdlxgp.top/tags/bind-mount/"},{"name":"docker manager volu","slug":"docker-manager-volu","permalink":"https://wsdlxgp.top/tags/docker-manager-volu/"},{"name":"manual","slug":"manual","permalink":"https://wsdlxgp.top/tags/manual/"},{"name":"macvlan","slug":"macvlan","permalink":"https://wsdlxgp.top/tags/macvlan/"},{"name":"bridge桥接","slug":"bridge桥接","permalink":"https://wsdlxgp.top/tags/bridge%E6%A1%A5%E6%8E%A5/"},{"name":"docker-registry","slug":"docker-registry","permalink":"https://wsdlxgp.top/tags/docker-registry/"},{"name":"docker私有仓库","slug":"docker私有仓库","permalink":"https://wsdlxgp.top/tags/docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"},{"name":"dockerfile参数","slug":"dockerfile参数","permalink":"https://wsdlxgp.top/tags/dockerfile%E5%8F%82%E6%95%B0/"},{"name":"镜像","slug":"镜像","permalink":"https://wsdlxgp.top/tags/%E9%95%9C%E5%83%8F/"},{"name":"bash","slug":"bash","permalink":"https://wsdlxgp.top/tags/bash/"},{"name":"dockerfile","slug":"dockerfile","permalink":"https://wsdlxgp.top/tags/dockerfile/"},{"name":"docker命令","slug":"docker命令","permalink":"https://wsdlxgp.top/tags/docker%E5%91%BD%E4%BB%A4/"},{"name":"kvm","slug":"kvm","permalink":"https://wsdlxgp.top/tags/kvm/"}]}